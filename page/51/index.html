<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta name="generator" content="Hugo 0.121.1">
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="菜鸟程序员博客">
		<meta property="og:title" content="菜鸟程序员博客" />
<meta property="og:description" content="菜鸟程序员博客" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://cainiaoprogram.github.io/" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	
	<link rel="alternate" type="application/rss+xml" href="/index.xml" title="菜鸟程序员博客">

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main list" role="main">
	<article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/430a3b76b877cc5f4b8fbffd0863198e/" rel="bookmark">
			mac zsh: command not found: python
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 前言 在 mac 上安装 python 后，会自动在 .zprofile 文件中，加入：
# Setting PATH for Python 3.12 # The original version is saved in .zprofile.pysave PATH="/Library/Frameworks/Python.framework/Versions/3.12/bin:${PATH}" export PATH 此时，python -V，还是会报错 zsh: command not found: python
解决 # 编辑环境变量文件 vim .zprofile # 新增如下 alias python="/Library/Frameworks/Python.framework/Versions/3.12/bin/python3" # 更新环境变量 source .zprofile $ python -V Python 3.12.1 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/6f7c65fec8e960388e938f80c22734ae/" rel="bookmark">
			从0开始python学习-35.allure报告企业定制
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录
1. 搭建allure环境
2. 生成报告
3. logo定制
4. 企业级报告内容或层级定制
5. allure局域网查看
1. 搭建allure环境 1.1 JDK，使用PyCharm
找到pycharm安装目录找到java.exe记下jbr目录的完整路径，eg: C:\Program Files\JetBrains\PyCharm Community Edition 2022.3\jbr\bin将地址添加进入环境变量重启 1.2 allure程序
下载地址：https://github.com/allure-framework/allure2/releases解压到指定路径。eg: D:\study\allure-2.25.0\allure-2.25.0\bin执行allurePath 追加allure安装路径验证是否安装成功：在dos窗口和Pycharm（需要重启加载环境变量）中都需要验证：allure --version 2. 生成报告 2.1 生成临时的json格式的报告
addopts = -vs --alluredir=./temps --clean-alluredir ; --clean-alluredir生成临时报告并清除 2.2 生成HTML的allure报告
if __name__ == "__main__": pytest.main(['./test_study/test_fixture.py']) os.system("allure generate ./temps -o ./reports --clean") # -o 指定输出测试报告路径 # --clean 清空历史数据 # ./temps 表示用来生成html的JSON临时文件目录 # ./reports 表示html文件生成目录 3. logo定制 3.1 在D:\study\allure-2.25.0\allure-2.25.0\config目录下的allure.yml中配置自定义的logo插件【- custom-logo-plugin】
3.2 重新运行并生成allue报告
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/6f7c65fec8e960388e938f80c22734ae/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/aeab0943eabe09c93d56505f2345a6df/" rel="bookmark">
			【期末考试】计算机网络、网络及其计算 考试重点
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		个人简介：Java领域新星创作者；阿里云技术博主、星级博主、专家博主；正在Java学习的路上摸爬滚打，记录学习的过程~
个人主页：.29.的博客
学习社区：进去逛一逛~
计算机网络及其计算 期末考点 🚀数据通信系统🚀计算机网络🚀物理层🚀数据链路层🚀网络层🚀传输层 🚀数据通信系统 数字通信：
数字通信的优点： 抗干扰性强、保密性好、设备易于集成化、便于使用计算机技术对其进行处理等。
数字通信的缺点： 占用的信道频带比模拟通信宽得多，降低了信道利用率。
数据通信系统 - 模型：
由 源系统、传输系统、目的系统 组成，有五个组成部分：
源点： 生成传输数据的设备，如PC。发送器： 源点生成的数据需要发送器编码后才能成为在传输系统中进行传输的电信号。传输系统： 简单的传输线或复杂的网络系统。接收器： 接收来自传输系统的信号，将其转换成数字比特流。终点： 获取来自接收器数据的设备。 数据通信系统的主要性能指标：
有效性指标： 衡量数据通信系统 传输能力 的指标。通常用 带宽、传输速率、频带利用率等指标表示。
特征性指标： 衡量数据通信系统 传输质量 的指标。
①差错率： 常用误码率表示。
②可靠性： 由两种主要指标表示：
平均无故障工作时间MTBF： Mean Time Between Failure，系统各部件相邻两次故障的平均间隔时间，一般来说MTBF值越大越好。平均故障维修时间MTTR： Mean Time To Repair，系统发生故障时需要维修花费的平均时间，一般来说MTTR值越小越好。可靠性定量特征的描述用 系统有效度(A) 更为确切： ③通信建立时间： 反映数据通信系统同步性能的指标，该指标应尽可能短。
④适应性： 指系统对外界条件变化的适应能力。
⑤使用维修性： 操作与维护是否简单方便，应具备必要的性能显示与自动故障检测报警功能，便于迅速排除故障。同时要求系统体积小，重量轻。
⑥经济性： 就是常说的性能价格比指标。
⑦标准性： 是缩短研制周期、降低生产成本、利于用户选购、便于维修的重要措施。采用国际化标准，易于升级换代。
🚀计算机网络 计算机网络的定义：
计算机网络主要是由一些通用的、可编程的硬件互连而成的，而这些硬件并非专门用来实现某一特定目的。这些可编程的硬件能够用来传送多种不同类型的数据，并能支持广泛和日益增长的应用。
计算机网络的功能：
①资源共享：共享网络资源是开发计算机网络的动机之一，网络资源包括 计算机硬件、软件和数据 ，通过资源共享，消除了用户使用计算机资源受地理位置的限制，也避免了资源的重复设置而造成的浪费。
硬件资源：是共享其他资源的基础，包括 处理机，内(外)存储器，输入/输出设备 等。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/aeab0943eabe09c93d56505f2345a6df/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/be9a5cef394e5797128952f2b8d77111/" rel="bookmark">
			python网站创建014：jQuery的引入、选择器和筛选器
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		1. 下载jQuery之后， 那如何使用呢？假如我想操作一个div标签， 给这个标签补充文字 &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;初识：JavaScript&lt;/title&gt; &lt;meta charset="UTF-8"&gt; &lt;/head&gt; &lt;body&gt; &lt;!--定义一个无文本的div标签--&gt; &lt;div id = "info"&gt;&lt;/div&gt; &lt;!--将jQuery引入--&gt; &lt;script src="../file/jquery-3.7.1.min.js"&gt;&lt;/script&gt; &lt;script&gt; // $("#info")：意思是找到id为“info”的标签，.text的意思是给这个标签插入文本 $("#info").text("插入的数据"); &lt;/script&gt; &lt;/body&gt; &lt;/html&gt; 效果：
2、 jQuery的选择器：使用jQuery操作标签时，首先第一部得找到要操作的标签，如何寻找自己想要的标签？ 就通过选择器来寻找 id选择器：$("#info")
&lt;body&gt; &lt;div id = "info"&gt;&lt;/div&gt; &lt;script src="../file/jquery-3.7.1.min.js"&gt;&lt;/script&gt; &lt;script&gt; $("#info").text("插入的数据"); &lt;/script&gt; &lt;/body&gt; class选择器：$(".info")
&lt;body&gt; &lt;div class="info"&gt;&lt;/div&gt; &lt;div class="info"&gt;&lt;/div&gt; &lt;script src="../file/jquery-3.7.1.min.js"&gt;&lt;/script&gt; &lt;script&gt; $(".info").text("插入的数据"); &lt;/script&gt; &lt;/body&gt; 标签选择器：$("h1")
&lt;body&gt; &lt;h1 class="info"&gt;&lt;/h1&gt; &lt;h2 class="info"&gt;&lt;/h2&gt; &lt;script src="../file/jquery-3.7.1.min.js"&gt;&lt;/script&gt; &lt;script&gt; $("h1").text("插入的数据"); &lt;/script&gt; &lt;/body&gt; 多选择器，也就是以不同条件选择多个标签：$("h1,.info2,#v1")
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/be9a5cef394e5797128952f2b8d77111/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3920f90e7bab519ab35360a686bb4540/" rel="bookmark">
			四. 基于环视Camera的BEV感知算法-BEVDepth
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录 前言0. 简述1. 算法动机&amp;开创性思路2. 主体结构3. 损失函数4. 性能对比总结下载链接参考 前言 自动驾驶之心推出的《国内首个BVE感知全栈系列学习教程》，链接。记录下个人学习笔记，仅供自己参考
本次课程我们来学习下课程第四章——基于环视Camera的BEV感知算法，一起去学习下 BEVDepth 感知算法
课程大纲可以看下面的思维导图
0. 简述 本节内容和大家一起学习一个非常好的工作叫 BEVDepth 是旷世研究院的工作
我们还是从以下四个方面展开，算法动机&amp;开创性思路、主体结构、损失函数和性能对比
1. 算法动机&amp;开创性思路 其实 BEV 感知算法我们讲了这么多，核心内容我们也强调了很多次是怎么去构建这个 BEV 空间的表征，我们怎么得到 BEV 呢，输入图像通过图像处理可以得到 BEV，输入点云通过点云处理可以得到 BEV，核心内容是我们怎么把图像特征，怎么把点云特征转换到 BEV 空间当中
那这个表征我们也讲过有很多方式，我们把它分为两类，一类是从 2D 到 3D 的方式，也有从 3D 到 2D 的方式，BEVDepth 是属于从 2D 到 3D 的方式，我们来复习一下，从 2D 到 3D 的映射离不开图像生成原理，如果我们已知相机的内参和外参矩阵且已知 2D 图像像素点 p p p，我们将 2D 点 p p p 投影到 3D 空间是什么呢，是一条射线，如果我们想要做到 2D 点 p p p 和 3D 点 P P P 唯一确定关系的话怎么做呢，需要深度值
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/3920f90e7bab519ab35360a686bb4540/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/5c834bbdc0151040e0278e885905dbcd/" rel="bookmark">
			数据库中间件介绍
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 文章目录 什么是数据库中间件？Smart-client 模式优点缺点 Proxy 模式优点缺点 单元化架构优点缺点 总结 数据库中间件是连接数据库和应用程序之间的软件层，用于简化数据库管理、提高性能和可伸缩性，同时提供额外的功能和服务。在分布式系统和大规模应用中，数据库中间件发挥着重要的作用。 什么是数据库中间件？ 数据库中间件是一种介于数据库系统和应用程序之间的软件层。它充当了一个抽象层，屏蔽了底层数据库的细节，为应用程序提供了更简化的接口。数据库中间件的主要目标是提供更高的性能、可用性、可扩展性，并简化数据库管理。
典型的数据库中间件设计方案有3种：proxy、smart-client、单元化架构
Smart-client 模式 通过独立的逻辑层建立数据分片和路由规则，实现单体数据库的初步管理，使应用能够对接多个单体数据库，实现并发、存储能力的扩展。其作为应用系统的一部分，对业务侵入比较深。这种客户端组件的典型产品是 Sharding-JDBC。
优点 实现简单。大多数据数据库厂商已经针对不同的语言提供了相应的数据库驱动driver，例如mysql针对java语言提供了mysql-connector-java驱动，针对python提供了mysql-connector-python驱动，客户端的通信协议已经在driver层面做过了。因此smart-client模式的中间件，通常只需要在此基础上进行封装即可。
天然去中心化。smart-client的方式，由于本身以sdk的方式，被应用直接引入，随着应用部署到不同的节点上，且直连数据库，中间不需要有代理层。因此除了网络资源之外，基本上不存在任何其他资源的竞争，也不需要考虑高可用的问题。只要应用的节点没有全部宕机，就可以访问数据库。
缺点 通常仅支持某一种语言。例如tddl、zebra、sharding-jdbc都是使用java语言开发，因此对于使用其他语言的用户，就无法使用这些中间件。如果其他语言要使用，那么就要开发多语言客户端。
版本升级困难。因为应用使用数据源代理就是引入一个jar包的依赖，在有多个应用都对某个版本的jar包产生依赖时，一旦这个版本有bug，所有的应用都需要升级。而数据库代理升级则相对容易，因为服务是单独部署的，只要升级这个代理服务器，所有连接到这个代理的应用自然也就相当于都升级了。
Proxy 模式 以独立中间件的方式，管理数据规则和路由规则，以独立进程存在，与业务应用层和单体数据库相隔离，减少了对应用的影响。随着代理中间件的发展，还会衍生出部分分布式事务处理能力。这种中间件的典型产品是 MyCat。
优点 多语言支持。不论你用的php、java或是其他语言，都可以支持。以mysql数据库为例，如果proxy本身实现了mysql的通信协议，那么你可以就将其看成一个mysql 服务器。mysql官方团队为不同语言提供了不同的客户端驱动，如java语言的mysql-connector-java，python语言的mysql-connector-python等等。因此不同语言的开发者都可以使用mysql官方提供的对应的驱动来与这个代理服务器建通信。
对业务开发同学透明。由于可以把proxy当成mysql服务器，理论上业务同学不需要进行太多代码改造，既可以完成接入。
缺点 实现复杂。因为proxy需要实现被代理的数据库server端的通信协议，实现难度较大。通常我们看到一些proxy模式的数据库中间件，实际上只能代理某一种数据库，如mysql。几乎没有数据库中间件，可以同时代理多种数据库(sqlserver、PostgreSQL、Oracle)。
proxy本身需要保证高可用。由于应用本来是直接访问数据库，现在改成了访问proxy，意味着proxy必须保证高可用。否则，proxy挂了，导致数据库无法正常访问，就尴尬了。
租户隔离。可能有多个应用访问proxy代理的底层数据库，必然会对proxy自身的内存、网络、cpu等产生资源竞争，proxy需要需要具备隔离的能力。
单元化架构 单元化架构是对业务应用系统的彻底重构，应用系统被拆分成若干实例，配置独立的单体数据库，让每个实例管理一定范围的数据。例如对于外卖系统，可以为每个城市搭建独立的应用实例，管理各自的数据。当出现跨城市业务时，通过迁移用户信息进行下单。
优点 灵活扩展。单元化架构通过统一的切分规则，将应用层和数据层进行立体拆分，无论是弹性扩缩容场景，还是多地多中心场景，都可以根据数据中心容量自由划分逻辑“切片”的多少。
网络耗时低，链路稳定性高。单元化架构通过“单元”，将逻辑调用和数据访问在“单元”内形成闭环，只有少数特定场景的调用会跨单元访问，这样几乎大部分的请求在地域内就可以返回，极大程度地减少了访问耗时，避免了跨异地访问链路拥堵造成的服务夯死，提高了链路稳定性。重要的是单元带来的显著的故障隔离效果，链路的可观测性方面也得到了明显改善，即从链路访问层面屏蔽了跨地域访问所带来的上述问题。
缺点 复杂的调度管理。首先需要确定一个统一的单元化规则中心，用于存储和下发单元化规则。实现方式可以是自身实现单元化规则服务，也可以借助注册配置中心，或者两者共存。单元化规则启用后很难再进行更改，所以在选择单元化切片的切分维度时需要慎重。
改造成本高。单元化需要从全局视角思考基础设施改造，建设意味着现在或未来需要买更多的机器、建更多的机房、搭更多的框架平台做支撑，以及架构升级过程中带来的各种各样的问题，这就需要更多的钱、人、时间。
风险高。单元化改造的参与者众多、落地时间周期长、业务影响面大，比如架构师需要重新做架构设计、研发人员需要针对单元化做适配开发、运维人员需要采购和部署、测试人员需要全量回归所有业务等等，其中某一环出现问题就可能造成延期或者埋下隐患。
总结 方式优点缺点Proxy 模式1.多语言支持
2.对业务开发透明1.实现复杂 2.Proxy 需要保证高可用 3.租户隔离需要考虑Smart-client 模式1.实现简单，易于使用
2.天然去中心化1.通常仅支持某一种语言
2.版本升级困难单元化1.灵活扩展
2.网络耗时低，链路稳定性高1.需要复杂的管理和调度
2.改造成本高3.风险大 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/482f8dbd19a4ee1fd7f7fefde78af7d4/" rel="bookmark">
			2023年第6届传智杯省赛第二场复赛 解题报告 | 珂学家
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言 因为OJ的承办方是牛客，除了初赛用的原题有点争议外，复赛用的是原创的新题(点赞)。
说真的，这个难度，超过我的想象，打得非常的吃力。
我其实总共打了两场初赛，一场复赛，外加VP一场复赛，没有一场是AK的，很惭愧。
第二场复赛，T3卡了下，然后T4头痛，T5没找到线索，倒是T6一眼题，最后关头磨出了T4，真的太不容易，感谢自己的坚持。
A. 思路: 模拟
标准的签到题
import java.io.BufferedInputStream; import java.util.Scanner; public class Main { public static void main(String[] args) { // 需要替换为快读 Scanner sc = new Scanner(new BufferedInputStream(System.in)); int n = sc.nextInt(), x = sc.nextInt(); int res = 0; int pre = 0; for (int i = 0; i &lt; n; i++) { int v = sc.nextInt(); if (i &gt; 0 &amp;&amp; pre &lt; x &amp;&amp; v &gt;= x) { res++; } pre = v; } System.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/482f8dbd19a4ee1fd7f7fefde78af7d4/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/354f0002633c883d6f4a588452170b22/" rel="bookmark">
			刷课必备！用Python实现网上自动做题
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		来源：blog.csdn.net/XM67_/article/details/132641455
👉 Python练手必备 👉 Python毕设实战项目 👉 Python爬虫实战必备 👉 30款Python小游戏附源码 👉 Python清理微信单向好友神器 前言 开学少不了老师会布置一些 软件上面的作业，今天教大家用python制作自动答题脚本，100%准确率哦~喜欢的同学记得关注、收藏哦~
环境使用 Python3.8
Pycharm
模块使用 import requests —&gt; 数据请求模块 pip install requests
import parsel —&gt; 数据解析模块 pip install parsel
from selenium import webdriver —&gt; 自动测试模块 pip install selenium==3.141.0
实现思路 1.打开考试网站 selenium --&gt; 浏览器驱动 --&gt; 操作浏览器 &lt;模拟人的行为做操作浏览器&gt;
2.获取答案 获取答案网站链接 获取问题以及答案内容
3.对比题目以及答案，选出正确答案 获取问题答案选项 和正确的答案进行对比 如果正确答案和选择答案一致, 那就进行点击
4.进行点击答题 最终效果 代码实现 导入模块 打开浏览器 webdriver.Chrome(‘驱动路径’) 1.驱动和代码放在一起
2.驱动文件和python安装目录放在一起
输入网址 获取问题及答案 点击判断 点击提交试卷 如果过快,可能程序还没找到元素 &lt;网页还没加载元素出来, 你就直接点了, 可能报错&gt;
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/d4d19a44839bf96f668fc8520bad0e2a/" rel="bookmark">
			制作自己的 Docker 容器
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		软件开发最大的麻烦事之一，就是环境配置。用户必须保证操作系统的设置，各种库和组件的安装，只有它们都正确，软件才能运行。docker从根本上解决问题，软件安装的时候，把原始环境一模一样地复制过来。
以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。准备工作，下载源码：git clone https://github.com/ruanyf/koa-demos.git cd koa-demos
1、编写 Dockerfile 文件
首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。
.git node_modules npm-debug.log 上面代码表示，这三个路径要排除，不要打包进入image文件。如果你没有路径要排除，这个文件可以不新建。
然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。
FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 上面代码一共五行，含义如下。
FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。
COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。
WORKDIR /app：指定接下来的工作路径为/app。
RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。
EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。
2、创建 image 文件
有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/d4d19a44839bf96f668fc8520bad0e2a/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/a2b48a0b156a1aaf561552ca3cb44293/" rel="bookmark">
			Nacos和Eureka的区别
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/19c3a10b3739fbba1d282bc58a0a47cf/" rel="bookmark">
			人工智能轨道交通行业周刊-第69期（2023.12.11-12.24）
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		本期关键词：集装箱智能管理、智慧工地、智能应急机器人、车辆构造、大模型推理
1 整理涉及公众号名单 1.1 行业类 RT轨道交通人民铁道世界轨道交通资讯网铁路信号技术交流北京铁路轨道交通网上榜铁路视点ITS World轨道交通联盟VSTR铁路与城市轨道交通RailMetro轨道世界铁路那些事铁路技术创新智慧交通RTAI智慧城轨网轨道交通智能装备NE轨道交通铁路供电上海铁道兰州铁路中国地方铁路协会铁路社评轨道部落现代轨道交通城市地铁捡瓶子的小灰灰马公子的杂货铺 1.2 人工智能类 江大白糙科技新智元AI科技评论智东西量子位我爱计算机视觉极视平台人工智能学家AI前线当交通遇上机器学习计算机视觉life新机器视觉雷锋网人工智能产业发展联盟AIIA自动驾驶之心笔记侠夕小瑶科技说水木人工智能学堂 2 数字轨道 （1）集装箱作业流程智能化控制系统设计与研究
导读：目前铁路集装箱作业管理缺少信息化管理系统的支撑，对集装箱进行计数、检查残损、指导装卸堆放、箱位管理等，都是通过工作人员现场的眼看、手抄、脑记、对讲等纯人工方式。本文设计了集装箱作业流程智能化控制系统，有利于解决目前铁路集装箱作业流程上安全卡控存在的难点和重点，充分利用技防手段，提升集装箱作业安全防护等级，提高作业效率，提升服务质量。
（2）长出“千里眼”“顺风耳”的项目获奖啦
导读：由申铁信息（上铁互联）公司自主研发的“智慧工地”升级版V2.0系统，开启了施工安全数字化保驾护航模式，确保了施工安全和施工进度，包括定位网关平台、智慧可视化大屏、视频分析等功能。
（3）铁科前沿：牵引变电所智能应急操作机器人
导读：日前，合肥供电段自主研发的牵引变电所智能应急操作机器人已在管内部分牵引所推广试运行，设计特殊结构的操作手爪，结合图像识别技术，针对不同操作目标，提出多种视觉导引智能控制策略，实现对开关、按钮、旋钮的安全可靠操作，以及对操作结果的精准确认。
3 轨道知识 （1）火车迷丨铁路接触网，如何立起来？
导读：小伙伴们坐火车时，会看见接触网悬挂在高空为列车提供动力，那么，接触网如何立起来？今天，小编就带大家一探究竟。
（2）强降雪为何会导致部分高铁限速甚至停运？
导读：连日来，北方地区持续低温降雪，京哈高铁、京广高铁、京沪高铁等部分区段限速、停运，部分列车晚点运行。强降雪为何会导致高铁限速甚至停运？还有哪些情况会使高铁降速？围绕这些问题，记者采访了有关专家。
（3）高铁车载设备主要工作模式都有哪些
导读：高速铁路动车组作为现代化交通系统的世界领先之一，操纵系统的先进性是其能够快速而安全地高速行驶的关键。与高铁司机熟悉的小伙伴一定经常听到高铁司机提到“XXX操作模式”，今天我们就来简单聊聊高铁车载设备的主要工作模式。
（5）涨知识| 普速铁路列车的车辆构造
导读：很多小伙伴想了解一下铁路车辆的车体构造知识，今天咱们就安排上，给大家简单普及一下~我国铁路车辆种类繁多，但其结构大致相似。铁路车辆由车体、车底架、走行部、车钩缓冲装置和制动装置组成。
（6）铁路五大基层系统岗位，你知道吗
导读：每次铁路局招聘都会有人问：铁路单位到底都有哪些系统？各个岗位到底是做什么的，今天咱们就来介绍一下。铁路上的五大系统，车，机，工，电，辆。也就是车务，机务，工务，电务，车辆等五大段。是铁路的最重要的五大基础。供电段、水电段等管铁路上的设备的水电之类的机构，虽然也很重要，但不属于传统五大基层系统。
4 AI产业 （1）北京大学发布LLMs（预训练+微调）数据管理全流程综述
导读：近日，来自北京大学的学者发布了LLMs训练数据管理全流程综述，分别从预训练与有监督微调两个阶段详细总结了包括数据规模、数据质量、领域组成以及数据管理系统等方面的研究。
（2）一文说尽「大模型推理」！12家高校机构联合发布150页报告，综述750篇论文
导读：最近，十二家机构联合发表了一篇论文，介绍了为推理任务设计或适用的一些开创性基础模型，并突出了在各种推理任务、方法和评估标准方面的最新进展。全面综述近750篇「基础模型推理」论文，聚焦于各种推理任务、方法论和基准测试的最新进展，详细阐述大模型在各种推理任务上的现状、技术局限性和未来可能性。
（3）【AI Agent行业深度】框架、应用方向、应用领域及相关公司一文深度梳理！
导读：随着大模型在各行各业的广泛应用，基于大模型的 agent 迎来了快速发展的阶段。那么，AI Agent 是什么？与其它人类与 AI 协同模式相比有何不同？其框架结构是怎样的？目前 AI Agent 的应用方向是什么？未来哪些领域可以应用 AI Agent？此外，又有哪些公司在该领域有所布局？ AI Agent 行业还面临哪些挑战？本篇研报将围绕以上问题展开探讨，旨在帮助读者能够了解 AI Agent 行业。
（4）大模型在IT运维领域的应用场景与实践
导读：大模型在IT运维领域的运用场景有很多，包括数字化运维助手、私有文档问答、脚本解读、数据注释、日志运维等等。本文将从大模型在日志场景的应用方向、实践路径、企业真实案例三个方面进行展开分享。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/e6da5440997e2f74b379f269d17f4194/" rel="bookmark">
			AttributeError: module ‘numpy‘ has no attribute ‘int‘.
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		解决方法 降低numpy版本 numpy == 1.22
修改源代码 参考 [1] 【已解决】AttributeError: module ‘numpy‘ has no attribute ‘int‘.
[2] AttributeError: module numpy has no attribute int .报错解决方案
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/f1369d37db1cbdfa26d28d576e31de8c/" rel="bookmark">
			oracle怎么修改连接数
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		Oracle是企业级关系型数据库管理系统，它的使用非常广泛。在Oracle中，连接数是指数据库可以同时支持的客户端连接数。当连接数过低时，可能会导致系统崩溃或出现性能问题。因此，修改Oracle连接数是很必要的。
Oracle支持两种连接方式：共享服务器和独立服务器。在共享服务器模式下，多个客户端会共享一份服务器资源，而在独立服务器模式下，每个客户端都会有自己的服务器进程。在默认的共享服务器模式下，Oracle可以同时支持的客户端连接数为150个。
如果需要增加连接数，可以按照以下步骤进行操作。
第一步：确认当前连接数
在Oracle中，可以使用如下命令来确认当前连接数：
select value from v$parameter where name='processes';
这会输出数据库当前支持的最大连接数。
第二步：确认当前连接数使用情况
可以使用如下命令来查看当前连接数的使用情况：
select count(*) from v$session;
这会输出当前的连接数。
第三步：修改连接数
要修改连接数，需要先修改数据库参数。可以使用如下命令来修改最大连接数：
alter system set processes=200 scope=spfile;
这会将最大连接数设为200，在数据库重启后生效。如果想要立即生效，可以使用以下命令：
alter system set processes=200; 这会将最大连接数设为200，但在数据库重启后会失效。
第四步：重启数据库
在修改完数据库参数后，需要重启Oracle才能使它生效。可以使用以下命令来重启Oracle：
shutdown immediate;
startup;
这会关闭并重新启动Oracle数据库。
总结
Oracle数据库连接数的大小对于系统的性能和稳定性有重要影响，需要根据具体的情况进行调整。改动最大连接数需要注意安全性和系统能承受的范围，确保系统不会出现崩溃或其他问题。
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/4489fa6ba12a3d5d52f6d3e08c24c113/" rel="bookmark">
			HALCON&amp;VS .net混合编程案例【02】：检测芯片的管脚间距
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言： 本章给出的HALCON和Visual Studio的WPF项目中联合编程的案例。
VS中WPF的编程，UI的设计非常方便，如果结合HALCON的算法，可以很快实施机器视觉相关的应用。本例的应用，实现了自动检测的一个三洋的芯片的管脚的间距。
一、项目结果展示： 步骤一：读取图片 拍摄一张芯片PCB的图：
步骤二：构建模式 对拍摄的图片，进行模式识别，这里构建了两个模式，模式1，OCR的文字识别，识别芯片上的文字。模式2，蓝色部分，实现对管脚的检测。
步骤三：检测时间匹配 对算法处理的节奏，进行处理
步骤四：管脚数量和间距检测 二、原理和设计说明： 2.1 设计说明： HALCON和 VS WPF应用结合，在Visual Studio的WPF项目中，可以通过拖动工具箱中的控件到设计视图来自动生成XAML代码。这些代码定义了用户界面的布局和控件。熟悉，XML语言的同学，应该知道，XML的标记语言，掌握了基本语法后，理解起来是很容易的。
拖动控件设计UI后，对于每个控件，你可以在其关联的code-behind文件中添加事件处理程序。就可以要编写或修改这些事件处理程序的代码，以实现你想要的功能。例如，某个按键控件的事件处理，Create_Click就是一个事件处理程序，它会在用户点击相关的按钮时被触发。
当然，为了实现具体的功能，你仍然需要编写和修改事件处理程序的代码。
2.1.1 XML的VS设计 XML显然可以作为一种方式，这里笔者给出了链接和案例参考：
微软 XML语言说明
在VS中编写XML实例程序
但是，XML的 方法不是，本例采用的语言，本例，采用AXML的方法。见下节：
2.1.2 AXML的设计 总的来说，虽然WPF的用户界面可以通过拖放控件来自动生成，但是HALCON的兼容界面设计，结合WPF似乎，采用AXML更方便。
【Franklin案】注意，这里提到的AXML和Android的AXML应该不是一个东西，别搞混了。
下面这个链接对AXML做了说明：
支付宝小程序 AXML 语法
上文，针对AXML语法大致做了如上说明：
AXML有五种语法，包括：数据绑定、条件渲染、列表渲染、模版、渲染。
具体，参考链接：
至于 Android的AXML是什么，参考如下：
安卓AXML图解
【Franklin案】所以，本项目中的AXML显然只是一句了AXML的对XML的一种裁剪的语言。
三、设计实例： 3.1 项目运行环境和配置： 本例，博主在WIN10+VS 2019上成功运行，需要如下.net的框架支持：
当然，作为HALCON混合编程，HALCONNET是必须的：
3.2 项目构建： 【Franklin案】我们大致了解一下，项目各个文件构建：
3.2.1 项目文件组成和各个文件的主要作用： Properties 文件夹：包含四个文件，用于管理应用程序资源和用户设置。
Resources.resx 和 Resources.Designer.cs：用于管理应用程序资源。这些文件包含一个名为 resourceMan 的 ResourceManager 类型的字段和一个名为 resourceCulture 的 CultureInfo 类型的字段，这些字段用于处理资源的本地化。Settings.settings 和 Settings.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/4489fa6ba12a3d5d52f6d3e08c24c113/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/6f31cfdacb6f2fc4fae5de63fad831c4/" rel="bookmark">
			Qt/C&#43;&#43;控件设计器/属性栏/组态/可导入导出/中文属性/串口网络/拖曳开发
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 一、功能特点 自动加载插件文件中的所有控件生成列表，默认自带的控件超过120个。拖曳到画布自动生成对应的控件，所见即所得。右侧中文属性栏，改变对应的属性立即应用到对应选中控件，直观简洁，非常适合小白使用。独创属性栏文字翻译映射机制，效率极高，可以非常方便拓展其他语言的属性栏。所有控件的属性自动提取并显示在右侧属性栏，包括枚举值下拉框等。支持手动选择插件文件，外部导入插件文件。可以将当前画布的所有控件配置信息导出到xml文件。可以手动选择xml文件打开控件布局，自动根据xml文件加载控件。可拉动滑动条、勾选模拟数据复选框、文本框输入，三种方式来生成数据应用所有控件。控件支持八个方位拉动调整大小，自适应任意分辨率，可键盘上下左右微调位置。左侧控件列表栏控件名称中文显示。支持将选中控件移到最前面和移到最后面显示。可以一键删除当前选中控件和清空所有控件。支持自定义属性，可以填写中文属性名称和对应的值，导出带自定义属性。打通了串口采集、网络采集、数据库采集三种方式设置数据。作为组态的雏形软件，可以自由拓展自己的功能。代码极其精简，注释非常详细，可以作为组态的雏形，自行拓展更多的功能。纯Qt编写，支持任意Qt版本、任意编译器、任意系统。 二、效果图 三、体验地址 体验地址：https://pan.baidu.com/s/1ZxG-oyUKe286LPMPxOrO2A 提取码：o05q 文件名：bin_quc.zip国内站点：https://gitee.com/feiyangqingyun国际站点：https://github.com/feiyangqingyun个人主页：https://blog.csdn.net/feiyangqingyun视频主页：https://space.bilibili.com/687803542/文章导航：https://qtchina.blog.csdn.net/article/details/125041217 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/347a1cfab1c51f0dc14dbbf4b9a92d22/" rel="bookmark">
			Element UI 框架中Loading 区域加载的使用方法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		给自己打个小广告: 有开发APP、小程序、网站、后台系统需求 或者 想学习前端的可以私信我哈！ Loading 加载用于加载数据时显示动效
Element UI中的Loading组件默认是全屏显示，大多时候出于美观考虑我们并不需要这种功能　而是让它显示在我们需要的地方，比如一个后台管理系统，我们和后台进行网络传输的时候，我们并不需要把导航栏和系统的头部覆盖住，只需要内容部分显示，这时候我们就需要对组件的参数进行设置。
Element 提供了两种调用 Loading 的方法：指令和服务。对于自定义指令v-loading，只需要绑定Boolean即可。默认状况下，Loading 遮罩会插入到绑定元素的子节点，通过添加body修饰符，可以使遮罩插入至 DOM 中的 body 上
在某页单独的地方进行设置该组件很容易　直接按照官网实例写即可
但是像之前我们要求的那样，每次和后端的交互都要显示loading框的话，我们通常是把该组件写在封装好的axios.js文件中，这时候就有一个区域显示的问题，我的做法是把系统除了顶部导航和菜单栏之外的内容部分的顶层ＤＩＶ加入一个唯一的class，然后通过对　target　参数的设置　借助　document.querySelector　方法实现区域覆盖。
get: function (url, params = {}) { let loadingInstance = Loading.service({ text: '请稍等', **target: document.querySelector('.loadingtext')** }); instance.defaults.headers.common['Authorization'] = Cookies.get('access_token'); return new Promise((resolve, reject) =&gt; { instance.get(url, { params: params }) .then( (response) =&gt; { if(response.data.code){ loadingInstance.close(); resolve(response.data); } else { loadingInstance.close(); resolve(response.data); } }) .
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/347a1cfab1c51f0dc14dbbf4b9a92d22/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/ab73416ff961de155209a0d6b8a7a2dc/" rel="bookmark">
			C# 基于MQTT创建客户端的可靠数据传输
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		C# 基于MQTT创建客户端的可靠数据传输 引言MQTT简介C# MQTT库引用代码和描述1、 代码2、 描述 引言 MQTT是tcpip的应用层协议，这里我们简单介绍一下MQTT的基本概念，并用C# 描述客户端的订阅和发布。
MQTT简介 MQTT(Message Queuing Telemetry Transport）即 消息队列遥测传输，是ISO 标准(ISO/IEC PRF 20922)下基于发布/订阅范式的消息协议。它也是工作在 TCP/IP协议族上，是为硬件性能低下的远程设备以及网络状况糟糕的情况下而设计的发布/订阅型消息协议。
MQTT协议是轻量、简单、开放和易于实现的，这些特点使它适用范围非常广泛。在很多情况下，包括受限的环境中，如：机器与机器（M2M）通信和物联网（IoT）。其在，通过卫星链路通信传感器、偶尔拨号的医疗设备、智能家居、及一些小型化设备中已广泛使用。
通过MQTT协议，目前已经扩展出了数十个MQTT服务器端程序，可以通过PHP，JAVA，Python，C，C#等系统语言来向MQTT发送相关消息。
MQTT 服务器是发布-订阅架构的转发中心，它可以非常简单地在Internet 服务器上实现。服务器分发消息，因此是推送者，客户端可以发布消息（发送方）、订阅消息（接收方）或两者兼而有之。客户端（也称为节点）是一种智能设备，如微控制器或具有 TCP/IP 堆栈和实现 MQTT 协议的软件的计算机。
QoS（Quality of Service levels）服务质量是 MQTT 的一个重要特性。当我们使用时，连接已经在一定程度上是不是面向连接的。MQTT 在这里帮助避免信息丢失及其服务质量水平。 服务质量水平包括三个等级。
AtMostOnce ——最多一次AtLeastOnce ——至少一次ExactlyOnce ——恰好一次，这个服务质量可以确保数据准确的发送到订阅端。 C# MQTT库引用 这里我使用是VS2022，在工具中的netGet包管理器中打开“管理解决方案包“，搜索MQTTnet，找到对应的包。这里注意要选择自己合适的版本！注意要选择自己合适的版本！注意要选择自己合适的版本！重要的话说3遍。我在win10环境下使用的VS2022,验证了多次才发现4.1.2.350是合适的。如下图所示。
代码和描述 1、 代码 using System; using System.Collections.Generic; using System.Threading.Tasks; using MQTTnet; using MQTTnet.Client; using MQTTnet.Protocol; using MQTTnet.Server; namespace WriteSN { internal class Mqtt { public static byte[] Mqtt_Message_Received_Str = new byte[] { }; //构造函数 public Mqtt() { //初始化全局变量 Mqtt_Message_Received_Str = new byte[] { }; } /// &lt;summary&gt; /// 发布和订阅MQTT专用主题授权获取数据 /// &lt;/summary&gt; /// &lt;param name="
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/ab73416ff961de155209a0d6b8a7a2dc/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/e2916b09f7094bc21b85551f6a767cf6/" rel="bookmark">
			【5G PHY】NR参考信号功率和小区总传输功率的计算
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		博主未授权任何人或组织机构转载博主任何原创文章，感谢各位对原创的支持！
博主链接
本人就职于国际知名终端厂商，负责modem芯片研发。
在5G早期负责终端数据业务层、核心网相关的开发工作，目前牵头6G算力网络技术标准研究。
博客内容主要围绕：
5G/6G协议讲解
算力网络讲解（云计算，边缘计算，端计算）
高级C语言讲解
Rust语言讲解
文章目录 NR参考信号功率和小区总传输功率的计算一、NR参考信号功率的计算1.1 例子15 KHz30 KHz60 KHz 二、小区总传输功率的计算2.1 例子8天线16天线64天线128天线 NR参考信号功率和小区总传输功率的计算 一、NR参考信号功率的计算 参考信号功率和小区的总发射功率可以用单通道功率计算，公式如下：
R S P o w e r = M a x T x P o w e r − 10 l o g 10 ( R B C e l l ∗ 12 ) ( d B m ) RS Power = Max Tx Power - 10log10(RBCell *12)(dBm) RSPower=MaxTxPower−10log10(RBCell∗12)(dBm)
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/e2916b09f7094bc21b85551f6a767cf6/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/81e0dbc59096be09eaf1fb5705b7b753/" rel="bookmark">
			centos安装apache2 https php
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		centos安装apache2 https+php apache2的安装包叫httpd
apche2下的配置文件都在/etc/httpd/conf。例如：httpd.conf是http的配置文件。php.conf是php的配置文件。ssl.conf是https的配置文件。
1, 安装 有时候安装anaconda的时候是顺带安装了httpd的。
yum list installed httpd # 查看是否安装 yum install httpd* -y # 一路yes安装 yum list httpd # 查看所有可安装版本 yum list updates httpd # 查看可否更新 yum update httpd* 2, 查看配置 cat /etc/httpd/conf/httpd.conf # 端口 Listen 80 # 根目录 ServerRoot "/etc/httpd" # 网页存放目录 DocumentRoot "/var/www/html" # 自己设置一个访问内容 cd /var/www/html mkdir test vim hello.html 3，启动 systemctl start httpd.service # 启动httpd systemctl status httpd.service # 查看状态 curl http://ip/test/hello.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/81e0dbc59096be09eaf1fb5705b7b753/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/c56e591077451cde1f116acb95387e2b/" rel="bookmark">
			U盘制作、安装Ubuntu系统
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		制作 ubuntu U盘启动盘 下载Ubuntu镜像 打开 Ubuntu 官网：https://ubuntu.com/download/desktop ，进入页面后，点击右边的【Download】按钮开始下载 Ubuntu 的 ISO 系统镜像文件
下载安装并配置U盘启动盘 下载 Rufuse 写盘工具，完成后打开
下载地址：http://rufus.ie/zh
插入用来做启动盘的 U 盘，如果 U 盘内有资料请注意进行备份，以免资料文件丢失，插入 U 盘后，在设备区域会显示 U 盘的容量大小。
点击【选择】找到下载的 Ubuntu 系统镜像文件后，点击【打开】
点击【开始】，写入 Ubuntu 系统镜像到 U 盘
如果出现以下提示，选择以 ISO 镜像模式写入，点击【OK】
耐心等待写入完成后，就可以拔掉 U 盘了
安装Ubuntu23.04 设置启动项
关闭你需要安装系统的主机，然后插入启动 U 盘，进行开机，当屏幕上出现 Logo，迅速按下【F7】键，进入引导启动菜单。
选择你的U盘作为启动项，回车
到这里我们就进入了安装程序，选择 Try or Install Ubuntu，回车直接安装
系统安装配置 根据自己的需求选择自己想要的语言，这里设置为中文，点击【下一步】继续安装
点击【安装Ubuntu】，点击【下一步】
键盘布局默认即可，点击【下一步】
网络链接
选择【我现在不想连接到互联网】，点击【下一步】
更新选项
可以根据自己的需求选择【正常安装】或者是【最小安装】，勾选【为图形和Wifi硬件安装第三方软件】选项，点击【下一步】
确认好分区后，点击【安装】
时区这里可以设置成【shanghai】,继续【下一步】
创建用户名，填写完成自己的信息后，点击【下一步】继续安装
主题选择，默认即可，继续【下一步】
耐心等待安装完成
安装完成后，拔掉 U 盘，点击【立即重启】就可以正常使用了
这就是安装 Ubuntu23.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/c56e591077451cde1f116acb95387e2b/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/0db20f72541ff25db60066252163aac1/" rel="bookmark">
			【LangChain学习】基于PDF文档构建问答知识库（三）实战整合 LangChain、OpenAI、FAISS等
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		接下来，我们开始在web框架上整合 LangChain、OpenAI、FAISS等。
一、PDF库 因为项目是基于PDF文档的，所以需要一些操作PDF的库，我们这边使用的是PyPDF2
from PyPDF2 import PdfReader # 获取pdf文件内容 def get_pdf_text(pdf): text = "" pdf_reader = PdfReader(pdf) for page in pdf_reader.pages: text += page.extract_text() return text 传入 pdf 文件路径，返回 pdf 文档的文本内容。
二、LangChain库 1、文本拆分器 首先我们需要将第一步拿到的本文内容拆分，我们使用的是 RecursiveCharacterTextSplitter ，默认使用 ["\n\n","\n"," "] 来分割文本。
from langchain.text_splitter import RecursiveCharacterTextSplitter # 拆分文本 def get_text_chunks(text): text_splitter = RecursiveCharacterTextSplitter( chunk_size=1000, # chunk_size=768, chunk_overlap=200, length_function=len ) chunks = text_splitter.split_text(text) return chunks 其中这里 chunk_size 参数要注意，这里是指文本块的最大尺寸，如果用chatgpt3.5会在问答的时候容易出现token长度超过4096的异常，这个后面会说如何调整，只需要换一下模型就好了。
这个参数对于向量化来说，比较重要，因为到时候喂给OpenAI去分析的时候，携带的上下文内容就会比较多，这样准确性和语义分析上也有不少的帮助。
2、向量库 项目使用 FAISS，就是将 pdf 读取到的文本向量化以后，通过 FAISS 保存到本地，后续就不需要再执行向量化，就可以读取之前的备份。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/0db20f72541ff25db60066252163aac1/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/23a8e0a9a013a610431efaea65442234/" rel="bookmark">
			openai最新探索：超级对齐是否可行？
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言 今天来介绍一篇openai最新的paper：弱到强的对齐。
openai专门成立了一个团队来做大模型的超级对齐即superhuman model，之前chatgpt取得成功依赖RLHF即依赖人类反馈，但是作者期望的superhuman model将会是一个能够处理各种复杂问题的强对齐模型，之前RLHF聚焦对齐某一方面能力比如安全，这个时候人类比较好判断case(是否安全)进而反馈，但是到superhuman model的时候，想要很好的反馈对人来说本身都是个挑战。
为此openai探索了一个方向：一个弱模型能否拿来监督生成一个更强大模型？
作者之所以探究这个方向是希望验证一个猜想：我们目标是想训练一个超人类大模型A，而现在我们所能用的监督信号是人类个体B，这是一个B监督A的学习过程也即弱监督强，那么这个是否work呢？为了验证这一点，所以作者做了一个类比来模拟验证，即用一个弱模型去监督一个强模型看看是否能监督地学出来些东西？
这就是这篇paper想要验证的理论。
《WEAK-TO-STRONG GENERALIZATION: ELICITING
STRONG CAPABILITIES WITH WEAK SUPERVISION》
论文链接：https://cdn.openai.com/papers/weak-to-strong-generalization.pdf
github: https://github.com/openai/weak-to-strong
其实仔细想想，openai目前已经走在世界最前列了，对于他们来说已经没有比自己更强的教师模型了，也就没有更强的模型可以直接拿来指导自己学习了，所以只能探索别的路（开始反过来想了，探索以弱监督强），而后来的追赶者其实还可以继续以openai为教师来蒸馏（比如蒸馏数据等等），这样也是最trick和高效的，先追上openai再说别的，正所谓openai在前摸着石头过河，其他摸着openai过河。
当然openai还可以继续秉承Scaling Law原则，继续无脑训更大的模型，效果也应该还会提高一些（无非就是再多投一些资源），但是显然这不是他们想要的，作为技术他们从理论上开始重新思考，也即训练一个superhuman model是否可行，以及路在何方？
废话不多说，我们看看openai都探索出哪些有意思的结论吧，学习一波～
温馨提示：全文较长，作者做的实验非常多，小结论也非常多，需要慢慢消化和理解作者在每节到底怎么想的以及探究出个啥。如果大家有兴趣，强烈建议结合着原paper来看，毕竟看完了后会有自己的理解和收获。
INTRODUCTION 之前使用RLHF技术的前提是人类能够很好的反馈给模型什么好的？什么是不好的？
但是我们期望的superhuman model是一个能够解决各种非常复杂的模型，对于这类问题，人类自己也不好（或者说成本很高）判断结果是否是好的，比如模型生成了一个一百万行极其复杂的代码，那人类此时就很难判断这个代码是不是好的，因为需要考虑的角度就很多比如该代码是否遵循了prompt？该代码是否安全？等等，既然人类都不好给出一个全面很好准确的反馈，那么这个使用这个监督信号就学不出啥了。
之前很多对齐技术都比较浅，作者都称之为today’s models，而作者想做的是future model (格局一下打开了，哈哈)，是真真的超级对齐，作者希望这个研究方向可以快速迭代，为此本篇paper作为第一篇来实践一下（之前的研究都是些理论研究）是否work?
首先从直觉上来想一下为啥“弱监督强”有可能会work？假设一个很强的基座模型已经能够写代码了，那么大概率它也自己知道生成的代码是否很好地遵循了用户的Prompt。因此就不需要一个很强的“老师”来指导这个强基座模型学会什么“新知识”，而只需要一个比较弱的模型来能够引导出强基座模型已经学会的知识即可，换句话说当前的强基座模型就是一个具备各种知识，但就是不会说话或者听不懂人话、不会交流的模型，弱监督模型只需要干一件事：教好他怎么组织好语言即可。
METHODOLOGY 在具体实施中，作者先训练了一个弱监督模型，此时弱监督模型的效果为weak performance，然后基于这个弱监督模型便可给其他样本打标，此时就相当于有了弱监督信号，用这个弱监督信号去指导一个强模型进行训练，得到的效果叫做weak-to-strong performance，为了对比还可以使用真实的样本（高质量）去训练强模型，此时得到的效果叫做strong ceiling performance。
进而作者定义了一个量化评估performance gap recovered (PGR)
如果很好的实现了弱到强的泛化，那么PGR=1，相反为0。
MAIN RESULTS 简单的在弱标签上微调 作者首先仅仅进行最简单的微调即什么策略不用看看效果，具体的使用传统的NLP任务、国际象棋、reward model进行测试
可以看到在传统的NLP任务中，弱到强的训练模型通常比弱模型本身泛化到更高的性能。即使是用非常弱的模型和非常强的模型（两个极端），也能恢复了超过20％的性能差距。其中PGR随着弱监督模型和强学生模型的大小增加而增加；对于最大的学生模型PGR通常高于50％。
同时在国际象棋测试中可以观察到当使用非常弱的监督模型时，PGR是为0的，只有到弱的监督模型不断增大时PGR才逐渐开始出现收益，同时另外一个反常现象就是随着学生模型的增大PGR反而开始下降。
在reward model测试中，弱到强的泛化都很差，只能恢复大概10％，即使是当弱模型和强模型之间模型大小相对较小的时候，PGR也未超过20％。
总的来说作者通过实验现象观察（强学生模型始终优于他们的弱监督模型）认为从弱到强进行泛化具有可行性，但同时作者也认为仅仅使用弱的人类级别的监督将不足以实现superhuman model；需要全新的技术来解决超级对齐。
一些增强弱到强效果的策略 上面只是简单的微调，这一节作者使用了一些策略来继续增强效果，具体的方法如下
（1）Bootstrapping
该方法的核心就是：慢慢来，既然步子太大，一下实现不了，那我们就一步步来，可以先对齐实现一个次一点的superhuman model，然后使用该模型再去对齐更强的superhuman model。具体的可以分为M1 → M2 → . . . → Mn，一步步对齐。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/23a8e0a9a013a610431efaea65442234/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/162636d35beda0f59602a857650ef266/" rel="bookmark">
			CycleGAN-两个领域非匹配图像的相互转换
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		1. CycleGAN的简介 pix2pix可以很好地处理匹配数据集图像转换，但是在很多情况下匹配数据集是没有的或者是很难收集到的，但是我们可以很容易的得到两个领域大量的非匹配数据。2017年有两篇非常相似的论文CycleGAN和DiscoGAN，提出了一种解决非匹配数据集的图像转换方案。而且CycleGAN在转换的过程中，只是将A领域图像的某些特性转换成B领域的一些特性，图像的其余大部分内容都没有改变。CycleGAN 能实现两个相近数据集之间的转换。
2. CycleGAN的网络结构 CycleGAN网络结构的拆分
该结构中，生成器相当于一个自编码网络，前半部分进行编码，后半部分进行解码，而且生成器G和生成器F的结构完全相同，其中生成器G负责实现由X到Y的转换，生成器F负责实现由Y到X的转换，它们的输入、输出的大小均为（batch_size, n_channel, cols, rows），判别器的输入为（batch_size, n_channel, cols, rows）, 判别器的输出为（batch_size, 1, s1, s2）。
3. CycleGAN的损失函数 （1）对抗损失
对抗损失的作用是，使生成的目标领域的图像和目标领域的真实图像尽可能地接近。
（2）循环损失
循环损失的作用是，使生成的图像尽可能多的保留原始图像的内容。
在网络训练的过程中是将G和F联合起来一起训练的，Dx和Dy是单独进行训练的。
G-F联合网络的损失函数为：
fake_B = G_AB(real_A)
loss_GAN_AB = torch.nn.MSELoss(D_B(fake_B), valid)
fake_A = G_BA(real_B)
loss_GAN_BA = torch.nn.MSELoss(D_A(fake_A), valid)
loss_G_GAN = (loss_GAN_AB + loss_GAN_BA) / 2 # 生成器的对抗损失
recov_A = G_BA(fake_B)
loss_cycle_A = torch.nn.L1Loss(recov_A, real_A)
recov_cycle_B = G_AB(fake_A)
loss_cycle_B = torch.nn.L1Loss(recov_B, real_B)
loss_cycle = (loss_cycle_A + loss_cycle_B) / 2 # 生成器的循环损失
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/162636d35beda0f59602a857650ef266/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/820475234838e565a5a2af54c934d497/" rel="bookmark">
			Spring security之授权
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		前言 本篇为大家带来Spring security的授权，首先要理解一些概念，有关于：权限、角色、安全上下文、访问控制表达式、方法级安全性、访问决策管理器
一.授权的基本介绍 Spring Security 中的授权分为两种类型：
基于角色的授权：以用户所属角色为基础进行授权，如管理员、普通用户等，通过为用户分配角色来控制其对资源的访问权限。
基于资源的授权：以资源为基础进行授权，如 URL、方法等，通过定义资源所需的权限，来控制对该资源的访问权限。
Spring Security 提供了多种实现授权的机制，最常用的是使用基于注解的方式，建立起访问资源和权限之间的映射关系。
其中最常用的两个注解是 @Secured 和 @PreAuthorize。@Secured 注解是更早的注解，基于角色的授权比较适用，@PreAuthorize 基于 SpEL 表达式的方式，可灵活定义所需的权限，通常用于基于资源的授权。
二.修改User配置角色和权限 方法一. 使用SQL语句的方式查询该角色的权限，并且可以对它进行修改
根据用户id查询出对应的角色信息
SELECT * FROM sys_user a, sys_user_role b, sys_role_module c, sys_module d WHERE a.id = b.user_id and b.role_id=c.role_id and c.module_id = d.id and a.id=#{id} 根据用户ID查询出角色对应的权限信息
select m.url from sys_user u,sys_user_role ur,sys_role r,sys_role_module rm,sys_module m where u.id=ur.userid and ur.roleid=r.roleid and r.roleid=rm.roleid and rm.moduleid=m.id and u.id=#{userid} and url is not null 但是并不推荐使用这种方法，当我们在实际开发中，要考虑到不同的数据表可能来自不同的库中，使用SQL查询时就会出现链表查询不同库的表的情况，所以，更多的时候我们会使用Java利用不同的操作对表进行依次查询作为条件最终得到结果
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/820475234838e565a5a2af54c934d497/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/5cab712f60e3c8da485dd59a07715a61/" rel="bookmark">
			Neo4j突然运行不了，log文件显示“Neo4j Server shutdown initiated by request,Stopping...,Stopped.”解决方案
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		用了很久的neo4j，突然运行不了
cat一下文件/var/log/neo4j/neo4j.log
报错信息显示：
2023-12-21 15:01:56.353+0000 INFO Neo4j Server shutdown initiated by request 2023-12-21 15:01:56.355+0000 INFO Stopping... 2023-12-21 15:02:01.410+0000 INFO Stopped. 在网上找了很多的解决方案都没有解决
但是最后还是解决了，下面分享一下解决方案。
进入文件目录/var/lib/neo4j/data/databases删除这个文件目录下的文件store_lock，必要时需要管理员权限来删除再去neo4j start问题解决！ 干净利索！！！
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/42baa9c45c86b2e311a8666280f21031/" rel="bookmark">
			利用快手的用户数据和精准营销提升电商平台用户转化率和销售额
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 一、快手用户数据的价值
快手作为国内领先的短视频平台，拥有庞大的用户群体和丰富的用户行为数据。这些数据包括用户的观看习惯、互动行为、兴趣偏好等，对于电商平台来说具有极高的商业价值。通过分析这些数据，电商平台可以深入了解用户需求，精准定位目标用户群体，为个性化推荐和精准营销提供有力支持。
快手用户数据获取示例代码（Python）：
import requests import json # 定义快手API的URL url = "https://api.kuaishou.com/user/data" # 定义请求参数 params = { "access_token": "YOUR_ACCESS_TOKEN", # 替换为你的访问令牌 "uid": "USER_ID", # 替换为用户ID "count": 1000 # 获取的用户数据数量 } # 发送GET请求获取用户数据 response = requests.get(url, params=params) data = response.json() # 将响应内容解析为JSON格式 # 处理获取到的用户数据（根据实际需求进行操作） 这段代码使用Python的requests库向快手API发送GET请求，获取指定用户的用户数据。你需要将YOUR_ACCESS_TOKEN替换为你的访问令牌，将USER_ID替换为用户ID，并根据实际需求处理获取到的用户数据。
二、精准营销策略的应用
个性化推荐：基于快手用户数据，电商平台可以构建个性化推荐系统，根据用户的兴趣和需求为其推荐相关商品。这种个性化推荐方式可以提高用户的购买意愿，从而提高转化率。定向广告投放：通过分析用户数据，电商平台可以精准定位目标用户群体，进行定向广告投放。这种精准的广告投放可以提高广告效果，降低营销成本，从而提高销售额。动态定价策略：根据市场需求和用户行为数据，电商平台可以制定动态定价策略。在需求旺盛时适当提高价格，在需求低迷时推出促销活动，从而最大化销售额。用户细分与定制服务：根据用户数据将用户划分为不同的细分群体，为不同群体提供定制化的服务和营销策略。这样可以提高用户满意度，增强用户忠诚度，从而提高转化率和销售额。 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/a5127f3ff889a50eebad55673d354eea/" rel="bookmark">
			java自定义注解实现数据库字段判重
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		本文使用mybatisplus版本：3.5.3.1
参考了两篇文章：
https://www.jianshu.com/p/6b6454073c89
https://www.cnblogs.com/xiaokangk/p/14208090.html
自己再实现的原因，mybatisplus版本升级了，包名也对应变化了。
增强实现的点：
1.增加子注解，实现多条件每个条件单独判充重
2.对于没有TableField的字段，用驼峰转下划线的字段
一、代码实现如下 1.注解定义 基本注解定义
package vip.xiaonuo.common.validator; import javax.validation.Constraint; import javax.validation.Payload; import java.lang.annotation.*; /** * &lt;p&gt; 自定义字段对应数据库内容重复校验 注解 &lt;/p&gt; * * @author dq * @description : * @author : zhengqing * @date : 2019/9/10 9:32 */ // 元注解: 给其他普通的标签进行解释说明 【@Retention、@Documented、@Target、@Inherited、@Repeatable】 @Documented /** * 指明生命周期: * RetentionPolicy.RUNTIME 注解可以保留到程序运行的时候，它会被加载进入到 JVM 中，所以在程序运行时可以获取到它们。 */ @Retention(RetentionPolicy.RUNTIME) /** * 指定注解运用的地方: * ElementType.TYPE 可以给一个类型进行注解，比如类、接口、枚举 */ @Target({ElementType.TYPE}) @Constraint(validatedBy = FieldRepeatValidatorClass.class) public @interface FieldRepeatValidator { /** * 需要校验的字段 * @return */ String[] fields() default {}; /** * 排序 * @return */ int order() default 0; /** * 默认错误提示信息 * @return */ String message() default "
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/a5127f3ff889a50eebad55673d354eea/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/0e007c1d0100c2f61831859cddbb4080/" rel="bookmark">
			浅谈Linux的OOM Killer机制
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录 1. OOM Killer简介2. /proc目录3. oom_score、oom_score_adj、oom_adj4. 查看Linux系统的内存和磁盘占用情况4.1 查看内存4.2 查看磁盘 Ref 1. OOM Killer简介 Linux中的OOM Killer（Out of Memory Killer）是内核的一个机制，当系统检测到内存不足以满足当前需要时，它会自动终止一些进程以释放内存，保护系统免于崩溃。通常，OOM Killer自动运行，无需手动干预，但了解和调整其行为可以帮助你更好地管理系统资源。
当系统内存非常紧张时，OOM Killer将被触发。它会根据一系列标准给每个进程评分（oom_score），基于其内存使用、运行时间、用户权限等。通常情况下，分数最高的进程将被选择终止。
2. /proc目录 Linux的 /proc 目录是一个虚拟文件系统，它不占用硬盘空间，而是直接存在于内存中。这个目录包含了系统运行时的信息，主要用于提供内核、进程、硬件状态等系统信息。
对于系统上的每一个正在活跃的进程，/proc 都有一个以进程ID命名的目录，即 /proc/[pid]，在这个目录里，有关于该进程的详细信息，例如：
/proc/[pid]/cmdline：进程启动命令/proc/[pid]/environ：进程的环境变量/proc/[pid]/status：进程的状态信息/proc/[pid]/oom_score：进程的OOM评分/proc/[pid]/oom_score_adj：调整OOM评分的值 3. oom_score、oom_score_adj、oom_adj oom_score 文件存储一个值，表示系统当前分配给该进程的OOM得分。这个得分是由内核根据进程的内存使用量、运行时间、以及 oom_adj 或 oom_score_adj 的设置计算出来的（消耗内存越多分越高，存活时间越长分越低）。得分越高，表示进程越有可能在内存不足时被杀死。注意，这个文件是只读的，用户或管理员不能直接修改这个得分，它是系统根据当前情况动态计算的。
oom_score_adj 文件存储一个值，范围从 -1000 到 +1000。-1000 表示进程永远不会被OOM Killer杀死，+1000 表示进程将是首先被杀死的候选。这允许管理员更精确地控制哪些进程在内存紧张时应该被保留，哪些可以被杀掉。
oom_adj 的作用和 oom_score_adj 一样，只不过它的存在是为了向后兼容性。该文件存储一个值，范围从 -17 到 +15。-17 表示进程永远不会被OOM Killer杀死，+15 表示进程将是首先被杀死的候选。
为了防止某个进程被OOM Killer杀死，我们可以在root身份下执行如下命令：
echo -1000 &gt; /proc/[pid]/oom_score_adj 或者：
echo -17 &gt; /proc/[pid]/oom_adj 注意，修改 oom_adj 时，系统会自动转换 oom_adj 的值到对应的 oom_score_adj 值。oom_adj 范围从 -17 到 +15，这个范围会映射到 oom_score_adj 的 -1000 到 +1000。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/0e007c1d0100c2f61831859cddbb4080/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/0a46adfe3255c426893acd1f1a9762a4/" rel="bookmark">
			DermoSegDiff: A Boundary-aware Segmentation Diffusion Model for Skin Lesion Delineation
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		DermoSegDiff:用于皮肤病变描绘的边界感知分割扩散模型
摘要：皮肤病变分割对皮肤病的早期发现和准确诊断起着至关重要的作用。消噪扩散概率模型(ddpm)最近因其出色的图像生成能力而受到关注。在这些进展的基础上，我们提出了DermoSegDiff，这是一个在学习过程中包含边界信息的皮肤病变分割的新框架。我们的方法引入了一种新的损失函数，在训练过程中对边界进行优先排序，逐渐降低其他区域的重要性。我们还介绍了一种新的基于u - net的去噪网络，该网络可以熟练地将网络内的噪声和语义信息集成在一起。在多个皮肤分割数据集上的实验结果表明，DermoSegDiff优于现有的基于CNN、transformer和diffusion的方法，显示了其在各种场景下的有效性和泛化性。该实现可以在GitHub上公开访问。
1 介绍
在医学图像分析中，皮肤病变分割的目的是从皮肤图像中识别皮肤异常或病变。皮肤科医生传统上依靠视觉检查和手工描绘来诊断皮肤病变，包括黑色素瘤、基底细胞癌、鳞状细胞癌和其他良性或恶性肿瘤。然而，准确和快速地分割这些病变在早期发现、治疗计划和疾病进展监测中起着至关重要的作用。近年来，自动医学图像分割方法因其具有提高诊断结果准确性和可靠性的潜力而受到广泛关注。这些模式的成功医学图像分割任务可归因于深度学习技术的进步，包括卷积神经网络(cnn)[2,23,13]、隐式神经表征[21]和视觉变压器[29,4]。
最近，去噪扩散概率模型(Denoising Diffusion probistic Models, ddpm)[11]因其在图像生成领域的卓越表现而引起了人们的极大兴趣。这种新发现的认识导致了对ddpm的兴趣和探索激增，其产生高质量和多样化样品的卓越能力推动了ddpm的发展。在此基础上，研究人员成功地提出了新的医学图像分割方法，利用扩散模型来解决这一具有挑战性的任务[14]。EnsDiff[30]利用地面真值分割作为训练数据，输入图像作为先验，生成分割分布，从而创建不确定性图和隐式分割集合。Kim等人[16]提出了一种新的自监督血管分割框架。MedSegDiff[31]引入了基于dpm的医学图像分割，使用动态条件编码和FF-Parser来减轻高频噪声影响。MedSegDiff-V2[32]使用条件U-Net对其进行了改进，以改善噪声-语义特征的交互。
事实证明，边界信息在皮肤图像分割中至关重要，特别是在准确定位和区分皮肤病变与周围健康组织时[19,29,15]。边界信息提供了皮肤内不同区域之间的空间关系，与其他区域相比具有更大的意义。通过在训练阶段强调这些区域，我们可以通过鼓励模型专注于强化边界区域而减少其他区域的影响来获得更准确的结果。然而，大多数基于扩散的分割方法忽略了这一重要性，并对所有区域指定同等重要性。另一个关键的考虑因素是去噪架构的选择，这直接影响模型学习复杂数据关系的能力。大多数方法都遵循基线方法[11,22]，忽略了在网络中更有效地结合语义和噪声交互的事实。
为了解决这些缺点，我们提出了一个新颖而直接的框架，称为DermoSegDiff。我们的方法通过考虑训练过程中边界信息的重要性并提出一种新的去噪网络来解决上述问题，该网络有助于更有效地理解噪声和语义信息之间的关系。具体来说，我们提出了一种新的损失函数来优先考虑分割中的区分边界。通过将动态参数纳入损失函数，我们增加了对边界区域的重视，同时随着我们远离边界而逐渐减少其他区域的重要性。此外，我们提出了一种新的基于u - net的去噪网络结构，通过结合精心设计的双路径编码器，增强了整个去噪过程中的制导集成。该编码器有效地结合了噪声和语义信息，提取了互补特征和判别特征。我们的模型还有一个独特的瓶颈，即线性注意[26]和原始自我注意[10]并行。最后，解码器接收合并后的输出从编码器传输的两个输出，并利用该信息来估计噪声的量。在ISIC 2018[9]、PH2[20]和HAM10000[27]皮肤分割数据集上，我们的实验结果表明，与CNN、变压器和基于扩散的最先进(SOTA)方法相比，我们提出的方法具有优越性，展示了我们的方法在各种场景下的有效性和泛化性。我们通过引入一种新的损失函数来强调在皮肤损伤分割中纳入边界信息的重要性，该损失函数鼓励模型优先考虑边界区域。我们提出了一种新的去噪网络，显著提高了降噪效果，增强了语义交互，在不同皮肤损伤数据集上，与基线模型相比，收敛速度更快。我们的方法超越了最先进的方法，包括cnn、变形金刚和基于扩散的技术，跨越了四个不同的皮肤分割数据集。
2 方法
图1概述了我们的基线DDPM模型，并展示了我们提出的用于皮肤病变分割的DermoSegDiff框架。传统的基于扩散的医学图像分割方法侧重于去噪输入图像的噪声分割掩模，我们提出在学习过程中加入边界信息可以显著提高性能。通过利用边缘信息来区分重叠的物体，我们的目标是解决模糊边界在困难情况下以及病灶和背景颜色相似的情况下所带来的挑战。我们首先介绍我们的基线方法。随后，我们深入研究了包含边界信息如何增强皮肤病变分割，并提出了一种将这些信息纳入学习过程的新方法。最后，我们介绍了我们的网络结构，通过去噪过程更有效地集成制导。
图1:(a)说明了基线的架构，(b)展示了我们提出的DermoSegDiff框架。
2.1 基线
本文采用的核心架构是基于ddpm的[11,30](见图1a)。扩散模型主要利用T时间步来学习训练数据的底层分布，表示为q(x0)，通过对马尔可夫过程进行变分推理。该框架由两个过程组成:正向和反向。在正演过程中，模型从地面真值分割掩模(x0∈RH×W ×1)开始，逐级加入高斯噪声，逐渐转化为噪声掩模:
其中β1，…， βt−1，βt表示跨扩散步骤的方差表。
然后，我们可以简单地对基于地面真值分割的噪声掩模的任意一步进行采样，如下所示:
其中αt:= 1−βt，¯αt:= Qt j=1 αj和λ ~ N (0, I)。在相反的过程中，目标是在给定输入图像作为指导(g∈RH×W ×3)的情况下，通过利用神经网络来学习底层过程，重建在扩散过程中受到扰动的掩模的原始结构。为了实现这一点，我们将xt和g连接起来，并将连接的输出表示为It:= xt∥g，其中It∈RH×W x(3+1)。因此，将反向过程定义为
其中Ho等人[11]得出结论，我们可以训练一个模型来预测添加的噪声ϵθ，而不是直接使用神经网络预测µθ，从而得到一个简化的目标:Lb =∥λ−ϵθ (It, t)∥2。
2.2 边界感知重要性
虽然扩散模型在医学图像分割中显示出有希望的结果，但在训练过程中，我们如何平等地对待分割掩模的所有像素存在明显的限制。这种方法可能导致饱和的结果，破坏模型的性能。在像皮肤病变分割这样的分割任务中，边界区域的重要性明显高于其他区域。这是因为边界描绘了物体的边缘和轮廓，提供了有助于区分这两类物体的关键空间信息。为了解决这个问题，我们提出了DermoSegDiff，它有效地将边界信息合并到学习过程中，并鼓励模型优先捕获和保留边界细节，从而导致比基线方法更快的收敛速度。我们的方法遵循一个简单而高效的策略控制学习去噪过程。它侧重于强化边界的重要性，同时随着我们利用新的损失函数远离边界区域而逐渐减少这种强调。如图1所示，我们的前向过程与基线保持一致，两个去噪网络都产生输出ϵθ。然而，在计算损失函数时，两者之间的分歧变得明显。我们定义损失函数如下:
其中WΘ∈RH×W ×1是一个动态参数，旨在增加边界区域噪声预测的权重，同时随着我们远离边界而降低其权重(见图5)。WΘ是通过计算距离图和随后计算边界注意力两步过程得到的。此外，WΘ是动态参数化的，这取决于计算距离图的时间点(t)。这意味着它作为一个变量，根据每个图像在时间步长t的特定特征进行动态调整。
我们的距离图函数通过将地面真值分割掩码作为输入来操作。最初，它通过为边界像素赋值1来标识它们，同时将所有其他像素设置为零。为了增强所得到的距离图的分辨率，我们从左右两侧水平地扩展边界点(例如，对于256 × 256的图像，每行将有7个边界像素)。为了获得距离图，我们采用距离变换函数[17]，这是一种常用的二值图像处理技术。该函数计算图像中每个非零(前景)像素与最近的零(背景)像素之间的欧几里得距离。结果是一个灰度级图像，其中前景区域内的点的强度被修改为表示从每个单独的点到最近边界的距离。为了标准化距离图的强度水平并提高其作为动态加权矩阵WΘ的适用性，我们采用图像处理中的伽马校正技术来计算边界注意力。通过调整伽马值，我们可以控制距离图的整体强度，从而获得更平滑的表示，从而增强其在损失函数中的有效性。
2.3 网络结构
编码器：
我们提出的去噪网络的整体架构如图2所示。我们提出了一种对U-Net网络架构的改进，用于预测噪声分割掩码xenci−1中添加的噪声ϵθ，由引导图像gi−1和时间嵌入t引导，其中i指第i个编码器。
编码器由一系列堆叠的编码器模块(EM)组成，随后在编码器的输出处进行卷积层以实现4 × 4张量。我们的方法不是简单地将xenci−1和gi−1连接并输入到网络中[30]，而是通过在每个编码器模块(EM)中采用双路径特征提取策略来增强条件反射过程。
图2:所提出的去噪网络架构概述。符号L-Att、RB、EM、DM、LS-Att、S-Att分别对应线性注意、ResNet块、编码器模块、解码器模块、线性自注意和自注意模块。
重点研究了噪声分割掩模与制导图像之间的相互影响。每条路径包括两个ResNet块(RB)，然后是一个线性注意(L-Att)[26]，这是计算效率高，并产生非冗余的特征表示。为了吸收时间信息，在每个RB中引入了时间嵌入。时间嵌入是通过将t传递给正弦位置嵌入，然后是一个线性层，一个GeLU激活函数和另一个线性层来获得的。我们使用两个时间嵌入，一个用于gi−1 (tg)，另一个用于xenci−1 (tx)，以捕获特定于每个输入的时间方面。此外，我们利用RBx1捕获的知识，将其与引导分支进行转移和连接，从而得到hi。通过合并两条路径，我们捕获了提供数据综合视图的特定表示。左侧路径提取噪声相关特征，右侧路径提取语义信息。这种组合使模型能够结合互补和判别特征。在应用rbg2之后，我们引入了一种反馈机制，该机制采用rbg2输出的卷积并连接到RBx2输入。这种反馈允许结果特征(包含有关制导和噪声的总体信息)与噪声路径共享。通过这样做并将特征映射相乘，我们强调重要的特征，同时减弱不太重要的特征。这种乘法运算作为一种注意机制，其中共享的特征引导噪声路径集中在相关和信息区域。在对左路径进行线性关注之后和对右路径进行线性关注之前，我们提供了这两条路径的另一个特征连接，称为bi。在每个EM块的末尾，我们获得四个输出:hi和bi，用于从编码器到解码器的跳过连接，得到的丰富的xenci和gi被馈送到下一个EM块中继续特征提取过程。
瓶颈:接下来，我们连接最后一个EM块的输出，xencL和gL，并通过瓶颈模块(BM)将它们与时间嵌入tx一起传递，瓶颈模块(BM)包含一个ResNet块，一个线性自关注(LS-Att)和另一个ResNet块。LS-Att是一种双注意模块，它结合了空间关系的原始自注意(S-Att)和并行捕获语义上下文的L-Att，增强了整体特征表征。然后将BM的输出送入解码器。
解码器:解码器由堆叠的解码器模块(DM)组成，后面跟着一个输出ϵθ的卷积块。堆叠dm的数量与编码器中em的数量相同。与EM模块是双路模块不同，DM模块是单路模块。它包括两个连续的RB模块和一个L-Att模块。将来自编码器的bi和hi分别与应用RBd1前后的特征图进行连接。通过结合这些特征，解码器可以从编码器获得精确的信息，从而帮助更好地估计前向过程中添加的噪声量，并在学习过程中恢复丢失的信息。此外，为了在解码过程中保持噪声的影响，我们实现了从x到解码器的最后一层的额外跳过连接。这涉及到将DM1的结果特征映射与x连接起来，并将它们一起通过最后一个卷积块来输出估计的噪声ϵθ。
3 结果
所提出的方法已使用PyTorch库(版本1.14.0)实现，并已在单个NVIDIA A100图形处理单元(80 GB VRAM)上进行了培训。训练过程采用32个批大小，并使用Adam优化器，基本学习率为0.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/0a46adfe3255c426893acd1f1a9762a4/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/bdf786adc2534856557304c0c6647e78/" rel="bookmark">
			ubuntu22.04下rv1109 rootfs编译问题处理
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		原文地址::ubuntu22.04下rv1109 rootfs编译问题处理-CSDN博客
相关文章
1、Ubuntu22 tina-linux 编译报错记录----Ubuntu22 tina-linux 编译报错记录_sigstksz-CSDN博客
2、firefly AIO-RK3399J Linux SDK编译报错解决----firefly AIO-RK3399J Linux SDK编译报错解决_host-libglib2 2.62.4-CSDN博客
3、rk3399 buildroot ubuntu20版本编译遇到问题----rk3399 buildroot ubuntu20版本编译遇到问题
ubuntu22.04下rv1109 rootfs编译问题处理
buildroot编译出错记录
问题一：c-stack.c的SIGSTKSZ错误
解决办法
问题二：libfakeroot.c的_STAT_VER报错
解决办法
问题三：fwriter_buffer重复定义
解决办法
问题四： qfloat16.h报错
解决办法
问题五： makedevs无法创建设备节点
解决办法
注意事项
buildroot编译出错记录
出于对Ubuntu新版本系统的体验，将系统更新到了ubuntu22.04了。然后在编译rv1109 sdk时出现了一些异常的错误。但是已经不回去了，只能硬着头皮一路走下去了。并将错误记录以下，以便下次有类似错误，做个参考。
问题一：c-stack.c的SIGSTKSZ错误
buildroot 报错：c-stack.c:55:26:error:missing binary operator before token “(“55
解决办法
在buildroot目录中找到c-stack.c文件,并更改c-stack.c文件中，SIGSTKSZ的宏定义。
find -name c-stack.c
gedit c-stack.c
将以下内容：
#ifndef SIGSTKSZ
# define SIGSTKSZ 16384
#elif HAVE_LIBSIGSEGV &amp;&amp; SIGSTKSZ &lt; 16384
/* libsigsegv 2.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/bdf786adc2534856557304c0c6647e78/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/11ec6263c703ce940dd4e1f95b7858a2/" rel="bookmark">
			玩转大数据22：常见的关联规则挖掘算法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		引言 关联规则挖掘是数据挖掘中的一种重要技术，主要用于发现数据集中项之间的有趣关系。关联规则挖掘在许多领域都有广泛的应用，如市场篮子分析、推荐系统等。常见的关联规则挖掘算法包括Apriori算法和FP-Growth算法。
一、Apriori算法 关联规则挖掘是数据挖掘领域中一个重要的研究方向，主要用于发现数据集中项之间的有趣关系。其中，Apriori算法是关联规则挖掘的经典算法之一，它通过寻找频繁项集来生成关联规则。
1.1 Apriori算法原理 Apriori算法的基本思想是利用已知的频繁项集来生成新的候选频繁项集，并通过扫描数据库来验证候选频繁项集的频繁性。算法采用了一种逐层搜索的迭代方法，通过减少搜索空间来提高效率。具体步骤如下：
扫描数据库，统计每个项集的支持度，找出频繁1项集。利用频繁k-1项集生成候选k项集。扫描数据库，统计候选k项集的支持度，找出频繁k项集。重复上述步骤直到无法生成新的频繁项集为止。根据频繁项集生成关联规则，并计算规则的支持度和置信度等指标。 1.2 Apriori算法实现过程 下面是Apriori算法的实现过程：
初始化：设置最小支持度阈值min_support和最大频繁项集长度max_length。扫描数据库，统计每个项集的支持度，找出频繁1项集L1。k=2，初始化候选k项集Ck为空集。对于每个频繁(k-1)项集li∈Lk-1，生成其非空子集组成的候选k项集Ci。扫描数据库，统计候选k项集的支持度，将支持度大于等于min_support的候选k项集加入到Ck中。如果Ck为空，则结束；否则，对于每个频繁(k-1)项集li∈Lk-1，生成其非空子集组成的候选(k+1)项集Ci+1。k=k+1，回到第4步。根据频繁项集生成关联规则，并计算规则的支持度和置信度等指标。输出具有较高支持度和置信度的关联规则。 1.3 代码示例 下面是一个基于Python的Apriori算法示例代码：
import pandas as pd from mlxtend.frequent_patterns import apriori, association_rules from mlxtend.frequent_patterns import transactions as transactions_utils from mlxtend.frequent_patterns import Itemset, Rule import numpy as np import random # 生成模拟数据集 data = [['牛奶', '面包', '黄油'], ['牛奶', '面包', '鸡蛋'], ['牛奶', '黄油', '鸡蛋'], ['面包', '黄油', '鸡蛋'], ['牛奶', '面包', '黄油', '鸡蛋'], ['牛奶', '面包', '黄油'], ['面包', '黄油', '鸡蛋']] dataset = transactions_utils.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/11ec6263c703ce940dd4e1f95b7858a2/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/01ba66ca1824886472b1bd87c13a2315/" rel="bookmark">
			洛谷 NOIP2016 普及组 回文日期 &#43; 洛谷 NOIP2017 图书管理员
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		回文日期这题目本来是不难想思路的。。。。。。
然而我第一次做的时候改了蛮久才把代码完全改对，主要感觉还是不够细心，敲的时候也没注意见检查一些小错误，那么接下来不说废话，请看题干：
接下来请看输入输出的样例以及数据范围：
我提供两个方法去做这个题，第一个思路是：
首先我们分析容易看出输入的日期其实当作两个八位数处理即可，然后直接循环，从起始日期到截止日期，如果是回文日期，直接ans++即可，只是我们需要思考如何来让日期进行正确的进位，所以这时候我考虑使用函数来达到目的的功能，接下来请看代码：
#include&lt;bits/stdc++.h&gt; using namespace std; int d1,d2,ans; int getday(int y,int m){ //y年m月有多少天 if(m==1 || m==3 || m==5 || m==7 || m==8 || m==10 || m==12) return 31; if(m==4 || m==6 || m==9 || m==11) return 30; //判断闰年 if(( !(y%4) &amp;&amp; y%100) || !(y%400)) return 29; else return 28; } int nextday(int x){ //x的下一天 表示为八位整数 int y=x/10000; int m=x/100%100; int d=x%100; if(d != getday(y,m)) ++d; else if(m!
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/01ba66ca1824886472b1bd87c13a2315/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/337528287a4b62cdbd73fc69bb262389/" rel="bookmark">
			C# 委托和事件委托
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		C# 委托和事件委托 目录 C# 委托和事件委托什么是委托？1、概念2、代码描述委托 什么是事件委托？1、概念2、代码描述事件委托 利用事件委托在不同窗体传参1、建窗体2、主窗体代码：3、子窗体代码： 什么是委托？ 1、概念 委托（Delegate）类似于 C 或 C++ 中函数的指针。是存有对某个方法的引用的一种引用类型变量。引用委托可在运行时被改变，特别是用于实现事件和回调方法。其来自于System.Delegate 类。
通俗的讲，委托就是让别人来做，当特别是你需要做一个不确定什么时间来操作的时候就特别有用。比如说 ，小孩不确定的肚子饿这件事情，作为父母非常负责的家长并不需要总是来询问他的小孩是否肚子饿了，只要告诉（委托）其小孩在自己肚子饿的时候表达（发出）肚子饿，来提示家长（触发请求）即可。这样就不要家长（主线程）来实时询问（查询）。大大减小了父母工作负担。
委托常用的函数方法：
public object Invoke(Delegate method);
public object Invoke(Delegate method, params object[] args);
2、代码描述委托 public delegate void weituoFunction(string data, bool Cs); //定义委托 weituoFunction _weituoFunction;//实例化委托 //WinForm加载 private void Form_Load(object sender, EventArgs e) { //委托添加对应实现的方法 _weituoFunction= new weituoFunction(RichTextboxAddDsiplay); } //定义的事件入口 private void OnPowerChange(object sender, EventArgs e) { hungryShow("Iam hungry!",true); } //委托实现的方法操作 private void RichTextboxAddDsiplay（string data, bool Cs） { if （Cs） this.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/337528287a4b62cdbd73fc69bb262389/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/fd82f5b908772b2ac09f64c3a1a31d94/" rel="bookmark">
			一个简单的获取显示器长宽和显示器分辨的代码
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		最近在做大屏显示，在现显示的时候有些显示器是不规则的，投到大屏上显示效果不好，可以直接获取显示器的分辨率，本地调整好，再直接部署。
&lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;title&gt;获取显示器的分辨率&lt;/title&gt; &lt;script&gt; window.onload = function() { var pixelRatio = window.devicePixelRatio; var screenWidth = window.screen.width * pixelRatio; var screenHeight = window.screen.height * pixelRatio; var resolutionInfo = "水平分辨率: " + screenWidth + "px, 垂直分辨率: " + screenHeight + "px"; document.getElementById("resolutionInfo").innerText = resolutionInfo; var screenWidth2 = window.screen.width; var screenHeight2 = window.screen.height; var displayInfo = "显示器宽度: " + screenWidth2 + "px, 显示器高度: "
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/fd82f5b908772b2ac09f64c3a1a31d94/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/1922c1c25b3bc0b861ee6a835df77cb0/" rel="bookmark">
			Kafka中的max-poll-records和listener.concurrency配置
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		1、max-poll-records是什么 max-poll-records是Kafka consumer的一个配置参数，表示consumer一次从Kafka broker中拉取的最大消息数目，默认值为500条。在Kafka中，一个消费者组可以有多个consumer实例，每个consumer实例负责消费一个或多个partition的消息，每个consumer实例一次从broker中可以拉取一个或多个消息。
max-poll-records参数的作用就是控制每次拉取消息的最大数目，以实现消费弱化和控制内存资源的需求。
2、max-poll-records解决的问题 避免一次性加载大量数据：
一次性拉取数量过大，会导致拉取消息时间过长，对broker和网络资源造成过度压力，同时consumer实例应用内存消耗过大，从而影响应用性能。如果要通过增加consumer实例数量或增加机器内存来解决该问题，则会增加成本；而通过控制每次拉取的消息数目，可以实现内存资源控制和应用性能优化。
更好地控制消息轮询的间隔时间：
当consumer实例消费消息的速度比broker生产消息的速度慢时，consumer会产生轮询时间间隔。如果轮询时间跨度过长，则会严重地延迟消息消费。而通过设置max-poll-records，可以控制consumer拉取消息的频率，进而控制消息消费的时间。
3、max-poll-records的最佳实践 max-poll-records的最佳实践共有下述三个核心思想：
3.1 根据机器内存和consumer实例数量调整参数
在设置max-poll-records参数时，应根据机器内存和实例数量来调整参数值，从而实现更好的性能和内存控制。如果消费数据量不大，可以设置较小的值，反之，如果消费数据量很大，则可以设置更大的值。
3.2 注意正确理解和使用max-poll-records
max-poll-records参数不是为了减少消息延迟而设置的，而是为了控制内存和消费弱化而设置的。在设置参数时应该明确这一点，从而更好地利用这个参数。
3.3 尽可能使用手动提交offset的方式
使用自动提交offset的方式，可能存在一些问题。如果一个消息批次在服务端已经被消费掉，但是由于客户端宕机或重启而没有及时提交offset，则可能导致消息重复消费的情况。因此， 建议在设置max-poll-records的同时，使用手动提交offset的方式。
4、案例实践 当前kafka的版本为2.8.11，Spring Boot的版本为2.7.6，在pom.xml中引入下述依赖：
&lt;dependency&gt; &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt; &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;version&gt;2.8.11&lt;/version&gt; &lt;/dependency&gt; 在yml配置文件进行如下配置：
spring: kafka: bootstrap-servers: 127.0.0.1:9092 consumer: group-id: 0 key-deserializer: org.apache.kafka.common.serialization.StringDeserializer value-deserializer: org.apache.kafka.common.serialization.StringDeserializer enable-auto-commit: false max-poll-records: 20 producer: key-serializer: org.apache.kafka.common.serialization.StringSerializer value-serializer: org.apache.kafka.common.serialization.StringSerializer listener: ack-mode: manual_immediate type: batch concurrency: 2 以下为相关配置的说明： spring.kafka.listener.type的值为batch表示开启批量消费，默认值为single(单条)。spring.kafka.consumer.enable-auto-commit的值为false表示关闭Kafka客户端的自动提交offSet。spring.kafka.consumer.max-poll-records的值为20表示在开启了批量消费以后，每次从Kafka服务端拉取的数据最大条数为20。spring.kafka.listener.ack-mode的值为manual_immediate表示关闭Spring的自动提交offSet，我们需要在代码中进行手动提交。spring.kafka.listener.ack-mode的取值有两个比较常见的选项值 MANUAL 和 MANUAL_IMMEDIATE。MANUAL表示处理完业务后，手动调用Acknowledgment.acknowledge()先将offset存放到map本地缓存，在下一次poll之前从缓存拿出来批量提交。MANUAL_IMMEDIATE表示每次处理完业务，手动调用Acknowledgment.acknowledge()后立即提交。 在项目中创建一个生产者用于往主题 topic0 中投递消息，如下所示：
import lombok.extern.slf4j.Slf4j; import org.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/1922c1c25b3bc0b861ee6a835df77cb0/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/8b44a9d20035effcc4150f3ff5ec168a/" rel="bookmark">
			数据存储【七】
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 7. 数据存储7.1 基本存储7.1.1 EmptyDir7.1.2 HostPath7.1.3 NFS 7.2 高级存储7.2.1 PV7.2.2 PVC7.2.3 生命周期 7.3 配置存储7.3.1 ConfigMap7.3.2 Secret 7. 数据存储 在前面已经提到，容器的生命周期可能很短，会被频繁地创建和销毁。那么容器在销毁时，保存在容器中的数据也会被清除。这种结果对用户来说，在某些情况下是不乐意看到的。为了持久化保存容器的数据，kubernetes引入了Volume的概念。
Volume是Pod中能够被多个容器访问的共享目录，它被定义在Pod上，然后被一个Pod里的多个容器挂载到具体的文件目录下，kubernetes通过Volume实现同一个Pod中不同容器之间的数据共享以及数据的持久化存储。Volume的生命容器不与Pod中单个容器的生命周期相关，当容器终止或者重启时，Volume中的数据也不会丢失。
kubernetes的Volume支持多种类型，比较常见的有下面几个：
简单存储：EmptyDir、HostPath、NFS高级存储：PV、PVC配置存储：ConfigMap、Secret 7.1 基本存储 7.1.1 EmptyDir EmptyDir是最基础的Volume类型，一个EmptyDir就是Host上的一个空目录。
EmptyDir是在Pod被分配到Node时创建的，它的初始内容为空，并且无须指定宿主机上对应的目录文件，因为kubernetes会自动分配一个目录，当Pod销毁时， EmptyDir中的数据也会被永久删除。 EmptyDir用途如下：
临时空间，例如用于某些应用程序运行时所需的临时目录，且无须永久保留一个容器需要从另一个容器中获取数据的目录（多容器共享目录） 接下来，通过一个容器之间文件共享的案例来使用一下EmptyDir。
在一个Pod中准备两个容器nginx和busybox，然后声明一个Volume分别挂在到两个容器的目录中，然后nginx容器负责向Volume中写日志，busybox中通过命令将日志内容读到控制台。
创建一个volume-emptydir.yaml
apiVersion: v1 kind: Pod metadata: name: volume-emptydir namespace: dev spec: containers: - name: nginx image: nginx:1.20.0 ports: - containerPort: 80 volumeMounts: # 将logs-volume挂在到nginx容器中，对应的目录为 /var/log/nginx - name: logs-volume mountPath: /var/log/nginx - name: busybox image: busybox:1.30 command: ["
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/8b44a9d20035effcc4150f3ff5ec168a/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/40a9bbfc9ef3f8042deeacd23c46421c/" rel="bookmark">
			undefined reference to symbol ‘sem_close@@GLIBC_2.2.5‘
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 1：sem_close 为信号量相关操作；
2：需要依赖 libpthread和librt 库；
3：所以编译的时候，需要增加 -lpthread -lrt 编译选项；
4：增加了依赖库之后，还要注意库的先后关系；先后关系不一致，也可能导致报错；
# 正确示例 gcc -o test test.c -lpthread -lrt # 报错示例 gcc -o test test.c -lrt -lpthread 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/b44c8faf40301b3c2d8845982de71368/" rel="bookmark">
			RT-Thread使用SystemView调试分析
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、SystemView SystemView is a toolkit for visual analysis of any embedded system. SystemView gives complete insight into an application, to gain a deep understanding of the runtime behavior, going far beyond what a debugger is offering. This is particularly advantageous when developing and working in complex systems with multiple tasks and events.
SystemView是一个用于可视化分析任何嵌入式系统的工具包。SystemView提供了对应用程序的完整洞察，以获得对运行时行为的深刻理解，远远超出了调试器所提供的。当在具有多个任务和事件的复杂系统中开发和工作时，这是特别有利的。
安装 进入SystemView官网进行下载
下载完成直接双击exe文件默认安装即可
进入SystemView，界面如下
二、RT-Thread 打开RT-Thread某例工程，添加SystemView软件包
打开SystemView通过工程地址与之联系
第一步，选择开始按钮
第二步，在弹出的窗口中选择 J-Link
第三步，填写mcu型号与工程地址
第四步，查看各线程运行情况
分析：
在此段中，线程thread1的开始运行时间为7.414s，由上方代码可知，设置的睡眠时间为100ms，也就是说经100ms的睡眠后会再次进入此线程
按下切换键后观察：
可发现，此时与理论值相吻合，分析成功
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/b44c8faf40301b3c2d8845982de71368/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/3bef3b07c9d05486a24e2d8575382f9c/" rel="bookmark">
			【Web前端期末大作业】中华文化宣传网站
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		目录 前言网页目录树1️⃣网页介绍2️⃣网页架构3️⃣系统环境4️⃣网页展示5️⃣代码展示结语 前言 015-【Web前端期末大作业】中华文化宣传网站
🥇个人主页：@MIKE笔记
🥈文章专栏：Web前端期末大作业
⛄源码咨询： wx：mikenote 15💴带走
网页目录树 在线演示：http://47.106.142.80:2023/
视频演示：https://www.bilibili.com/video/BV1Ug4y1r7Nt/?share_source=copy_web&amp;vd_source=d764770ff4322f1a1111e85d452245c6
原生html+css+javascript完成
1️⃣网页介绍 网站建设工具
1.使用VScode（当然使用记事本也是可以的）智能，快捷，支持代码补全，节省了开发时间，并且支持多种语言 只需安装插件配置文件即可。
2.网站建设学习资源
b站CSDN 3.网站建设步骤及思路分享
网站建设步骤在我一点学习的导航栏里有更为清晰的体现，这里就不一一赘述了网站的思路分享：整体的布局，以及内容，搜寻所需要的素材，建立站点 。布局的好坏直接影响了你网页看起来的效果，在此我推荐一些常用的网站布局，一般是导航栏在顶部，下面分为左右结构，分清主次 或者上中下三层结构等等，很多布局我觉得可以参考一些大型网站的布局或者一些个人博客的布局，以此增加自己的审美以及知识库。 建议壁纸在一些桌面软件里找，会比较清晰。同时建设网页的过程不会是一帆风顺的，要想有理想的效果一定是需要一定时间去调试使用的。 2️⃣网页架构 📢前端三件套：
htmlcssjs 3️⃣系统环境 环境版本 / 下载系统win 10 /win 11vscode2023 备注：以上版本为博主电脑配置，可点击进入官网下载
4️⃣网页展示 图片展示
页面太多，其他请看在线演示。
5️⃣代码展示 下面展示一些 内联代码片。
主页
&lt;!DOCTYPE html&gt; &lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Document&lt;/title&gt; &lt;link rel="stylesheet" href="css/index.css" &gt; &lt;/head&gt; &lt;body&gt; &lt;script src="./JS/index.js"&gt;&lt;/script&gt; &lt;header&gt; &lt;div class="nav"&gt; &lt;ul&gt; &lt;li class="
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/3bef3b07c9d05486a24e2d8575382f9c/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/aaa091bbe71ece206e83bcbb2cd40cf3/" rel="bookmark">
			Linux环境下通过journal命令查看和管理日志
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 前言问题分析journal 和 syslog 对比journal 和 syslog 配置使用journalctl查看和管理日志查看日志查看指定服务日志查看调整存储 回到文章开头的问题总结 前言 就在半月之前，负责打包更新的服务器突然登录不上去了，赶紧找来运维的同事帮忙解决，发现系统日志中有很多 systemd-journald[424]: Failed to open runtime journal: No space left on device 字样的错误，被告知磁盘满了需要清理，但是我当时登录不上去，只能让他们帮忙重启后利用单用户模式上去删除临时文件试试，但重启后发现问题解决了，很是诧异，查询服务器后台监控平台，发现磁盘空间还有50%，inode只占用了0.02%，这怎么会磁盘满了呢？
问题分析 后来经过分析，应该是journal默认将系统日志存储在/run/log/journal目录中，而 /run是一个临时文件系统，通常挂载在内存中，用于存储运行时产生的临时文件，如进程 ID 文件、锁文件等，如果登录所需的文件或进程受到 /run 空间不足的影响，可能会导致登录问题。例如，如果 sshd 进程的运行所需的文件被存储在 /run 中并且空间不足，那么可能无法正常登录。
$ df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 7.8G 0 7.8G 0% /dev tmpfs 7.8G 868K 7.8G 1% /run 所以系统重启后，这个空间释放了也就能通过ssh登录了，并且重启后journal日志清空也证实了这一点。
关于这个空间限制多数说的是10%，但是如果真是的所处分区的10%，那么不会导致我登录不上的，所以我倾向于是系统内存10%或者硬盘最大10%，默认最大限制4G，具体限制等我有空时查查文档吧，先贴一段看起来很靠谱的描述
SystemMaxUse=, SystemKeepFree=, SystemMaxFileSize=, SystemMaxFiles=, RuntimeMaxUse=, RuntimeKeepFree=, RuntimeMaxFileSize=, RuntimeMaxFiles=
限制日志文件的 大小上限。 以 “System” 开头的选项用于限制磁盘使用量， 也就是 /var/log/journal 的使用量。 以 “Runtime” 开头的选项用于限制内存使用量， 也就是 /run/log/journal 的使用量。 以 “System” 开头的选项仅在 /var/log/journal 目录确实存在且可写时才有意义。 但以 “Runtime” 开头的选项永远有意义。 也就是说， 在系统启动早期 /var 尚未挂载时、 或者系统管理员禁止在磁盘上存储日志的时候， 仅有 “Runtime” 开头的选项有意义。 journalctl 与 systemd-journald 工具会忽略日志目录中 所有后缀名不等于 “.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/aaa091bbe71ece206e83bcbb2cd40cf3/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/a9b1aaf33b9f00741f722fb95a29b974/" rel="bookmark">
			execjs执行报： ‘gbk‘ codec can‘t decode byte 0xac in position 62: illegal multibyte sequence
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		 import subprocess from functools import partial subprocess.Popen = partial(subprocess.Popen, encoding="utf-8") import execjs 
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/99118c0b7905d509670825c6ad50a12c/" rel="bookmark">
			Win系统修改Nginx配置结合内网穿透实现远程访问多个Web站点
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 1. 下载windows版Nginx2. 配置Nginx3. 测试局域网访问4. cpolar内网穿透5. 测试公网访问6. 配置固定二级子域名7. 测试访问公网固定二级子域名 1. 下载windows版Nginx 进入官方网站(http://nginx.org/en/download.html)下载windows版的nginx
下载好后解压进入nginx目录双击Nginx.exe即可运行
打开浏览器输入http://localhost ,nginx默认使用80端口,所以无需加端口号.出现nginx欢迎页面表示启动成功
2. 配置Nginx 在8086,和9999端口分别配置两个web服务,这里不详细说如何搭建web站点服务,可以参考该教程:https://www.cpolar.com/blog/build-web-server-in-windows-system
站点搭建好后,接下来需要修改nginx.conf配置文件,打开nginx目录,找到conf文件夹下面的nginx.conf
编辑文件,这里使用notepad++进行编辑,添加如下信息:
location ^~ /webs/ { proxy_pass http://127.0.0.1:8086/; } location ^~ /webc/ { proxy_pass http://127.0.0.1:9999/; } 参数简介(详情请看官方文档): ^~ : 表示开头对URL路径进行前缀匹配,并且在正则之前 proxy_pass: 代理的服务地址 编辑完保存,打开cmd窗口,进入nginx目录,执行如下命令重启:
nginx.exe -s reload 3. 测试局域网访问 重启后Nginx后，打开浏览器,以80端口加上在配置文件中配置的location代理转发规则进行访问两个站点:
4. cpolar内网穿透 接下来,我们通过强大的且稳定的内网穿透工具cpolar，将本地nginx服务暴露至公网环境,以实现穿透多个站点端口需求，无需公网IP，也不用设置路由器。
cpolar官网：https://www.cpolar.com/
打开cpolar官网，下载cpolar并安装。安装完成后，在浏览器上访问本地9200端口【http://localhost:9200/】，登录进入cpolar web ui管理界面。
点击左侧的隧道管理——创建隧道：
隧道名称：可自定义，注意不要与已有的隧道名称重复协议：http协议本地地址：80域名类型：免费选择随机域名地区：选择china vip 点击创建
隧道创建成功后，点击左侧的状态——在线隧道列表，可以看到已经有生成了相应的公网地址，将其复制下来。
5. 测试公网访问 打开浏览器，使用cpolar所生成的公网地址+在配置文件中配置的location代理转发规则来访问两个站点，测试访问成功。
6. 配置固定二级子域名 由于以上使用的cpolar所生成的公网地址为随机临时地址，24小时内会随机变化，我们可以为其配置固定的二级子域名。
注意，配置固定二级子域名需要将cpolar套餐升级至基础套餐或以上。
进入cpolar官网并登录进入后台界面，点击左侧的预留，找到保留二级子域名:
地区：选择China
二级域名：可自定义
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/99118c0b7905d509670825c6ad50a12c/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/de723a8b347dfb9f75e1bd0a3bad37f4/" rel="bookmark">
			初识Stable Diffusion
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		界面选项解读
这是在趋动云上部署的Stable Diffusion
txt2img prompt （1）分割符号：使用逗号 , 用于分割词缀，且有一定权重排序功能，逗号前权重高，逗号后权重低
（2）建议的通用范式：建议用以下归类的三大部分来准备相关提示词：前缀（画质词+画风词+镜头效果+光照效果） + 主体（人物&amp;对象+姿势+服装+道具） + 场景（环境+细节）
（3）更改提示词权重：使用小括号（）增加模型对被括住提示词的注意 (提高权重)。用 (xxx: ) 语法形式来提升权重，其中 xxx 是你要强调的词 1.x 代表要提升的比例，如 1.5 就是提升 150% 的权重。权重取值范围 0.4-1.6，权重太小容易被忽视，太大容易拟合图像出错。例：(beautiful:1.3) 。叠加权重：通过叠加小括号方式提高权重，每加一层相当于提高1.1倍权重，例：((((beautiful eyes))))相当于(beautiful eyes: 1.1*1.1*1.1)
(PromptA:权重)：用于提高或降低该提示词的权重比例，注：数值大于1提高，小于1降低(PromptB)：PromptB的权重为1.1=(PromptA:1.1){PromptC}: PromptC的权重为1.05=(PromptB:1.05)[PromptD]: PromptD的权重减弱0.952=(PromptC:0.952)((PromptE)=(PromptE:1.1*1.1){{PromptF}}=(PromptF:1.05*1.05)[[PromptG]]=(PromptG:0.952*0.952) （4）调取 LoRA &amp; Hypernetworks 模型：使用尖括号 &lt;&gt; 调取LoRA或超网络模型。
按照下述形式输入：&lt;lora:filename:multiplier&gt; 或 &lt;hypernet:filename:multiplier&gt; 可调取相应模型，例：&lt;lora:cuteGirlMix4_v10:0.5&gt; 。
注：要先确保在【...\models\lora】或【...\models\hypernetworks】文件夹已保存好相关模型文件
（5）分布与交替渲染：使用方框号 [] 可应用较为复杂的分布与交替需求。
[A:B:step] 代表执行A效果到多少进度，然后开始执行B。例：[blue:red:0.4]，渲染蓝色到40%进度渲染红色。注：step &gt; 1 时表示该组合在前多少步时做为 A 渲染，之后作为 B 渲染。step &lt; 1 时表示迭代步数百分比。[A:0.5] 这样写的含义是从50%进度开始渲染A[A::step] 渲染到多少进度的时候去除A[A|B] A和B交替混合渲染 （6）反向提示词：反向提示词（Negative prompt），就是我们不想出现什么的描述。例：NSFW 不适合在工作时看的内容，包括限制级，还有低画质相关和一些容易变形身体部位的描述等。
注：在C站可下载一个叫 Easynegative 的文件，它的作用是把一些常用的反向提示词整合在一起了，让我们只需输入简单的关键词就能得到较好效果。把它放到 xxx/enbeddings 文件夹，需要触发时在 negative prompt 中输入 easynegative 即可生效。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/de723a8b347dfb9f75e1bd0a3bad37f4/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/eddb9f3f056ee54f4c599fb45ca253ed/" rel="bookmark">
			以良好的架构方式在亚马逊云科技上构建安全应用程序
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		关键字: [Amazon Web Services re:Invent 2023, Amazon CodeGuru, Secure Applications, Well Architected Framework, Threat Modeling, Security Champions, Software Composition Analysis]
本文字数: 1100, 阅读完需: 6 分钟
视频 如视频不能正常播放，请前往bilibili观看本视频。&gt;&gt; 以良好的架构方式在亚马逊云科技上构建安全应用程序 [重复]_哔哩哔哩_bilibili
导读 今年，亚马逊云科技宣布更新亚马逊云科技六大支柱的 "良好架构框架"。安全支柱增加了一个新的最佳实践领域--应用安全（AppSec）。在本讲座中，我们将介绍该领域中强调的一些最佳实践。回顾四个关键领域：组织和文化、管道的安全性、管道中的安全性和依赖关系管理。探索每个领域如何提供一套可以实施的原则，以及如何提供设计、开发、构建、部署和运行工作负载的完整视图。了解如何使用本指南，就用于开发软件的工具、测试和组织方法做出决策。
演讲精华 以下是小编为您整理的本次演讲的精华，共800字，阅读时间大约是4分钟。如果您想进一步了解演讲内容或者观看演讲全文，请观看演讲完整视频或者下面的演讲原文。
这份演讲主要关注在亚马逊云科技(Amazon Web Services)平台上构建安全应用程序的策略与实践，并运用了一系列架构良好的框架。首先，亚马逊云科技解决方案架构师Ree De Souza女士简要介绍了在亚马逊云科技平台上进行应用开发和架构良好框架中的安全要素。她表示，企业希望通过在亚马逊云科技上构建安全的环境来提高业务价值。着陆区提供了一个类似内部数据中心硬件环境的完整安全屏障。对于不熟悉的人来说，设计模式和服务如亚马逊云科技控制塔可以帮助建立着陆区。一旦建立了着陆区，持续集成和持续交付(CI/CD)管道的基础设施就可以支持开发和部署应用程序。
现代的云原生应用程序通常采用微服务和无服务器架构，这种架构为开发者带来了灵活性，但也模糊了信息安全和应用程序安全之间的界限。通过遵循架构良好的框架提供的指导，可以保护在亚马逊云科技上的人和资产。最近纳入的应用程序安全最佳实践有助于在所有权转移到专注于快速发布功能的开发团队时维持安全性。
De Souza女士详细介绍了现代云应用的构成。她指出，可组合的架构包括一系列对不同微服务的API调用，这些微服务可以使用亚马逊云科技的服务或第三方服务。基于微服务的架构使开发者能够灵活地选择编程语言和开源包，从而实现更快速的开发。新的范式包括容器化的工作负载和无服务器应用程序，其中业务逻辑编写到代码中，模糊了信息安全与应用安全之间的界限。
在创作过程初期，威胁建模揭示了早期设计中的潜在风险，以便在代码层面或通过使用亚马逊云科技的安全服务加以解决。作为开源工具，亚马逊云科技的威胁建模器能够提供针对特定应用场景的威胁分析和修复指导。据De Souza女士介绍，成熟的亚马逊云科技客户应定期基于每轮冲刺或每个里程碑进行威胁建模工作。在这个过程中，会运用诸如STRIDE、OWASP Top 10和MITRE ATT&amp;CK等框架来对潜在问题展开头脑风暴。理解攻击者的行为和技能有助于更准确地评估被利用的风险。最终，这将导致更安全代码的编写以及亚马逊云科技提供的各种安全控制的充分利用。
例如，亚马逊云科技的服务如CodeWhisperer能在集成开发环境中（IDE）为开发者提供实时安全和编码建议。De Soula女士解释道，CodeWhisperer能分析代码和注释，为开发人员提供改进功能和代码块的实用建议，使他们能够根据需要进行调整。此外，亚马逊云科技的服务如CodeArtifact提供了一个可靠的第三方软件包存储库。而亚马逊云科技AppSync则负责连接和管理企业内部的软件即服务（SaaS）应用程序。De Soula女士强调，通过AppSync，可以实现对SaaS应用程序的数据进行安全处理和记录。
在源代码阶段，亚马逊云科技的服务如CodeGuru能通过对API的使用进行分析来发现潜在的漏洞。而亚马逊云科技的服务如Signer则能通过对代码进行签名来确保其完整性和可靠来源。De Soula女士进一步阐述，Signer不仅能为Lambda和IoT设备签名，还能为亚马逊云科技ECR中的容器镜像数字签名包。它集中管理签署权限，并与亚马逊云科技CloudTrail集成以确保合规性。
在构建和测试阶段，软件组成分析有助于识别第三方组件带来的潜在风险，而渗透测试则验证了已实施的缓解措施的有效性。亚马逊云科技的服务如Inspector能对Elastic Compute Cloud（EC2）、Lambda和容器进行漏洞扫描。De Soula女士特别强调了亚马逊云科技Inspector的自动化漏洞管理功能，如跨多个资源监控的汇总软件物料清单。她同时还提到了Inspector与CodeGuru之间最近的集成，用于对无服务器代码进行扫描和修复。
杰夫·隆巴尔多先生致力于研究如何在持续集成/部署（CI/CD）管道中实现自动化安全方法。通过集中式源代码控制以及对代码作为基础设施的应用，可以追踪代码更改。管道的各个阶段有助于分析软件材料清单等工件，从而了解潜在的风险点。隆巴尔多先生强调在管道中记录安全事件的重要性，以便进行追溯。
来自Zillow的乔希·麦金蒂先生详细阐述了他们的安全冠军计划，该计划旨在在团队中嵌入安全工程师，以便分析和修复代码中的漏洞。他们通过执行威胁建模、渗透测试和实际操作培训来建立安全专业知识。关键经验包括以同理心为主导，关注协助团队而非指责，以及理解系统以制定相应的保护措施。
总之，与开发人员密切合作以深入了解系统，与亚马逊云科技解决方案架构师合作，使用Well-Architected Framework评估工作负载，以及培养无责文化是被视为推荐做法的。可用资源包括Well-Architected Framework的安全支柱、亚马逊云科技安全参考架构以及将于2023年6月在费城举行的re:Inforce安全会议。
下面是一些演讲现场的精彩瞬间：
来自亚马逊云科技的一位解决方案架构师，Ree De Souza，与他的同事Jeff Lombardo以及来自Zillow的朋友Josh McKinty共同参加了一个活动。
在这个活动中，他们分享了各自的经验和见解。
Zillow致力于帮助人们寻找理想的家，从而开启人生的新篇章。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/eddb9f3f056ee54f4c599fb45ca253ed/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/06e905ab05bac30bb694c8c56affa604/" rel="bookmark">
			C&#43;&#43;对象的生命周期详细解读
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		提示：文章写完后，目录可以自动生成，如何生成可参考右边的帮助文档
文章目录 前言一、什么是生命周期？二、对象类型1.局部对象（local object）2.名字空间对象和类静态对象（namespace object，static class object）3.局部静态对象（local static object）4.自由存储空间对象（free-store object）5.临时对象 三、很重要总结 前言 我们写C++就不可避免需要用到变量，用到变量就要知道生命周期原则，要不然写的代码自带bug，崩盘只是迟早的事。
一、什么是生命周期？ 生命期顾名思义就是出生到死亡的这个时间。放到C++的对象上就是从对象被创建开始到对象被回收结束这么一个过程。
二、对象类型 前面已经说了生命周期是相对于对象来说的，要讲解生命期必须围绕着对象的类型来说，不同类型的对象生命期是完全不一样的。
1.局部对象（local object） 又称自动对象（automatic object），在程序执行到对象定义的位置时创建，在程序执行到对象的作用域末尾时被回收。
代码如下（示例）：
#include &lt;iostream&gt; class Demo { public: Demo() { std::cout &lt;&lt; "Demo" &lt;&lt; std::endl; } ~Demo() { std::cout &lt;&lt; "~Demo" &lt;&lt; std::endl; } }; void test() { Demo d;//对象定义的位置 } int main() { test(); } 为了方便演示，增加了自定义构造和析构。
执行结果：
Demo
~Demo
2.名字空间对象和类静态对象（namespace object，static class object） 在程序开始时（main之前）被创建，在程序结束后（main之后）被销毁。
代码如下（示例）：
#include &lt;iostream&gt; class Demo { public: Demo() { std::cout &lt;&lt; "
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/06e905ab05bac30bb694c8c56affa604/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/6bfb2fd7cce36e9c245cf3c3e8648964/" rel="bookmark">
			自定义security的权限验实现 @EnableGlobalMethodSecurity(prePostEnabled = true)
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		文章目录 场景分析(EnableGlobalMethodSecurity)实现 场景 security @EnableGlobalMethodSecurity(prePostEnabled = true)注解 支持自定义的方式实现权限验证, 下面展示一个实现方案。
分析(EnableGlobalMethodSecurity) @EnableGlobalMethodSecurity 注解是spring security用来开启方法级别权限验证注解的注解, 可以控制。
prePostEnabled = true 用来开启@PreAuthorize 和 @PostAuthorize 注解，允许在方法上使用表达式定义安全规则。
securedEnabled = true 表示启用 @Secured 注解，允许在方法上使用 @Secured 注解定义基于角色的访问控制
我们使用SPEL的方式自定义实现权限控制，比如: @PreAuthorize(“@customPermission.hasPermission(‘system:user:create’)”) 代表着调用customPermission bean的hasPermission 返回true代表有权限,false没有权限。
实现 开启@PreAuthorize注解 @EnableGlobalMethodSecurity(prePostEnabled = true) public class DemoWebSecurityConfigurerAdapter {} 注册权限验证类 /** * 自定义权限校验服务 * */ @Bean("customPermission") public SecurityPermissionService securityFrameworkService(PermissionApi permissionApi) { return new SecurityFrameworkServiceImpl(permissionApi); } /** * @version V1.0 * @author: carsonlius * @date: 2023/12/22 13:58 * @company * @description */ @RequiredArgsConstructor public class SecurityFrameworkServiceImpl implements SecurityPermissionService { private final PermissionApi permissionApi; @Override public boolean hasPermission(String permission) { return hasAnyPermissions(permission); } @Override public boolean hasAnyPermissions(String.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/6bfb2fd7cce36e9c245cf3c3e8648964/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/05191d8e6f3c1651883f38bae2ea91f9/" rel="bookmark">
			热部署 和 热加载
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		本文主要讲热部署和热加载的区别、原理，以及常用的热部署的方式实践心得，其中包括HotSwap、Spring-loaded、Spring-boot-devtools、HotCode2和JRebel，诸多方式任你选择，希望能为你的开发进一步提效
1 热部署和热加载 开篇先说下热部署和热加载的区别：
热部署：在服务器运行时重新部署应用，也就是说在不停止容器的情况下实现整个应用的重新加载部署，这种方式会释放内存，多用于生成环境
热加载：在应用运行时重新加载class，主要依赖于Java的类加载机制，如果监控的类文件有改变，则重新载入，多用于应用开发阶段，又叫开发者模式，在开发过程中会经常性的进行修改文件或debug，频繁启动应用会花费很多时间成本，热加载机制可以极大的提升开发效率，这也是写这篇文章的主要原因，提高大家的开发效率。
但我们通常所说的热部署其实包括热加载的，可以理解为热加载是热部署的一种VIP情况
2 热加载的原理 2.1 类加载过程 在了解热加载之前，首先说下类加载的过程，类加载的过程简单来说就是JVM虚拟机把.class文件中类信息加载进内存，并进行解析生成对应的class对象的过程；类加载的过程主要分为三大部分：加载、连接、初始化，其中连接又分为：验证、准备、解析；示例图如下：
编译：把Java文件编译成.class字节码的过程加载：类加载过程的开始，把class字节码文件从各个源通过类加载器载入内存中连接 验证：确保类加载的正确性，保证加载进来的字节流符合JVM规范，不会造成安全问题准备：类变量（注意，不是实例变量，是static变量）分配内存，并且设置这些类变量的初始值解析：将常量池内的符号引用替换为直接引用的过程初始化：是类加载过程的最后一步，可以理解为是执行类构造器&lt;clinit&gt;（）方法的过程，真正开始执行类中定义的Java程序代码或者说字节码。 2.2 剖析原理 首先通过Java编译器把Java文件编译成class字节码，Java类加载器（classLoad）读取字节码到内存中，生成实例对象，一个类加载器中的Java全限定名是全局唯一的，也就是说一个类加载器只能加载一个同名类，classLoader内部会缓存已经加载过的class，重新加载的话，是直接读 取缓存的，如果是使用自定义的classLoader加载，不使用双亲委派模型，绕过判断，但是在JVM解析、验证class时也是会抛出异常的，所以实现__热部署的关键是在可更改已加载的class文件，用新的class文件替换同名的old class文件（或者更改class字节码），或者是重新创建一个classLoader进行加载，然后把老的classLoader卸载掉__；第二种方案可以理解成热部署，所以这种方案为开发提效有限；而第一种方案是更新或替换old class文件所以这种热加载的方式对开发提效非常明显。
2.3 发展历程 在JDK1.4时，Sun在JVM中引入了HotSwap的实验性技术，这一技术被合成到了Debugger API内部，其允许调试者使用同一个类标识来更新类的字节码，这就意味着在不重载容器的情况下，允许动态更新class文件，使应用程序在执行时可执行新的代码。
从JDK1.5开始，提出了“Instrumentation”特性，可通过Instrumentation API直接提供给Java应用使用，开发者可以构建一个独立于应用程序的代理程序（Agent），用来监测和协助运行在 JVM 上的程序，甚至能够替换和修改某些类的定义，但在 JDK1.5 中，需要要求在运行前利用命令行参数或者系统参数来设置代理类。
JDK1.6之后，对Instrumentation进行了加强，启动后的 instrument、本地代码（native code）instrument，以及动态改变 classpath 等等，“java.lang.instrument”包的具体实现，依赖于 JVMTI（Java Virtual Machine Tool Interface），JVMTI 提供了一套”代理”程序机制，可以支持第三方工具程序以代理的方式连接和访问 JVM，并利用 JVMTI 提供的丰富的编程接口，完成很多跟 JVM 相关的功能，JVMTI 还在虚拟机内存管理，线程控制，方法和变量操作等等方面提供了大量有价值的函数，Instrumentation 的最大作用，就是类定义动态改变和操作。--参见IBM Developer
3 Hot Swap实现热部署 这种方式有两个弊端：
1 就是仅限于修改方法体，对比如新增方法、字段之类 就需要重新部署才可以了，这种方式有没有解决方案呐，答案是肯定的，收费的JRebel，或者免费的HotSwapAgent+DCEVM
2 HotSwap需要依托于IDE集成，比如主流的IDE：IntlliJ IDEA、Eclipse、MyEclipse、NetBeans等
下面HotSwap以IDEA为例实现方法体内的热部署功能
3.1 IDEA基于HotSwap的热部署功能 使用IDEA自动编译部署功能，实现应用的热部署(Hot Swap)
3.1.1 检查是否开启HotSwap，默认是开启的 3.1.2 开启IDEA自动编译功能 弹出registry浮层面板，快捷键control+shift+a,然后找到compiler.automake.allow.when.app.runing勾选
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/05191d8e6f3c1651883f38bae2ea91f9/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/28807051eea3d9d8b2ef489fe5ae29ec/" rel="bookmark">
			js排序常用算法
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		一、冒泡排序 1、基本思想： 通过相邻元素的比较和交换，使得每一趟循环都能找到未有序数组的最大值或最小值
2、 冒泡排序代码 function bubblingSort(){ //外循环，对被排序的数组进行遍历，轮数为数组的长度 for (let i = 0; i &lt; arr.length - 1; i++) { // 内循环 负责每轮交换的次数，循环比较相邻元素 for (let j = 0; j &lt; arr.length - i - 1; j++) { //如果前一个元素大于后一个元素的话，就交换两个元素的位置，最后是以从大到小的顺序输出 if (arr[j] &gt; arr[j + 1]) { let temp = arr[j] arr[j] = arr[j + 1] arr[j + 1] = temp } } } return arr } let arr = [4,1,6,3,5,2] console.
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/28807051eea3d9d8b2ef489fe5ae29ec/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/7eb97c07d75240553092f43bdc43abbd/" rel="bookmark">
			SpringMVC系列之技术点定向爆破二
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		SpringMVC的运行流程 客户端发送请求
tomcat接收对应的请求
SpringMVC的核心调度器DispatcherServlet接收到所有请求
请求地址与@RequestMapping注解进行匹配，定位到具体的类和具体的处理方法（封装在Handler中）
核心调度器找到Handler后交给HandlerAdapter执行具体的Handler
执行后Controller将具体的执行结果（ModelAndView）返回给HandlerAdapter
核心调度器把ModelAndView交给视图解析器，视图解析器找到具体的jsp封装到View对象中
View视图把jsp转换成html内容再交给核心调度器
核心调度器把html内容返回给客户端。
RequestMapping注解 在Controller中通过RequestMapping注解来定义匹配请求的URL。
RequestMapping注解可以定义在类的上方，作为类的中多个方法的统一URL前缀。
RequestMapping注解定义在方法的上方，作为此次请求具体要执行的方法的限定。
/** @Author: 索尔 */ @Controller //声明这是一个控制器 @RequestMapping("/hello") //访问路径，等价于url-pattern public class HelloController { @RequestMapping("/test1") //访问路径 public String hello1(){ System.out.println("hello world");//具体的业务逻辑 return "redirect:/index.jsp"; //跳转：/index.jsp } } RequestParam注解 RequestParam注解往往和RequestMapping注解配合使用，用来绑定请求参数和处理方法的参数。
我们来看下RequestParam注解的源码：
@Target({ElementType.PARAMETER}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface RequestParam { @AliasFor("name") String value() default ""; @AliasFor("value") String name() default ""; boolean required() default true; String defaultValue() default "\n\t\t\n\t\t\n\ue000\ue001\ue002\n\t\t\t\t\n"; } @RequestParam(required = false/true,value = “参数名”,defaultValue = “”) 其中name和value等效这里用value，推荐使用value。
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/7eb97c07d75240553092f43bdc43abbd/">Read more…</a>
	</div>
</article><article class="list__item post">
	
	<header class="list__header">
		<h2 class="list__title post__title">
			<a href="/posts/5154f1dc8ef7c7bcac6bf5f009b83237/" rel="bookmark">
			云卷云舒：云原生业务应用成熟度模型
			</a>
		</h2>
		
	</header>
	<div class="content list__excerpt post__content clearfix">
		笔者最近学习了信通院发布的《云原生应用成熟度的评估模型》，做如下解读：
一、概述 云原生业务应用成熟度模型从企业业务应用基础设施域、应用研发域以及服务治理域等三个能力域二十个过程域综合评估企业业务应用在弹性、高可用、自愈性、可观测性以及自动化等五个维度的云原生能力成熟度水平。
1、基础设施域：评估企业业务应用底层计算、存储以及网络等基础设施资源的云原生化程度以及基础设施层运维方式和能力；
2、应用研发域：从架构设计、开发构建、部署发布以及质量管理等企业业务应用研发关键环节能力水平；
3、服务治理域：从企业业务应用发布上线后，评估云原生业务应用在应用层面运维运营支撑能力水平。
二、云原生业务应用特性成熟度评估方法 云原生业务应用特性包括弹性、高可用、自愈性、可观测性以及自动化等，其成熟度评估以及对 应能力域与过程域成熟度等级综合计算，具体对应关系如下：
表1 云原生业务应用特性成熟度
能力域
过程域
云原生业务应用特性
弹性
高可用
自愈性
可观测性
自动化
基础设施域(C)
基础设施资源（I1）
√
√
√
基础设施资源（I1）
√
√
√
应用研发域(D)
架构设计（D1）
√
√
开发构建（D2）
√
√
√
测试管理（D3）
√
√
部署发布（D4）
√
服务治理域（G）
注册发现（G1）
√
√
流量管理（G2）
√
服务容错（G3）
√
√
服务降级（G4）
√
√
故障注入（G5）
√
√
链路追踪（G6）
√
应用监控（G7）
√
√
日志管理（G8）
√
配置管理（G9）
√
√
√
√
根据云原生业务应用特性成熟度对照表（表1），云原生业务应用特性成熟度计算方法如下：
	</div>
	<div class="list__footer clearfix">
		<a class="list__footer-readmore btn" href="/posts/5154f1dc8ef7c7bcac6bf5f009b83237/">Read more…</a>
	</div>
</article>
</main>

<div class="pagination">
	<a class="pagination__item pagination__item--prev btn" href="/page/50/">«</a>
	<span class="pagination__item pagination__item--current">51/489</span>
	<a class="pagination__item pagination__item--next btn" href="/page/52/">»</a>
</div>

			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>