<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Spatial Attention - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Spatial Attention" />
<meta property="og:description" content="Attention 机制 所谓Attention机制，便是聚焦于局部信息的机制。当我们再看一样东西时，我们当前时刻关注的一定是我们当前正在看的东西的某一个地方。随着任务的变化，注意力区域往往会发生变化。
面对上面这张图，如果从整体上看，只看到了很多的车，但仔细一看会发现每辆车的车牌号不同，汽车厂家也不同。
图中除了汽车之外的信息均是无用信息，也对目标识别网络起不到作用。Attention机制便是要找到这些对训练最有用的信息。
1. 基于Attention的显著目标检测 和注意力机制相伴而生的一个任务是显著目标检测，即salient object detection。它的输入是一张图，输出是一张概率图，概率越大的地方，获得人眼关注的概率越大。典型的显著图目标检测图如下：
左侧图像为显著图，其中在头部和身体概率最大，远处的门也有一定的概率，这就是左侧图像中有用的信息。右侧图中为显著性目标检测图像，将关注的重点人突出显示出来。
显著目标检测需要一个数据集，而此数据集的收集便是通过追踪多个实验者的眼球在一定时间内的注意力方向进行平均得到，典型的步骤如下：
（1）让被测试者观察图。
（2）用eye tracker记录眼睛的注意力位置。
（3）对所有测试者的注意力位置使用高斯滤波进行综合。
（4）结果以0~1的概率记录。
于是得到下面这样的图，第二行是眼球追踪结果，第三行是显著目标概率图。
上面讲述的都是空间上的注意力机制，及关注的是不同空间位置，而在CNN结构中，还有不同的特征通道，因此不同特征通道也有类似的原理。
2. Attention模型框架 注意力机制的本质就是定位到感兴趣的信息，抑制无用信息，结果通常都是以概率图或者概率特征向量的形式展示，从原理上来说，主要分为空间注意力模型，通道注意力模型，空间和通道混合注意力模型三种，这里不区分soft和hard attention。
2.1 空间注意力模型(spatial attention) 不是图像中所有的区域对任务的贡献都是同样重要的，只有任务相关的区域才是需要关心的，比如分类任务的主体，空间注意力模型就是寻找网络中最重要的部位进行处理。
在这里给大家介绍两个具有代表性的模型，第一个就是Google DeepMind提出的STN网络(Spatial Transformer Network[1])。它通过学习输入的形变，从而完成适合任务的预处理操作，是一种基于空间的Attention模型，网络结构如下：
这里的Localization Net用于生成仿射变换系数，输入是C×H×W维的图像，输出是一个空间变换系数，它的大小根据要学习的变换类型而定，如果是仿射变换，则是一个6维向量。
这样的一个网络要完成的效果如下图：
即定位到目标的位置，然后进行旋转等操作，使得输入样本更加容易学习。
相比于Spatial Transformer Networks 一步完成目标的定位和仿射变换调整，Dynamic Capacity Networks[2]则采用了两个子网络，分别是低性能的子网络(coarse model)和高性能的子网络(fine model)。低性能的子网络(coarse model)用于对全图进行处理，定位感兴趣区域，如下图中的操作fc。高性能的子网络(fine model)则对感兴趣区域进行精细化处理，如下图的操作ff。两者共同使用，可以获得更低的计算代价和更高的精度。
由于在大部分情况下我们感兴趣的区域只是图像中的一小部分，因此空间注意力的本质就是定位目标并进行一些变换或者获取权重。
2.2 通道注意力机制 对于输入2维图像的CNN来说，一个维度是图像的尺度空间，即长宽，另一个维度就是通道，因此基于通道的Attention也是很常用的机制。
SENet(Sequeeze and Excitation Net)[3]是2017届ImageNet分类比赛的冠军网络，本质上是一个基于通道的Attention模型，它通过建模各个特征通道的重要程度，然后针对不同的任务增强或者抑制不同的通道，原理图如下：
在正常的卷积操作后分出了一个旁路分支，首先进行Squeeze操作(即图中Fsq(·))，它将空间维度进行特征压缩，即每个二维的特征图变成一个实数，相当于具有全局感受野的池化操作，特征通道数不变。
然后是Excitation操作(即图中的Fex(·))，它通过参数w为每个特征通道生成权重，w被学习用来显式地建模特征通道间的相关性。在文章中，使用了一个2层bottleneck结构(先降维再升维)的全连接层&#43;Sigmoid函数来实现。
得到了每一个特征通道的权重之后，就将该权重应用于原来的每个特征通道，基于特定的任务，就可以学习到不同通道的重要性。
将其机制应用于若干基准模型，在增加少量计算量的情况下，获得了更明显的性能提升。作为一种通用的设计思想，它可以被用于任何现有网络，具有较强的实践意义。而后SKNet[4]等方法将这样的通道加权的思想和Inception中的多分支网络结构进行结合，也实现了性能的提升。
通道注意力机制的本质，在于建模了各个特征之间的重要性，对于不同的任务可以根据输入进行特征分配，简单而有效。
2.3 空间和通道注意力机制的融合 前述的Dynamic Capacity Network是从空间维度进行Attention，SENet是从通道维度进行Attention，自然也可以同时使用空间Attention和通道Attention机制。
CBAM(Convolutional Block Attention Module)[5]是其中的代表性网络，结构如下：
通道方向的Attention建模的是特征的重要性，结构如下：
同时使用最大pooling和均值pooling算法，然后经过几个MLP层获得变换结果，最后分别应用于两个通道，使用sigmoid函数得到通道的attention结果。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a12c1b66adb7074ea7dd452ff547824e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-30T18:37:02+08:00" />
<meta property="article:modified_time" content="2022-10-30T18:37:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Spatial Attention</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><strong>Attention 机制</strong></h2> 
<p>所谓Attention机制，便是聚焦于局部信息的机制。当我们再看一样东西时，我们当前时刻关注的一定是我们当前正在看的东西的某一个地方。随着任务的变化，注意力区域往往会发生变化。</p> 
<p><img alt="" height="593" src="https://images2.imgbox.com/04/22/dgEM82UM_o.png" width="1077"></p> 
<p>面对上面这张图，如果从整体上看，只看到了很多的车，但仔细一看会发现每辆车的车牌号不同，汽车厂家也不同。</p> 
<p>图中除了汽车之外的信息均是无用信息，也对目标识别网络起不到作用。Attention机制便是要找到这些对训练最有用的信息。</p> 
<h4>1. 基于Attention的显著目标检测</h4> 
<p>和注意力机制相伴而生的一个任务是显著目标检测，即salient object detection。它的输入是一张图，输出是一张概率图，概率越大的地方，获得人眼关注的概率越大。典型的显著图目标检测图如下：</p> 
<p><img alt="" height="433" src="https://images2.imgbox.com/0f/19/EmyNDWpS_o.png" width="666"></p> 
<p>左侧图像为显著图，其中在头部和身体概率最大，远处的门也有一定的概率，这就是左侧图像中有用的信息。右侧图中为显著性目标检测图像，将关注的重点人突出显示出来。</p> 
<p>显著目标检测需要一个数据集，而此数据集的收集便是通过追踪多个实验者的眼球在一定时间内的注意力方向进行平均得到，典型的步骤如下：</p> 
<p>（1）让被测试者观察图。</p> 
<p>（2）用eye tracker记录眼睛的注意力位置。</p> 
<p>（3）对所有测试者的注意力位置使用高斯滤波进行综合。</p> 
<p>（4）结果以0~1的概率记录。</p> 
<p>于是得到下面这样的图，第二行是眼球追踪结果，第三行是显著目标概率图。</p> 
<p><img alt="" height="337" src="https://images2.imgbox.com/11/73/kZkseHt3_o.png" width="672"></p> 
<p>上面讲述的都是空间上的注意力机制，及关注的是不同空间位置，而在CNN结构中，还有不同的特征通道，因此不同特征通道也有类似的原理。</p> 
<h4>2. Attention模型框架</h4> 
<p>注意力机制的本质就是定位到感兴趣的信息，抑制无用信息，结果通常都是以概率图或者概率特征向量的形式展示，从原理上来说，主要分为<strong>空间注意力模型，通道注意力模型，空间和通道混合注意力模型三种，这里不区分soft和hard attention。</strong></p> 
<h4>2.1 空间注意力模型(spatial attention)</h4> 
<p>不是图像中所有的区域对任务的贡献都是同样重要的，只有任务相关的区域才是需要关心的，比如分类任务的主体，空间注意力模型就是寻找网络中最重要的部位进行处理。</p> 
<p>在这里给大家介绍两个具有代表性的模型，第一个就是Google DeepMind提出的STN网络(Spatial Transformer Network[1])。它通过学习输入的形变，从而完成适合任务的预处理操作，是一种基于空间的Attention模型，网络结构如下：</p> 
<p><img alt="" height="293" src="https://images2.imgbox.com/65/67/D5XmWNEK_o.png" width="675"></p> 
<p>这里的Localization Net用于生成仿射变换系数，输入是C×H×W维的图像，输出是一个空间变换系数，它的大小根据要学习的变换类型而定，如果是仿射变换，则是一个6维向量。</p> 
<p>这样的一个网络要完成的效果如下图：</p> 
<p><img alt="" height="290" src="https://images2.imgbox.com/d4/a3/KYu9XFeK_o.png" width="686"></p> 
<p>即定位到目标的位置，然后进行旋转等操作，使得输入样本更加容易学习。</p> 
<p>相比于Spatial Transformer Networks 一步完成目标的定位和仿射变换调整，Dynamic Capacity Networks[2]则采用了两个子网络，分别是低性能的子网络(coarse model)和高性能的子网络(fine model)。低性能的子网络(coarse model)用于对全图进行处理，定位感兴趣区域，如下图中的操作fc。高性能的子网络(fine model)则对感兴趣区域进行精细化处理，如下图的操作ff。两者共同使用，可以获得更低的计算代价和更高的精度。</p> 
<p><img alt="" height="295" src="https://images2.imgbox.com/7f/b5/RbekzyHC_o.png" width="650"></p> 
<p>由于在大部分情况下我们感兴趣的区域只是图像中的一小部分，因此空间注意力的本质就是定位目标并进行一些变换或者获取权重。</p> 
<h4>2.2 通道注意力机制</h4> 
<p>对于输入2维图像的CNN来说，一个维度是图像的尺度空间，即长宽，另一个维度就是通道，因此基于通道的Attention也是很常用的机制。</p> 
<p>SENet(Sequeeze and Excitation Net)[3]是2017届ImageNet分类比赛的冠军网络，本质上是一个基于通道的Attention模型，它通过建模各个特征通道的重要程度，然后针对不同的任务增强或者抑制不同的通道，原理图如下：</p> 
<p><img alt="" height="169" src="https://images2.imgbox.com/d3/54/b9kU1M7L_o.png" width="706"></p> 
<p></p> 
<p>在正常的卷积操作后分出了一个旁路分支，首先进行Squeeze操作(即图中Fsq(·))，它将空间维度进行特征压缩，即每个二维的特征图变成一个实数，相当于具有全局感受野的池化操作，特征通道数不变。</p> 
<p>然后是Excitation操作(即图中的Fex(·))，它通过参数w为每个特征通道生成权重，w被学习用来显式地建模特征通道间的相关性。在文章中，使用了一个2层bottleneck结构(先降维再升维)的全连接层+Sigmoid函数来实现。</p> 
<p>得到了每一个特征通道的权重之后，就将该权重应用于原来的每个特征通道，基于特定的任务，就可以学习到不同通道的重要性。</p> 
<p>将其机制应用于若干基准模型，在增加少量计算量的情况下，获得了更明显的性能提升。作为一种通用的设计思想，它可以被用于任何现有网络，具有较强的实践意义。而后SKNet[4]等方法将这样的通道加权的思想和Inception中的多分支网络结构进行结合，也实现了性能的提升。</p> 
<p>通道注意力机制的本质，在于建模了各个特征之间的重要性，对于不同的任务可以根据输入进行特征分配，简单而有效。</p> 
<h4>2.3 空间和通道注意力机制的融合</h4> 
<p>前述的Dynamic Capacity Network是从空间维度进行Attention，SENet是从通道维度进行Attention，自然也可以同时使用空间Attention和通道Attention机制。</p> 
<p>CBAM(Convolutional Block Attention Module)[5]是其中的代表性网络，结构如下：</p> 
<p><img alt="" height="213" src="https://images2.imgbox.com/07/3f/Wxefv1OH_o.png" width="668"></p> 
<p> 通道方向的Attention建模的是特征的重要性，结构如下：</p> 
<p><img alt="" height="190" src="https://images2.imgbox.com/d7/48/RqGRSmZt_o.png" width="679"></p> 
<p></p> 
<p>同时使用最大pooling和均值pooling算法，然后经过几个MLP层获得变换结果，最后分别应用于两个通道，使用sigmoid函数得到通道的attention结果。</p> 
<p>空间方向的Attention建模的是空间位置的重要性，结构如下：</p> 
<p><img alt="" height="245" src="https://images2.imgbox.com/99/93/dttFIEKh_o.png" width="675"></p> 
<p>首先将通道本身进行降维，分别获取最大池化和均值池化结果，然后拼接成一个特征图，再使用一个卷积层进行学习。</p> 
<p>这两种机制，分别学习了通道的重要性和空间的重要性，还可以很容易地嵌入到任何已知的框架中。</p> 
<p>除此之外，还有很多的注意力机制相关的研究，比如<strong>残差注意力机制，多尺度注意力机制，递归注意力机制等。</strong></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/15f28945891f3ad5f5804f7dac643137/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">新浪下拉菜单案例淘宝服饰精品案例</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/89acf9e60d0fa535faee924c70821bec/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">postman发送post请求如何传递参数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>