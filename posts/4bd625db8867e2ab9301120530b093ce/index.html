<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>决策树与随机森林 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="决策树与随机森林" />
<meta property="og:description" content="目录 决策树是：Why：How：基本概念决策树生成举例决策树缺点参考 Demo 随机森林1.是：2.Why：3.How：参考 Demo 决策树 是： 1.一种有监督的分类（或预测）算法。
2.利用属性、属性值构造一个决策的路径，可类比程序的if_else的多层判断。
如：利用贷款人信息预测是否会拖延还贷的一个简单决策树。
Why： 易于理解和解释。树可以被可视化。几乎不需要数据准备。其他算法通常需要数据标准化，需要创建虚拟变量并删除缺失值。但是，请注意，此模块不支持缺失值。使用树的成本(即预测数据)是用于训练树的数据点数的对数。 能够处理数值型和分类型数据。其他技术通常专门分析只有一种类型变量的数据集。能够处理多输出问题。使用白盒模型。如果给定的情况在模型中是可以观察到的，那么对条件的解释就很容易用布尔逻辑来解释。相反，在黑箱模型中(例如，在人工神经网络中)，结果可能很难解释。可以使用统计测试验证模型。这样就有可能对模型的可靠性作出解释。 即使它的假设在某种程度上被生成数据的真实模型所违背，它也表现得很好。 How： 基本概念 训练数据：用于训练模型的数据，英文是train。
测试数据：用于测试（验证）模型准确度的数据，英文是test。训练数据、测试数据都是来自已知的数据集，然后划分为2部分，一部分训练、一部分测试（验证），也就是在已知的数据集内完成训练和验证，才能去预测实战。
纯度、不纯度：根据某个属性分割数据集，样本类型的集中度，纯度越高越高。如按是否恒温划分是否哺乳动物，10个里9个是哺乳动物，纯度高；如按是否有毛发划分，则10个里有6个是哺乳动物，则纯度降低。是否恒温是更好的划分属性。常用的测算纯度的函数有基尼gini、熵entropy。、
信息增益（information gain）：对父节点，按属性再次划分后，纯度的增加量。
决策树生成 举例 数据集
样本个数10个，属性3个：有房者、婚姻、年收入；标签：是否拖欠贷款。
可以凭感觉，用if-else构造一个决策树。属性排序：有房者、婚姻、年收入。
问题：因为属性、属性性值、先后顺序，决策树有指数个肯能，哪个是最优？
属性测算
婚姻属性的信息纯度最高。
3. 属性选择
类似，生成完整的树。与感性的分配有差异，属性排序：婚姻、有房者、年收入。
关键问题：如何选择属性、生成节点？
选择属性、按属性值分类、局部最优、信息增益最大。
后序以此类推。
决策树缺点 决策树学习器可以创建过于复杂的树，不能很好地概括数据。这就是所谓的过拟合。为了避免这个问题，必须设置剪枝、设置叶节点所需的最小样本数或设置树的最大深度等机制。决策树可能是不稳定的，因为数据中的小变化可能导致生成完全不同的树。通过集成决策树来缓解这个问题。学习最优决策树的问题在最优性的几个方面都是NP-complete的，甚至对于简单的概念也是如此。因此，实际的决策树学习算法是基于启发式算法，如贪婪算法，在每个节点上进行局部最优决策。这种算法不能保证返回全局最优决策树。这可以通过训练多棵树再集成一个学习器来缓解，其中特征和样本被随机抽取并替换。有些概念很难学习，因为决策树不能很容易地表达它们，例如异或、奇偶校验或多路复用器问题。如果某些类占主导地位，则决策树学习者会创建有偏见的树。因此，建议在拟合决策树之前平衡数据集。 参考 https://www.bilibili.com/video/BV1T7411b7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=1e37904a72db86b329d6b5320c86a013
Demo 酒分类预测：
https://github.com/heroicpoem/MachineLearningInAction/blob/master/decisionTree.ipynb
随机森林 1.是： 基于决策树的、集成算法。
森林，指包含多个决策树；
随机，指构造单棵决策树时，随机的选择样本，使得决策树是不同，或者侧重不同的能力。最后是整合多棵树的预测结果：均值或者众数。
2.Why： 随机决策森林纠正了决策树的过度拟合随机森林通常优于决策树，但它们的准确性低于梯度提升树更多的树会提高性能并使预测更稳定抗噪 3.How： 构造多棵决策树，分别决策，整合结果。
2个超参：决策树个数、分几层、如何采样、结果整合方法。
参考 https://www.bilibili.com/video/BV1H5411e73F/?spm_id_from=333.337.search-card.all.click&amp;vd_source=1e37904a72db86b329d6b5320c86a013
Demo https://blog.csdn.net/Graow/article/details/106749351" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4bd625db8867e2ab9301120530b093ce/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-03T17:26:52+08:00" />
<meta property="article:modified_time" content="2023-08-03T17:26:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">决策树与随机森林</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_2" rel="nofollow">决策树</a></li><li><ul><li><a href="#_3" rel="nofollow">是：</a></li><li><a href="#Why_10" rel="nofollow">Why：</a></li><li><a href="#How_19" rel="nofollow">How：</a></li><li><ul><li><a href="#_20" rel="nofollow">基本概念</a></li><li><a href="#_32" rel="nofollow">决策树生成</a></li><li><ul><li><a href="#_33" rel="nofollow">举例</a></li><li><a href="#_51" rel="nofollow">决策树缺点</a></li><li><ul><li><a href="#_57" rel="nofollow">参考</a></li></ul> 
    </li></ul> 
    </li><li><a href="#Demo_59" rel="nofollow">Demo</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_64" rel="nofollow">随机森林</a></li><li><ul><li><a href="#1_65" rel="nofollow">1.是：</a></li><li><a href="#2Why_69" rel="nofollow">2.Why：</a></li><li><a href="#3How_74" rel="nofollow">3.How：</a></li><li><ul><li><ul><li><a href="#_79" rel="nofollow">参考</a></li></ul> 
   </li></ul> 
   </li><li><a href="#Demo_82" rel="nofollow">Demo</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_2"></a>决策树</h2> 
<h3><a id="_3"></a>是：</h3> 
<p>1.一种有监督的分类（或预测）算法。<br> 2.利用属性、属性值构造一个决策的路径，可类比程序的if_else的多层判断。<br> 如：利用贷款人信息预测是否会拖延还贷的一个简单决策树。<br> <img src="https://images2.imgbox.com/99/02/SEsZjQXK_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Why_10"></a>Why：</h3> 
<ol><li>易于理解和解释。树可以被可视化。</li><li>几乎不需要数据准备。其他算法通常需要数据标准化，需要创建虚拟变量并删除缺失值。但是，请注意，此模块不支持缺失值。</li><li>使用树的成本(即预测数据)是用于训练树的数据点数的对数。 能够处理数值型和分类型数据。其他技术通常专门分析只有一种类型变量的数据集。</li><li>能够处理多输出问题。</li><li>使用白盒模型。如果给定的情况在模型中是可以观察到的，那么对条件的解释就很容易用布尔逻辑来解释。相反，在黑箱模型中(例如，在人工神经网络中)，结果可能很难解释。</li><li>可以使用统计测试验证模型。这样就有可能对模型的可靠性作出解释。 即使它的假设在某种程度上被生成数据的真实模型所违背，它也表现得很好。</li></ol> 
<h3><a id="How_19"></a>How：</h3> 
<h4><a id="_20"></a>基本概念</h4> 
<ol><li> <p>训练数据：用于训练模型的数据，英文是train。</p> </li><li> <p>测试数据：用于测试（验证）模型准确度的数据，英文是test。训练数据、测试数据都是来自已知的数据集，然后划分为2部分，一部分训练、一部分测试（验证），也就是在已知的数据集内完成训练和验证，才能去预测实战。</p> </li><li> <p>纯度、不纯度：根据某个属性分割数据集，样本类型的集中度，纯度越高越高。如按是否恒温划分是否哺乳动物，10个里9个是哺乳动物，纯度高；如按是否有毛发划分，则10个里有6个是哺乳动物，则纯度降低。是否恒温是更好的划分属性。常用的测算纯度的函数有基尼gini、熵entropy。、<br> <img src="https://images2.imgbox.com/be/28/VT8f3bo1_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3f/34/Ax8D9ljM_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/31/1e/w2rUYcnP_o.png" alt="在这里插入图片描述"></p> </li><li> <p>信息增益（information gain）：对父节点，按属性再次划分后，纯度的增加量。</p> </li></ol> 
<h4><a id="_32"></a>决策树生成</h4> 
<h5><a id="_33"></a>举例</h5> 
<ol><li> <p>数据集<br> 样本个数10个，属性3个：有房者、婚姻、年收入；标签：是否拖欠贷款。<br> 可以凭感觉，用if-else构造一个决策树。属性排序：有房者、婚姻、年收入。<br> 问题：因为属性、属性性值、先后顺序，决策树有指数个肯能，哪个是最优？<br> <img src="https://images2.imgbox.com/60/ec/TltDIHGA_o.png" alt="在这里插入图片描述"></p> </li><li> <p>属性测算<br> <img src="https://images2.imgbox.com/66/e4/BSCKURDm_o.png" alt="在这里插入图片描述"></p> </li></ol> 
<p>婚姻属性的信息纯度最高。<br> 3. 属性选择<br> <img src="https://images2.imgbox.com/25/ba/eoOCwKUN_o.png" alt="在这里插入图片描述"></p> 
<p>类似，生成完整的树。与感性的分配有差异，属性排序：婚姻、有房者、年收入。<br> <strong>关键问题：如何选择属性、生成节点？</strong><br> 选择属性、按属性值分类、局部最优、信息增益最大。<br> 后序以此类推。</p> 
<h5><a id="_51"></a>决策树缺点</h5> 
<ol><li>决策树学习器可以创建过于复杂的树，不能很好地概括数据。这就是所谓的过拟合。为了避免这个问题，必须设置剪枝、设置叶节点所需的最小样本数或设置树的最大深度等机制。</li><li>决策树可能是不稳定的，因为数据中的小变化可能导致生成完全不同的树。通过集成决策树来缓解这个问题。</li><li>学习最优决策树的问题在最优性的几个方面都是NP-complete的，甚至对于简单的概念也是如此。因此，实际的决策树学习算法是基于启发式算法，如贪婪算法，在每个节点上进行局部最优决策。这种算法不能保证返回全局最优决策树。这可以通过训练多棵树再集成一个学习器来缓解，其中特征和样本被随机抽取并替换。</li><li>有些概念很难学习，因为决策树不能很容易地表达它们，例如异或、奇偶校验或多路复用器问题。</li><li>如果某些类占主导地位，则决策树学习者会创建有偏见的树。因此，建议在拟合决策树之前平衡数据集。</li></ol> 
<h6><a id="_57"></a>参考</h6> 
<p>https://www.bilibili.com/video/BV1T7411b7DG/?spm_id_from=333.337.search-card.all.click&amp;vd_source=1e37904a72db86b329d6b5320c86a013</p> 
<h4><a id="Demo_59"></a>Demo</h4> 
<p>酒分类预测：<br> https://github.com/heroicpoem/MachineLearningInAction/blob/master/decisionTree.ipynb</p> 
<h2><a id="_64"></a>随机森林</h2> 
<h3><a id="1_65"></a>1.是：</h3> 
<p>基于决策树的、集成算法。<br> 森林，指包含多个决策树；<br> 随机，指构造单棵决策树时，随机的选择样本，使得决策树是不同，或者侧重不同的能力。最后是整合多棵树的预测结果：均值或者众数。</p> 
<h3><a id="2Why_69"></a>2.Why：</h3> 
<ol><li>随机决策森林纠正了决策树的过度拟合</li><li>随机森林通常优于决策树，但它们的准确性低于梯度提升树</li><li>更多的树会提高性能并使预测更稳定</li><li>抗噪</li></ol> 
<h3><a id="3How_74"></a>3.How：</h3> 
<p>构造多棵决策树，分别决策，整合结果。<br> 2个超参：决策树个数、分几层、如何采样、结果整合方法。<br> <img src="https://images2.imgbox.com/88/f9/ZadPwUjT_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_79"></a>参考</h5> 
<p>https://www.bilibili.com/video/BV1H5411e73F/?spm_id_from=333.337.search-card.all.click&amp;vd_source=1e37904a72db86b329d6b5320c86a013</p> 
<h3><a id="Demo_82"></a>Demo</h3> 
<p>https://blog.csdn.net/Graow/article/details/106749351</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/11b5477cb13bc285d3cd4b2d5cd47ec5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">UE5实现像素流送</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/038b2c0678a8e30b6ca5ed26e4828e08/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Docker 中使用 Nginx</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>