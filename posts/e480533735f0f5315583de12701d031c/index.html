<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch-å®ç°å¤©æ°”è¯†åˆ« - èœé¸Ÿç¨‹åºå‘˜åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch-å®ç°å¤©æ°”è¯†åˆ«" />
<meta property="og:description" content="ğŸ¨ æœ¬æ–‡ä¸ºğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥Â ä¸­çš„å­¦ä¹ è®°å½•åšå®¢ğŸ¦ å‚è€ƒæ–‡ç« ï¼š[365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥-ç¬¬P3å‘¨ï¼šå¤©æ°”è¯†åˆ«](365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥-ç¬¬P3å‘¨ï¼šå¤©æ°”è¯†åˆ« Â· è¯­é›€ (yuque.com))**ğŸ– åŸä½œè€…ï¼šKåŒå­¦å•Š|æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶ æˆ‘çš„ç¯å¢ƒ
è¯­è¨€ç¯å¢ƒï¼šPython3.6ç¼–è¯‘å™¨ï¼šjupyter labæ·±åº¦å­¦ä¹ ç¯å¢ƒï¼špytorch1.10å‚è€ƒæ–‡ç« ï¼šæœ¬äººåšå®¢(60æ¡æ¶ˆæ¯) æœºå™¨å­¦ä¹ ä¹‹â€”â€”tensorflow&#43;pytorch_é‡é‚®ç ”ç©¶æ£®çš„åšå®¢-CSDNåšå®¢ ğŸºè¦æ±‚ï¼š
æœ¬åœ°è¯»å–å¹¶åŠ è½½æ•°æ®ã€‚ï¼ˆâœ”ï¼‰ æµ‹è¯•é›†accuracyåˆ°è¾¾93%ï¼ˆâœ”ï¼‰ ğŸ»æ‹”é«˜ï¼š
æµ‹è¯•é›†accuracyåˆ°è¾¾95%ï¼ˆâœ”ï¼‰è°ƒç”¨æ¨¡å‹è¯†åˆ«ä¸€å¼ æœ¬åœ°å›¾ç‰‡ï¼ˆâœ”ï¼‰ ç›®å½•
ä¸€ å‰æœŸå·¥ä½œ
1.è®¾ç½®GPUæˆ–è€…cpu
2.å¯¼å…¥æ•°æ®
äºŒ æ•°æ®é¢„å¤„ç†
ä¸‰ æ­å»ºç½‘ç»œ
å›› è®­ç»ƒæ¨¡å‹
1.è®¾ç½®å­¦ä¹ ç‡
2.æ¨¡å‹è®­ç»ƒ
äº” æ¨¡å‹è¯„ä¼°
1.Losså’ŒAccuracyå›¾
2.å¯¹ç»“æœè¿›è¡Œé¢„æµ‹
3.æ€»ç»“
ä¸€ å‰æœŸå·¥ä½œ ç¯å¢ƒï¼špython3.6ï¼Œ1080tiï¼Œpytorch1.10ï¼ˆå®éªŒå®¤æœåŠ¡å™¨çš„ç¯å¢ƒğŸ˜‚ğŸ˜‚ï¼‰
1.è®¾ç½®GPUæˆ–è€…cpu import torch import torch.nn as nn import matplotlib.pyplot as plt import torchvision device = torch.device(&#34;cuda&#34; if torch.cuda.is_available() else &#34;cpu&#34;) device 2.å¯¼å…¥æ•°æ® import os,PIL,random,pathlib data_dir = &#39;weather_photos/&#39; data_dir = pathlib.Path(data_dir) print(data_dir) data_paths = list(data_dir." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e480533735f0f5315583de12701d031c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-07T17:17:22+08:00" />
<meta property="article:modified_time" content="2022-10-07T17:17:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="èœé¸Ÿç¨‹åºå‘˜åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">èœé¸Ÿç¨‹åºå‘˜åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch-å®ç°å¤©æ°”è¯†åˆ«</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <ul><li><strong>ğŸ¨ æœ¬æ–‡ä¸º<a href="https://mp.weixin.qq.com/s/xLjALoOD8HPZcH563En8bQ" rel="nofollow" title="ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥">ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥</a>Â ä¸­çš„å­¦ä¹ è®°å½•åšå®¢</strong></li><li><strong>ğŸ¦ å‚è€ƒæ–‡ç« ï¼š[365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥-ç¬¬P3å‘¨ï¼šå¤©æ°”è¯†åˆ«](</strong><a href="https://www.yuque.com/mingtian-fkmxf/hv4lcq/regaw7#199aab1d" rel="nofollow" title="365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥-ç¬¬P3å‘¨ï¼šå¤©æ°”è¯†åˆ« Â· è¯­é›€ (yuque.com)">365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥-ç¬¬P3å‘¨ï¼šå¤©æ°”è¯†åˆ« Â· è¯­é›€ (yuque.com)</a><strong>)**</strong></li><li><strong>ğŸ– åŸä½œè€…ï¼š<a href="https://mtyjkh.blog.csdn.net/" rel="nofollow" title="KåŒå­¦å•Š|æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶">KåŒå­¦å•Š|æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶</a></strong></li></ul> 
<p>Â <strong>æˆ‘çš„ç¯å¢ƒ</strong></p> 
<blockquote> 
 <ul><li>è¯­è¨€ç¯å¢ƒï¼šPython3.6</li><li>ç¼–è¯‘å™¨ï¼šjupyter lab</li><li>æ·±åº¦å­¦ä¹ ç¯å¢ƒï¼špytorch1.10</li><li>å‚è€ƒæ–‡ç« ï¼šæœ¬äººåšå®¢<a href="https://blog.csdn.net/m0_60524373/category_11829318.html?spm=1001.2014.3001.5482" title="(60æ¡æ¶ˆæ¯) æœºå™¨å­¦ä¹ ä¹‹â€”â€”tensorflow+pytorch_é‡é‚®ç ”ç©¶æ£®çš„åšå®¢-CSDNåšå®¢">(60æ¡æ¶ˆæ¯) æœºå™¨å­¦ä¹ ä¹‹â€”â€”tensorflow+pytorch_é‡é‚®ç ”ç©¶æ£®çš„åšå®¢-CSDNåšå®¢</a></li></ul> 
</blockquote> 
<p id="u99981e30">ğŸºè¦æ±‚ï¼š</p> 
<ol><li id="u7f300174">æœ¬åœ°è¯»å–å¹¶åŠ è½½æ•°æ®ã€‚ï¼ˆâœ”ï¼‰</li></ol> 
<ol><li id="ue4737e4b">æµ‹è¯•é›†accuracyåˆ°è¾¾93%ï¼ˆâœ”ï¼‰</li></ol> 
<p id="u1c4c1bb9">ğŸ»æ‹”é«˜ï¼š</p> 
<ol><li id="ud6bb751d">æµ‹è¯•é›†accuracyåˆ°è¾¾95%ï¼ˆâœ”ï¼‰</li><li id="u8f0519c3">è°ƒç”¨æ¨¡å‹è¯†åˆ«ä¸€å¼ æœ¬åœ°å›¾ç‰‡ï¼ˆâœ”ï¼‰</li></ol> 
<p>Â </p> 
<hr> 
<p id="main-toc"><strong>ç›®å½•</strong></p> 
<p id="%E4%B8%80%20%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C-toc" style="margin-left:40px;"><a href="#%E4%B8%80%20%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C" rel="nofollow">ä¸€ å‰æœŸå·¥ä½œ</a></p> 
<p id="1.%E8%AE%BE%E7%BD%AEGPU%E6%88%96%E8%80%85cpu-toc" style="margin-left:80px;"><a href="#1.%E8%AE%BE%E7%BD%AEGPU%E6%88%96%E8%80%85cpu" rel="nofollow">1.è®¾ç½®GPUæˆ–è€…cpu</a></p> 
<p id="%C2%A02.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE-toc" style="margin-left:80px;"><a href="#%C2%A02.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE" rel="nofollow">2.å¯¼å…¥æ•°æ®</a></p> 
<p id="%E4%BA%8C%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86" rel="nofollow">äºŒ æ•°æ®é¢„å¤„ç†</a></p> 
<p id="%C2%A0%E4%B8%89%20%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px;"><a href="#%C2%A0%E4%B8%89%20%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C" rel="nofollow">ä¸‰ æ­å»ºç½‘ç»œ</a></p> 
<p id="%E5%9B%9B%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px;"><a href="#%E5%9B%9B%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B" rel="nofollow">å›› è®­ç»ƒæ¨¡å‹</a></p> 
<p id="1.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87-toc" style="margin-left:80px;"><a href="#1.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87" rel="nofollow">1.è®¾ç½®å­¦ä¹ ç‡</a></p> 
<p id="3.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-toc" style="margin-left:80px;"><a href="#3.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" rel="nofollow">2.æ¨¡å‹è®­ç»ƒ</a></p> 
<p id="%C2%A0%E4%BA%94%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0-toc" style="margin-left:40px;"><a href="#%C2%A0%E4%BA%94%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0" rel="nofollow">äº” æ¨¡å‹è¯„ä¼°</a></p> 
<p id="1.Loss%E5%92%8CAccuracy%E5%9B%BE-toc" style="margin-left:80px;"><a href="#1.Loss%E5%92%8CAccuracy%E5%9B%BE" rel="nofollow">1.Losså’ŒAccuracyå›¾</a></p> 
<p id="2.%E5%AF%B9%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B-toc" style="margin-left:80px;"><a href="#2.%E5%AF%B9%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B" rel="nofollow">2.å¯¹ç»“æœè¿›è¡Œé¢„æµ‹</a></p> 
<p id="3.%E6%80%BB%E7%BB%93-toc" style="margin-left:80px;"><a href="#3.%E6%80%BB%E7%BB%93" rel="nofollow">3.æ€»ç»“</a></p> 
<p></p> 
<hr> 
<h3 id="%E4%B8%80%20%E5%89%8D%E6%9C%9F%E5%B7%A5%E4%BD%9C">ä¸€ å‰æœŸå·¥ä½œ</h3> 
<p>ç¯å¢ƒï¼špython3.6ï¼Œ1080tiï¼Œpytorch1.10ï¼ˆå®éªŒå®¤æœåŠ¡å™¨çš„ç¯å¢ƒğŸ˜‚ğŸ˜‚ï¼‰</p> 
<h4 id="1.%E8%AE%BE%E7%BD%AEGPU%E6%88%96%E8%80%85cpu"><a name="t1"></a>1.è®¾ç½®GPUæˆ–è€…cpu</h4> 
<pre><code class="language-python">import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import torchvision
 
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
 
device</code></pre> 
<h4 id="%C2%A02.%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE">2.å¯¼å…¥æ•°æ®</h4> 
<pre><code class="language-python">import os,PIL,random,pathlib

data_dir = 'weather_photos/'
data_dir = pathlib.Path(data_dir)
print(data_dir)

data_paths = list(data_dir.glob('*'))
print(data_paths)
classeNames = [str(path).split("/")[1] for path in data_paths]
classeNames</code></pre> 
<h3 id="%E4%BA%8C%20%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86">äºŒ æ•°æ®é¢„å¤„ç†</h3> 
<p>æ•°æ®æ ¼å¼è®¾ç½®</p> 
<pre><code class="language-python">total_datadir = 'weather_photos/'

# å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863
train_transforms = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])

total_data = datasets.ImageFolder(total_datadir,transform=train_transforms)
total_data</code></pre> 
<p>æ•°æ®é›†åˆ’åˆ†</p> 
<pre><code class="language-python">train_size = int(0.8 * len(total_data))
test_size  = len(total_data) - train_size
train_dataset, test_dataset = torch.utils.data.random_split(total_data, [train_size, test_size])
train_dataset, test_dataset</code></pre> 
<p>è®¾ç½®dataset</p> 
<pre><code class="language-python">batch_size = 32

train_dl = torch.utils.data.DataLoader(train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True,
                                           num_workers=1)
test_dl = torch.utils.data.DataLoader(test_dataset,
                                          batch_size=batch_size,
                                          shuffle=True,
                                          num_workers=1)</code></pre> 
<p>æ£€æŸ¥æ•°æ®æ ¼å¼Â </p> 
<pre><code class="language-python">for X, y in test_dl:
    print("Shape of X [N, C, H, W]: ", X.shape)
    print("Shape of y: ", y.shape, y.dtype)
    break</code></pre> 
<p>Â <img alt="" height="61" src="https://images2.imgbox.com/d6/b9/Nkze3cwV_o.png" width="658">Â </p> 
<h3 id="%C2%A0%E4%B8%89%20%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C">ä¸‰ æ­å»ºç½‘ç»œ</h3> 
<pre><code class="language-python">
import torch
from torch import nn
from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential,ReLU

num_classes = 4

class Model(nn.Module):
    def __init__(self):
        super(Model,self).__init__()
        # å·ç§¯å±‚
        self.layers = Sequential(
            # ç¬¬ä¸€å±‚
            nn.Conv2d(3, 24, kernel_size=5),
            nn.BatchNorm2d(24),
            nn.ReLU(),
            # ç¬¬äºŒå±‚
            nn.Conv2d(24,64 , kernel_size=5),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2,2),
            nn.Conv2d(64, 128, kernel_size=5),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(128, 24, kernel_size=5),
            nn.BatchNorm2d(24),
            nn.ReLU(),
            nn.MaxPool2d(2,2),
            nn.Flatten(),
            nn.Linear(24*50*50, 516,bias=True),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(516, 215,bias=True),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(215, num_classes,bias=True),
        )

    def forward(self, x):

        x = self.layers(x)
        return x    


device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using {} device".format(device))

model = Model().to(device)
model</code></pre> 
<p>æ‰“å°ç½‘ç»œç»“æ„</p> 
<p>Â <img alt="" height="580" src="https://images2.imgbox.com/40/fc/wv5BK2Sq_o.png" width="712">Â </p> 
<h3 id="%E5%9B%9B%20%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">å›› è®­ç»ƒæ¨¡å‹</h3> 
<h4 id="1.%E8%AE%BE%E7%BD%AE%E5%8A%A8%E6%80%81%E5%AD%A6%E4%B9%A0%E7%8E%87"><a name="t9"></a>1.è®¾ç½®å­¦ä¹ ç‡</h4> 
<pre><code class="language-python">loss_fn    = nn.CrossEntropyLoss() # åˆ›å»ºæŸå¤±å‡½æ•°
learn_rate = 1e-3 # å­¦ä¹ ç‡
opt        = torch.optim.SGD(model.parameters(),lr=learn_rate)</code></pre> 
<h4 id="3.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">2.æ¨¡å‹è®­ç»ƒ</h4> 
<p>è®­ç»ƒå‡½æ•°</p> 
<pre><code class="language-python"># è®­ç»ƒå¾ªç¯
def train(dataloader, model, loss_fn, optimizer):
    size = len(dataloader.dataset)  # è®­ç»ƒé›†çš„å¤§å°ï¼Œä¸€å…±60000å¼ å›¾ç‰‡
    num_batches = len(dataloader)   # æ‰¹æ¬¡æ•°ç›®ï¼Œ1875ï¼ˆ60000/32ï¼‰
 
    train_loss, train_acc = 0, 0  # åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡
    
    for X, y in dataloader:  # è·å–å›¾ç‰‡åŠå…¶æ ‡ç­¾
        X, y = X.to(device), y.to(device)
        
        # è®¡ç®—é¢„æµ‹è¯¯å·®
        pred = model(X)          # ç½‘ç»œè¾“å‡º
        loss = loss_fn(pred, y)  # è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()  # gradå±æ€§å½’é›¶
        loss.backward()        # åå‘ä¼ æ’­
        optimizer.step()       # æ¯ä¸€æ­¥è‡ªåŠ¨æ›´æ–°
        
        # è®°å½•accä¸loss
        train_acc  += (pred.argmax(1) == y).type(torch.float).sum().item()
        train_loss += loss.item()
            
    train_acc  /= size
    train_loss /= num_batches
 
    return train_acc, train_loss</code></pre> 
<p>æµ‹è¯•å‡½æ•°Â </p> 
<pre><code class="language-python">def test (dataloader, model, loss_fn):
    size        = len(dataloader.dataset)  # æµ‹è¯•é›†çš„å¤§å°ï¼Œä¸€å…±10000å¼ å›¾ç‰‡
    num_batches = len(dataloader)          # æ‰¹æ¬¡æ•°ç›®ï¼Œ313ï¼ˆ10000/32=312.5ï¼Œå‘ä¸Šå–æ•´ï¼‰
    test_loss, test_acc = 0, 0
    
    # å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—
    with torch.no_grad():
        for imgs, target in dataloader:
            imgs, target = imgs.to(device), target.to(device)
            
            # è®¡ç®—loss
            target_pred = model(imgs)
            loss        = loss_fn(target_pred, target)
            
            test_loss += loss.item()
            test_acc  += (target_pred.argmax(1) == target).type(torch.float).sum().item()
 
    test_acc  /= size
    test_loss /= num_batches
 
    return test_acc, test_loss</code></pre> 
<p>å…·ä½“è®­ç»ƒä»£ç Â </p> 
<pre><code class="language-python">epochs     = 30
train_loss = []
train_acc  = []
test_loss  = []
test_acc   = []

for epoch in range(epochs):
    model.train()
    epoch_train_acc, epoch_train_loss = train(train_dl, model, loss_fn, opt)
    
    model.eval()
    epoch_test_acc, epoch_test_loss = test(test_dl, model, loss_fn)
    
    train_acc.append(epoch_train_acc)
    train_loss.append(epoch_train_loss)
    test_acc.append(epoch_test_acc)
    test_loss.append(epoch_test_loss)
    
    template = ('Epoch:{:2d}, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%ï¼ŒTest_loss:{:.3f}')
    print(template.format(epoch+1, epoch_train_acc*100, epoch_train_loss, epoch_test_acc*100, epoch_test_loss))
print('Done')</code></pre> 
<p>Â <img alt="" height="582" src="https://images2.imgbox.com/fb/43/6MnhF5ED_o.png" width="1016">Â </p> 
<h3 id="%C2%A0%E4%BA%94%20%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0">äº” æ¨¡å‹è¯„ä¼°</h3> 
<h4 id="1.Loss%E5%92%8CAccuracy%E5%9B%BE"><a name="t12"></a>1.Losså’ŒAccuracyå›¾</h4> 
<pre><code class="language-python">import matplotlib.pyplot as plt
#éšè—è­¦å‘Š
import warnings
warnings.filterwarnings("ignore")               #å¿½ç•¥è­¦å‘Šä¿¡æ¯
plt.rcParams['font.sans-serif']    = ['SimHei'] # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['axes.unicode_minus'] = False      # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
plt.rcParams['figure.dpi']         = 100        #åˆ†è¾¨ç‡

epochs_range = range(epochs)

plt.figure(figsize=(12, 3))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, train_acc, label='Training Accuracy')
plt.plot(epochs_range, test_acc, label='Test Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, train_loss, label='Training Loss')
plt.plot(epochs_range, test_loss, label='Test Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()</code></pre> 
<p>Â <img alt="" height="330" src="https://images2.imgbox.com/a2/fd/nMMDTxkC_o.png" width="1200">Â </p> 
<h4 id="2.%E5%AF%B9%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B">2.å¯¹ç»“æœè¿›è¡Œé¢„æµ‹</h4> 
<pre><code class="language-python">import os
import json

import torch
from PIL import Image
from torchvision import transforms
import matplotlib.pyplot as plt

img_path = "weather_photos/cloudy/cloudy1.jpg"
classes = ['cloudy', 'rain', 'shine', 'sunrise']
data_transform = transforms.Compose([
    transforms.Resize([224, 224]),  # å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸
    transforms.ToTensor(),          # å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´
    transforms.Normalize(           # æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›
        mean=[0.485, 0.456, 0.406], 
        std=[0.229, 0.224, 0.225])  # å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚
])
def main():
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    
    img = Image.open(img_path)
    plt.imshow(img)
    # [N, C, H, W]
    img = data_transform(img)
    # expand batch dimension
    img = torch.unsqueeze(img, dim=0)
    model.eval()
    with torch.no_grad():
        # predict class
        output = torch.squeeze(model(img.to(device))).cpu()
        predict = torch.softmax(output, dim=0)
        predict_cla = torch.argmax(predict).numpy()
        print(classes[predict_cla])
    plt.show()
    
if __name__ == '__main__':
    main()
</code></pre> 
<p>é¢„æµ‹ç»“æœå¦‚ä¸‹ï¼š</p> 
<p>Â <img alt="" height="410" src="https://images2.imgbox.com/7c/b8/ZGFYEwFg_o.png" width="759">Â </p> 
<h4 id="3.%E6%80%BB%E7%BB%93">3.æ€»ç»“</h4> 
<p>Â 1.æœ¬æ¬¡èƒ½ä¸»è¦å¯¹ä»¥ä¸‹å‡½æ•°è¿›è¡Œäº†å­¦ä¹ </p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>transforms.Compose</td><td>é’ˆå¯¹æ•°æ®è½¬æ¢ï¼Œä¾‹å¦‚å°ºå¯¸ï¼Œç±»å‹</td></tr><tr><td>datasets.ImageFolder</td><td>ç»“åˆä¸Šé¢è¿™ä¸ªå¯¹æŸæ–‡ä»¶å¤¹ä¸‹æ•°æ®å¤„ç†</td></tr><tr><td>torch.utils.data.DataLoader</td><td>è®¾ç½®dataset</td></tr></tbody></table> 
<p>è¯¦æƒ…æ–‡ç« å‚è€ƒå¦‚ä¸‹ï¼š</p> 
<p><a href="https://blog.csdn.net/qq_38251616/article/details/124878863" title="torchvision.transforms.Compose()è¯¦è§£ã€Pytorchå…¥é—¨æ‰‹å†Œã€‘_KåŒå­¦å•Šçš„åšå®¢-CSDNåšå®¢_torchvision.transforms.compose">torchvision.transforms.Compose()è¯¦è§£ã€Pytorchå…¥é—¨æ‰‹å†Œã€‘_KåŒå­¦å•Šçš„åšå®¢-CSDNåšå®¢_torchvision.transforms.compose</a></p> 
<p>Â <a href="https://blog.csdn.net/qq_33254870/article/details/103362621" title="(10æ¡æ¶ˆæ¯) torchvision.datasets.ImageFolder_å¹³å‡¡çš„ä¹…æœˆçš„åšå®¢-CSDNåšå®¢_datasets.imagefolder">(10æ¡æ¶ˆæ¯) torchvision.datasets.ImageFolder_å¹³å‡¡çš„ä¹…æœˆçš„åšå®¢-CSDNåšå®¢_datasets.imagefolder</a></p> 
<p>2.å¯¹äºpytorchä¸‹é¢è¿›è¡Œé¢„æµ‹æ„Ÿè§‰è¿˜æ·»éº»çƒ¦çš„ï¼Œï¼Œï¼Œï¼Œï¼Œä¸Šæ–‡é¢„æµ‹ä»£ç è¿˜æ˜¯ç½‘ä¸Šæœçš„ã€‚Â </p> 
<p>3.å‡†ç¡®ç‡æé«˜åˆ°äº†97</p> 
<p>Â </p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/76132dbe7bf43d922e053653650be0ef/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">CentOS8é…ç½®æœ¬åœ°yumæº</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/db00d4c2b43e89dd706f19bd6eadc79a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">PythonæŠ¥é”™UnicodeDecodeError: â€˜gbkâ€˜ codec canâ€˜t decode byte</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 èœé¸Ÿç¨‹åºå‘˜åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>