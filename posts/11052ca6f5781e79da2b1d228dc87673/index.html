<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>理解对比表示学习(Contrastive Learning) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="理解对比表示学习(Contrastive Learning)" />
<meta property="og:description" content="目录 一、前言二、对比学习三、主要论文（附代码分析）1. AMDIM ([Bachman](https://arxiv.org/pdf/1906.00910.pdf) *et al.* 2019)2. SIMCLR ([Geoffrey Hinton](https://arxiv.org/pdf/2002.05709.pdf) *et al* 2020)3.MOCO ([Kaiming He](https://ieeexplore.ieee.org/document/9157636) *et al.* 2020) 四、总结 一、前言 监督学习近些年获得了巨大的成功，但是有如下的缺点：
人工标签相对数据来说本身是稀疏的，蕴含的信息不如数据内容丰富；监督学习只能学到特定任务的知识，不是通用知识，一般难以直接迁移到其他任务中。 由于这些原因，自监督学习的发展被给予厚望。监督学习，无监督学习和自监督学习的区别
如果说自监督学习是蛋糕，那么监督学习就是蛋糕上的小冰块，强化学习就是蛋糕上点缀的樱桃。(“self-supervised learning is the cake, supervised learning is the icing on the cake, reinforcement learning is the cherry on the cake”) —Yann LeCun
自监督学习不需要人工标注的类别标签信息，直接利用数据本身作为监督信息，学习样本数据的特征表达，应用于下游的任务。自监督学习又可以分为对比学习(contrastive learning) 和 生成学习(generative learning) 两条主要的技术路线。对比学习的核心思想是讲正样本和负样本在特征空间对比，学习样本的特征表示，难点在于如何构造正负样本。
最近，诸如BERT和T5之类的自然语言处理模型已经表明，可以通过首先在一个大型的未标记数据集上进行预训练，然后在一个较小的标记数据集上进行微调，从而用很少的类标签来获得良好的结果。 同样，对未标记的大型图像数据集进行预训练，有可能提高计算机视觉任务的性能。这点已经在对比表示学习的相关论文，例如Exemplar-CNN, Instance Discrimination, CPC, AMDIM, CMC, MoCo，获得了证实。对比学习训练得到的神经网络模型，可以被用作下游的任务，例如分类、分割、检测等。经过对比学习预训练得到的神经网络，已经具有很强的表达能力，一般只需要再用很少的有标签数据微调，就可以获得非常优秀的性能。
以下图片引用
二、对比学习 对比学习首先学习未标记数据集上图像的通用表示形式，然后可以使用少量标记图像对其进行微调，以提升在给定任务(例如分类)的性能。简单地说，对比表示学习可以被认为是通过比较学习。相对来说，生成学习(generative learning)是学习某些（伪）标签的映射的判别模型然后重构输入样本。在对比学习中，通过在输入样本之间进行比较来学习表示。对比学习不是一次从单个数据样本中学习信号，而是通过在不同样本之间进行比较来学习。可以在“相似”输入的正对和“不同”输入的负对之间进行比较。以下图片引用。
对比学习原理 对比学习通过同时最大化同一图像的不同变换视图(例如剪裁，翻转，颜色变换等)之间的一致性，以及最小化不同图像的变换视图之间的一致性来学习的。 简单来说，就是对比学习要做到相同的图像经过各类变换之后，依然能识别出是同一张图像，所以要最大化各类变换后图像的相似度（因为都是同一个图像得到的）。相反，如果是不同的图像（即使经过各种变换可能看起来会很类似），就要最小化它们之间的相似度。通过这样的对比训练，编码器(encoder)能学习到图像的更高层次的通用特征 (image-level representations)，而不是图像级别的生成模型(pixel-level generation)。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/11052ca6f5781e79da2b1d228dc87673/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-12T12:31:55+08:00" />
<meta property="article:modified_time" content="2020-12-12T12:31:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">理解对比表示学习(Contrastive Learning)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_4" rel="nofollow">一、前言</a></li><li><a href="#_24" rel="nofollow">二、对比学习</a></li><li><a href="#_39" rel="nofollow">三、主要论文（附代码分析）</a></li><li><ul><li><a href="#1_AMDIM_Bachmanhttpsarxivorgpdf190600910pdf_et_al_2019_42" rel="nofollow">1. AMDIM ([Bachman](https://arxiv.org/pdf/1906.00910.pdf) *et al.* 2019)</a></li><li><a href="#2_SIMCLR_Geoffrey_Hintonhttpsarxivorgpdf200205709pdf_et_al_2020_171" rel="nofollow">2. SIMCLR ([Geoffrey Hinton](https://arxiv.org/pdf/2002.05709.pdf) *et al* 2020)</a></li><li><a href="#3MOCO_Kaiming_Hehttpsieeexploreieeeorgdocument9157636_et_al_2020_277" rel="nofollow">3.MOCO ([Kaiming He](https://ieeexplore.ieee.org/document/9157636) *et al.* 2020)</a></li></ul> 
  </li><li><a href="#_334" rel="nofollow">四、总结</a></li></ul> 
</div> 
<p></p> 
<hr color="#000000" size='1"'> 
<h2><a id="_4"></a>一、前言</h2> 
<p>监督学习近些年获得了巨大的成功，但是有如下的缺点：</p> 
<ol><li>人工标签相对数据来说本身是稀疏的，蕴含的信息不如数据内容丰富；</li><li>监督学习只能学到特定任务的知识，不是通用知识，一般难以直接迁移到其他任务中。</li></ol> 
<p>由于这些原因，自监督学习的发展被给予厚望。监督学习，无监督学习和自监督学习的区别</p> 
<blockquote> 
 <p>如果说自监督学习是蛋糕，那么监督学习就是蛋糕上的小冰块，强化学习就是蛋糕上点缀的樱桃。(“self-supervised learning is the cake, supervised learning is the icing on the cake, reinforcement learning is the cherry on the cake”) —Yann LeCun</p> 
</blockquote> 
<p><strong>自监督学习</strong>不需要人工标注的类别标签信息，直接利用数据本身作为监督信息，学习样本数据的<strong>特征表达</strong>，应用于下游的任务。自监督学习又可以分为<strong>对比学习(contrastive learning)</strong> 和 <strong>生成学习(generative learning)</strong> 两条主要的技术路线。对比学习的核心思想是讲正样本和负样本在特征空间对比，学习样本的特征表示，难点在于如何构造正负样本。</p> 
<p>最近，诸如BERT和T5之类的自然语言处理模型已经表明，可以通过首先在一个大型的未标记数据集上进行预训练，然后在一个较小的标记数据集上进行微调，从而用很少的类标签来获得良好的结果。 同样，对未标记的大型图像数据集进行预训练，有可能提高计算机视觉任务的性能。这点已经在对比表示学习的相关论文，例如Exemplar-CNN, Instance Discrimination, CPC, AMDIM, CMC, MoCo，获得了证实。对比学习训练得到的神经网络模型，可以被用作下游的任务，例如分类、分割、检测等。经过对比学习预训练得到的神经网络，已经具有很强的表达能力，一般只需要再用很少的有标签数据微调，就可以获得非常优秀的性能。</p> 
<p>以下图片<a href="https://arxiv.org/pdf/2006.08218.pdf" rel="nofollow">引用</a><br> <img src="https://images2.imgbox.com/51/f2/mIJxjc3G_o.png" alt="监督学习，无监督学习和自监督学习的区别。" height="300"></p> 
<hr color="#000000" size='1"'> 
<h2><a id="_24"></a>二、对比学习</h2> 
<p>对比学习首先学习未标记数据集上图像的通用表示形式，然后可以使用少量标记图像对其进行微调，以提升在给定任务(例如分类)的性能。简单地说，对比表示学习可以被认为是通过<strong>比较</strong>学习。相对来说，生成学习(generative learning)是学习某些（伪）标签的映射的判别模型然后重构输入样本。在对比学习中，通过在输入样本之间进行比较来学习表示。对比学习不是一次从单个数据样本中学习信号，而是通过在不同样本之间进行比较来学习。可以在“相似”输入的正对和“不同”输入的负对之间进行比较。以下图片<a href="https://towardsdatascience.com/a-framework-for-contrastive-self-supervised-learning-and-designing-a-new-approach-3caab5d29619" rel="nofollow">引用</a>。</p> 
<p><img src="https://images2.imgbox.com/e0/1f/Xow3eK2z_o.gif" alt="对比学习" height="300"></p> 
<center>
  对比学习原理 
</center> 
<p>对比学习通过同时最大化同一图像的不同变换视图(例如剪裁，翻转，颜色变换等)之间的一致性，以及最小化不同图像的变换视图之间的一致性来学习的。 简单来说，就是对比学习要做到相同的图像经过各类变换之后，依然能识别出是同一张图像，所以要最大化各类变换后图像的相似度（因为都是同一个图像得到的）。相反，如果是不同的图像（即使经过各种变换可能看起来会很类似），就要最小化它们之间的相似度。通过这样的<strong>对比训练</strong>，编码器(encoder)能学习到图像的更高层次的通用特征 (image-level representations)，而不是图像级别的生成模型(pixel-level generation)。</p> 
<blockquote> 
 <p>Pixel-level generation is computationally expensive and may not be necessary for representation learning. —SimCLR论文</p> 
</blockquote> 
<hr color="#000000" size='1"'> 
<h2><a id="_39"></a>三、主要论文（附代码分析）</h2> 
<h3><a id="1_AMDIM_Bachmanhttpsarxivorgpdf190600910pdf_et_al_2019_42"></a>1. AMDIM (<a href="https://arxiv.org/pdf/1906.00910.pdf" rel="nofollow">Bachman</a> <em>et al.</em> 2019)</h3> 
<p>本文的基本想法是最大化同一个图像不同视角之间的互信息 (mutual information)，也就是题目所说的“通过最大化不同视角之间的互信息进行表示学习” (Learning Representations by Maximizing Mutual Information Across Views)。这个想法和人类观察世界的的方式有类似之处，例如，我们观察<strong>同一个物体</strong>的时候，通常可以通过从不同的位置（例如，场景中的摄像机位置）以及通过不同的方式（例如，触觉，听觉或视觉）进行观察，可以产生局部时空视图。这样不同视角的观察图像，可以用数据增强 (data augmentation) 的方式生成。最大化从这些视图提取的特征之间的互信息，要求捕捉到更高层次的图像因素，例如某些物体或者事件是否出现或者发生。</p> 
<p>下图(b)就是本文的Augmented Multiscale Deep InfoMax (AMDIM)结构。<br> <img src="https://images2.imgbox.com/1c/a8/K3sVFVXR_o.jpg" alt="AMDIM"><br> <font color="#999AAA">Encoder部分的核心代码如下:</font></p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dummy_batch<span class="token punctuation">,</span> num_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> ndf<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> n_rkhs<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> 
                n_depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> encoder_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> use_bn<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Encoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ndf <span class="token operator">=</span> ndf
        self<span class="token punctuation">.</span>n_rkhs <span class="token operator">=</span> n_rkhs
        self<span class="token punctuation">.</span>use_bn <span class="token operator">=</span> use_bn
        self<span class="token punctuation">.</span>dim2layer <span class="token operator">=</span> <span class="token boolean">None</span>

        <span class="token comment"># encoding block for local features</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Using a {}x{} encoder'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>encoder_size<span class="token punctuation">,</span> encoder_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> encoder_size <span class="token operator">==</span> <span class="token number">32</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>layer_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
                Conv3x3<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> ndf<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResNxN<span class="token punctuation">(</span>ndf<span class="token punctuation">,</span> ndf<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">1</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                MaybeBatchNorm2d<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResNxN<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                MaybeBatchNorm2d<span class="token punctuation">(</span>n_rkhs<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> encoder_size <span class="token operator">==</span> <span class="token number">64</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>layer_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
                Conv3x3<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> ndf<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">1</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                MaybeBatchNorm2d<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResNxN<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                MaybeBatchNorm2d<span class="token punctuation">(</span>n_rkhs<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> encoder_size <span class="token operator">==</span> <span class="token number">128</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>layer_list <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
                Conv3x3<span class="token punctuation">(</span>num_channels<span class="token punctuation">,</span> ndf<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> pad_mode<span class="token operator">=</span><span class="token string">'reflect'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                Conv3x3<span class="token punctuation">(</span>ndf<span class="token punctuation">,</span> ndf<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">1</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                MaybeBatchNorm2d<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResBlock<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> n_depth<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                ConvResNxN<span class="token punctuation">(</span>ndf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">,</span>
                MaybeBatchNorm2d<span class="token punctuation">(</span>n_rkhs<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
            <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> RuntimeError<span class="token punctuation">(</span><span class="token string">"Could not build encoder."</span>
                               <span class="token string">"Encoder size {} is not supported"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>encoder_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>_config_modules<span class="token punctuation">(</span>dummy_batch<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">init_weights</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> init_scale<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        Run custom weight init for modules...
        '''</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>layer_list<span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> <span class="token punctuation">(</span>ConvResNxN<span class="token punctuation">,</span> ConvResBlock<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                layer<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span>init_scale<span class="token punctuation">)</span>
        <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> <span class="token punctuation">(</span>ConvResNxN<span class="token punctuation">,</span> ConvResBlock<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                layer<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span>init_scale<span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>layer<span class="token punctuation">,</span> FakeRKHSConvNet<span class="token punctuation">)</span><span class="token punctuation">:</span>
                layer<span class="token punctuation">.</span>init_weights<span class="token punctuation">(</span>init_scale<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_config_modules</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> rkhs_layers<span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        Configure the modules for extracting fake rkhs embeddings for infomax.
        '''</span>
        enc_acts <span class="token operator">=</span> self<span class="token punctuation">.</span>_forward_acts<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dim2layer <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> h_i <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>enc_acts<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> d <span class="token keyword">in</span> rkhs_layers<span class="token punctuation">:</span>
                <span class="token keyword">if</span> h_i<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">==</span> d<span class="token punctuation">:</span>
                    self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span>d<span class="token punctuation">]</span> <span class="token operator">=</span> i
        <span class="token comment"># get activations and feature sizes at different layers</span>
        self<span class="token punctuation">.</span>ndf_1 <span class="token operator">=</span> enc_acts<span class="token punctuation">[</span>self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ndf_5 <span class="token operator">=</span> enc_acts<span class="token punctuation">[</span>self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ndf_7 <span class="token operator">=</span> enc_acts<span class="token punctuation">[</span>self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># configure modules for fake rkhs embeddings</span>
        self<span class="token punctuation">.</span>rkhs_block_1 <span class="token operator">=</span> NopNet<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rkhs_block_5 <span class="token operator">=</span> FakeRKHSConvNet<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ndf_5<span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rkhs_block_7 <span class="token operator">=</span> FakeRKHSConvNet<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ndf_7<span class="token punctuation">,</span> n_rkhs<span class="token punctuation">,</span> use_bn<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_forward_acts</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        Return activations from all layers.
        '''</span>
        <span class="token comment"># run forward pass through all layers</span>
        layer_acts <span class="token operator">=</span> <span class="token punctuation">[</span>x<span class="token punctuation">]</span>
        <span class="token keyword">for</span> _<span class="token punctuation">,</span> layer <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>layer_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layer_in <span class="token operator">=</span> layer_acts<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            layer_out <span class="token operator">=</span> layer<span class="token punctuation">(</span>layer_in<span class="token punctuation">)</span>
            layer_acts<span class="token punctuation">.</span>append<span class="token punctuation">(</span>layer_out<span class="token punctuation">)</span>
        <span class="token comment"># remove input from the returned list of activations</span>
        return_acts <span class="token operator">=</span> layer_acts<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token keyword">return</span> return_acts

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">'''
        Compute activations and Fake RKHS embeddings for the batch.
        '''</span>
        <span class="token keyword">if</span> has_many_gpus<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> x<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1e</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">:</span>
                r1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rkhs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
                r5 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rkhs<span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
                r7 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>n_rkhs<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 device<span class="token operator">=</span>x<span class="token punctuation">.</span>device<span class="token punctuation">,</span> dtype<span class="token operator">=</span>x<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
                <span class="token keyword">return</span> r1<span class="token punctuation">,</span> r5<span class="token punctuation">,</span> r7
        <span class="token comment"># compute activations in all layers for x</span>
        acts <span class="token operator">=</span> self<span class="token punctuation">.</span>_forward_acts<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># gather rkhs embeddings from certain layers</span>
        r1 <span class="token operator">=</span> self<span class="token punctuation">.</span>rkhs_block_1<span class="token punctuation">(</span>acts<span class="token punctuation">[</span>self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        r5 <span class="token operator">=</span> self<span class="token punctuation">.</span>rkhs_block_5<span class="token punctuation">(</span>acts<span class="token punctuation">[</span>self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        r7 <span class="token operator">=</span> self<span class="token punctuation">.</span>rkhs_block_7<span class="token punctuation">(</span>acts<span class="token punctuation">[</span>self<span class="token punctuation">.</span>dim2layer<span class="token punctuation">[</span><span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> r1<span class="token punctuation">,</span> r5<span class="token punctuation">,</span> r7
</code></pre> 
<h3><a id="2_SIMCLR_Geoffrey_Hintonhttpsarxivorgpdf200205709pdf_et_al_2020_171"></a>2. SIMCLR (<a href="https://arxiv.org/pdf/2002.05709.pdf" rel="nofollow">Geoffrey Hinton</a> <em>et al</em> 2020)</h3> 
<p>SIMCLR提出了一种构建负样本的方式，基本思想是：输入一幅图像，对其进行随机变换(Data Augmentation)得到两幅图像<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
        
       
      
        x_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          j 
         
        
       
      
        x_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，分别通过编码器得到相应的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          j 
         
        
       
      
        h_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，然后，采用非线性全连接层以获得表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          i 
         
        
       
      
        z_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          j 
         
        
       
      
        z_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。学习的任务就是对于同一张图片，最大化这两种表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          i 
         
        
       
      
        z_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          j 
         
        
       
      
        z_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>之间的相似性。网络学习完成之后，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>, <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          j 
         
        
       
      
        h_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>就可以作为图像的一种特征表示，用作下游的学习任务(Downstream tasks)。<br> <img src="https://images2.imgbox.com/0c/2a/kIaFOMcR_o.png" alt="SimCLR"><br> <strong>第一步</strong>，数据增强，包括 random cropping(剪裁)， random color distortions (颜色变换), and random Gaussian blur (高斯模糊)等。虽然可以采用更为复杂的数据增强方式，例如<a href="https://arxiv.org/pdf/1805.09501.pdf" rel="nofollow">AutoAugment</a>，但是作者认为，这些简单的变换已经足以让神经网络学习到足够丰富的表达。</p> 
<p><img src="https://images2.imgbox.com/0d/ea/wpyIeVD7_o.png" alt="DataAugment"></p> 
<p><font color="#999AAA">核心代码如下:</font></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms

train_transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>RandomApply<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span><span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.4</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>RandomGrayscale<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.4914</span><span class="token punctuation">,</span> <span class="token number">0.4822</span><span class="token punctuation">,</span> <span class="token number">0.4465</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.2023</span><span class="token punctuation">,</span> <span class="token number">0.1994</span><span class="token punctuation">,</span> <span class="token number">0.2010</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>第二步</strong>，由基编码器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         f 
        
       
         ( 
        
       
         ⋅ 
        
       
         ) 
        
       
      
        f(\cdot) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>得到表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          j 
         
        
       
      
        h_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。文章中作者使用ResNet-50作为卷积神经网络编码器。输出向量<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的维度是2048.</p> 
<p><strong>第三步</strong>，投影端(projection head) <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         g 
        
       
         ( 
        
       
         ⋅ 
        
       
         ) 
        
       
      
        g(\cdot) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>，主要由全连接层和激活层ReLU组成，将表示<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          j 
         
        
       
      
        h_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>进一步非线性映射为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          i 
         
        
       
      
        z_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          j 
         
        
       
      
        z_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。作者说，非线性投影端很重要，一方面可以将映射后的表达<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          z 
         
        
          i 
         
        
       
      
        z_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.04398em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>用来计算相似度，另一方面，可以让投影端之前的表达<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          h 
         
        
          i 
         
        
       
      
        h_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>保留更多图像信息。</p> 
<p><font color="#999AAA">核心代码如下，包含基编码器<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          f 
         
        
          ( 
         
        
          ⋅ 
         
        
          ) 
         
        
       
         f(\cdot) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>和投影端<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          g 
         
        
          ( 
         
        
          ⋅ 
         
        
          ) 
         
        
       
         g(\cdot) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>：</font></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet <span class="token keyword">import</span> resnet50

<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feature_dim<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Model<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>f <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> name<span class="token punctuation">,</span> module <span class="token keyword">in</span> resnet50<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>named_children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> name <span class="token operator">==</span> <span class="token string">'conv1'</span><span class="token punctuation">:</span>
                module <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span> <span class="token operator">and</span> <span class="token operator">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>module<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>f<span class="token punctuation">.</span>append<span class="token punctuation">(</span>module<span class="token punctuation">)</span>
        <span class="token comment"># encoder</span>
        self<span class="token punctuation">.</span>f <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>self<span class="token punctuation">.</span>f<span class="token punctuation">)</span>
        <span class="token comment"># projection head</span>
        self<span class="token punctuation">.</span>g <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm1d<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> feature_dim<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>f<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        feature <span class="token operator">=</span> torch<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>x<span class="token punctuation">,</span> start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>g<span class="token punctuation">(</span>feature<span class="token punctuation">)</span>
        <span class="token keyword">return</span> F<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>feature<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> F<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>out<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>第四步</strong>，训练网络，计算图像之间的相似度，再以此计算网络的交叉熵损失。</p> 
<p>相似度：为了比较投影端产生的表示，使用余弦相似度，其定义为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
           
             sim 
            
           
             ⁡ 
            
           
             ( 
            
           
             u 
            
           
             , 
            
           
             v 
            
           
             ) 
            
           
             = 
            
            
             
              
              
                u 
               
              
                T 
               
              
             
               v 
              
             
             
             
               ∥ 
              
             
               u 
              
             
               ∥ 
              
             
               ∥ 
              
             
               v 
              
             
               ∥ 
              
             
            
           
          
          
          
          
            (1) 
           
          
         
        
       
         \operatorname{sim}(u, v)=\frac{u^{T} v}{\|u\|\|v\|} \tag{1} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mopen">(</span><span class="mord mathdefault">u</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.45433em; vertical-align: -0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.51833em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">∥</span><span class="mord mathdefault">u</span><span class="mord">∥</span><span class="mord">∥</span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mord">∥</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">T</span></span></span></span></span></span></span></span></span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height: 2.45433em; vertical-align: -0.936em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">1</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<p>损失函数：基于相似度，正对示例的损失函数定义为(与MOCO损失函数类似)：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              ℓ 
             
             
             
               i 
              
             
               , 
              
             
               j 
              
             
            
           
             = 
            
           
             − 
            
           
             log 
            
           
             ⁡ 
            
            
             
             
               exp 
              
             
               ⁡ 
              
              
              
                ( 
               
              
                sim 
               
              
                ⁡ 
               
               
               
                 ( 
                
                
                
                  z 
                 
                
                  i 
                 
                
               
                 , 
                
                
                
                  z 
                 
                
                  j 
                 
                
               
                 ) 
                
               
              
                / 
               
              
                τ 
               
              
                ) 
               
              
             
             
              
              
                ∑ 
               
               
               
                 k 
                
               
                 = 
                
               
                 1 
                
               
               
               
                 2 
                
               
                 N 
                
               
              
              
              
                1 
               
               
               
                 [ 
                
               
                 k 
                
               
                 ≠ 
                
               
                 i 
                
               
                 ] 
                
               
              
             
               exp 
              
             
               ⁡ 
              
              
              
                ( 
               
              
                sim 
               
              
                ⁡ 
               
               
               
                 ( 
                
                
                
                  z 
                 
                
                  i 
                 
                
               
                 , 
                
                
                
                  z 
                 
                
                  k 
                 
                
               
                 ) 
                
               
              
                / 
               
              
                τ 
               
              
                ) 
               
              
             
            
           
          
          
          
          
            (2) 
           
          
         
        
       
         \ell_{i, j}=-\log \frac{\exp \left(\operatorname{sim}\left(\boldsymbol{z}_{i}, \boldsymbol{z}_{j}\right) / \tau\right)}{\sum_{k=1}^{2 N} \mathbb{1}_{[k \neq i]} \exp \left(\operatorname{sim}\left(\boldsymbol{z}_{i}, \boldsymbol{z}_{k}\right) / \tau\right)} \tag{2} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord">ℓ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.65343em; vertical-align: -1.22643em;"></span><span class="mord">−</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.427em;"><span class="" style="top: -2.12877em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: -5e-06em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.981231em;"><span class="" style="top: -2.40029em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.29971em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord">1</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">[</span><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span><span class="mrel mtight"><span class="mrel mtight"><span class="mord mtight"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.69444em;"><span class="" style="top: -2.7em;"><span class="pstrut" style="height: 2.7em;"></span><span class="rlap mtight"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="inner"><span class="mrel mtight"></span></span><span class="fix"></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.19444em;"><span class=""></span></span></span></span></span></span><span class="mrel mtight">=</span></span><span class="mord mathdefault mtight">i</span><span class="mclose mtight">]</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.04213em;">z</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.04213em;">z</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">/</span><span class="mord mathdefault" style="margin-right: 0.1132em;">τ</span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mop">exp</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mop"><span class="mord mathrm">s</span><span class="mord mathrm">i</span><span class="mord mathrm">m</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.04213em;">z</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right: 0.04213em;">z</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord">/</span><span class="mord mathdefault" style="margin-right: 0.1132em;">τ</span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.22643em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height: 2.65343em; vertical-align: -1.22643em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">2</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 其中，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         τ 
        
       
      
        \tau 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.1132em;">τ</span></span></span></span></span>被称为temperature parameter。该损失函数又称作normalized temperature-scaled cross-entropy loss。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> model <span class="token keyword">import</span> Model

<span class="token comment"># train for one epoch to learn unique features</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span> data_loader<span class="token punctuation">,</span> train_optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_loss<span class="token punctuation">,</span> total_num<span class="token punctuation">,</span> train_bar <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> tqdm<span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span>
    <span class="token keyword">for</span> pos_1<span class="token punctuation">,</span> pos_2<span class="token punctuation">,</span> target <span class="token keyword">in</span> train_bar<span class="token punctuation">:</span>
        pos_1<span class="token punctuation">,</span> pos_2 <span class="token operator">=</span> pos_1<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span> pos_2<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        feature_1<span class="token punctuation">,</span> out_1 <span class="token operator">=</span> net<span class="token punctuation">(</span>pos_1<span class="token punctuation">)</span>
        feature_2<span class="token punctuation">,</span> out_2 <span class="token operator">=</span> net<span class="token punctuation">(</span>pos_2<span class="token punctuation">)</span>
        <span class="token comment"># [2*B, D]</span>
        out <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>out_1<span class="token punctuation">,</span> out_2<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token comment"># [2*B, 2*B]</span>
        sim_matrix <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>out<span class="token punctuation">,</span> out<span class="token punctuation">.</span>t<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> temperature<span class="token punctuation">)</span>
        mask <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>sim_matrix<span class="token punctuation">)</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> batch_size<span class="token punctuation">,</span> device<span class="token operator">=</span>sim_matrix<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">bool</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># [2*B, 2*B-1]</span>
        sim_matrix <span class="token operator">=</span> sim_matrix<span class="token punctuation">.</span>masked_select<span class="token punctuation">(</span>mask<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># compute loss</span>
        pos_sim <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>out_1 <span class="token operator">*</span> out_2<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> temperature<span class="token punctuation">)</span>
        <span class="token comment"># [2*B]</span>
        pos_sim <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>pos_sim<span class="token punctuation">,</span> pos_sim<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token operator">-</span> torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>pos_sim <span class="token operator">/</span> sim_matrix<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        total_num <span class="token operator">+=</span> batch_size
        total_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size
        train_bar<span class="token punctuation">.</span>set_description<span class="token punctuation">(</span><span class="token string">'Train Epoch: [{}/{}] Loss: {:.4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epochs<span class="token punctuation">,</span> total_loss <span class="token operator">/</span> total_num<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> total_loss <span class="token operator">/</span> total_num
</code></pre> 
<p>在对比学习任务中对SimCLR模型进行了训练之后，舍弃投影端<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         g 
        
       
         ( 
        
       
         ⋅ 
        
       
         ) 
        
       
      
        g(\cdot) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>，使用基编码器(base encoder) <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         f 
        
       
         ( 
        
       
         ⋅ 
        
       
         ) 
        
       
      
        f(\cdot) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span> 获得的图像的表示，将表示向量用于下游任务，例如ImageNet分类。</p> 
<h3><a id="3MOCO_Kaiming_Hehttpsieeexploreieeeorgdocument9157636_et_al_2020_277"></a>3.MOCO (<a href="https://ieeexplore.ieee.org/document/9157636" rel="nofollow">Kaiming He</a> <em>et al.</em> 2020)</h3> 
<p>MOCO的一个核心观点是，<strong>样本数量对于对比学习很重要</strong>。本文提出一种<strong>动量对比</strong> (Mometum contrast) 的方法提高每个mini-batch的负样本数量。具体地说，MOCO通过查询值 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         q 
        
       
      
        q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">q</span></span></span></span></span> 和含有编码键值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         { 
        
        
        
          k 
         
        
          0 
         
        
       
         , 
        
        
        
          k 
         
        
          1 
         
        
       
         , 
        
        
        
          k 
         
        
          2 
         
        
       
         , 
        
       
         … 
         
       
         } 
        
       
      
        \{k_0, k_1, k_2, \dots \} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{<!-- --></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03148em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03148em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.301108em;"><span class="" style="top: -2.55em; margin-left: -0.03148em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mclose">}</span></span></span></span></span>的字典之间的匹配损失，来优化一个编码器。假设字典中存在唯一一个键值 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          + 
         
        
       
      
        k_+ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.902771em; vertical-align: -0.208331em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.258331em;"><span class="" style="top: -2.55em; margin-left: -0.03148em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.208331em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 与 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         q 
        
       
      
        q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">q</span></span></span></span></span> 匹配，那么对比损失函数 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          q 
         
        
       
      
        \mathcal{L}_q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 函数值可以取得最小。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          L 
         
        
          q 
         
        
       
      
        \mathcal{L}_q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>表示为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              L 
             
            
              q 
             
            
           
             = 
            
           
             − 
            
           
             log 
            
           
             ⁡ 
            
            
             
             
               exp 
              
             
               ⁡ 
              
              
              
                ( 
               
              
                q 
               
              
                ⋅ 
               
               
               
                 k 
                
               
                 + 
                
               
              
                / 
               
              
                τ 
               
              
                ) 
               
              
             
             
              
              
                ∑ 
               
               
               
                 i 
                
               
                 = 
                
               
                 0 
                
               
              
                K 
               
              
             
               exp 
              
             
               ⁡ 
              
              
              
                ( 
               
              
                q 
               
              
                ⋅ 
               
               
               
                 k 
                
               
                 i 
                
               
              
                / 
               
              
                τ 
               
              
                ) 
               
              
             
            
           
          
          
          
          
            (3) 
           
          
         
        
       
         \mathcal{L}_{q}=-\log \frac{\exp \left(q \cdot k_{+} / \tau\right)}{\sum_{i=0}^{K} \exp \left(q \cdot k_{i} / \tau\right)} \tag{3} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.969438em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathcal">L</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.59794em; vertical-align: -1.17094em;"></span><span class="mord">−</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop">lo<span style="margin-right: 0.01389em;">g</span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.427em;"><span class="" style="top: -2.12877em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: -5e-06em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.981231em;"><span class="" style="top: -2.40029em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">K</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.29971em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord mathdefault" style="margin-right: 0.03588em;">q</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03148em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathdefault" style="margin-right: 0.1132em;">τ</span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mop">exp</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord mathdefault" style="margin-right: 0.03588em;">q</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.258331em;"><span class="" style="top: -2.55em; margin-left: -0.03148em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">+</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.208331em;"><span class=""></span></span></span></span></span></span><span class="mord">/</span><span class="mord mathdefault" style="margin-right: 0.1132em;">τ</span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.17094em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="tag"><span class="strut" style="height: 2.59794em; vertical-align: -1.17094em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">3</span></span><span class="mord">)</span></span></span></span></span></span></span></p> 
<p>本文认为，如果字典足够大，包含的负样本足够丰富 (large) 的话，可以学到更好的特征表达。与此同时，用于字典键值的编码器要在学习进化的过程中尽量保持一致 (consistent)。MOCO有两个核心模块：(1) 用队列实现字典，主要的作用是可以实现字典大小和mini-batch大小的耦合，如此便可不受限制地提高bath size；(2) 动量更新，主要是为了解决引入队列维护字典之后，字典的编码器无法通过梯度反传获得参数更新的问题，具体为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
          
          
           
            
            
              θ 
             
            
              k 
             
            
           
             ← 
            
           
             m 
            
            
            
              θ 
             
            
              k 
             
            
           
             + 
            
           
             ( 
            
           
             1 
            
           
             − 
            
           
             m 
            
           
             ) 
            
            
            
              θ 
             
            
              q 
             
            
           
          
          
          
          
            (4) 
           
          
         
        
       
         \theta_{\mathrm{k}} \leftarrow m \theta_{\mathrm{k}}+(1-m) \theta_{\mathrm{q}} \tag{4} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">k</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord mathdefault">m</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">k</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.03611em; vertical-align: -0.286108em;"></span><span class="mord mathdefault">m</span><span class="mclose">)</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">q</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span><span class="tag"><span class="strut" style="height: 1.03611em; vertical-align: -0.286108em;"></span><span class="mord text"><span class="mord">(</span><span class="mord"><span class="mord">4</span></span><span class="mord">)</span></span></span></span></span></span></span><br> 如图©所示，通过这种动量更新的方法，可以从<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         q 
        
       
      
        q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">q</span></span></span></span></span> 的梯度反向传播间接获得 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span></span></span></span></span> 的梯度。相对于直接用 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         q 
        
       
      
        q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.03588em;">q</span></span></span></span></span> 的梯度更新替代 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         k 
        
       
      
        k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.03148em;">k</span></span></span></span></span> 的梯度更新，这种动量更新的方式更加平稳。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         m 
        
       
      
        m 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">m</span></span></span></span></span> 一般取0.99 ，如果取 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         0.9 
        
       
      
        0.9 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">9</span></span></span></span></span> 会太小，实验效果不好 ，这说明 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          q 
         
        
       
      
        \theta_q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          θ 
         
        
          k 
         
        
       
      
        \theta_k 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.84444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 的耦合不宜过强。</p> 
<p>下图总结对比了常用的三种负样本管理机制。图(a)是原始的end-to-end结构，最主要的问题是batch size和ditionary size相互耦合，ditionary size因此受限于GPU的内存大小。图(b)通过增加memory bank 结构，改进了图(a)的结构。memory bank可以存储数据集中所有样本的特征表达，每个字典随机地从memory bank中采样。但是从memory bank随机采样的问题是在不同的更新阶段，样本缺乏一致性，这就是MOCO反复强调的<strong>consistent</strong>问题。</p> 
<p><img src="https://images2.imgbox.com/c7/c8/woXt3Thx_o.jpg" alt="MoCo"><br> <font color="#999AAA">核心代码如下 (pytorch伪代码):</font></p> 
<pre><code class="prism language-python"><span class="token comment"># f_q, f_k: encoder networks for query and key</span>
<span class="token comment"># queue: dictionary as a queue of K keys (CxK)</span>
<span class="token comment"># m: momentum</span>
<span class="token comment"># t: temperature</span>
f_k<span class="token punctuation">.</span>params <span class="token operator">=</span> f_q<span class="token punctuation">.</span>params <span class="token comment"># initialize</span>
<span class="token keyword">for</span> x <span class="token keyword">in</span> loader<span class="token punctuation">:</span> <span class="token comment"># load a minibatch x with N samples</span>
    x_q <span class="token operator">=</span> aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># a randomly augmented version</span>
	x_k <span class="token operator">=</span> aug<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># another randomly augmented version</span>
	q <span class="token operator">=</span> f_q<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x_q<span class="token punctuation">)</span> <span class="token comment"># queries: NxC</span>
	k <span class="token operator">=</span> f_k<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x_k<span class="token punctuation">)</span> <span class="token comment"># keys: NxC</span>
	k <span class="token operator">=</span> k<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># no gradient to keys</span>
	<span class="token comment"># positive logits: Nx1</span>
	l_pos <span class="token operator">=</span> bmm<span class="token punctuation">(</span>q<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>C<span class="token punctuation">)</span><span class="token punctuation">,</span> k<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span>C<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token comment"># negative logits: NxK</span>
	l_neg <span class="token operator">=</span> mm<span class="token punctuation">(</span>q<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span>C<span class="token punctuation">)</span><span class="token punctuation">,</span> queue<span class="token punctuation">.</span>view<span class="token punctuation">(</span>C<span class="token punctuation">,</span>K<span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token comment"># logits: Nx(1+K)</span>
	logits <span class="token operator">=</span> cat<span class="token punctuation">(</span><span class="token punctuation">[</span>l_pos<span class="token punctuation">,</span> l_neg<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	<span class="token comment"># contrastive loss, Eqn.(1)</span>
	labels <span class="token operator">=</span> zeros<span class="token punctuation">(</span>N<span class="token punctuation">)</span> <span class="token comment"># positives are the 0-th</span>
	loss <span class="token operator">=</span> CrossEntropyLoss<span class="token punctuation">(</span>logits<span class="token operator">/</span>t<span class="token punctuation">,</span> labels<span class="token punctuation">)</span>
	<span class="token comment"># SGD update: query network</span>
	loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
	update<span class="token punctuation">(</span>f_q<span class="token punctuation">.</span>params<span class="token punctuation">)</span>
	<span class="token comment"># momentum update: key network</span>
	f_k<span class="token punctuation">.</span>params <span class="token operator">=</span> m<span class="token operator">*</span>f_k<span class="token punctuation">.</span>params<span class="token operator">+</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>m<span class="token punctuation">)</span><span class="token operator">*</span>f_q<span class="token punctuation">.</span>params
	<span class="token comment"># update dictionary</span>
	enqueue<span class="token punctuation">(</span>queue<span class="token punctuation">,</span> k<span class="token punctuation">)</span> <span class="token comment"># enqueue the current minibatch</span>
	dequeue<span class="token punctuation">(</span>queue<span class="token punctuation">)</span> <span class="token comment"># dequeue the earliest minibatch</span>

<span class="token comment"># bmm: batch matrix multiplication; mm: matrix multiplication; cat: concatenation.</span>
</code></pre> 
<p>最后，附上一张现有主流对比学习模型的性能图，来自SIMCLR论文。</p> 
<p><img src="https://images2.imgbox.com/10/bb/AcgpdnZg_o.jpg" alt="Comparisons" height="400"></p> 
<hr color="#000000" size='1"'> 
<h2><a id="_334"></a>四、总结</h2> 
<p>本文介绍了自监督学习中的一种重要方法–对比学习（contrastive learning）的基本概念和三篇代表性的最新论文，并且从模型创新点和代码实现角度进行了分析。对比学习是当前自监督学习一个重要的分支，目的在于从小样本无标签的数据中，学习到更有效的特征表达。目前的研究进展表明，自监督学习正在逐步逼近监督学习的水平。在很多场景中，例如医学影像分析，有标签的数据极其稀有。用自监督学习进行表示学习和预训练，将会是重要的一环。</p> 
<p>本博客撰写过程参考了以下博客内容：</p> 
<ol><li><a href="https://ai.googleblog.com/2020/04/advancing-self-supervised-and-semi.html" rel="nofollow">Google AI blog</a></li><li><a href="https://medium.com/@nainaakash012/simclr-contrastive-learning-of-visual-representations-52ecf1ac11fa#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6ImQ0Y2JhMjVlNTYzNjYwYTkwMDlkODIwYTFjMDIwMjIwNzA1NzRlODIiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MDczOTUyNzQsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwMjE1NTQ2OTk2NzAxMDM3MzAxNSIsImVtYWlsIjoiZGVyZWsuaHNpYW5nMTdAZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF6cCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsIm5hbWUiOiJEZXJlayBIc2lhbmciLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2dCa1JnV016WFQwTVMycGpHNHRXekZTU21xTUNOc0w5YzNfMkxBPXM5Ni1jIiwiZ2l2ZW5fbmFtZSI6IkRlcmVrIiwiZmFtaWx5X25hbWUiOiJIc2lhbmciLCJpYXQiOjE2MDczOTU1NzQsImV4cCI6MTYwNzM5OTE3NCwianRpIjoiMWU5MDFmZmE4ZmY4ZjYwMDgwYTcwY2RiZjNmMWEzNzMwY2QwMGEyYiJ9.qOvDrdVBFPXcb--KyHFAPu--FaemqBB8D_P6CmO0-AQSDuve00hiL-k6mT8CHZTTGV_AIx8BLXP8tDAcIprPt0yBHMV-z3Dti-900oXnAli6E8-C5riKwKfJQVsQT5AVbVXhWy8tjo798dLHTGlAnn5sCc0PS6lLu9mWg-oGNLpjqzLTBcKOmFhx7x7J9WxJMge0sDcT3C144vm6U7tgiosgNo040i4aQozrrjGAa6xikr5KlTC3VfDfOlXtLrV1KKmQ1hGndzbO8AY8dZWQjei6zHhASe7WibHc9uzvW-Ut1wxyLM3Yjoe_4uyRJLoE7XO7dugNFvwiMkfv32kxCw" rel="nofollow">SimCLR Post</a></li><li><a href="https://zhuanlan.zhihu.com/p/141141365" rel="nofollow">对比学习（Contrastive Learning）相关进展梳理</a></li><li><a href="https://zhuanlan.zhihu.com/p/141172794" rel="nofollow">对比学习（Contrastive Learning）</a></li><li><a href="https://towardsdatascience.com/a-framework-for-contrastive-self-supervised-learning-and-designing-a-new-approach-3caab5d29619" rel="nofollow">A Framework For Contrastive Self-Supervised Learning And Designing A New Approach</a></li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a73dcbe0176da46ba116f0b80f11f738/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">MyBatis二级缓存异常 org.apache.ibatis.cache.CacheException</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a07f0ffec787f73d9d6e77422b18c8cf/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">并发编程 — 原子类 AtomicReference 详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>