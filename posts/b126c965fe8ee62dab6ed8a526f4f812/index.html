<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【深度学习&amp;NLP】数据预处理的详细说明（含数据清洗、分词、过滤停用词、实体识别、词性标注、向量化、划分数据集等详细的处理步骤以及一些常用的方法） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【深度学习&amp;NLP】数据预处理的详细说明（含数据清洗、分词、过滤停用词、实体识别、词性标注、向量化、划分数据集等详细的处理步骤以及一些常用的方法）" />
<meta property="og:description" content="目录
一、数据预处理简介
二、进行数据预处理的原因
1、文本中含有不必要的信息和噪声
2、数据可能不一致或者不太规范
3、文本需要标记和分词
4、可能需要词形还原和词干提取 ( 词性标注 )
5、需要将文本向量化处理
三、数据预处理方法介绍及使用样例
1、数据清洗
2、分词
3、停用词过滤
4、词性标注
5、实体识别
6、词向量化
一、数据预处理简介 在深度学习中，数据预处理是一个重要的步骤。原始训练数据中，由于每一维特征的来源以及度量单位不同，会造成特征值的分布范围差异很大。当计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用。因此，对于基于相似度比较的机器学习方法，必须先对样本进行预处理，将各维度特征归一化到同一取值区间，并且消除不同特征之间的相关性，才能获得理想的结果。
数据预处理还可以通过数据增强来增加训练样本的多样性，提高模型鲁棒性，避免过拟合，例如， 翻转、旋转、平移、缩放、随机裁剪或补零，色彩抖动等 ( 这些都是在CV当中的一些情况 )；在NLP的任务中，数据预处理又可以通过以下方式来有效地增加训练数据的多样性，避免模型对训练数据的过拟合，提高模型的泛化能力和鲁棒性，例如，同义词替换、随即插入、随即删除、随即交换、随机扰动等，这些方法还可以缓解NLP中数据量不足的问题，提高模型的性能。
二、进行数据预处理的原因 1、文本中含有不必要的信息和噪声 文本数据通常包含大量的无关信息和噪声，如标点符号、HTML标记、停用词、缩写、拼写错误、语法错误等。这些信息和噪声会干扰模型的学习和性能，导致模型预测不准确或低效。通过数据预处理，可以去除这些不必要的信息和噪声，使文本数据更加干净和有用。
2、数据可能不一致或者不太规范 文本数据通常具有多种表现形式和写作风格，如大小写、缩写、单复数、变体词等，在中文中可能存在语义分割的问题，有些词与词之间的界限不清晰、有些词语的多义性和歧义性、还有语法和语义的变化、简体字和繁体字、以及不同民族的文字，所以中文的数据在处理起来可能更加的困难、需要我们更加的小心和细心。这些差异会导致数据不一致和不规范，从而使模型学习变得更加困难。通过数据预处理，可以将文本数据转换为一致和规范的形式，使模型更容易学习和理解。
3、文本需要标记和分词 在NLP中，将文本数据划分为单个标记或单词是很重要的。这可以帮助我们理解文本的含义和结构，以及构建词汇表和语料库。标记化和分词可以将文本数据转换为可操作的形式，从而为模型学习提供基础。这一步中，对中文的处理也比英文要困难，英文的词都是用空格隔开的，而中文的一句话很多时候都是连起来的，所以在分词、词性标注的时候就更加的不容易，不过现在也有像 jieba 这样的比较优秀的中文分词的工具。
4、可能需要词形还原和词干提取 ( 词性标注 ) 在NLP中，有时候我们需要将单词转换为它们的基本形式，这被称为词形还原和词干提取，在中文的NLP中其实词形还原和词干提取用的比较少 ( 在机器翻译和信息检索需要形态学分析的时候可能会用到 )，一般来说中文更多的是使用分词技术和词性标注技术来处理。这可以帮助我们理解单词的含义和关系，以及减少词汇量。通过数据预处理，可以将文本数据中的单词转换为它们的基本形式，从而提高模型的性能和效果。
5、需要将文本向量化处理 NLP中的大多数模型需要将文本数据转换为数字特征向量，这可以使它们与其他机器学习算法兼容。向量化可以帮助我们表示文本数据，并为模型学习提供基础。通过数据预处理，可以将文本数据转换为数字特征向量，使其更加适合于机器学习算法。
NLP中的数据预处理是一个非常重要的步骤，可以帮助我们减少噪声和错误，提高数据的一致性和规范性，转换文本数据为可操作的形式，以及提高模型性能。
三、数据预处理方法介绍及使用样例 这里我们主要介绍在中文的NLP任务中数据预处理每一步所使用的一些方法。
1、数据清洗 数据清洗是指去除数据中不需要的内容，例如HTML标签、数字、特殊符号等。这可以通过正则表达式、字符串匹配和过滤等技术实现。
例：
import re def clean_text(sentence): # 过滤HTML标签 sentence = re.sub(r&#39;&lt;.*?&gt;&#39;, &#39;&#39;, sentence) # 过滤数字 sentence = re.sub(r&#39;\d&#43;&#39;, &#39;&#39;, sentence) # 过滤特殊符号 sentence = re." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b126c965fe8ee62dab6ed8a526f4f812/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-27T19:24:10+08:00" />
<meta property="article:modified_time" content="2023-04-27T19:24:10+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【深度学习&amp;NLP】数据预处理的详细说明（含数据清洗、分词、过滤停用词、实体识别、词性标注、向量化、划分数据集等详细的处理步骤以及一些常用的方法）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%AE%80%E4%BB%8B-toc" style="margin-left:0px;"><a href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%AE%80%E4%BB%8B" rel="nofollow">一、数据预处理简介</a></p> 
<p id="%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E5%8E%9F%E5%9B%A0-toc" style="margin-left:0px;"><a href="#%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E5%8E%9F%E5%9B%A0" rel="nofollow">二、进行数据预处理的原因</a></p> 
<p id="%E6%96%87%E6%9C%AC%E4%B8%AD%E5%90%AB%E6%9C%89%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84%E4%BF%A1%E6%81%AF%E5%92%8C%E5%99%AA%E5%A3%B0-toc" style="margin-left:40px;"><a href="#%E6%96%87%E6%9C%AC%E4%B8%AD%E5%90%AB%E6%9C%89%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84%E4%BF%A1%E6%81%AF%E5%92%8C%E5%99%AA%E5%A3%B0" rel="nofollow">1、文本中含有不必要的信息和噪声</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%83%BD%E4%B8%8D%E4%B8%80%E8%87%B4%E6%88%96%E8%80%85%E4%B8%8D%E5%A4%AA%E8%A7%84%E8%8C%83-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%83%BD%E4%B8%8D%E4%B8%80%E8%87%B4%E6%88%96%E8%80%85%E4%B8%8D%E5%A4%AA%E8%A7%84%E8%8C%83" rel="nofollow">2、数据可能不一致或者不太规范</a></p> 
<p id="%E6%96%87%E6%9C%AC%E9%9C%80%E8%A6%81%E6%A0%87%E8%AE%B0%E5%92%8C%E5%88%86%E8%AF%8D-toc" style="margin-left:40px;"><a href="#%E6%96%87%E6%9C%AC%E9%9C%80%E8%A6%81%E6%A0%87%E8%AE%B0%E5%92%8C%E5%88%86%E8%AF%8D" rel="nofollow">3、文本需要标记和分词</a></p> 
<p id="%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F%E5%92%8C%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96%20(%20%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%20)-toc" style="margin-left:40px;"><a href="#%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F%E5%92%8C%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96%20%28%20%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%20%29" rel="nofollow">4、可能需要词形还原和词干提取 ( 词性标注 )</a></p> 
<p id="%E9%9C%80%E8%A6%81%E5%B0%86%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96%E5%A4%84%E7%90%86-toc" style="margin-left:40px;"><a href="#%E9%9C%80%E8%A6%81%E5%B0%86%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96%E5%A4%84%E7%90%86" rel="nofollow">5、需要将文本向量化处理</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%A0%B7%E4%BE%8B-toc" style="margin-left:0px;"><a href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%A0%B7%E4%BE%8B" rel="nofollow">三、数据预处理方法介绍及使用样例</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97" rel="nofollow">1、数据清洗</a></p> 
<p id="%E5%88%86%E8%AF%8D-toc" style="margin-left:40px;"><a href="#%E5%88%86%E8%AF%8D" rel="nofollow">2、分词</a></p> 
<p id="%E5%81%9C%E7%94%A8%E8%AF%8D%E8%BF%87%E6%BB%A4-toc" style="margin-left:40px;"><a href="#%E5%81%9C%E7%94%A8%E8%AF%8D%E8%BF%87%E6%BB%A4" rel="nofollow">3、停用词过滤</a></p> 
<p id="%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8-toc" style="margin-left:40px;"><a href="#%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8" rel="nofollow">4、词性标注</a></p> 
<p id="%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB-toc" style="margin-left:40px;"><a href="#%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB" rel="nofollow">5、实体识别</a></p> 
<p id="%E8%AF%8D%E5%90%91%E9%87%8F%E5%8C%96-toc" style="margin-left:40px;"><a href="#%E8%AF%8D%E5%90%91%E9%87%8F%E5%8C%96" rel="nofollow">6、词向量化</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%AE%80%E4%BB%8B"><span style="color:#4da8ee;">一、数据预处理简介</span></h2> 
<p>        在深度学习中，数据预处理是一个重要的步骤。原始训练数据中，由于每一维特征的来源以及度量单位不同，会造成特征值的分布范围差异很大。当计算不同样本之间的欧氏距离时，取值范围大的特征会起到主导作用。因此，对于基于相似度比较的机器学习方法，必须先对样本进行预处理，将各维度特征归一化到同一取值区间，并且消除不同特征之间的相关性，才能获得理想的结果。</p> 
<p>        数据预处理还可以通过数据增强来增加训练样本的多样性，提高模型鲁棒性，避免过拟合，例如， 翻转、旋转、平移、缩放、随机裁剪或补零，色彩抖动等 ( 这些都是在CV当中的一些情况 )；在NLP的任务中，数据预处理又可以通过以下方式来有效地增加训练数据的多样性，避免模型对训练数据的过拟合，提高模型的泛化能力和鲁棒性，例如，同义词替换、随即插入、随即删除、随即交换、随机扰动等，这些方法还可以缓解NLP中数据量不足的问题，提高模型的性能。</p> 
<p></p> 
<h2 id="%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E7%9A%84%E5%8E%9F%E5%9B%A0"><span style="color:#4da8ee;">二、进行数据预处理的原因</span></h2> 
<h3 id="%E6%96%87%E6%9C%AC%E4%B8%AD%E5%90%AB%E6%9C%89%E4%B8%8D%E5%BF%85%E8%A6%81%E7%9A%84%E4%BF%A1%E6%81%AF%E5%92%8C%E5%99%AA%E5%A3%B0"><span style="color:#6eaad7;">1、文本中含有不必要的信息和噪声</span></h3> 
<p>        文本数据通常包含大量的无关信息和噪声，如标点符号、HTML标记、停用词、缩写、拼写错误、语法错误等。这些信息和噪声会干扰模型的学习和性能，导致模型预测不准确或低效。通过数据预处理，可以去除这些不必要的信息和噪声，使文本数据更加干净和有用。</p> 
<p></p> 
<h3 id="%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%83%BD%E4%B8%8D%E4%B8%80%E8%87%B4%E6%88%96%E8%80%85%E4%B8%8D%E5%A4%AA%E8%A7%84%E8%8C%83"><span style="color:#6eaad7;">2、数据可能不一致或者不太规范</span></h3> 
<p>        文本数据通常具有多种表现形式和写作风格，如大小写、缩写、单复数、变体词等，在中文中可能存在语义分割的问题，有些词与词之间的界限不清晰、有些词语的多义性和歧义性、还有语法和语义的变化、简体字和繁体字、以及不同民族的文字，所以中文的数据在处理起来可能更加的困难、需要我们更加的小心和细心。这些差异会导致数据不一致和不规范，从而使模型学习变得更加困难。通过数据预处理，可以将文本数据转换为一致和规范的形式，使模型更容易学习和理解。</p> 
<p></p> 
<h3 id="%E6%96%87%E6%9C%AC%E9%9C%80%E8%A6%81%E6%A0%87%E8%AE%B0%E5%92%8C%E5%88%86%E8%AF%8D"><span style="color:#6eaad7;">3、文本需要标记和分词</span></h3> 
<p>        在NLP中，将文本数据划分为单个标记或单词是很重要的。这可以帮助我们理解文本的含义和结构，以及构建词汇表和语料库。标记化和分词可以将文本数据转换为可操作的形式，从而为模型学习提供基础。这一步中，对中文的处理也比英文要困难，英文的词都是用空格隔开的，而中文的一句话很多时候都是连起来的，所以在分词、词性标注的时候就更加的不容易，不过现在也有像 jieba 这样的比较优秀的中文分词的工具。</p> 
<p></p> 
<h3 id="%E5%8F%AF%E8%83%BD%E9%9C%80%E8%A6%81%E8%AF%8D%E5%BD%A2%E8%BF%98%E5%8E%9F%E5%92%8C%E8%AF%8D%E5%B9%B2%E6%8F%90%E5%8F%96%20(%20%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8%20)"><span style="color:#6eaad7;">4、可能需要词形还原和词干提取 ( 词性标注 )</span></h3> 
<p>        在NLP中，有时候我们需要将单词转换为它们的基本形式，这被称为词形还原和词干提取，在中文的NLP中其实词形还原和词干提取用的比较少 ( 在机器翻译和信息检索需要形态学分析的时候可能会用到 )，一般来说中文更多的是使用分词技术和词性标注技术来处理。这可以帮助我们理解单词的含义和关系，以及减少词汇量。通过数据预处理，可以将文本数据中的单词转换为它们的基本形式，从而提高模型的性能和效果。</p> 
<p></p> 
<h3 id="%E9%9C%80%E8%A6%81%E5%B0%86%E6%96%87%E6%9C%AC%E5%90%91%E9%87%8F%E5%8C%96%E5%A4%84%E7%90%86"><span style="color:#6eaad7;">5、需要将文本向量化处理</span></h3> 
<p>        NLP中的大多数模型需要将文本数据转换为数字特征向量，这可以使它们与其他机器学习算法兼容。向量化可以帮助我们表示文本数据，并为模型学习提供基础。通过数据预处理，可以将文本数据转换为数字特征向量，使其更加适合于机器学习算法。</p> 
<p>        NLP中的数据预处理是一个非常重要的步骤，可以帮助我们减少噪声和错误，提高数据的一致性和规范性，转换文本数据为可操作的形式，以及提高模型性能。</p> 
<p></p> 
<h2 id="%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E4%BB%8B%E7%BB%8D%E5%8F%8A%E4%BD%BF%E7%94%A8%E6%A0%B7%E4%BE%8B"><span style="color:#4da8ee;">三、数据预处理方法介绍及使用样例</span></h2> 
<p>        这里我们主要介绍在中文的NLP任务中数据预处理每一步所使用的一些方法。</p> 
<h3 id="%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97"><span style="color:#6eaad7;">1、数据清洗</span></h3> 
<p>        数据清洗是指去除数据中不需要的内容，例如HTML标签、数字、特殊符号等。这可以通过正则表达式、字符串匹配和过滤等技术实现。</p> 
<p>例：</p> 
<pre><code class="language-python">import re

def clean_text(sentence):
    # 过滤HTML标签
    sentence = re.sub(r'&lt;.*?&gt;', '', sentence)

    # 过滤数字
    sentence = re.sub(r'\d+', '', sentence)

    # 过滤特殊符号
    sentence = re.sub(r'[^\w\s]', '', sentence)

    # 过滤空格
    sentence = sentence.replace(' ', '')

    return sentence

text = "&lt;p&gt;这是一个包含HTML标签、数字12 3和特 殊符  号以及空格!@#的文本。&lt;/p&gt;"
clean_text = clean_text(text)
print(clean_text)</code></pre> 
<p>        结果如下所示：</p> 
<pre><code class="language-bash">这是一个包含HTML标签数字和特殊符号以及空格的文本</code></pre> 
<p></p> 
<h3 id="%E5%88%86%E8%AF%8D"><span style="color:#6eaad7;">2、分词</span></h3> 
<p>        中文文本需要先进行分词，将句子分割成单独的词语。中文的分词算法有很多，例如基于规则的算法、基于统计的算法和基于深度学习的算法。其中，基于深度学习的算法如BERT、LSTM等，能够更好地处理语义信息。可能在你做的很多实际的项目中，你经常会直接使用现有的分词工具，在这里我们就介绍一下分词工具的使用，至于完整实现一个分词的算法可能在后续的文章中会单独出一篇，内容应该比较多和细，所以在这里就不展开说了，下面我们给出一些现在用的比较多的分词工具的使用 ( 这里作者主要介绍一下中文的分词工具，英文的用的比较多的应该是NLTK )。</p> 
<p>例：</p> 
<pre><code class="language-python">text = "自然语言处理是人工智能领域的一个重要方向。"

# 使用jieba分词
import jieba
seg_list = jieba.cut(text)
print("jieba分词结果：", " ".join(seg_list))

# 使用THULAC分词
import thulac
thu = thulac.thulac()
seg_list = thu.cut(text)
print("THULAC分词结果：", " ".join([item[0] for item in seg_list]))

# 使用HanLP分词
from pyhanlp import HanLP
seg_list = HanLP.segment(text)
print("HanLP分词结果：", " ".join([term.word for term in seg_list]))

# 使用LTP分词
from ltp import LTP
ltp = LTP()
seg, _ = ltp.seg([text])
print("LTP分词结果：", " ".join(seg[0]))</code></pre> 
<p>        结果如下所示：</p> 
<pre><code class="language-bash">jieba分词结果： 自然语言 处理 是 人工智能 领域 的 一个 重要 方向 。
THULAC分词结果： 自然语言 处理 是 人工智能 领域 的 一 个 重要 方向 。
HanLP分词结果： 自然语言 处理 是 人工智能 领域 的 一个 重要 方向 。
LTP分词结果： 自然语言 处理 是 人工智能 领域 的 一个 重要 方向 .</code></pre> 
<p id=""></p> 
<h3 id="%E5%81%9C%E7%94%A8%E8%AF%8D%E8%BF%87%E6%BB%A4"><span style="color:#6eaad7;">3、停用词过滤</span></h3> 
<p>        停用词是指在文本中频繁出现但对文本意义贡献较小的词语，例如“的”、“了”、“是”等。通常需要将这些词语从文本中去除，以减少处理时间和存储空间，并提高文本处理效率。常用的中文的停用词表又哈工大(HIT)停用词表、百度(baidu)停用词表、川大机器智能实验室停用词表(SCU)以及中文停用词表(CN)等。下面就是这几个常用的中文停用词表的下载仓库地址：</p> 
<p><a href="https://github.com/goto456/stopwords" title="GitHub - goto456/stopwords: 中文常用停用词表（哈工大停用词表、百度停用词表等）">GitHub - goto456/stopwords: 中文常用停用词表（哈工大停用词表、百度停用词表等）</a></p> 
<p>        下面我给出一个使用哈工大停用词表去停用词的示例：</p> 
<p>例：</p> 
<pre><code class="language-python">import jieba

# 加载停用词表
with open('hit_stopwords.txt', 'r', encoding='utf-8') as f:
    stopwords = [line.strip() for line in f.readlines()]

# 定义去停用词函数
def remove_stopwords(text):
    seg_list = jieba.cut(text)
    filtered_list = [word for word in seg_list if word not in stopwords]
    return ' '.join(filtered_list)

text = "我与杀戮之中盛放，亦如黎明中的花朵。"
filtered_text = remove_stopwords(text)
print(filtered_text)</code></pre> 
<p>结果如下：</p> 
<pre><code class="language-bash">杀戮 之中 盛放 亦 黎明 中 花朵</code></pre> 
<p></p> 
<h3 id="%E8%AF%8D%E6%80%A7%E6%A0%87%E6%B3%A8"><span style="color:#6eaad7;">4、词性标注</span></h3> 
<p>        词性标注是指对分词后的词语进行词性标记，例如名词、动词、形容词等。词性标注能够帮助模型更好地理解文本，同时也有助于其他任务，例如命名实体识别和依存句法分析等。词性标注算法包括基于规则的算法、基于统计的算法和基于深度学习的算法。词性标注可以用隐马尔可夫模型中经典的维特比算法来做，也可以用现在用的比较多的神经网络来做，不过说起来都比较冗长，后面有机会可以出一篇专门实现的文章，在这里我们直接展示一下使用 <strong>jieba </strong>分词工具来进行词性标注：</p> 
<p>例：</p> 
<pre><code class="language-python">import jieba.posseg as pseg

text = "云日明松雪，溪山进晚风。"
result = pseg.cut(text)

for word, tag in result:
    print(word, tag)</code></pre> 
<p>结果如下：</p> 
<pre><code class="language-bash">云日明 nr
松雪 nr
， x
溪山 ns
进 v
晚风 n
。 x</code></pre> 
<p>        读者可自行搜索这些词性所代表的含义。</p> 
<p></p> 
<h3 id="%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB"><span style="color:#6eaad7;">5、实体识别</span></h3> 
<p>        实体识别是指在文本中自动识别和提取出人名、地名、机构名等具有特定意义的实体。实体识别通常采用基于规则的方法或基于机器学习的方法，例如条件随机场（CRF）和循环神经网络（RNN）等。本文章只展示使用现有的工具进行命名实体识别的方法，有很多工具可以用来进行命名实体识别。一些较为成熟的中文命名实体识别（NER）工具包括 LTP（语言技术平台），PyHanlp，Lac 等。底层的实现，有时间再单独做。</p> 
<p>例：</p> 
<pre><code class="language-python">from LAC import LAC

lac = LAC(mode='lac')
text = "杨超越在1998年7月31日出生于江苏省盐城市大丰区。"
result = lac.run(text)
print(result)</code></pre> 
<p>结果如下：</p> 
<pre><code class="language-bash">[['杨超越', '在', '1998年', '7月31日出生于', '江苏省', '盐城市', '大丰区', '。'], ['PER', 'p', 'TIME', 'v', 'LOC', 'LOC', 'LOC', 'w']]</code></pre> 
<p></p> 
<h3 id="%E8%AF%8D%E5%90%91%E9%87%8F%E5%8C%96"><span style="color:#6eaad7;">6、词向量化</span></h3> 
<p>        将文本转换为向量表示是深度学习中的一个重要步骤，词向量化是将分词后的词语转换为向量表示的过程。常见的词向量化算法有词袋模型（Bag-of-words, BoW）、word2vec、GloVe、TDF-IDF等。</p> 
<p>        TF-IDF（词频-逆文档频率）是一种常用的文本特征提取方法，它用于衡量单词在文档集合中的重要性。TF-IDF 是由两部分组成的：词频（TF）和逆文档频率（IDF）。词频（TF）表示单词在文档中出现的频率。它通常通过将单词在文档中出现的次数除以文档的总单词数来计算。词频越高，说明单词在文档中越重要。逆文档频率（IDF）表示单词在文档集合中的普遍重要性。它通常通过将文档集合的总文档数除以包含该单词的文档数，然后取对数来计算。逆文档频率越高，说明单词在文档集合中越重要。TF-IDF 值是通过将词频和逆文档频率相乘来计算的。TF-IDF 值越高，说明单词在文档中越重要。下面是直接使用sklearn来进行TDF-IDF向量化的例子：</p> 
<p>例：</p> 
<pre><code class="language-python">from sklearn.feature_extraction.text import TfidfVectorizer

# 准备数据
corpus = ['赵六 王五', '张三 李四']

# 创建 TfidfVectorizer 对象
vectorizer = TfidfVectorizer()

# 计算 TF-IDF 值
tfidf = vectorizer.fit_transform(corpus)

# 输出结果
print(tfidf.toarray())
</code></pre> 
<p>结果如下：</p> 
<pre><code class="language-bash">[[0.         0.         0.70710678 0.70710678]
 [0.70710678 0.70710678 0.         0.        ]]</code></pre> 
<p>        </p> 
<p>        中文NLP任务的数据预处理包括数据清洗、分词、停用词过滤、词性标注、实体识别和词向量化等多个步骤，每个步骤都有不同的数据预处理技术可以选择，以后的文章中我可能还会介绍一些不错的方法实现，本篇文章对数据预处理部分就暂时叙述到这里。</p> 
<p></p> 
<p><strong>本篇文章到此结束，感谢各位读者的阅读！</strong></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e17cf0b277c1eda75cd3220e12e867f7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">2、AD新建项目及编辑界面介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4f27662b5f18236f1e56cd8f13dcabca/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;中可变参数宏</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>