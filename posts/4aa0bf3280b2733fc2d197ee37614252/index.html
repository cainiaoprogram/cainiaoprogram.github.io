<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MindOpt Tuner调参器，提升求解速度、性能（一） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="MindOpt Tuner调参器，提升求解速度、性能（一）" />
<meta property="og:description" content="MindOpt Studio简介 MindOpt 调参器（MindOpt Tuner，简称 MTuner）是一款超参自动优化工具。
它可以帮助运筹优化工程师在使用求解器时自动搜索最佳参数组合。优化求解器往往拥有很多配置参数，例如启发式方法的开关、割平面方法的开关、预处理的配置以及各种误差容忍度等等。MindOpt Tuner会尝试不同的参数组合，评估每组参数的性能，然后基于这些结果来确定最佳参数。这样可以大大减少手动调整参数的时间和精力，并且可以帮助提升求解性能。
不同于常见的贪心算法、遗传算法、粒子群算法等调参算法，MindOpt Tuner使用了团队新研发的快速算法，只需要相对少的评估就能给出性能很好的参数。
输入:
业务场景中的优化问题数据，一个或者多个均可以待调的求解器（可选）这个求解器待调的参数。若没有指定，则会自动用MindOpt Tuner内部内置的能力。 输出：
一套最优参数。采用此参数运行该求解器，在您的业务场景上会得到更优的效果。一系列结果文件和日志，给出调参效果分析。比如会列出对效果影响更大的几个参数。 用法 MindOpt Tuner 当前支持以下几种用法：
web页面作业提交：可直接在浏览器访问“作业提交”来提交和管理任务、获取结果，在其他渠道提交的任务也可在此任务管理查看到。Notebook容器：类似MindOpt求解器和建模语言，可以访问MindOpt建模求解平台的Notebook容器中使用Mtuner。其内核同单机版，但无需安装步骤直接浏览器中使用。采用Notebook项目方便记录笔记、查询接口和参数说明、混合编程、公开分享项目等。单机版：支持在MacOS、Linux、Windows平台环境下来创建并触发调参任务。适合需要定制化集成或私有化部署的客户,安装包获取&gt;&gt; 本篇系列将重点讲解下Notebook容器中如何使用命令行（本篇）和PythonAPI，并且给出web页面任务提交用法示例截图。
注：下面的文件包含code源码，您可复制本项目，然后在浏览项目内容页点击右上角的NoteBook按钮，进入环境后查看、运行、修改调试代码。
Notebook容器中使用 下文将通过以下顺序讲解：
提交任务：根据一个问题调优学习查询指令查询结果使用结果提交一组数据用于调参（本地和OSS）其他常用指令 1. 提交任务：根据一个问题调优 这里假设我们业务场景搜集到两个数据，nl_train_1.nl用来调参，nl_test_1.nl用来验证调参结果可用。
首先我们运行如下指令提交一个调参任务:
! mindopt-tuner create-task --solver cbc --problem &#39;./model/nl_train_1.nl&#39; --max-tuning-time 600 OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k Problem file &#34;nl_train_1.nl&#34; uploaded successfully. Task #438394355699425280 created succesfully. 这里需注意：为了节省数据存储空间，同用户下的MD5值相同的数据文件，服务端仅会存一次。因此重复提交后会提醒文件已存在。此时调参任务继续执行，线上存的数据不更新。
这里小编已经提交了测试过，新提交taskID会和后文描述不一样。小编提交的taskID是 438394355699425280。后文将基于此ID来讲解获取结果，用户请注意更换自己的ID测试。
这段任务提交的指令可以解析为：
指令段说明!使用cell magic，让可以在Python内核的Notebook的code cell里面运行命令行指令。mindopt-tuner是MindOpt Tuner调参器的可执行程序的名称create-task创建任务。还有其他指令可以通过 mindopt-tuner -h去查询–solver cbc选择求解器为cbc。还有其他参数可以通过 mindopt-tuner create-task -h去查询–problem ‘." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4aa0bf3280b2733fc2d197ee37614252/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-03T17:12:53+08:00" />
<meta property="article:modified_time" content="2023-11-03T17:12:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MindOpt Tuner调参器，提升求解速度、性能（一）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="MindOpt_Studio_0"></a>MindOpt Studio简介</h2> 
<p><strong>MindOpt 调参器</strong>（<strong>MindOpt Tuner</strong>，简称 <strong>MTuner</strong>）是一款超参自动优化工具。</p> 
<p>它可以帮助运筹优化工程师在使用求解器时自动搜索最佳参数组合。优化求解器往往拥有很多配置参数，例如启发式方法的开关、割平面方法的开关、预处理的配置以及各种误差容忍度等等。MindOpt Tuner会尝试不同的参数组合，评估每组参数的性能，然后基于这些结果来确定最佳参数。这样可以大大减少手动调整参数的时间和精力，并且可以帮助提升求解性能。</p> 
<p>不同于常见的贪心算法、遗传算法、粒子群算法等调参算法，MindOpt Tuner使用了团队新研发的快速算法，只需要相对少的评估就能给出性能很好的参数。</p> 
<p><img src="https://images2.imgbox.com/8a/aa/hNtI7q9x_o.png" alt="image.png"></p> 
<p>输入:</p> 
<ul><li>业务场景中的<strong>优化问题数据</strong>，一个或者多个均可以</li><li>待调的求解器</li><li>（可选）这个求解器待调的参数。若没有指定，则会自动用MindOpt Tuner内部内置的能力。</li></ul> 
<p>输出：</p> 
<ul><li><strong>一套最优参数</strong>。采用此参数运行该求解器，在您的业务场景上会得到更优的效果。</li><li>一系列结果文件和日志，给出调参效果分析。比如会列出对效果影响更大的几个参数。</li></ul> 
<h3><a id="_21"></a>用法</h3> 
<p>MindOpt Tuner 当前支持以下几种用法：</p> 
<ol><li><strong>web页面作业提交</strong>：可直接在浏览器访问“作业提交”来提交和管理任务、获取结果，在其他渠道提交的任务也可在此任务管理查看到。</li><li><strong>Notebook容器</strong>：类似MindOpt求解器和建模语言，可以访问MindOpt建模求解平台的Notebook容器中使用Mtuner。其内核同单机版，但无需安装步骤直接浏览器中使用。采用Notebook项目方便记录笔记、查询接口和参数说明、混合编程、公开分享项目等。</li><li><strong>单机版</strong>：支持在MacOS、Linux、Windows平台环境下来创建并触发调参任务。适合需要定制化集成或私有化部署的客户,<a href="https://www.yuque.com/mindopt/tuner/downloads" rel="nofollow">安装包获取&gt;&gt;</a></li></ol> 
<p>本篇系列将重点讲解下<strong>Notebook容器</strong>中如何使用<strong>命令行（本篇）<strong>和</strong>PythonAPI</strong>，并且给出<strong>web页面任务提交</strong>用法示例截图。</p> 
<p>注：下面的文件包含code源码，您可复制本项目，然后在浏览项目内容页点击右上角的NoteBook按钮，进入环境后查看、运行、修改调试代码。</p> 
<h2><a id="Notebook_33"></a>Notebook容器中使用</h2> 
<p>下文将通过以下顺序讲解：</p> 
<ol><li>提交任务：根据一个问题调优</li><li>学习查询指令</li><li>查询结果</li><li>使用结果</li><li>提交一组数据用于调参（本地和OSS）</li><li>其他常用指令</li></ol> 
<h3><a id="1__44"></a>1. 提交任务：根据一个问题调优</h3> 
<p>这里假设我们业务场景搜集到两个数据，<a href="https://opt.aliyun.com/#/platform/case/experience?projectName=BFnQjmumY7zq" rel="nofollow">nl_train_1.nl</a>用来调参，<a href="https://opt.aliyun.com/#/platform/case/experience?projectName=BFnQjmumY7zq" rel="nofollow">nl_test_1.nl</a>用来验证调参结果可用。</p> 
<p>首先我们运行如下指令提交一个调参任务:</p> 
<pre><code>! mindopt-tuner create-task --solver cbc --problem './model/nl_train_1.nl' --max-tuning-time 600
</code></pre> 
<pre><code>OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Problem file "nl_train_1.nl" uploaded successfully.
Task #438394355699425280 created succesfully.
</code></pre> 
<p>这里需注意：为了节省数据存储空间，同用户下的MD5值相同的数据文件，服务端仅会存一次。因此重复提交后会提醒文件已存在。此时调参任务继续执行，线上存的数据不更新。</p> 
<p>这里小编已经提交了测试过，新提交taskID会和后文描述不一样。小编提交的taskID是 <code>438394355699425280</code>。后文将基于此ID来讲解获取结果，用户请注意更换自己的ID测试。</p> 
<p>这段任务提交的指令可以解析为：</p> 
<table><thead><tr><th>指令段</th><th>说明</th></tr></thead><tbody><tr><td>!</td><td>使用cell magic，让可以在Python内核的Notebook的code cell里面运行命令行指令。</td></tr><tr><td>mindopt-tuner</td><td>是MindOpt Tuner调参器的可执行程序的名称</td></tr><tr><td>create-task</td><td>创建任务。还有其他指令可以通过 <code>mindopt-tuner -h</code></td></tr><tr><td>去查询</td><td></td></tr><tr><td>–solver cbc</td><td>选择求解器为cbc。还有其他参数可以通过 <code>mindopt-tuner create-task -h</code></td></tr><tr><td>去查询</td><td></td></tr><tr><td>–problem ‘./model/nl_train_1.nl’</td><td>使用’./model/nl_train_1.nl’数据用于调参。</td></tr><tr><td>–max-tuning-time 600</td><td>设置调参任务的时间额度为600秒，到时间后会停止调优。</td></tr></tbody></table> 
<h3><a id="2__77"></a>2. 学习查询指令</h3> 
<p>在上一节中我们提到了</p> 
<table><thead><tr><th>指令段</th><th>说明</th></tr></thead><tbody><tr><td>create-task</td><td>创建任务。还有其他指令可以通过 <code>mindopt-tuner -h</code></td></tr><tr><td>去查询</td><td></td></tr><tr><td>–solver cbc</td><td>选择求解器为cbc。还有其他参数可以通过 <code>mindopt-tuner create-task -h</code></td></tr><tr><td>去查询</td><td></td></tr></tbody></table> 
<p>这里，我们可以试运行以下指令，查询接口的用法：</p> 
<pre><code>!mindopt-tuner -h
</code></pre> 
<pre><code>OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
MindOpt Tuner v0.9.0 (Build: 20230404)

Usage: mindopt-tuner [-h] [-v] &lt;action&gt; [&lt;action options&gt;]

Arguments:
  -h, --help         Show help information.
  -v, --version      Show the software version.

Actions:
  create-task        Create a new tuning task, and then start it.
  terminate-task     Terminate one or more existing tuning tasks.
  delete-task        Delete one or more tuning tasks. If a task to delete is running, it will be terminated and deleted.
  check-cloud-usage  Check cloud resource usage.
  task-status        Show the status of one or more tuning tasks.
  list-tasks         List tuning tasks.
  fetch-result       Fetch tuning result.
  upload-file        Upload a file to the cloud.

'mindopt-tuner &lt;action&gt; -h' Show the help information of an action.

</code></pre> 
<p>这里我们得到了操作词和功能说明，然后我们还可以根据 <code>mindopt-tuner 操作词 -h</code>来查询对应操作词的使用说明。比如如何获取结果：</p> 
<pre><code>!mindopt-tuner task-status -h
!mindopt-tuner fetch-result -h
</code></pre> 
<pre><code>OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
MindOpt Tuner v0.9.0 (Build: 20230404)

Usage: mindopt-tuner task-status [-h] --task-id &lt;id&gt; [&lt;id&gt; ...]

Show the status of one or more tuning tasks.

Arguments:
  -h, --help                 Show help information.
  --task-id &lt;id&gt; [&lt;id&gt; ...]  Specify the id(s) of the tuning task(s), separated by space.
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
MindOpt Tuner v0.9.0 (Build: 20230404)

Usage: mindopt-tuner fetch-result [-h] --task-id &lt;id&gt; [--file &lt;file&gt;] [--show-url]

Fetch tuning result.

Arguments:
  -h, --help      Show help information.
  --task-id &lt;id&gt;  Specify the id of the tuning task
  --file &lt;file&gt;   Path to the file to fetch
  --show-url      Show the file download URL
</code></pre> 
<h3><a id="3__150"></a>3. 查询结果</h3> 
<p>根据上面的指令,我们可以通过以下方式来查询我们刚刚提交的任务的结果。用户测试时候，请注意更换上面自己任务的ID号。</p> 
<pre><code>!mindopt-tuner task-status --task-id 438394355699425280

print("-------分割线--------")
! mindopt-tuner fetch-result --task-id 438394355699425280
</code></pre> 
<pre><code>OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
+--------------------+---------+--------------+----------+---------------------+-----------------------------------------+
|                 id |   cores |   memory(GB) | status   | creation time       | file outputs                            |
+====================+=========+==============+==========+=====================+=========================================+
| 438394355699425280 |       2 |            2 | finished | 2023-04-24T17:42:39 | ['result/FINISHED',                     |
|                    |         |              |          |                     | 'result/log_mtuner.log',                |
|                    |         |              |          |                     | 'result/tuning_config_mtuner.txt',      |
|                    |         |              |          |                     | 'result/performance.txt',               |
|                    |         |              |          |                     | 'result/summary_mtuner.csv',            |
|                    |         |              |          |                     | 'result/evaluation_history_mtuner.csv', |
|                    |         |              |          |                     | 'result/best_parameters_mtuner.prm']    |
+--------------------+---------+--------------+----------+---------------------+-----------------------------------------+
-------分割线--------
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k

****************************************************************************************************
MindOpt Tuner 0.9.0 started at 2023-04-24 17:43:18
- Tuning for COIN-OR Cbc 2.10.5 (Build Date: Nov 24 2021).
- Tuning on "nl_train_1.nl".
- Initial "max_eval_time": 300s.
- Tuning-objective: wallclock_time.
- Tuning task will be terminated after evaluating 200 para-combos or reaching 600s.
- Evaluating default parameters...
- "wallclock_time" with default parameters: 3.21
- Remained tuning time: 578.96s.

Tuning starts at 2023-04-24 17:43:39.
   ================================================================================
   &lt;#Eval&gt;       &lt;wallclock_time&gt;   &lt;Current best&gt;   &lt;Elapsed time&gt;   &lt;Eval status&gt;
   -------       ----------------   --------------   --------------   -------------
         1                 2.5900           2.5900            24.00         OPTIMAL
         2                 0.6900           0.6900            44.87         OPTIMAL
         3                 2.0000           0.6900            65.97          CUTOFF
         4                 0.1000           0.1000            87.02         OPTIMAL
         5                 2.0000           0.1000           104.90          CUTOFF
         6                 2.0000           0.1000           122.95          CUTOFF
         7                 2.0000           0.1000           143.91          CUTOFF
         8                 2.0000           0.1000           167.95          CUTOFF
         9                 2.0000           0.1000           188.95          CUTOFF
        10                 1.7100           0.1000           209.93         OPTIMAL
        11                 0.1000           0.1000           230.89         OPTIMAL
        12                 0.1000           0.1000           248.87         OPTIMAL
        13                 0.1000           0.1000           266.96         OPTIMAL
        14                 0.1000           0.1000           284.86         OPTIMAL
        15                 0.1100           0.1000           302.92         OPTIMAL
        16                 0.1000           0.1000           320.90         OPTIMAL
        17                 0.1000           0.1000           338.91         OPTIMAL
        18                 0.1000           0.1000           356.92         OPTIMAL
        19                 0.1000           0.1000           377.93         OPTIMAL
        20                 0.1000           0.1000           398.93         OPTIMAL
        21                 0.1000           0.1000           416.91         OPTIMAL
        22                 0.1000           0.1000           434.89         OPTIMAL
        23                 0.2100           0.1000           455.89         OPTIMAL
        24                 0.1000           0.1000           476.90         OPTIMAL
        25                 0.1000           0.1000           494.90         OPTIMAL
        26                 0.1000           0.1000           512.90         OPTIMAL
        27                 0.0900           0.0900           530.89         OPTIMAL
        28                 0.1000           0.0900           548.91         OPTIMAL
        29                 0.1000           0.0900           566.90         OPTIMAL
        30                 2.0000           0.0900           584.89          CUTOFF
Tuning finished at 2023-04-24 17:53:24.

   ===========================================================================
   Best wallclock_time: 0.09                               Status: finished
   ---------------------------------------------------------------------------
   &lt;Parameters&gt;                                   &lt;Values&gt;        &lt;Importance&gt;
   ------------                                   --------        ------------
   cuts                                               root          0.0277 *
   preprocess                                    aggregate          0.9309 ***
   heuristics                                          off          0.0007
   strongBranching                                       2          0.0101
   trustPseudoCosts                                      5          0.0306 **

   NOTE: The 'Importance' scores indicate the relative importance of each parameter.
   The higher the score (more '*' attached), the more effective the parameter is.

Tuning finished, the best wallclock_time is 0.09 [** 35.67x improvement **]

The following files have been generated:

   1. result/best_parameters_mtuner.prm                  // Best parameters in '.prm' format.    
   2. result/log_mtuner.log                              // Logs of the tuning process.
   3. result/evaluation_history_mtuner.csv               // Evaluation history of the tuning process. 
   4. result/summary_mtuner.csv                          // Summary of the tuning results. 

****************************************************************************************************

</code></pre> 
<p>这个日志列出了比较详细的信息，其中：</p> 
<ul><li><code>- "wallclock_time" with default parameters: 3.21</code> 代表调参前的求解时间是 3.21s</li><li>调参结束后的 <code>&lt;Parameters&gt; &lt;Values&gt; &lt;Importance&gt;</code>代表的是优化调参后的建议取值和重要性评估。</li><li><code>Tuning finished, the best wallclock_time is 0.09 [** 35.67x improvement **]</code> 这句话代表，调参后的最快速度是0.09秒求解（wallclock_time），比原始参数提速 35.67 = 3.21/0.09 倍。</li></ul> 
<p>我们还可以运行如下指令，去获取上面表格 <code>file outputs</code>里面的文件信息，比如：</p> 
<pre><code>print("----调参后参数----")
! mindopt-tuner fetch-result --task-id 438394355699425280 --file result/best_parameters_mtuner.prm
print("----调参表现----")
! mindopt-tuner fetch-result --task-id 438394355699425280 --file result/performance.txt --show-url
</code></pre> 
<pre><code>----调参后参数----
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
cuts	"root"
preprocess	"aggregate"
heuristics	"off"
strongBranching	2
trustPseudoCosts	5

----调参表现----
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Tuning finished, the best wallclock_time is 0.09 [** 35.67x improvement **]

Download url of the file:
https://opt-mdp-prod.oss-cn-beijing.aliyuncs.com/distrun_cloud/prod/result/438394355955273728/result/performance.txt?Expires=1682344463&amp;OSSAccessKeyId=LTAI5tNoeFXtmgwggcXkt2wP&amp;Signature=iGTXfaojbwxzObNebCpDceQzzEU%3D
</code></pre> 
<h3><a id="4_285"></a>4.使用结果</h3> 
<p>这里我们可以验证下效果。刚求解的是.nl文件，可以参考MindOpt APL建模语言的<a href="https://www.yuque.com/mindopt/apl/favezt#ZvHcf" rel="nofollow">设置求解器参数</a>的指引来使用和设置参数。</p> 
<p>如以下跑的代码：</p> 
<ol><li>用cbc默认参数，原始参数求解完后，(Wallclock seconds):2.07 秒。</li><li>用MindOpt Tuner调参后的参数，(Wallclock seconds): 0.09 秒。</li></ol> 
<p>2.07 / 0.09 ≈ 23 倍</p> 
<p><strong>这里需要注意的是</strong>：<strong>不同机器运行的耗时不一样</strong>，因此计算的提升倍数有差异，最优参数推荐值也可能不一样。上面调参器调优的结果是在云平台的远程服务器中运行，与本容器的环境并不一致，从本容器的运行结果大致也能看到速度有明显提升。</p> 
<blockquote> 
 <p>下面的指令输出的日志太长，为了优化阅读体验，我们删除了运行记录，您可以将下面的cell属性从Raw更改为Code后运行：</p> 
</blockquote> 
<pre><code>print("====================采用原始参数====================")
!cbc model/nl_train_1.nl -AMPL wantsol=1 log=1
print("====================采用MindOpt Tuner调优后的参数====================")
!cbc model/nl_train_1.nl -AMPL   cuts=root preprocess=aggregate heuristics=off strongBranching=2 trustPseudoCosts=5 wantsol=1 log=1
</code></pre> 
<p>这里我们还可以测试以下这个参数的迁移性，<a href="https://opt.aliyun.com/#/platform/case/experience?projectName=BFnQjmumY7zq" rel="nofollow">nl_test_1.nl</a>文件是和<a href="https://opt.aliyun.com/#/platform/case/experience?projectName=BFnQjmumY7zq" rel="nofollow">nl_train_1.nl</a>相似的一个问题，我们可以看看用训练出来的参数求解表现如何。</p> 
<p>从运行结果看，花费的时间与训练数据接近，调优后的参数能提速近20倍。</p> 
<blockquote> 
 <p>下面的指令输出的日志太长，为了优化阅读体验，我们删除了运行记录，您可以将下面的cell属性从Raw更改为Code后运行：</p> 
</blockquote> 
<pre><code>print("====================test-采用原始参数====================")
!cbc model/nl_test_1.nl -AMPL wantsol=1 log=1
print("====================test-采用MindOpt Tuner调优后的参数====================")
!cbc model/nl_test_1.nl -AMPL   cuts=root preprocess=aggregate heuristics=off strongBranching=2 trustPseudoCosts=5 wantsol=1 log=1
</code></pre> 
<h3><a id="5_OSS_320"></a>5. 提交一组数据用于调参（本地和OSS）</h3> 
<p>除了对于单个文件调参，还可以根据一组数据进行调参。举例：我们将数据存在 <code>src/mps_train</code>文件夹（这些数据来源于MindOpt求解器单机版的安装包的 <code>examples/data</code>文件夹，），其访问路径（相对本运行环境）存储为一个txt文件<a href="https://opt.aliyun.com/#/platform/case/experience?projectName=BFnQjmumY7zq" rel="nofollow">mps_train_local.txt</a>。</p> 
<p>同时不仅仅支持文件存在本地容器，也支持存在云端oss。这个方式适合大文件（不适合浏览器上传或者这个容器放不下），我们可以用阿里云的<a href="https://www.aliyun.com/product/oss" rel="nofollow">对象存储OSS</a>。这里我们举例有几个数据，存在了云端OSS（公开可访问），然后将数据的地址存入<a href="https://opt.aliyun.com/#/platform/case/experience?projectName=BFnQjmumY7zq" rel="nofollow">mps_train_oss.txt</a>。</p> 
<p>然后我们运行如下提交指令进行测试提交：</p> 
<pre><code>print("----本地的文件提交-----")

!mindopt-tuner create-task --solver cbc --problem ./model/mps_train_local.txt --max-tuning-time 3600
</code></pre> 
<pre><code>----本地的文件提交-----
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Problem file "enlight7.nl" uploaded successfully.
Problem file "enlight8.nl" uploaded successfully.
Problem file "enlight10.nl" uploaded successfully.
Task #438398613857509376 created succesfully.
</code></pre> 
<pre><code>print("----OSS的文件提交-----")
!mindopt-tuner create-task --solver cbc --problem ./model/mps_train_oss.txt --max-tuning-time 3600
</code></pre> 
<pre><code>----OSS的文件提交-----
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Task #438398626012602368 created succesfully.
</code></pre> 
<p>小编运行的时候得到taskID：438398613857509376New 和 438398626012602368。<br> 运行结束后，我们可以获得结果。从结果可以看出，可以得到提升。<br> <strong>Tips</strong> ：对于求解器的调参，我们建议只在同一场景的问题上调优。如果问题结构差异很大，调参效果并不一定好</p> 
<pre><code>#print("-------查看状态和results文件链接--------")
#!mindopt-tuner task-status --task-id 438398613857509376 438398626012602368

print("-------本地的提交结果--------")
! mindopt-tuner fetch-result --task-id 438398613857509376 --file result/performance.txt
print("-------OSS的提交结果，一样的--------")
! mindopt-tuner fetch-result --task-id 438398626012602368 --file result/performance.txt
</code></pre> 
<pre><code>-------本地的提交结果--------
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Tuning finished, the best avg_wallclock_time is 3.87333 [** 33.01x improvement **]

-------OSS的提交结果，一样的--------
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Tuning finished, the best avg_wallclock_time is 3.9 [** 32.71x improvement **]
</code></pre> 
<h3><a id="6_378"></a>6.其他常用指令</h3> 
<p>如果任务等待了很久，忘记了taskID，您还可以运行下面的指令查询自己账号下面的所有任务ID。任务排队也可以查看当前环境和账号支持的额度。更多的指令可以参考上文的 <code>2. 学习查询指令</code>的 <code>mindopt-tuner [操作词] -h</code>来表示。</p> 
<pre><code>print("-----当前份额：-----")
! mindopt-tuner check-cloud-usage --resource tasks
! mindopt-tuner check-cloud-usage --resource machines

print("-----所有的任务：-----")
! mindopt-tuner list-tasks --page-number 1  --tasks-per-page 2
</code></pre> 
<pre><code>-----当前份额：-----
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Tuning tasks:
+-------------------------+----------------+----------------+
| Name                    | Usage          | Limit          |
+=========================+================+================+
| Number of running tasks | 0 concurrently | 3 concurrently |
+-------------------------+----------------+----------------+
| Number of saved tasks   | 26             | 1000           |
+-------------------------+----------------+----------------+
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
Computing resources:
+-----------------+----------------+----------------------+
| Name            | Usage          | Limit                |
+=================+================+======================+
| Number of evals | 0 concurrently | 200 concurrently     |
+-----------------+----------------+----------------------+
| CPU(core-hour)  | 3.79           | 160/day, max 16/eval |
+-----------------+----------------+----------------------+
| Memory(GB-hour) | 7.58           | 640/day, max 32/eval |
+-----------------+----------------+----------------------+
*Each eval is counted for minimally 1 core-hour and 1 GB-hour.
-----所有的任务：-----
OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k
+--------------------+---------+--------------+----------+---------------------+-----------------------------------------+
|                 id |   cores |   memory(GB) | status   | creation time       | file outputs                            |
+====================+=========+==============+==========+=====================+=========================================+
| 438413495201964032 |       2 |            2 | finished | 2023-04-24T18:58:42 | ['result/FINISHED',                     |
|                    |         |              |          |                     | 'result/log_mtuner.log',                |
|                    |         |              |          |                     | 'result/tuning_config_mtuner.txt',      |
|                    |         |              |          |                     | 'result/performance.txt',               |
|                    |         |              |          |                     | 'result/summary_mtuner.csv',            |
|                    |         |              |          |                     | 'result/evaluation_history_mtuner.csv', |
|                    |         |              |          |                     | 'result/best_parameters_mtuner.prm']    |
+--------------------+---------+--------------+----------+---------------------+-----------------------------------------+
| 438398626012602368 |       2 |            2 | finished | 2023-04-24T17:59:37 | ['result/FINISHED',                     |
|                    |         |              |          |                     | 'result/log_mtuner.log',                |
|                    |         |              |          |                     | 'result/tuning_config_mtuner.txt',      |
|                    |         |              |          |                     | 'result/summary_mtuner.csv',            |
|                    |         |              |          |                     | 'result/performance.txt',               |
|                    |         |              |          |                     | 'result/evaluation_history_mtuner.csv', |
|                    |         |              |          |                     | 'result/best_parameters_mtuner.prm']    |
+--------------------+---------+--------------+----------+---------------------+-----------------------------------------+
Starting page=1 / Page size=2 / Total page=13/ Total task=26
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/aa9fc6aa35ec96772c7644c4da34b3c8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">BERT和ALBERT的区别；BERT和RoBERTa的区别；与bert相关的模型总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7d6a7adb216daa0ad6a069f53756282e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python调用MindOpt求解二次规划问题的几点总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>