<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习-day1 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习-day1" />
<meta property="og:description" content="@day1 人工智能阶段 机器学习 三天 深度学习 三天 量化交易 四天 传统的机器学习算法 机器学习概述、特征工程 1天 分类算法 1天`` 回归算法、聚类 1天 机器学习概述 1.1 人工智能概述 达特茅斯会议-人工智能的起点 机器学习是人工智能的一个实现途径 深度学习是机器学习的一个方法发展而来 1.1.2 机器学习、深度学习能做些什么 传统预测 图像识别 自然语言处理 1.2 什么是机器学习 数据 模型 预测 从历史数据当中获得规律？这些历史数据是怎么的格式？ 1.2.3 数据集构成 特征值 &#43; 目标值 1.3 机器学习算法分类 监督学习 目标值：类别 - 分类问题 k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归 目标值：连续型的数据 - 回归问题 线性回归、岭回归 目标值：无 - 无监督学习 聚类 k-means 1、预测明天的气温是多少度？ 回归 2、预测明天是阴、晴还是雨？ 分类 3、人脸年龄预测？ 回归/分类 4、人脸识别？ 分类 1.4 机器学习开发流程 1）获取数据 2）数据处理 3）特征工程 4）机器学习算法训练 - 模型 5）模型评估 6）应用 1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0f0f379aaa5d4c5aed2a1422f3386f3a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-23T10:50:24+08:00" />
<meta property="article:modified_time" content="2021-09-23T10:50:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习-day1</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>@<a href="%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0" rel="nofollow">day1 </a></p> 
<ol><li> <pre><code>人工智能阶段
    机器学习 三天
    深度学习 三天
    量化交易 四天
传统的机器学习算法
    机器学习概述、特征工程 1天
    分类算法             1天``
    回归算法、聚类        1天
机器学习概述
    1.1 人工智能概述
        达特茅斯会议-人工智能的起点
        机器学习是人工智能的一个实现途径
        深度学习是机器学习的一个方法发展而来
        1.1.2 机器学习、深度学习能做些什么
            传统预测
            图像识别
            自然语言处理
    1.2 什么是机器学习
        数据
        模型
        预测
        从历史数据当中获得规律？这些历史数据是怎么的格式？
        1.2.3 数据集构成
            特征值 + 目标值
    1.3 机器学习算法分类
        监督学习
            目标值：类别 - 分类问题
                k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归
            目标值：连续型的数据 - 回归问题
                线性回归、岭回归
        目标值：无 - 无监督学习
            聚类 k-means
        1、预测明天的气温是多少度？ 回归
        2、预测明天是阴、晴还是雨？ 分类
        3、人脸年龄预测？ 回归/分类
        4、人脸识别？ 分类
    1.4 机器学习开发流程
        1）获取数据
        2）数据处理
        3）特征工程
        4）机器学习算法训练 - 模型
        5）模型评估
        6）应用
    1.5 学习框架和资料介绍
        1）算法是核心，数据与计算是基础
        2）找准定位
        3）怎么做？
            1、入门
            2、实战类书籍
            3、机器学习 -”西瓜书”- 周志华
               统计学习方法 - 李航
               深度学习 - “花书”
        4）1.5.1 机器学习库与框架
特征工程
    2.1 数据集
        2.1.1 可用数据集
            公司内部 百度
            数据接口 花钱
            数据集
            学习阶段可以用的数据集：
                1）sklearn
                2）kaggle
                3）UCI
        2.1.2 sklearn数据集
                1 Scikit-learn工具介绍
                    sklearn.datasets
                    load_*  获取小规模数据集
                    fetch_* 获取大规模数据集
                2 sklearn小数据集
                    sklearn.datasets.load_iris()
                3 sklearn大数据集 
                  sklearn.datasets.fetch_20newsgroups(data_home=None,subset=‘train’)
                4 数据集的返回值
                    datasets.base.Bunch（继承自字典）
                        data:特征数据数组
                        target:标签数组
                        DESCR:数据描述
                        feature_names:特征名，新闻数据，手写数字，回归数据集没有
                        target_names:标签名
                        dict["key"] = values
                        bunch.key = values
                思考：拿到的数据是否全部都用来训练一个模型？
        2.1.3 数据集的划分
            训练数据：用于训练，构建模型
            测试数据：在模型检验时使用，用于评估模型是否有效
                测试集 20%~30%
                sklearn.model_selection.train_test_split(arrays, options)
                训练集特征值，测试集特征值，训练集目标值，测试集目标值
                x_train, x_test, y_train, y_test    random_state:随机种子
    2.2 特征工程介绍
        算法 特征工程
        2.2.1 为什么需要特征工程(Feature Engineering)
        2.2.2 什么是特征工程
            sklearn 特征工程
            pandas 数据清洗、数据处理
                特征抽取/特征提取 （将任意数据转换成可用于机器学习的数学特征）
                机器学习算法 - 统计方法 - 数学公式
                    文本类型 -》 数值
                    类型 -》 数值
        2.3.1 特征提取
            sklearn.feature_extraction
        2.3.2 字典特征提取 - 类别 -&gt; one-hot编码
            sklearn.feature_extraction.DictVectorizer(sparse=True,…)
            vector 数学：向量 物理：矢量
                矩阵 matrix 二维数组
                向量 vector 一维数组
            父类：转换器类
                返回sparse矩阵(sparse=True)默认
                sparse稀疏
                    将非零值 按位置表示出来
                    节省内存 - 提高加载效率
                应用场景：
                    1）pclass, sex 数据集当中类别特征比较多
                        1、将数据集的特征-》字典类型
                        2、DictVectorizer转换
                    2）本身拿到的数据就是字典类型
        2.3.3 文本特征提取
            单词 作为 特征
            句子、短语、单词、字母
            特征：特征词
            方法1：CountVectorizer
                统计每个样本特征词出现的个数
                stop_words停用的词
                停用词表
                关键词：在某一个类别的文章中，出现的次数很多，但是在其他类别的文章当中出现很少
                str.join(sqe) 方法用于将序列中的元素以指定的字符连接生成一个新的字符串。
            方法2：TfidfVectorizer
                TF-IDF - 重要程度
                两个词 “经济”，“非常”
                1000篇文章-语料库
                100篇文章 - "非常"
                10篇文章 - “经济”
                两篇文章
                文章A(100词) : 10次“经济” TF-IDF:0.2
                    tf:10/100 = 0.1
                    idf:lg 1000/10 = 2
                文章B(100词) : 10次“非常” TF-IDF:0.1
                    tf:10/100 = 0.1
                    idf: log 10 1000/100 = 1
                    对数？
                        2 ^ 3 = 8
                        log 2 8 = 3
                        log 10 10 = 1
                    TF - 词频（term frequency，tf)
                    IDF - 逆向文档频率
    特征预处理
        2.4.1 什么是特征预处理 sklearn.
            为什么我们要进行归一化/标准化？
            通过一些转换函数将特征数据装换成更加适合算法模型的特征数据过程
    无量纲化
        2.4.2 归一化(通过原始数据 把数据映射到-之间）MinMaxScaler
            异常值：最大值、最小值
            X'=（x-min）/（max-min）  X“=X'*（mx-mi）+mi (mx为一列最大值，mi为最小值，一般为1-0）
        2.4.3 标准化（用原始把数据变换到均值为0，标准差为1的范围内）StandardScaler
            X'=(x - mean) / std（标准差）
            标准差：集中程度
            应用场景：
            在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。
    特征降维
        2.5.1 降维 - 降低维度
            ndarray
            维数：嵌套的层数
            0维 标量
            1维 向量
            2维 矩阵
            3维
            n维
            二维数组
                此处的降维：
                降低特征的个数
                效果：
                    特征与特征之间不相关
        2.5.2 降维（降低随机变量的个数，得到一组不相关主变量）
    特征选择（从原有特征中找出主要特征）
        Filter过滤式
            方差选择法：低方差特征过滤
            相关系数 - 特征与特征之间的相关程度
                取值范围：–1≤ r ≤+1
                皮尔逊相关系数
                0.9942
                特征与特征之间相关性很高：
                    1）选取其中一个
                    2） 加权求和
                    3）主成分分析
    主成分分析
        2.6.1 什么是主成分分析(PCA：找到一个合适的直线，通过一个矩阵运算得出主成分分析的结果)
            sklearn.decomposition.PCA(n_components=None)
            n_components
                小数 表示保留百分之多少的信息
                整数 减少到多少特征
</code></pre> </li></ol> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> TfidfVectorizer
<span class="token keyword">import</span> jieba
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

<span class="token comment"># 鸢尾花数据集</span>
<span class="token keyword">def</span> <span class="token function">datasets_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花数据集:\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花的数据集描述:\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">[</span><span class="token string">"DESCR"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看特征值的名字:\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看特征值:\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment"># 数据集划分</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练集的特征值:\n"</span><span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"----------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 字典特征抽取</span>
<span class="token keyword">def</span> <span class="token function">dict_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 字典特征抽取</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'北京'</span><span class="token punctuation">,</span> <span class="token string">'温度'</span><span class="token punctuation">:</span> <span class="token number">10</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'上海'</span><span class="token punctuation">,</span> <span class="token string">'温度'</span><span class="token punctuation">:</span> <span class="token number">20</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{<!-- --></span><span class="token string">'city'</span><span class="token punctuation">:</span> <span class="token string">'成都'</span><span class="token punctuation">,</span> <span class="token string">'温度'</span><span class="token punctuation">:</span> <span class="token number">30</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
    <span class="token comment"># 实例化一个转化器</span>
    transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment"># 调用fit_transform</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字:\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 英文本特征抽取</span>
<span class="token keyword">def</span> <span class="token function">count_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 文本特征抽取 :CountVectorizer</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"good good study"</span><span class="token punctuation">,</span> <span class="token string">"day day up"</span><span class="token punctuation">]</span>
    <span class="token comment"># 实例化一个转换对象</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>
    name_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字:\n"</span><span class="token punctuation">,</span> name_new<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 中文文本特征抽取</span>
<span class="token keyword">def</span> <span class="token function">count_chinese_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 中文文本特征抽取</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"热爱 世间 万  物"</span><span class="token punctuation">,</span> <span class="token string">"无  最   爱，无   例  外"</span><span class="token punctuation">]</span>
    <span class="token comment"># 实例化一个转换对象</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征值名称:\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"--------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># jieba分词</span>
<span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        进行中文分词:热爱世间万物--热爱 世间 万  物
        利用 jieba 进行断句
    """</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token string">" "</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># 中文文本分词</span>
<span class="token keyword">def</span> <span class="token function">count_chinese_demo2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 将中文文本进行分词</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"想让自己成为美好的人拥有热情习惯麻烦热爱生活感谢黑夜的降临才会有新的明天大概是为自己从未过好今天找的最拙劣的借口"</span><span class="token punctuation">,</span> <span class="token string">"但我也希望告别以前的自己那个把未来描述成不堪重负黯淡无光的自己"</span><span class="token punctuation">,</span>
            <span class="token string">"新的一年愿我爱的一切岁岁平安愿岁月无可回头亦不忧愁"</span><span class="token punctuation">]</span>
    data_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token comment"># 实例化一个对象</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"自己"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    data_last <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_last:\n"</span><span class="token punctuation">,</span> data_last<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字:\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 文本特征抽取</span>
<span class="token keyword">def</span> <span class="token function">tfidf_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 将中文文本进行分词</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"想让自己成为美好的人拥有热情习惯麻烦热爱生活感谢黑夜的降临才会有新的明天大概是为自己从未过好今天找的最拙劣的借口"</span><span class="token punctuation">,</span> <span class="token string">"但我也希望告别以前的自己那个把未来描述成不堪重负黯淡无光的自己"</span><span class="token punctuation">,</span>
            <span class="token string">"新的一年愿我爱的一切岁岁平安愿岁月无可回头亦不忧愁"</span><span class="token punctuation">]</span>
    data_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token comment"># 实例化一个对象</span>
    transfer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"自己"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    data_last <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span><span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_last:\n"</span><span class="token punctuation">,</span> data_last<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字:\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        <span class="token string">"---------------------------------------------------------------------------------------------------------------------------------------------------------------------------"</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 归一化</span>
<span class="token keyword">def</span> <span class="token function">minmax_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        归一化
    """</span>
    <span class="token comment"># 获取数据</span>
    <span class="token comment"># 读取文本文件</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dating.txt"</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
    <span class="token comment"># 实例化一个转换器  范围自己规范，默认0-1</span>
    tranfer <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span>feature_range<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 调用fit_transform</span>
    data_new <span class="token operator">=</span> tranfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 标准化</span>
<span class="token keyword">def</span> <span class="token function">stand_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        归一化
    """</span>
    <span class="token comment"># 获取数据</span>
    <span class="token comment"># 读取文本文件</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"dating.txt"</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
    <span class="token comment"># 实例化一个转换器  范围自己规范，默认0-1</span>
    tranfer <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 调用fit_transform</span>
    data_new <span class="token operator">=</span> tranfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 低方差过滤</span>
<span class="token keyword">def</span> <span class="token function">vari_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
        降维
    """</span>
    <span class="token comment"># 获取数据</span>
    <span class="token comment"># 读取文本文件</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"factor_returns.csv"</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
    <span class="token comment"># 实例化一个转换器  范围自己规范，默认0-1</span>
    tranfer <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 调用fit_transform</span>
    data_new <span class="token operator">=</span> tranfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token comment"># 计算俩个变量之间的相关系数</span>
    r1 <span class="token operator">=</span> pearsonr<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">"pe_ratio"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">"pb_ratio"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"相关系数:\n"</span><span class="token punctuation">,</span> r1<span class="token punctuation">)</span>
    r2 <span class="token operator">=</span> pearsonr<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'revenue'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">[</span><span class="token string">'total_expense'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"相关系数"</span><span class="token punctuation">,</span>r2<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token comment"># 主成分分析-降维</span>
<span class="token keyword">def</span> <span class="token function">pca_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    transfer<span class="token operator">=</span>PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    data_new<span class="token operator">=</span>transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data_new:\n'</span><span class="token punctuation">,</span>data_new<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token comment"># 中文文本特征抽取</span>
    <span class="token comment"># count_chinese_demo()</span>
    <span class="token comment"># 中文文本分词</span>
    <span class="token comment"># count_chinese_demo2()</span>
    <span class="token comment"># 文本特征抽取</span>
    <span class="token comment"># tfidf_demo()</span>
    <span class="token comment"># 归一化</span>
    <span class="token comment">#  minmax_demo()</span>
    <span class="token comment"># 标准化</span>
    <span class="token comment"># stand_demo()</span>
    <span class="token comment"># 低方差过滤</span>
    <span class="token comment"># vari_demo()</span>
    <span class="token comment"># 主成分分析-降维</span>
    pca_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/02c9eee7f63bf5c6a9899616cd16e252/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">The given artifact contains a string literal with a package reference ‘android.support.v4.content‘ t</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fe75246cdbedbee137c5b515f38adc51/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">软件工程的经典书籍有哪些？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>