<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>文献阅读笔记5：Cascaded Pyramid Network for Multi Person Pose Estimation - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="文献阅读笔记5：Cascaded Pyramid Network for Multi Person Pose Estimation" />
<meta property="og:description" content="文章来源：CVPR2018,COCO 2017的冠军模型文章。
主要贡献：提出了基于Cascaded Pyramid Network的多人关键点检测框架。
网络结构：
整个网络分为GlobalNet和RefineNet两个stages，采用的是top-down的策略，即先找出所有人的bounding box,再对bounding box 中的人进行关键点检测：
Global Net:
这个部分的功能是学习一个良好的特征表示，并检测出容易检测的关键点。主要是基于ResNet的架构，并在其中嵌入了U型结构，以此来保证输出为后面的层的特征中既能包含丰富的空间位置信息，又能包含足够的语义信息。在进行element-wise操作时，都进行了1×1卷积操作。Global Net最终会输出一张关键点的heat map,如图所示:
GlobalNet可以有效地定位像眼睛一样的关键点，但可能无法精确定位臀部的位置。
Refine Net:
这个部分则主要解决GlobalNet无法检测到的key points。
各个level的特征会进行相互传输，并在最后通过上采样和拼接的方法进行融合。在更深的层中堆叠了更多的bottleneck，在有效性和效率之间实现了很好的权衡
由于随着训练的进行，网络会比较关注容易检测的关键点，因此，作者通过修改训练的损失函数来选择难以检测的点，即Refine Net只对这些难检测点进行损失函数的回归。
其他改进：
soft NMS：
soft NMS会将重叠较大的框中分数较小的那个框的分数拉到很低，但仍旧保留这个框，这样召回率相对较高。hard NMS就是传统的NMS，直接将IOU大于一定阈值的框中得分较低的框直接去掉，相对召回率较低。作者将soft NMS用到了CPN网络的Person Detector中，提高了0.3的人体检测AP。
ROIAlign:
作者将目标检测算法FPN中的ROI Pooling层改成了ROIAlign，这样可以减少ROI Pooling两次量化中浮点数取整造成的rigion proposal偏差
模型性能
作者在 MS COCO test-dev ， testchallenge dataset分别将CPN网络与其它方法进行了比较：
在没有额外训练数据的情况下，一个CPN模型AP达到了72.1，使用不同ground truth heat map的CPN集成模型实现了73.0的AP。在test-challenge2017 dataset年数据集上实现了最先进的性能:72.1AP.表11显示了CPN和CPN(集成模型)在CocoMinival数据集上的性能，为COCO Minval数据集与CoCO数据集的标准Testdev或test-Change数据集之间的差别提供了参考。
遗留问题
1.哪里用到了hourglass？
2.bottleneck在Refine Net中如何发挥作用？
3.U型结构怎么发挥融合低层位置信息和高层语义信息的效果？" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/8b03d57a49b020b4f11a5dc05164bc8a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-12-12T16:28:16+08:00" />
<meta property="article:modified_time" content="2018-12-12T16:28:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">文献阅读笔记5：Cascaded Pyramid Network for Multi Person Pose Estimation</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <ul><li> <p>文章来源：CVPR2018,COCO 2017的冠军模型文章。</p> </li><li> <p>主要贡献：提出了基于Cascaded Pyramid Network的多人关键点检测框架。</p> </li><li> <p>网络结构：<br> <img src="https://images2.imgbox.com/53/ec/V2mpMvMb_o.png" alt="在这里插入图片描述"><br> 整个网络分为GlobalNet和RefineNet两个stages，采用的是top-down的策略，即先找出所有人的bounding box,再对bounding box 中的人进行关键点检测：<br> Global Net:<br> 这个部分的功能是学习一个良好的特征表示，并检测出容易检测的关键点。主要是基于ResNet的架构，并在其中嵌入了U型结构，以此来保证输出为后面的层的特征中既能包含丰富的空间位置信息，又能包含足够的语义信息。在进行element-wise操作时，都进行了1×1卷积操作。Global Net最终会输出一张关键点的heat map,如图所示:<br> <img src="https://images2.imgbox.com/2a/9a/ff3v6QXo_o.png" alt="在这里插入图片描述">GlobalNet可以有效地定位像眼睛一样的关键点，但可能无法精确定位臀部的位置。<br> Refine Net:<br> 这个部分则主要解决GlobalNet无法检测到的key points。<br> 各个level的特征会进行相互传输，并在最后通过上采样和拼接的方法进行融合。在更深的层中堆叠了更多的bottleneck，在有效性和效率之间实现了很好的权衡<br> 由于随着训练的进行，网络会比较关注容易检测的关键点，因此，作者通过修改训练的损失函数来选择难以检测的点，即Refine Net只对这些难检测点进行损失函数的回归。</p> </li><li> <p>其他改进：<br> soft NMS：<br> soft NMS会将重叠较大的框中分数较小的那个框的分数拉到很低，但仍旧保留这个框，这样召回率相对较高。hard NMS就是传统的NMS，直接将IOU大于一定阈值的框中得分较低的框直接去掉，相对召回率较低。作者将soft NMS用到了CPN网络的Person Detector中，提高了0.3的人体检测AP。</p> <p>ROIAlign:<br> 作者将目标检测算法FPN中的ROI Pooling层改成了ROIAlign，这样可以减少ROI Pooling两次量化中浮点数取整造成的rigion proposal偏差</p> </li><li> <p>模型性能<br> 作者在 MS COCO test-dev ， testchallenge dataset分别将CPN网络与其它方法进行了比较：<br> <img src="https://images2.imgbox.com/fa/d1/hKXONzsq_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/66/cd/9QoT1LEX_o.png" alt="在这里插入图片描述"><br> 在没有额外训练数据的情况下，一个CPN模型AP达到了72.1，使用不同ground truth heat map的CPN集成模型实现了73.0的AP。在test-challenge2017 dataset年数据集上实现了最先进的性能:72.1AP.表11显示了CPN和CPN(集成模型)在CocoMinival数据集上的性能，为COCO Minval数据集与CoCO数据集的标准Testdev或test-Change数据集之间的差别提供了参考。</p> </li><li> <p>遗留问题<br> 1.哪里用到了hourglass？<br> 2.bottleneck在Refine Net中如何发挥作用？<br> 3.U型结构怎么发挥融合低层位置信息和高层语义信息的效果？</p> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/99d4a3d3cebcdb9e786b93670a3bd077/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[20181212]bash shell 字符串 补零.txt</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/351109611ee85cbec3f0fe66a183a3ac/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python 中 if not 的用法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>