<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【深度学习】深度学习基础-Warm_up训练策略 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【深度学习】深度学习基础-Warm_up训练策略" />
<meta property="og:description" content="背景 学习率是最影响性能的超参数之一，如果我们只能调整一个超参数，那么最好的选择就是它。 其实在我们的大多数情况下，遇到 loss 变成 NaN 的情况大多数是由于学习率选择不当引起的。
warmup介绍 warmup可以称为训练热身。由于神经网络在刚开始训练的时候是非常不稳定的，因此刚开始的学习率应当设置得很低很低，这样可以保证网络能够具有良好的收敛性。但是较低的学习率会使得训练过程变得非常缓慢，因此这里会采用以较低学习率逐渐增大至较高学习率的方式实现网络训练的“热身”阶段，随着训练的进行学习率慢慢变大，到了一定程度，以设置的初始学习率进行训练，接着过了一些inter后，学习率再慢慢变小；学习率变化：上升——平稳——下降；
warmup具体步骤 启用warm up，设置warm up setp（一般等于epoch*iter_one_epoch），当step小于warm up setp时，学习率等于基础学习率×(当前step/warmup_step)，由于后者是一个小于1的数值，因此在整个warm up的过程中，学习率是一个递增的过程！当warm up结束后，学习率以基础学习率进行训练，再学习率开始递减。
warmup学习率计算公式：
其中base_lr是初始学习率，后面分式就是用来控制warm_up操作的，分子是模型训练当前迭代的step步数，分母中warm_epoch是设置的热身的epoch数(例如另epoch=5)，iter_one_epoch是训练集迭代一个epoch需要的步数。
从上式中可以看出，前warm_epoch个训练阶段，随着step增加，学习率是递增的，一直到warm_epoch时，分子等于分母，此时学习率增长到初始学习率的值，warmup阶段完成。
学习率变化曲线： 应用场景 （1）训练出现NaN：当网络非常容易nan时候，采用warm up进行训练，可使得网络正常训练；
（2）过拟合：训练集损失很低，准确率高，但测试集损失大，准确率低，可用warm up；
应用原理 这个问题目前还没有被充分证明，目前效果有：
（1）有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳；
（2）有助于保持模型深层的稳定性。
参考链接：https://blog.csdn.net/weixin_40051325/article/details/107465843" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d0de637089270bcab6bcd54a1228b936/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-07T14:50:04+08:00" />
<meta property="article:modified_time" content="2021-09-07T14:50:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【深度学习】深度学习基础-Warm_up训练策略</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>背景</h4> 
<p>        学习率是最影响性能的超参数之一，如果我们只能调整一个超参数，那么最好的选择就是它。 其实在我们的大多数情况下，<strong>遇到 loss 变成 NaN 的情况大多数是由于学习率选择不当引起的</strong>。</p> 
<h4>warmup介绍</h4> 
<p>        warmup可以称为训练热身。由于神经网络在刚开始训练的时候是非常不稳定的，因此<strong>刚开始的学习率应当设置得很低很低</strong>，这样可以保证网络能够具有良好的收敛性。但是较低的学习率会使得训练过程变得非常缓慢，因此这里会<strong>采用以较低学习率逐渐增大至较高学习率的方式实现网络训练的“热身”阶段</strong>，随着训练的进行学习率慢慢变大，到了一定程度，以设置的初始学习率进行训练，接着过了一些inter后，学习率再慢慢变小；<span style="color:#fe2c24;">学习率变化：<strong>上升——平稳——下降</strong></span>；</p> 
<p></p> 
<h4>warmup具体步骤</h4> 
<p>        启用warm up，设置warm up setp（一般等于epoch*iter_one_epoch），当step小于warm up setp时，学习率等于基础学习率×(当前step/warmup_step)，由于后者是一个小于1的数值，因此在整个warm up的过程中，学习率是一个递增的过程！当warm up结束后，学习率以基础学习率进行训练，再学习率开始递减。</p> 
<p><strong>warmup学习率计算公式：</strong></p> 
<p><img alt="" height="78" src="https://images2.imgbox.com/60/ff/wZEmmEok_o.png" width="325"></p> 
<p>        其中base_lr是初始学习率，后面分式就是用来控制warm_up操作的，分子是模型训练当前迭代的step步数，分母中warm_epoch是设置的热身的epoch数(例如另epoch=5)，iter_one_epoch是训练集迭代一个epoch需要的步数。</p> 
<p>        从上式中可以看出，前warm_epoch个训练阶段，随着step增加，学习率是递增的，一直到warm_epoch时，分子等于分母，此时学习率增长到初始学习率的值，<strong>warmup阶段完成。</strong></p> 
<h4>学习率变化曲线：</h4> 
<p><img alt="" height="363" src="https://images2.imgbox.com/8e/0d/GZgwYlyH_o.png" width="481"></p> 
<h4>应用场景</h4> 
<p>（1）训练出现NaN：当网络非常容易nan时候，采用warm up进行训练，可使得网络正常训练；</p> 
<p>（2）过拟合：训练集损失很低，准确率高，但测试集损失大，准确率低，可用warm up；</p> 
<h4>应用原理</h4> 
<p>这个问题目前还没有被充分证明，目前效果有：<br> （1）有助于减缓模型在初始阶段对mini-batch的提前过拟合现象，保持分布的平稳；<br> （2）有助于保持模型深层的稳定性。</p> 
<p></p> 
<p>参考链接：<a href="https://blog.csdn.net/weixin_40051325/article/details/107465843">https://blog.csdn.net/weixin_40051325/article/details/107465843</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c3bec0c92242cedc153247e9a97e040a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python解决读取文件时中文乱码的解决方案</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dc3996064c0a7fa7bc4b1889a804b9d6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">this 的指向问题和箭头函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>