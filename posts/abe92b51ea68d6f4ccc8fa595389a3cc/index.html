<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>图像分割之图割（Graph Cut） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="图像分割之图割（Graph Cut）" />
<meta property="og:description" content="基本概念 这里介绍一种用于n维图像数据的边界优化和区域分割的分割技术。该分割算法来自论文：Interactive Graph Cuts for Optimal Boundary &amp; Region Segmentation of Objects in N-D Images。该方法通过交互式的或自动的定位一个或多个代表“物体”的点以及一个或多个代表“背景”的点来进行初始化—这些点被称作种子（Seed并被用于分割的硬约束（hard constraints）。另外的软约束（soft constraints）反映了边界和/或区域信息。基本原理如下图：
图弧的权重计算如下。
示例演示 我们利用OpenCV的GCGraph(实现最大流最小割)实现了Graph Cut算法。下面是核心算法的代码，完整的工程代码链接。
cv::Mat GraphCut::runInitially(const std::vector&lt;cv::Point&gt; &amp;objectseeds, const std::vector&lt;cv::Point&gt; &amp;backgroundseeds) { Mat image; // copy of image_ for computing if (image_.channels() == 3) { cvtColor(image_, image, cv::COLOR_RGB2GRAY); } else { image_.copyTo(image); } //update mask and compute intensity distributions uchar objecthist[256] = { 0 }; int objectcount = 0; uchar backgroundhist[256] = { 0 }; int backgroundcount = 0; uchar pixel = 0; for (auto &amp;p : objectseeds) { pixel = image." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/abe92b51ea68d6f4ccc8fa595389a3cc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-11T11:09:15+08:00" />
<meta property="article:modified_time" content="2019-08-11T11:09:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">图像分割之图割（Graph Cut）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>基本概念</h2> 
<p>        这里介绍一种用于n维图像数据的边界优化和区域分割的分割技术。该分割算法来自论文：<a href="https://static.aminer.org/pdf/PDF/000/292/851/demonstration_of_segmentation_with_interactive_graph_cuts.pdf" rel="nofollow">Interactive Graph Cuts for Optimal Boundary &amp; Region Segmentation of Objects in N-D Images</a>。该方法通过交互式的或自动的定位一个或多个代表“物体”的点以及一个或多个代表“背景”的点来进行初始化—这些点被称作种子（Seed并被用于分割的硬约束（hard constraints）。另外的软约束（soft constraints）反映了边界和/或区域信息。基本原理如下图：<br> <img src="https://images2.imgbox.com/80/89/PgulWFYs_o.png" alt="在这里插入图片描述"><br> 图弧的权重计算如下。<br> <img src="https://images2.imgbox.com/99/b9/xGPSPZsl_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_6"></a>示例演示</h2> 
<p>        我们利用OpenCV的GCGraph(实现最大流最小割)实现了Graph Cut算法。下面是核心算法的代码，<a href="https://github.com/webzhuce07/Digital-Image-Processing/tree/master/Segment/GraphCut">完整的工程代码链接</a>。</p> 
<pre><code>cv::Mat GraphCut::runInitially(const std::vector&lt;cv::Point&gt; &amp;objectseeds, const std::vector&lt;cv::Point&gt; &amp;backgroundseeds)
{
	Mat image; // copy of image_ for computing
	if (image_.channels() == 3)
	{
		cvtColor(image_, image, cv::COLOR_RGB2GRAY);
	}
	else
	{
		image_.copyTo(image);
	}
	
	//update mask and compute intensity distributions
	uchar objecthist[256] = { 0 };
	int objectcount = 0;
	uchar backgroundhist[256] = { 0 };
	int backgroundcount = 0;
	uchar pixel = 0;
	for (auto &amp;p : objectseeds)
	{
		pixel = image.at&lt;uchar&gt;(p);
		++objecthist[pixel];
		++objectcount;
		mask_.at&lt;uchar&gt;(p) = OBJECT;
	}
	for (auto &amp;p : backgroundseeds)
	{
		pixel = image.at&lt;uchar&gt;(p);
		++backgroundhist[pixel];
		++backgroundcount;
		mask_.at&lt;uchar&gt;(p) = BACKGROUND;
	}

	//compute weight and create graph
	int vtxCount = image.cols * image.rows,
		edgeCount = 2 * (4 * image.cols * image.rows - 3 * (image.cols + image.rows) + 2);
	graph_.create(vtxCount, edgeCount);
	std::vector&lt;cv::Point&gt; neighbors;
	neighbors.push_back({ -1, 0 }); //left
	neighbors.push_back({ 1, 0 }); //right
	neighbors.push_back({ 0, -1 }); //up
	neighbors.push_back({ 0, 1 }); //down

	neighbors.push_back({ -1, -1 }); //left-up
	neighbors.push_back({ -1, 1 }); //left-down
	neighbors.push_back({ 1, -1 }); //right-up
	neighbors.push_back({ 1, 1 }); //right-down
	Point p, neighborp;

	//compute neighbor weights(B{p,q}) and K
	std::vector&lt;std::vector&lt;double&gt;&gt; neighborweights;
	neighborweights.reserve(vtxCount);
	double maxsum = 0.0, sum = 0.0, weight = 0;
	uchar neighborpixel = 0;
	for (p.y = 0; p.y &lt; image.rows; p.y++)
	{
		for (p.x = 0; p.x &lt; image.cols; p.x++)
		{
			pixel = image.at&lt;uchar&gt;(p);
			std::vector&lt;double&gt; weights;
			sum = 0.0;
			for (auto &amp;offset : neighbors)
			{
				neighborp.x = p.x + offset.x;
				neighborp.y = p.y + offset.y;
				if (neighborp.x &lt; 0 || neighborp.x &gt;= image.cols ||
					neighborp.y &lt; 0 || neighborp.y &gt;= image.rows)
				{
					weights.push_back(0.0);
					continue;
				}
				neighborpixel = image.at&lt;uchar&gt;(neighborp);
				weight = -1.0 * std::pow((pixel - neighborpixel), 2) / (2.0 * std::pow(sigma_, 2));
				weight = exp(weight) / std::sqrt(std::pow(offset.x, 2) + std::pow(offset.y, 2));
				weights.push_back(weight);
				sum += weight;				
			}
			neighborweights.push_back(weights);
			if (maxsum &lt; sum)
				maxsum = sum;
		}
	}
	double k = 1 + maxsum;

	neighbors.clear();
	neighbors.push_back({ -1, 0 }); //left
	//neighbors.push_back({ 1, 0 }); //right
	neighbors.push_back({ 0, -1 }); //up
	//neighbors.push_back({ 0, 1 }); //down

	neighbors.push_back({ -1, -1 }); //left-up
	//neighbors.push_back({ -1, 1 }); //left-down
	neighbors.push_back({ 1, -1 }); //right-up
	//neighbors.push_back({ 1, 1 }); //right-down

	for (p.y= 0;  p.y &lt; image.rows; p.y++)
	{
		for (p.x = 0; p.x &lt; image.cols; p.x++)
		{
			// add node
			int vtxIdx = graph_.addVtx();
			pixel = image.at&lt;uchar&gt;(p);

			// set t-weights
			double fromSource, toSink;
			if (mask_.at&lt;uchar&gt;(p) == NO_INDICATING)
			{
				//Pr(0, 1)
				fromSource = -log(std::max((int)backgroundhist[pixel], 1) / (double)backgroundcount) * lambda_;
				toSink = -log(std::max((int)objecthist[pixel], 1) / (double)objectcount) * lambda_;
				//std::cout &lt;&lt; fromSource &lt;&lt; " " &lt;&lt; toSink &lt;&lt; std::endl;
			}
			else if (mask_.at&lt;uchar&gt;(p) == BACKGROUND)
			{
				fromSource = 0;
				toSink = k;
			}
			else // OBJECT
			{
				fromSource = k;
				toSink = 0;
			}
			graph_.addTermWeights(vtxIdx, fromSource, toSink);

			// set n-weights
			for (int i = 0;i &lt; neighbors.size(); i++)
			{
				auto &amp;offset = neighbors[i];
				neighborp.x = p.x + offset.x;
				neighborp.y = p.y + offset.y;
				if (neighborp.x &lt; 0 || neighborp.x &gt;= image.cols ||
					neighborp.y &lt; 0 || neighborp.y &gt;= image.rows)
					continue;
				weight = neighborweights[p.x + p.y * image.cols][i * 2];
				graph_.addEdges(vtxIdx, vtxIdx + offset.x + offset.y * image.cols, weight, weight);
			}	
		}
		
	}

	//result
	Mat result;
	image_.copyTo(result);
	graph_.maxFlow();
	for (p.y = 0; p.y &lt; result.rows; p.y++)
	{
		for (p.x = 0; p.x &lt; result.cols; p.x++)
		{
			if (!graph_.inSourceSegment(p.y * image.cols + p.x /*vertex index*/))
			{
				if(result.channels() == 1)
					result.at&lt;uchar&gt;(p) = 0;
				else
				{
					result.at&lt;cv::Vec3b&gt;(p)[0] = 0;
					result.at&lt;cv::Vec3b&gt;(p)[1] = 0;
					result.at&lt;cv::Vec3b&gt;(p)[2] = 255;
				}
			}			
		}
	}
	return result;
}
</code></pre> 
<h3><a id="_173"></a>运行结果</h3> 
<p><img src="https://images2.imgbox.com/61/bf/YwZJH9UE_o.gif" alt="在这里插入图片描述"></p> 
<h2><a id="_175"></a>参考资料</h2> 
<ul><li>图像处理、分析与机器视觉[M]</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/439d01d10cc6242f7289f0e6e29a537f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">01背包问题  图解&#43;详细解析 （转载）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2565cf5d6b74922a6ccae5a3e605dc2b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">神经网络中参数权重w,偏置b的作用（为何需要偏置b的解释）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>