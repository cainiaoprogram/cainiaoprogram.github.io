<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习（手写数字识别） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习（手写数字识别）" />
<meta property="og:description" content="欢迎大家关注我的B站：
偷吃薯片的Zheng同学的个人空间-偷吃薯片的Zheng同学个人主页-哔哩哔哩视频 (bilibili.com)
本程序采用百度paddlepaddle深度学习框架，并在百度AI Studio平台上运行
目录
1 实验内容
2 实验流程
3 DNN模型
4 LeNet 模型
4.1 LeNet-1模型
4.2 Lenet-4 模型
4.3 LeNet-5 模型
4.4 LeNet 模型的总结
4.5 LeNet 模型与DNN模型比较
5 模型的应用
5.1 自己的手写数字图片
5.2将手写的图片进行预处理
5.3调用训练好的模型进行预测
5.4 总结
1 实验内容 本次实验采用构造 DNN 模型与 LeNet 模型进行手写数字识别实验，采用经典手写数字识别数据集 MINIST，MINIST 数据集包含60000个训练集与10000个测试集。数据集分为图片与标签，其中图片是28*28的像素矩阵，标签为 0~9 共10个数字。该数据集的官方网址为MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges
2 实验流程 在实验过程中为确保最终训练的神经网络拥有较强的泛化能力，本次实验会在最后对自己手写的一些数字图片进行识别。
3 DNN模型 以下的代码判断就是定义一个简单的 DNN模型（多层感知器），一共有三层，两个大小为100的隐层和一个大小为10的输出层，因为MNIST数据集是手写0到9的灰度图像，类别有10个，所以最后的输出大小是10。最后输出层的激活函数是Softmax，所以最后的输出层相当于一个分类器。加上一个输入层的话，多层感知器的结构是：输入层--&gt;&gt;隐层--&gt;&gt;隐层--&gt;&gt;输出层。神经网络结构如下
利用 paddlepaddle 的动态图对初始的 DNN 模型进行定义，代码如下" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a0cddc0cb86d696b08db48e1ffa95c9c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-25T17:12:03+08:00" />
<meta property="article:modified_time" content="2023-12-25T17:12:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习（手写数字识别）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><span style="color:#fe2c24;"><strong>欢迎大家关注我的B站：</strong></span></p> 
<p><a href="https://space.bilibili.com/1353527764?spm_id_from=333.1007.0.0" rel="nofollow" title="偷吃薯片的Zheng同学的个人空间-偷吃薯片的Zheng同学个人主页-哔哩哔哩视频 (bilibili.com)">偷吃薯片的Zheng同学的个人空间-偷吃薯片的Zheng同学个人主页-哔哩哔哩视频 (bilibili.com)</a></p> 
<p><strong>本程序采用百度paddlepaddle深度学习框架，并在百度AI Studio平台上运行</strong></p> 
<p><strong>目录</strong></p> 
<p style="margin-left:0px;"><a href="#1%20%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9" rel="nofollow">1 实验内容</a></p> 
<p style="margin-left:0px;"><a href="#2%20%E5%AE%9E%E9%AA%8C%E6%B5%81%E7%A8%8B" rel="nofollow">2 实验流程</a></p> 
<p style="margin-left:0px;"><a href="#3%20DNN%E6%A8%A1%E5%9E%8B" rel="nofollow">3 DNN模型</a></p> 
<p style="margin-left:0px;"><a href="#4%20LeNet%20%E6%A8%A1%E5%9E%8B" rel="nofollow">4 LeNet 模型</a></p> 
<p style="margin-left:40px;"><a href="#4.1%C2%A0LeNet-1%E6%A8%A1%E5%9E%8B" rel="nofollow">4.1 LeNet-1模型</a></p> 
<p style="margin-left:40px;"><a href="#%C2%A04.2%20Lenet-4%20%E6%A8%A1%E5%9E%8B" rel="nofollow">4.2 Lenet-4 模型</a></p> 
<p style="margin-left:40px;"><a href="#4.3%20LeNet-5%20%E6%A8%A1%E5%9E%8B" rel="nofollow">4.3 LeNet-5 模型</a></p> 
<p style="margin-left:40px;"><a href="#4.4%20LeNet%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%80%BB%E7%BB%93" rel="nofollow">4.4 LeNet 模型的总结</a></p> 
<p style="margin-left:40px;"><a href="#4.5%20LeNet%20%E6%A8%A1%E5%9E%8B%E4%B8%8EDNN%E6%A8%A1%E5%9E%8B%E6%AF%94%E8%BE%83" rel="nofollow">4.5 LeNet 模型与DNN模型比较</a></p> 
<p style="margin-left:0px;"><a href="#5%20%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BA%94%E7%94%A8" rel="nofollow">5 模型的应用</a></p> 
<p style="margin-left:40px;"><a href="#5.1%20%E8%87%AA%E5%B7%B1%E7%9A%84%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%9B%BE%E7%89%87" rel="nofollow">5.1 自己的手写数字图片</a></p> 
<p style="margin-left:40px;"><a href="#5.2%E5%B0%86%E6%89%8B%E5%86%99%E7%9A%84%E5%9B%BE%E7%89%87%E8%BF%9B%E8%A1%8C%E9%A2%84%E5%A4%84%E7%90%86" rel="nofollow">5.2将手写的图片进行预处理</a></p> 
<p style="margin-left:40px;"><a href="#5.3%E8%B0%83%E7%94%A8%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B" rel="nofollow">5.3调用训练好的模型进行预测</a></p> 
<p style="margin-left:40px;"><a href="#5.4%20%E6%80%BB%E7%BB%93" rel="nofollow">5.4 总结</a></p> 
<hr> 
<p></p> 
<h2>1 实验内容</h2> 
<p>本次实验采用构造 <strong>DNN 模型与 LeNet 模型</strong>进行手写数字识别实验，采用经典手写数字识别数据集 MINIST，MINIST 数据集包含60000个训练集与10000个测试集。数据集分为图片与标签，其中图片是28*28的像素矩阵，标签为 0~9 共10个数字。该数据集的官方网址为<a href="http://yann.lecun.com/exdb/mnist" rel="nofollow" title="MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges">MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges</a></p> 
<h2>2 实验流程</h2> 
<p>在实验过程中为确保最终训练的神经网络拥有<strong>较强的泛化能力</strong>，本次实验会在最后对<strong>自己手写</strong>的一些数字图片进行识别。</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/80/45/Hbh6Lnq5_o.png"></p> 
<h2>3 DNN模型</h2> 
<p>以下的代码判断就是定义一个简单的 DNN模型（多层感知器），一共有三层，两个大小为100的隐层和一个大小为10的输出层，因为MNIST数据集是手写<strong>0到9的灰度图像</strong>，类别有10个，所以最后的输出大小是10。最后输出层的激活函数是Softmax，所以最后的输出层相当于一个<strong>分类器</strong>。加上一个输入层的话，多层感知器的结构是：输入层--&gt;&gt;隐层--&gt;&gt;隐层--&gt;&gt;输出层。神经网络结构如下</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/48/f3/OQV1zflo_o.png"></p> 
<p> 利用 <strong>paddlepaddle 的动态图</strong>对初始的 DNN 模型进行定义，代码如下</p> 
<pre><code># 定义多层感知器 
#动态图定义多层感知器
class multilayer_perceptron(fluid.dygraph.Layer):
    def __init__(self):
        super(multilayer_perceptron,self).__init__()
        self.fc1 = Linear(input_dim=28*28, output_dim=100, act='relu')
        self.fc2 = Linear(input_dim=100, output_dim=100, act='relu')
        self.fc3 = Linear(input_dim=100, output_dim=10,act="softmax")
    def forward(self,input_):
        x = fluid.layers.reshape(input_, [input_.shape[0], -1])
        x = self.fc1(x)
        x = self.fc2(x)
        y = self.fc3(x)
        return y</code></pre> 
<p>经过一段时间的调参最终选择 <strong>optimizer 为 Adam，learning rate 为0.001，batch_size 为64，epoch为5，损失函数选择softmax</strong>，最终训练曲线与在验证集上的准确率如下</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/6d/b4/ab3mU6Yq_o.png"></p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_19,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/ee/cb/P865K0MV_o.png"></p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/4a/21/2ZlEM9Ln_o.png"></p> 
<p></p> 
<p>由以上结果可以看出DNN模型在经过调参后在测试集的准确率较高，但是由于这种三层全连接神经网络的结构过于简单，并且经典数据集量较少，所以 loss曲线与acc曲线的震荡都比较厉害，可见模型在预测时的稳定性较差，因此接下来将采用 LeNet 模型进行识别。</p> 
<h2>4 LeNet 模型</h2> 
<h3>4.1 LeNet-1模型</h3> 
<p style="text-align:justify;">在Lenet-1中, 28*28 的输入图像矩阵 --&gt; 经过卷积(卷积层4层，卷积核size为5*5，步长为1) --&gt; 4个24*24 feature maps --&gt;平均池化层(2*2 size，步长为2）--&gt;4个12*12 feature maps --&gt;经过卷积(卷积层3层，卷积核size为5*5，步长为1)--&gt; 12个8*8 feature maps平均池化层(2*2 size，步长为2）--&gt;12个4*4 feature maps --&gt; 直接全连接到10个输出。示意图如下</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/6c/ab/M2oL3dhv_o.png"></p> 
<p>定义 LeNet-1 模型的代码如下</p> 
<pre><code>import paddle
import paddle.nn.functional as F
class LeNet(paddle.nn.Layer):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=4, kernel_size=5, stride=1, padding=2)
        self.Max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=4, out_channels=12, kernel_size=5, stride=1)
        self.Max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.linear1 = paddle.nn.Linear(in_features=12*5*5, out_features=10)
def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.Max_pool1(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.Max_pool2(x)
        x = paddle.flatten(x, start_axis=1,stop_axis=-1)
        x = self.linear1(x)
        return x</code></pre> 
<p> 最终 LeNet-1模型对MINIST测试集的评估结果如下（准确率达到98.05%）</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/36/83/ZsMT6SH6_o.png"></p> 
<h3>4.2 Lenet-4 模型</h3> 
<p>在Lenet-4中, 32*32 的输入图像矩阵 --&gt; 经过卷积(卷积层4层，卷积核size为5*5，步长为1) --&gt; 4个28*28 feature maps --&gt;平均池化层(2*2 size，步长为2）--&gt;4个14*14 feature maps --&gt;经过卷积(卷积层16层，卷积核size为5*5，步长为1)--&gt; 16个10*10 feature maps平均池化层(2*2 size，步长为2）--&gt;16个5*5 feature maps --&gt; 直接全连接到120个神经元 --&gt; 直接全连接到10个输出。示意图如下</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/c8/5d/pOer5o5B_o.png"></p> 
<p>定义 LeNet-4 模型的代码如下</p> 
<pre><code>import paddle
import paddle.nn.functional as F
class LeNet(paddle.nn.Layer):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)
        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1)
        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.linear1 = paddle.nn.Linear(in_features=16*5*5, out_features=120)
        self.linear2 = paddle.nn.Linear(in_features=120, out_features=10)
def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.max_pool1(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.max_pool2(x)
        x = paddle.flatten(x, start_axis=1,stop_axis=-1)
        x = self.linear1(x)
        x = F.relu(x)
        x = self.linear2(x)
        return x</code></pre> 
<p>最终 LeNet-1模型对MINIST测试集的评估结果如下（准确率达到98.54%）</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/ef/2b/EfLFh6kk_o.png"></p> 
<h3>4.3 LeNet-5 模型</h3> 
<p>在Lenet-4中, 32*32 的输入图像矩阵 --&gt; 经过卷积(卷积层6层，卷积核size为5*5，步长为1) --&gt; 4个28*28 feature maps --&gt;平均池化层(2*2 size，步长为2）--&gt;4个14*14 feature maps --&gt;经过卷积(卷积层16层，卷积核size为5*5，步长为1)--&gt; 16个10*10 feature maps平均池化层(2*2 size，步长为2）--&gt;16个5*5 feature maps --&gt; 直接全连接到120个神经元 --&gt; 直接全连接到84个输出 --&gt; 直接全连接到10个输出。示意图如下</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/bb/91/PdiMKZAz_o.png"></p> 
<p> 定义 LeNet-5 模型的代码如下</p> 
<pre><code>
import paddle
import paddle.nn.functional as F
class LeNet(paddle.nn.Layer):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)
        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1)
        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.linear1 = paddle.nn.Linear(in_features=16*5*5, out_features=100)
        self.linear2 = paddle.nn.Linear(in_features=100, out_features=84)
        self.linear3 = paddle.nn.Linear(in_features=84, out_features=10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.max_pool1(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.max_pool2(x)
        x = paddle.flatten(x, start_axis=1,stop_axis=-1)
        x = self.linear1(x)
        x = F.relu(x)
        x = self.linear2(x)
        x = F.relu(x)
        x = self.linear3(x)
        return x</code></pre> 
<p>最终 LeNet-5模型对MINIST测试集的评估结果如下（准确率达到98.89%）</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/ef/52/zkAdM1Q2_o.png"></p> 
<h3>4.4 LeNet 模型的总结</h3> 
<p>由上述三个模型的对比可知</p> 
<p>（1）神经网络在层数增加时会有更好的识别能力，也就是为什么深层的网络泛化能力更好</p> 
<p>（2）最大池化比平均池化的效果更好，因为捕捉更尖锐的特征是识别时更关注的</p> 
<p>（3）LeNet-4与LeNet-5通过padding=2使28*28的图变成32*32的图，像素更大，识别会更精确</p> 
<p>（4）在实际代码中我采用了最大池化，与原始模型不同，目的是加速收敛，激活函数采用relu， 因为relu的拟合能力更强</p> 
<p>（5）LeNet-5效果最好，也是通常LeNet模型所指向的版本</p> 
<h3>4.5 LeNet 模型与DNN模型比较</h3> 
<p>LeNet采用卷积神经网络，通过卷积对图像的特征提取能力更强，通过共享参数使图像的平移不变性得到保证，通过池化来减少过拟合，总之在图像处理预测的问题上卷积神经网络具有更强大的能力。</p> 
<h2>5 模型的应用</h2> 
<h3>5.1 自己的手写数字图片</h3> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_16,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/11/3c/vb6Yv324_o.jpg">     <img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_14,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/81/03/Pmxwg0iy_o.jpg">     <img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_16,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/03/8d/Dsxk8cSe_o.jpg">   <img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_15,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/3d/e0/7iyzZOXq_o.jpg"> <img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_20,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/4f/e0/w339e30S_o.jpg">    </p> 
<h3>5.2将手写的图片进行预处理</h3> 
<p>为了保证训练数据的一致性（不受光照等因素影响），将图片转变成黑白图片,代码如下</p> 
<pre><code>#读取图片进行预处理
def load_image(infer_path):
    image=Image.open(infer_path).convert('L')
    image=image.resize((28, 28), Image.ANTIALIAS)
    image=np.array(image).reshape(28,28).astype(np.float32)
    image=image/255*2-1
    #将图片转化为黑白图
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            if image[i][j]&gt;0.1:
                image[i][j]=-1
            else:
                image[i][j]=1
    plt.imshow(image.reshape(28,28),cmap='gray')
    plt.show()
    return image.reshape(1,1,28,28)         </code></pre> 
<h3>5.3调用训练好的模型进行预测</h3> 
<p>代码如下</p> 
<pre><code>infer_path='微信图片_20220331172616.jpg'
#获取图片
test_data, test_label= load_image(infer_path),0 #标签值自己设定
test_data = test_data.reshape([28,28])
plt.figure(figsize=(2,2))
#展示图片
print(plt.imshow(test_data, cmap=plt.cm.binary))
print('test_data 的标签为: ' + str(test_label))
#模型预测
result = model.predict([test_data.reshape(1,1,28,28)])
#打印模型预测的结果
print('预测值为：%d' %np.argmax(result))</code></pre> 
<p>预测结果如下图</p> 
<p><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_8,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/c3/4f/NAz3oD1s_o.png"><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_8,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/a8/0b/9snE67Ml_o.png"><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_8,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/ce/d8/04wpLB6I_o.png"><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_8,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/82/8a/n10EqVDW_o.png"><img alt="watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5peg5oSPMjEyMQ==,size_7,color_FFFFFF,t_70,g_se,x_16" src="https://images2.imgbox.com/c7/d3/UAqh2aQo_o.png"></p> 
<h3>5.4 总结</h3> 
<p>虽然此次识别都正确，但是在真正的生活场景中，训练好的神经网络又不再适用，因为数字大小、位置、背景、光照、颜色等因素影响比较大，在MINIST数据集与自己手写导入的数据中，图片都是分辨率较低，外界的影响都比较相似，所以要获得一个适用于较广场景的数字手写识别神经网络，需要有包含各种环境的庞大数据集，并且还需要设计更复杂的网络模型。</p> 
<h3>5.5 完整 LeNet 模型源程序</h3> 
<pre><code>#导入需要的包
import zipfile
import os
import random
import paddle
import matplotlib.pyplot as plt
from paddle.nn import MaxPool2D,Conv2D,BatchNorm
from paddle.nn import Linear
import sys
import numpy as np
from PIL import Image
from PIL import ImageEnhance
import paddle
from multiprocessing import cpu_count
import matplotlib.pyplot as plt
import json 

#导入数据集Compose的作用是将用于数据集预处理的接口以列表的方式进行组合。
#导入数据集Normalize的作用是图像归一化处理，支持两种方式： 1. 用统一的均值和标准差值对图像的每个通道进行归一化处理； 2. 对每个通道指定不同的均值和标准差值进行归一化处理。
from paddle.vision.transforms import Compose, Normalize
transform = Compose([Normalize(mean=[127.5],std=[127.5],data_format='CHW')])
# 使用transform对数据集做归一化
print('下载并加载训练数据')
train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)
test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)
print('加载完成')

#让我们一起看看数据集中的图片是什么样子的
train_data0, train_label_0 = train_dataset[0][0],train_dataset[0][1]
train_data0 = train_data0.reshape([28,28])
plt.figure(figsize=(2,2))
print(plt.imshow(train_data0, cmap=plt.cm.binary))
print('train_data0 的标签为: ' + str(train_label_0))

#定义LeNet
import paddle
import paddle.nn.functional as F
class LeNet(paddle.nn.Layer):
    def __init__(self):
        super(LeNet, self).__init__()
        self.conv1 = paddle.nn.Conv2D(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)
        self.max_pool1 = paddle.nn.MaxPool2D(kernel_size=2,  stride=2)
        self.conv2 = paddle.nn.Conv2D(in_channels=6, out_channels=16, kernel_size=5, stride=1)
        self.max_pool2 = paddle.nn.MaxPool2D(kernel_size=2, stride=2)
        self.linear1 = paddle.nn.Linear(in_features=16*5*5, out_features=100)
        self.linear2 = paddle.nn.Linear(in_features=100, out_features=84)
        self.linear3 = paddle.nn.Linear(in_features=84, out_features=10)

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.max_pool1(x)
        x = self.conv2(x)
        x = F.relu(x)
        x = self.max_pool2(x)
        x = paddle.flatten(x, start_axis=1,stop_axis=-1)
        x = self.linear1(x)
        x = F.relu(x)
        x = self.linear2(x)
        x = F.relu(x)
        x = self.linear3(x)
        return x

from paddle.metric import Accuracy
model = paddle.Model(LeNet())   # 用Model封装模型
optim = paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters())

# 配置模型
model.prepare(
    optim,
    paddle.nn.CrossEntropyLoss(),
    Accuracy()
    )

model.fit(train_dataset,
        epochs=4,
        batch_size=128,
        verbose=1
        )

model.evaluate(test_dataset, batch_size=64, verbose=1)

#读取图片进行预处理
def load_image(infer_path):
    image=Image.open(infer_path).convert('L')
    image=image.resize((28, 28), Image.ANTIALIAS)
    image=np.array(image).reshape(28,28).astype(np.float32)
    image=image/255*2-1
    #将图片转化为黑白图
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            if image[i][j]&gt;0.1:
                image[i][j]=-1
            else:
                image[i][j]=1
    plt.imshow(image.reshape(28,28),cmap='gray')
    plt.show()
    return image.reshape(1,1,28,28)            

infer_path='xxxx.jpg'#填写照片路径
#获取图片
test_data, test_label= load_image(infer_path),0
test_data = test_data.reshape([28,28])
plt.figure(figsize=(2,2))
#展示图片
print(plt.imshow(test_data, cmap=plt.cm.binary))
print('test_data 的标签为: ' + str(test_label))
#模型预测
result = model.predict([test_data.reshape(1,1,28,28)])
#打印模型预测的结果
print('预测值为：%d' %np.argmax(result))</code></pre> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fcca4e95ddc009192bab88c514776cd0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">CS插件——CobaltStrike_CNA-权限维持</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d289805110cec1cd69396eff7f92ad95/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【pytorch】常用图像处理与数据增强方法合集（torchvision.transforms）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>