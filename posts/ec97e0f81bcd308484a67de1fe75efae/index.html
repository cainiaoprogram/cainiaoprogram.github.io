<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Resnet-18-训练实验-warm up操作 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Resnet-18-训练实验-warm up操作" />
<meta property="og:description" content=" 实验数据：cat-dog 二分类，训练集：19871 验证集：3975 实验模型：resnet-18 batchsize：128*2 （一个K80吃128张图片）
存在的问题： 对训练集 accuracy可达0.99 loss=1e-2 -3，然而验证集 accuracy 0.5，loss 很高，试了多个初始学习率（0.1 — 0.0001）都不行
解决上述问题： 采取warm up方法 ，对上述问题有点帮助
训练resnet，由于不finetune，很容易过拟合，paper《Deep Residual Learning for Image Recognition》中对cifar10的实验用了一个trick是 warm up（热身），就是先采用小的学习率（0.01）进行训练，训练了400iterations之后将学习率调整至0.1开始正式训练。
一开始不以为然，我分别用了四个初始学习率 lr=0.1; 0.01; 0.001; 0.0001; 然后每1000个iterations就降低一次lr。然而这四种初始学习率都试过之后，发现，验证集的accuracy怎么都上不去，都是0.5~0.6之间，而训练集的可以到0.99。而resnet采用了batch normalization,在caffe中，batch normalization 就有一个“坑”，就是use_global_stats 的设置问题。training时候是关闭，testing的时候是要打开，deploy也是要打开的。 对于训练集accuracy达0.99，验证集accuracy是0.5&#43;的情况，我以为是batch normalization出问题，于是乎各种捣鼓BN去了，最后试了一下warm up，网络在验证集的loss才有所下降。
来看看warm up 的loss，分别采用 0.01 0.001 0.001 0.0001，gamma=10 ；stepsize在图中已经隔断 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ec97e0f81bcd308484a67de1fe75efae/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-09-07T17:45:51+08:00" />
<meta property="article:modified_time" content="2017-09-07T17:45:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Resnet-18-训练实验-warm up操作</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>实验数据</strong>：cat-dog 二分类，训练集：19871 验证集：3975 <br> <strong>实验模型</strong>：resnet-18 <br> <strong>batchsize</strong>：128*2 （一个K80吃128张图片）</p> 
<p><strong>存在的问题</strong>： 对训练集 accuracy可达0.99 loss=1e-2 -3，然而验证集 accuracy 0.5，loss 很高，试了多个初始学习率（0.1 — 0.0001）都不行</p> 
<p><strong>解决上述问题</strong>： 采取warm up方法 ，对上述问题有点帮助</p> 
<p>训练resnet，由于不finetune，很容易过拟合，paper《Deep Residual Learning for Image Recognition》中对cifar10的实验用了一个trick是 warm up（热身），就是先采用小的学习率（0.01）进行训练，训练了400iterations之后将学习率调整至0.1开始正式训练。</p> 
<p>一开始不以为然，我分别用了四个初始学习率 lr=0.1; 0.01; 0.001; 0.0001; 然后每1000个iterations就降低一次lr。然而这四种初始学习率都试过之后，发现，验证集的accuracy怎么都上不去，都是0.5~0.6之间，而训练集的可以到0.99。而resnet采用了batch normalization,在caffe中，batch normalization 就有一个“坑”，就是use_global_stats 的设置问题。training时候是关闭，testing的时候是要打开，deploy也是要打开的。 <br> 对于训练集accuracy达0.99，验证集accuracy是0.5+的情况，我以为是batch normalization出问题，于是乎各种捣鼓BN去了，最后试了一下warm up，网络在验证集的loss才有所下降。</p> 
<p>来看看warm up 的loss，分别采用 0.01 0.001 0.001 0.0001，gamma=10 ；stepsize在图中已经隔断 <br> <img src="https://images2.imgbox.com/fd/d2/AplcXtvv_o.png" alt="lr=0.01；step=1000" title=""></p> 
<p><img src="https://images2.imgbox.com/30/f9/3zxdRXpI_o.png" alt="lr=0.001；step=500" title=""></p> 
<p><img src="https://images2.imgbox.com/c3/4c/8mTAdyjS_o.png" alt="lr=0.001；step=10000" title=""></p> 
<p><img src="https://images2.imgbox.com/49/ae/53BWSDew_o.png" alt="lr=0.001；step=1000" title=""></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b0be10a92d5a4a7af1e815c2518d19fe/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Java常见面试（8）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9361d5c1db2a053c604d15eb6d7f0ec7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">OVS&#43;DPDK</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>