<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多层多输入的CNN-LSTM时间序列回归预测（卷积神经网络-长短期记忆网络）——附代码 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="多层多输入的CNN-LSTM时间序列回归预测（卷积神经网络-长短期记忆网络）——附代码" />
<meta property="og:description" content=" 目录
摘要：
卷积神经网络(CNN)的介绍：
长短期记忆网络（LSTM）的介绍：
CNN-LSTM：
Matlab代码运行结果：
本文Matlab代码&#43;数据分享： 摘要： 本文使用CNN-LSTM混合神经网络对时间序列数据进行回归预测。本模型的输入数据个数可以自行选择，可以为多输入、也可以为单输入，使用Matlab自带的数据集进行训练，可以轻松的更换数据集以实现自己的功能。首先使用CNN网络对输入数据进行深度特征提取，然后将提取到的抽象特征进行压缩，将压缩后的数据输入后续的LSTM网络进行回归预测。相比一般的单层网络结构，本文所提出的CNN-LSTM包含了三层CNN和三层LSTM网络，因此本文网络预测的准确度有了一定的提升。
本文代码结构清晰，实现效果很好，出图美观，适合初学者进行模仿学习或用于数学建模方面。
有关于CNN-LSTM进行多输入特征分类的代码，可以看我之前发的文章。
卷积神经网络(CNN)的介绍： 卷积神经网络（ConvolutionalNeuralNetworks,CNN）能有效的提取二维图像和高维数据的特征。卷积神经网络具有减少内存占用、减少网络参数、缓解过拟合问题等优势，因此基于卷积神经网络时间序列预测模型。
卷积神经网络由输入层、隐含层和输出层组成，其中隐含层又分为卷积层、池化层和全连接层。结构如图：
（1）输入层：
输入层的作用是预处理输入的图像或数据。预处理方法能够减少数据量纲的差异对模型的影响，可以提高模型的学习效率。
（2）隐含层：
隐含层包括卷积层、池化层、全连接层，作用是完成特征的提取和学习。
（a）卷积层：卷积层中最重要的是卷积核。卷积核的个数、大小和形状，需要根据数据或图像的实际情况确定。一维卷积通常用来处理一维、二维数据或图像，二维卷积常用于二维数据矩阵的卷积操作，三维卷积常用于医学及视频处理领域的三维数据。步长是指进行卷积计算时，每次移动的格数。即步长为几时，卷积核每次向右移动几个格子。在模型训练时，可以根据需要改变步长、卷积核的大小和数量。卷积操作的具体步骤以图举例说明。图中左侧的4×4的矩阵代表输入，中间3×3的矩阵为卷积核，步长设为1，则右侧的矩阵为特征结果图。卷积操作过程为：将卷积核在输入数据或图像上每次先向右平移一个步长，将卷积核矩阵和输入数据对应位置矩阵进行内积计算，输出一个数值，放在特征结果图的对应位置上。水平方向完成卷积计算后再向下移动一个步长，重复卷积计算步骤，最终得到输入数据或图像的特征结果图，
（b）池化层：池化层也称采样层，主要作用是采样降维，即在不改变数据或图像特征的前提下，将数据的维数尽可能地降低。通过池化函数，将特征图某点替换为其相邻输出的全局特征。按照滤波器映射范围内像素点取值的不同，可分为平均池化和最大池化。平均池化：计算所有非零数据的平均值并用作输出。以2×2池化为例，左侧为卷积操作后得到的特征结果图，池化滤波器在特征结果图上每次平移两个步长，得到特征结果图被划分成四部分，分别计算非零像素点的平均值，并作为该位置的输出。
（c）全连接层：全连接层的作用是将特征映射到样本标记空间。通过全连接层将神经元权重连接，并向下一层网络传递数据信息。即通过矩阵乘法对特征向量加权求和计算，并通过激活函数得到全连接层的输出
（3）输出层：
增加一层回归层，并将全连接层的输出值输入到回归层中，得到神经网络的最后输出，即神经网络非线性映射的非线性变换结果。
长短期记忆网络（LSTM）的介绍： LSTM和循环神经网络都是链式结构，其特殊性在于LSTM加入门结构来存储细胞的状态。因为门结构的存在，随着迭代层数的增加，激活函数的反向误差仍能向下传递，避免长期依赖问题
LSTM是RNN的一种变形，隐含层加入忘记门、输入门和输出门使其不仅能接受上一层神经元的输出，还能通过门结构选择性的保留历史时刻的有用信息。
LSTM是一种含有LSTM区块（blocks）或其他的一种类神经网络，文献或其他资料中LSTM区块可能被描述成智能网络单元，因为它可以记忆不定时间长度的数值，区块中有一个gate能够决定input是否重要到能被记住及能不能被输出output。
最左边函数依情况可能成为区块的input，右边三个会经过gate决定input是否能传入区块，左边第二个为inputgate，如果这里产出近似于零，将把这里的值挡住，不会进到下一层。左边第三个是forgetgate，当这产生值近似于零，将把区块里记住的值忘掉。第四个也就是最右边的input为outputgate，他可以决定在区块记忆中的input是否能输出。
CNN-LSTM： 考虑到CNN和LSTM分别在提取高维数据特征信息和处理时间序列数据方面的优势，设计CNN-LSTM模型来预测实现序列。
卷积神经网络特有的卷积核池化操作能很好的提取数据的特征信息，而长短期记忆神经网络具有很强的记忆性，对序列化数据处理效果较好。基于两种神经网络模型的优势考虑，将两种模型组合。
Matlab代码运行结果： 本文Matlab代码&#43;数据分享： " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/25770e0a404aab365a7a8e8fffb18d78/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-19T11:01:53+08:00" />
<meta property="article:modified_time" content="2023-03-19T11:01:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多层多输入的CNN-LSTM时间序列回归预测（卷积神经网络-长短期记忆网络）——附代码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E6%91%98%E8%A6%81%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E6%91%98%E8%A6%81%EF%BC%9A" rel="nofollow">摘要：</a></p> 
<p id="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%28CNN%29%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A" rel="nofollow">卷积神经网络(CNN)的介绍：</a></p> 
<p id="%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%EF%BC%88LSTM%EF%BC%89%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%EF%BC%88LSTM%EF%BC%89%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A" rel="nofollow">长短期记忆网络（LSTM）的介绍：</a></p> 
<p id="CNN-LSTM%EF%BC%9A-toc" style="margin-left:0px;"><a href="#CNN-LSTM%EF%BC%9A" rel="nofollow">CNN-LSTM：</a></p> 
<p id="%C2%A0Matlab%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%C2%A0Matlab%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%EF%BC%9A" rel="nofollow"> Matlab代码运行结果：</a></p> 
<p id="%E6%9C%AC%E6%96%87Matlab%E4%BB%A3%E7%A0%81%2B%E6%95%B0%E6%8D%AE%E5%88%86%E4%BA%AB%EF%BC%9A%C2%A0-toc" style="margin-left:0px;"><a href="#%E6%9C%AC%E6%96%87Matlab%E4%BB%A3%E7%A0%81%2B%E6%95%B0%E6%8D%AE%E5%88%86%E4%BA%AB%EF%BC%9A%C2%A0" rel="nofollow">本文Matlab代码+数据分享： </a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E6%91%98%E8%A6%81%EF%BC%9A" style="margin-left:0px;text-align:justify;"><strong>摘要：</strong></h2> 
<p style="margin-left:0;text-align:justify;">本文使用CNN-LSTM混合神经网络对时间序列数据进行回归预测。本模型的输入数据个数可以自行选择，可以为多输入、也可以为单输入，使用Matlab自带的数据集进行训练，可以轻松的更换数据集以实现自己的功能。首先使用CNN网络对输入数据进行深度特征提取，然后将提取到的抽象特征进行压缩，将压缩后的数据输入后续的LSTM网络进行回归预测。相比一般的单层网络结构，本文所提出的CNN-LSTM包含了三层CNN和三层LSTM网络，因此本文网络预测的准确度有了一定的提升。</p> 
<p style="margin-left:0;text-align:justify;"><strong>本文代码结构清晰，实现效果很好，出图美观，适合初学者进行模仿学习或用于数学建模方面。</strong></p> 
<p style="margin-left:0;text-align:justify;"><strong>有关于CNN-LSTM进行多输入特征分类的代码，可以看我之前发的文章。</strong></p> 
<h2 id="%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C(CNN)%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A" style="margin-left:0px;text-align:justify;"><strong>卷积神经网络(CNN)的介绍：</strong></h2> 
<p style="margin-left:0;text-align:justify;">卷积神经网络（ConvolutionalNeuralNetworks,CNN）能有效的提取二维图像和高维数据的特征。卷积神经网络具有减少内存占用、减少网络参数、缓解过拟合问题等优势，因此基于卷积神经网络时间序列预测模型。</p> 
<p style="margin-left:0;text-align:justify;">卷积神经网络由输入层、隐含层和输出层组成，其中隐含层又分为卷积层、池化层和全连接层。结构如图：</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="236" src="https://images2.imgbox.com/49/2e/R9mCilkX_o.png" width="463"></p> 
<p style="margin-left:0;text-align:justify;">（1）输入层：</p> 
<p style="margin-left:0;text-align:justify;">输入层的作用是预处理输入的图像或数据。预处理方法能够减少数据量纲的差异对模型的影响，可以提高模型的学习效率。</p> 
<p style="margin-left:0;text-align:justify;">（2）隐含层：</p> 
<p style="margin-left:0;text-align:justify;">隐含层包括卷积层、池化层、全连接层，作用是完成特征的提取和学习。</p> 
<p style="margin-left:0;text-align:justify;">（a）卷积层：卷积层中最重要的是卷积核。卷积核的个数、大小和形状，需要根据数据或图像的实际情况确定。一维卷积通常用来处理一维、二维数据或图像，二维卷积常用于二维数据矩阵的卷积操作，三维卷积常用于医学及视频处理领域的三维数据。步长是指进行卷积计算时，每次移动的格数。即步长为几时，卷积核每次向右移动几个格子。在模型训练时，可以根据需要改变步长、卷积核的大小和数量。卷积操作的具体步骤以图举例说明。图中左侧的4×4的矩阵代表输入，中间3×3的矩阵为卷积核，步长设为1，则右侧的矩阵为特征结果图。卷积操作过程为：将卷积核在输入数据或图像上每次先向右平移一个步长，将卷积核矩阵和输入数据对应位置矩阵进行内积计算，输出一个数值，放在特征结果图的对应位置上。水平方向完成卷积计算后再向下移动一个步长，重复卷积计算步骤，最终得到输入数据或图像的特征结果图，</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="168" src="https://images2.imgbox.com/52/d6/VzNrLfUA_o.png" width="484"></p> 
<p style="margin-left:0;text-align:justify;">（b）池化层：池化层也称采样层，主要作用是采样降维，即在不改变数据或图像特征的前提下，将数据的维数尽可能地降低。通过池化函数，将特征图某点替换为其相邻输出的全局特征。按照滤波器映射范围内像素点取值的不同，可分为平均池化和最大池化。平均池化：计算所有非零数据的平均值并用作输出。以2×2池化为例，左侧为卷积操作后得到的特征结果图，池化滤波器在特征结果图上每次平移两个步长，得到特征结果图被划分成四部分，分别计算非零像素点的平均值，并作为该位置的输出。</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="192" src="https://images2.imgbox.com/83/84/YrLJzkUe_o.png" width="421"></p> 
<p style="margin-left:0;text-align:justify;">（c）全连接层：全连接层的作用是将特征映射到样本标记空间。通过全连接层将神经元权重连接，并向下一层网络传递数据信息。即通过矩阵乘法对特征向量加权求和计算，并通过激活函数得到全连接层的输出</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="321" src="https://images2.imgbox.com/65/14/fLhFS536_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">（3）输出层：</p> 
<p style="margin-left:0;text-align:justify;">增加一层回归层，并将全连接层的输出值输入到回归层中，得到神经网络的最后输出，即神经网络非线性映射的非线性变换结果。</p> 
<h2 id="%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%EF%BC%88LSTM%EF%BC%89%E7%9A%84%E4%BB%8B%E7%BB%8D%EF%BC%9A" style="margin-left:0px;text-align:justify;"><strong>长短期记忆网络（LSTM）的介绍：</strong></h2> 
<p style="margin-left:0;text-align:justify;">LSTM和循环神经网络都是链式结构，其特殊性在于LSTM加入门结构来存储细胞的状态。因为门结构的存在，随着迭代层数的增加，激活函数的反向误差仍能向下传递，避免长期依赖问题</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="238" src="https://images2.imgbox.com/44/1f/O9QdIXPa_o.png" width="588"></p> 
<p style="margin-left:0;text-align:justify;">LSTM是RNN的一种变形，隐含层加入忘记门、输入门和输出门使其不仅能接受上一层神经元的输出，还能通过门结构选择性的保留历史时刻的有用信息。</p> 
<p style="margin-left:0;text-align:justify;">LSTM是一种含有LSTM区块（blocks）或其他的一种类神经网络，文献或其他资料中LSTM区块可能被描述成智能网络单元，因为它可以记忆不定时间长度的数值，区块中有一个gate能够决定input是否重要到能被记住及能不能被输出output。</p> 
<p style="margin-left:0;text-align:justify;">最左边函数依情况可能成为区块的input，右边三个会经过gate决定input是否能传入区块，左边第二个为inputgate，如果这里产出近似于零，将把这里的值挡住，不会进到下一层。左边第三个是forgetgate，当这产生值近似于零，将把区块里记住的值忘掉。第四个也就是最右边的input为outputgate，他可以决定在区块记忆中的input是否能输出。</p> 
<h2 id="CNN-LSTM%EF%BC%9A" style="margin-left:0px;text-align:justify;"><strong>CNN-LSTM：</strong></h2> 
<p style="margin-left:0;text-align:justify;">考虑到CNN和LSTM分别在提取高维数据特征信息和处理时间序列数据方面的优势，设计CNN-LSTM模型来预测实现序列。</p> 
<p style="margin-left:0;text-align:justify;">卷积神经网络特有的卷积核池化操作能很好的提取数据的特征信息，而长短期记忆神经网络具有很强的记忆性，对序列化数据处理效果较好。基于两种神经网络模型的优势考虑，将两种模型组合。</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="189" src="https://images2.imgbox.com/ec/4d/G8lwePes_o.png" width="406"></p> 
<h2 id="%C2%A0Matlab%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%EF%BC%9A"> Matlab代码运行结果：</h2> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="523" src="https://images2.imgbox.com/56/bb/EgbJp0Af_o.png" width="594"><img alt="" height="1200" src="https://images2.imgbox.com/5b/09/BsF8Tefy_o.png" width="1200"></p> 
<p> </p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="1200" src="https://images2.imgbox.com/98/01/YJt4BVEW_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="1112" src="https://images2.imgbox.com/db/47/womxzCPV_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="1106" src="https://images2.imgbox.com/98/56/I1X6GTKG_o.png" width="1200"></p> 
<h2 id="%E6%9C%AC%E6%96%87Matlab%E4%BB%A3%E7%A0%81%2B%E6%95%B0%E6%8D%AE%E5%88%86%E4%BA%AB%EF%BC%9A%C2%A0">本文Matlab代码+数据分享： </h2>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5dc07c378ac9db98fcb40bb3fe4a92d5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">图像处理:傅里叶变换</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d043193f83aef3c60ce69aaa1232c2d4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python(Opencv)的特征点提取和画线匹配 - 代码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>