<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>黑马程序员---三天快速入门Python机器学习（第一天） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="黑马程序员---三天快速入门Python机器学习（第一天）" />
<meta property="og:description" content="机器学习入门 一、机器学习概述1.1 人工智能概述1.1.1 机器学习与人工智能、深度学习1.1.2 机器学习、深度学习能做什么1.1.3 人工智能阶段课程安排 1.2 什么是机器学习1.2.1 定义1.2.2 解释1.2.3 数据集构成 1.3 机器学习算法分类1.3.1 总结1.3.2 练习1.3.3 机器学习算法分类 1.4 机器学习开发流程1.5 学习框架和资料介绍1.5.1 机器学习库与框架1.5.2 书籍资料1.5.3 提深内功 二、特征工程2.1 数据集2.1.1 可用数据集2.1.2 sklearn数据集2.1.3 数据集的划分 2.2 特征工程介绍2.2.1 为什么需要特征工程2.2.2 什么是特征工程2.2.3 特征工程的位置与数据处理的比较 2.3 特征提取2.3.1 什么是特征提取2.3.2 字典特征提取2.3.3 文本特征提取 2.4 特征预处理2.4.1 什么是特征预处理2.4.2 归一化2.4.3 标准化 2.5 特征降维2.5.1 降维2.5.2 降维的两种方式2.5.3 什么是特征选择 2.6 主成分分析2.6.1 什么是主成分分析（PCA）2.6.2 案例：探究用户对物品类别的喜好细分降维 2.7 机器学习第一天总结 前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。点击跳转到网站：人工智能从入门到精通教程
一、机器学习概述 1.1 人工智能概述 1.1.1 机器学习与人工智能、深度学习 机器学习是人工智能的一个实现途径深度学习是机器学习的一种方法 1.1.2 机器学习、深度学习能做什么 传统预测：店铺销量预测、量化投资、广告推荐、企业客户分类、SQL语句安全检测分类图像识别：街道交通标志检测、人脸识别自然语言处理：文本分类、情感分析、自动聊天、文本检测 1.1.3 人工智能阶段课程安排 1.2 什么是机器学习 1.2.1 定义 机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/de46fd8e3b46075bee0013cb358fcf9c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-11T16:01:57+08:00" />
<meta property="article:modified_time" content="2022-08-11T16:01:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">黑马程序员---三天快速入门Python机器学习（第一天）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>机器学习入门</h4> 
 <ul><li><a href="#_8" rel="nofollow">一、机器学习概述</a></li><li><ul><li><a href="#11__9" rel="nofollow">1.1 人工智能概述</a></li><li><ul><li><a href="#111__10" rel="nofollow">1.1.1 机器学习与人工智能、深度学习</a></li><li><a href="#112__14" rel="nofollow">1.1.2 机器学习、深度学习能做什么</a></li><li><a href="#113__19" rel="nofollow">1.1.3 人工智能阶段课程安排</a></li></ul> 
   </li><li><a href="#12__22" rel="nofollow">1.2 什么是机器学习</a></li><li><ul><li><a href="#121__23" rel="nofollow">1.2.1 定义</a></li><li><a href="#122__25" rel="nofollow">1.2.2 解释</a></li><li><a href="#123__29" rel="nofollow">1.2.3 数据集构成</a></li></ul> 
   </li><li><a href="#13__36" rel="nofollow">1.3 机器学习算法分类</a></li><li><ul><li><a href="#131__61" rel="nofollow">1.3.1 总结</a></li><li><a href="#132__63" rel="nofollow">1.3.2 练习</a></li><li><a href="#133__70" rel="nofollow">1.3.3 机器学习算法分类</a></li></ul> 
   </li><li><a href="#14__80" rel="nofollow">1.4 机器学习开发流程</a></li><li><a href="#15__90" rel="nofollow">1.5 学习框架和资料介绍</a></li><li><ul><li><a href="#151__97" rel="nofollow">1.5.1 机器学习库与框架</a></li><li><a href="#152__99" rel="nofollow">1.5.2 书籍资料</a></li><li><a href="#153__101" rel="nofollow">1.5.3 提深内功</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_106" rel="nofollow">二、特征工程</a></li><li><ul><li><a href="#21__107" rel="nofollow">2.1 数据集</a></li><li><ul><li><a href="#211__111" rel="nofollow">2.1.1 可用数据集</a></li><li><a href="#212_sklearn_154" rel="nofollow">2.1.2 sklearn数据集</a></li><li><a href="#213__203" rel="nofollow">2.1.3 数据集的划分</a></li></ul> 
   </li><li><a href="#22__245" rel="nofollow">2.2 特征工程介绍</a></li><li><ul><li><a href="#221__246" rel="nofollow">2.2.1 为什么需要特征工程</a></li><li><a href="#222__249" rel="nofollow">2.2.2 什么是特征工程</a></li><li><a href="#223__253" rel="nofollow">2.2.3 特征工程的位置与数据处理的比较</a></li></ul> 
   </li><li><a href="#23__264" rel="nofollow">2.3 特征提取</a></li><li><ul><li><a href="#231__265" rel="nofollow">2.3.1 什么是特征提取</a></li><li><a href="#232__277" rel="nofollow">2.3.2 字典特征提取</a></li><li><a href="#233__321" rel="nofollow">2.3.3 文本特征提取</a></li></ul> 
   </li><li><a href="#24__567" rel="nofollow">2.4 特征预处理</a></li><li><ul><li><a href="#241__569" rel="nofollow">2.4.1 什么是特征预处理</a></li><li><a href="#242__584" rel="nofollow">2.4.2 归一化</a></li><li><a href="#243__634" rel="nofollow">2.4.3 标准化</a></li></ul> 
   </li><li><a href="#25__681" rel="nofollow">2.5 特征降维</a></li><li><ul><li><a href="#251__682" rel="nofollow">2.5.1 降维</a></li><li><a href="#252__685" rel="nofollow">2.5.2 降维的两种方式</a></li><li><a href="#253__689" rel="nofollow">2.5.3 什么是特征选择</a></li></ul> 
   </li><li><a href="#26__813" rel="nofollow">2.6 主成分分析</a></li><li><ul><li><a href="#261_PCA_814" rel="nofollow">2.6.1 什么是主成分分析（PCA）</a></li><li><a href="#262__871" rel="nofollow">2.6.2 案例：探究用户对物品类别的喜好细分降维</a></li></ul> 
   </li><li><a href="#27__919" rel="nofollow">2.7 机器学习第一天总结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<p><mark><strong>前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。点击跳转到网站：<a href="https://www.captainai.net/zdb" rel="nofollow">人工智能从入门到精通教程</a></strong></mark></p> 
<hr> 
<p><br><br></p> 
<h2><a id="_8"></a>一、机器学习概述</h2> 
<h3><a id="11__9"></a>1.1 人工智能概述</h3> 
<h4><a id="111__10"></a>1.1.1 机器学习与人工智能、深度学习</h4> 
<p><img src="https://images2.imgbox.com/f0/28/ko7mLPLq_o.png" alt="在这里插入图片描述"></p> 
<ul><li>机器学习是人工智能的一个实现途径</li><li>深度学习是机器学习的一种方法</li></ul> 
<h4><a id="112__14"></a>1.1.2 机器学习、深度学习能做什么</h4> 
<ul><li>传统预测：店铺销量预测、量化投资、广告推荐、企业客户分类、SQL语句安全检测分类</li><li>图像识别：街道交通标志检测、人脸识别</li><li>自然语言处理：文本分类、情感分析、自动聊天、文本检测</li></ul> 
<h4><a id="113__19"></a>1.1.3 人工智能阶段课程安排</h4> 
<p><img src="https://images2.imgbox.com/79/a6/bFYbkUMV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="12__22"></a>1.2 什么是机器学习</h3> 
<h4><a id="121__23"></a>1.2.1 定义</h4> 
<p>机器学习是从数据中自动分析获得模型，并利用模型对未知数据进行预测</p> 
<h4><a id="122__25"></a>1.2.2 解释</h4> 
<p><img src="https://images2.imgbox.com/49/11/uZMFpo2G_o.png" alt="在这里插入图片描述"><br> 对经验归纳总结，对未知事物预测</p> 
<h4><a id="123__29"></a>1.2.3 数据集构成</h4> 
<p>结构：特征值+目标值<br> <img src="https://images2.imgbox.com/44/18/hXB1Xi99_o.png" alt="在这里插入图片描述"><br> 注：</p> 
<ul><li>对于每一行数据我们可以称为样本</li><li>有些数据集可以没有目标值<br> <img src="https://images2.imgbox.com/24/5f/d1pHFFVd_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="13__36"></a>1.3 机器学习算法分类</h3> 
<p>第一种：<br> <img src="https://images2.imgbox.com/26/97/KktXCTyS_o.png" alt="在这里插入图片描述"><br> 识别猫和狗：<br> 特征值：图片<br> 目标值：猫/狗**-类别**<br> <mark>分类问题</mark><br> <br></p> 
<p>第二种：</p> 
<p><img src="https://images2.imgbox.com/cd/23/9SCewppU_o.png" alt="在这里插入图片描述"><br> 房屋价格预测：<br> 特征值：房屋的各个属性信息<br> 目标值：房屋价格**-连续型的数据**<br> <mark>回归问题</mark><br> <br></p> 
<p>第三种<br> <img src="https://images2.imgbox.com/95/44/gVW5CqW3_o.png" alt="在这里插入图片描述"><br> 特征值：人物的各个属性信息<br> 目标值：无<br> <mark>无监督学习</mark></p> 
<h4><a id="131__61"></a>1.3.1 总结</h4> 
<p><img src="https://images2.imgbox.com/b9/12/H2mOxzRi_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="132__63"></a>1.3.2 练习</h4> 
<p>说一下他们具体问题分类：<br> 1、预测明天的天气是多少度？ <mark>回归</mark><br> 2、依存明天是阴天还是晴天还是雨天？<mark>分类</mark><br> 3、人脸年龄预测？<mark>分类或回归</mark><br> 4、人脸识别？<mark>分类</mark></p> 
<h4><a id="133__70"></a>1.3.3 机器学习算法分类</h4> 
<p>监督学习：预测</p> 
<ul><li>定义：输入数据是由输入特征和目标值所组成，函数的输出可以是一个连续的值，称为<strong>回归</strong>；也可以是一个离散的值，称为<strong>分类</strong></li><li>分类：k-近邻算法、贝叶斯分类、决策树与随机森林、逻辑回归</li><li>回归：线性回归、岭回归</li></ul> 
<p>无监督学习</p> 
<ul><li>定义：输入数据是由输入特征值组成</li><li>聚类：k-means</li></ul> 
<h3><a id="14__80"></a>1.4 机器学习开发流程</h3> 
<p><img src="https://images2.imgbox.com/2c/2f/EnxkPMPs_o.png" alt="在这里插入图片描述"><br> 流程：<br> 1）获取数据<br> 2）数据处理<br> 3）特征工程<br> 4）机器学习算法训练-得到模型<br> 5）模型评估<br> 6）应用</p> 
<h3><a id="15__90"></a>1.5 学习框架和资料介绍</h3> 
<p>大部分复杂模型的算法设计都是算法工程师在做，而我们</p> 
<ul><li>分析很多的数据</li><li>分析具体的业务</li><li>应用常见的算法</li><li>特征工程、调参、优化</li></ul> 
<h4><a id="151__97"></a>1.5.1 机器学习库与框架</h4> 
<p><img src="https://images2.imgbox.com/ea/b9/aZRv4H0e_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="152__99"></a>1.5.2 书籍资料</h4> 
<p><img src="https://images2.imgbox.com/a3/c3/MyYM9CCC_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="153__101"></a>1.5.3 提深内功</h4> 
<p><img src="https://images2.imgbox.com/4d/e0/NXieKQut_o.png" alt="在这里插入图片描述"><br> <br><br></p> 
<h2><a id="_106"></a>二、特征工程</h2> 
<h3><a id="21__107"></a>2.1 数据集</h3> 
<p>目标</p> 
<ul><li>知道数据集分为<mark>训练集和测试集</mark></li><li>会使用sklearn的数据集</li></ul> 
<h4><a id="211__111"></a>2.1.1 可用数据集</h4> 
<p>Kaggle网址：<a href="https://www.kaggle.com/datasets" rel="nofollow">https://www.kaggle.com/datasets</a><br> UCI数据集网址：<a href="http://archive.ics.uci.edu/ml/" rel="nofollow"> http://archive.ics.uci.edu/ml/</a><br> scikit-learn网址： <a href="http://scikit-learn.org/stable/datasets/index.html#datasets" rel="nofollow">http://scikit-learn.org/stable/datasets/index.html#datasets</a><br> https://scikit-learn.org.cn/</p> 
<p>scikit-learn特点：</p> 
<ul><li>1、数据量小</li><li>2、方便学习</li></ul> 
<p>UCI特点：</p> 
<ul><li>1、收录了360个数据集</li><li>2、覆盖科学、生活、经济等领域</li><li>3、数据集几十万</li></ul> 
<p>Kaggle特点：</p> 
<ul><li>1、大数据竞赛平台</li><li>2、80万科学家</li><li>3、数据量巨大</li></ul> 
<p><strong>1 Scikit-learn工具介绍</strong><br> <img src="https://images2.imgbox.com/f7/1f/nSFhsAmY_o.png" alt="在这里插入图片描述"></p> 
<ul><li>Python语言的机器学习工具</li><li>Scikit-learn包括许多知名的机器学习算法的实现</li><li>Scikit-learn文档完善，容易上手，丰富的API</li><li>目前稳定版本0.19.1</li></ul> 
<p><strong>2 安装</strong></p> 
<pre><code class="prism language-python">pip install Scikit<span class="token operator">-</span>learn <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>douban<span class="token punctuation">.</span>com<span class="token operator">/</span>simple
</code></pre> 
<p>安装好之后可以通过以下命令查看是否安装成功</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> sklearn
</code></pre> 
<p><img src="https://images2.imgbox.com/e7/c4/IFwPl3Mw_o.png" alt="在这里插入图片描述"></p> 
<p>注：安装scikit-learn需要Numpy，Scipy等库</p> 
<p><strong>3 Scikit-learn包含的内容</strong><br> <img src="https://images2.imgbox.com/c3/01/SNlSVBZz_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="212_sklearn_154"></a>2.1.2 sklearn数据集</h4> 
<p><strong>1 scikit-learn数据集API介绍</strong></p> 
<ul><li><strong>sklearn.datasets.load_*()</strong>：获取小规模数据集，数据包含在datasets里</li><li><strong>sklearn.datasets.fetch_*(data_home=None)</strong>：获取大规模数据集，需要从网络上下载，函数的第一个参数是data_home，表示数据集下载的目录，默认是**~/scikit_learn_data/**</li></ul> 
<p><strong>2 sklearn小数据集</strong></p> 
<ul><li>sklearn.datasets.load_iris()：加载并返回鸢尾花数据集<br> <img src="https://images2.imgbox.com/7a/8e/lO0gL49F_o.png" alt="在这里插入图片描述"></li><li>sklearn.datasets.load_boston()：加载并返回波士顿房价数据集<br> <img src="https://images2.imgbox.com/bb/9e/ZLJ1dhKX_o.png" alt="在这里插入图片描述"></li></ul> 
<p><strong>3 sklearn大数据集</strong><br> sklearn.datasets.fetch_20newsgroups(data=None, subset=‘train’)</p> 
<ul><li>subset：‘train’或者’test’，‘all’，可选，选择要加载的数据集</li><li>训练集的‘训练’，测试集的‘测试’，两者的‘全部’</li></ul> 
<p><strong>4 sklearn数据集的使用</strong><br> sklearn数据集返回值介绍<br> load和fetch返回的数据类型datasets.base.Bunch（<strong>字典格式</strong>）</p> 
<ul><li>data：特征数据数组，是[n_samples * n_features]的二维numpy.ndarry数组</li><li>target：标签数组，是n_samples的一维numpy.ndarry数组</li><li>DESCR：数据描述</li><li>feature_names：特征名，新闻数据，手写数字、回归数据集没有</li><li>target_names：标签名</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris

<span class="token keyword">def</span> <span class="token function">datasets_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    sklearn数据集使用
    :return:
    """</span>
    <span class="token comment"># 获取数据集</span>
    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花数据集：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看数据集描述：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">[</span><span class="token string">"DESCR"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>           <span class="token comment"># 数据集的描述信息</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看特征值的名字：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看特征值：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># shape:(150,4)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    datasets_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">查看特征值的名字：
 <span class="token punctuation">[</span><span class="token string">'sepal length (cm)'</span><span class="token punctuation">,</span> <span class="token string">'sepal width (cm)'</span><span class="token punctuation">,</span> <span class="token string">'petal length (cm)'</span><span class="token punctuation">,</span> <span class="token string">'petal width (cm)'</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="213__203"></a>2.1.3 数据集的划分</h4> 
<p>机器学习一般的数据集会划分为两个部分：</p> 
<ul><li>训练数据：用于训练，构建模型</li><li>测试数据：在模型检验时使用，用于评估模型是否有效</li></ul> 
<p>划分比例：</p> 
<ul><li>训练集：70%、80%</li><li>测试集：30%、20%</li></ul> 
<p><strong>数据集划分api</strong>：sklearn.model_selection.train_test_split(arrays, *options)</p> 
<ul><li>x 数据集的特征值</li><li>y 数据集的标签值</li><li>test_size测试集的大小，一般为float</li><li>random_state随机数种子，不同的种子会造成不同的随机采样结果。相同的种子采样结果相同</li><li>return训练集特征值，测试集特征值，训练集目标值，测试集目标值</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_iris
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split


<span class="token keyword">def</span> <span class="token function">datasets_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    sklearn数据集使用
    :return:
    """</span>
    <span class="token comment"># 获取数据集</span>
    iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"鸢尾花数据集：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看数据集描述：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">[</span><span class="token string">"DESCR"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看特征值的名字：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>feature_names<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"查看特征值：\n"</span><span class="token punctuation">,</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># 150个样本</span>

    <span class="token comment"># 数据集划分  X为特征 Y为标签</span>
    x_train<span class="token punctuation">,</span> x_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>iris<span class="token punctuation">.</span>data<span class="token punctuation">,</span> iris<span class="token punctuation">.</span>target<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">22</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练集的特征值：\n"</span><span class="token punctuation">,</span> x_train<span class="token punctuation">,</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>   <span class="token comment"># 120个样本</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    datasets_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<br> 
<h3><a id="22__245"></a>2.2 特征工程介绍</h3> 
<h4><a id="221__246"></a>2.2.1 为什么需要特征工程</h4> 
<p>数据和特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已</p> 
<h4><a id="222__249"></a>2.2.2 什么是特征工程</h4> 
<p>特征工程是使用专业背景知识和技巧处理数据，使得特征能在机器学习算法上发挥更好的作用的过程<br> 意义：会直接影响机器学习的效果</p> 
<h4><a id="223__253"></a>2.2.3 特征工程的位置与数据处理的比较</h4> 
<ul><li>pandas：一个数据读取非常方便以及基本的处理格式的工具</li><li>sklearn：对于特征的处理提供了强大的接口</li></ul> 
<p>特征工程包含内容：</p> 
<ul><li>特征抽取/特征提取</li><li>特征预处理</li><li>特征降维</li></ul> 
<p>什么是特征提取？<br> <img src="https://images2.imgbox.com/34/69/LsYEoKux_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23__264"></a>2.3 特征提取</h3> 
<h4><a id="231__265"></a>2.3.1 什么是特征提取</h4> 
<p><strong>1 将任意数据（如文本或图像）转换为可用于机器学习的数字特征</strong><br> 注：特征值是为了计算机更好的去理解数据</p> 
<ul><li>字典特征提取（特征离散化）</li><li>文本特征提取</li><li>图像特征提取（深度学习再介绍）</li></ul> 
<p><strong>2 特征提取API</strong></p> 
<pre><code class="prism language-python">sklearn<span class="token punctuation">.</span>feature_extraction
</code></pre> 
<h4><a id="232__277"></a>2.3.2 字典特征提取</h4> 
<p><strong>作用：对字典数据进行特征值化</strong></p> 
<p><strong>sklearn.feature_extraction.DictVectorizer(sparse=True, …)</strong></p> 
<ul><li><strong>DictVectorizer.fit_transform(X)</strong>， X：字典或者包含字典的迭代器返回值，返回sparse矩阵</li><li><strong>DictVectorizer.inverse_transform(X)</strong>， X：array数组或者sparse矩阵 返回值：转换之前数据格式</li><li><strong>DictVectorizer.get_feature_names()</strong>：返回类别名称</li></ul> 
<p><strong>1 应用</strong><br> 对数据进行特征提取：<strong>将类别转换为one-hot编码</strong>，节省内存，提高下载效率</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction <span class="token keyword">import</span> DictVectorizer

<span class="token keyword">def</span> <span class="token function">dict_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    字典特征抽取
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">'city'</span><span class="token punctuation">:</span><span class="token string">'北京'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">{<!-- --></span><span class="token string">'city'</span><span class="token punctuation">:</span><span class="token string">'上海'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">60</span><span class="token punctuation">}</span><span class="token punctuation">,</span>
            <span class="token punctuation">{<!-- --></span><span class="token string">'city'</span><span class="token punctuation">:</span><span class="token string">'深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">:</span><span class="token number">30</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    <span class="token comment">#transfer = DictVectorizer() # 返回sparse矩阵</span>
    transfer <span class="token operator">=</span> DictVectorizer<span class="token punctuation">(</span>sparse<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform()</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new：\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>   <span class="token comment"># 转化后的</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    dict_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">data_new：
 <span class="token punctuation">[</span><span class="token punctuation">[</span>  <span class="token number">0.</span>   <span class="token number">1.</span>   <span class="token number">0.</span> <span class="token number">100.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">1.</span>   <span class="token number">0.</span>   <span class="token number">0.</span>  <span class="token number">60.</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span>  <span class="token number">0.</span>   <span class="token number">0.</span>   <span class="token number">1.</span>  <span class="token number">30.</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
 特征名字：
 <span class="token punctuation">[</span><span class="token string">'city=上海'</span><span class="token punctuation">,</span> <span class="token string">'city=北京'</span><span class="token punctuation">,</span> <span class="token string">'city=深圳'</span><span class="token punctuation">,</span> <span class="token string">'temperature'</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="233__321"></a>2.3.3 文本特征提取</h4> 
<p>单词作为特征</p> 
<p>作用：对文本数据进行特征值化</p> 
<p><strong>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])：返回词频矩阵</strong></p> 
<ul><li><strong>CountVectorizer.fit_transform(X)</strong>，X：文本或者包含文本字符串的可迭代对象，返回值：返回sparse矩阵</li><li><strong>CountVectorizer.inverse_transform(X)</strong>，X：array数组或者sparse矩阵，返回值：转换之前数据格</li><li><strong>CountVectorizer.get_feature_names()</strong>：返回值：单词列表</li></ul> 
<p><strong>sklearn.feature_extraction.text.TfidVectorizer</strong></p> 
<p><strong>1 应用</strong><br> <strong>英文文本分词</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer


<span class="token keyword">def</span> <span class="token function">count_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    文本特征抽取：CountVectorizer
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'life is short,i like like python'</span><span class="token punctuation">,</span>
            <span class="token string">'life is too long,i dislike python'</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new：\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># toarray转换为二维数组</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    count_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">data_new：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
特征名字：
 <span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">]</span>
</code></pre> 
<p>停用词：<strong>stop_words=[]</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer


<span class="token keyword">def</span> <span class="token function">count_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    文本特征抽取：CountVectorizer
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'life is short,i like like python'</span><span class="token punctuation">,</span>
            <span class="token string">'life is too long,i dislike python'</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span>stop_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'is'</span><span class="token punctuation">,</span> <span class="token string">'too'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new：\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># toarray转换为二维数组</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    count_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">data_new：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
特征名字：
 <span class="token punctuation">[</span><span class="token string">'dislike'</span><span class="token punctuation">,</span> <span class="token string">'life'</span><span class="token punctuation">,</span> <span class="token string">'like'</span><span class="token punctuation">,</span> <span class="token string">'long'</span><span class="token punctuation">,</span> <span class="token string">'python'</span><span class="token punctuation">,</span> <span class="token string">'short'</span><span class="token punctuation">]</span>
</code></pre> 
<p><strong>中文文本分词</strong><br> <mark>注意：不支持单个中文词！</mark><br> <mark>这个方法是计算特征词出现的个数的</mark></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer


<span class="token keyword">def</span> <span class="token function">count_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    文本特征抽取：CountVectorizer
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'我 爱 北京 天安门'</span><span class="token punctuation">,</span>
            <span class="token string">'天安门 上 太阳 升'</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new：\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># toarray转换为二维数组</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    count_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">data_new：
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
特征名字：
 <span class="token punctuation">[</span><span class="token string">'北京'</span><span class="token punctuation">,</span> <span class="token string">'天安门'</span><span class="token punctuation">,</span> <span class="token string">'太阳'</span><span class="token punctuation">]</span>
</code></pre> 
<p>例2</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer
<span class="token keyword">import</span> jieba


<span class="token keyword">def</span> <span class="token function">count_chinese_demo2</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    中文文本特征抽取，自动分词
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。'</span><span class="token punctuation">,</span>
            <span class="token string">'我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。'</span><span class="token punctuation">,</span>
            <span class="token string">'如果只用一种方式了解某件事物，他就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。'</span><span class="token punctuation">]</span>
    data_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>

    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> CountVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data_final <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_final:\n"</span><span class="token punctuation">,</span> data_final<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    进行中文分词：“我爱北京天安门” -&gt; "我 爱  北京 天安门"
    :param text:
    :return:
    """</span>

    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    count_chinese_demo2<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#print(cut_word('我爱北京天安门'))</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span><span class="token punctuation">,</span> <span class="token string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span><span class="token punctuation">,</span> <span class="token string">'如果 只用 一种 方式 了解 某件事 物 ， 他 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span><span class="token punctuation">]</span>
data_final<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span>
  <span class="token number">0</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">3</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span>
  <span class="token number">1</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">4</span> <span class="token number">2</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">2</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span> <span class="token number">1</span> <span class="token number">0</span> <span class="token number">0</span>
  <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
特征名字：
 <span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">,</span> <span class="token string">'之前'</span><span class="token punctuation">,</span> <span class="token string">'了解'</span><span class="token punctuation">,</span> <span class="token string">'事物'</span><span class="token punctuation">,</span> <span class="token string">'今天'</span><span class="token punctuation">,</span> <span class="token string">'光是在'</span><span class="token punctuation">,</span> <span class="token string">'几百万年'</span><span class="token punctuation">,</span> <span class="token string">'发出'</span><span class="token punctuation">,</span> <span class="token string">'取决于'</span><span class="token punctuation">,</span> <span class="token string">'只用'</span><span class="token punctuation">,</span> <span class="token string">'后天'</span><span class="token punctuation">,</span> <span class="token string">'含义'</span><span class="token punctuation">,</span> <span class="token string">'大部分'</span><span class="token punctuation">,</span> <span class="token string">'如何'</span><span class="token punctuation">,</span> <span class="token string">'如果'</span><span class="token punctuation">,</span> <span class="token string">'宇宙'</span><span class="token punctuation">,</span> <span class="token string">'我们'</span><span class="token punctuation">,</span> <span class="token string">'所以'</span><span class="token punctuation">,</span> <span class="token string">'放弃'</span><span class="token punctuation">,</span> <span class="token string">'方式'</span><span class="token punctuation">,</span> <span class="token string">'明天'</span><span class="token punctuation">,</span> <span class="token string">'星系'</span><span class="token punctuation">,</span> <span class="token string">'晚上'</span><span class="token punctuation">,</span> <span class="token string">'某件事'</span><span class="token punctuation">,</span> <span class="token string">'残酷'</span><span class="token punctuation">,</span> <span class="token string">'每个'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'秘密'</span><span class="token punctuation">,</span> <span class="token string">'绝对'</span><span class="token punctuation">,</span> <span class="token string">'美好'</span><span class="token punctuation">,</span> <span class="token string">'联系'</span><span class="token punctuation">,</span> <span class="token string">'过去'</span><span class="token punctuation">,</span> <span class="token string">'还是'</span><span class="token punctuation">,</span> <span class="token string">'这样'</span><span class="token punctuation">]</span>
</code></pre> 
<p><mark>关键词：在某一个类别的文章中，出现的次数很多，但是在其他类别的文章当中出现很少</mark></p> 
<p><strong>5 Tf-idf文本特征提取</strong></p> 
<ul><li>Tf-idf的主要思想是：如果某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分能力，适合用来分来</li><li>Tf-idf作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度<br> <mark>这种方法是计算特征词的重要程度的</mark><br> TF-IDF:衡量重要程度<br> TF：词频<br> IDF：逆向文档频率，可以<strong>由总文件数目 / 包含该词语之文件的数目，再将得到的商取以10为底的对数得到</strong></li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_extraction<span class="token punctuation">.</span>text <span class="token keyword">import</span> CountVectorizer<span class="token punctuation">,</span> TfidfVectorizer
<span class="token keyword">import</span> jieba


<span class="token keyword">def</span> <span class="token function">cut_word</span><span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    进行中文分词：“我爱北京天安门” -&gt; "我 爱  北京 天安门"
    :param text:
    :return:
    """</span>

    <span class="token keyword">return</span> <span class="token string">' '</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">tfidf_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    用TF-IDF的方法进行文本特征抽取
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。'</span><span class="token punctuation">,</span>
            <span class="token string">'我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。'</span><span class="token punctuation">,</span>
            <span class="token string">'如果只用一种方式了解某件事物，他就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。'</span><span class="token punctuation">]</span>
    data_new <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> sent <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        data_new<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cut_word<span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>

    <span class="token comment"># 1、实例化一个转换器类</span>
    transfer <span class="token operator">=</span> TfidfVectorizer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 2、调用fit_transform</span>
    data_final <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data_new<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_final:\n"</span><span class="token punctuation">,</span> data_final<span class="token punctuation">.</span>toarray<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征名字：\n"</span><span class="token punctuation">,</span> transfer<span class="token punctuation">.</span>get_feature_names<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    tfidf_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#print(cut_word('我爱北京天安门'))</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token string">'一种 还是 一种 今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。'</span><span class="token punctuation">,</span> <span class="token string">'我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。'</span><span class="token punctuation">,</span> <span class="token string">'如果 只用 一种 方式 了解 某件事 物 ， 他 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。'</span><span class="token punctuation">]</span>
data_final<span class="token punctuation">:</span>
 <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.30847454</span> <span class="token number">0.</span>         <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.40560694</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.20280347</span> <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.40560694</span> <span class="token number">0.</span>
  <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.40560694</span> <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.20280347</span> <span class="token number">0.20280347</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.20280347</span>
  <span class="token number">0.</span>        <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.2410822</span>  <span class="token number">0.2410822</span>  <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>
  <span class="token number">0.55004769</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.48216441</span> <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.2410822</span>  <span class="token number">0.</span>
  <span class="token number">0.2410822</span> <span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token number">0.12826533</span> <span class="token number">0.16865349</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.67461397</span> <span class="token number">0.33730698</span>
  <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.16865349</span> <span class="token number">0.16865349</span>
  <span class="token number">0.</span>         <span class="token number">0.16865349</span> <span class="token number">0.</span>         <span class="token number">0.16865349</span> <span class="token number">0.16865349</span> <span class="token number">0.</span>
  <span class="token number">0.12826533</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.16865349</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>         <span class="token number">0.16865349</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.33730698</span>
  <span class="token number">0.16865349</span> <span class="token number">0.</span>         <span class="token number">0.</span>         <span class="token number">0.16865349</span> <span class="token number">0.</span>         <span class="token number">0.</span>
  <span class="token number">0.</span>        <span class="token punctuation">]</span><span class="token punctuation">]</span>
特征名字：
 <span class="token punctuation">[</span><span class="token string">'一种'</span><span class="token punctuation">,</span> <span class="token string">'不会'</span><span class="token punctuation">,</span> <span class="token string">'不要'</span><span class="token punctuation">,</span> <span class="token string">'之前'</span><span class="token punctuation">,</span> <span class="token string">'了解'</span><span class="token punctuation">,</span> <span class="token string">'事物'</span><span class="token punctuation">,</span> <span class="token string">'今天'</span><span class="token punctuation">,</span> <span class="token string">'光是在'</span><span class="token punctuation">,</span> <span class="token string">'几百万年'</span><span class="token punctuation">,</span> <span class="token string">'发出'</span><span class="token punctuation">,</span> <span class="token string">'取决于'</span><span class="token punctuation">,</span> <span class="token string">'只用'</span><span class="token punctuation">,</span> <span class="token string">'后天'</span><span class="token punctuation">,</span> <span class="token string">'含义'</span><span class="token punctuation">,</span> <span class="token string">'大部分'</span><span class="token punctuation">,</span> <span class="token string">'如何'</span><span class="token punctuation">,</span> <span class="token string">'如果'</span><span class="token punctuation">,</span> <span class="token string">'宇宙'</span><span class="token punctuation">,</span> <span class="token string">'我们'</span><span class="token punctuation">,</span> <span class="token string">'所以'</span><span class="token punctuation">,</span> <span class="token string">'放弃'</span><span class="token punctuation">,</span> <span class="token string">'方式'</span><span class="token punctuation">,</span> <span class="token string">'明天'</span><span class="token punctuation">,</span> <span class="token string">'星系'</span><span class="token punctuation">,</span> <span class="token string">'晚上'</span><span class="token punctuation">,</span> <span class="token string">'某件事'</span><span class="token punctuation">,</span> <span class="token string">'残酷'</span><span class="token punctuation">,</span> <span class="token string">'每个'</span><span class="token punctuation">,</span> <span class="token string">'看到'</span><span class="token punctuation">,</span> <span class="token string">'真正'</span><span class="token punctuation">,</span> <span class="token string">'秘密'</span><span class="token punctuation">,</span> <span class="token string">'绝对'</span><span class="token punctuation">,</span> <span class="token string">'美好'</span><span class="token punctuation">,</span> <span class="token string">'联系'</span><span class="token punctuation">,</span> <span class="token string">'过去'</span><span class="token punctuation">,</span> <span class="token string">'还是'</span><span class="token punctuation">,</span> <span class="token string">'这样'</span><span class="token punctuation">]</span>
</code></pre> 
<br> 
<h3><a id="24__567"></a>2.4 特征预处理</h3> 
<p><img src="https://images2.imgbox.com/ad/14/rypgObLE_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="241__569"></a>2.4.1 什么是特征预处理</h4> 
<p><strong>通过一些转换函数，将特征数据转换成更适合算法模型的特征数据的过程</strong></p> 
<p>数值数据的<strong>无量纲化</strong>：</p> 
<ul><li><mark>归一化</mark></li><li><mark>标准化</mark></li></ul> 
<p><strong>2 特征预处理API</strong></p> 
<pre><code class="prism language-python">sklearn<span class="token punctuation">.</span>preprocessing
</code></pre> 
<p><strong>为什么要进行归一化/标准化？</strong></p> 
<ul><li>特征<strong>的单位或者大小相差较大，或者某特征的方法相比其他的特征要大出几个数量级，容易影响（支配）目标结果</strong>，使得一些算法无法学习到其它的特征<br> <img src="https://images2.imgbox.com/9f/3c/OrMMDkY2_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="242__584"></a>2.4.2 归一化</h4> 
<p><strong>1 定义</strong><br> 通过对原始的数据进行变换把数据映射到（默认为[0,1]之间）</p> 
<p><strong>2 公式</strong><br> <img src="https://images2.imgbox.com/8a/29/9cLjQzWo_o.png" alt="在这里插入图片描述"><br> <strong>3 API</strong><br> <strong>sklearn.preprocessing.MinMaxScaler(feature_range=(0,1)…)</strong><br> MinMaxScaler.fit_transform(X)，X：numpy array格式的数据[n_samples,n_features]，返回值：转换后的形式相同的array</p> 
<p><strong>4 数据计算</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler


<span class="token keyword">def</span> <span class="token function">minmax_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    归一化
    :return:
    """</span>
    <span class="token comment"># 1、获取数据</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"datingTestSet2.txt"</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data:\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>

    <span class="token comment"># 2、实例化一个转换器类</span>
    transform <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#transform = MinMaxScaler(feature_range=[2,3])</span>

    <span class="token comment"># 3、调用fit_transform</span>
    data_new <span class="token operator">=</span> transform<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    minmax_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e6/79/TOF43baq_o.png" alt="在这里插入图片描述"><br> 问题：如果有异常值会有什么影响<br> <strong>异常值：最大值，最小值</strong><br> <img src="https://images2.imgbox.com/df/db/kZ038PLJ_o.png" alt="在这里插入图片描述"><br> <strong>5 归一化总结</strong><br> 注意最大值最小值是变化的，另外，最大值与最小值非常容易受到异常值影响，<br> 所以这种方法<mark>鲁棒性较差</mark>，只适合传统精确小数据场景<br> <br></p> 
<h4><a id="243__634"></a>2.4.3 标准化</h4> 
<p><strong>1 定义</strong><br> 通过对原始数据进行变换把数据变换到<mark>均值为0，标准差为1</mark>的范围内</p> 
<p><strong>2 公式</strong><br> <img src="https://images2.imgbox.com/a1/6c/jQenTp8i_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c7/e6/2RKNPimD_o.png" alt="在这里插入图片描述"></p> 
<ul><li>对于归一化来说：如果出现异常点，影响了最大值和最小值，name结果显然会发生改变</li><li>对于标准化来说，如果出现异常点，由于具有一定数据量，少量的异常点对于平均值的影响不大，从而方差改变较小</li></ul> 
<p><strong>4 代码</strong><br> <strong>sklearn.perprocessing.StandradScaler()</strong><br> 处理之后，对每列来说，所有数据都聚集在均值为0附近，标准差为1<br> <strong>StandardScaler.fit_transform(X)</strong>，X;numpy array格式的数据[n_samples,n_features]，返回值：转化后的形状相同的array</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler<span class="token punctuation">,</span> StandardScaler


<span class="token keyword">def</span> <span class="token function">stand_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    标准化
    :return:
    """</span>
    <span class="token comment"># 1、获取数据</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"datingTestSet2.txt"</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data:\n"</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>

    <span class="token comment"># 2、实例化一个转换器类</span>
    transform <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#transform = StandardScaler(feature_range=[2,3])</span>

    <span class="token comment"># 3、调用fit_transform</span>
    data_new <span class="token operator">=</span> transform<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new:\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    stand_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e1/01/xzUe0y8Y_o.png" alt="在这里插入图片描述"><br> <strong>5 标准化总结</strong><br> 在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景</p> 
<h3><a id="25__681"></a>2.5 特征降维</h3> 
<h4><a id="251__682"></a>2.5.1 降维</h4> 
<p>降维是指在某些限定条件下，<mark>降低随机变量（特征）个数</mark>，得到<mark>一组“不相关”主变量</mark>的过程</p> 
<h4><a id="252__685"></a>2.5.2 降维的两种方式</h4> 
<ul><li><strong>特征选择</strong></li><li><strong>主成分分析（可以理解一种特征提取的方式）</strong></li></ul> 
<h4><a id="253__689"></a>2.5.3 什么是特征选择</h4> 
<p><strong>1 定义</strong><br> 数据中包含冗余或相关变量（或称特征、属性、指标等），旨在从原有特征中找出主要特征<br> <img src="https://images2.imgbox.com/3a/3b/qLfJd2fj_o.png" alt="在这里插入图片描述"><br> <strong>2 方法</strong><br> <strong>Filter过滤式：主要探究特征本身特点、特征与特征和目标值之间关联</strong></p> 
<ul><li>（1）方差选择法：低方差特征过滤</li><li>（2）相关系数：特征与特征之间的相关程度</li></ul> 
<p><strong>Embedded嵌入式：算法自动选择特征（特征与目标值之间的关联）</strong></p> 
<ul><li>（1）决策树：信息熵、信息增益</li><li>（2）正则化：L1，L2</li><li>（3）深度学习：卷积等</li></ul> 
<p><strong>3 模块</strong></p> 
<pre><code class="prism language-python">sklearn<span class="token punctuation">.</span>feature_selection
</code></pre> 
<p><strong>4 过滤式</strong><br> <strong>4.1 低方差特征过滤</strong><br> 删除低方差的一些特征</p> 
<ul><li>特征方差小：某个特征大多样本的值<strong>比较相近</strong></li><li>特征方差大：某个特征很多样本的值都有差别</li></ul> 
<p><strong>4.1.1 API</strong><br> <strong>sklearn.feature_selection.VArianceThreshold(threshold=0.0)</strong><br> 删除所有低方差特征<br> <strong>Variance.fit_transform(X)</strong>，X：numpy array格式的数据[m_sample,n_features]，返回值：训练集差异低于threadshold的特征将被删除。默认值是保留非零方差特征，即删除所有样本中具有相同值的特征</p> 
<p><strong>4.1.2 数据计算</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold


<span class="token keyword">def</span> <span class="token function">variance_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    低方差特征过滤
    :return:
    """</span>
    <span class="token comment"># 1、获取数据</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'factor_returns.csv'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data:\n'</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data:\n'</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>

    <span class="token comment"># 2、实例化一个转换器类</span>
    <span class="token comment">#transform = VarianceThreshold()</span>
    transform <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token comment"># 3、调用fit_transform</span>
    data_new <span class="token operator">=</span> transform<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    variance_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/20/5c/hXXkQG35_o.png" alt="在这里插入图片描述"><strong>4.2 相关系数</strong><br> 皮尔逊相关系数（Pearson Correlation Coefficient）：反映变量之间相关关系密切程度的统计指标</p> 
<p><strong>公式：</strong><br> <img src="https://images2.imgbox.com/a9/a1/AfN79edY_o.png" alt="在这里插入图片描述"></p> 
<p><strong>计算过程</strong><br> <img src="https://images2.imgbox.com/e4/9f/CqjHhuxg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/87/1b/s79rcmWh_o.png" alt="在这里插入图片描述"></p> 
<p><strong>4.2.3 特点</strong><br> 相关系数的值介于-1与+1之间，即-1&lt;=r&lt;=+1。其性质如下：</p> 
<ul><li>当r&gt;0时，表示两变量正相关；r&lt;0时，两变量为负相关</li><li>当|r|=1时，表示两变量为完全相关；当r=0时，表示两变量间无相关关系</li><li>当0&lt;|r|&lt;1时，表示两变量存在一定程度的相关。且|r|越接近1，两变量间线性关系越密切；|r|越接近0，表示两变量的线性相关越弱</li><li>一般可按三级划分：|r|&lt;0.4为低度相关；0.4&lt;=|r|&lt;0.7为显著相关；0.7&lt;=|r|&lt;1为高维线性相关</li></ul> 
<p><strong>4.2.4 API</strong></p> 
<pre><code class="prism language-python"> <span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr
</code></pre> 
<ul><li>x：（N.）array_like</li><li>y：（N.）array_like Returns:(Perason’s correlation coefficient, p-value)</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>feature_selection <span class="token keyword">import</span> VarianceThreshold
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>stats <span class="token keyword">import</span> pearsonr

<span class="token keyword">def</span> <span class="token function">variance_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    低方差特征过滤
    :return:
    """</span>
    <span class="token comment"># 1、获取数据</span>
    data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'factor_returns.csv'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data:\n'</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>
    data <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'data:\n'</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>

    <span class="token comment"># 2、实例化一个转换器类</span>
    <span class="token comment">#transform = VarianceThreshold()</span>
    transform <span class="token operator">=</span> VarianceThreshold<span class="token punctuation">(</span>threshold<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token comment"># 3、调用fit_transform</span>
    data_new <span class="token operator">=</span> transform<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">,</span> data_new<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

    <span class="token comment"># 计算两个变量之间的相关系数</span>
    r <span class="token operator">=</span> pearsonr<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">"pe_ratio"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>data<span class="token punctuation">[</span><span class="token string">"pb_ratio"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"相关系数：\n"</span><span class="token punctuation">,</span> r<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token boolean">None</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    variance_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><mark>相关系数看前面那个</mark><br> <img src="https://images2.imgbox.com/2e/13/y7FtJtlA_o.png" alt="在这里插入图片描述"><br> 如果特征与特征相关性很高：<br> 1）选取其中一个<br> 2）加权求和<br> 3）主成分分析</p> 
<h3><a id="26__813"></a>2.6 主成分分析</h3> 
<h4><a id="261_PCA_814"></a>2.6.1 什么是主成分分析（PCA）</h4> 
<p>定义：高维数据转换为低维数据的过程，在此过程中可能会舍弃原有数据、创造新的变量<br> 作用：是数据维数的压缩，尽可能降低原数据的维数（复杂度），损失少量信息<br> 应用：回归分析或者聚类分析中<br> <img src="https://images2.imgbox.com/c1/e9/0hTfgXSo_o.png" alt="在这里插入图片描述"></p> 
<p><strong>1 计算案例理解</strong><br> 二维降到一维</p> 
<p><strong>2 代码</strong><br> <strong>sklearn.decomposition.PCA(n_components=None)</strong></p> 
<ul><li>将数据分解为较低维度空间</li><li>n_components:</li><li> 
  <ul><li>小数：表示保留百分之多少的信息</li></ul> </li><li> 
  <ul><li>整数：减少到多少特征<br> <strong>PCA.fit_transform(X)</strong>，X：numpy array格式的数据[N_samples, n_features]，返回值：转换后指定维度的array</li></ul> </li></ul> 
<p><strong>3 数据计算</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA


<span class="token keyword">def</span> <span class="token function">pca_demo</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    PCA降维
    :return:
    """</span>
    data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">9</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
    <span class="token comment"># 1、实例化一个转换器类</span>
    transform <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># 4个特征降到2个特征</span>

    <span class="token comment"># 2、调用fit_transform</span>
    data_new <span class="token operator">=</span> transform<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new\n"</span><span class="token punctuation">,</span> data_new<span class="token punctuation">)</span>

    transform2 <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">)</span>  <span class="token comment"># 保留95%的信息</span>
    data_new2 <span class="token operator">=</span> transform2<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"data_new2\n"</span><span class="token punctuation">,</span> data_new2<span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token boolean">None</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    pca_demo<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">data_new
 <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.28620952e-15</span>  <span class="token number">3.82970843e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">5.74456265e+00</span> <span class="token operator">-</span><span class="token number">1.91485422e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5.74456265e+00</span> <span class="token operator">-</span><span class="token number">1.91485422e+00</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
data_new2
 <span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.28620952e-15</span>  <span class="token number">3.82970843e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span> <span class="token number">5.74456265e+00</span> <span class="token operator">-</span><span class="token number">1.91485422e+00</span><span class="token punctuation">]</span>
 <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">5.74456265e+00</span> <span class="token operator">-</span><span class="token number">1.91485422e+00</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="262__871"></a>2.6.2 案例：探究用户对物品类别的喜好细分降维</h4> 
<p>数据：<br> 1）order_prodects_prior.csv：订单与商品信息</p> 
<ul><li> 
  <ul><li>字段：order_id, product_id, add_to_cart_order, reordered<br> 2）products.csv：商品信息</li></ul> </li><li> 
  <ul><li>字段：product_id, product_name, aisle_id, department_id<br> 3）order.csv：用户的订单信息</li></ul> </li><li> 
  <ul><li>字段：order_id, user_id, eval_set, order_number, …<br> 4）aisles.csv：商品所属具体物品类别</li></ul> </li><li> 
  <ul><li>字段：aisle_id, aisle</li></ul> </li></ul> 
<p>处理成这个样子<br> <img src="https://images2.imgbox.com/66/6d/LYfy95q7_o.png" alt="在这里插入图片描述"><br> 需求<br> 1）需要将user_id和aisle放在同一个表中—合并<br> 2）找到user_id和aisle----交叉表和透视表</p> 
<pre><code class="prism language-python"><span class="token comment"># 1、获取数据</span>
<span class="token comment"># 2、合并表</span>
<span class="token comment"># 3、找到suer_id和aisle之间的关系</span>
<span class="token comment"># 4、PAC降维</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token comment"># 1、获取数据</span>
order_products <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./instacart/order_products__prior.csv'</span><span class="token punctuation">)</span> <span class="token comment">#32434489× 4 </span>
products <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./instacart/products.csv'</span><span class="token punctuation">)</span>  <span class="token comment"># (49688,4)</span>
orders <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./instacart/orders.csv'</span><span class="token punctuation">)</span>     <span class="token comment">#3421083 rows × 7 columns</span>
aisles <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./instacart/aisles.csv'</span><span class="token punctuation">)</span>  <span class="token comment">#(134,2)</span>
<span class="token comment"># 2、合并表'</span>
​
<span class="token comment"># 合并aisles和products</span>
tab1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>aisles<span class="token punctuation">,</span> products<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"aisle_id"</span><span class="token punctuation">,</span> <span class="token string">"aisle_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#49688 × 5 c</span>
tab2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>tab1<span class="token punctuation">,</span> order_products<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"product_id"</span><span class="token punctuation">,</span> <span class="token string">"product_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#32434489 ,8 </span>
tab3 <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>tab2<span class="token punctuation">,</span> orders<span class="token punctuation">,</span> on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"order_id"</span><span class="token punctuation">,</span> <span class="token string">"order_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#32434489 ,14 </span>
<span class="token comment"># tab3.head()</span>
<span class="token comment"># 3、找到suer_id和aisle之间的关系</span>
table <span class="token operator">=</span> pd<span class="token punctuation">.</span>crosstab<span class="token punctuation">(</span>tab3<span class="token punctuation">[</span><span class="token string">"user_id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tab3<span class="token punctuation">[</span><span class="token string">"aisle"</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#206209 rows × 134 columns</span>
data <span class="token operator">=</span> table<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span> <span class="token comment">#10000 rows × 134 columns</span>

<span class="token comment"># 4、PAC降维</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA
<span class="token comment"># 1)实例化一个转换器类</span>
transfer <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">0.95</span><span class="token punctuation">)</span>  <span class="token comment"># 保留95%的信息</span>
<span class="token comment"># 2）调用fit_transform</span>
data_new <span class="token operator">=</span> transfer<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>data<span class="token punctuation">)</span>  <span class="token comment">#(10000, 42)，由134个特征降维到42个</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/ab/bb/v6XIx2CS_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="27__919"></a>2.7 机器学习第一天总结</h3> 
<p><img src="https://images2.imgbox.com/38/8c/MM6OH4P3_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c221eddef084bb0b8a920d3f8e355593/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">黑马程序员---三天快速入门Python机器学习（第三天）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/082208aa6c0ce1bf4eb7038fe67e9627/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">物联网安全的概念</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>