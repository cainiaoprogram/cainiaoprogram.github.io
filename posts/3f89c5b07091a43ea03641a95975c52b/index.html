<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习pytorch代码流程模板（入门推荐） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习pytorch代码流程模板（入门推荐）" />
<meta property="og:description" content="从参数定义，到网络模型定义，再到训练步骤，验证步骤，测试步骤，总结了一套较为直观的模板。目录如下：
目录
一、导入包以及设置随机种子
二、以类的方式定义超参数
三、定义自己的模型
四、定义早停类(此步骤可以省略)
五、定义自己的数据集Dataset,DataLoader
六、实例化模型，设置loss，优化器等
七、开始训练以及调整lr
八、绘图
九、预测
十、运行实例参考（结合上述模型理解）
一、导入包以及设置随机种子 import numpy as np import torch import torch.nn as nn import numpy as np import pandas as pd from torch.utils.data import DataLoader, Dataset from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt import random seed = 42 torch.manual_seed(seed) np.random.seed(seed) random.seed(seed) 注：random.seed不懂的同学可看看我这篇文章：random.seed()的用法_云隐雾匿的博客-CSDN博客
二、以类的方式定义超参数 class argparse(): pass args = argparse() args.epochs, args.learning_rate, args.patience = [30, 0.001, 4] args.hidden_size, args.input_size= [40, 30] args." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/3f89c5b07091a43ea03641a95975c52b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-23T20:14:17+08:00" />
<meta property="article:modified_time" content="2023-01-23T20:14:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习pytorch代码流程模板（入门推荐）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>从参数定义，到网络模型定义，再到训练步骤，验证步骤，测试步骤，总结了一套较为直观的模板。目录如下：</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E5%AF%BC%E5%85%A5%E5%8C%85%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90-toc" style="margin-left:80px;"><a href="#%E4%B8%80%E3%80%81%E5%AF%BC%E5%85%A5%E5%8C%85%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90" rel="nofollow">一、导入包以及设置随机种子</a></p> 
<p id="%E4%BA%8C%E3%80%81%E4%BB%A5%E7%B1%BB%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9A%E4%B9%89%E8%B6%85%E5%8F%82%E6%95%B0-toc" style="margin-left:80px;"><a href="#%E4%BA%8C%E3%80%81%E4%BB%A5%E7%B1%BB%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9A%E4%B9%89%E8%B6%85%E5%8F%82%E6%95%B0" rel="nofollow">二、以类的方式定义超参数</a></p> 
<p id="%E4%B8%89%E3%80%81%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%E4%B8%89%E3%80%81%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B" rel="nofollow">三、定义自己的模型</a></p> 
<p id="%E5%9B%9B%E3%80%81%E5%AE%9A%E4%B9%89%E6%97%A9%E5%81%9C%E7%B1%BB(%E6%AD%A4%E6%AD%A5%E9%AA%A4%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5)-toc" style="margin-left:80px;"><a href="#%E5%9B%9B%E3%80%81%E5%AE%9A%E4%B9%89%E6%97%A9%E5%81%9C%E7%B1%BB%28%E6%AD%A4%E6%AD%A5%E9%AA%A4%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5%29" rel="nofollow">四、定义早停类(此步骤可以省略)</a></p> 
<p id="%E4%BA%94%E3%80%81%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86Dataset%2CDataLoader-toc" style="margin-left:80px;"><a href="#%E4%BA%94%E3%80%81%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86Dataset%2CDataLoader" rel="nofollow">五、定义自己的数据集Dataset,DataLoader</a></p> 
<p id="%E5%85%AD%E3%80%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%AE%BE%E7%BD%AEloss%EF%BC%8C%E4%BC%98%E5%8C%96%E5%99%A8%E7%AD%89-toc" style="margin-left:80px;"><a href="#%E5%85%AD%E3%80%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%AE%BE%E7%BD%AEloss%EF%BC%8C%E4%BC%98%E5%8C%96%E5%99%A8%E7%AD%89" rel="nofollow">六、实例化模型，设置loss，优化器等</a></p> 
<p id="%E4%B8%83%E3%80%81%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E4%BB%A5%E5%8F%8A%E8%B0%83%E6%95%B4lr-toc" style="margin-left:80px;"><a href="#%E4%B8%83%E3%80%81%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E4%BB%A5%E5%8F%8A%E8%B0%83%E6%95%B4lr" rel="nofollow">七、开始训练以及调整lr</a></p> 
<p id="%E5%85%AB%E3%80%81%E7%BB%98%E5%9B%BE-toc" style="margin-left:80px;"><a href="#%E5%85%AB%E3%80%81%E7%BB%98%E5%9B%BE" rel="nofollow">八、绘图</a></p> 
<p id="%E4%B9%9D%E3%80%81%E9%A2%84%E6%B5%8B-toc" style="margin-left:80px;"><a href="#%E4%B9%9D%E3%80%81%E9%A2%84%E6%B5%8B" rel="nofollow">九、预测</a></p> 
<p id="%E5%8D%81%E3%80%81%E8%BF%90%E8%A1%8C%E5%AE%9E%E4%BE%8B%E5%8F%82%E8%80%83%EF%BC%88%E7%BB%93%E5%90%88%E4%B8%8A%E8%BF%B0%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%EF%BC%89-toc" style="margin-left:80px;"><a href="#%E5%8D%81%E3%80%81%E8%BF%90%E8%A1%8C%E5%AE%9E%E4%BE%8B%E5%8F%82%E8%80%83%EF%BC%88%E7%BB%93%E5%90%88%E4%B8%8A%E8%BF%B0%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%EF%BC%89" rel="nofollow">十、运行实例参考（结合上述模型理解）</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h4 id="%E4%B8%80%E3%80%81%E5%AF%BC%E5%85%A5%E5%8C%85%E4%BB%A5%E5%8F%8A%E8%AE%BE%E7%BD%AE%E9%9A%8F%E6%9C%BA%E7%A7%8D%E5%AD%90">一、导入包以及设置随机种子</h4> 
<pre><code class="language-python">import numpy as np
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

import random
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)</code></pre> 
<p>注：random.seed不懂的同学可看看我这篇文章：<a href="https://blog.csdn.net/weixin_45684362/article/details/126415226?spm=1001.2014.3001.5502" title="random.seed()的用法_云隐雾匿的博客-CSDN博客">random.seed()的用法_云隐雾匿的博客-CSDN博客</a></p> 
<h4 id="%E4%BA%8C%E3%80%81%E4%BB%A5%E7%B1%BB%E7%9A%84%E6%96%B9%E5%BC%8F%E5%AE%9A%E4%B9%89%E8%B6%85%E5%8F%82%E6%95%B0">二、以类的方式定义超参数</h4> 
<pre><code class="language-python">class argparse():
    pass

args = argparse()
args.epochs, args.learning_rate, args.patience = [30, 0.001, 4]
args.hidden_size, args.input_size= [40, 30]
args.device, = [torch.device("cuda:0" if torch.cuda.is_available() else "cpu"),]</code></pre> 
<h4 id="%E4%B8%89%E3%80%81%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%A8%A1%E5%9E%8B">三、定义自己的模型</h4> 
<pre><code class="language-vbscript">class Your_model(nn.Module):
    def __init__(self):
        super(Your_model, self).__init__()
        pass
        
    def forward(self,x):
        pass
        return x</code></pre> 
<h4 id="%E5%9B%9B%E3%80%81%E5%AE%9A%E4%B9%89%E6%97%A9%E5%81%9C%E7%B1%BB(%E6%AD%A4%E6%AD%A5%E9%AA%A4%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5)">四、定义早停类(此步骤可以省略)</h4> 
<pre><code class="language-python">class EarlyStopping():
    def __init__(self,patience=7,verbose=False,delta=0):
        self.patience = patience
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf
        self.delta = delta
    def __call__(self,val_loss,model,path):
        print("val_loss={}".format(val_loss))
        score = -val_loss
        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss,model,path)
        elif score &lt; self.best_score+self.delta:
            self.counter+=1
            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter&gt;=self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss,model,path)
            self.counter = 0
    def save_checkpoint(self,val_loss,model,path):
        if self.verbose:
            print(
                f'Validation loss decreased ({self.val_loss_min:.6f} --&gt; {val_loss:.6f}).  Saving model ...')
        torch.save(model.state_dict(), path+'/'+'model_checkpoint.pth')
        self.val_loss_min = val_loss</code></pre> 
<h4 id="%E4%BA%94%E3%80%81%E5%AE%9A%E4%B9%89%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86Dataset%2CDataLoader">五、定义自己的数据集Dataset,DataLoader</h4> 
<pre><code class="language-vbscript">class Dataset_name(Dataset):
    def __init__(self, flag='train'):
        assert flag in ['train', 'test', 'valid']
        self.flag = flag
        self.__load_data__()

    def __getitem__(self, index):
        pass
    def __len__(self):
        pass

    def __load_data__(self, csv_paths: list):
        pass
        print(
            "train_X.shape:{}\ntrain_Y.shape:{}\nvalid_X.shape:{}\nvalid_Y.shape:{}\n"
            .format(self.train_X.shape, self.train_Y.shape, self.valid_X.shape, self.valid_Y.shape))

train_dataset = Dataset_name(flag='train')
train_dataloader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)
valid_dataset = Dataset_name(flag='valid')
valid_dataloader = DataLoader(dataset=valid_dataset, batch_size=64, shuffle=True)</code></pre> 
<h4 id="%E5%85%AD%E3%80%81%E5%AE%9E%E4%BE%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%EF%BC%8C%E8%AE%BE%E7%BD%AEloss%EF%BC%8C%E4%BC%98%E5%8C%96%E5%99%A8%E7%AD%89">六、实例化模型，设置loss，优化器等</h4> 
<pre><code class="language-python">model = Your_model().to(args.device)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(Your_model.parameters(),lr=args.learning_rate)

train_loss = []
valid_loss = []
train_epochs_loss = []
valid_epochs_loss = []

early_stopping = EarlyStopping(patience=args.patience,verbose=True)</code></pre> 
<h4 id="%E4%B8%83%E3%80%81%E5%BC%80%E5%A7%8B%E8%AE%AD%E7%BB%83%E4%BB%A5%E5%8F%8A%E8%B0%83%E6%95%B4lr">七、开始训练以及调整lr</h4> 
<pre><code class="language-python">for epoch in range(args.epochs):
    Your_model.train()
    train_epoch_loss = []
    for idx,(data_x,data_y) in enumerate(train_dataloader,0):
        data_x = data_x.to(torch.float32).to(args.device)
        data_y = data_y.to(torch.float32).to(args.device)
        outputs = Your_model(data_x)
        optimizer.zero_grad()
        loss = criterion(data_y,outputs)
        loss.backward()
        optimizer.step()
        train_epoch_loss.append(loss.item())
        train_loss.append(loss.item())
        if idx%(len(train_dataloader)//2)==0:
            print("epoch={}/{},{}/{}of train, loss={}".format(
                epoch, args.epochs, idx, len(train_dataloader),loss.item()))
    train_epochs_loss.append(np.average(train_epoch_loss))
    
    #=====================valid============================
    Your_model.eval()
    valid_epoch_loss = []
    for idx,(data_x,data_y) in enumerate(valid_dataloader,0):
        data_x = data_x.to(torch.float32).to(args.device)
        data_y = data_y.to(torch.float32).to(args.device)
        outputs = Your_model(data_x)
        loss = criterion(outputs,data_y)
        valid_epoch_loss.append(loss.item())
        valid_loss.append(loss.item())
    valid_epochs_loss.append(np.average(valid_epoch_loss))
    #==================early stopping======================
    early_stopping(valid_epochs_loss[-1],model=Your_model,path=r'c:\\your_model_to_save')
    if early_stopping.early_stop:
        print("Early stopping")
        break
    #====================adjust lr========================
    lr_adjust = {
            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6,
            10: 5e-7, 15: 1e-7, 20: 5e-8
        }
    if epoch in lr_adjust.keys():
        lr = lr_adjust[epoch]
        for param_group in optimizer.param_groups:
            param_group['lr'] = lr
        print('Updating learning rate to {}'.format(lr))</code></pre> 
<h4 id="%E5%85%AB%E3%80%81%E7%BB%98%E5%9B%BE">八、绘图</h4> 
<pre><code class="language-python">plt.figure(figsize=(12,4))
plt.subplot(121)
plt.plot(train_loss[:])
plt.title("train_loss")
plt.subplot(122)
plt.plot(train_epochs_loss[1:],'-o',label="train_loss")
plt.plot(valid_epochs_loss[1:],'-o',label="valid_loss")
plt.title("epochs_loss")
plt.legend()
plt.show()</code></pre> 
<h4 id="%E4%B9%9D%E3%80%81%E9%A2%84%E6%B5%8B">九、预测</h4> 
<pre><code class="language-python"># 此处可定义一个预测集的Dataloader。也可以直接将你的预测数据reshape,添加batch_size=1
Your_model.eval()
predict = Your_model(data)</code></pre> 
<h4 id="%E5%8D%81%E3%80%81%E8%BF%90%E8%A1%8C%E5%AE%9E%E4%BE%8B%E5%8F%82%E8%80%83%EF%BC%88%E7%BB%93%E5%90%88%E4%B8%8A%E8%BF%B0%E6%A8%A1%E5%9E%8B%E7%90%86%E8%A7%A3%EF%BC%89">十、运行实例参考（结合上述模型理解）</h4> 
<p>下面用18个数训练了一个分类网络，判断一个数字是否大于8（在dataset中设置），具有完整的训练和预测流程。</p> 
<p>网络是最简单的全连接，输入为1，输出为2（2分类）。</p> 
<pre><code class="language-python">import random

import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from tqdm import tqdm

# 设置随机数种子保证论文可复现
seed = 42
torch.manual_seed(seed)
np.random.seed(seed)
random.seed(seed)
torch.cuda.manual_seed_all(seed)

# 以类的方式定义参数，还有很多方法，config文件等等
class Args:
    def __init__(self) -&gt; None:
        self.batch_size = 1
        self.lr = 0.001
        self.epochs = 10
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.data_train = np.array([-2, -1, 0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 20])
        self.data_val = np.array([15, 16, 17, 0.1, -3, -4])


args = Args()

# 定义一个简单的全连接
class Net(nn.Module):
    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):
        super().__init__()
        self.layer1 = nn.Sequential(
            nn.Linear(in_dim, n_hidden_1), nn.ReLU(True))
        self.layer2 = nn.Sequential(
            nn.Linear(n_hidden_1, n_hidden_2), nn.ReLU(True))
        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))

    def forward(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        return x


# 定义数据集，判断一个数字是否大于8
class Dataset_num(Dataset):
    def __init__(self, flag='train') -&gt; None:
        self.flag = flag
        assert self.flag in ['train', 'val'], 'not implement!'

        if self.flag == 'train':
            self.data = args.data_train
        else:
            self.data = args.data_val

    def __getitem__(self, index: int):
        val = self.data[index]

        if val &gt; 8:
            label = 1
        else:
            label = 0

        return torch.tensor(label, dtype=torch.long), torch.tensor([val], dtype=torch.float32)

    def __len__(self) -&gt; int:
        return len(self.data)


def train():
    train_dataset = Dataset_num(flag='train')
    train_dataloader = DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=True)
    val_dataset = Dataset_num(flag='val')
    val_dataloader = DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=True)

    model = Net(1, 32, 16, 2).to(args.device) # 网路参数设置，输入为1，输出为2，即判断一个数是否大于8
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)  # , eps=1e-8)

    train_epochs_loss = []
    valid_epochs_loss = []
    train_acc = []
    val_acc = []

    for epoch in range(args.epochs):
        model.train()
        train_epoch_loss = []
        acc, nums = 0, 0
        # =========================train=======================
        for idx, (label, inputs) in enumerate(tqdm(train_dataloader)):
            inputs = inputs.to(args.device)
            label = label.to(args.device)
            outputs = model(inputs)
            optimizer.zero_grad()
            loss = criterion(outputs, label)
            loss.backward()
            # torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0) #用来梯度裁剪
            optimizer.step()
            train_epoch_loss.append(loss.item())
            acc += sum(outputs.max(axis=1)[1] == label).cpu()
            nums += label.size()[0]
        train_epochs_loss.append(np.average(train_epoch_loss))
        train_acc.append(100 * acc / nums)
        print("train acc = {:.3f}%, loss = {}".format(100 * acc / nums, np.average(train_epoch_loss)))
        # =========================val=========================
        with torch.no_grad():
            model.eval()
            val_epoch_loss = []
            acc, nums = 0, 0

            for idx, (label, inputs) in enumerate(tqdm(val_dataloader)):
                inputs = inputs.to(args.device)  # .to(torch.float)
                label = label.to(args.device)
                outputs = model(inputs)
                loss = criterion(outputs, label)
                val_epoch_loss.append(loss.item())

                acc += sum(outputs.max(axis=1)[1] == label).cpu()
                nums += label.size()[0]

            valid_epochs_loss.append(np.average(val_epoch_loss))
            val_acc.append(100 * acc / nums)

            print("epoch = {}, valid acc = {:.2f}%, loss = {}".format(epoch, 100 * acc / nums, np.average(val_epoch_loss)))

    # =========================plot==========================
    plt.figure(figsize=(12, 4))
    plt.subplot(121)
    plt.plot(train_epochs_loss[:])
    plt.title("train_loss")
    plt.subplot(122)
    plt.plot(train_epochs_loss, '-o', label="train_loss")
    plt.plot(valid_epochs_loss, '-o', label="valid_loss")
    plt.title("epochs_loss")
    plt.legend()
    plt.show()
    # =========================save model=====================
    torch.save(model.state_dict(), 'model.pth')


def pred(val):
    model = Net(1, 32, 16, 2)
    model.load_state_dict(torch.load('model.pth'))
    model.eval()
    val = torch.tensor(val).reshape(1, -1).float()
    # 需要转换成相应的输入shape，而且得带上batch_size，因此转换成shape=(1,1)这样的形状
    res = model(val)
    # real: tensor([[-5.2095, -0.9326]], grad_fn=&lt;AddmmBackward0&gt;) 需要找到最大值所在的列数，就是标签
    res = res.max(axis=1)[1].item()
    print("predicted label is {}, {} {} 8".format(res, val.item(), ('&gt;' if res == 1 else '&lt;')))



if __name__ == '__main__':
    train()
    pred(24)
    pred(3.14)
    pred(7.8)  # 这个会预测错误，所以数据量对于深度学习很重要</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8fcc94addeaae6a82d7e3f1f8fb65157/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">eNSP:软件下载链接</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0327f6a10c2fa3c4eea415f3652ef78c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【ABAQUS 二次开发笔记】使用keyword 、python和matlab一起处理Odb数据</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>