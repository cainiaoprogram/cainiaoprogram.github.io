<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Docker下运行多个ClickHouse容器,在ReplicatedMergeTree引擎中借助Zookeeper同步数据时日志提示“DNS_ERROR”且数据同步失败的解决方案 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Docker下运行多个ClickHouse容器,在ReplicatedMergeTree引擎中借助Zookeeper同步数据时日志提示“DNS_ERROR”且数据同步失败的解决方案" />
<meta property="og:description" content="前置准备 目的 在物理机中基于Docker服务运行两个Clickhouse容器，配置并连接Zookeeper服务器；依照官网对ReplicatedMergeTree引擎的描述分别在两个容器中创建副本表；通过Zookeeper对ClickHouse的支持达到数据同步,最终让两台ClickHouse互为数据副本（Data Replication）.
准备 物理机基础环境
IP地址：192.168.182.10
Docker容器和IP信息
服务名称网段名称IP地址主机名Docker执行命令CK节点1(第一个ClickHouse容器)bridge172.17.0.37409ace09488docker run -d --name clickhouse-server-c1 --ulimit nofile=262144:262144 --volume=/software/docker/clickhouse/ck1/config:/etc/clickhouse-server/ -v /software/docker/clickhouse/ck1/data:/var/lib/clickhouse -p 8123:8123 -p 9000:9000 -p 9009:9009 yandex/clickhouse-serverCK节点2(第二个ClickHouse容器)bridge172.17.0.4b22679b9d346docker run -d --name clickhouse-server-c2 --ulimit nofile=262144:262144 --volume=/software/docker/clickhouse/ck2/config:/etc/clickhouse-server/ -v /software/docker/clickhouse/ck2/data:/var/lib/clickhouse -p 8124:8123 -p 9001:9000 -p 9010:9009 yandex/clickhouse-serverzookeeperbridge172.17.0.5不重要docker run --name zookeeper -d -p 2181:2181 zookeeper ClickHouse服务配置
3.1. CK节点1和CK节点2的config/config.d目录中新建metrika-share.xml配置文件,并写入以下配置
metrika-share.xml 内容 &lt;?xml version=&#34;1.0&#34;?&gt; &lt;clickhouse&gt; &lt;zookeeper&gt; &lt;node&gt; &lt;!--因zookeeper的2181端口已对外暴露，此处可直接使用本机地址访问,防止Zookeeper IP地址变动--&gt; &lt;host&gt;192.168.182.10&lt;/host&gt; &lt;port&gt;2181&lt;/port&gt; &lt;/node&gt; &lt;/zookeeper&gt; &lt;/clickhouse&gt; 3.2 CK节点1和CK节点2的config.xml配置中搜索&lt;include_from&gt; 标签,添加为以下内容
&lt;!--因Docker挂载目录已映射成功,故此处可以直接连接到下列配置--&gt; &lt;include_from&gt;/etc/clickhouse-server/config." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/77c1215e94f35e3944da709c1f8fa871/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-18T22:30:28+08:00" />
<meta property="article:modified_time" content="2023-04-18T22:30:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Docker下运行多个ClickHouse容器,在ReplicatedMergeTree引擎中借助Zookeeper同步数据时日志提示“DNS_ERROR”且数据同步失败的解决方案</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>前置准备</h2> 
<h3><a id="_1"></a>目的</h3> 
<p><strong>在物理机中基于Docker服务运行两个Clickhouse容器，配置并连接Zookeeper服务器；依照官网对ReplicatedMergeTree引擎的描述分别在两个容器中创建副本表；通过Zookeeper对ClickHouse的支持达到数据同步,最终让两台ClickHouse互为数据副本（Data Replication）.</strong></p> 
<h3><a id="_4"></a>准备</h3> 
<ol><li> <p>物理机基础环境</p> <p><strong>IP地址：192.168.182.10</strong></p> </li><li> <p>Docker容器和IP信息</p> 
  <table><thead><tr><th>服务名称</th><th>网段名称</th><th>IP地址</th><th>主机名</th><th>Docker执行命令</th></tr></thead><tbody><tr><td>CK节点1(第一个ClickHouse容器)</td><td>bridge</td><td>172.17.0.3</td><td>7409ace09488</td><td>docker run -d --name clickhouse-server-c1 --ulimit nofile=262144:262144 --volume=/software/docker/clickhouse/ck1/config:/etc/clickhouse-server/ -v /software/docker/clickhouse/ck1/data:/var/lib/clickhouse -p 8123:8123 -p 9000:9000 -p 9009:9009 yandex/clickhouse-server</td></tr><tr><td>CK节点2(第二个ClickHouse容器)</td><td>bridge</td><td>172.17.0.4</td><td>b22679b9d346</td><td>docker run -d --name clickhouse-server-c2 --ulimit nofile=262144:262144 --volume=/software/docker/clickhouse/ck2/config:/etc/clickhouse-server/ -v /software/docker/clickhouse/ck2/data:/var/lib/clickhouse -p 8124:8123 -p 9001:9000 -p 9010:9009 yandex/clickhouse-server</td></tr><tr><td>zookeeper</td><td>bridge</td><td>172.17.0.5</td><td>不重要</td><td>docker run --name zookeeper -d -p 2181:2181 zookeeper</td></tr></tbody></table></li><li> <p>ClickHouse服务配置</p> <p>3.1. CK节点1和CK节点2的<strong>config/config.d</strong>目录中新建<strong>metrika-share.xml</strong>配置文件,并写入以下配置</p> 
  <ul><li>metrika-share.xml 内容</li></ul> <pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0"?&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>clickhouse</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>zookeeper</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>node</span><span class="token punctuation">&gt;</span></span>
      	 <span class="token comment">&lt;!--因zookeeper的2181端口已对外暴露，此处可直接使用本机地址访问,防止Zookeeper IP地址变动--&gt;</span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>host</span><span class="token punctuation">&gt;</span></span>192.168.182.10<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>host</span><span class="token punctuation">&gt;</span></span>
         <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>port</span><span class="token punctuation">&gt;</span></span>2181<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>port</span><span class="token punctuation">&gt;</span></span>
      <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>node</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>zookeeper</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>clickhouse</span><span class="token punctuation">&gt;</span></span>
</code></pre> <p>3.2 CK节点1和CK节点2的config.xml配置中<mark>搜索&lt;include_from&gt; 标签</mark>,添加为以下内容</p> <pre><code class="prism language-xml"><span class="token comment">&lt;!--因Docker挂载目录已映射成功,故此处可以直接连接到下列配置--&gt;</span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>include_from</span><span class="token punctuation">&gt;</span></span>/etc/clickhouse-server/config.d/metrika-share.xml<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>include_from</span><span class="token punctuation">&gt;</span></span>
</code></pre> <p><strong>注意：修改配置完毕后需要重启ClickHouse服务</strong></p> </li></ol> 
<h2><a id="_39"></a>问题复现</h2> 
<p>1.<strong>CK客户端中访问Zookeeper正常相应，打印结果如图1所示；</strong><br> <img src="https://images2.imgbox.com/32/78/QXHkDObS_o.png" alt="判断Zookeeper是否正确连通"><br> 图1：判断Zookeeper是否正确连通</p> 
<p>2.<strong>两个容器的CK客户端中分别创建ReplicatedMergeTree引擎的建表语句正常创建成功，建表语句如图2所示；</strong><br> <img src="https://images2.imgbox.com/3c/43/LrGwIApx_o.jpg" alt="在这里插入图片描述"><br> 图2：两个节点的建表语句.</p> 
<ol start="3"><li>CK节点1执行<mark>2条插入语句</mark>，结果为<strong>CK节点1存在数据</strong>,而<strong>CK节点2无数据</strong>，说明数据<mark>同步失败</mark>；同样在CK节点2执行<mark>2条插入语句</mark>，结果为<strong>CK节点2存在数据</strong>,而<strong>CK节点1无数据</strong>，使用IDEA的Zookeeper连接工具插件查看自动创建的【/clickhouse/tables/01/t_replicated_merge】目录，目前展示图如图3所示.<br> <img src="https://images2.imgbox.com/45/6f/rrSdpwQ9_o.jpg" alt="在这里插入图片描述"><br> 图3.Zookeeper中对ReplicatedMergeTree支持的节点展示图</li></ol> 
<p><strong>主要目录解释</strong><br> 1). 【replicas】目录为副本的信息节点，包含了副本节点的连接IP、端口号、是否存活等信息.<br> 2). 【log】目录为数据同步目录，即副本间数据同步通过该目录下的log-xxxxx进行数据交互，其中log-xxxxx可以等价为“insert into xxx values(v1,v2)”，当然还有附加属性如客户端标识、大小之类的信息.</p> 
<h2><a id="_56"></a>问题定位</h2> 
<p>立即打开CK节点1的服务端错误日志，日志名为：【clickhouse-server.err.log】（Linux环境下错误日志所在位置一般为【/var/log/clickhouse-server】），发现错误【<mark>DNSResolver: Cannot resolve host (b22679b9d346), error 0: b22679b9d346.XXX.const: Code: 198. DB::Exception: Not found address of host: b22679b9d346. (DNS_ERROR)</mark>】；开发CK节点2的服务日志，也是类似错误；较完整错误日志打印如下：</p> 
<pre><code>2022.08.26 11:03:33.409494 [ 90 ] {} &lt;Error&gt; DNSResolver: Cannot resolve host (b22679b9d346), error 0: b22679b9d346.
2022.08.26 11:03:33.409738 [ 90 ] {} &lt;Error&gt; default.t_replicated_merge (35f8baf4-d1e4-43d9-88fc-c45e1ff8adb0): auto DB::StorageReplicatedMergeTree::processQueueEntry(ReplicatedMergeTreeQueue::SelectedEntryPtr)::(anonymous class)::operator()(DB::StorageReplicatedMergeTree::LogEntryPtr &amp;) const: Code: 198. DB::Exception: Not found address of host: b22679b9d346. (DNS_ERROR), Stack trace (when copying this message, always include the lines below):

0. DB::Exception::Exception(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, int, bool) @ 0xa82d07a in /usr/bin/clickhouse
1. ? @ 0xa8e7951 in /usr/bin/clickhouse
2. ? @ 0xa8e8122 in /usr/bin/clickhouse
3. DB::DNSResolver::resolveHost(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;) @ 0xa8e71fe in /usr/bin/clickhouse
4. ? @ 0xa9d9493 in /usr/bin/clickhouse
5. ? @ 0xa9dd0f9 in /usr/bin/clickhouse
6. PoolBase&lt;Poco::Net::HTTPClientSession&gt;::get(long) @ 0xa9dc837 in /usr/bin/clickhouse
7. DB::makePooledHTTPSession(Poco::URI const&amp;, Poco::URI const&amp;, DB::ConnectionTimeouts const&amp;, unsigned long, bool) @ 0xa9dacb8 in /usr/bin/clickhouse
8. DB::makePooledHTTPSession(Poco::URI const&amp;, DB::ConnectionTimeouts const&amp;, unsigned long, bool) @ 0xa9d9819 in /usr/bin/clickhouse
9. DB::UpdatablePooledSession::UpdatablePooledSession(Poco::URI, DB::ConnectionTimeouts const&amp;, unsigned long, unsigned long) @ 0x141c76e9 in /usr/bin/clickhouse
10. DB::PooledReadWriteBufferFromHTTP::PooledReadWriteBufferFromHTTP(Poco::URI, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::function&lt;void (std::__1::basic_ostream&lt;char, std::__1::char_traits&lt;char&gt; &gt;&amp;)&gt;, DB::ConnectionTimeouts const&amp;, Poco::Net::HTTPBasicCredentials const&amp;, unsigned long, unsigned long, unsigned long) @ 0x141be51e in /usr/bin/clickhouse
11. DB::DataPartsExchange::Fetcher::fetchPart(std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt; const&amp;, std::__1::shared_ptr&lt;DB::Context const&gt;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, int, DB::ConnectionTimeouts const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::shared_ptr&lt;DB::Throttler&gt;, bool, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::optional&lt;DB::CurrentlySubmergingEmergingTagger&gt;*, bool, std::__1::shared_ptr&lt;DB::IDisk&gt;) @ 0x141bb8f2 in /usr/bin/clickhouse
12. ? @ 0x1405188d in /usr/bin/clickhouse
13. DB::StorageReplicatedMergeTree::fetchPart(std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, std::__1::shared_ptr&lt;DB::StorageInMemoryMetadata const&gt; const&amp;, std::__1::basic_string&lt;char, std::__1::char_traits&lt;char&gt;, std::__1::allocator&lt;char&gt; &gt; const&amp;, bool, unsigned long, std::__1::shared_ptr&lt;zkutil::ZooKeeper&gt;) @ 0x13fae906 in /usr/bin/clickhouse
14. DB::StorageReplicatedMergeTree::executeFetch(DB::ReplicatedMergeTreeLogEntry&amp;) @ 0x13fa12b4 in /usr/bin/clickhouse
15. DB::StorageReplicatedMergeTree::executeLogEntry(DB::ReplicatedMergeTreeLogEntry&amp;) @ 0x13f9074d in /usr/bin/clickhouse
16. ? @ 0x1404f41f in /usr/bin/clickhouse
17. DB::ReplicatedMergeTreeQueue::processEntry(std::__1::function&lt;std::__1::shared_ptr&lt;zkutil::ZooKeeper&gt; ()&gt;, std::__1::shared_ptr&lt;DB::ReplicatedMergeTreeLogEntry&gt;&amp;, std::__1::function&lt;bool (std::__1::shared_ptr&lt;DB::ReplicatedMergeTreeLogEntry&gt;&amp;)&gt;) @ 0x14468165 in /usr/bin/clickhouse
18. DB::StorageReplicatedMergeTree::processQueueEntry(std::__1::shared_ptr&lt;DB::ReplicatedMergeTreeQueue::SelectedEntry&gt;) @ 0x13fd1073 in /usr/bin/clickhouse
19. DB::ExecutableLambdaAdapter::executeStep() @ 0x1404fd11 in /usr/bin/clickhouse
20. DB::MergeTreeBackgroundExecutor&lt;DB::OrdinaryRuntimeQueue&gt;::routine(std::__1::shared_ptr&lt;DB::TaskRuntimeData&gt;) @ 0xa806ffa in /usr/bin/clickhouse
21. DB::MergeTreeBackgroundExecutor&lt;DB::OrdinaryRuntimeQueue&gt;::threadFunction() @ 0xa806eb5 in /usr/bin/clickhouse
22. ThreadPoolImpl&lt;ThreadFromGlobalPool&gt;::worker(std::__1::__list_iterator&lt;ThreadFromGlobalPool, void*&gt;) @ 0xa8720aa in /usr/bin/clickhouse
23. ThreadFromGlobalPool::ThreadFromGlobalPool&lt;void ThreadPoolImpl&lt;ThreadFromGlobalPool&gt;::scheduleImpl&lt;void&gt;(std::__1::function&lt;void ()&gt;, int, std::__1::optional&lt;unsigned long&gt;)::'lambda0'()&gt;(void&amp;&amp;, void ThreadPoolImpl&lt;ThreadFromGlobalPool&gt;::scheduleImpl&lt;void&gt;(std::__1::function&lt;void ()&gt;, int, std::__1::optional&lt;unsigned long&gt;)::'lambda0'()&amp;&amp;...)::'lambda'()::operator()() @ 0xa873ec4 in /usr/bin/clickhouse
24. ThreadPoolImpl&lt;std::__1::thread&gt;::worker(std::__1::__list_iterator&lt;std::__1::thread, void*&gt;) @ 0xa86f4b7 in /usr/bin/clickhouse
25. ? @ 0xa872ebd in /usr/bin/clickhouse
26. ? @ 0x7fb368403609 in ?
27. __clone @ 0x7fb36832a293 in ?
 (version 22.1.3.7 (official build))

</code></pre> 
<p><strong>既然是找不到主机名，则要去寻找匹配的信息，正好图3提到的【replicas】目录有记录节点的主机和IP等信息，打开【replicas】目录发现【r_1(CK节点1)】和【r_2(CK节点2)】节点中记录的【host】信息正好就是错误日志中的host。【r_1】节点部分信息如图4所示，【r_2】节点部分信息如图5所示.</strong><br> <img src="https://images2.imgbox.com/71/04/xlLRJISL_o.jpg" alt="在这里插入图片描述"><br> 图4.CK节点1的节点信息截图<br> <img src="https://images2.imgbox.com/d8/b0/fFK33Inn_o.jpg" alt="在这里插入图片描述"><br> 图5.CK节点2的节点信息截图</p> 
<blockquote> 
 <p>通过对ClickHouse官网的ReplicatedMergeTree配置参数的解释和config.xml文件的其他参数定义查阅，最终在官网文档【<strong>https://clickhouse.com/docs/en/operations/server-configuration-parameters/settings/#default_replica_name</strong>】中找到标签<mark>interserver_http_host</mark>，对此标签官网的解释为：【<strong>其他服务器访问此服务器时可以使用的主机名。如果省略，它的定义方式与hostname-f命令相同。用于脱离特定的网络接口。</strong>】。</p> 
</blockquote> 
<blockquote> 
 <p>番外： <strong>都说默认和hostname -f命令执行相同，那就去容器节点看看吧，结果还真是!!! 如图6，图7所示.</strong><br> <img src="https://images2.imgbox.com/00/2a/c0VebgSl_o.jpg" alt="在这里插入图片描述"><br> 图6. CK节点1的host<br> <img src="https://images2.imgbox.com/09/02/NTbEy3kl_o.jpg" alt="在这里插入图片描述"><br> 图7. CK节点2的host</p> 
</blockquote> 
<h2><a id="_108"></a>问题解决</h2> 
<h3><a id="1_109"></a>方案1</h3> 
<blockquote> 
 <p>执行下列步骤：<br> 1.修改CK节点1的config.xml文件，定位到标签【interserver_http_host】，将默认的“example.clickhouse.com”改为IP地址“172.17.0.3”<br> 2.修改CK节点2的config.xml文件，定位到标签【interserver_http_host】，将默认的“example.clickhouse.com”改为IP地址“172.17.0.4”<br> 3.<strong>重启服务</strong></p> 
</blockquote> 
<p><strong>经过以上步骤,再重新查询任意节点的数据，发现之前未正常写入的数据都已经正确同步! 至此，问题圆满解决.</strong></p> 
<h4><a id="_116"></a>方案缺点</h4> 
<ol><li>Docker容器停止后,内部IP地址会发生变动，导致配置每次都需要更正;<mark>（重要）</mark></li><li>副本应基于宏定义标签进行动态定值,需要额外在metrika-share.xml中配置宏标签 <strong>（废话）</strong></li><li>重复配置配置文件,工作量大 <strong>（废话）</strong></li></ol> 
<h3><a id="2_121"></a>方案2</h3> 
<p><strong>备注：该方案于2023年4月17日更新,较于【方案1】的优势便是将重要缺点补足(其他缺点解决可联系博主私发简单的执行脚本)，且不用更改标签&lt;interserver_http_host&gt;,甚至可以应用在物理资源不足的测试/生产环境中…</strong></p> 
<hr> 
<h4><a id="_126"></a>思路</h4> 
<p>因Docker默认网络存在先天缺陷,导致属于该网段的Container-IP并未与Contailer-HostName做内部绑定；但Docker支持创建自定义网络,且会自动将IP同HostName进行关联，因此将<strong>多个CK容器置于同一个自定义网络</strong>中即可使其通过HostName进行通讯~</p> 
<h4><a id="_128"></a>方案步骤</h4> 
<p>1.（如使用过方案1）注释CK容器的&lt;interserver_http_host&gt;标签<br> 2. <strong>执行Docker命令 docker network create clickhouse-network</strong><br> 3. 修改原有CK节点1和CK节点2容器的docker run 命令,在其中添加== --network clickhouse-network== 选项<br> 4. 重启服务,over~~</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/de59247ea12c33a0adf042ca3065ae91/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">泛型的用法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c8d151e864c4e5971840575793ac1206/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">PHP&#43;xshell线上同步</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>