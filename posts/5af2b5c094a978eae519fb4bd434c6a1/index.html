<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MindSpore新型轻量级神经网络GhostNet，在ImageNet分类、图像识别和目标检测等多个应用场景效果优异！ - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="MindSpore新型轻量级神经网络GhostNet，在ImageNet分类、图像识别和目标检测等多个应用场景效果优异！" />
<meta property="og:description" content="华为研究员提出一种新型轻量神经网络架构，表现全面超越谷歌MobileNetV3和Facebook的FBNet，相关论文累计引用近300，入围PaperDigest的CVPR 2020 Most Influential Papers榜单。论文提出了一个全新的Ghost模块，旨在通过廉价操作生成更多的特征图。基于一组原始的特征图，作者应用一系列线性变换，以很小的代价生成许多能从原始特征发掘所需信息的“幻影”特征图（Ghost feature maps）。该Ghost模块即插即用，通过堆叠Ghost模块得出Ghost bottleneck，进而搭建轻量级神经网络——GhostNet。GhostNet在多种场景如ImageNet分类、细粒度图像识别和目标检测等取得了明显优于MobileNet的效果。GhostNet做持续放大，构建出B1-B4系列模型，持续优于EfficientNet。
论文链接1：https://arxiv.org/abs/1911.11907
论文链接2：https://arxiv.org/abs/2108.00177
Gitee开源地址：
https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet
Github开源地址：https://github.com/mindspore-ai/models/tree/master/research/cv/ghostnet
引言
卷积神经网络推动了计算机视觉诸多任务的进步，比如图像识别、目标检测等。但是，神经网络在移动设备上的应用还亟待解决，主要原因是现有模型又大又慢。因而，一些研究提出了模型的压缩方法，比如剪枝、量化、知识蒸馏等；还有一些则着重于高效的网络结构设计，比如MobileNet、ShuffleNet等。本文就设计了一种全新的神经网络基本单元Ghost模块，从而搭建出轻量级神经网络架构GhostNet。
在一个训练好的深度神经网络中，通常会包含丰富甚至冗余的特征图，以保证对输入数据有全面的理解。如下图所示，在ResNet-50中，将经过第一个残差块处理后的特征图拿出来，三个相似的特征图对示例用相同颜色的框注释。该对中的一个特征图可以通过廉价操作（用扳手表示）将另一特征图变换而获得，可以认为其中一个特征图是另一个的“幻影”。因为，本文提出并非所有特征图都要用卷积操作来得到，“幻影”特征图可以用更廉价的操作来生成。
ResNet50特征图可视化
在本文中，作者提出了一种新颖的Ghost模块，可以使用更少的参数来生成更多特征图。具体来说，深度神经网络中的普通卷积层将分为两部分。第一部分涉及普通卷积，但是将严格控制它们的总数。给定第一部分的固有特征图，然后将一系列简单的线性运算应用于生成更多特征图。与普通卷积神经网络相比，在不更改输出特征图大小的情况下，该Ghost模块中所需的参数总数和计算复杂度均已降低。基于Ghost模块，作者建立了一种有效的神经体系结构，即GhostNet。作者首先在基准神经体系结构中替换原始的卷积层，以证明Ghost模块的有效性，然后在几个基准视觉数据集上验证GhostNet的优越性。实验结果表明，所提出的Ghost模块能够在保持相似识别性能的同时降低通用卷积层的计算成本，并且GhostNet可以超越MobileNetV3等先进的高效深度模型，在移动设备上进行快速推断。
GhostNet基础模型
Ghost模块 深度卷积神经网络通常引用由大量卷积组成的卷积神经网络，导致大量的计算成本。尽管最近的工作，例如MobileNet和ShuffleNet引入了深度卷积或混洗操作，以使用较小的卷积核（浮点运算）来构建有效的CNN，其余1x1卷积层仍将占用大量内存和FLOPs。
鉴于主流CNN计算出的中间特征图中存在大量的冗余（如图1所示），作者提出减少所需的资源，即用于生成它们的卷积核。实际上，给定输入数据
，其中c是输入通道数，h和w是高度，输入数据的宽度，分别用于生成n个特征图的任意卷积层的运算可表示为
其中*是卷积运算，b是偏差项，
是具有n个通道的输出特征图， 是这一层中的卷积核。另外，h’和w’分别是输出数据的高度和宽度，kxk分别是卷积核f的内核大小。在此卷积过程中，由于卷积核数量n和通道数c通常非常大（例如256或512），所需的FLOPs数量达
之多。
(a) 普通卷积层 (b) Ghost模块
根据上述公式，要优化的参数数量（f和b中的参数）由输入和输出特征图的尺寸确定。如图1中所观察到的，卷积层的输出特征图通常包含很多冗余，并且其中一些可能彼此相似。作者指出，没有必要使用大量的FLOPs和参数一一生成这些冗余特征图，而是说，输出特征图是少数原始特征图通过一些廉价转换的“幻影”。这些原始特征图通常具有较小的大小，并由普通的卷积核生成。具体来说，m个原始特征图Y’是使用一次卷积生成的：
其中f&#39;是使用的卷积核，m&lt;=n，为简单起见，这里省略了偏差项。超参数（例如卷积核大小，stride，padding）与普通卷积中的超参数相同，以保持输出特征图的空间大小（即h’和w&#39; ）保持一致。为了进一步获得所需的n个特征图，作者提出对Y&#39;中的每个原始特征应用一系列廉价的线性运算，以生成s个幻影特征图：
其中y&#39;_i是Y&#39;中第i 个原始特征图，上述函数中的
是第j个线性运算，用于生成第 j 个幻影特征图y_ {ij} ，也就是说，y&#39;_i 可以具有一个或多个幻影特征图
最后的
是用于保留原始特征图的恒等映射，如图2(b)所示。通过使用廉价操作，我们可以获得n=m*s个特征图
作为Ghost模块的输出数据。注意，线性运算
在每个通道上运行，其计算量比普通卷积少得多。实际上，Ghost模块中可能有几种不同的线性运算，例如3x3和5x5线性内核，将在实验部分进行分析。
在每个通道上运行，其计算量比普通卷积少得多。实际上，Ghost模块中可能有几种不同的线性运算，例如3x3和5x5线性内核，将在实验部分进行分析。
构建GhostNet Ghost Bottleneck：利用Ghost模块的优势，作者介绍了专门为小型CNN设计的Ghost bottleneck（G-bneck）。如图3所示，Ghost bottleneck似乎类似于ResNet中的基本残差块（Basic Residual Block），其中集成了多个卷积层和shortcut。Ghost bottleneck主要由两个堆叠的Ghost模块组成。第一个Ghost模块用作扩展层，增加了通道数。这里将输出通道数与输入通道数之比称为expansion ratio。第二个Ghost模块减少通道数，以与shortcut路径匹配。然后，使用shortcut连接这两个Ghost模块的输入和输出。这里借鉴了MobileNetV2，第二个Ghost模块之后不使用ReLU，其他层在每层之后都应用了批量归一化（BN）和ReLU非线性激活。上述Ghost bottleneck适用于stride= 1，对于stride = 2的情况，shortcut路径由下采样层和stride = 2的深度卷积（Depthwise Convolution）来实现。出于效率考虑，Ghost模块中的初始卷积是点卷积（Pointwise Convolution）。
Ghost bottleneck
GhostNet：基于Ghost bottleneck，作者提出GhostNet，如表1所示。作者遵循MobileNetV3的基本体系结构的优势，然后使用Ghost bottleneck替换MobileNetV3中的bottleneck。GhostNet主要由一堆Ghost bottleneck组成，其中Ghost bottleneck以Ghost模块为构建基础。第一层是具有16个卷积核的标准卷积层，然后是一系列Ghost bottleneck，通道逐渐增加。这些Ghost bottleneck根据其输入特征图的大小分为不同的阶段。除了每个阶段的最后一个Ghost bottleneck是stride = 2，其他所有Ghost bottleneck都以stride = 1进行应用。最后，利用全局平均池和卷积层将特征图转换为1280维特征向量以进行最终分类。SE模块也用在了某些Ghost bottleneck中的残留层，如表1中所示。与MobileNetV3相比，这里用ReLU换掉了Hard-swish激活函数。尽管进一步的超参数调整或基于自动架构搜索的Ghost模块将进一步提高性能，但表1所提供的架构提供了一个基本设计参考。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/5af2b5c094a978eae519fb4bd434c6a1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-25T09:33:08+08:00" />
<meta property="article:modified_time" content="2022-06-25T09:33:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MindSpore新型轻量级神经网络GhostNet，在ImageNet分类、图像识别和目标检测等多个应用场景效果优异！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p class="img-center"><img alt="" src="https://images2.imgbox.com/f3/41/2eKYllCX_o.gif"></p> 
<p>华为研究员提出一种新型轻量神经网络架构，表现全面超越谷歌MobileNetV3和Facebook的FBNet，相关论文累计引用近300，入围PaperDigest的CVPR 2020 Most Influential Papers榜单。论文提出了一个全新的Ghost模块，旨在通过廉价操作生成更多的特征图。基于一组原始的特征图，作者应用一系列线性变换，以很小的代价生成许多能从原始特征发掘所需信息的“幻影”特征图（Ghost feature maps）。该Ghost模块即插即用，通过堆叠Ghost模块得出Ghost bottleneck，进而搭建轻量级神经网络——GhostNet。GhostNet在多种场景如ImageNet分类、细粒度图像识别和目标检测等取得了明显优于MobileNet的效果。GhostNet做持续放大，构建出B1-B4系列模型，持续优于EfficientNet。</p> 
<p>论文链接1：<em><strong>https://arxiv.org/abs/1911.11907</strong></em></p> 
<p>论文链接2：<em><strong>https://arxiv.org/abs/2108.00177</strong></em></p> 
<p>Gitee开源地址：</p> 
<p><em><strong>https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet</strong></em></p> 
<p>Github开源地址：<em><strong>https://github.com/mindspore-ai/models/tree/master/research/cv/ghostnet</strong></em></p> 
<p><strong>引言</strong></p> 
<p>卷积神经网络推动了计算机视觉诸多任务的进步，比如图像识别、目标检测等。但是，神经网络在移动设备上的应用还亟待解决，主要原因是现有模型又大又慢。因而，一些研究提出了模型的压缩方法，比如剪枝、量化、知识蒸馏等；还有一些则着重于高效的网络结构设计，比如MobileNet、ShuffleNet等。本文就设计了一种全新的神经网络基本单元Ghost模块，从而搭建出轻量级神经网络架构GhostNet。</p> 
<p>在一个训练好的深度神经网络中，通常会包含丰富甚至冗余的特征图，以保证对输入数据有全面的理解。如下图所示，在ResNet-50中，将经过第一个残差块处理后的特征图拿出来，三个相似的特征图对示例用相同颜色的框注释。该对中的一个特征图可以通过廉价操作（用扳手表示）将另一特征图变换而获得，可以认为其中一个特征图是另一个的“幻影”。因为，本文提出并非所有特征图都要用卷积操作来得到，“幻影”特征图可以用更廉价的操作来生成。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/fa/65/eLBZ1G16_o.png"></p> 
<p>ResNet50特征图可视化</p> 
<p>在本文中，作者提出了一种新颖的Ghost模块，可以使用更少的参数来生成更多特征图。具体来说，深度神经网络中的普通卷积层将分为两部分。第一部分涉及普通卷积，但是将严格控制它们的总数。给定第一部分的固有特征图，然后将一系列简单的线性运算应用于生成更多特征图。与普通卷积神经网络相比，在不更改输出特征图大小的情况下，该Ghost模块中所需的参数总数和计算复杂度均已降低。基于Ghost模块，作者建立了一种有效的神经体系结构，即GhostNet。作者首先在基准神经体系结构中替换原始的卷积层，以证明Ghost模块的有效性，然后在几个基准视觉数据集上验证GhostNet的优越性。实验结果表明，所提出的Ghost模块能够在保持相似识别性能的同时降低通用卷积层的计算成本，并且GhostNet可以超越MobileNetV3等先进的高效深度模型，在移动设备上进行快速推断。</p> 
<p><strong>GhostNet基础模型</strong></p> 
<h4><strong>Ghost模块</strong></h4> 
<p>深度卷积神经网络通常引用由大量卷积组成的卷积神经网络，导致大量的计算成本。尽管最近的工作，例如MobileNet和ShuffleNet引入了深度卷积或混洗操作，以使用较小的卷积核（浮点运算）来构建有效的CNN，其余1x1卷积层仍将占用大量内存和FLOPs。</p> 
<p>鉴于主流CNN计算出的中间特征图中存在大量的冗余（如图1所示），作者提出减少所需的资源，即用于生成它们的卷积核。实际上，给定输入数据</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c3/bb/Arf2Z0ho_o.png"></p> 
<p>，其中c是输入通道数，h和w是高度，输入数据的宽度，分别用于生成n个特征图的任意卷积层的运算可表示为</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/8a/85/k3vnGtcF_o.png"></p> 
<p>其中*是卷积运算，b是偏差项，</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/58/9d/XlQXBVDu_o.png"></p> 
<p>是具有n个通道的输出特征图， </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/4e/d2/bL8v5Klv_o.png"></p> 
<p>是这一层中的卷积核。另外，h’和w’分别是输出数据的高度和宽度，kxk分别是卷积核f的内核大小。在此卷积过程中，由于卷积核数量n和通道数c通常非常大（例如256或512），所需的FLOPs数量达</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b6/a0/7A5boG0O_o.png"></p> 
<p>之多。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/e4/1a/MudGOqQo_o.png"></p> 
<p><strong>(a) 普通卷积层 (b) Ghost模块</strong></p> 
<p>根据上述公式，要优化的参数数量（f和b中的参数）由输入和输出特征图的尺寸确定。如图1中所观察到的，卷积层的输出特征图通常包含很多冗余，并且其中一些可能彼此相似。作者指出，没有必要使用大量的FLOPs和参数一一生成这些冗余特征图，而是说，输出特征图是少数原始特征图通过一些廉价转换的“幻影”。这些原始特征图通常具有较小的大小，并由普通的卷积核生成。具体来说，m个原始特征图Y’是使用一次卷积生成的：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/86/61/1gzgCm9P_o.png"></p> 
<p>其中f'是使用的卷积核，m&lt;=n，为简单起见，这里省略了偏差项。超参数（例如卷积核大小，stride，padding）与普通卷积中的超参数相同，以保持输出特征图的空间大小（即h’和w' ）保持一致。为了进一步获得所需的n个特征图，作者提出对Y'中的每个原始特征应用一系列廉价的线性运算，以生成s个幻影特征图：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/4d/4f/DPWQb7ZL_o.png"></p> 
<p>其中y'_i是Y'中第i 个原始特征图，上述函数中的</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/ad/65/RWltjmrr_o.png"></p> 
<p>是第j个线性运算，用于生成第 j 个幻影特征图y_ {ij} ，也就是说，y'_i 可以具有一个或多个幻影特征图</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/38/17/wM31lYNj_o.png"></p> 
<p>最后的</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/3b/20/IUKNwrLI_o.png"></p> 
<p>是用于保留原始特征图的恒等映射，如图2(b)所示。通过使用廉价操作，我们可以获得n=m*s个特征图</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/59/3c/uuP8fku2_o.png"></p> 
<p></p> 
<p>作为Ghost模块的输出数据。注意，线性运算</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/08/d1/39yDFzBT_o.png"></p> 
<p>在每个通道上运行，其计算量比普通卷积少得多。实际上，Ghost模块中可能有几种不同的线性运算，例如3x3和5x5线性内核，将在实验部分进行分析。</p> 
<p>在每个通道上运行，其计算量比普通卷积少得多。实际上，Ghost模块中可能有几种不同的线性运算，例如3x3和5x5线性内核，将在实验部分进行分析。</p> 
<h4><strong>构建GhostNet</strong></h4> 
<p><strong>Ghost Bottleneck：</strong>利用Ghost模块的优势，作者介绍了专门为小型CNN设计的Ghost bottleneck（G-bneck）。如图3所示，Ghost bottleneck似乎类似于ResNet中的基本残差块（Basic Residual Block），其中集成了多个卷积层和shortcut。Ghost bottleneck主要由两个堆叠的Ghost模块组成。第一个Ghost模块用作扩展层，增加了通道数。这里将输出通道数与输入通道数之比称为expansion ratio。第二个Ghost模块减少通道数，以与shortcut路径匹配。然后，使用shortcut连接这两个Ghost模块的输入和输出。这里借鉴了MobileNetV2，第二个Ghost模块之后不使用ReLU，其他层在每层之后都应用了批量归一化（BN）和ReLU非线性激活。上述Ghost bottleneck适用于stride= 1，对于stride = 2的情况，shortcut路径由下采样层和stride = 2的深度卷积（Depthwise Convolution）来实现。出于效率考虑，Ghost模块中的初始卷积是点卷积（Pointwise Convolution）。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/2b/b7/zXXitO3r_o.png"></p> 
<p>Ghost bottleneck</p> 
<p><strong>GhostNet：</strong>基于Ghost bottleneck，作者提出GhostNet，如表1所示。作者遵循MobileNetV3的基本体系结构的优势，然后使用Ghost bottleneck替换MobileNetV3中的bottleneck。GhostNet主要由一堆Ghost bottleneck组成，其中Ghost bottleneck以Ghost模块为构建基础。第一层是具有16个卷积核的标准卷积层，然后是一系列Ghost bottleneck，通道逐渐增加。这些Ghost bottleneck根据其输入特征图的大小分为不同的阶段。除了每个阶段的最后一个Ghost bottleneck是stride = 2，其他所有Ghost bottleneck都以stride = 1进行应用。最后，利用全局平均池和卷积层将特征图转换为1280维特征向量以进行最终分类。SE模块也用在了某些Ghost bottleneck中的残留层，如表1中所示。与MobileNetV3相比，这里用ReLU换掉了Hard-swish激活函数。尽管进一步的超参数调整或基于自动架构搜索的Ghost模块将进一步提高性能，但表1所提供的架构提供了一个基本设计参考。</p> 
<p></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/47/ff/nSEn15l0_o.png"></p> 
<p>GhostNet网络架构</p> 
<h4>GhostNet性能</h4> 
<p><strong>ImageNet分类数据集：</strong>为了验证所提出的GhostNet的优越性，作者对ImageNet分类任务进行了实验。在ImageNet验证集上报告的所有结果均是single crop的top-1的性能。对于GhostNet，为简单起见，作者在初始卷积中设置了内核大小k = 1，在所有Ghost模块中设置了s = 2和 d = 3。作者和现有最优秀的几种小型网络结构作对比，包括MobileNet系列、ShuffleNet系列、IGCV3、ProxylessNAS、FBNet、MnasNet等。结果汇总在表5中，这些模型分为3个级别的计算复杂性，即~50，~150和200-300 MFLOPs。从结果中我们可以看到，通常较大的FLOPs会在这些小型网络中带来更高的准确性，这表明了它们的有效性。而GhostNet在各种计算复杂度级别上始终优于其他竞争对手，主要是因为GhostNet在利用计算资源生成特征图方面效率更高。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b8/56/LnfMJ9Hr_o.png"></p> 
<p>GhostNet在ImageNet数据集的表现</p> 
<h4><strong>硬件推理速度：胜过其他最新模型，如谷歌MobileNet系列，ProxylessNAS，FBNet和MnasNet。</strong></h4> 
<p>由于提出的GhostNet是为移动设备设计的，因此作者使用TFLite工具（下次用MindSpore Lite）在基于ARM的手机华为P30Pro上进一步测量GhostNet和其他模型的实际推理速度。遵循MobileNet中的常用设置，作者使用Batch size为1的单线程模式。从图6的结果中，我们可以看到与具有相同延迟的MobileNetV3相比，GhostNet大约提高了0.5%的top-1的准确性，另一方面GhostNet需要更少的运行时间来达到相同的精度。例如，精度为75.0％的GhostNet仅具有40毫秒的延迟，而精度类似的MobileNetV3大约需要46毫秒来处理一张图像。总体而言，作者的模型总体上胜过其他最新模型，例如谷歌MobileNet系列，ProxylessNAS，FBNet和MnasNet。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/c2/b0/A1fVbxme_o.png"></p> 
<p>GhostNet和其他模型的FLOPs、推理速度对比</p> 
<p><strong>GhostNet模型放大</strong></p> 
<p>为了进一步提升深度学习模型在目标数据集上的准确率，常用的方法是模型缩放，EfficientNet，FBNetV2和RegNet通过调整网络的深度，宽度和输入分辨率，在Imagenet数据集上取得了更高的准确率。但是这些方法都是基于人工的经验或者统计分析而获得的，而经验和统计数据都是基于大量的小网络结构获得的，因此这种方法对于模型放大并不适用。</p> 
<p>我们提出了一种基于网络结构搜索实现模型放大的方法，目标是把新增加的计算量（FLOPs）放到网络中最合适的位置，从而达到计算量的最优分配和最优利用。使用公式表达如下：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/9c/3c/0t2236k2_o.png"></p> 
<p>上式中，N表示网络，θ表示网络中的待训练参数，r,d,w分别表示网络的输入分辨率，深度和宽度，δ是预设的误差阈值，T表示目标计算量。</p> 
<p>通过对每个stage进行深度和宽度的搜索，可以达到更细粒度的计算量分配和利用的目标，整体方法架构如图所示：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/17/c2/Yjpu4or0_o.png"></p> 
<p>具体地，我们将整个搜索过程分为多个阶段，从一个给定的基础网络模型开始，在每一阶段不断增加计算量，然后搜索当前计算量下的最优网络结构，并把当前的最优网络结构加入到一个最优网络结构集合中；在下一个搜索阶段，从当前的最优网络结构集合出发，搜索基于前面的最优网络结构在当前计算量下的网络结构，并进行快速评估，保留当前的最优网络结构并加入到最优网络结构集合中。这是一种动态规划的思想，最后我们会获得一个最优网络结构的集合，包括的不同计算量下的最优网络结构。</p> 
<p>在Imagenet上，我们利用的提出的方法将GhostNet基础网络进行放大，构建出GhostNet-B1和B4。如下表，我们的GhostNet大模型取得了比EfficientNet系列更好的结果。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/0a/ad/eotjH1e7_o.png"></p> 
<p><strong>GhostNet多场景应用，作为骨干网络，可以用于各类下游任务，比如细粒度图像识别和目标检测</strong></p> 
<h4><strong>细粒度图像识别：</strong></h4> 
<p>细粒度图像识别任务是对属于同一大类的图像进一步做细分类，比如Oxford Pets数据集就是用于做猫狗细分类任务。下表展示了GhostNet用于猫狗品种分类的结果，在计算量更小、速度更快的情况下，GhostNet取得了比MobileNetV2更好的识别效果。</p> 
<p>GhostNet结合做猫狗品种识别的模型也已经发布在MindSpore Hub，欢迎开发者和高校师生试用。</p> 
<ul><li> <p>预训练模型：</p> <p><em>https://mindspore.cn/resources/hub/details?noah-cvlab/gpu/1.0/ghostnet_v1.0_oxford_pets</em></p> </li></ul> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/b7/f3/4xaDD9Kd_o.png"></p> 
<p>GhostNet在Oxford Pets猫狗品种分类的表现</p> 
<h4><strong>目标检测：</strong></h4> 
<p>为了进一步评估GhostNet的泛化能力，作者在MS COCO数据集上进行了目标检测实验。具有功能金字塔网络（FPN）的两阶段Faster R-CNN和单阶段的RetinaNet作为baseline，而GhostNet用于骨干网络做特征提取器。下表显示了检测结果，其中FLOPs是使用224x224输入图像计算的。通过使用显着降低的计算成本，GhostNet可以在单阶段的RetinaNet和两阶段的Faster R-CNN框架上达到和MobileNetV2和MobileNetV3类似的mAP。</p> 
<p>GhostNet结合SSD做目标检测的代码也已经发布在MindSpore，欢迎开发者和高校师生试用。</p> 
<ul><li> <p>代码：</p> <p><em>https://gitee.com/mindspore/models/tree/master/research/cv/ssd_ghostnet</em></p> </li><li> <p>预训练模型：</p> <p><em>https://mindspore.cn/resources/hub/details?noah-cvlab/ascend/1.0/ghostnet_ssd_v1.0</em></p> <p class="img-center"><img alt="" src="https://images2.imgbox.com/24/08/DyjGw2nP_o.png"></p> </li></ul> 
<p>GhostNet在COCO目标检测任务的表现</p> 
<p><strong>基于MindSpore的GhostNet总结和开源地址，欢迎体验</strong></p> 
<p>GhostNet系列模型已经在MindSpore开源，路径汇总如下，欢迎开发者、研究人员、高校师生试用。</p> 
<p>GhostNet训练：</p> 
<p><em>https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet</em></p> 
<p>GhostNet图像分类：</p> 
<p><em>https://mindspore.cn/resources/hub/details?noah-cvlab/gpu/1.0/ghostnet_v1.0_oxford_pets</em></p> 
<p>GhostNet目标检测：</p> 
<p><em>https://gitee.com/mindspore/models/tree/master/research/cv/ssd_ghostnet</em></p> 
<p>GhostNet量化：</p> 
<p><em>https://gitee.com/mindspore/models/tree/master/research/cv/ghostnet_quant</em></p> 
<h4>一个好消息：</h4> 
<p>最后告诉各位开发者一个好消息：根据Paperswithcode网站统计，基于MindSpore的AI论文2021年10月份在所有AI框架中占比11%，按月统计进入全球第二，感谢CAAI和各位高校老师支持，我们一起继续努力做好AI科研创新</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/4d/45/bZts9w87_o.png"></p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ad1b80325ed5e20c067febf20b97faea/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">一、python基础入门2-变量和数据类型</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/04293247373a413f9a2f19c0d13bd057/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java岛屿数量(DFS)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>