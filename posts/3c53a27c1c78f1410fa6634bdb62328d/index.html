<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>语义分割中的损失 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="语义分割中的损失" />
<meta property="og:description" content="语义分割中的损失 loss list: CEBCEWCEFocal lossDice lossIOU lossTversky loss敏感性–特异性 lossGeneralized Dice lossBCE &#43; Dice lossDice &#43; Focal lossExponential Logarithmic loss
以上部分有一篇博客讲得比较清楚：
原文博客链接: (https://blog.csdn.net/m0_37477175/article/details/83004746) Lov´asz-Softmaxloss
请看我的另一篇博客：（https://blog.csdn.net/weixin_41134246/article/details/103280203） Boundary loss 提出generalized Dice loss，对Dice loss在计算中加上权重，主要是为了解决样本不平衡问题。
根据这一个权重函数可以看出来， r l n r_{ln} rln​代表这一个类的label map之和，当这一个类别像素值少的时候权重会变大，像素值大的时候权重会变小。
主要还是应用权重来解决不平衡的问题。
还有一个部分是边界损失
想法比较简单，用groundtruth计算出边界部分，然后在预测值对这一部分进行损失计算，对各像素损失求和。
代码链接：（https://github.com/LIVIAETS/surface-loss） ConservativeLoss 核心思想是为了在不同领域的适应能力中，有较强的泛化性。对表现极度好的结果进行惩罚，从而鼓励中等表现得结果。
如图所示，根据置信度来计算CL loss，相应得进行惩罚。 λ \lambda λ为5， a a a为 e e e。
combo loss
代码地址：https://github.com/asgsaeid/ComboLoss/blob/master/combo_loss.py
dice loss &#43; weighted ce
β \beta β控制 假阳性和假阴性的权重，大于0.5惩罚假阳性，小于0.5惩罚假阴性。
a a a控制dice loss 和weighted ce loss的权重。 边界部分有权重的loss Active Contour Loss" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/3c53a27c1c78f1410fa6634bdb62328d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-12-02T22:19:25+08:00" />
<meta property="article:modified_time" content="2019-12-02T22:19:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">语义分割中的损失</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>语义分割中的损失</h2> 
<h4><a id="loss_list_2"></a>loss list:</h4> 
<ul><li>CE</li><li>BCE</li><li>WCE</li><li>Focal loss</li><li>Dice loss</li><li>IOU loss</li><li>Tversky loss</li><li>敏感性–特异性 loss</li><li>Generalized Dice loss</li><li>BCE + Dice loss</li><li>Dice + Focal loss</li><li>Exponential Logarithmic loss<br> 以上部分有一篇博客讲得比较清楚：<br> 原文博客链接: (https://blog.csdn.net/m0_37477175/article/details/83004746)</li></ul> 
<hr> 
<ul><li>Lov´asz-Softmaxloss<br> 请看我的另一篇博客：（https://blog.csdn.net/weixin_41134246/article/details/103280203）</li></ul> 
<hr> 
<ul><li>Boundary loss</li></ul> 
<hr> 
<p>提出generalized Dice loss，对Dice loss在计算中加上权重，主要是为了解决样本不平衡问题。<br> <img src="https://images2.imgbox.com/5a/bf/ZW6No1LK_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/27/ad/b3HxlSgM_o.png" alt="在这里插入图片描述"><br> 根据这一个权重函数可以看出来，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          r 
         
         
         
           l 
          
         
           n 
          
         
        
       
      
        r_{ln} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>代表这一个类的label map之和，当这一个类别像素值少的时候权重会变大，像素值大的时候权重会变小。<br> 主要还是应用权重来解决不平衡的问题。</p> 
<ul><li>还有一个部分是边界损失<br> 想法比较简单，用groundtruth计算出边界部分，然后在预测值对这一部分进行损失计算，对各像素损失求和。<br> <img src="https://images2.imgbox.com/7d/e6/1TNmtjJN_o.png" alt="在这里插入图片描述"><br> 代码链接：（https://github.com/LIVIAETS/surface-loss）</li></ul> 
<hr> 
<ul><li>ConservativeLoss</li></ul> 
<hr> 
<p>核心思想是为了在不同领域的适应能力中，有较强的泛化性。对表现极度好的结果进行惩罚，从而鼓励中等表现得结果。<br> <img src="https://images2.imgbox.com/b5/eb/7VMsFm3e_o.png" alt="在这里插入图片描述"><br> 如图所示，根据置信度来计算CL loss，相应得进行惩罚。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         λ 
        
       
      
        \lambda 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">λ</span></span></span></span></span>为5， <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         a 
        
       
      
        a 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">a</span></span></span></span></span>为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         e 
        
       
      
        e 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">e</span></span></span></span></span>。</p> 
<hr> 
<ul><li>combo loss<br> 代码地址：https://github.com/asgsaeid/ComboLoss/blob/master/combo_loss.py<br> <img src="https://images2.imgbox.com/fc/57/xZvoYgFM_o.png" alt="在这里插入图片描述"><br> dice loss + weighted ce<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          β 
         
        
       
         \beta 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.05278em;">β</span></span></span></span></span>控制 假阳性和假阴性的权重，大于0.5惩罚假阳性，小于0.5惩罚假阴性。<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          a 
         
        
       
         a 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">a</span></span></span></span></span>控制dice loss 和weighted ce loss的权重。</li></ul> 
<hr> 
<h5><a id="loss_51"></a>边界部分有权重的loss</h5> 
<hr> 
<ul><li>Active Contour Loss<br> 代码地址：（https://github.com/xuuuuuuchen/Active-Contour-Loss/blob/master/Active-Contour-Loss.py）<br> <img src="https://images2.imgbox.com/81/33/65cjBZKG_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/83/24/L7EE6ZDm_o.png" alt="在这里插入图片描述"> 
  <ul><li>最终的loss是Length 和Region 的和，代码中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
        
         
          
          
            λ 
           
          
         
           \lambda 
          
         
       </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em;"></span><span class="mord mathdefault">λ</span></span></span></span></span>设为的1，这是一个超参数。</li><li>首先看一下整个损失，它的计算方式都是用的差的平方的形式。</li><li>然后Length loss部分，只用了pred的信息，最小化梯度的大小，在这里我的理解是，它想达到的目的是让物体的内部尽量平滑，只有边界部分有这个梯度的变化。</li><li>接着是Region部分，使用label的监督信息对每一个点进行监督训练。</li><li>总结一下整个地方，感觉在边界部分，这两个Loss有冲突的地方，Length损失在边界部分会变大，但是它因为没有监督信息，它趋向于对所有位置都平滑处理，但是Region部分有监督信息，为了让边界部分损失变小会将物体和边界分开。也因为是用的差的平方的形式，边界部分的预测值概率应该是平滑下降的，骤降的loss太大，也就是惩罚太大。感觉是对整个预测结果作了一个平滑处理。</li></ul> </li></ul> 
<hr> 
<ul><li>Distance Map Loss Penalty Term for Semantic Segmentation</li></ul> 
<p><img src="https://images2.imgbox.com/78/67/qeEPK6N3_o.png" alt="在这里插入图片描述"><br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ϕ 
        
       
      
        \phi 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.88888em; vertical-align: -0.19444em;"></span><span class="mord mathdefault">ϕ</span></span></span></span></span>代表 边界的距离图，如图所示：<br> <img src="https://images2.imgbox.com/b0/36/vQ2Ejf9R_o.png" alt="在这里插入图片描述"><br> 结合上面的公式，就代表着边界部分的权重会高于其他地方，其他的没有改动。</p> 
<hr> 
<ul><li>NonAdjacencyLoss<br> 代码地址：https://github.com/trypag/NonAdjLoss<br> 创新点是加入了各个类之间的邻接矩阵，用一个子网络去预测这个矩阵。即可以监督学习也可以半监督的学习。<br> <img src="https://images2.imgbox.com/2d/60/xdKXtfNM_o.png" alt="在这里插入图片描述"><br> 前面一部分是一般的损失，如dice或交叉熵等，后面是用邻接矩阵加的限定损失。</li></ul> 
<p><img src="https://images2.imgbox.com/67/16/BBgRakfH_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/fb/58/CYAbDvvD_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/99/33/oAwEx56N_o.png" alt="在这里插入图片描述"><br> 求<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          a 
         
         
         
           i 
          
         
           j 
          
         
        
        
        
          ( 
         
        
          ϕ 
         
        
          ) 
         
        
       
      
        a_{ij}\left( \phi \right) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.03611em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord mathdefault">ϕ</span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span>这个过程是离线的过程，根据总的有标签的数据求一个最后求和的邻接矩阵“模板”。形成一个先验的知识，对于半监督无标签时，这个G(w)这一项的损失也可以根据这个“模板”进行计算。对于医疗图像来说，这样做也是有一定道理的。<br> 但是我自己认为这样做会无法考虑到空间中的信息，只是考虑了类与类之间的信息。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d945263b97e558b5edf212b77ad2bd33/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">anaconda和python库的文件位置</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8d176feca4779f8b15a068bec8b6cda9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux下仅主机模式、桥接模式和NAT模式的区别</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>