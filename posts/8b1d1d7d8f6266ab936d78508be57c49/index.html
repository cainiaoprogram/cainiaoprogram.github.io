<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg解码H264视频裸流(直接可用) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg解码H264视频裸流(直接可用)" />
<meta property="og:description" content="1、写在前面
此文章主要包含解码H264视频流数据，主要有以下几点：
1、H264视频帧为Annex B格式，若使用AVCC格式可自行研究；
2、H264视频裸流，非解码视频文件(若有需要我后期可添加这部分代码);
3、支持输出RGB24或YUV420格式，其他可自行修改；
4、FFmpeg官网代码迭代及接口变更较大，代码适应于FFmpeg3.4.2&#34;Cantor&#34;、3.3.7&#34;Hilbert&#34;等版本，较旧接口请看旧版本代码；
2、新版本 FFmpegVideoDecoder.h
#include &lt;libavcodec/avcodec.h&gt; /** 视频流解码器初始化 @param ctx 解码参数结构体AVCodecParameters @see FFmpeg_H264DecoderInit，此为解码H264视频流 @return 初始化成功返回0，否则&lt;0 */ int FFmpeg_VideoDecoderInit(AVCodecParameters *ctx); /** H264视频流解码器初始化 @return 初始化成功返回0，否则&lt;0 */ int FFmpeg_H264DecoderInit(void); /** 释放解码器 @return 初始化成功返回0，否则&lt;0 */ int FFmpeg_VideoDecoderRelease(void); //return 0:暂未收到解码数据，-1：解码失败，1：解码成功 /** 解码视频流数据 @param inbuf 视频裸流数据 @param inbufSize 视频裸流数据大小 @param framePara 接收帧参数数组：{width,height,linesize1,linesiz2,linesize3} @param outRGBBuf 输出RGB数据(若已申请内存) @param outYUVBuf 输出YUV数据(若已申请内存) @return 成功返回解码数据帧大小，否则&lt;=0 */ int FFmpeg_H264Decode(unsigned char * inbuf, int inbufSize, int *framePara, unsigned char *outRGBBuf, unsigned char **outYUVBuf); FFmpegVideoDecoder." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/8b1d1d7d8f6266ab936d78508be57c49/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-30T20:00:00+08:00" />
<meta property="article:modified_time" content="2023-11-30T20:00:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg解码H264视频裸流(直接可用)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>1、写在前面</p> 
<p>此文章主要包含解码H264视频流数据，主要有以下几点：</p> 
<p>1、H264视频帧为Annex B格式，若使用AVCC格式可自行研究；</p> 
<p>2、H264视频裸流，非解码视频文件(若有需要我后期可添加这部分代码);</p> 
<p>3、支持输出RGB24或YUV420格式，其他可自行修改；</p> 
<p>4、FFmpeg官网代码迭代及接口变更较大，代码适应于FFmpeg3.4.2"Cantor"、3.3.7"Hilbert"等版本，较旧接口请看旧版本代码；</p> 
<h4>2、新版本</h4> 
<p>FFmpegVideoDecoder.h</p> 
<pre><code>#include &lt;libavcodec/avcodec.h&gt;
 
/**
 视频流解码器初始化
 @param ctx 解码参数结构体AVCodecParameters
 @see FFmpeg_H264DecoderInit，此为解码H264视频流
 @return 初始化成功返回0，否则&lt;0
 */
int FFmpeg_VideoDecoderInit(AVCodecParameters *ctx);
 
/**
 H264视频流解码器初始化
 @return 初始化成功返回0，否则&lt;0
 */
int FFmpeg_H264DecoderInit(void);
 
/**
 释放解码器
 @return 初始化成功返回0，否则&lt;0
 */
int FFmpeg_VideoDecoderRelease(void);
 
//return 0:暂未收到解码数据，-1：解码失败，1：解码成功
 
/**
 解码视频流数据
 @param inbuf 视频裸流数据
 @param inbufSize 视频裸流数据大小
 @param framePara 接收帧参数数组：{width,height,linesize1,linesiz2,linesize3}
 @param outRGBBuf 输出RGB数据(若已申请内存)
 @param outYUVBuf 输出YUV数据(若已申请内存)
 @return 成功返回解码数据帧大小，否则&lt;=0
 */
int FFmpeg_H264Decode(unsigned char * inbuf, int inbufSize, int *framePara, unsigned char *outRGBBuf, unsigned char **outYUVBuf);</code></pre> 
<p>FFmpegVideoDecoder.c</p> 
<pre><code>#include &lt;libavformat/avformat.h&gt;
#include &lt;libswscale/swscale.h&gt;
#include "FFmpegVideoDecoder.h"
 
struct AVCodecContext *pAVCodecCtx_decoder = NULL;
struct AVCodec *pAVCodec_decoder;
struct AVPacket mAVPacket_decoder;
struct AVFrame *pAVFrame_decoder = NULL;
struct SwsContext* pImageConvertCtx_decoder = NULL;
struct AVFrame *pFrameYUV_decoder = NULL;
 
int FFmpeg_VideoDecoderInit(AVCodecParameters *codecParameters)
{
    if (!codecParameters) {
        CPrintf("Source codec context is NULL.");   //CPrintf需替换为printf
        return -1;
    }
    FFmpeg_VideoDecoderRelease();
    avcodec_register_all();
    
    pAVCodec_decoder = avcodec_find_decoder(codecParameters-&gt;codec_id);
    if (!pAVCodec_decoder) {
        CPrintf1("Can not find codec:%d\n", codecParameters-&gt;codec_id);
        return -2;
    }
    
    pAVCodecCtx_decoder = avcodec_alloc_context3(pAVCodec_decoder);
    if (!pAVCodecCtx_decoder) {
        CPrintf("Failed to alloc codec context.");
        FFmpeg_VideoDecoderRelease();
        return -3;
    }
    
    if (avcodec_parameters_to_context(pAVCodecCtx_decoder, codecParameters) &lt; 0) {
        CPrintf("Failed to copy avcodec parameters to codec context.");
        FFmpeg_VideoDecoderRelease();
        return -3;
    }
 
    
    if (avcodec_open2(pAVCodecCtx_decoder, pAVCodec_decoder, NULL) &lt; 0){
        CPrintf("Failed to open h264 decoder");
        FFmpeg_VideoDecoderRelease();
        return -4;
    }
    
    av_init_packet(&amp;mAVPacket_decoder);
    
    pAVFrame_decoder = av_frame_alloc();
    pFrameYUV_decoder = av_frame_alloc();
    
    return 0;
}
 
int FFmpeg_H264DecoderInit()
{
    avcodec_register_all();
    AVCodec *pAVCodec = avcodec_find_decoder(AV_CODEC_ID_H264);
    if (!pAVCodec){
        CPrintf("can not find H264 codec\n");
        return -1;
    }
 
    AVCodecContext *pAVCodecCtx = avcodec_alloc_context3(pAVCodec);
    if (pAVCodecCtx == NULL) {
        CPrintf("Could not alloc video context!\n");
        return -2;
    }
    
    AVCodecParameters *codecParameters = avcodec_parameters_alloc();
    if (avcodec_parameters_from_context(codecParameters, pAVCodecCtx) &lt; 0) {
        CPrintf("Failed to copy avcodec parameters from codec context.");
        avcodec_parameters_free(&amp;codecParameters);
        avcodec_free_context(&amp;pAVCodecCtx);
        return -3;
    }
    
    int ret = FFmpeg_VideoDecoderInit(codecParameters);
    avcodec_parameters_free(&amp;codecParameters);
    avcodec_free_context(&amp;pAVCodecCtx);
    
    return ret;
}
 
int FFmpeg_VideoDecoderRelease() {
    if (pAVCodecCtx_decoder != NULL) {
        avcodec_free_context(&amp;pAVCodecCtx_decoder);
        pAVCodecCtx_decoder = NULL;
    }
    
    if (pAVFrame_decoder != NULL) {
        av_packet_unref(&amp;mAVPacket_decoder);
        av_free(pAVFrame_decoder);
        pAVFrame_decoder = NULL;
    }
    
    if (pFrameYUV_decoder) {
        av_frame_unref(pFrameYUV_decoder);
        av_free(pFrameYUV_decoder);
        pFrameYUV_decoder = NULL;
    }
    
    if (pImageConvertCtx_decoder) {
        sws_freeContext(pImageConvertCtx_decoder);
    }
    
    av_packet_unref(&amp;mAVPacket_decoder);
    
    return 0;
}
 
int FFmpeg_H264Decode(unsigned char *inbuf, int inbufSize, int *framePara, unsigned char *outRGBBuf, unsigned char **outYUVBuf)
{
    if (!pAVCodecCtx_decoder || !pAVFrame_decoder || !inbuf || inbufSize&lt;=0 || !framePara || (!outRGBBuf &amp;&amp; !outYUVBuf)) {
        return -1;
    }
    av_frame_unref(pAVFrame_decoder);
    av_frame_unref(pFrameYUV_decoder);
    
    framePara[0] = framePara[1] = 0;
    mAVPacket_decoder.data = inbuf;
    mAVPacket_decoder.size = inbufSize;
    
    int ret = avcodec_send_packet(pAVCodecCtx_decoder, &amp;mAVPacket_decoder);
    if (ret == 0) {
        ret = avcodec_receive_frame(pAVCodecCtx_decoder, pAVFrame_decoder);
        if (ret == 0) {
            framePara[0] = pAVFrame_decoder-&gt;width;
            framePara[1] = pAVFrame_decoder-&gt;height;
            
            if (outYUVBuf) {
                *outYUVBuf = (unsigned char *)pAVFrame_decoder-&gt;data;
                framePara[2] = pAVFrame_decoder-&gt;linesize[0];
                framePara[3] = pAVFrame_decoder-&gt;linesize[1];
                framePara[4] = pAVFrame_decoder-&gt;linesize[2];
            } else if (outRGBBuf) {
                pFrameYUV_decoder-&gt;data[0] = outRGBBuf;
                pFrameYUV_decoder-&gt;data[1] = NULL;
                pFrameYUV_decoder-&gt;data[2] = NULL;
                pFrameYUV_decoder-&gt;data[3] = NULL;
                int linesize[4] = { pAVCodecCtx_decoder-&gt;width * 3, pAVCodecCtx_decoder-&gt;height * 3, 0, 0 };
                pImageConvertCtx_decoder = sws_getContext(pAVCodecCtx_decoder-&gt;width, pAVCodecCtx_decoder-&gt;height, AV_PIX_FMT_YUV420P, pAVCodecCtx_decoder-&gt;width, pAVCodecCtx_decoder-&gt;height, AV_PIX_FMT_RGB24, SWS_FAST_BILINEAR, NULL, NULL, NULL);
                sws_scale(pImageConvertCtx_decoder, (const uint8_t* const *) pAVFrame_decoder-&gt;data, pAVFrame_decoder-&gt;linesize, 0, pAVCodecCtx_decoder-&gt;height, pFrameYUV_decoder-&gt;data, linesize);
                sws_freeContext(pImageConvertCtx_decoder);
                
                return 1;
            }
        } else if (ret == AVERROR(EAGAIN)) {
            return 0;
        } else {
            return -1;
        }
    }
    
    return 0;
}</code></pre> 
<h4>3、旧版本</h4> 
<p>FFmpegVideoDecoder.h</p> 
<pre><code>int FFmpeg_VideoDecoderInit(AVCodecContext *ctx);
int FFmpeg_H264DecoderInit(void);
int FFmpeg_VideoDecoderRelease(void);
int FFmpeg_H264Decode(unsigned char * inbuf, int inbufSize, int *framePara, unsigned char *outRGBBuf, unsigned char **outYUVBuf);</code></pre> 
<p>FFmpegVideoDecoder.c</p> 
<pre><code>#include &lt;libavformat/avformat.h&gt;
#include &lt;libswscale/swscale.h&gt;
#include "FFmpegVideoDecoder.h"
 
struct AVCodecContext *pAVCodecCtx = NULL;
struct AVCodec *pAVCodec;
struct AVPacket mAVPacket;
struct AVFrame *pAVFrame = NULL;
struct SwsContext* pImageConvertCtx = NULL;
struct AVFrame *pFrameYUV = NULL;
 
int FFmpeg_VideoDecoderInit(AVCodecContext *ctx)
{
    if (!ctx) {
        cv_printf("Source codec context is NULL.");     //cv_printf需替换为printf
        return -1;
    }
    FFmpeg_VideoDecoderRelease();
    avcodec_register_all();
    
    pAVCodec = avcodec_find_decoder(ctx-&gt;codec_id);
    if (!pAVCodec) {
        cv_printf("Can not find codec:%d\n", ctx-&gt;codec_id);
        return -2;
    }
    
    pAVCodecCtx = avcodec_alloc_context3(pAVCodec);
    if (!pAVCodecCtx || avcodec_copy_context(pAVCodecCtx, ctx) != 0) {
        cv_printf("Failed to alloc codec context.");
        FFmpeg_VideoDecoderRelease();
        return -3;
    }
    
    if (avcodec_open2(pAVCodecCtx, pAVCodec, NULL) &lt; 0){
        cv_printf("Failed to open h264 decoder");
        FFmpeg_VideoDecoderRelease();
        return -4;
    }
    
    av_init_packet(&amp;mAVPacket);
    
    pAVFrame = av_frame_alloc();
    pFrameYUV = av_frame_alloc();
    
    return 0;
}
 
int FFmpeg_H264DecoderInit()
{
    avcodec_register_all();
    AVCodec *pAVCodec = avcodec_find_decoder(AV_CODEC_ID_H264);
    if (!pAVCodec){
        cv_printf("can not find H264 codec\n");
        return -1;
    }
    
    AVCodecContext *pAVCodecCtx = avcodec_alloc_context3(pAVCodec);
    int ret = FFmpeg_VideoDecoderInit(pAVCodecCtx);
    
    if (pAVCodecCtx || ret &lt; 0) {
        avcodec_free_context(&amp;pAVCodecCtx);
        pAVCodecCtx = NULL;
    }
    
    return ret;
}
 
int FFmpeg_VideoDecoderRelease() {
    if (pAVCodecCtx != NULL) {
        avcodec_close(pAVCodecCtx);
        avcodec_free_context(&amp;pAVCodecCtx);
        pAVCodecCtx = NULL;
    }
    
    if (pAVFrame != NULL) {
        av_packet_unref(&amp;mAVPacket);
        av_free(pAVFrame);
        pAVFrame = NULL;
    }
    
    if (pFrameYUV) {
        av_frame_unref(pFrameYUV);
        av_free(pFrameYUV);
        pFrameYUV = NULL;
    }
    
    if (pImageConvertCtx) {
        sws_freeContext(pImageConvertCtx);
    }
    
    av_packet_unref(&amp;mAVPacket);
    
    return 0;
}
 
int FFmpeg_H264Decode(unsigned char * inbuf, int inbufSize, int *framePara, unsigned char *outRGBBuf, unsigned char **outYUVBuf)
{
    av_frame_unref(pAVFrame);
    av_frame_unref(pFrameYUV);
    
    framePara[0] = framePara[1] = 0;
    mAVPacket.data = inbuf;
    mAVPacket.size = inbufSize;
    
    if (inbuf==NULL || inbufSize&lt;=0) {
        return -1;
    }
    
    int len = -1, got_picture = 0;
    len = avcodec_decode_video2(pAVCodecCtx, pAVFrame, &amp;got_picture, &amp;mAVPacket);
    if (len &lt; 0) {
        cv_printf("解码错误:%d\n",len);
        return len;
    }
   
    if (got_picture &gt; 0) {
        framePara[0] = pAVFrame-&gt;width;
        framePara[1] = pAVFrame-&gt;height;
        
        if (outYUVBuf) {
            *outYUVBuf = (unsigned char *)pAVFrame-&gt;data;
            framePara[2] = pAVFrame-&gt;linesize[0];
            framePara[3] = pAVFrame-&gt;linesize[1];
            framePara[4] = pAVFrame-&gt;linesize[2];
        } else if (outRGBBuf) {
            pFrameYUV-&gt;data[0] = outRGBBuf;
            pFrameYUV-&gt;data[1] = NULL;
            pFrameYUV-&gt;data[2] = NULL;
            pFrameYUV-&gt;data[3] = NULL;
            int linesize[4] = { pAVCodecCtx-&gt;width * 3, pAVCodecCtx-&gt;height * 3, 0, 0 };
            pImageConvertCtx = sws_getContext(pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, AV_PIX_FMT_YUV420P, pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, AV_PIX_FMT_RGB24, SWS_FAST_BILINEAR, NULL, NULL, NULL);
            sws_scale(pImageConvertCtx, (const uint8_t* const *) pAVFrame-&gt;data, pAVFrame-&gt;linesize, 0, pAVCodecCtx-&gt;height, pFrameYUV-&gt;data, linesize);
            sws_freeContext(pImageConvertCtx);
        }
    }
    
    return len;
}</code></pre> 
<p></p> 
<p>版权声明：本文为CSDN博主「W2Y」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。</p> 
<p>原文链接：<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/lizhijian21/article/details/80495684" rel="nofollow" title="FFmpeg解码H264视频裸流(直接可用)-CSDN博客">FFmpeg解码H264视频裸流(直接可用)-CSDN博客</a></p> 
<p><span style="color:#fe2c24;"><strong>★文末名片可以免费领取音视频开发学习资料，内容包括（FFmpeg ，webRTC ，rtmp ，hls ，rtsp ，ffplay ，srs）以及音视频学习路线图等等。</strong></span></p> 
<p><span style="color:#fe2c24;"><strong>见下方!↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓</strong></span></p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0bc1405f8a705569827b2acdaab6c0d1/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">js中reduce()函数的用法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5616643428fdf3221269b6bae812a5b1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【栈与队列】栈与队列的相互转换OJ题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>