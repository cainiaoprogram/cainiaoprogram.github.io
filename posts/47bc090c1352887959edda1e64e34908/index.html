<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch实现RNN - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch实现RNN" />
<meta property="og:description" content="RNN实现分类问题 import torch import torch.nn as nn from torch.autograd import Variable import torchvision.datasets as dsets #包括了一些数据库，图片的数据库也包含了 import torchvision.transforms as transforms import matplotlib.pyplot as plt #超参数 EPOCH = 1 BATCH_SIZE = 64 TIME_STEP = 28 #rnn time step--&gt;image height INPUT_SIZE = 28 #rnn input size--&gt;image width LR = 0.01 DOWNLOAD_MNIST = False #已经下载好了，download设置成false #准备训练数据 train_data = dsets.MNIST( root = r&#39;D:\python\minist&#39;, #存储路径 train = True, transform = transforms.ToTensor(), #把下载的数据改成Tensor形式 #把(0-255)转换成(0-1) download = DOWNLOAD_MNIST #如果没下载就确认下载,如果已经下载了就填False ) #把train_data变成train_loader，训练起来比较有效率 train_loader = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/47bc090c1352887959edda1e64e34908/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-07T22:08:49+08:00" />
<meta property="article:modified_time" content="2020-07-07T22:08:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch实现RNN</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="RNN_0"></a>RNN实现分类问题</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> dsets <span class="token comment">#包括了一些数据库，图片的数据库也包含了</span>
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment">#超参数</span>
EPOCH <span class="token operator">=</span> <span class="token number">1</span>
BATCH_SIZE <span class="token operator">=</span> <span class="token number">64</span>
TIME_STEP <span class="token operator">=</span> <span class="token number">28</span>  <span class="token comment">#rnn time step--&gt;image height</span>
INPUT_SIZE <span class="token operator">=</span> <span class="token number">28</span>  <span class="token comment">#rnn input size--&gt;image width</span>
LR <span class="token operator">=</span> <span class="token number">0.01</span>
DOWNLOAD_MNIST <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token comment">#已经下载好了，download设置成false</span>



<span class="token comment">#准备训练数据</span>
train_data <span class="token operator">=</span> dsets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>
        root <span class="token operator">=</span> r<span class="token string">'D:\python\minist'</span><span class="token punctuation">,</span> <span class="token comment">#存储路径</span>
        train <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>
        transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">#把下载的数据改成Tensor形式</span>
        <span class="token comment">#把(0-255)转换成(0-1)</span>
        download <span class="token operator">=</span> DOWNLOAD_MNIST <span class="token comment">#如果没下载就确认下载,如果已经下载了就填False</span>
        <span class="token punctuation">)</span>
<span class="token comment">#把train_data变成train_loader，训练起来比较有效率</span>
train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset <span class="token operator">=</span> train_data<span class="token punctuation">,</span>batch_size <span class="token operator">=</span> BATCH_SIZE<span class="token punctuation">,</span>shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>




<span class="token comment">#准备测试数据</span>
test_data <span class="token operator">=</span> dsets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span>
        root <span class="token operator">=</span> r<span class="token string">'D:\python\minist'</span><span class="token punctuation">,</span> <span class="token comment">#存储路径</span>
        train <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token comment">#提取测试集不是训练集了</span>
        transform <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment">#把下载的数据改成Tensor形式</span>
        <span class="token comment">#把(0-255)转换成(0-1)</span>
        <span class="token punctuation">)</span>

test_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>test_data<span class="token punctuation">.</span>test_data<span class="token punctuation">,</span>volatile <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">255</span>
test_y <span class="token operator">=</span> test_data<span class="token punctuation">.</span>test_labels<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2000</span><span class="token punctuation">]</span>


<span class="token comment">#建立RNN神经网路</span>
<span class="token keyword">class</span> <span class="token class-name">RNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RNN<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>     <span class="token comment">#nn.RNN没有nn.LSTM效果好，收敛快</span>
                input_size <span class="token operator">=</span> INPUT_SIZE<span class="token punctuation">,</span>
                hidden_size <span class="token operator">=</span> <span class="token number">64</span><span class="token punctuation">,</span>
                num_layers <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment">#中间只有一层神经层</span>
                batch_first <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span> <span class="token comment">#把batch_size参数放在第一个维度(batch,time_step,input)</span>
                <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
        
    <span class="token comment">#三维数据展平成2维数据</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        r_out<span class="token punctuation">,</span><span class="token punctuation">(</span>h_n<span class="token punctuation">,</span>h_c<span class="token punctuation">)</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">)</span>  <span class="token comment">#x--&gt;(batch,time_step,input_size)</span>
        <span class="token comment">#在这里分类问题不涉及(h_n,h_c),传入的是None</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>r_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#r_out--&gt;(batch,time_step,input)</span>
        <span class="token comment">#选取最后一个时间的out作为评价</span>
        <span class="token keyword">return</span> out

rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>rnn<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/8e/20/8T89RGbd_o.png" alt="在这里插入图片描述"><br> RNN网络只有一个LSTM层一个输出层，LSTM有64个神经元</p> 
<pre><code class="prism language-python"><span class="token comment">#优化器</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> LR<span class="token punctuation">)</span><span class="token comment">#优化器</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#计算损失函数</span>
<span class="token comment">#CrossEntropy在torch中定义的不是onehot类型的，是int型的标签，标签是7就是7</span>

<span class="token comment">#训练过程</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> step<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>   <span class="token comment"># 分配 batch data, normalize x when iterate train_loader</span>
        b_x <span class="token operator">=</span> Variable<span class="token punctuation">(</span>x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#reshape x to (batch,time_step,input_size)</span>
        <span class="token comment">#view设置不能缺参数，设置为-1表示自动判断，给出后面两维的大小28,28，自动判断前面的数</span>
        b_y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token comment">#batch y</span>
        output <span class="token operator">=</span> rnn<span class="token punctuation">(</span>b_x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>output<span class="token punctuation">,</span>b_y<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment">#打印出来训练效果</span>
        <span class="token keyword">if</span> step <span class="token operator">%</span> <span class="token number">50</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            test_output <span class="token operator">=</span> rnn<span class="token punctuation">(</span>test_x<span class="token punctuation">)</span>
            pred_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>test_output<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
            accuracy <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">(</span>pred_y <span class="token operator">==</span> test_y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>test_y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment">#算括号里的是否等于，等于表示预测对了记一次，总共对的次数除以总数就是accuracy</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: '</span><span class="token punctuation">,</span>epoch<span class="token punctuation">,</span><span class="token string">'| train loss: %.4f'</span> <span class="token operator">%</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'| test accuracy: %.2f'</span> <span class="token operator">%</span> accuracy<span class="token punctuation">)</span>
        

<span class="token comment">#拿测试集前十个数据测试一下效果</span>
test_output <span class="token operator">=</span> rnn<span class="token punctuation">(</span>test_x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pred_y <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>test_output<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pred_y<span class="token punctuation">,</span><span class="token string">'prediction number'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test_y<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'real number'</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/4d/65/acyRWoZl_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="RNN_109"></a>RNN实现回归问题</h3> 
<p>目标是给出一个sin分布的值，来预测一个cos分布的值，就是给出sin上面的一个y值，预测cos上面的值是多少</p> 
<p><img src="https://images2.imgbox.com/e8/e0/B8JA6QqN_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># Hyper Parameters</span>
TIME_STEP <span class="token operator">=</span> <span class="token number">10</span>      <span class="token comment"># rnn time step</span>
INPUT_SIZE <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment"># rnn input size</span>
LR <span class="token operator">=</span> <span class="token number">0.02</span>           <span class="token comment"># learning rate</span>

<span class="token comment">## show data</span>
<span class="token comment">#steps = np.linspace(0, np.pi*2, 100, dtype=np.float32)  # float32 for converting torch FloatTensor</span>
<span class="token comment">#x_np = np.sin(steps)</span>
<span class="token comment">#y_np = np.cos(steps)</span>
<span class="token comment">#plt.plot(steps, y_np, 'r-', label='target (cos)')</span>
<span class="token comment">#plt.plot(steps, x_np, 'b-', label='input (sin)')</span>
<span class="token comment">#plt.legend(loc='best')</span>
<span class="token comment">#plt.show()</span>

<span class="token keyword">class</span> <span class="token class-name">RNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNN<span class="token punctuation">(</span>
            input_size<span class="token operator">=</span>INPUT_SIZE<span class="token punctuation">,</span>
            hidden_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>     <span class="token comment"># rnn hidden unit</span>
            num_layers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>       <span class="token comment"># number of rnn layer</span>
            batch_first<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>   <span class="token comment"># input &amp; output will has batch size as 1s dimension. e.g. (batch, time_step, input_size)</span>
        <span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>out <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        
        <span class="token comment">#rnn在同一时间点上input和output都应该是1</span>
        
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> h_state<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># x (batch, time_step, input_size)</span>
        <span class="token comment"># h_state (n_layers, batch, hidden_size)</span>
        <span class="token comment"># r_out (batch, time_step, hidden_size)</span>
        r_out<span class="token punctuation">,</span> h_state <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_state<span class="token punctuation">)</span> <span class="token comment">#此时的h_state表示为之前网络情况的记忆</span>
        
        outs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token comment"># save all predictions</span>
        <span class="token keyword">for</span> time_step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>r_out<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment"># calculate output for each time step</span>
            outs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>out<span class="token punctuation">(</span>r_out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> time_step<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>outs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> h_state
        
rnn <span class="token operator">=</span> RNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>rnn<span class="token punctuation">)</span>

optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>rnn<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>LR<span class="token punctuation">)</span>   <span class="token comment"># optimize all cnn parameters</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

h_state <span class="token operator">=</span> <span class="token boolean">None</span>      <span class="token comment"># for initial hidden state</span>
<span class="token comment">#最先开始的hidden state没有输入的state，自然也不能通过前面的state算出来当状态下的state，所以初始state直接设定为None</span>


plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ion<span class="token punctuation">(</span><span class="token punctuation">)</span>           <span class="token comment"># continuously plot</span>

<span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    start<span class="token punctuation">,</span> end <span class="token operator">=</span> step <span class="token operator">*</span> np<span class="token punctuation">.</span>pi<span class="token punctuation">,</span> <span class="token punctuation">(</span>step<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>np<span class="token punctuation">.</span>pi   <span class="token comment"># time range</span>
    <span class="token comment"># use sin predicts cos</span>
    steps <span class="token operator">=</span> np<span class="token punctuation">.</span>linspace<span class="token punctuation">(</span>start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> TIME_STEP<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> endpoint<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># float32 for converting torch FloatTensor</span>
    x_np <span class="token operator">=</span> np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>
    y_np <span class="token operator">=</span> np<span class="token punctuation">.</span>cos<span class="token punctuation">(</span>steps<span class="token punctuation">)</span>

    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_np<span class="token punctuation">[</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment"># shape (batch, time_step, input_size)</span>
    y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_np<span class="token punctuation">[</span>np<span class="token punctuation">.</span>newaxis<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span><span class="token punctuation">)</span>

    prediction<span class="token punctuation">,</span> h_state <span class="token operator">=</span> rnn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> h_state<span class="token punctuation">)</span>   <span class="token comment"># rnn output</span>
    <span class="token comment"># !! next step is important !!</span>
    h_state <span class="token operator">=</span> Variable<span class="token punctuation">(</span>h_state<span class="token punctuation">.</span>data<span class="token punctuation">)</span>        <span class="token comment"># repack the hidden state, break the connection from last iteration</span>

    loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> y<span class="token punctuation">)</span>         <span class="token comment"># calculate loss</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>                   <span class="token comment"># clear gradients for this training step</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>                         <span class="token comment"># backpropagation, compute gradients</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>                        <span class="token comment"># apply gradients</span>

    <span class="token comment"># plotting</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>steps<span class="token punctuation">,</span> y_np<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'r-'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>steps<span class="token punctuation">,</span> prediction<span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'b-'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>draw<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> plt<span class="token punctuation">.</span>pause<span class="token punctuation">(</span><span class="token number">0.05</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>ioff<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



</code></pre> 
<p><img src="https://images2.imgbox.com/dc/a0/W2g8xMSx_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7193e5767dc477f5e82eecd0a13f24e5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">宿主机使用WiFi时Ubuntu16.04系统VMware虚拟机联网方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7a52ae1128c090c4ed143f38cbeb09be/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">kolla-ansible 多区域 multiRegion 安装 部署 openstack</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>