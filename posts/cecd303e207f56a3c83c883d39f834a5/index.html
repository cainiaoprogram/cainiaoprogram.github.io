<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【文献阅读】 2019-IJCAI-Sequential Recommender Systems Challenges, Progress and Prospects - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【文献阅读】 2019-IJCAI-Sequential Recommender Systems Challenges, Progress and Prospects" />
<meta property="og:description" content="说明 1.原文链接
2.此处将Sequential Recommender Systems 翻译为序列推荐系统，具体定义参见下文的形式化定义。
3.本篇为顶会IJCAI上的文章，给出关于此会议其他推荐系统的文章参考。
标题 序列推荐系统的挑战、进展和前景
作者： S h o u j i n W a n g 1 , L i a n g H u 2 , Y a n W a n g 1 , L o n g b i n g C a o 2 , Q u a n Z . S h e n g 1 , M e h m e t O r g u n 1 ShoujinWang^1, Liang Hu^2, Yan Wang^1, Longbing Cao^2, Quan Z." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/cecd303e207f56a3c83c883d39f834a5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-10-05T15:57:25+08:00" />
<meta property="article:modified_time" content="2019-10-05T15:57:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【文献阅读】 2019-IJCAI-Sequential Recommender Systems Challenges, Progress and Prospects</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>说明</h2> 
<p>  1.<font face="Times New Roman"><a href="https://www.researchgate.net/publication/337183009_Sequential_Recommender_Systems_Challenges_Progress_and_Prospects" rel="nofollow">原文链接</a><br>   2.此处将Sequential Recommender Systems 翻译为序列推荐系统，具体定义参见下文的形式化定义。<br>   3.本篇为顶会IJCAI上的文章，给出<a href="https://cloud.tencent.com/developer/article/1488769" rel="nofollow">关于此会议其他推荐系统的文章</a>参考。</font></p> 
<h3><a id="_6"></a>标题</h3> 
<p>  <strong>序列推荐系统的挑战、进展和前景</strong><br>   作者：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          S 
         
        
          h 
         
        
          o 
         
        
          u 
         
        
          j 
         
        
          i 
         
        
          n 
         
        
          W 
         
        
          a 
         
        
          n 
         
         
         
           g 
          
         
           1 
          
         
        
          , 
         
        
          L 
         
        
          i 
         
        
          a 
         
        
          n 
         
        
          g 
         
        
          H 
         
         
         
           u 
          
         
           2 
          
         
        
          , 
         
        
          Y 
         
        
          a 
         
        
          n 
         
        
          W 
         
        
          a 
         
        
          n 
         
         
         
           g 
          
         
           1 
          
         
        
          , 
         
        
          L 
         
        
          o 
         
        
          n 
         
        
          g 
         
        
          b 
         
        
          i 
         
        
          n 
         
        
          g 
         
        
          C 
         
        
          a 
         
         
         
           o 
          
         
           2 
          
         
        
          , 
         
        
          Q 
         
        
          u 
         
        
          a 
         
        
          n 
         
        
          Z 
         
        
          . 
         
        
          S 
         
        
          h 
         
        
          e 
         
        
          n 
         
         
         
           g 
          
         
           1 
          
         
        
          , 
         
        
          M 
         
        
          e 
         
        
          h 
         
        
          m 
         
        
          e 
         
        
          t 
         
        
          O 
         
        
          r 
         
        
          g 
         
        
          u 
         
         
         
           n 
          
         
           1 
          
         
        
       
         ShoujinWang^1, Liang Hu^2, Yan Wang^1, Longbing Cao^2, Quan Z. Sheng^1, Mehmet Orgun^1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.05855em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">h</span><span class="mord mathdefault">o</span><span class="mord mathdefault">u</span><span class="mord mathdefault" style="margin-right: 0.05724em;">j</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">i</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault" style="margin-right: 0.08125em;">H</span><span class="mord"><span class="mord mathdefault">u</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault">L</span><span class="mord mathdefault">o</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault">b</span><span class="mord mathdefault">i</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault" style="margin-right: 0.07153em;">C</span><span class="mord mathdefault">a</span><span class="mord"><span class="mord mathdefault">o</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault">Q</span><span class="mord mathdefault">u</span><span class="mord mathdefault">a</span><span class="mord mathdefault">n</span><span class="mord mathdefault" style="margin-right: 0.07153em;">Z</span><span class="mord">.</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">h</span><span class="mord mathdefault">e</span><span class="mord mathdefault">n</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mord mathdefault">e</span><span class="mord mathdefault">h</span><span class="mord mathdefault">m</span><span class="mord mathdefault">e</span><span class="mord mathdefault">t</span><span class="mord mathdefault" style="margin-right: 0.02778em;">O</span><span class="mord mathdefault" style="margin-right: 0.02778em;">r</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault">u</span><span class="mord"><span class="mord mathdefault">n</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span><br>   单位：<br>     <font face="Times New Roman">1：Department of Computing, Macquarie University<br>     <font face="Times New Roman">2：Advanced Analytics Institute, University of Technology Sydney</font></font></p> 
<h3><a id="_12"></a>摘要</h3> 
<p>  <font face="Times New Roman">近年来，序列推荐系统(SRSs)这一新兴的研究课题越来越受到人们的关注。与包括基于协同过滤和基于内容的传统的推荐系统(RSs)不同，SRSs试图理解和建模用户的行为序列中用户和项目之间的交互，以及用户的偏好和项目的流行度随时间的演变。SRSs涉及上述方面，以更精确地描述用户上下文、意图和目标，以及项目消费趋势，产生更准确、定制化和动态的推荐。本文对SRSs进行了系统的综述。我们首先介绍了SRSs的特点，然后对该研究领域的关键挑战进行了总结和分类，接着是相应的研究进展，包括该课题最新的和有代表性的进展。最后，讨论了该领域的重要研究方向。</font></p> 
<h3><a id="1__14"></a>1 介绍</h3> 
<p>  <font face="Times New Roman">序列推荐系统(SRSs)主要通过对用户-物品交互(例如，在线购物平台上查看或购买物品)上的序列相关性建模，来推荐用户可能感兴趣的物品。传统的推荐系统(RSs)，包括基于内容和协同过滤的RSs，以静态的方式对用户-项目交互进行建模，只能捕获用户的一般偏好。相比之下，SRSs将用户-项目交互视为一个动态序列，并将序列相关性考虑在内，以捕获用户当前和最近的偏好，以获得更准确的推荐[Chen et al.， 2018]。为了加深对SRSs的理解，接下来我们介绍了SRSs的动机和形式化。</font></p> 
<h4><a id="_16"></a>动机：为什么需要序列推荐系统</h4> 
<p>  <font face="Times New Roman"><em><strong>用户-项目交互基本上是顺序相关的。</strong></em> 在现实世界中，用户的购物行为通常是按顺序依次发生的，而不是孤立的。以图1所示的Jimmy的购物事件为例，在Jimmy开始度假之前，他先后预定了机票和酒店，租车，接下来的行动可能是自驾游一个旅游景点。在这种情况下，酒店可能离航班目的地机场很近，租车地点可能离酒店不远。在这个场景中，Jimmy的下一个操作都依赖于前一个操作，因此所有四个消费操作都是顺序依赖的。同样，我们可以看到蒂娜案例中的顺序依赖关系。这种顺序依赖关系通常存在于<strong>事务数据</strong>中，但传统的基于内容的RSs或协同过滤RSs无法很好地捕捉到[Kang et al.， 2018]，这从本质上推动了SRSs的发展。<br> <img src="https://images2.imgbox.com/44/96/PXOdd0g3_o.png" alt="在这里插入图片描述"><br>   <font face="Times New Roman"><em><strong>随着时间的推移，用户的偏好和项目的受欢迎程度都是动态的，而不是静态的。</strong></em> 事实上，用户的偏好和品味可能会随着时间而改变。例如，许多曾经是iPhone迷的年轻人现在变成了华为或三星手机的粉丝，而iPhone的受欢迎程度近年来一直在下降。这样的动态对于精确地分析用户或项目以获得更精确的推荐非常重要，并且它们只能被SRSs捕获。<br>   <font face="Times New Roman"><em>用户-项目交互通常发生在特定的连续上下文中。</em> 不同的上下文通常会导致不同的用户与条目之间的交互，然而，传统的RSs(如协同过滤)常常忽略了这一点。相反，SRs将先前的顺序交互作为上下文来预测哪些项将在不久的将来交互。因此，通过避免重复推荐那些与已经选择的项目相同或相似的项目，更容易使推荐结果多样化。</font></font></font></p> 
<h4><a id="_21"></a>形式化定义：什么是序列推荐系统</h4> 
<p>  <font face="Times New Roman">通常，SRS将一系列user-item交互作为输入，并试图通过建模在user-item交互序列中潜在的复杂顺序相关性来预测在不久的将来可能发生的后续user-item交互。更具体地说，给定一个用户-项目交互序列，通过最大化效用函数值(例如，似然函数)，生成一个由排名最高的候选项目组成的推荐列表，如下所示:<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           R 
          
         
           = 
          
         
           a 
          
         
           r 
          
         
           g 
          
         
           m 
          
         
           a 
          
         
           x 
          
         
           f 
          
         
           ( 
          
         
           S 
          
         
           ) 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           ( 
          
         
           1 
          
         
           ) 
          
         
        
          R = arg max f(S)....................................... (1) 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.02778em;">r</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault">x</span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mclose">)</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mopen">(</span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span></span><br>   <font face="Times New Roman">其中 <em>f</em> 是输出候选项排名分数的效用函数，它可以是多种形式的，如条件概率[Wang et al.， 2018]，或交互分数[Huang et al.， 2018]。<em>S</em> = {<!-- --><em>i</em><sub>1</sub>,<em>i</em><sub>2</sub>,…,<em>i<sub>|s|</sub></em>}是一个用户-项目交互序列，其中每个交互<em>i<sub>j</sub></em> =&lt; <em>u</em>,<em>a</em>,<em>v</em> &gt;是一个三组成的用户,用户的动作,和相应的条目诉在某些情况下,用户和项目相关的一些元数据(例如,人口或功能),而行为可能有不同的类型(例如,单击,添加到购物车,购买)和发生在不同上下文(例如,时间、地点、天气)。输出R是根据排名分数排序的项目列表。<br>   <font face="Times New Roman">与一般的序列建模不同，在一般的序列建模中，序列结构要简单得多，因为序列通常是由原子元素(例如，实值、基因)组成的，而SRSs中的学习任务更具有挑战性，因为序列结构更复杂(例如，每个元素是一个三元组)。这促使我们系统地分析SRSs面临的挑战，并总结相应的进展。</font></font></font></p> 
<h4><a id="_27"></a>贡献</h4> 
<ul><li>我们系统地分析了SRSs中不同数据特征所带来的一系列关键挑战，并从数据驱动的角度对它们进行了分类，这为深入理解SRSs的特征提供了一个新的视角。</li><li>我们从技术的角度系统地对艺术作品进行了分类，总结了SRSs目前的研究进展。</li><li>我们分享和讨论SRSs的一些前景，以供参考。</li></ul> 
<h3><a id="2__33"></a>2 数据特征及挑战</h3> 
<p>  <font face="Times New Roman">由于顾客购物行为、物品特征以及现实世界中特定的购物情境的多样性和复杂性，所生成的用户-物品交互数据往往具有不同的特征。不同的数据特征本质上给SRSs带来了不同的挑战，需要不同的解决方案，如表1所示。在接下来的五个小节中，我们将分别具体讨论由不同数据特征引起的SRSs中的五个关键挑战。在每个小节中，我们首先介绍特定的数据特征，然后说明相应的挑战。<br> <img src="https://images2.imgbox.com/f6/b0/sr8jsnbZ_o.png" alt="在这里插入图片描述"></font></p> 
<h5><a id="21__36"></a>2.1 处理长用户-项目交互序列</h5> 
<p>  <font face="Times New Roman">一个较长的用户-项目交互序列由相对大量的用户-项目交互组成。因此，在其内部的多个交互上有更复杂和更全面的依赖关系的可能性要大得多，这使得序列推荐更具挑战性。具体来说，长用户-项目交互序列中两个最关键的挑战是 <em><strong>学习高阶顺序依赖关系</strong> 和 <strong>学习长期顺序依赖关系</strong></em>，下面将分别介绍这两个问题。</font></p> 
<h6><a id="_38"></a>学习高阶序列依赖关系</h6> 
<p>  <font face="Times New Roman">高阶序列依赖关系通常存在于用户-商品交互序列中，尤其是长序列中。相较而言，低阶序列依赖相当简单，它能轻易地通过马尔科夫模型[Garcin et.al.，2013]或因子分解机[Rendel et.at.，2010；Hidasi and Tikk，2016]建模。而由于其复杂的多级级联依赖关系跨越多个用户项交互，因此高阶序列依赖关系更加复杂，也更难捕获。到目前为止，已经有两种基本方法在一定程度上能解决序列推荐系统中的这个挑战： <em><strong>高阶马尔科夫模型[He and McAuley，2016] 和 循环神经网络[Hidasi et al.，2016a]</strong></em> 。然而，每一种方法都有自身的限制，例如，包含在高阶马尔科夫模型中的历史状态是相当有限的，因为要被估计的模型参数的数量随着阶数的增长呈现指数型增长，而循环神经网络中的过强的次序假设限制了循环神经网络在序列中应用的灵活性。</font></p> 
<h5><a id="_40"></a>学习长期序列依赖关系</h5> 
<p>  <font face="Times New Roman">长期序列依赖关系指的是在一个序列中相互之间相距很远的交互间的依赖关系。例如，给定一个购物序列<em>S<sub>1</sub></em> = {玫瑰花，鸡蛋，面包，一瓶牛奶，一个花瓶}，这包含了Janet成功购买的一篮子商品。显而易见，花瓶和玫瑰花是高依赖关系，即使他们之间的相距很远。这种情况在现实中并不少见，因为用户的行为通常是高度不确定的，他们可能会把任何物品放进购物车中。<br>   <font face="Times New Roman">为了解决这种关键的问题，基于长短时记忆和基于门循环单元的循环神经网络已经被应用于序列推荐系统中了，这种情况下就能捕获序列中用户-商品的交互间的长期以来关系。然而，对于用循环神经网络模型通过过度假设（任何邻近商品在序列中都是高依赖关系）生成错误依赖关系是比较容易发生的。在上面Janet购物的序列中，循环神经网络通常是通过假设牛奶和花瓶是有依赖关系的来构造<em>S<sub>1</sub></em> 的，这是由于他们之间的距离很近，但是实际上是不相关的。为了解决这个问题，还做了一些其他的努力，在一个统一的模型中，通过利用混合模型的优势，结合不同时间范围内的多个子模型去捕获短期和长期的依赖关系[Tang et al.，2019]。总的来说，能够解决这一挑战的工作相当有限，需要进行更多的研究来弥补这一差距。</font></font></p> 
<h4><a id="22__43"></a>2.2 使用灵活的顺序处理用户-项目交互序列</h4> 
<p>  <font face="Times New Roman">在现实世界中，一些用户-项目交互序列是严格有序的，而另一些则可能不是，即不是所有相邻的交互都是顺序相关的。例如，在购物序列<em>S<sub>2</sub></em> = {牛奶, 黄油, 面粉}中，先买牛奶还是先买黄油并不重要，但同时购买这两种商品会导致接下来购买面粉的可能性更高;也就是说，牛奶和黄油之间没有严格的顺序，但面粉的顺序取决于它们的结合。因此，对于具有灵活顺序的序列，最好捕获 <em><strong>集体顺序依赖关系</strong></em>，而不是点向顺序依赖关系，因为前者是模糊的，并且在用户-项交互上没有严格的顺序。因此，<em><strong>如何在灵活顺序假设下捕获集体顺序依赖关系</strong></em>，成为SRSs中使用灵活顺序处理序列的关键挑战。<br>   <font face="Times New Roman">虽然在SRSs中很常见也很重要，但已有的研究尚未对这一问题给予足够的重视。现有的建立在markov链上的SRSs，因式分解机或RNN只能处理点向依赖，而不擅长建模和捕获集体依赖。只有少数作品像[唐和王，2018;Yuan等人(2019)]试图解决这一挑战，他们利用传统神经网络(CNN)对“图像”中不同区域之间的局部和全局依赖关系进行建模，即，一个交互序列的嵌入矩阵。基于cnn的SRSs取得的技术进展将在3.3节中介绍。</font></font></p> 
<h4><a id="23__46"></a>2.3 处理带有噪声的用户-项目交互序列</h4> 
<p>  <font face="Times New Roman">由于用户购物行为的不确定性，大部分的用户-物品交互序列是不干净的，这意味着它们可能包含一些噪声和不相关的交互，对下一次交互预测产生干扰。在实践中，在一个用户-项目交互序列中，一些历史交互与下一个交互密切相关，而其他交互可能是弱相关甚至不相关的。例如，在另一个购物序列<em>S<sub>3</sub></em>= {培根，玫瑰，鸡蛋，面包}中，物品“玫瑰”可能是一个有噪声的物品，因为它与其他物品有很大的不同，并且与它们没有相关性。下一项可能是一瓶牛奶，概率很高，它只是依次依赖培根、鸡蛋和面包，而与玫瑰无关。因此，SRSs中的另一个关键挑战是，在有噪声的用户-项目交互序列上，仔细而有区别地学习顺序依赖关系。<br>   <font face="Times New Roman">相当多的研究试图通过使用注意力模型(Wang et al.， 2018)或记忆网络(Chen et al.， 2018)来解决这一典型问题，有选择地保留和利用那些与下一次交互预测真正相关的交互信息。这些解决办法所取得的技术进展将在第3.3节中介绍。</font></font></p> 
<h4><a id="24__49"></a>2.4 处理具有异构关系的用户-项目交互序列</h4> 
<p>  <font face="Times New Roman">异构关系是指传递不同信息的不同类型的关系，在SRSs中应该以不同的方式建模。例如，在一个用户-项目交互序列中，除了普遍存在的基于用户-项目交互的顺序依赖关系之外，在相互作用的项目之间也存在基于相似性的关系。此外，尽管两者都是顺序依赖项，但长期顺序依赖项与短期顺序依赖项有很大的不同，它们不能以相同的方式建模。因此，SRSs中的另一个关键挑战是 <em><strong>如何有效地分别捕获用户-项目交互序列中的这些潜在的异构关系，并在处理与异构关系相关的用户-项目交互序列时使它们协同工作，以获得序列的推荐</strong></em> 。<br>   <font face="Times New Roman">在SRSs中解决这一挑战的文献报道甚少。混合模型[Kang等，2018;唐等人，2019年;Wang等人，2019年)是迄今为止应对这种挑战的唯一解决方案。混合模型集成了不同子模型建模的不同类型的关系，以协作地生成序列推荐。具体技术进展情况见第3.3节。</font></font></p> 
<h4><a id="25__52"></a>2.5 处理具有层次结构的用户-项目交互序列</h4> 
<p>  <font face="Times New Roman">一般来说，与用户-项目交互序列相关的层次结构主要有两种:(1) <em><strong>元数据与用户-项目交互之间的层次结构。</strong></em> 具体来说，用户的人口统计可以在一定程度上决定用户的偏好，进而影响用户与商品的交互。同样，项目的特征往往会影响用户是否喜欢和互动[Hidasi et al.， 2016b];(2)<em><strong>子序列与用户-项目交互之间的层次结构。</strong></em> 更具体地说，在某些SRSs中，一个用户-项目交互序列 <em><strong>包含多个子序列(也称为会话)</strong></em> 。在这种情况下，除了当前子序列内的先验交互之外，历史子序列还可能影响当前子序列中将要预测的下一个用户-项目交互[Ying et al.， 2018]。因此，SRSs中另一个关键的挑战是 <em><strong>如何将这两种层次结构中潜在的层次依赖关系合并到序列依赖关系学习中，以生成更准确的序列推荐。</strong></em><br>   <font face="Times New Roman">虽然已有不少研究试图从某些方面来应对这一挑战，但对其他方面的研究较少。一方面，为了考虑项目特征对用户-项目交互的影响，提出了一系列特征丰富的神经模型，包括[Hidasi et al.， 2016b]。相比之下，现有的SRSs很少考虑用户人口统计的影响，应该在这方面投入更多的努力。另一方面，一些层次模型，包括层次嵌入模型[Wang et al.， 2015]、层次RNN [Quadrana et al.， 2017]和层次注意网络[Ying et al.， 2018]已经被设计出来，将历史子序列合并到序列依赖学习中，以构建更强大的SRSs。特别是第3.2和3.3节将介绍为应付这一挑战所取得的技术进展。</font></font></p> 
<h3><a id="3__55"></a>3 研究进展</h3> 
<p>  <font face="Times New Roman">为了对SRSs的技术进展进行概述，并提供针对上述挑战的解决方案的更多技术细节，我们在本节中从技术角度总结并简要讨论了SRSs的研究进展。特别地，我们首先从技术角度对SRSs的所有方法进行了分类，然后简要地强调了每个类别中最近的进展。SRS方法的分类如图2所示。我们注意到，从技术角度来看，SRSs的各种方法首先被分为11个原子类(例如，顺序模式挖掘、因子分解机和递归神经网络)。然后将所有这些原子类进一步划分为三个分类法，包括传统的序列模型、潜在表示模型和深度神经网络模型。一般来说，这三种分类法由简单到复杂依次报道。接下来，我们总结了这三个分类的研究进展。<br> <img src="https://images2.imgbox.com/b1/50/FuSIzeDo_o.png" alt="在这里插入图片描述"></font></p> 
<h4><a id="31_SRSs_58"></a>3.1 用于SRSs的传统序列模型</h4> 
<p>  <font face="Times New Roman">传统的序列模型，包括序列模式挖掘和马尔可夫链模型，利用它们在序列中用户-项目交互之间的序列相关性建模方面的自然优势，为SRSs提供了直观的解决方案。<br>   <font face="Times New Roman"><em><strong>序列模式挖掘。</strong></em> 基于序列模式的RSs首先在序列数据上挖掘频繁模式，然后利用挖掘出的模式指导后续的推荐。序列模式挖掘虽然简单直接，但通常会产生大量的冗余模式，增加了不必要的时间和空间开销。另一个明显的缺点是，由于频率约束，它经常丢失那些不经常出现的模式和项目，这将推荐结果限制为那些流行的项目。因此，除了有代表性的一篇[Yap et al.， 2012]外，本类文献较少。<br>   <font face="Times New Roman"><em><strong>马尔可夫链模型。</strong></em> 基于马尔可夫链的RSs采用马尔可夫链模型对用户-项目交互之间的转换进行序列建模，以预测下一次交互。根据使用的具体技术，将基于马尔可夫链的RSs方法分为基于基本马尔可夫链的方法和基于潜在马尔可夫嵌入的方法。前者基于显式观测直接计算转移概率[Garcin et al.， 2013]，而后者首先将马尔可夫链嵌入到欧几里德空间中，然后根据其欧几里德距离计算相互作用之间的转移概率[Feng et al.， 2015]。基于马尔可夫链的RSs的缺点是显而易见的，一方面，由于马尔可夫特性假设当前的交互仅依赖于一个或多个最近的交互，所以它只能捕获短期的依赖，而忽略了长期的依赖;另一方面，它们只能捕获点依赖项，而忽略用户-项交互上的集体依赖项。因此，近年来他们在SRSs中的使用越来越少。</font></font></font></p> 
<h4><a id="32_SRSs_62"></a>3.2 用于SRSs的潜在表达模型</h4> 
<p>  <font face="Times New Roman">潜在表示模型首先学习每个用户或项的潜在表示，然后利用所学习的表示来预测后续的user-item交互。结果表明，在潜在空间中捕获了更多的隐式和复杂的依赖关系，这极大地有利于推荐。接下来，我们将介绍两种属于这种分类的典型模型。<br>   <font face="Times New Roman"><em><strong>因子分解机</strong></em>。基于因子分解机的SRSs通常利用矩阵因子分解或张量因子分解来将观察到的用户-物品交互分解为用户的潜在因子和推荐的物品[Rendle et al.， 2010;Hidasi和Tikk, 2016]。与协同过滤(collaborative filtering, CF)不同的是，需要进行因子分解的矩阵或张量是由交互作用组成的，而不是CF中的评级。这样的模型容易受到观测数据的稀疏性的影响，不能得到理想的推荐。<br>   <font face="Times New Roman"><em><strong>嵌入</strong></em>。基于嵌入的SRSs通过将序列中的所有用户-项目交互编码到潜在空间中，为每个用户和后续推荐的项目学习潜在表示。具体而言，一些作品将习得的潜在表征作为网络的输入，进一步计算用户与物品之间的交互得分，或连续的用户行为[Wang et al.， 2015;[2018]，而其他著作则直接利用它们计算欧几里德距离等度量作为交互分数[He et al.， 2018]。近年来，该模型以其简单、效率高、有效性强的特点显示出巨大的发展潜力。</font></font></font></p> 
<h4><a id="33_SRSs_66"></a>3.3 用于SRSs的深度神经网络模型</h4> 
<p>  <font face="Times New Roman">深度神经网络具有天然的能力，可以对不同实体(如用户、项目、交互)之间的综合关系进行序列建模和捕获，因此在过去几年中，深度神经网络几乎主导了SRSs。SRSs的最新进展也属于这一分类。通常，这种分类可以分为两个子类:基于基本深度神经网络的SRSs和基于包含一些高级模型的深度神经网络的SRSs。</font></p> 
<h5><a id="_68"></a>基本深度神经网络</h5> 
<p>  <font face="Times New Roman">针对SRSs最常用的深度神经网络是递归神经网络(RNN)，它具有序列建模的天然优势，但也存在缺陷。最近，卷积神经网络(convolutional neural networks, CNN)和图神经网络(graph neural networks, GNN)也在SRSs中得到了应用，弥补了RNN的不足。接下来，我们分别介绍了建立在这三种深度神经网络上的SRSs。<br>   <font face="Times New Roman"><em><strong>基于RNN的SRSs</strong></em>。给定一系列历史用户-项目交互，基于RNN的SRS通过对给定交互的顺序依赖关系建模，尝试预测下一个可能的交互。除了基本的RNN外，长短时记忆(LSTM)- [Wu et al.， 2017]和基于门控递归单元(GRU)的[Hidasi et al.， 2016a] RNN也被开发用于捕获序列中的长期依赖关系。近年来，基于RNN的自主学习支持系统蓬勃发展，主导了基于深度学习的自主学习支持系统乃至整个自主学习支持系统的研究。除了基本的RNN结构外，还提出了一些变体来捕获序列中更复杂的依赖关系，如递阶RNN [Quadrana et al.， 2017]。然而对于SRSs而言,RNN不是完美的,它有两方面的缺点:(1)很容易产生假依赖由于过于强烈的假设任何相邻的交互必须依赖一个序列,这可能不是情况在现实世界中,因为通常是无关紧要的或在嘈杂的交互序列;而且(2)它可能只捕获点依赖项，而忽略集合依赖项(例如，多个交互协作影响下一个交互)。<br>   <font face="Times New Roman"><em><strong>基于CNN的SRSs</strong></em>。与RNN不同的是，给定一个用户-物品交互序列，CNN首先将所有这些交互嵌入到一个矩阵中，然后将这个矩阵作为时间和潜在空间中的“图像”。最后，CNN学习序列模式作为图像的局部特征，使用卷积过滤器进行后续推荐。由于CNN对序列中的相互作用并没有很强的顺序假设，并且他们是在“图像”中学习区域之间的模式而不是相互作用，因此基于CNN的SRSs可以在一定程度上弥补基于RNN的SRSs的上述缺陷。然而，基于CNN的SRSs不能有效地捕获长期依赖关系，因为CNN中使用的过滤器的大小有限，这限制了它们的应用。典型作品有[唐和王，2018;Yuan等人，2019年]。<br>   <font face="Times New Roman"><em><strong>基于GNN的SRSs</strong></em>。最近，随着GNN的快速发展，人们设计了基于GNN的SRSs来利用GNN建模并捕获用户-项目交互之间的复杂转换。通常，通过将每个交互作为图中的一个节点，而将每个序列映射到一个路径，首先在序列数据上构建一个有向图。然后，在图上学习用户或项目的嵌入，在整个图上嵌入更复杂的关系[Wu et al.， 2019]。该方法充分利用了GNN的优势来捕获结构化关系数据集中的复杂关系。基于gnn的SRSs通过揭示推荐项和相应的顺序上下文之间的复杂关系，显示了提供可解释的推荐的巨大潜力。这种SRSs还处于早期阶段。</font></font></font></font></p> 
<h5><a id="_73"></a>高级模型</h5> 
<p>  <font face="Times New Roman">为了解决建立在基本神经网络结构上的SRSs的局限性，一些高级模型通常与某种基本的深度神经网络(如RNN、CNN)结合在一起，构建更强大的SRSs，能够应对特定的挑战。接下来，我们将介绍三种在SRSs中常用的高级模型。<br>   <font face="Times New Roman"> <em><strong>注意力模型。</strong></em> 在SRSs中，注意力模型通常被用来在一个序列中强调那些真正相关和重要的交互作用，同时淡化那些与下一次交互作用无关的交互作用。它们被广泛地纳入浅层网络[Wang et al.， 2018]和RNN [Ying et al.， 2018]来处理带有噪声的交互序列。<br>   <font face="Times New Roman"><em><strong>记忆网络。</strong></em> 将内存网络引入到SRSs中，通过合并外部内存矩阵来捕获任何历史用户-项交互与下一个交互之间的依赖关系。这样的矩阵使得以更显式和动态的顺序存储和更新历史交互成为可能，从而提高模型的表达性，减少那些不相关交互的干扰[Chen et al.， 2018]。此外，还有一些作品结合键值存储网络，按顺序存储和更新交互项的相应知识库信息，以了解属性级偏好，以增强推荐[Huang et al.， 2018]。一般来说，内存网络在SRSs中已经显示出了它们的潜力，但是还没有得到充分的研究。<br>   <font face="Times New Roman"><em><strong>混合模型。</strong></em> 基于混合模型的SRS将擅长捕获不同类型依赖项的不同模型组合在一起，以增强整个模型捕获各种依赖项以获得更好推荐的能力。一个典型的例子是[Tang et al.， 2019]，它结合了不同种类的编码器，分别适用于短期和长期依赖关系，以学习后续推荐的更精确的序列表示，并已证明是非常有效的。然而，这些模型还处于早期阶段。</font></font></font></font></p> 
<h3><a id="4__78"></a>4 开放的研究方向</h3> 
<p>  <font face="Times New Roman">近年来，特别是近三年来，序列推荐系统发展迅速，深度学习，尤其是递归神经网络蓬勃发展。在对该领域的研究实践进行分类和总结的同时，我们还确定了下面讨论的进一步开放的研究方向。<br>   <font face="Times New Roman"><em><strong>上下文感知顺序推荐系统。</strong></em> 用户或项目所在的当前上下文可能会极大地影响用户对该项目的选择，在进行推荐时应该考虑这一点。这在SRSs中更为必要，因为上下文可能随时间而变化。然而，大多数现有的SRSs忽略了这一重要方面。因此，上下文感知的SRSs将是未来工作的一个重要方向。<br>   <font face="Times New Roman"><em><strong>社会感知顺序推荐系统。</strong></em> 用户生活在一个社会中，与各种各样的人在线上线下都有联系。他人的行为或观点往往会对用户的选择产生很大的影响。因此，在SRSs中需要考虑社会影响，这在现有的工作中往往被忽略。<br>   <font face="Times New Roman"><em><strong>交互式顺序推荐系统。</strong></em> 现实世界中的大多数购物行为是连续的，而不是孤立的。换句话说，用户与购物平台(如Amazon)之间实际上存在顺序交互。然而，现有的SRSs常常忽略了这些交互作用，并且只在单个时间步长中为一个操作生成推荐。如何结合用户与卖家的交互，从而产生多时间步长推荐是一个很有前途的研究方向。<br>   <font face="Times New Roman"><em><strong>跨域顺序推荐系统。</strong></em> 在现实世界中，用户在某段时间内购买的商品通常来自多个域，而不是一个域。本质上，来自不同领域的项目之间存在一些顺序依赖关系，例如在购买汽车之后购买汽车保险。这种跨域顺序依赖关系在大多数SRSs中被忽略。因此，跨域SRS是另一个很有前途的研究方向，通过利用来自其他领域的信息和来自不同领域的更多样化的推荐来生成更准确的推荐。</font></font></font></font></font></p> 
<h3><a id="5__84"></a>5 总结</h3> 
<p>  <font face="Times New Roman">推荐系统(RS)是人工智能在我们日常生活中最直接、最实用的应用之一。序列推荐系统(SRSs)在过去三到五年里一直是RS领域的核心，因为它们提供了更智能和更有利的推荐来满足我们的日常需求。我们希望这篇综述能够为RS研究界提供关于SRSs面临的挑战、最近的进展以及未来的一些方向的概述。</font></p> 
<h4><a id="_86"></a>参考文献</h4> 
<p><font face="Times New Roman">[Chen et al., 2018] Xu Chen, Hongteng Xu, Yongfeng Zhang, and et al. Sequential recommendation with user memory networks. In Proceedings of the 11th ACM International Conference on Web Search and Data Mining, pages 108–116, 2018.<br> [Feng et al., 2015] Shanshan Feng, Xutao Li, Yifeng Zeng, Gao Cong, and Yeow Meng Chee. Personalized ranking metric embedding for next new poi recommendation. In Proceedings of the 24th International Joint Conference on Artificial Intelligence, pages 2069–2075, 2015.<br> [Garcin et al., 2013] Florent Garcin, Christos Dimitrakakis, and Boi Faltings. Personalized news recommendation with context trees. In Proceedings of the 7th ACM Conference on Recommender Systems, pages 105–112, 2013.<br> [He and McAuley, 2016] Ruining He and Julian McAuley. Fusing similarity models with markov chains for sparse sequential recommendation. In Proceedings of the 16th IEEE International Conference on Data Mining, pages 191–200, 2016.<br> [He et al., 2018] Ruining He, Wang-Cheng Kang, and Julian McAuley. Translation-based recommendation: A scalable method for modeling sequential behavior. In Proceedings of the 27th International Joint Conference on Artificial Intelligence, pages 5264–5268, 2018.<br> [Hidasi and Tikk, 2016] Bal´azs Hidasi and Domonkos Tikk. General factorization framework for context-aware recommendations. Data Mining and Knowledge Discovery, 30(2):342–371, 2016.<br> [Hidasi et al., 2016a] Bal´azs Hidasi, Alexandros Karatzoglou, and et al. Session-based recommendations with recurrent neural networks. In Proceedings of the 4th International Conference on Learning Representations, pages 1–10, 2016.<br> [Hidasi et al., 2016b] Bal´azs Hidasi, Massimo Quadrana, Alexandros Karatzoglou, and Domonkos Tikk. Parallel recurrent neural network architectures for feature-rich session-based recommendations. In Proceedings of the 10th ACM Conference on Recommender Systems, pages 241–248, 2016.<br> [Huang et al., 2018] Jin Huang, Wayne Xin Zhao, Hongjian Dou, Ji-Rong Wen, and Edward Y Chang. Improving sequential recommendation with knowledge-enhanced memory networks. In Proceedings of the 41st ACM SIGIR Conference on Research &amp; Development in Information Retrieval, pages 505–514, 2018.<br> [Kang et al., 2018] Wang-Cheng Kang, Mengting Wan, and Julian McAuley. Recommendation through mixtures of heterogeneous item relationships. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management, pages 1143–1152, 2018.<br> [Quadrana et al., 2017] Massimo Quadrana, Alexandros Karatzoglou, and et al. Personalizing session-based recommendations with hierarchical recurrent neural networks. In Proceedings of the 11th ACM Conference on Recommender Systems, pages 130–137, 2017.<br> [Rendle et al., 2010] Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. Factorizing personalized markov chains for next-basket recommendation. In Proceedings of the 19th International Conference on World Wide Web, pages 811–820, 2010.<br> [Tang and Wang, 2018] Jiaxi Tang and Ke Wang. Personalized top-n sequential recommendation via convolutional sequence embedding. In Proceedings of the 11th ACM International Conference on Web Search and Data Mining, pages 565–573, 2018.<br> [Tang et al., 2019] Jiaxi Tang, Francois Belletti, Sagar Jain, Minmin Chen, Alex Beutel, and et al. Towards neural mixture recommender for long range dependent user sequences. In Proceedings of the 28th International Conference on World Wide Web, pages 811–820, 2019.<br> [Wang et al., 2015] Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, ShengxianWan, and Xueqi Cheng. Learning hierarchical representation model for next basket recommendation. In Proceedings of the 38th ACM SIGIR Conference on Research and Development in Information Retrieval, pages 403–412, 2015.<br> [Wang et al., 2018] Shoujin Wang, Liang Hu, Longbing Cao, Xiaoshui Huang, Defu Lian, andWei Liu. Attentionbased transactional context embedding for next-item recommendation. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, pages 2532–2539, 2018.<br> [Wang et al., 2019] Shoujin Wang, Liang Hu, Yang Wang, and et al. Modeling multi-purpose sessions for nextitem recommendations via mixture-channel purpose routing networks. In Proceedings of the 28th International Joint Conference on Artificial Intelligence, pages 1–7, 2019.<br> [Wu et al., 2017] Chao-Yuan Wu, Amr Ahmed, Alex Beutel, Alexander J Smola, and How Jing. Recurrent recommender networks. In Proceedings of the 10th ACM International Conference on Web Search and Data Mining, pages 495–503, 2017.<br> [Wu et al., 2019] Shu Wu, Yuyuan Tang, and et al. Sessionbased recommendation with graph neural networks. In Proceedings of the 33rd AAAI Conference on Artificial Intelligence, pages 1–9, 2019.<br> [Yap et al., 2012] Ghim-Eng Yap, Xiao-Li Li, and Philip Yu. Effective next-items recommendation via personalized sequential pattern mining. In Database Systems for Advanced Applications, pages 48–64, 2012.<br> [Ying et al., 2018] Haochao Ying, Fuzhen Zhuang, Fuzheng Zhang, Yanchi Liu, Guandong Xu, and Xing Xie. Sequential recommender system based on hierarchical attention networks. In Proceedings of the 27th International Joint Conference on Artificial Intelligence, 2018.<br> [Yuan et al., 2019] Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M Jose, and Xiangnan He. A simple convolutional generative network for next item recommendation. In Proceedings of the 12th ACM International Conference on Web Search and Data Mining, pages 582–590, 2019.</font></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b7b1e314614cf326c6e2b6eba1540682/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">TODO</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9e86cc845c8bb5195f578416a75a817b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数字IC设计——用Verilog实现串并转换（移位寄存器）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>