<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>细粒度图像分类 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="细粒度图像分类" />
<meta property="og:description" content="细粒度图像分类
细粒度图像分类的经典方法是首先在图像上定义不同的位置，例如，鸟的头部、脚部或翅膀。然后我们必须从这些位置提取特征，最后，组合这些特征并使用它们来完成分类。
目前在工业界和实际生活中有着广泛的业务需求和应用场景。细粒度图像相较于粗粒度图像具有更加相似的外观和特征，加之采集中存在姿态、视角、光照、遮挡、背景干扰等影响，导致数据呈现类间差异性大、类内差异性小的现象，从而使分类更加具有难度。
局部特征：早期基于人工特征的细粒度图像分类算法，其研究重点为图像的局部特征，一般先从图像中提取某些局部特征，然后利用相关编码模型进行特征编码。
视觉词包：为了进一步提升分类精度，相关人员在局部特征的基础上又进一步提出视觉词包（BOVW）的概念。通过统计图像的整体信息，将量化后的图像作为视觉单词，通过视觉单词分布来描述图像内容。（例如，把一张图像当做一个文档，从图像中提取出来的特征就相当于词（通常还需要一些额外的操作，下面会提到）。词包表示法可以作为进一步图像处理的基本步骤，如对象分类。）
特征定位：局部特征和视觉词包都没有构建与全局特征之间的关联，只在图像的部分区域进行语义挖掘，因此人们提出对特征进行定位，如利用关键点的位置信息发现最具价值的图像信息。
基于特征提取的传统算法
局部特征：由于局部特征选择过程繁琐，表述能力有限，其自身也存在一定缺陷，即忽略了不同局部特征之间的关联以及与全局特征之间的位置空间关系，因此并没有取得令人满意的结果。
视觉词包：词包模型与一系列特征提取算法进行融合，虽然取得了一定的进展，但距离实际应用要求还有很远的距离。同时，构建词包的过程非常复杂，需要额外的处理工作。
特征定位：局部特征和视觉词包都没有构建与全局特征之间的关联，只在图像的部分区域进行语义挖掘，因此人们提出对特征进行定位，如利用关键点的位置信息发现最具价值的图像信息。
通过位置信息的辅助，分类精度也得到了一定的提高，但是位置信息的获取需要高精度的算法来完成，同时还需要精细的人工标注，其成本更大。
基于深度学习的算法
随着深度学习的兴起，从神经网络中自动获得的特征，比人工特征具有更强大的描述能力，在一定程度上极大地促进了细粒度图像分类算法的发展。
根据监督方式的不同，该类算法可以分为强监督和弱监督两种类别。
强监督细粒度图像分类
强监督利用bounding box和key point等额外的人工标注信息，获取目标的位置、大小等，有利于提升局部和全局之间的关联，从而提高分类精度。Multi-proposal Net则通过Edge Box Crop方法获取图像块，并引入关键点及视觉特征的输出层，进一步强化了局部特征与全部信息直接的位置关联，该算法在CUB-200数据集上取得了80.3%的精度。
弱监督细粒度图像分类
弱监督即仅利用图像的类别标注信息，不使用额外的标注。该方法又可以总结为图像过滤和双线性网络两类。
图像过滤：图像过滤的思想和强监督中利用bounding box的方法类似，只不过仅借助于图像的类别信息过滤图片中与物体无关的模块，其中比较有代表性的即Two Attention Level算法。该算法在CUB-200数据集上取得了75.7%的精度。
**双线性网络：**B-CNN根据大脑工作时同认知类别和关注显著特征的方式，构建了两个线性网络，协调完成局部特征提取和分类的任务，该算法在CUB-200数据集上取得了84.1%的精度，不过该方法在合并阶段会产生较高的维度，使得整个计算开销非常大。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9b8b4884825f68f12cab6ae1af924076/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-01-31T20:40:32+08:00" />
<meta property="article:modified_time" content="2020-01-31T20:40:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">细粒度图像分类</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>细粒度图像分类</p> 
<p>细粒度图像分类的经典方法是首先在图像上定义不同的位置，例如，鸟的头部、脚部或翅膀。然后我们必须从这些位置提取特征，最后，组合这些特征并使用它们来完成分类。</p> 
<p>目前在工业界和实际生活中有着广泛的业务需求和应用场景。细粒度图像相较于粗粒度图像具有更加相似的外观和特征，加之采集中存在姿态、视角、光照、遮挡、背景干扰等影响，导致数据呈现类间差异性大、类内差异性小的现象，从而使分类更加具有难度。</p> 
<p><img src="https://images2.imgbox.com/7e/5c/VRi6QtJi_o.png" alt="在这里插入图片描述"><br> 局部特征：早期基于人工特征的细粒度图像分类算法，其研究重点为图像的局部特征，一般先从图像中提取某些局部特征，然后利用相关编码模型进行特征编码。</p> 
<p>视觉词包：为了进一步提升分类精度，相关人员在局部特征的基础上又进一步提出视觉词包（BOVW）的概念。通过统计图像的整体信息，将量化后的图像作为视觉单词，通过视觉单词分布来描述图像内容。（<strong>例如，把一张图像当做一个文档，从图像中提取出来的特征就相当于词（通常还需要一些额外的操作，下面会提到）。词包表示法可以作为进一步图像处理的基本步骤，如对象分类。</strong>）</p> 
<p>特征定位：局部特征和视觉词包都没有构建与全局特征之间的关联，只在图像的部分区域进行语义挖掘，因此人们提出对特征进行定位，如利用关键点的位置信息发现最具价值的图像信息。</p> 
<p>基于特征提取的传统算法</p> 
<p><strong>局部特征</strong>：由于局部特征选择过程繁琐，表述能力有限，其自身也存在一定缺陷，即忽略了不同局部特征之间的关联以及与全局特征之间的位置空间关系，因此并没有取得令人满意的结果。<br> <strong>视觉词包</strong>：词包模型与一系列特征提取算法进行融合，虽然取得了一定的进展，但距离实际应用要求还有很远的距离。同时，构建词包的过程非常复杂，需要额外的处理工作。<br> <strong>特征定位</strong>：局部特征和视觉词包都没有构建与全局特征之间的关联，只在图像的部分区域进行语义挖掘，因此人们提出对特征进行定位，如利用关键点的位置信息发现最具价值的图像信息。<br> 通过位置信息的辅助，分类精度也得到了一定的提高，但是位置信息的获取需要高精度的算法来完成，同时还需要精细的人工标注，其成本更大。</p> 
<p><strong>基于深度学习的算法</strong></p> 
<p>随着深度学习的兴起，从神经网络中自动获得的特征，比人工特征具有更强大的描述能力，在一定程度上极大地促进了细粒度图像分类算法的发展。<br> 根据监督方式的不同，该类算法可以分为强监督和弱监督两种类别。<br> <strong>强监督细粒度图像分类</strong><br> 强监督利用<strong>bounding box</strong>和<strong>key point</strong>等额外的人工标注信息，获取目标的位置、大小等，有利于提升局部和全局之间的关联，从而提高分类精度。Multi-proposal Net则通过Edge Box Crop方法获取图像块，并引入关键点及视觉特征的输出层，进一步强化了局部特征与全部信息直接的位置关联，该算法在CUB-200数据集上取得了80.3%的精度。<br> <strong>弱监督细粒度图像分类</strong><br> 弱监督即仅利用图像的类别标注信息，不使用额外的标注。该方法又可以总结为图像过滤和双线性网络两类。<br> <strong>图像过滤</strong>：图像过滤的思想和强监督中利用bounding box的方法类似，只不过仅借助于图像的类别信息过滤图片中与物体无关的模块，其中比较有代表性的即Two Attention Level算法。该算法在CUB-200数据集上取得了75.7%的精度。<br> **双线性网络：**B-CNN根据大脑工作时同认知类别和关注显著特征的方式，构建了两个线性网络，协调完成局部特征提取和分类的任务，该算法在CUB-200数据集上取得了84.1%的精度，不过该方法在合并阶段会产生较高的维度，使得整个计算开销非常大。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/91205db6e57a3a4edbe7fa1462cf2535/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Ansible之roles（角色）详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2f2b0d09fb0a0a6b6b4c4a867eb0acfb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java笔记-使用Kaptcha验证码框架</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>