<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习：基本概要：监督，无监督，半监督，弱监督，多示例，迁移学习 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习：基本概要：监督，无监督，半监督，弱监督，多示例，迁移学习" />
<meta property="og:description" content="参考：https://blog.csdn.net/limiyudianzi/article/details/78921450
什么是监督学习、无监督学习、强化学习、弱监督学习、半监督学习、多示例学习？
随着机器学习问题不断深入人心，人们也将现实中遇到不同的问题分为不同的学习方式，其中，最基础的应属监督学习，无监督学习和强化学习了。
监督学习(supervised learning)：已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。监督学习是最常见的学习问题之一，就是人们口中常说的分类问题。比如已知一些图片是猪，一些图片不是猪，那么训练一个算法，当一个新的图片输入算法的时候算法告诉我们这张图片是不是猪。
无监督学习(unsupervised learning)：已知数据不知道任何标签，按照一定的偏好，训练一个智能算法，将所有的数据映射到多个不同标签的过程。相对于有监督学习，无监督学习是一类比较困难的问题，所谓的按照一定的偏好，是比如特征空间距离最近，等人们认为属于一类的事物应具有的一些特点。举个例子，猪和鸵鸟混杂在一起，算法会测量高度，发现动物们主要集中在两个高度，一类动物身高一米左右，另一类动物身高半米左右，那么算法按照就近原则，75厘米以上的就是高的那类也就是鸵鸟，矮的那类是第二类也就是猪，当然这里也会出现身材矮小的鸵鸟和身高爆表的猪会被错误的分类。
强化学习(reinforcement learning)：智能算法在没有人为指导的情况下，通过不断的试错来提升任务性能的过程。“试错”的意思是还是有一个衡量标准，用棋类游戏举例，我们并不知道棋手下一步棋是对是错，不知道哪步棋是制胜的关键，但是我们知道结果是输还是赢，如果算法这样走最后的结果是胜利，那么算法就学习记忆，如果按照那样走最后输了，那么算法就学习以后不这样走。
弱监督学习(weakly supervised learning)： 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。
半监督学习(semi supervised learning) ：已知数据和部分数据一一对应的标签，有一部分数据的标签未知，训练一个智能算法，学习已知标签和未知标签的数据，将输入数据映射到标签的过程。半监督通常是一个数据的标注非常困难，比如说医院的检查结果，医生也需要一段时间来判断健康与否，可能只有几组数据知道是健康还是非健康，其他的只有数据不知道是不是健康。那么通过有监督学习和无监督的结合的半监督学习就在这里发挥作用了。
多示例学习(multiple instance learning) ：已知包含多个数据的数据包和数据包的标签，训练智能算法，将数据包映射到标签的过程，在有的问题中也同时给出包内每个数据的标签。多事例学习引入了数据包的概念，比如说一段视频由很多张图组成，假如1000张，那么我们要判断视频里是否有猪出现，一张一张的标注每一帧是否有猪太耗时，所以人们看一遍说这个视频里有猪或者没猪，那么就得到了多示例学习的数据，1000帧的数据不是每一个都有猪出现，只要有一帧有猪，那么我们就认为这个包是有猪的，所有的都没有猪，才是没有猪的，从这里面学习哪一段视频（1000张）有猪哪一段视频没有就是多事例学习的问题。
参考：https://cloud.tencent.com/developer/article/1077499
迁移学习：可以使我们在他人训练过的模型基础上进行小改动便可投入使用。
1. 什么是迁移学习？ 神经网络需要用数据来训练，它从数据中获得信息，进而把它们转换成相应的权重。这些权重能够被提取出来，迁移到其他的神经网络中，我们“迁移”了这些学来的特征，就不需要从零开始训练一个神经网络了 。针对训练数据集小，防止过拟合使用。通常在计算机视觉imagenet 进行预训练。
2. 什么是预训练模型？ 简单来说，预训练模型(pre-trained model)是前人为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从在类似问题中训练过的模型入手。
比如说，如果你想做一辆自动驾驶汽车，可以花数年时间从零开始构建一个性能优良的图像识别算法，也可以从Google在ImageNet数据集上训练得到的inception model(一个预训练模型)起步，来识别图像。
一个预训练模型可能对于你的应用中并不是100%的准确对口，但是它可以为你节省大量功夫。
3.怎样使用预训练模型？ 当在训练经网络的时候我们的目标是什么？我们希望网络能够在多次正向反向迭代的过程中，找到合适的权重。
通过使用之前在大数据集上经过训练的预训练模型，我们可以直接使用相应的结构和权重，将它们应用到我们正在面对的问题上。这被称作是“迁移学习”，即将预训练的模型“迁移”到我们正在应对的特定问题中。
ImageNet数据集已经被广泛用作训练集，因为它规模足够大(包括120万张图片)，有助于训练普适模型。ImageNet的训练目标，是将所有的图片正确地划分到1000个分类条目下。这1000个分类基本上都来源于我们的日常生活，比如说猫猫狗狗的种类，各种家庭用品，日常通勤工具等等。
在迁移学习中，这些预训练的网络对于ImageNet数据集外的图片也表现出了很好的泛化性能。
既然预训练模型已经训练得很好，我们就不会在短时间内去修改过多的权重，在迁移学习中用到它的时候，往往只是进行微调(fine tune)。
在修改模型的过程中，我们通过会采用比一般训练模型更低的学习速率。
5. 微调模型的方法 特征提取
我们可以将预训练模型当做特征提取装置来使用。具体的做法是，将输出层去掉，然后将剩下的整个网络当做一个固定的特征提取机，从而应用到新的数据集中。
采用预训练模型的结构
我们还可以采用预训练模型的结构，但先将所有的权重随机化，然后依据自己的数据集进行训练。
训练特定层，冻结其他层
另一种使用预训练模型的方法是对它进行部分的训练。具体的做法是，将模型起始的一些层的权重保持不变，重新训练后面的层，得到新的权重。在这个过程中，我们可以多次进行尝试，从而能够依据结果找到frozen layers和retrain layers之间的最佳搭配。
如何使用与训练模型，是由数据集大小和新旧数据集(预训练的数据集和我们要解决的数据集)之间数据的相似度来决定的。
下图表展示了在各种情况下应该如何使用预训练模型：
场景一：数据集小，数据相似度高(与pre-trained model的训练数据相比而言)
在这种情况下，因为数据与预训练模型的训练数据相似度很高，因此我们不需要重新训练模型。我们只需要将输出层改制成符合问题情境下的结构就好。
我们使用预处理模型作为模式提取器。
比如说我们使用在ImageNet上训练的模型来辨认一组新照片中的小猫小狗。在这里，需要被辨认的图片与ImageNet库中的图片类似，但是我们的输出结果中只需要两项——猫或者狗。
在这个例子中，我们需要做的就是把dense layer和最终softmax layer的输出从1000个类别改为2个类别。
场景二：数据集小，数据相似度不高
在这种情况下，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，当然最后一层也需要根据相应的输出格式来进行修改。
因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。
场景三：数据集大，数据相似度不高
在这种情况下，因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。
因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/44b3469018ef22b858d1840d27380ebd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-09-21T16:55:49+08:00" />
<meta property="article:modified_time" content="2018-09-21T16:55:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习：基本概要：监督，无监督，半监督，弱监督，多示例，迁移学习</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>参考：<a href="https://blog.csdn.net/limiyudianzi/article/details/78921450">https://blog.csdn.net/limiyudianzi/article/details/78921450</a></p> 
<p>什么是监督学习、无监督学习、强化学习、弱监督学习、半监督学习、多示例学习？<br> 随着机器学习问题不断深入人心，人们也将现实中遇到不同的问题分为不同的学习方式，其中，最基础的应属监督学习，无监督学习和强化学习了。</p> 
<p><strong>监督学习(supervised learning)</strong>：已知数据和其一一对应的标签，训练一个智能算法，将输入数据映射到标签的过程。监督学习是最常见的学习问题之一，就是人们口中常说的分类问题。比如已知一些图片是猪，一些图片不是猪，那么训练一个算法，当一个新的图片输入算法的时候算法告诉我们这张图片是不是猪。</p> 
<p><strong>无监督学习(unsupervised learning)</strong>：已知数据不知道任何标签，按照一定的偏好，训练一个智能算法，将所有的数据映射到多个不同标签的过程。相对于有监督学习，无监督学习是一类比较困难的问题，所谓的按照一定的偏好，是比如特征空间距离最近，等人们认为属于一类的事物应具有的一些特点。举个例子，猪和鸵鸟混杂在一起，算法会测量高度，发现动物们主要集中在两个高度，一类动物身高一米左右，另一类动物身高半米左右，那么算法按照就近原则，75厘米以上的就是高的那类也就是鸵鸟，矮的那类是第二类也就是猪，当然这里也会出现身材矮小的鸵鸟和身高爆表的猪会被错误的分类。</p> 
<p><strong>强化学习(reinforcement learning)</strong>：智能算法在没有人为指导的情况下，通过不断的试错来提升任务性能的过程。“试错”的意思是还是有一个衡量标准，用棋类游戏举例，我们并不知道棋手下一步棋是对是错，不知道哪步棋是制胜的关键，但是我们知道结果是输还是赢，如果算法这样走最后的结果是胜利，那么算法就学习记忆，如果按照那样走最后输了，那么算法就学习以后不这样走。</p> 
<p><strong>弱监督学习(weakly supervised learning)</strong>： 已知数据和其一一对应的弱标签，训练一个智能算法，将输入数据映射到一组更强的标签的过程。标签的强弱指的是标签蕴含的信息量的多少，比如相对于分割的标签来说，分类的标签就是弱标签，如果我们知道一幅图，告诉你图上有一只猪，然后需要你把猪在哪里，猪和背景的分界在哪里找出来，那么这就是一个已知若标签，去学习强标签的弱监督学习问题。</p> 
<p><strong>半监督学习(semi supervised learning</strong>) ：已知数据和部分数据一一对应的标签，有一部分数据的标签未知，训练一个智能算法，<strong>学习已知标签和未知标签的数据，将输入数据映射到标签的过程</strong>。半监督通常是一个数据的标注非常困难，比如说医院的检查结果，医生也需要一段时间来判断健康与否，可能只有几组数据知道是健康还是非健康，其他的只有数据不知道是不是健康。那么通过有监督学习和无监督的结合的半监督学习就在这里发挥作用了。</p> 
<p><strong>多示例学习(multiple instance learning)</strong> ：已知包含多个数据的数据包和数据包的标签，训练智能算法，<strong>将数据包映射到标签的过程</strong>，在有的问题中也同时给出包内每个数据的标签。多事例学习引入了数据包的概念，比如说一段视频由很多张图组成，假如1000张，那么我们要判断视频里是否有猪出现，一张一张的标注每一帧是否有猪太耗时，所以人们看一遍说这个视频里有猪或者没猪，那么就得到了多示例学习的数据，1000帧的数据不是每一个都有猪出现，只要有一帧有猪，那么我们就认为这个包是有猪的，所有的都没有猪，才是没有猪的，从这里面学习哪一段视频（1000张）有猪哪一段视频没有就是多事例学习的问题。</p> 
<p>参考：<a href="https://cloud.tencent.com/developer/article/1077499" rel="nofollow">https://cloud.tencent.com/developer/article/1077499</a></p> 
<p><strong>迁移学习</strong>：可以使我们在他人训练过的模型基础上进行小改动便可投入使用。</p> 
<h2><strong>1. 什么是迁移学习？</strong></h2> 
<p>神经网络需要用数据来训练，它从数据中获得信息，进而把它们转换成相应的权重。<strong>这些权重能够被提取出来，迁移到其他的神经网络中</strong>，我们“迁移”了这些学来的特征，就不需要从零开始训练一个神经网络了 。针对训练数据集小，防止过拟合使用。通常在计算机视觉imagenet 进行预训练。</p> 
<h2><strong>2. 什么是预训练模型？</strong></h2> 
<p>简单来说，预训练模型(pre-trained model)是前人为了解决类似问题所创造出来的模型。你在解决问题的时候，不用从零开始训练一个新模型，可以从在类似问题中训练过的模型入手。</p> 
<p>比如说，如果你想做一辆自动驾驶汽车，可以花数年时间从零开始构建一个性能优良的图像识别算法，也可以从Google在ImageNet数据集上训练得到的inception model(一个预训练模型)起步，来识别图像。</p> 
<p>一个预训练模型可能对于你的应用中并不是100%的准确对口，但是它可以为你节省大量功夫。</p> 
<h2><strong>3.怎样使用预训练模型？</strong></h2> 
<p>当在训练经网络的时候我们的目标是什么？我们希望网络能够在多次正向反向迭代的过程中，找到合适的权重。</p> 
<p><strong>通过使用之前在大数据集上经过训练的预训练模型，我们可以直接使用相应的结构和权重，将它们应用到我们正在面对的问题上。</strong>这被称作是“迁移学习”，即将预训练的模型“迁移”到我们正在应对的特定问题中。</p> 
<p><strong>ImageNe</strong>t数据集已经被广泛用作训练集，因为它规模足够大(包括120万张图片)，有助于训练普适模型。ImageNet的训练目标，是将所有的图片正确地划分到1000个分类条目下。这1000个分类基本上都来源于我们的日常生活，比如说猫猫狗狗的种类，各种家庭用品，日常通勤工具等等。</p> 
<p>在迁移学习中，这些预训练的网络对于ImageNet数据集外的图片也表现出了很好的泛化性能。</p> 
<p>既然预训练模型已经训练得很好，我们就不会在短时间内去修改过多的权重，在迁移学习中用到它的时候，往往只是进行<strong>微调(fine tune)</strong>。</p> 
<p>在修改模型的过程中，我们通过会采用比一般训练模型更低的学习速率。</p> 
<h2><strong>5. 微调模型的方法</strong></h2> 
<p><strong>特征提取</strong></p> 
<p>我们可以将预训练模型当做特征提取装置来使用。具体的做法是，将输出层去掉，然后将剩下的整个网络当做一个固定的特征提取机，从而应用到新的数据集中。</p> 
<p><strong>采用预训练模型的结构</strong></p> 
<p>我们还可以采用预训练模型的结构，但先将所有的权重随机化，然后依据自己的数据集进行训练。</p> 
<p><strong>训练特定层，冻结其他层</strong></p> 
<p>另一种使用预训练模型的方法是对它进行部分的训练。具体的做法是，将模型起始的一些层的权重保持不变，重新训练后面的层，得到新的权重。在这个过程中，我们可以多次进行尝试，从而能够依据结果找到frozen layers和retrain layers之间的最佳搭配。</p> 
<p>如何使用与训练模型，是由数据集大小和新旧数据集(预训练的数据集和我们要解决的数据集)之间数据的相似度来决定的。</p> 
<p>下图表展示了在各种情况下应该如何使用预训练模型：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/98/db/53ffqdQy_o.jpg"></p> 
<p><strong>场景一：数据集小，数据相似度高(与pre-trained model的训练数据相比而言)</strong></p> 
<p>在这种情况下，因为数据与预训练模型的训练数据相似度很高，因此我们不需要重新训练模型。我们只需要将输出层改制成符合问题情境下的结构就好。</p> 
<p>我们使用预处理模型作为模式提取器。</p> 
<p>比如说我们使用在ImageNet上训练的模型来辨认一组新照片中的小猫小狗。在这里，需要被辨认的图片与ImageNet库中的图片类似，但是我们的输出结果中只需要两项——猫或者狗。</p> 
<p>在这个例子中，我们需要做的就是把dense layer和最终softmax layer的输出从1000个类别改为2个类别。</p> 
<p><strong>场景二：数据集小，数据相似度不高</strong></p> 
<p>在这种情况下，我们可以冻结预训练模型中的前k个层中的权重，然后重新训练后面的n-k个层，当然最后一层也需要根据相应的输出格式来进行修改。</p> 
<p>因为数据的相似度不高，重新训练的过程就变得非常关键。而新数据集大小的不足，则是通过冻结预训练模型的前k层进行弥补。</p> 
<p><strong>场景三：数据集大，数据相似度不高</strong></p> 
<p>在这种情况下，因为我们有一个很大的数据集，所以神经网络的训练过程将会比较有效率。然而，因为实际数据与预训练模型的训练数据之间存在很大差异，采用预训练模型将不会是一种高效的方式。</p> 
<p>因此最好的方法还是将预处理模型中的权重全都初始化后在新数据集的基础上重头开始训练。</p> 
<p><strong>场景四：数据集大，数据相似度高</strong></p> 
<p>这就是最理想的情况，采用预训练模型会变得非常高效。最好的运用方式是保持模型原有的结构和初始权重不变，随后在新数据集的基础上重新训练。</p> 
<h2><strong>5. 在手写数字识别中使用预训练模型</strong></h2> 
<p>现在，让我们尝试来用预训练模型去解决一个简单的问题。</p> 
<p>我曾经使用vgg16作为预训练的模型结构，并把它应用到手写数字识别上。</p> 
<p>让我们先来看看这个问题对应着之前四种场景中的哪一种。我们的训练集(MNIST)有大约60,000张左右的手写数字图片，这样的数据集显然是偏小的。所以这个问题应该属于场景一或场景二。</p> 
<p>我们可以尝试把两种对应的方法都用一下，看看最终的效果。</p> 
<p><strong>只重新训练输出层 &amp; dense layer</strong></p> 
<p>这里我们采用vgg16作为特征提取器。随后这些特征，会被传递到依据我们数据集训练的dense layer上。输出层同样由与我们问题相对应的softmax层函数所取代。</p> 
<p>在vgg16中，输出层是一个拥有1000个类别的softmax层。我们把这层去掉，换上一层只有10个类别的softmax层。我们只训练这些层，然后就进行数字识别的尝试。</p> 
<pre class="has"><code>
# importing required librariesfrom keras.models import Sequentialfrom scipy.misc import imread
get_ipython().magic('matplotlib inline')import matplotlib.pyplot as pltimport numpy as npimport kerasfrom keras.layers import Denseimport pandas as pdfrom 

keras.applications.vgg16 import VGG16from keras.preprocessing import imagefrom 
keras.applications.vgg16 import preprocess_inputimport numpy as npfrom 
keras.applications.vgg16 import decode_predictions
train=pd.read_csv("R/Data/Train/train.csv")
test=pd.read_csv("R/Data/test.csv")
train_path="R/Data/Train/Images/train/"
test_path="R/Data/Train/Images/test/"from scipy.misc import imresize# preparing the train 

datasettrain_img=[]for i in range(len(train)):

    temp_img=image.load_img(train_path+train['filename'][i],target_size=(224,224))

    temp_img=image.img_to_array(temp_img)

    train_img.append(temp_img)#converting train images to array and applying mean subtraction processingtrain_img=np.array(train_img) 

train_img=preprocess_input(train_img)# applying the same procedure with the test datasettest_img=[]for i in range(len(test)):

    temp_img=image.load_img(test_path+test['filename'][i],target_size=(224,224))

    temp_img=image.img_to_array(temp_img)

    test_img.append(temp_img)

test_img=np.array(test_img) 
test_img=preprocess_input(test_img)# loading VGG16 model weightsmodel = VGG16(weights='imagenet', include_top=False)# Extracting features from the train dataset using the VGG16 pre-trained modelfeatures_train=model.predict(train_img)# Extracting features from the train dataset using the VGG16 pre-trained modelfeatures_test=model.predict(test_img)# flattening the layers to conform to MLP inputtrain_x=features_train.reshape(49000,25088)# converting target variable to arraytrain_y=np.asarray(train['label'])# performing one-hot encoding for the target variabletrain_y=pd.get_dummies(train_y)
train_y=np.array(train_y)# creating training and validation setfrom sklearn.model_selection import train_test_split
X_train, X_valid, Y_train, Y_valid=train_test_split(train_x,train_y,test_size=0.3, random_state=42)# creating a mlp modelfrom keras.layers import Dense, Activation
model=Sequential()

model.add(Dense(1000, input_dim=25088, activation='relu',kernel_initializer='uniform'))
keras.layers.core.Dropout(0.3, noise_shape=None, seed=None)

model.add(Dense(500,input_dim=1000,activation='sigmoid'))
keras.layers.core.Dropout(0.4, noise_shape=None, seed=None)

model.add(Dense(150,input_dim=500,activation='sigmoid'))
keras.layers.core.Dropout(0.2, noise_shape=None, seed=None)

model.add(Dense(units=10))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy', optimizer="adam", metrics=['accuracy'])# fitting the model model.fit(X_train, Y_train, epochs=20, batch_size=128,validation_data=(X_valid,Y_valid))
</code></pre> 
<p><strong>冻结最初几层网络的权重</strong></p> 
<p>这里我们将会把vgg16网络的前8层进行冻结，然后对后面的网络重新进行训练。这么做是因为最初的几层网络捕获的是曲线、边缘这种普遍的特征，这跟我们的问题是相关的。我们想要保证这些权重不变，让网络在学习过程中重点关注这个数据集特有的一些特征，从而对后面的网络进行调整。</p> 
<pre class="has"><code>from keras.models import Sequentialfrom scipy.misc import imread
get_ipython().magic('matplotlib inline')import matplotlib.pyplot as pltimport numpy as npimport kerasfrom keras.layers import Denseimport pandas as pdfrom keras.applications.vgg16 import VGG16from keras.preprocessing import imagefrom keras.applications.vgg16 import preprocess_inputimport numpy as npfrom keras.applications.vgg16 import decode_predictionsfrom keras.utils.np_utils import to_categoricalfrom sklearn.preprocessing import LabelEncoderfrom keras.models import Sequentialfrom keras.optimizers import SGDfrom keras.layers import Input, Dense, Convolution2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, merge, Reshape, Activationfrom sklearn.metrics import log_loss

train=pd.read_csv("R/Data/Train/train.csv")
test=pd.read_csv("R/Data/test.csv")
train_path="R/Data/Train/Images/train/"test_path="R/Data/Train/Images/test/"from scipy.misc import imresize

train_img=[]for i in range(len(train)):

    temp_img=image.load_img(train_path+train['filename'][i],target_size=(224,224))

    temp_img=image.img_to_array(temp_img)

    train_img.append(temp_img)

train_img=np.array(train_img) 
train_img=preprocess_input(train_img)

test_img=[]for i in range(len(test)):

temp_img=image.load_img(test_path+test['filename'][i],target_size=(224,224))

    temp_img=image.img_to_array(temp_img)

    test_img.append(temp_img)

test_img=np.array(test_img) 
test_img=preprocess_input(test_img)from keras.models import Modeldef vgg16_model(img_rows, img_cols, channel=1, num_classes=None):

    model = VGG16(weights='imagenet', include_top=True)

    model.layers.pop()

    model.outputs = [model.layers[-1].output]

    model.layers[-1].outbound_nodes = []

          x=Dense(num_classes, activation='softmax')(model.output)

    model=Model(model.input,x)#To set the first 8 layers to non-trainable (weights will not be updated)

          for layer in model.layers[:8]:

       layer.trainable = False# Learning rate is changed to 0.001
    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)
    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])    return model

train_y=np.asarray(train['label'])

le = LabelEncoder()

train_y = le.fit_transform(train_y)

train_y=to_categorical(train_y)

train_y=np.array(train_y)from sklearn.model_selection import train_test_split
X_train, X_valid, Y_train, Y_valid=train_test_split(train_img,train_y,test_size=0.2, random_state=42)# Example to fine-tune on 3000 samples from Cifar10img_rows, img_cols = 224, 224 # Resolution of inputschannel = 3num_classes = 10 batch_size = 16 nb_epoch = 10# Load our modelmodel = vgg16_model(img_rows, img_cols, channel, num_classes)

model.summary()# Start Fine-tuningmodel.fit(X_train, Y_train,batch_size=batch_size,epochs=nb_epoch,shuffle=True,verbose=1,validation_data=(X_valid, Y_valid))# Make predictionspredictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)# Cross-entropy loss scorescore = log_loss(Y_valid, predictions_valid)</code></pre> 
<h2><strong>相关资源</strong></h2> 
<p>原文： https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/</p> 
<p>VGG-16： https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3</p> 
<p>Keras库中的ImageNet预训练模型： https://keras.io/applications/</p> 
<p>手写数字数据集MNIST： http://yann.lecun.com/exdb/mnist/</p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ab7c50b3028fd5bd7c5f4b30579fb160/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">mininet walkthrough 中遇到 dpctl failed to send packet to switch:connection refused</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6e4a71dc20f998eed4dddb305d2b5ac0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux 模拟网络丢包和延迟命令</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>