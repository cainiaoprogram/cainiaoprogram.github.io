<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>科研学习|论文解读——超准确性反馈：使用眼动追踪来检测阅读过程中的可理解性和兴趣 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="科研学习|论文解读——超准确性反馈：使用眼动追踪来检测阅读过程中的可理解性和兴趣" />
<meta property="og:description" content="摘要： 了解用户想要什么信息是信息科学和技术面临的最大挑战。隐式反馈是解决这一挑战的关键，因为它允许信息系统了解用户的需求和偏好。然而，可用的反馈往往是有限的，而且其解释也很困难。为了应对这一挑战，我们提出了一项用户研究，探索追踪眼动是否可以解开相关性和相关性决策固有的部分复杂性。将阅读18篇新闻文章的 30名参与者的眼睛行为与他们在话语层面上主观评价的理解力和兴趣进行了比较。 使用线性回归模型，眼球追踪信号解释了49.93%（可理解性）和 30.41%（兴趣）的方差 (p &lt; .001)。 我们得出结论，眼睛行为提供了超准确性的隐式反馈，从而为个性化信息系统提供了新形式的适应和交互支持。
1.引言 理解和了解用户在信息方面的需求是信息系统面临的最大挑战（Saracevic, 2007）。文本挖掘技术目前用于通过估计文档是否与查询相似（信息检索）、是否在相似的人或朋友中流行（协同过滤）或与用户模型相似（认知过滤）来推断用户的信息需求。尽管这些技术无疑是成功的，但它们似乎被一个神奇的障碍所困扰：它们预测信息价值的潜力有限（Said &amp; Bellogín, 2018; Voorhees, 2002）。当前的技术难以适应用户之间的差异，例如他们的知识和偏好，以及用户内部的差异，例如不断变化的信息需求和兴趣（Hill, 1995）。由于每个用户的信息价值不同，并且会随时间变化（Belkin, 2008; Saracevic, 2007），因此需要持续反馈以更好地预测信息是否以及何时对用户有价值（Ghorab, 2013; Liu, 2020)。
要求用户就他们想要的信息提供大量和持续的输入是不可能成功的。相反，不需要用户进行任何交互的隐式反馈是一个更可行的选择（Barra, 2016; Ghorab, 2013; Liu, 2020）。基本的在线措施已经成功地用于文本挖掘。 来自点击流数据、浏览数据和查询文本关系的特征将二进制排名精度提高到高达 31%（Agichtein, 2006）、预测分级相关性评估高达 r = .411（Guo &amp; Agichtein, 2012）。此外，生理信号（Barral, 2016 ），尤其是眼动追踪（Li,2018）有望扩展这些结果（Cole, 2015）。对于相关和不相关的结果，人类的注意力遵循一种独特且可识别的模式（Li, 2018）。眼球追踪数据可以显示关注了哪些搜索结果或文档的哪些部分，并将其用作查询扩展、优化（Buscher, 2012）甚至构建（Ajanki, 2009）。 在二进制文本挖掘精度上，可以通过眼动追踪检测到相关性，精度为 64%（Liu,2014）、74%（Gwizdka,2014）、80%（Bhattacharya,2020）和 86%（Gwizdka,2017）。
从眼动数据预测（二元）相关性决策的表现证实了其在隐式反馈方面的潜力。尽管如此，相关性的直观概念包含了人类判断和经验的巨大复杂性。用户在判断相关性时会应用一系列标准，例如文档的时事性、可信度、风格和阅读水平 (Schamber, 1994) 以及电影的故事和视觉效果 (Adomavicius &amp; Kwon, 2015)。 人类判断的这种巨大复杂性随后形成了相关的认知情感体验（Ruthven，2021）。在一个不断发展的交互会话中，一套特定的元认知判断和体验展开了，比如用户对处理动态的反思。认知上的轻松通常与满意的感觉相关（Al-Maskari &amp; Sanderson, 2010），而中间的复杂性似乎与兴趣的感觉相关（Dubey &amp; Griffiths, 2020; van der Sluis, 2014）。在互动过程中，这些认知-情感判断和体验的重要性表明了 &#34;超越传统准确性指标 &#34;的反馈潜力（McNee, 2006）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2e6a73084fd865ba14d5d506051866e9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-06T21:04:51+08:00" />
<meta property="article:modified_time" content="2024-01-06T21:04:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">科研学习|论文解读——超准确性反馈：使用眼动追踪来检测阅读过程中的可理解性和兴趣</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>摘要：</h2> 
<blockquote> 
 <p><span style="color:#000000;">了解用户想要什么信息是信息科学和技术面临的最大挑战。</span><u><span style="color:#FF0000;"><strong>隐式反馈</strong></span></u><span style="color:#000000;">是解决这一挑战的关键，因为它允许信息系统了解用户的需求和偏好。然而，可用的反馈往往是有限的，而且其解释也很困难。为了应对这一挑战，我们提出了</span><u><span style="color:#FF0000;"><strong>一项用户研究</strong></span></u><span style="color:#000000;">，探索</span><u><span style="color:#FF0000;"><strong>追踪眼动</strong></span></u><span style="color:#000000;">是否可以解开相关性和相关性决策固有的部分复杂性。将阅读</span><u><span style="color:#FF0000;"><strong>18</strong></span></u><u><span style="color:#FF0000;"><strong>篇新闻文章</strong></span></u><span style="color:#000000;">的 </span><u><span style="color:#FF0000;"><strong>30</strong></span></u><u><span style="color:#FF0000;"><strong>名参与者</strong></span></u><span style="color:#000000;">的眼睛行为与他们在话语层面上主观评价的理解力和兴趣进行了比较。 使用</span><u><span style="color:#FF0000;"><strong>线性回归模型</strong></span></u><span style="color:#000000;">，眼球追踪信号解释了</span><span style="color:#000000;">49.93%</span><span style="color:#000000;">（</span><u><span style="color:#FF0000;"><strong>可理解性</strong></span></u><span style="color:#000000;">）和 </span><span style="color:#000000;">30.41%</span><span style="color:#000000;">（</span><u><span style="color:#FF0000;"><strong>兴趣</strong></span></u><span style="color:#000000;">）的方差 </span><span style="color:#000000;">(p &lt; .001)</span><span style="color:#000000;">。 我们得出结论，眼睛行为提供了超准确性的隐式反馈，从而为个性化信息系统提供了新形式的适应和交互支持。</span></p> 
</blockquote> 
<h2>1.引言</h2> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>理解和了解用户在信息方面的需求是信息系统面临的最大挑战</strong></span></u><span style="color:#000000;">（</span><span style="color:#000000;">Saracevic</span><span style="color:#000000;">, 2007</span><span style="color:#000000;">）。文本挖掘技术目前用于通过估计文档是否与查询相似（信息检索）、是否在相似的人或朋友中流行（协同过滤）或与用户模型相似（认知过滤）来推断用户的信息需求。尽管这些技术无疑是成功的，但它们似乎被一个神奇的障碍所困扰：它们预测信息价值的潜力有限（</span><span style="color:#000000;">Said &amp; </span><span style="color:#000000;">Bellogín</span><span style="color:#000000;">, 2018; Voorhees,</span> <span style="color:#000000;">2002</span><span style="color:#000000;">）。当前的技术难以适应用户之间的差异，例如他们的知识和偏好，以及用户内部的差异，例如不断变化的信息需求和兴趣（</span><span style="color:#000000;">Hill,</span> <span style="color:#000000;">1995</span><span style="color:#000000;">）。由于每个用户的信息价值不同，并且会随时间变化（</span><span style="color:#000000;">Belkin,</span> <span style="color:#000000;">2008; </span><span style="color:#000000;">Saracevic</span><span style="color:#000000;">, 2007</span><span style="color:#000000;">），因此需要持续反馈以更好地预测信息是否以及何时对用户有价值（</span><span style="color:#000000;">Ghorab</span><span style="color:#000000;">, 2013; Liu, 2020)</span><span style="color:#000000;">。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>要求用户就他们想要的信息提供大量和持续的输入是不可能成功的</strong></span></u><span style="color:#000000;">。相反，不需要用户进行任何交互的隐式反馈是一个更可行的选择（</span><span style="color:#000000;">Barra, 2016; </span><span style="color:#000000;">Ghorab</span><span style="color:#000000;">,</span> <span style="color:#000000;">2013; Liu, 2020</span><span style="color:#000000;">）。基本的在线措施已经成功地用于文本挖掘。 来自点击流数据、浏览数据和查询文本关系的特征将二进制排名精度提高到高达 </span><span style="color:#000000;">31%</span><span style="color:#000000;">（</span><span style="color:#000000;">Agichtein</span><span style="color:#000000;">, 2006</span><span style="color:#000000;">）、预测分级相关性评估高达 </span><span style="color:#000000;">r = .411</span><span style="color:#000000;">（</span><span style="color:#000000;">Guo &amp; </span><span style="color:#000000;">Agichtein</span><span style="color:#000000;">, 2012</span><span style="color:#000000;">）。此外，生理信号（</span><span style="color:#000000;">Barral</span><span style="color:#000000;">, 2016 </span><span style="color:#000000;">），尤其是眼动追踪（</span><span style="color:#000000;">Li,2018</span><span style="color:#000000;">）有望扩展这些结果（</span><span style="color:#000000;">Cole, 2015</span><span style="color:#000000;">）。对于相关和不相关的结果，人类的注意力遵循一种独特且可识别的模式（</span><span style="color:#000000;">Li, 2018</span><span style="color:#000000;">）。眼球追踪数据可以显示关注了哪些搜索结果或文档的哪些部分，并将其用作查询扩展、优化（</span><span style="color:#000000;">Buscher</span><span style="color:#000000;">,</span> <span style="color:#000000;">2012</span><span style="color:#000000;">）甚至构建（</span><span style="color:#000000;">Ajanki</span><span style="color:#000000;">, 2009</span><span style="color:#000000;">）。 在二进制文本挖掘精度上，可以通过眼动追踪检测到相关性，精度为 </span><span style="color:#000000;">64%</span><span style="color:#000000;">（</span><span style="color:#000000;">Liu,2014</span><span style="color:#000000;">）、</span><span style="color:#000000;">74%</span><span style="color:#000000;">（</span><span style="color:#000000;">Gwizdka,2014</span><span style="color:#000000;">）、</span><span style="color:#000000;">80%</span><span style="color:#000000;">（</span><span style="color:#000000;">Bhattacharya,2020</span><span style="color:#000000;">）和 </span><span style="color:#000000;">86%</span><span style="color:#000000;">（</span><span style="color:#000000;">Gwizdka,2017</span><span style="color:#000000;">）。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>从眼动数据预测（二元）相关性决策的表现证实了其在隐式反馈方面的潜力</strong></span></u><span style="color:#000000;">。尽管如此，相关性的直观概念包含了人类判断和经验的巨大复杂性。用户在判断相关性时会应用一系列标准，例如文档的时事性、可信度、风格和阅读水平 </span><span style="color:#000000;">(Schamber, 1994) </span><span style="color:#000000;">以及电影的故事和视觉效果 </span><span style="color:#000000;">(</span><span style="color:#000000;">Adomavicius</span><span style="color:#000000;"> &amp; Kwon, 2015)</span><span style="color:#000000;">。 人类判断的这种巨大复杂性随后形成了相关的认知情感体验（</span><span style="color:#000000;">Ruthven</span><span style="color:#000000;">，</span><span style="color:#000000;">2021</span><span style="color:#000000;">）。在一个不断发展的交互会话中，一套特定的元认知判断和体验展开了，比如用户对处理动态的反思。认知上的轻松通常与满意的感觉相关（</span><span style="color:#000000;">Al-</span><span style="color:#000000;">Maskari</span><span style="color:#000000;"> &amp; Sanderson, 2010</span><span style="color:#000000;">），而中间的复杂性似乎与兴趣的感觉相关（</span><span style="color:#000000;">Dubey &amp; Griffiths, 2020; van der </span><span style="color:#000000;">Sluis</span><span style="color:#000000;">, 2014</span><span style="color:#000000;">）。在互动过程中，这些认知</span><span style="color:#000000;">-</span><span style="color:#000000;">情感判断和体验的重要性表明了 </span><span style="color:#000000;">"</span><span style="color:#000000;">超越传统准确性指标 </span><span style="color:#000000;">"</span><span style="color:#000000;">的反馈潜力（</span><span style="color:#000000;">McNee</span><span style="color:#000000;">, 2006</span><span style="color:#000000;">）</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>眼动追踪提供了一种独特的潜力，可以解开相关性和相关性决策所固有的部分复杂性</strong></span></u><span style="color:#000000;">。众所周知，从 </span><span style="color:#000000;">Hess </span><span style="color:#000000;">和 </span><span style="color:#000000;">Polt</span><span style="color:#000000;"> (1960, 1964) </span><span style="color:#000000;">的早期工作开始，眼睛可以反映认知处理和兴趣价值的各个方面。随后的研究强调，眼睛特别善于反映瞬间的认知过程（</span><span style="color:#000000;">Just &amp; Carpenter,1980;Miller,2015;Rayner,1998</span><span style="color:#000000;">）。其中，眼睛停留在难以处理的单词或区域上的时间更长（</span><span style="color:#000000;">Rayner,2006</span><span style="color:#000000;">）。人们认为，感兴趣的个人引导注意力并利用认知资源来保持中等的信息获取率。他们提供持续反馈的能力使得追踪眼睛很可能揭示出感兴趣的个体处理动态和注意力模式。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>尽管确定了眼动追踪数据用于隐式反馈的用途和潜力，但尚不清楚眼睛的独特潜力是否可以作为（二元）相关决策、认知处理或兴趣的指标，也不清楚这些构造的效果如何使用眼动数据来区分。</strong></span></u><span style="color:#000000;">类似于行为轨迹数据（</span><span style="color:#000000;">Van der Sluis,2017</span><span style="color:#000000;">）和生理信号（</span><span style="color:#000000;">van den Broek,2011</span><span style="color:#000000;">）中固有的模糊性，眼动追踪数据很难解释。这些认知过程是否通过观察阅读过程中的眼睛行为变得明显尚不清楚，因为许多认知过程交织在一起，当跨单词、句子和话语水平组合时，观察到的效果通常很小且不明显（</span><span style="color:#000000;">Rayner,2006</span><span style="color:#000000;">）。此外，眼球追踪数据本质上是嘈杂的，特别是在生态有效的环境中。</span><u><span style="color:#000000;"><strong>头部位置和距离、照明条件和低采样频率可能会有显着变化，尤其是对于廉价的消费市场眼动仪。</strong></span></u><span style="color:#000000;">鉴于这些挑战，通常会在高度受控的设置和刺激下提出和探索关于认知</span><span style="color:#000000;">-</span><span style="color:#000000;">情感过程的眼动追踪反馈 </span><span style="color:#000000;">(Rayner et al., 2006)</span><span style="color:#000000;">，这引发了对其在文本挖掘等应用环境中可行性的质疑。</span></p> 
</blockquote> 
<blockquote> 
 <p><span style="color:#000000;">结合眼睛为隐式反馈提供的机遇和挑战，本文提出了一项研究，检查跟踪眼睛是否可以提供超越传统准确性指标的反馈。我们探讨了如何识别和区分可理解性和兴趣，并讨论了这些方面如何反馈给文本挖掘。我们根据兴趣的情绪评估理论来构建兴趣，该理论将兴趣视为由外部刺激引起的瞬间兴趣（Silvia,2006</span><span style="color:#000000;">）。这种框架与情境兴趣的概念化一致，但与更持久的个人或个人兴趣形成对比（</span><span style="color:#000000;">Shin &amp; Kim,2019;Sinnamon,2021</span><span style="color:#000000;">）。它还假设，在可理解的范围内，一定程度的处理难度有助于产生兴趣（</span><span style="color:#000000;">Sinnamon,2021;van der Sluis,2014</span><span style="color:#000000;">）。</span></p> 
</blockquote> 
<blockquote> 
 <p><span style="color:#000000;">通过探索眼睛揭示可理解性和兴趣的能力，本研究旨在在人类信息交互的背景下，在认知活动和兴趣价值之间对眼睛行为的解释带来经典和长期存在的差异。</span></p> 
</blockquote> 
<h2>2.背景：眼睛行为</h2> 
<blockquote> 
 <p><span style="color:#000000;">在阅读时，我们的眼睛遵循着一种独特的、可识别的模式。手头的任务(</span><span style="color:#000000;">如阅读</span><span style="color:#000000;">)</span><span style="color:#000000;">和上下文</span><span style="color:#000000;">(</span><span style="color:#000000;">如文本</span><span style="color:#000000;">)</span><span style="color:#000000;">会影响眼睛行为的主要特征</span><span style="color:#000000;">(Luke &amp; Henderson,2013;Rothkopf et al.,2007)</span><span style="color:#000000;">。尽管这意味着眼睛行为主要由任务和文本决定，但更高阶的认知过程</span><span style="color:#000000;">——</span><span style="color:#000000;">如理解和兴趣</span><span style="color:#000000;">——</span><span style="color:#000000;">可以改变这些行为的特定特征</span><span style="color:#000000;">(Luke &amp; Henderson, 2013)</span><span style="color:#000000;">。赫斯和波尔很早就发现了</span><u><span style="color:#FF0000;"><strong>眼睛反映高阶心理过程的潜力</strong></span></u><span style="color:#000000;">:</span><span style="color:#000000;">对视觉信息的兴趣</span><span style="color:#000000;">(1960)</span><span style="color:#000000;">和由解决问题困难引起的心理活动</span><span style="color:#000000;">(1964)</span><span style="color:#000000;">。这种区别反映了</span><span style="color:#000000;">(a)</span><span style="color:#000000;">认知控制假说</span><span style="color:#000000;">(</span><span style="color:#000000;">或</span><span style="color:#000000;">:</span><u><span style="color:#FF0000;"><strong>眼</strong></span></u><u><span style="color:#FF0000;"><strong>-</strong></span></u><u><span style="color:#FF0000;"><strong>心联系</strong></span></u><span style="color:#000000;">)</span><span style="color:#000000;">，该假说认为“只要一个单词正在被加工，眼睛就会一直注视着这个单词”</span><span style="color:#000000;">(Just &amp; Carpenter, 1980, p. 330)</span><span style="color:#000000;">，将注视与认知加工联系起来</span><span style="color:#000000;">;(b)“</span><span style="color:#000000;">喜欢的越多，看的越多”假设</span><span style="color:#000000;">(</span><span style="color:#000000;">或</span><span style="color:#000000;">:</span><u><span style="color:#FF0000;"><strong>信息价值联系</strong></span></u><span style="color:#000000;">)</span><span style="color:#000000;">，即感兴趣的观察者会将目光转向他们重视的刺激</span><span style="color:#000000;">(Gottlieb, 2012;Miller,2015)</span><span style="color:#000000;">。在下面的小节中，我们将回顾这两种假设，特别关注高阶认知过程。</span></p> 
</blockquote> 
<h3>2.1 眼-心联系</h3> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>在自定速阅读和眼动研究中，阅读速度和眼球运动被解释为认知活动的间接测量</strong></span></u><span style="color:#000000;">。阅读过程中，眼睛会做一系列快速运动</span><span style="color:#000000;">(</span><u><span style="color:#000000;"><strong>眼跳</strong></span></u><span style="color:#000000;">)</span><span style="color:#000000;">，中间有几段时间相对静止</span><span style="color:#000000;">(</span><u><span style="color:#000000;"><strong>注视</strong></span></u><span style="color:#000000;">)</span><span style="color:#000000;">。注视过程中，新视觉信息从文本中编码出来。固定时间通常持续</span><span style="color:#000000;">200-250</span><span style="color:#000000;">毫秒，短或长都不常见。</span><u><span style="color:#000000;"><strong>扫视</strong></span></u><span style="color:#000000;">通常持续</span><span style="color:#000000;">20-40</span><span style="color:#000000;">毫秒，取决于所走距离</span><span style="color:#000000;">(Rayner et al.,2006)</span><span style="color:#000000;">。在熟练阅读者中，向后移动的扫视</span><span style="color:#000000;">(</span><u><span style="color:#000000;"><strong>倒退</strong></span></u><span style="color:#000000;">)</span><span style="color:#000000;">约占所有扫视的</span><span style="color:#000000;">10%</span><span style="color:#000000;">，且经常移动很短距离</span><span style="color:#000000;">(</span><span style="color:#000000;">一个单词</span><span style="color:#000000;">)</span><span style="color:#000000;">。</span><u><span style="color:#000000;"><strong>与眼球运动相比，瞳孔大小和眨眼对人类认知活动变化的反应延迟</strong></span></u><u><span style="color:#000000;"><strong>1.3</strong></span></u><u><span style="color:#000000;"><strong>秒</strong></span></u><span style="color:#000000;">(Just et al.,2003)</span><span style="color:#000000;">，而其主要对亮度变化做出反应</span><span style="color:#000000;">(Beatty &amp; Lucero-Wagoner, 2000)</span><span style="color:#000000;">。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>按照眼</strong></span></u><u><span style="color:#FF0000;"><strong>-</strong></span></u><u><span style="color:#FF0000;"><strong>心联系，与单词解码和识别相关的低阶过程与阅读过程中的眼球运动有因果关系</strong></span></u><span style="color:#000000;">。</span><span style="color:#000000;">例如，印刷词频率决定了每个词的总注视持续时间高达</span><span style="color:#000000;">30-90 </span><span style="color:#000000;">毫秒 </span><span style="color:#000000;">(</span><span style="color:#000000;">Inhoff</span><span style="color:#000000;">, 1986)</span><span style="color:#000000;">。 此外，读者会在上下文中感知一个词。 更多语义相关的词需要更少的注视时间来处理。同样，更短和更有可能的词（</span><span style="color:#000000;">n-grams</span><span style="color:#000000;">）更有可能被跳过，从而增加扫视长度和缩短注视时间（</span><span style="color:#000000;">Ehrlich,1981</span><span style="color:#000000;">）。当读者需要解决一个词的歧义时，也可以观察到溢出效应。词义歧义会增加注视时间，当读者在理解某个意思之前试图获取额外信息时，可能会延迟到后续单词，并且当读者最初理解错误的意思时，可能会导致倒退</span><span style="color:#000000;">(Rayner, 1986)</span><span style="color:#000000;">。 这些强烈的影响不仅表明与词汇处理相关的低阶过程与眼睛行为有因果关系，而且它们可相当准确地建模：时间、扫视长度 </span><span style="color:#000000;">(Rayner, 2006)</span><span style="color:#000000;">。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>在理解文本时，读者必须能够整合句子内部和句子之间的信息，以形成连贯的话语表达</strong></span></u><span style="color:#000000;">。</span><span style="color:#000000;">总体而言，这种高阶过程通过更长和更多的注视、更多的阅读时间和更多的倒退（</span><span style="color:#000000;">Rayner,2006;Schotter,2014</span><span style="color:#000000;">）来表现出来，而理解过程中的持续努力可能会增加瞳孔大小（</span><span style="color:#000000;">Just,2003</span><span style="color:#000000;">）并减少其可变性（</span><span style="color:#000000;">Toker,2017</span><span style="color:#000000;">）。例如，读者在句子末尾放慢速度，随后对下一个句子表现出更大的扫视，因为读者可能会将信息包装在一个句子中（</span><span style="color:#000000;">Rayner,2006</span><span style="color:#000000;">）。此外，当读者遇到句子之间的不一致时，注视和倒退会增加，当先行词距离较远或难以识别时，他们会更长时间地看代词、回指和名词短语。然而，与低阶过程相反，高阶过程与眼睛行为没有因果关系。它们主要在“某些东西不计算”时变得明显这对于熟练的读者和普通的、写得很好的文本来说并不常见。这就不清楚阅读理解研究中典型的高度控制的结果是否能在应用语境中推断出可理解性模型。</span></p> 
</blockquote> 
<h3>2.2 信息价值联系</h3> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>眼睛行为与兴趣密切相关</strong></span></u><span style="color:#000000;">。公开的视觉注意力被认为与兴趣共享，两者都寻求最大化信息价值。给定一个已知任务，观察者会将目光转移到能够最佳地减少他们对下一个适当行动不确定性的来源。</span><u><span style="color:#000000;"><strong>感兴趣的观察者</strong></span></u><u><span style="color:#000000;"><strong>——</strong></span></u><u><span style="color:#000000;"><strong>不受任务驱使</strong></span></u><u><span style="color:#000000;"><strong>——</strong></span></u><u><span style="color:#000000;"><strong>同样将注意力转移到他们看重的资源上，</strong></span></u><span style="color:#000000;">正如“喜欢更多，看起来更多”假设所恰当地捕捉到的那样。兴趣值与提供不确定性减少和</span><span style="color:#000000;">/</span><span style="color:#000000;">或知识获取潜力的来源相关。眼动控制的信息价值视角将兴趣与眼动联系起来。它以概率、信息论的术语投射眼球运动，优化某种形式的信息价值并解释了为什么眼球运动（例如与搜索结果的相关性相关）是相当可预测的。 这种类型的眼球运动控制取决于已知的上下文，观察者（以及类似地，实验者）可以估计他们可以参与的来源的预期信息价值，例如通过阅读摘要或浏览标题。</span></p> 
</blockquote> 
<blockquote> 
 <p><span style="color:#000000;">尽管信息价值观点表明兴趣和眼球运动之间存在强烈、正式和精细的联系，但兴趣的主观体验通常被认为是一种高阶结构，比单一注视转移跨越更长的时间。</span><u><span style="color:#FF0000;"><strong>在某种程度上，这种主观的兴趣体验也以阅读行为中可识别的模式为特征。</strong></span></u><span style="color:#000000;">读者在有趣的句子上花的时间比花在不那么有趣的句子上的时间，而兴趣往往会减少而不是增加话语层面的阅读。一旦感兴趣，读者可能会更有效地利用他们的心理资源并减少分心。这些发现表明，独特的眼部行为在兴趣体验典型的动机资源激活之前和之后。感兴趣的读者的独特模式可能是可以检测到的，例如焦点注意力和环境注意力之间的差异。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>有希望的例子是建模与兴趣相关的高阶情感结构</strong></span></u><span style="color:#000000;">。</span><span style="color:#000000;">Jaques</span><span style="color:#000000;">等人</span><span style="color:#000000;">(2014)</span><span style="color:#000000;">通过对智能辅导系统的各种界面元素之间的注视转换以及相当长的交互片段（</span><span style="color:#000000;">14</span><span style="color:#000000;">分钟）进行建模，预测学生的好奇心，准确率为</span><span style="color:#000000;">73.17%</span><span style="color:#000000;">。</span><span style="color:#000000;">Sims</span><span style="color:#000000;">和</span><span style="color:#000000;">Conati</span><span style="color:#000000;"> (2020)</span><span style="color:#000000;">使用经过眼动追踪功能训练的神经网络可视化预测用户的困惑，准确率高达</span><span style="color:#000000;">82%</span><span style="color:#000000;">。</span><span style="color:#000000;">Bixler</span><span style="color:#000000;">和</span><span style="color:#000000;">D‘Mello</span><span style="color:#000000;">(2016) </span><span style="color:#000000;">使用具有眼动追踪特征和文本特征（即难度）的各种分类器预测阅读时走神的准确率高达</span><span style="color:#000000;">72%</span><span style="color:#000000;">（机会水平为 </span><span style="color:#000000;">60%</span><span style="color:#000000;">）。任务、上下文和结构的差异使得不清楚这些结果是否在阅读过程中因兴趣而重复。</span></p> 
</blockquote> 
<h3>2.3 共有挑战</h3> 
<blockquote> 
 <p><span style="color:#000000;">如前文所述，</span><u><span style="color:#000000;"><strong>低阶过程通过眼</strong></span></u><u><span style="color:#000000;"><strong>-</strong></span></u><u><span style="color:#000000;"><strong>心联系的影响已得到很好的确立，而信息价值联系的解释正在加强</strong></span></u><span style="color:#000000;">。这些联系支持了这样一种理解，即在明确指定的任务和环境中，眼睛行为是相当可预测的</span><span style="color:#000000;">(Albrengues,2019;Anderson,2004;Chandra,2020;Luke,2013)</span><span style="color:#000000;">。这表明眼睛主要是由低阶过程驱动的；他们“不会在高阶认知过程的要求下做任何他们本来不会做的事情”</span><span style="color:#000000;">(Luke,2013</span><span style="color:#000000;">，</span><span style="color:#000000;">1241</span><span style="color:#000000;">页</span><span style="color:#000000;">)</span><span style="color:#000000;">。同时，认知</span><span style="color:#000000;">(</span><span style="color:#000000;">如理解</span><span style="color:#000000;">)</span><span style="color:#000000;">和情感</span><span style="color:#000000;">(</span><span style="color:#000000;">如兴趣</span><span style="color:#000000;">)</span><span style="color:#000000;">处理似乎都影响眼睛行为的特定特征和模式。然而，高阶过程与眼睛行为没有因果关系。这引发了共存的挑战</span><span style="color:#000000;">——</span><u><span style="color:#FF0000;"><strong>不同的高阶和低阶过程通过可能的交互和协同关系影响眼睛行为</strong></span></u><span style="color:#000000;">。</span><span style="color:#000000;">(</span><span style="color:#000000;">Goettker</span><span style="color:#000000;"> &amp; </span><span style="color:#000000;">Gegenfurtner</span><span style="color:#000000;">, 2021;Kaakinen, 2021)</span><span style="color:#000000;">。</span></p> 
</blockquote> 
<blockquote> 
 <p><span style="color:#000000;">正如Hess</span><span style="color:#000000;">和</span><span style="color:#000000;">Polt</span><span style="color:#000000;">(1960,1964)</span><span style="color:#000000;">所指出的那样，眼睛行为可以被解释为认知活动和兴趣。这种表面上的共存可以用认知加工动力学和兴趣体验之间的理论复杂关系来解释</span><span style="color:#000000;">(Graf &amp; Landwehr, 2015)</span><span style="color:#000000;">。为了引起兴趣，文本必须包含一定程度的新颖性和复杂性，但仍能让读者理解</span><span style="color:#000000;">(O‘Brien &amp; McKay, 2016;</span> <span style="color:#000000;">van der </span><span style="color:#000000;">Sluis</span><span style="color:#000000;"> et al.,2014)</span><span style="color:#000000;">。因此，感兴趣的模型需要将这些独特的处理模式从具有可理解性的处理动态中分离出来。</span></p> 
</blockquote> 
<blockquote> 
 <p><span style="color:#000000;">Hess和</span><span style="color:#000000;">Polt’s</span><span style="color:#000000;">(1960</span><span style="color:#000000;">、</span><span style="color:#000000;">1964)</span><span style="color:#000000;">最初的观点强调了眼睛在揭示读者的可理解性和兴趣方面的潜力。然而，共存对使用眼动追踪建模高阶结构提出了明显的挑战。</span><u><span style="color:#FF0000;"><strong>我们将这一挑战分解如下</strong></span></u><span style="color:#000000;">:</span></p> 
 <p><span style="color:#000000;">1. 对于常规的、非实验性的</span><span style="color:#000000;">(</span><span style="color:#000000;">新闻</span><span style="color:#000000;">)</span><span style="color:#000000;">内容，在话语层面上的检测可理解性差异的能力如何</span><span style="color:#000000;">?</span></p> 
 <p><span style="color:#000000;">2. 有没有可能揭示阅读过程中的兴趣体验</span><span style="color:#000000;">?</span></p> 
 <p><span style="color:#000000;">3. 我们能否理清对眼睛行为的不同解释</span><span style="color:#000000;">?</span></p> 
 <p><span style="color:#000000;">在阅读过程中，需要解决这三个问题，以使眼球追踪诱导的个人反馈对可理解性和兴趣都有帮助。此外，阅读是一种习得行为，因此在眼睛行为方面显示出巨大的人际差异(Carter &amp; Luke, 2018;Payne et al.,2020)。类似于我们的虹膜和视网膜，我们的眼睛行为也是个性化的，可能具有生物特征(van den Broek</span><span style="color:#000000;">, 2010)</span><span style="color:#000000;">，需要考虑这些特征。下一节将介绍我们用来应对这些挑战的研究方法。</span></p> 
</blockquote> 
<h2>3.方法</h2> 
<blockquote> 
 <p><span style="color:#000000;">van der Sluis</span> <span style="color:#000000;">等人报告了对主观数据的初步分析。目前的研究报告了眼动追踪揭示可理解性和兴趣的潜力。</span></p> 
</blockquote> 
<h3>3.1 参与者与材料</h3> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>30</strong></span></u><u><span style="color:#FF0000;"><strong>名志愿者</strong></span></u><span style="color:#000000;">(</span><span style="color:#000000;">男</span><span style="color:#000000;">22</span><span style="color:#000000;">名，女</span><span style="color:#000000;">8</span><span style="color:#000000;">名</span><span style="color:#000000;">)</span><span style="color:#000000;">参与，平均年龄</span><span style="color:#000000;">28.60</span><span style="color:#000000;">岁</span><span style="color:#000000;">(SD = 6.06)</span><span style="color:#000000;">。他们的母语都不是英语。但是，所有学生都认为自己的阅读能力较高</span><span style="color:#000000;">(M = 4.63; Sd = .62; range 1-5)</span><span style="color:#000000;">，并且都在攻读或已经获得大学学位</span><span style="color:#000000;">(university degree)</span><span style="color:#000000;">。</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>来自</strong></span></u><u><span style="color:#FF0000;"><strong>《</strong></span></u><u><span style="color:#FF0000;"><strong>卫报</strong></span></u><u><span style="color:#FF0000;"><strong>》</strong></span></u><u><span style="color:#FF0000;"><strong>的</strong></span></u><u><span style="color:#FF0000;"><strong>18</strong></span></u><u><span style="color:#FF0000;"><strong>篇文章</strong></span></u><span style="color:#000000;">从</span><span style="color:#000000;">14,856</span><span style="color:#000000;">篇文章中抽样，分为低、中、高三个复杂级别。文本复杂度使用</span><span style="color:#000000;">van der </span><span style="color:#000000;">Sluis</span><span style="color:#000000;">等人</span><span style="color:#000000;">(2014)</span><span style="color:#000000;">指定的计算分析进行估计。该分析包括七个文本特征，包括词频等常见特征和字符和词级熵等新颖特征。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">所有文章都在1200</span><span style="color:#000000;">个字符后被截断。加了三个点表示故事正常继续。所有的版面都从文章中剥离，只留下标题和文本内容。布局并不是专门为眼球追踪设计的。相反，它的目的是模仿</span><span style="color:#000000;">(</span><span style="color:#000000;">自助</span><span style="color:#000000;">)</span><span style="color:#000000;">设计在互联网上常见。图</span><span style="color:#000000;">1</span><span style="color:#000000;">显示了一个示例。</span></p> 
</blockquote> 
<p class="img-center"><img alt="" height="325" src="https://images2.imgbox.com/22/6d/nDMHSYwn_o.png" width="472"></p> 
<h3>3.2 工具</h3> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>在阅读完每篇文章后，研究人员进行了一份问卷调查</strong></span></u><span style="color:#000000;">，以衡量以下评价</span><span style="color:#000000;">:</span></p> 
 <p></p> 
 <p><span style="color:#000000;">根据相关研究，</span><u><span style="color:#FF0000;"><strong>可理解性</strong></span></u><span style="color:#000000;">通过三个</span><span style="color:#000000;">7</span><span style="color:#000000;">点差异来衡量：可理解</span><span style="color:#000000;">-</span><span style="color:#000000;">不可理解，连贯</span><span style="color:#000000;">-</span><span style="color:#000000;">不连贯，易于理解</span><span style="color:#000000;">-</span><span style="color:#000000;">难以理解</span><span style="color:#000000;">(</span><span style="color:#000000;">较高的</span><span style="color:#000000;">Cronbach α=0.893</span><span style="color:#000000;">，</span><span style="color:#000000;">N=540)</span><span style="color:#000000;">。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">对</span><u><span style="color:#FF0000;"><strong>兴趣</strong></span></u><span style="color:#000000;">的测量使用了兴趣研究中常用的三个项目</span><span style="color:#000000;">(Silvia, 2005,2008a, 2010)</span><span style="color:#000000;">。两个</span><span style="color:#000000;">7</span><span style="color:#000000;">分的差异</span><span style="color:#000000;">:</span><span style="color:#000000;">有趣</span><span style="color:#000000;">-</span><span style="color:#000000;">无趣和无聊</span><span style="color:#000000;">-</span><span style="color:#000000;">令人兴奋，以及一个</span><span style="color:#000000;">7</span><span style="color:#000000;">点李克特量表要求参与者同意“我有兴趣阅读更多本文”这一说法。这三个项目形成了一个一致的量表。</span><span style="color:#000000;">(</span><span style="color:#000000;">优秀的</span><span style="color:#000000;">Cronbach‘s alpha .921</span><span style="color:#000000;">，</span><span style="color:#000000;">N = 540)</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>新颖性</strong></span></u><span style="color:#000000;">和</span><u><span style="color:#FF0000;"><strong>复杂性</strong></span></u><span style="color:#000000;">也被额外测量，但不会在与眼球追踪的关系中进行分析。这些测量包括以下</span><span style="color:#000000;">7</span><span style="color:#000000;">点语义差异</span><span style="color:#000000;">:</span><span style="color:#000000;">复杂</span><span style="color:#000000;">-</span><span style="color:#000000;">简单</span><span style="color:#000000;">(Silvia, 2008a)</span><span style="color:#000000;">，熟悉</span><span style="color:#000000;">-</span><span style="color:#000000;">不熟悉</span><span style="color:#000000;">(Silvia, 2008a)</span><span style="color:#000000;">，易读</span><span style="color:#000000;">-</span><span style="color:#000000;">难读</span><span style="color:#000000;">(Song &amp; Schwarz, 2008)</span><span style="color:#000000;">。</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>这些量表通常用于文本刺激和艺术品兴趣评价结构的实验</strong></span></u><span style="color:#000000;">。结构方程模型证实，每个量表涵盖了一个独特的因素，每个量表都解释了兴趣反应中的很大一部分方差</span><span style="color:#000000;">(van der </span><span style="color:#000000;">Sluis</span><span style="color:#000000;"> et al.</span><span style="color:#000000;">， </span><span style="color:#000000;">2014)</span><span style="color:#000000;">。这些量表进一步显示出对理论相关的量表和操作的反应，包括应对潜力和个体差异。</span></p> 
</blockquote> 
<h3>3.3 眼动仪与分析</h3> 
<blockquote> 
 <p><span style="color:#000000;">在这里，我们描述了眼动采集，如图 2 </span><span style="color:#000000;">所示。我们使用 </span><u><span style="color:#FF0000;"><strong>60Hz</strong></span></u><u><span style="color:#FF0000;"><strong>的 </strong></span></u><u><span style="color:#FF0000;"><strong>SMI RED60 </strong></span></u><u><span style="color:#FF0000;"><strong>双目眼动仪</strong></span></u><span style="color:#000000;">和 </span><u><span style="color:#FF0000;"><strong>BeGaze</strong></span></u><u><span style="color:#FF0000;"><strong> 3.0.181 </strong></span></u><u><span style="color:#FF0000;"><strong>软件</strong></span></u><span style="color:#000000;">来跟踪参与者在</span><u><span style="color:#FF0000;"><strong>标准</strong></span></u><u><span style="color:#FF0000;"><strong>2200TFT</strong></span></u><u><span style="color:#FF0000;"><strong>显示器</strong></span></u><span style="color:#000000;">（分辨率：</span><span style="color:#000000;">1280×1024</span><span style="color:#000000;">）上的注视。由于软件故障，一名参与者的眼球追踪数据丢失了。</span></p> 
 <p></p> 
 <p style="text-align:justify;"><span style="color:#000000;">即将推出的特征（和参数）集包含阅读研究中经常使用的特征，辅以扫视和倒退</span><span style="color:#000000;">(regressions)</span><span style="color:#000000;">速度以捕捉感兴趣的读者通常看到的阅读速度差异：</span><u><span style="color:#FF0000;"><strong>注视</strong></span></u><span style="color:#000000;">（计数、持续时间）：使用基于色散的算法检测，预先指定的最短持续时间为 </span><span style="color:#000000;">80 </span><span style="color:#000000;">毫秒。</span><u><span style="color:#FF0000;"><strong>扫视</strong></span></u><span style="color:#000000;">（计数、振幅、持续时间、峰值速度）：两个后续注视之间的联系。眼动仪将眨眼记录为具有 </span><span style="color:#000000;">0,0px</span><span style="color:#000000;">位置的扫视，这被排除在进一步分析之外。</span><u><span style="color:#FF0000;"><strong>倒退</strong></span></u><span style="color:#000000;">(</span><span style="color:#000000;">计数，振幅，持续时间，峰值速度</span><span style="color:#000000;">):</span><span style="color:#000000;">以最小</span><span style="color:#000000;">20px</span><span style="color:#000000;">向北</span><span style="color:#000000;">(y</span><span style="color:#000000;">轴</span><span style="color:#000000;">)</span><span style="color:#000000;">和水平</span><span style="color:#000000;">(x</span><span style="color:#000000;">轴</span><span style="color:#000000;">)</span><span style="color:#000000;">方向扫视。这与屏幕上单词“</span><span style="color:#000000;">the”</span><span style="color:#000000;">的大小大致重叠，并排除了常规的、渐进的扫视以及可能纠正眼睛位置位移的微扫视。</span><u><span style="color:#FF0000;"><strong>系数</strong></span></u><u><span style="color:#FF0000;"><strong>K</strong></span></u><span style="color:#000000;">：</span><span style="color:#000000;">其中 </span><span style="color:#000000;">ai-1 </span><span style="color:#000000;">是扫视幅度，</span><span style="color:#000000;">di </span><span style="color:#000000;">是第 </span><span style="color:#000000;">i</span> <span style="color:#000000;">个注视持续时间，</span><span style="color:#000000;">μd</span><span style="color:#000000;">、</span><span style="color:#000000;">σd</span><span style="color:#000000;">、</span><span style="color:#000000;">μa</span> <span style="color:#000000;">和 </span><span style="color:#000000;">σa</span> <span style="color:#000000;">是参与者注视持续时间和扫视幅度的平均值和标准差（参见第</span><span style="color:#000000;">15</span><span style="color:#000000;">页的标准化）。这衡量了焦点注意力（表现为较长时间的注视，表明视觉处理的中心模式）与环境注意力（以较长的眼跳指示探索性处理模式为特征）之间的比率（</span><span style="color:#000000;">Krejtz</span><span style="color:#000000;">，</span><span style="color:#000000;">2016</span><span style="color:#000000;">）。</span><u><span style="color:#FF0000;"><strong>瞳孔大小</strong></span></u><span style="color:#000000;">(</span><span style="color:#000000;">以像素为单位</span><span style="color:#000000;">)</span><span style="color:#000000;">：注视时两眼归一化</span><span style="color:#000000;">(</span><span style="color:#000000;">见公式</span><span style="color:#000000;">2)</span><span style="color:#000000;">的平均瞳孔直径。由于不同人群的瞳孔大小基线水平不同，非标准化瞳孔大小不包括在内。</span><u><span style="color:#FF0000;"><strong>阅读时间</strong></span></u><span style="color:#000000;">(</span><span style="color:#000000;">秒</span><span style="color:#000000;">)</span><span style="color:#000000;">：每篇文章从第一次阅读到最后一次阅读的时间。</span></p> 
</blockquote> 
<p class="img-center"><img alt="" height="237" src="https://images2.imgbox.com/cf/a1/DmjDbvqQ_o.png" width="1121"></p> 
<p class="img-center"><img alt="" height="82" src="https://images2.imgbox.com/dc/a4/V15BKZ5a_o.png" width="463"></p> 
<blockquote> 
 <p><span style="color:#000000;">对于每个特征，计算四分位间距(</span><span style="color:#000000;">iqr</span><span style="color:#000000;">)</span><span style="color:#000000;">。位于第二个四分位数以下或第三个四分位数以上</span><span style="color:#000000;">4</span><span style="color:#000000;">倍</span><span style="color:#000000;">iqr</span><span style="color:#000000;">限制之外的数据点被确定为</span><u><span style="color:#FF0000;"><strong>异常值并被删除</strong></span></u><span style="color:#000000;">。这是一个相当宽松的限制</span><span style="color:#000000;">(</span><span style="color:#000000;">例如，几秒钟的扫视</span><span style="color:#000000;">)</span><span style="color:#000000;">，并允许相当扭曲的分布</span><span style="color:#000000;">(</span><span style="color:#000000;">例如，扫视持续时间</span><span style="color:#000000;">)</span><span style="color:#000000;">。结果共有</span><span style="color:#000000;">285,190</span><span style="color:#000000;">次注视，</span><span style="color:#000000;">259,286</span><span style="color:#000000;">次扫视，</span><span style="color:#000000;">34,605</span><span style="color:#000000;">次倒退，</span><span style="color:#000000;">196,613</span><span style="color:#000000;">个</span><span style="color:#000000;">K</span><span style="color:#000000;">样本，分别删除了</span><span style="color:#000000;">0.50%,15.35%,6.80%</span><span style="color:#000000;">和</span><span style="color:#000000;">1.59%</span><span style="color:#000000;">。</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>不在感兴趣区域（即文章标题或内容）中的眼睛事件已被删除</strong></span></u><u><span style="color:#FF0000;"><strong>。</strong></span></u><span style="color:#000000;">得到</span><span style="color:#000000;">168,914 </span><span style="color:#000000;">次注视、</span><span style="color:#000000;">154,560 </span><span style="color:#000000;">次眼跳、</span><span style="color:#000000;">18,450 </span><span style="color:#000000;">次回归和 </span><span style="color:#000000;">88,723 K </span><span style="color:#000000;">个样本。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">眼事件数据在每次阅读时进行总结。 随后，对于每个特征，计算统计参数计数、均值、方差、偏度和峰度以表示信号的分布。 统计矩方差、偏度和峰度被包括在内，以捕捉话语水平和局部对阅读模式的影响（第2 </span><span style="color:#000000;">节）。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">为了解决眼行为的内部和个人之间的差异，</span><u><span style="color:#FF0000;"><strong>所有数据被标准化</strong></span></u><span style="color:#000000;">如下：</span></p> 
 <p><span style="color:#000000;">其中 μ </span><span style="color:#000000;">是原始特征序列 </span><span style="color:#000000;">f(t) </span><span style="color:#000000;">中参与者的个人基线。标准化执行两次，</span><span style="color:#000000;">μ</span><span style="color:#000000;">分别为实验期间</span><span style="color:#000000;">(</span><span style="color:#000000;">用</span><span style="color:#000000;">a</span><span style="color:#000000;">标注</span><span style="color:#000000;">)</span><span style="color:#000000;">和各自实验块</span><span style="color:#000000;">(</span><span style="color:#000000;">用</span><span style="color:#000000;">b</span><span style="color:#000000;">标注</span><span style="color:#000000;">)</span><span style="color:#000000;">的参与者中位数。系数</span><span style="color:#000000;">K</span><span style="color:#000000;">是一个例外，因为它已经被归一化了（见公式 </span><span style="color:#000000;">1</span><span style="color:#000000;">）。这种归一化步骤是心理生理学和眼球测量研究中的标准步骤，对于绝对水平比较来说既合适又可靠 </span><span style="color:#000000;">(van den </span><span style="color:#000000;">Broek</span><span style="color:#000000;">, 2011)</span><span style="color:#000000;">。由于这些规范化中的每一个都可能（不）涵盖不同的可变性来源，因此它们将各自包含在后续的特征选择和统计建模步骤中。 结果数据集总共包含 </span><span style="color:#000000;">130 </span><span style="color:#000000;">个变量和 </span><span style="color:#000000;">522 </span><span style="color:#000000;">个观察值。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">为了确保进一步处理，</span><u><span style="color:#FF0000;"><strong>对缺失值、变量内方差和变量间相关性进行了检查</strong></span></u><span style="color:#000000;">。总共删除了五个包含缺失值的观察值，没有一个变量的方差接近零，五个变量高度相关 </span><span style="color:#000000;">(r &gt; .95)</span><span style="color:#000000;">，随后被删除：扫视计数、</span><span style="color:#000000;">K </span><span style="color:#000000;">偏度和 </span><span style="color:#000000;">K </span><span style="color:#000000;">峰度。 最终数据集包含 </span><span style="color:#000000;">517 </span><span style="color:#000000;">个阅读片段的 </span><span style="color:#000000;">127 </span><span style="color:#000000;">个变量。</span></p> 
</blockquote> 
<h3>3.4 统计分析</h3> 
<blockquote> 
 <p><span style="color:#000000;">统计分析在R</span><span style="color:#000000;">语言中使用软件包</span><span style="color:#000000;">outliers, caret, </span><span style="color:#000000;">Hmisc</span><span style="color:#000000;">, MASS, ggplot2, </span><span style="color:#000000;">和 </span><span style="color:#000000;">ggextra</span><span style="color:#000000;">进行。</span><u><span style="color:#FF0000;"><strong>回归分析分两步进行</strong></span></u><span style="color:#000000;">。首先，对于可理解性和兴趣，在会话数据上训练了一个线性回归模型（</span><span style="color:#000000;">LRM</span><span style="color:#000000;">），并逐步减少变量。回归模型的解释性能是用</span><span style="color:#000000;">R2</span><span style="color:#000000;">来评估的。</span><u><span style="color:#FF0000;"><strong>图</strong></span></u><u><span style="color:#FF0000;"><strong>3</strong></span></u><span style="color:#000000;">显示了所产生的预测器组（减少变量后）之间的重叠情况。其次，在</span><u><span style="color:#000000;"><strong>留一交叉验证</strong></span></u><span style="color:#000000;">的情况下，利用线性模型中减少的预测变量集来预测未见过的观察结果。对于</span><span style="color:#000000;">N</span><span style="color:#000000;">个总观测值中的每个观测值，在</span><span style="color:#000000;">N-1</span><span style="color:#000000;">个观测值上训练</span><span style="color:#000000;">LRM</span><span style="color:#000000;">（没有减少变量），并在一个观测值上测试。因此，预测器的集合被认为是一个最佳集合，而系数在每次评估时都被重新训练。预测性能是用</span><span style="color:#000000;">min-max</span><span style="color:#000000;">归一化均方根误差（</span><span style="color:#000000;">nRMSE</span><span style="color:#000000;">）和</span><span style="color:#000000;">Pearson</span><span style="color:#000000;">的相关</span><span style="color:#000000;">r</span><span style="color:#000000;">来评估的（见图</span><span style="color:#000000;">4</span><span style="color:#000000;">）。图</span><span style="color:#000000;">4</span><span style="color:#000000;">显示了密度图和带有</span><span style="color:#000000;">95%</span><span style="color:#000000;">置信区间的趋势线，是用</span><span style="color:#000000;">R</span><span style="color:#000000;">的</span><span style="color:#000000;">loess</span><span style="color:#000000;">和</span><span style="color:#000000;">predict.lm</span><span style="color:#000000;">方法进行局部加权平滑计算的。</span></p> 
</blockquote> 
<p class="img-center"><img alt="" height="252" src="https://images2.imgbox.com/46/64/XTUIV1I0_o.png" width="349"></p> 
<p class="img-center"><img alt="" height="307" src="https://images2.imgbox.com/2a/5c/OmEufC7p_o.png" width="573"></p> 
<h2>4.结果</h2> 
<h3>4.1 描述性统计</h3> 
<blockquote> 
 <p><span style="color:#000000;">参与者将这18</span><span style="color:#000000;">篇文章评价为易于理解（</span><span style="color:#000000;">M=5.35,SD=1.23</span><span style="color:#000000;">）和有趣（</span><span style="color:#000000;">M=4.66</span><span style="color:#000000;">，</span><span style="color:#000000;">SD=1.43</span><span style="color:#000000;">）（等级：</span><span style="color:#000000;">1-7</span><span style="color:#000000;">）。 可理解性和兴趣评估共享</span><span style="color:#000000;">21.69%</span><span style="color:#000000;">的方差。</span><u><span style="color:#FF0000;"><strong>表</strong></span></u><u><span style="color:#FF0000;"><strong>1</strong></span></u><span style="color:#000000;">给出了眼动追踪特征及其参数的平均值。表</span><span style="color:#000000;">1</span><span style="color:#000000;">中的两个值与典型值不同（参见第 </span><span style="color:#000000;">2 </span><span style="color:#000000;">节）。</span><u><span style="color:#FF0000;"><strong>平均注视长度</strong></span></u><span style="color:#000000;">为</span><span style="color:#000000;">367.35 </span><span style="color:#000000;">毫秒，</span><span style="color:#000000;">SD = 112.27)</span><span style="color:#000000;">，其中典型的注视时间为 </span><span style="color:#000000;">200–250 </span><span style="color:#000000;">毫秒。 </span><u><span style="color:#FF0000;"><strong>扫视持续时间</strong></span></u><span style="color:#000000;">长于平均 </span><span style="color:#000000;">71.08 </span><span style="color:#000000;">毫秒（</span><span style="color:#000000;">SD = 32.45</span><span style="color:#000000;">）的平均扫视持续时间，但是这可以预期，因为扫视规范排除了微扫视（参见第 </span><span style="color:#000000;">3.4 </span><span style="color:#000000;">节）。</span></p> 
</blockquote> 
<p class="img-center"><img alt="" height="472" src="https://images2.imgbox.com/c7/25/2wbbPJiu_o.png" width="875"></p> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>表</strong></span></u><u><span style="color:#FF0000;"><strong>2</strong></span></u><span style="color:#000000;">给出了眼球追踪变量与可理解性和兴趣的显著相关关系。相关分析显示，归一化前后</span><u><span style="color:#FF0000;"><strong>阅读时间</strong></span></u><span style="color:#000000;">均与可理解性和兴趣相关</span><span style="color:#000000;">(</span><span style="color:#000000;">a,b</span><span style="color:#000000;">):</span><span style="color:#000000;">容易理解的文本需要更少的阅读时间，感兴趣的读者阅读速度更快。这也反映在注视、扫视和倒退的计数上。阅读时间越少，这些症状就会显著减少。</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>平均瞳孔大小</strong></span></u><span style="color:#000000;">与可理解性相关，表明付出的努力较少，而其方差随着可理解性和兴趣的增加而减小。对于</span><u><span style="color:#FF0000;"><strong>归一化注视时间</strong></span></u><span style="color:#000000;">，其方差随着可理解性和兴趣度的增加而降低。这意味着一种更流畅和一致的阅读行为，具有可理解性和趣味性。</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>对于扫视</strong></span></u><span style="color:#000000;">，它们的振幅、持续时间和速度有几个显著的关系。这些关系的总体情况是，有了可理解性，扫视更短，花的时间更少，峰值速度更低。在兴趣方面，扫视除了峰值速度以外也表现出类似的关系。此外，感兴趣的读者在他们的扫视持续时间的分布中表现出较小的方差和较高的偏态。</span><u><span style="color:#FF0000;"><strong>倒退</strong></span></u><span style="color:#000000;">的振幅随可理解性而减小，峰值速度的偏度和峰度随可理解性而增大，表明可理解性和兴趣之间存在显著的回归分布。除了扫视和倒退，</span><u><span style="color:#FF0000;"><strong>归一化系数</strong></span></u><u><span style="color:#FF0000;"><strong>K</strong></span></u><span style="color:#000000;">方差随兴趣的增加而减小，这表明视觉处理的焦点和环境模式之间的差异较小。</span></p> 
</blockquote> 
<p class="img-center"><img alt="" height="425" src="https://images2.imgbox.com/0d/45/uHVFgNKQ_o.png" width="971"></p> 
<h3>4.2 线性回归</h3> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>可理解性的</strong></span></u><u><span style="color:#FF0000;"><strong>LRM</strong></span></u><span style="color:#000000;">由</span><span style="color:#000000;">60</span><span style="color:#000000;">个参数组成，</span><span style="color:#000000;">R</span><span style="color:#000000;">2</span><span style="color:#000000;">=49.93, F(59,454) =7.67, p &lt; .001</span><span style="color:#000000;">。</span><u><span style="color:#FF0000;"><strong>感兴趣的</strong></span></u><u><span style="color:#FF0000;"><strong>LRM</strong></span></u><span style="color:#000000;">由</span><span style="color:#000000;">69</span><span style="color:#000000;">个参数组成，</span><span style="color:#000000;">R</span><span style="color:#000000;">2</span><span style="color:#000000;">=30.41, F(68, 445) = 2.86, p &lt; .001</span><span style="color:#000000;">。使用逐步变量约简来降低</span><span style="color:#000000;">LRM</span><span style="color:#000000;">的维数。</span></p> 
 <p></p> 
 <p><u><span style="color:#FF0000;"><strong>图 </strong></span></u><u><span style="color:#FF0000;"><strong>3 </strong></span></u><span style="color:#000000;">说明了两个模型的独特和共享预测变量的数量，包括相关方向是否共享。 可理解性模型包含 </span><span style="color:#000000;">14 </span><span style="color:#000000;">个独特的预测变量。 兴趣模型包含 </span><span style="color:#000000;">23 </span><span style="color:#000000;">个独特的预测变量。 模型共有 </span><span style="color:#000000;">45 </span><span style="color:#000000;">个特征，其中 </span><span style="color:#000000;">38 </span><span style="color:#000000;">个特征相同，</span><span style="color:#000000;">7 </span><span style="color:#000000;">个特征相反。 图 </span><span style="color:#000000;">3 </span><span style="color:#000000;">还显示</span><span style="background-color:#FF0000;"><span style="color:#000000;">注视</span></span><span style="color:#000000;">、</span><span style="background-color:#008000;"><span style="color:#000000;">扫视</span></span><span style="color:#000000;">和</span><span style="background-color:#800080;"><span style="color:#000000;">倒退</span></span><span style="color:#000000;">预测因子存在于两个模型及其重叠中。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">值得注意的是，图3</span><span style="color:#000000;">中的</span><span style="background-color:#0000FF;"><span style="color:#000000;">阅读时间</span></span><span style="color:#000000;">、</span><span style="background-color:#FFFF00;"><span style="color:#000000;">瞳孔大小</span></span><span style="color:#000000;">和</span><span style="background-color:#C0C0C0;"><span style="color:#000000;">系数</span></span><span style="background-color:#C0C0C0;"><span style="color:#000000;">k</span></span><span style="color:#000000;">的影响，阅读时间对两个模型都有强烈但相反的影响，抵消了阅读时间与兴趣和可理解性之间的一贯负相关关系</span><span style="color:#000000;">(</span><span style="color:#000000;">见表</span><span style="color:#000000;">1)</span><span style="color:#000000;">。</span></p> 
 <p></p> 
 <p><span style="color:#000000;">瞳孔大小有六分之四的特征可以预测兴趣或反相关，这与瞳孔大小和认知努力之间的典型关系形成对比。最后，系数</span><span style="color:#000000;">K</span><span style="color:#000000;">主要与兴趣模型有关，</span><span style="color:#000000;">6</span><span style="color:#000000;">个预测因子中有</span><span style="color:#000000;">4</span><span style="color:#000000;">个是它独有的。这些观察表明，当考虑与其他包括的预测因素的相互依赖时，这三个特征可以帮助区分可理解性和兴趣。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>为了评估两种</strong></span></u><u><span style="color:#FF0000;"><strong>LRM</strong></span></u><u><span style="color:#FF0000;"><strong>的预测性能，我们应用了留一交叉验证</strong></span></u><span style="color:#000000;">。</span><span style="color:#000000;">LRM</span><span style="color:#000000;">预测可理解性和兴趣评级的</span><span style="color:#000000;">r = .608</span><span style="color:#000000;">和</span><span style="color:#000000;">r = .329</span><span style="color:#000000;">，归一化误差分别为</span><span style="color:#000000;">nRMSE=.164</span><span style="color:#000000;">和</span><span style="color:#000000;">nRMSE=.232</span><span style="color:#000000;">。图</span><span style="color:#000000;">4</span><span style="color:#000000;">说明了这种预测性能。它将模型预测与参与者的实际评估联系起来，包括预测的</span><span style="color:#000000;">95%</span><span style="color:#000000;">置信区间。此外，该图还显示了实际值和预测值的分布情况。</span></p> 
</blockquote> 
<blockquote> 
 <p><span style="color:#000000;">图4a</span><span style="color:#000000;">显示了对预测性能的可能损害。</span><u><span style="color:#FF0000;"><strong>由于缺乏训练数据</strong></span></u><span style="color:#000000;">，可理解性模型在可理解性较低的情况下可靠性较差。在中高可理解度下，预测值与实际值之间的关系接近于一条最优对角线，且置信区间较小。图</span><span style="color:#000000;">4b</span><span style="color:#000000;">显示了兴趣的低预测性能。预测兴趣和参与者评估兴趣之间的数据分布差异进一步表明了这一点。</span></p> 
</blockquote> 
<h2>5.讨论</h2> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>我们阐明了一个经典的、超过半个世纪的眼行为解释的分歧</strong></span></u><span style="color:#000000;">：处理</span><span style="color:#000000;">(Hess &amp; </span><span style="color:#000000;">Polt</span><span style="color:#000000;">, 1964)</span><span style="color:#000000;">和价值</span><span style="color:#000000;">(Hess &amp; </span><span style="color:#000000;">Polt</span><span style="color:#000000;">, 1960)</span><span style="color:#000000;">。眼球追踪数据能够描述认知过程的各个方面，并在较小程度上描述兴趣价值。</span><span style="color:#000000;">LRM</span><span style="color:#000000;">对可理解性和兴趣性分别解释了</span><span style="color:#000000;">49.93%</span><span style="color:#000000;">和</span><span style="color:#000000;">30.41%</span><span style="color:#000000;">的方差</span><span style="color:#000000;">(p &lt; .001)</span><span style="color:#000000;">，预测性能分别为</span><span style="color:#000000;">r=.608</span><span style="color:#000000;">和</span><span style="color:#000000;">r=.329</span><span style="color:#000000;">。这些发现证实了眼睛提供反馈的潜力，超过了传统的准确性指标。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>本研究是第一个对眼球追踪研究的可理解性和兴趣进行基准测试和比较的研究</strong></span></u><span style="color:#000000;">。其他研究确实评估了眼球追踪预测相关结构的能力，例如</span><span style="color:#000000;">64-86%</span><span style="color:#000000;">的相关性判断</span><span style="color:#000000;">(Gwizdka,2017;Liu,014)</span><span style="color:#000000;">，阅读时走神</span><span style="color:#000000;">72%(</span><span style="color:#000000;">高于概率水平</span><span style="color:#000000;">12%)(Bixler, 2016)</span><span style="color:#000000;">，好奇</span><span style="color:#000000;">73% (Jaques,2014)</span><span style="color:#000000;">，困惑</span><span style="color:#000000;">82% (Sims, 2020)</span><span style="color:#000000;">。然而，与本研究中所采用的方法有显著差异。这些研究评估了二元分类的准确性，而不是连续回归问题。</span><span style="color:#000000;">7</span><span style="color:#000000;">分量表的基线机会水平</span><span style="color:#000000;">(14.29%)</span><span style="color:#000000;">远低于二元量表</span><span style="color:#000000;">(50.00%)(van den </span><span style="color:#000000;">Broek</span><span style="color:#000000;"> et al.,2013)</span><span style="color:#000000;">。此外，在记录更长的时间框架时，通常会添加有关文本和用户界面交互的辅助特征作为预测因素。通过专注于短时间的阅读，我们解决了一个非常困难的问题。此外，通过仅使用基于事件的眼球跟踪特征和直接的回归技术，目前的工作将重点从机器学习技术转移到特征的价值和可能性及其在预测结构方面的解释上</span><span style="color:#000000;">(Rudin, 2019)</span><span style="color:#000000;">。总的来说，在</span><span style="color:#000000;">14.29%</span><span style="color:#000000;">的基线上探索长期存在的差异，</span><span style="color:#000000;">49.93%(</span><span style="color:#000000;">可理解性</span><span style="color:#000000;">)</span><span style="color:#000000;">和</span><span style="color:#000000;">30.41%(</span><span style="color:#000000;">兴趣</span><span style="color:#000000;">)</span><span style="color:#000000;">的解释方差可以被认为是一个有前途的表现。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>研究结果支持了评价的可理解性可以通过眼睛来检测的观点</strong></span></u><span style="color:#000000;">。所使用的文本段落均为新闻文章，内容较为易懂</span><span style="color:#000000;">(M=5.35, SD=1.43)</span><span style="color:#000000;">。这表明，可理解性的微小差异已经可以从眼睛中察觉出来。预测的可理解性与评价的可理解性之间的小置信区间和线性拟合进一步支持了这一点</span><span style="color:#000000;">(</span><span style="color:#000000;">见图</span><span style="color:#000000;">4a)</span><span style="color:#000000;">。这一结果与之前的研究结果不同，因为通常单词级的困难在语篇级平均，而语篇级的困难只有在遇到大的、通常是人为的障碍时才会变得可见 </span><span style="color:#000000;">(Rayner,2006)</span><span style="color:#000000;">。结果表明，与理解相关的高阶过程，尽管与眼睛行为没有因果关系，但仍然可以从眼睛中检测到。然而，我们的模型是否适用于其他类型的文本，或者有效的模型是否只能用于特定类型的文本，这仍然是一个问题。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>与</strong></span></u><u><span style="color:#FF0000;"><strong>Hess</strong></span></u><u><span style="color:#FF0000;"><strong>和</strong></span></u><u><span style="color:#FF0000;"><strong>Polt</strong></span></u><u><span style="color:#FF0000;"><strong>（</strong></span></u><u><span style="color:#FF0000;"><strong>19601964</strong></span></u><u><span style="color:#FF0000;"><strong>）的研究结果一致，眼睛不仅显示了认知活动的各个方面，还显示了兴趣</strong></span></u><span style="color:#000000;">。我们的结果特别证实了最初的发现，即瞳孔大小的变化在可理解性和兴趣方面具有显著的分布。然而，兴趣模型的预测性能也突出了从眼睛检测兴趣的挑战。使用眼动追踪数据，似乎很难区分可理解性和兴趣。可理解性和兴趣模型共享大多数预测因子（</span><span style="color:#000000;">45</span><span style="color:#000000;">个变量）。对这种重叠的一种可能的解释来自于可理解性作为关键利益评估的理论重要性（</span><span style="color:#000000;">Silvia,2006</span><span style="color:#000000;">）。特别是，预测因素之间的重叠指出了复杂性的干预作用：文本复杂性可以通过刺激读者增加兴趣，同时通过降低可理解性降低兴趣。这表明独特的处理动态</span><span style="color:#000000;">——</span><span style="color:#000000;">复杂但可理解</span><span style="color:#000000;">——</span><span style="color:#000000;">可能是兴趣体验的基础（</span><span style="color:#000000;">Graf &amp; Landwehr,2015;Silvia,2006</span><span style="color:#000000;">），并解释了可理解性和兴趣之间预测变量的重叠。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>预测因子之间重叠的另一种解释可能来自心理测量和眼部测量的限制</strong></span></u><span style="color:#000000;">。从心理测量学的角度来看，用户的内省判断总体上受到积极情感和自上而下的加工预期的影响。这自然地限制了可理解性和兴趣度量的不同有效性。</span><span style="color:#000000;">21.69%</span><span style="color:#000000;">的共享方差证实了某种程度的重叠，这也是理论上预期的，但尽管如此，这两个结构可以在主观上进行区分。从眼部测量的角度来看，眼睛并不像“喜欢得越多，看得越多”的假设那样容易表现出兴趣。我们所证实的阅读时间和兴趣之间的负相关反而表明，有兴趣的读者更有效地利用他们的心理资源</span><span style="color:#000000;">——</span><span style="color:#000000;">可能对他们的眼睛行为有细微的影响。兴趣模型有</span><span style="color:#000000;">23</span><span style="color:#000000;">个独特的预测因子，与可理解性模型有</span><span style="color:#000000;">45</span><span style="color:#000000;">个相同的特征，目前的结果既不能证实也不能反驳使用眼球追踪数据将兴趣与可理解性分离的可能性。我们的研究结果表明，需要专门的眼球追踪功能和主观工具来识别和区分兴趣的独特处理动态。一个典型的例子是用系数</span><span style="color:#000000;">K</span><span style="color:#000000;">衡量的焦点注意力和环境注意力之间的比率，它显示出兴趣的独特分布。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>高阶过程的纠缠是“共存挑战”所固有的：高阶过程结合在一起影响眼睛行为的特定特征，而低阶过程影响眼睛行为的主要特征</strong></span></u><span style="color:#000000;">。</span><span style="color:#000000;">眼</span><span style="color:#000000;">-</span><span style="color:#000000;">心联系和信息价值联系的确定性性质为这种共存提供了部分解决方案。眼</span><span style="color:#000000;">-</span><span style="color:#000000;">心联系因果地将注视与单词的词汇处理联系起来，而信息价值联系概率地将注视转移与不确定性减少和知识获取联系起来。这些联系表明，眼睛行为的很大一部分变化源于文本特征和相关性，而不是可理解性和兴趣的高阶影响。文本区域特征建模以及这些区域的相关性可以帮助解释词和话语层面的眼睛行为。这样的模型具有关联和区分高阶和低阶过程的潜力，包括文字处理和可理解性之间的关系，以及相关性和兴趣之间的关系，并可能在当前结果的基础上改进可理解性和兴趣的预测。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>通过探索可理解性和兴趣的隐含度量，本研究旨在揭示相关性所固有的人类判断和经验的巨大复杂性</strong></span></u><span style="color:#000000;">。在这些测量中，可理解性传统上与信息的认知相关性或工具性信息需求相关。这种相关性空间通常在基于任务的情况下被考虑，在这种情况下，</span><span style="color:#000000;">(</span><span style="color:#000000;">或多或少</span><span style="color:#000000;">)</span><span style="color:#000000;">客观和智力标准主导着相关性决策</span><span style="color:#000000;">(Saracevic,2007)</span><span style="color:#000000;">。相反，兴趣与本质上更快乐和情感互动有关。尽管各种各样的互动似乎不再是由工具需求驱动的，但可以说，相关性的情感方面并没有很好地整合到相关性理论中</span><span style="color:#000000;">(Belkin, 2008)</span><span style="color:#000000;">。我们的研究结果强调了认知加工动态和兴趣的情感体验之间的复杂关系。这一结论与兴趣的情绪评估理论相一致，该理论假设兴趣和一般的情绪都源于</span><span style="color:#000000;">(</span><span style="color:#000000;">潜意识</span><span style="color:#000000;">)</span><span style="color:#000000;">认知评估</span><span style="color:#000000;">(Ellsworth &amp; Scherer, 2003)</span><span style="color:#000000;">。这表明相关性的非工具性和情感方面遵循通常被认为的认知相关性。关联的认知层面和情感层面不是二元对立的，而是紧密相关的。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>这项研究有助于进一步理解对用户情感体验至关重要的认知判断，以及它们在多大程度上可以被揭示以获得反馈</strong></span></u><span style="color:#000000;">。知道哪些判断是核心的，哪些判断是可以揭示的，这为新的适应形式打开了大门。正确的反馈类型可以解释为什么某些东西是相关的，这可能会提高对用户信息需求的理解。它还可以将用户对检索信息的认知情感体验转化为信息系统的目标。这可能会提供各种新形式的交互支持，帮助用户应对信息和知识的复杂性。这些新的适应机会将有助于信息系统与其用户建立合作关系，在这种关系中，系统越来越多地考虑信息交互的主观方面，直到它们最终迎合挑战但与用户产生共鸣的信息</span><span style="color:#000000;">(Ruthven, 2021)</span><span style="color:#000000;">。</span></p> 
</blockquote> 
<blockquote> 
 <p><u><span style="color:#FF0000;"><strong>尽管眼动追踪作为文本挖掘隐式反馈的广泛应用不太可能在不久的将来实现，但本研究表明了它的潜在用途</strong></span></u><span style="color:#000000;">。 跟踪眼睛提供了一个独特的潜力来揭示处理动态，这些处理动态是信息交互的认知和情感方面的基础。 这一结论与半个多世纪前 </span><span style="color:#000000;">Hess </span><span style="color:#000000;">和 </span><span style="color:#000000;">Polt</span><span style="color:#000000;"> (1960, 1964) </span><span style="color:#000000;">的观察一致：眼睛可以揭示认知活动和兴趣价值的两个方面。 特别是，目前的工作表明，眼球运动揭示了话语层面的可理解性，而特定的认知处理动态部分地构成了兴趣体验的基础。所提议的连续观察类型的贡献为新系统设计提供了机会。对于提供个性化信息的系统，针对我们处理和体验信息的方式进行了“超越传统准确性指标”的优化。</span></p> 
</blockquote> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8ce7aa32d33de52d05381af6fc27247d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【深度学习：数据增强】计算机视觉中数据增强的完整指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7e9908e7e0a384e18aeacc1f07d1f3b6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux常用指令四：查看进程以及内存信息</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>