<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python数据分析（4）：jieba分词详解 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python数据分析（4）：jieba分词详解" />
<meta property="og:description" content="文章目录 jieba分词器1. jieba分词器的分词模式说明（1）精确模式（2）全模式（3）搜索引擎模式（4）Paddle模式 2. jieba分词器的基本用法（1）三种模式案例（2）词性标注（3）识别新词：HMM参数（4）搜索引擎模式分词：cut_for_search()函数 3. 调整词典（1）使用自定义词典：load_userdict()函数（2）动态修改词典：add_word()、del_word()函数（3）调节词频：suggest_freq()函数 4. 关键词提取（1）基于TF-IDF算法的关键词提取：extract_tags()函数（2）基于TextRank算法的关键词提取：textrank()函数 5. 停用词过滤6. 词频统计 前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。点击跳转到网站：人工智能从入门到精通教程
jieba分词器 1. jieba分词器的分词模式说明 jieba分词器提供4种分词模式，并且支持简体/繁体分词、自定义词典、关键词提取、词性标注。
（1）精确模式 该模式会将句子最精确地切分开，适合在文本分析时使用。
（2）全模式 该模式会将句子中所有成词的词语都扫描出来，速度也非常快，缺点是不能解决歧义问题，有歧义的词语也会被扫描出来。
（3）搜索引擎模式 该模式会在精确模式的基础上对长词再进行切分，将更短的词语切分出来。在搜索引擎中，要求输入词语的一部分也能检索到整个词语相关的文档，所以该模式适用于搜索引擎分词。
（4）Paddle模式 该模式利用PaddlePaddle深度学习框架，训练序列标注网络模型实现分词，同时支持词性标注。该模式在4.0及以上版本的jieba分词器中才能使用。使用该模式需要安装paddlepaddle模块。
2. jieba分词器的基本用法 在Python中，可以使用jieba模块的cut()函数进行分词，返回结果是一个迭代器。
cut()函数有4个参数：
第一个参数：待分词文本cut_all：设置使用全模式(True)还是精确模式(False)； 默认Falseuse_paddle：控制是否使用Paddle模式进行分词HMM：控制是否使用HMM模式识别新词 （1）三种模式案例 设置参数cut_all为True：全分词
import jieba str1 = &#39;我来到了西北皇家理工学院，发现这儿真不错&#39; seg_list = jieba.cut(str1, cut_all=True) # 使用全模式进行分词 生成列表 print(&#39;全模式分词结果：&#39;, &#39;/&#39;.join(seg_list)) # /拼接列表元素 全模式分词结果： 我/来到/了/西北/皇家/理工/理工学/理工学院/工学/工学院/学院/，/发现/这儿/真不/真不错/不错 设置参数cut_all为False：精确分词
import jieba str1 = &#39;我来到了西北皇家理工学院，发现这儿真不错&#39; seg_list = jieba.cut(str1, cut_all=False) # 使用精确模式进行分词 print(&#39;精确模式分词结果：&#39;, &#39;/&#39;.join(seg_list)) 精确式分词结果： 我/来到/了/西北/皇家/理工学院/，/发现/这儿/真不错 cut_all参数不给定时，默认为false，即精确分词
import jieba str1 = &#39;我来到了西北皇家理工学院，发现这儿真不错&#39; seg_list = jieba." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7e75229b6472c08ae305e934b0068982/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-29T16:19:15+08:00" />
<meta property="article:modified_time" content="2022-10-29T16:19:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python数据分析（4）：jieba分词详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#jieba_11" rel="nofollow">jieba分词器</a></li><li><ul><li><a href="#1_jieba_13" rel="nofollow">1. jieba分词器的分词模式说明</a></li><li><ul><li><a href="#1_19" rel="nofollow">（1）精确模式</a></li><li><a href="#2_23" rel="nofollow">（2）全模式</a></li><li><a href="#3_27" rel="nofollow">（3）搜索引擎模式</a></li><li><a href="#4Paddle_31" rel="nofollow">（4）Paddle模式</a></li></ul> 
   </li><li><a href="#2_jieba_37" rel="nofollow">2. jieba分词器的基本用法</a></li><li><ul><li><a href="#1_50" rel="nofollow">（1）三种模式案例</a></li><li><a href="#2_111" rel="nofollow">（2）词性标注</a></li><li><a href="#3HMM_134" rel="nofollow">（3）识别新词：HMM参数</a></li><li><a href="#4cut_for_search_155" rel="nofollow">（4）搜索引擎模式分词：cut_for_search()函数</a></li></ul> 
   </li><li><a href="#3__177" rel="nofollow">3. 调整词典</a></li><li><ul><li><a href="#1load_userdict_203" rel="nofollow">（1）使用自定义词典：load_userdict()函数</a></li><li><a href="#2add_worddel_word_222" rel="nofollow">（2）动态修改词典：add_word()、del_word()函数</a></li><li><a href="#3suggest_freq_259" rel="nofollow">（3）调节词频：suggest_freq()函数</a></li></ul> 
   </li><li><a href="#4__295" rel="nofollow">4. 关键词提取</a></li><li><ul><li><a href="#1TFIDFextract_tags_307" rel="nofollow">（1）基于TF-IDF算法的关键词提取：extract_tags()函数</a></li><li><a href="#2TextRanktextrank_340" rel="nofollow">（2）基于TextRank算法的关键词提取：textrank()函数</a></li></ul> 
   </li><li><a href="#5__370" rel="nofollow">5. 停用词过滤</a></li><li><a href="#6__428" rel="nofollow">6. 词频统计</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<p><mark><strong>前些天发现了一个巨牛的人工智能学习网站，通俗易懂，风趣幽默，忍不住分享一下给大家。点击跳转到网站：<a href="https://www.captainai.net/zdb" rel="nofollow">人工智能从入门到精通教程</a></strong></mark></p> 
<hr> 
<p><br><br></p> 
<h2><a id="jieba_11"></a>jieba分词器</h2> 
<h3><a id="1_jieba_13"></a>1. jieba分词器的分词模式说明</h3> 
<p>jieba分词器提供4种分词模式，并且支持简体/繁体分词、自定义词典、关键词提取、词性标注。</p> 
<h4><a id="1_19"></a>（1）精确模式</h4> 
<p>该模式会将句子最精确地切分开，适合在文本分析时使用。</p> 
<h4><a id="2_23"></a>（2）全模式</h4> 
<p>该模式会将句子中所有成词的词语都扫描出来，速度也非常快，缺点是不能解决歧义问题，有歧义的词语也会被扫描出来。</p> 
<h4><a id="3_27"></a>（3）搜索引擎模式</h4> 
<p>该模式会在<strong>精确模式</strong>的基础上对长词再进行切分，将更短的词语切分出来。在搜索引擎中，要求输入词语的一部分也能检索到整个词语相关的文档，所以该模式适用于搜索引擎分词。</p> 
<h4><a id="4Paddle_31"></a>（4）Paddle模式</h4> 
<p>该模式利用PaddlePaddle深度学习框架，训练序列标注网络模型实现分词，同时支持词性标注。该模式在4.0及以上版本的jieba分词器中才能使用。使用该模式需要安装<strong>paddlepaddle模块</strong>。</p> 
<h3><a id="2_jieba_37"></a>2. jieba分词器的基本用法</h3> 
<p>在Python中，可以使用jieba模块的cut()函数进行分词，返回结果是一个迭代器。</p> 
<p>cut()函数有4个参数：</p> 
<ol><li><strong>第一个参数：待分词文本</strong></li><li><strong>cut_all：设置使用全模式(True)还是精确模式(False)； 默认False</strong></li><li><strong>use_paddle：控制是否使用Paddle模式进行分词</strong></li><li><strong>HMM：控制是否使用HMM模式识别新词</strong></li></ol> 
<h4><a id="1_50"></a>（1）三种模式案例</h4> 
<p><strong>设置参数cut_all为True：全分词</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
str1 <span class="token operator">=</span> <span class="token string">'我来到了西北皇家理工学院，发现这儿真不错'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str1<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment"># 使用全模式进行分词  生成列表</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'全模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># /拼接列表元素</span>
</code></pre> 
<pre><code class="prism language-python">全模式分词结果： 我<span class="token operator">/</span>来到<span class="token operator">/</span>了<span class="token operator">/</span>西北<span class="token operator">/</span>皇家<span class="token operator">/</span>理工<span class="token operator">/</span>理工学<span class="token operator">/</span>理工学院<span class="token operator">/</span>工学<span class="token operator">/</span>工学院<span class="token operator">/</span>学院<span class="token operator">/</span>，<span class="token operator">/</span>发现<span class="token operator">/</span>这儿<span class="token operator">/</span>真不<span class="token operator">/</span>真不错<span class="token operator">/</span>不错
</code></pre> 
<p><strong>设置参数cut_all为False：精确分词</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
str1 <span class="token operator">=</span> <span class="token string">'我来到了西北皇家理工学院，发现这儿真不错'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str1<span class="token punctuation">,</span> cut_all<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 使用精确模式进行分词</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'精确模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">精确式分词结果： 我<span class="token operator">/</span>来到<span class="token operator">/</span>了<span class="token operator">/</span>西北<span class="token operator">/</span>皇家<span class="token operator">/</span>理工学院<span class="token operator">/</span>，<span class="token operator">/</span>发现<span class="token operator">/</span>这儿<span class="token operator">/</span>真不错
</code></pre> 
<p><strong>cut_all参数不给定时，默认为false，即精确分词</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
str1 <span class="token operator">=</span> <span class="token string">'我来到了西北皇家理工学院，发现这儿真不错'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'全模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">精确模式分词结果： 我<span class="token operator">/</span>来到<span class="token operator">/</span>了<span class="token operator">/</span>西北<span class="token operator">/</span>皇家<span class="token operator">/</span>理工学院<span class="token operator">/</span>，<span class="token operator">/</span>发现<span class="token operator">/</span>这儿<span class="token operator">/</span>真不错
</code></pre> 
<p><strong>use_paddle参数可以设置开启paddle模式</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">import</span> paddle
str1 <span class="token operator">=</span> <span class="token string">'我来到了西北皇家理工学院，发现这儿真不错'</span>
<span class="token comment">#jieba.enable_paddle()   已经停用</span>
paddle<span class="token punctuation">.</span>enable_static<span class="token punctuation">(</span><span class="token punctuation">)</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str1<span class="token punctuation">,</span> use_paddle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#使用paddle模式进行分词</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Paddle模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">Paddle模式分词结果： 我<span class="token operator">/</span>来到<span class="token operator">/</span>了<span class="token operator">/</span>西北<span class="token operator">/</span>皇家<span class="token operator">/</span>理工学院<span class="token operator">/</span>，<span class="token operator">/</span>发现<span class="token operator">/</span>这儿<span class="token operator">/</span>真不错
</code></pre> 
<h4><a id="2_111"></a>（2）词性标注</h4> 
<p><img src="https://images2.imgbox.com/98/5a/5YcuzvCn_o.png" alt="image-20211215163657726"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
<span class="token keyword">import</span> jieba<span class="token punctuation">.</span>posseg <span class="token keyword">as</span> pseg
<span class="token comment">#jieba.enable_paddle()</span>
str2 <span class="token operator">=</span> <span class="token string">'上海自来水来自海上'</span>
seg_list <span class="token operator">=</span> pseg<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str2<span class="token punctuation">,</span> use_paddle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#使用posseg进行分词</span>
<span class="token keyword">for</span> seg<span class="token punctuation">,</span> flag <span class="token keyword">in</span> seg_list<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>seg<span class="token punctuation">,</span> flag<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">上海 ns
自来水 l
来自 v
海上 s
</code></pre> 
<h4><a id="3HMM_134"></a>（3）识别新词：HMM参数</h4> 
<p>HMM参数设置为True，可以识别新词，即词典中不存在的词。</p> 
<p><strong>词典为jieba分词自带的字典。</strong></p> 
<p>如下：他知</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
str3 <span class="token operator">=</span> <span class="token string">'他知科技研发有限公司是一家互联网行业的公司'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str3<span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment">#HMM默认为True，所以可以不设置</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'精确模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">精确模式分词结果： 他知<span class="token operator">/</span>科技<span class="token operator">/</span>研发<span class="token operator">/</span>有限公司<span class="token operator">/</span>是<span class="token operator">/</span>一家<span class="token operator">/</span>互联网<span class="token operator">/</span>行业<span class="token operator">/</span>的<span class="token operator">/</span>公司
</code></pre> 
<h4><a id="4cut_for_search_155"></a>（4）搜索引擎模式分词：cut_for_search()函数</h4> 
<p>cut_for_search()函数可以进行搜索引擎模式分词</p> 
<p>该函数只有两个参数：</p> 
<ol><li>第一个参数：待分词文本</li><li>第二个参数：HMM，默认为True</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
str1 <span class="token operator">=</span> <span class="token string">'我来到了西北皇家理工学院，发现这儿真不错'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut_for_search<span class="token punctuation">(</span>str1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'搜索引擎模式分词结果：'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">搜索引擎模式分词结果： 我<span class="token operator">/</span>来到<span class="token operator">/</span>了<span class="token operator">/</span>西北<span class="token operator">/</span>皇家<span class="token operator">/</span>理工<span class="token operator">/</span>工学<span class="token operator">/</span>学院<span class="token operator">/</span>理工学<span class="token operator">/</span>工学院<span class="token operator">/</span>理工学院<span class="token operator">/</span>，<span class="token operator">/</span>发现<span class="token operator">/</span>这儿<span class="token operator">/</span>真不<span class="token operator">/</span>不错<span class="token operator">/</span>真不错
</code></pre> 
<h3><a id="3__177"></a>3. 调整词典</h3> 
<p>用户也可以自己生成一个自定义词典，包含jieba分词自带字典中没有的词语，添加到程序中。比如：</p> 
<p><img src="https://images2.imgbox.com/67/bf/7Up9d1cW_o.png" alt="image-20211215163733067"></p> 
<p><strong>注意：词频、词性可省略。</strong></p> 
<p>未加载自定义字典时使用精确切分来进行分词</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>
    <span class="token string">'心灵感应般地蓦然回首，才能撞见那一低头的温柔；也最是那一低头的温柔，似一朵水莲花不胜凉风的娇羞；也最是那一抹娇羞，才能让两人携手共白首。'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'未加载自定义词典时的精确模式分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">未加载自定义词典时的精确模式分词结果：
 心灵感应<span class="token operator">/</span>般地<span class="token operator">/</span>蓦然回首<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>撞见<span class="token operator">/</span>那一<span class="token operator">/</span>低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最<span class="token operator">/</span>是<span class="token operator">/</span>那<span class="token operator">/</span>一<span class="token operator">/</span>低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>，<span class="token operator">/</span>似<span class="token operator">/</span>一朵<span class="token operator">/</span>水<span class="token operator">/</span>莲花<span class="token operator">/</span>不胜<span class="token operator">/</span>凉风<span class="token operator">/</span>的<span class="token operator">/</span>娇羞<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最<span class="token operator">/</span>是<span class="token operator">/</span>那<span class="token operator">/</span>一抹<span class="token operator">/</span>娇羞<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>让<span class="token operator">/</span>两人<span class="token operator">/</span>携手<span class="token operator">/</span>共<span class="token operator">/</span>白首<span class="token operator">/</span>。
</code></pre> 
<h4><a id="1load_userdict_203"></a>（1）使用自定义词典：load_userdict()函数</h4> 
<p><strong>load_userdict()函数</strong>加载用户自定义字典</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span><span class="token string">'用户词典.txt'</span><span class="token punctuation">)</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>
    <span class="token string">'心灵感应般地蓦然回首，才能撞见那一低头的温柔；也最是那一低头的温柔，似一朵水莲花不胜凉风的娇羞；也最是那一抹娇羞，才能让两人携手共白首。'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'加载自定义词典时的精确模式分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">加载自定义词典时的精确模式分词结果：
 心灵感应<span class="token operator">/</span>般地<span class="token operator">/</span>蓦然回首<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>撞见<span class="token operator">/</span>那<span class="token operator">/</span>一低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最<span class="token operator">/</span>是<span class="token operator">/</span>那<span class="token operator">/</span>一低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>，<span class="token operator">/</span>似<span class="token operator">/</span>一朵<span class="token operator">/</span>水莲花<span class="token operator">/</span>不胜<span class="token operator">/</span>凉风<span class="token operator">/</span>的<span class="token operator">/</span>娇羞<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最<span class="token operator">/</span>是<span class="token operator">/</span>那<span class="token operator">/</span>一抹<span class="token operator">/</span>娇羞<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>让<span class="token operator">/</span>两人<span class="token operator">/</span>携手<span class="token operator">/</span>共<span class="token operator">/</span>白首<span class="token operator">/</span>。
</code></pre> 
<h4><a id="2add_worddel_word_222"></a>（2）动态修改词典：add_word()、del_word()函数</h4> 
<p><strong>1. 动态添加词：add_word()</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span><span class="token string">'用户词典.txt'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>add_word<span class="token punctuation">(</span><span class="token string">'最是'</span><span class="token punctuation">)</span>  <span class="token comment">#添加词，  但是不会添加到   用户字典.txt   文件中</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>
    <span class="token string">'心灵感应般地蓦然回首，才能撞见那一低头的温柔；也最是那一低头的温柔，似一朵水莲花不胜凉风的娇羞；也最是那一抹娇羞，才能让两人携手共白首。'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'添加自定义词时的精确模式分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">添加自定义词时的精确模式分词结果：
 心灵感应<span class="token operator">/</span>般地<span class="token operator">/</span>蓦然回首<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>撞见<span class="token operator">/</span>那<span class="token operator">/</span>一低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最是<span class="token operator">/</span>那<span class="token operator">/</span>一低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>，<span class="token operator">/</span>似<span class="token operator">/</span>一朵<span class="token operator">/</span>水莲花<span class="token operator">/</span>不胜<span class="token operator">/</span>凉风<span class="token operator">/</span>的<span class="token operator">/</span>娇羞<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最是<span class="token operator">/</span>那<span class="token operator">/</span>一抹<span class="token operator">/</span>娇羞<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>让<span class="token operator">/</span>两人<span class="token operator">/</span>携手<span class="token operator">/</span>共<span class="token operator">/</span>白首<span class="token operator">/</span>。
</code></pre> 
<p><strong>2.动态删除词：del_word()</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
jieba<span class="token punctuation">.</span>load_userdict<span class="token punctuation">(</span><span class="token string">'用户词典.txt'</span><span class="token punctuation">)</span>
jieba<span class="token punctuation">.</span>del_word<span class="token punctuation">(</span><span class="token string">'一低头'</span><span class="token punctuation">)</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span><span class="token string">'心灵感应般地蓦然回首，才能撞见那一低头的温柔；也最是那一低头的温柔，似一朵水莲花不胜凉风的娇羞；也最是那一抹娇羞，才能让两人携手共白首。'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'删除自定义词时的精确模式分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">删除自定义词时的精确模式分词结果：
 心灵感应<span class="token operator">/</span>般地<span class="token operator">/</span>蓦然回首<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>撞见<span class="token operator">/</span>那一<span class="token operator">/</span>低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最<span class="token operator">/</span>是<span class="token operator">/</span>那<span class="token operator">/</span>一<span class="token operator">/</span>低头<span class="token operator">/</span>的<span class="token operator">/</span>温柔<span class="token operator">/</span>，<span class="token operator">/</span>似<span class="token operator">/</span>一朵<span class="token operator">/</span>水莲花<span class="token operator">/</span>不胜<span class="token operator">/</span>凉风<span class="token operator">/</span>的<span class="token operator">/</span>娇羞<span class="token operator">/</span>；<span class="token operator">/</span>也<span class="token operator">/</span>最<span class="token operator">/</span>是<span class="token operator">/</span>那<span class="token operator">/</span>一抹<span class="token operator">/</span>娇羞<span class="token operator">/</span>，<span class="token operator">/</span>才能<span class="token operator">/</span>让<span class="token operator">/</span>两人<span class="token operator">/</span>携手<span class="token operator">/</span>共<span class="token operator">/</span>白首<span class="token operator">/</span>。
</code></pre> 
<h4><a id="3suggest_freq_259"></a>（3）调节词频：suggest_freq()函数</h4> 
<p>不修改词频前：</p> 
<pre><code class="prism language-python"><span class="token comment">#不修改词频</span>
<span class="token keyword">import</span> jieba
str3 <span class="token operator">=</span> <span class="token string">'他认为未来几年健康产业在GDP中将占比第一。'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str3<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'精确模式分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">精确模式分词结果：
 他<span class="token operator">/</span>认为<span class="token operator">/</span>未来<span class="token operator">/</span>几年<span class="token operator">/</span>健康<span class="token operator">/</span>产业<span class="token operator">/</span>在<span class="token operator">/</span>GDP<span class="token operator">/</span>中将<span class="token operator">/</span>占<span class="token operator">/</span>比<span class="token operator">/</span>第一<span class="token operator">/</span>。
</code></pre> 
<p>修改词频后：</p> 
<pre><code class="prism language-python"><span class="token comment">#修改词频</span>
<span class="token keyword">import</span> jieba
str3 <span class="token operator">=</span> <span class="token string">'他认为未来几年健康产业在GDP中将占比第一。'</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'中'</span><span class="token punctuation">,</span> <span class="token string">'将'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>   <span class="token comment">#修改词频  强制“中将”</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token string">'占比'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>         <span class="token comment">#强制让“占比”作为一次词</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>str3<span class="token punctuation">,</span> HMM<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'精确模式分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">精确模式分词结果：
 他<span class="token operator">/</span>认为<span class="token operator">/</span>未来<span class="token operator">/</span>几年<span class="token operator">/</span>健康<span class="token operator">/</span>产业<span class="token operator">/</span>在<span class="token operator">/</span>GDP<span class="token operator">/</span>中<span class="token operator">/</span>将<span class="token operator">/</span>占比<span class="token operator">/</span>第一<span class="token operator">/</span>。
</code></pre> 
<h3><a id="4__295"></a>4. 关键词提取</h3> 
<p>从文本文件中提取关键词的理论方法主要有两种：</p> 
<p>第一种是有监督的学习方法，该方法将关键词的提取视为一个二分类问题，要么是关键词，要么不是</p> 
<p>第二种是无监督的学习方法，该方法对候选词进行打分，大风范最高的候选词为关键词</p> 
<p>常见的打分算法有<strong>TF-IDF和TextRank</strong>。</p> 
<h4><a id="1TFIDFextract_tags_307"></a>（1）基于TF-IDF算法的关键词提取：extract_tags()函数</h4> 
<p><strong>extract_tags()函数</strong>能基于TF-IDF算法提取关键词</p> 
<pre><code class="prism language-python">jieba<span class="token punctuation">.</span>analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>sentence<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>该函数有四个参数：</p> 
<ol><li>sentence：待提取关键词的文本</li><li>topK：关键词数</li><li>withWeight：是否返回权重</li><li>allowPOS：指定筛选关键词的词性；默认不分词性</li></ol> 
<p><strong>基于TF-IDF算法的关键词提取</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 基于TF-IDF算法的关键词提取</span>
<span class="token keyword">from</span> jieba <span class="token keyword">import</span> analyse
text <span class="token operator">=</span> <span class="token string">'记者日前从中国科学院南京地质古生物研究所获悉，该所早期生命研究团队与美国学者合作，在中国湖北三峡地区的石板滩生物群中，发现了4种形似树叶的远古生物。这些“树叶”实际上是形态奇特的早期动物，它们生活在远古海洋底部。相关研究成果已发表在古生物学国际专业期刊《古生物学杂志》上。'</span>
keywords <span class="token operator">=</span> analyse<span class="token punctuation">.</span>extract_tags<span class="token punctuation">(</span>text<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>keywords<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'古生物学'</span><span class="token punctuation">,</span> <span class="token number">0.783184303024</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'树叶'</span><span class="token punctuation">,</span> <span class="token number">0.6635900468544</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生物群'</span><span class="token punctuation">,</span> <span class="token number">0.43238540794400004</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'古生物'</span><span class="token punctuation">,</span> <span class="token number">0.38124919198039997</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'期刊'</span><span class="token punctuation">,</span> <span class="token number">0.36554014868720003</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'石板'</span><span class="token punctuation">,</span> <span class="token number">0.34699723913040004</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'形似'</span><span class="token punctuation">,</span> <span class="token number">0.3288202017184</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'研究成果'</span><span class="token punctuation">,</span> <span class="token number">0.3278758070928</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'团队'</span><span class="token punctuation">,</span> <span class="token number">0.2826627565264</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'获悉'</span><span class="token punctuation">,</span> <span class="token number">0.28072960723920004</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<h4><a id="2TextRanktextrank_340"></a>（2）基于TextRank算法的关键词提取：textrank()函数</h4> 
<p><strong>textrank()函数</strong>能基于TextRank算法提取关键字</p> 
<pre><code>jieba.analyse.textrank(sentance, topK=20, withWeight=False, allowPOS=('ns', 'n', 'vn', 'v'))
</code></pre> 
<p>两种方法的区别是<strong>默认提取的词性</strong>不同</p> 
<p>当然算法不同，结果可能有差异</p> 
<p><strong>基于TextRank算法的关键词提取</strong></p> 
<pre><code class="prism language-python"><span class="token comment"># 基于TextRank算法的关键词提取</span>
<span class="token keyword">from</span> jieba <span class="token keyword">import</span> analyse
text <span class="token operator">=</span> <span class="token string">'记者日前从中国科学院南京地质古生物研究所获悉，该所早期生命研究团队与美国学者合作，在中国湖北三峡地区的石板滩生物群中，发现了4种形似树叶的远古生物。这些“树叶”实际上是形态奇特的早期动物，它们生活在远古海洋底部。相关研究成果已发表在古生物学国际专业期刊《古生物学杂志》上。'</span>
keywords <span class="token operator">=</span> analyse<span class="token punctuation">.</span>textrank<span class="token punctuation">(</span>text<span class="token punctuation">,</span> topK<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> withWeight<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> allowPOS<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'n'</span><span class="token punctuation">,</span> <span class="token string">'v'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>keywords<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'古生物学'</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'树叶'</span><span class="token punctuation">,</span> <span class="token number">0.8797803471074045</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'形似'</span><span class="token punctuation">,</span> <span class="token number">0.6765568513591282</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'专业'</span><span class="token punctuation">,</span> <span class="token number">0.6684901270801065</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生物'</span><span class="token punctuation">,</span> <span class="token number">0.648692596888148</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'发表'</span><span class="token punctuation">,</span> <span class="token number">0.6139083953888275</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'生物群'</span><span class="token punctuation">,</span> <span class="token number">0.59981945604977</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'期刊'</span><span class="token punctuation">,</span> <span class="token number">0.5651065025924439</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'国际'</span><span class="token punctuation">,</span> <span class="token number">0.5642917600351786</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'获悉'</span><span class="token punctuation">,</span> <span class="token number">0.5620719278559326</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre> 
<h3><a id="5__370"></a>5. 停用词过滤</h3> 
<p>停用词：“你”、“我”、“的”、“在”及标点符号等大量出现但非关键词的词。</p> 
<p>我们可以把它们过滤掉</p> 
<p>启动停用词过滤前：</p> 
<pre><code class="prism language-python"><span class="token comment">#未启动停用词过滤</span>
<span class="token keyword">import</span> jieba
text <span class="token operator">=</span> <span class="token string">'商务部4月23日发布的数据显示，一季度，全国农产品网络零售额达936.8亿元，增长31.0%；电商直播超过400万场。电商给农民带来了新的机遇。'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'未启用停用词过滤时的分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>seg_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">未启用停用词过滤时的分词结果：
 商务部<span class="token operator">/</span><span class="token number">4</span><span class="token operator">/</span>月<span class="token operator">/</span><span class="token number">23</span><span class="token operator">/</span>日<span class="token operator">/</span>发布<span class="token operator">/</span>的<span class="token operator">/</span>数据<span class="token operator">/</span>显示<span class="token operator">/</span>，<span class="token operator">/</span>一季度<span class="token operator">/</span>，<span class="token operator">/</span>全国<span class="token operator">/</span>农产品<span class="token operator">/</span>网络<span class="token operator">/</span>零售额<span class="token operator">/</span>达<span class="token operator">/</span><span class="token number">936.8</span><span class="token operator">/</span>亿元<span class="token operator">/</span>，<span class="token operator">/</span>增长<span class="token operator">/</span><span class="token number">31.0</span><span class="token operator">%</span><span class="token operator">/</span>；<span class="token operator">/</span>电商<span class="token operator">/</span>直播<span class="token operator">/</span>超过<span class="token operator">/</span><span class="token number">400</span><span class="token operator">/</span>万场<span class="token operator">/</span>。<span class="token operator">/</span>电商<span class="token operator">/</span>给<span class="token operator">/</span>农民<span class="token operator">/</span>带来<span class="token operator">/</span>了<span class="token operator">/</span>新<span class="token operator">/</span>的<span class="token operator">/</span>机遇<span class="token operator">/</span>。
</code></pre> 
<p>为了过滤停用词，需要有一个停用词词典。</p> 
<p>我们可以自己制作停用词词典，停用词词典的内容是根据NLP的目的变化的。</p> 
<p>如果制作太慢，可以百度下载一个停用词词典，稍作修改成自己想要的。如下：</p> 
<p><img src="https://images2.imgbox.com/40/b4/5rasa2D2_o.png" alt="image-20211215163754231"></p> 
<p>启动停用词过滤后：</p> 
<pre><code class="prism language-python"><span class="token comment">#启动停用词过滤</span>
<span class="token keyword">import</span> jieba
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'stopwords.txt'</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> fp<span class="token punctuation">:</span>
    stopwords <span class="token operator">=</span> fp<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>  <span class="token comment">#将停用词词典的每一行停用词作为列表中的一个元素</span>
word_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment">#用于存储过滤停用词后的分词结果</span>
text <span class="token operator">=</span> <span class="token string">'商务部4月23日发布的数据显示，一季度，全国农产品网络零售额达936.8亿元，增长31.0%；电商直播超过400万场。电商给农民带来了新的机遇。'</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">for</span> seg <span class="token keyword">in</span> seg_list<span class="token punctuation">:</span>
    <span class="token keyword">if</span> seg <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span>
        word_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>seg<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'启用停用词过滤时的分词结果：\n'</span><span class="token punctuation">,</span> <span class="token string">'/'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>word_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">启用停用词过滤时的分词结果：
 商务部<span class="token operator">/</span><span class="token number">4</span><span class="token operator">/</span>月<span class="token operator">/</span><span class="token number">23</span><span class="token operator">/</span>日<span class="token operator">/</span>发布<span class="token operator">/</span>数据<span class="token operator">/</span>显示<span class="token operator">/</span>一季度<span class="token operator">/</span>全国<span class="token operator">/</span>农产品<span class="token operator">/</span>网络<span class="token operator">/</span>零售额<span class="token operator">/</span>达<span class="token operator">/</span><span class="token number">936.8</span><span class="token operator">/</span>亿元<span class="token operator">/</span>增长<span class="token operator">/</span><span class="token number">31.0</span><span class="token operator">%</span><span class="token operator">/</span>电商<span class="token operator">/</span>直播<span class="token operator">/</span>超过<span class="token operator">/</span><span class="token number">400</span><span class="token operator">/</span>万场<span class="token operator">/</span>电商<span class="token operator">/</span>农民<span class="token operator">/</span>带来<span class="token operator">/</span>新<span class="token operator">/</span>机遇
</code></pre> 
<p>注意：我们根据不同的编码方式，修改encoding参数</p> 
<h3><a id="6__428"></a>6. 词频统计</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> jieba
text <span class="token operator">=</span> <span class="token string">'蒸馍馍锅锅蒸馍馍，馍馍蒸了一锅锅，馍馍搁上桌桌，桌桌上面有馍馍。'</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'stopwords.txt'</span><span class="token punctuation">,</span> <span class="token string">'r+'</span><span class="token punctuation">,</span> encoding <span class="token operator">=</span> <span class="token string">'utf-8'</span><span class="token punctuation">)</span><span class="token keyword">as</span> fp<span class="token punctuation">:</span>
    stopwords <span class="token operator">=</span> fp<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">)</span>    <span class="token comment">#加载停用词</span>
word_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>                           <span class="token comment">#用于存储词频统计结果的词典</span>
jieba<span class="token punctuation">.</span>suggest_freq<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">'桌桌'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment">#让“桌桌”作为一个词</span>
seg_list <span class="token operator">=</span> jieba<span class="token punctuation">.</span>cut<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
<span class="token keyword">for</span> seg <span class="token keyword">in</span> seg_list<span class="token punctuation">:</span>
    <span class="token keyword">if</span> seg <span class="token keyword">not</span> <span class="token keyword">in</span> stopwords<span class="token punctuation">:</span>
        <span class="token keyword">if</span> seg <span class="token keyword">in</span> word_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            word_dict<span class="token punctuation">[</span>seg<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>     <span class="token comment">#存在则词频+1</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            word_dict<span class="token punctuation">[</span>seg<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>      <span class="token comment">#不存在则存入键值对</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>word_dict<span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token punctuation">{<!-- --></span><span class="token string">'蒸'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'馍馍'</span><span class="token punctuation">:</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token string">'锅锅'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'一锅'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'锅'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'搁'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'桌桌'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'上面'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/952d3e5f4cdc4aa596a64ec9d2b38604/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;快速实现去掉数组中重复元素</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7e557133d6fa8bb154ed71806c89d79c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android11以上无法访问Android/data目录的解决方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>