<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习之Attention模型详解 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习之Attention模型详解" />
<meta property="og:description" content="转载自：Datawhale（ID：Datawhale）
作者：yif
本文8434字41图，建议阅读22分钟。
本文介绍深度学习中的Attention模型。
Attention的产生
起因：《Sequence to Sequence Learning with Neural Networks》
Attention模型的引入原因：
seq2seq将输入序列都压缩成一个固定大小的隐变量，就像我们的压缩文件一样，这个过程是有损压缩的，会迫使丢失许多输入序列中的信息；
存在着难以对齐的问题。比如中译音“我爱你” “I love you”,输入序列中的“我”应该与“I”对齐(贡献最大)，然而在seq2seq模型中，“我”对&#34;I&#34;，&#34;love&#34;，&#34;you&#34;的贡献都是一致的。
Attention的发展
Show, attend and tell: Neural image caption generation with visual attention 本文可以算是第一篇Attention论文。
该任务是实现图文转换。与前面讲述的seq2seq的问题一样，在之前的图文转换任务中也是存在着难以对齐的问题。所谓难以对齐就是毫无重点。
本文提出了两种attention：
sort Attention
hard Attention
本文的模型结构：
将图片通过一个CNN转换成的L D.这里称L个向量为L个注释向量(annotation vector)，D为特征维度，可以认为提取了图片中L个区域的特征。对这L个区域向量加权相加来表示这张图片。由于不同时刻的关注点是不同的，annotation vector还要与decoder中的隐状态进行交互，以便知道下一时刻的关注区域。
这里编码器是VGG，解码器是LSTM。LTSM输入是不同时刻的图片的关注点信息，然后生成当前时刻的单词。
Attention的计算
如上所属，attention的值不仅与annotation vector 有关，还与上一时刻解码器的隐状态有关。因此有：
其中t表示时刻t，i表示第i个区域，a是我们得到的attention weight分布。
f实际上是对齐函数，用于计算对齐的分数，常见的对齐函数有：dot product，general，multilayer perceptron。
1，Soft attention：直接使用attention的权重对L个向量加权相加，这么做的好处是整个问题是可微的，可以利用BP end to end。
2，Hard attention：Hard attention很粗暴，挑出最大权重的向量，剔除其余向量(置0)。显然这种形式的模型是不可微的，为了实现BP，这里采用蒙特卡洛采样的方法来估计模块的梯度。
帮助我们在t时刻选出了第i个向量 是我们最后选中的的向量，引入一个变量 ,当区域i被选中时取值为1，否则为0.则有：
问题如何生成 ,在本文中，将 视为隐变量，为参数是 的多元伯努利分布(伯努利是两点分布)
$$P(s_{t,i}=1|s_{t&lt;j},a)=\alpha_{t,i} $$=&#34;&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/6e9cd70fee8469acc2edf64c67bbe43b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-11-26T07:30:00+08:00" />
<meta property="article:modified_time" content="2019-11-26T07:30:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习之Attention模型详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <h3></h3> 
 <p><img src="https://images2.imgbox.com/df/fb/9szRglMF_o.png" style="width: 677px"></p> 
 <p>转载自：Datawhale（ID：Datawhale）</p> 
 <p>作者：yif</p> 
 <p>本文<strong>8434字41图</strong>，建议阅读<strong>22</strong><strong>分钟</strong>。</p> 
 <p>本文介绍深度学习中的Attention模型。</p> 
 <p><strong>Attention的产生</strong></p> 
 <p>起因：《Sequence to Sequence Learning with Neural Networks》</p> 
 <p>Attention模型的引入原因：</p> 
 <ol><li><p>seq2seq将输入序列都压缩成一个固定大小的隐变量，就像我们的压缩文件一样，这个过程是有损压缩的，会迫使丢失许多输入序列中的信息；</p></li><li><p>存在着难以对齐的问题。比如中译音“我爱你” 
    <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -511 1000 522" style="vertical-align: -0.025ex;width: 2.262ex;height: 1.181ex;"> 
     <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
      <g> 
       <g> 
        <path d="M56 237T56 250T70 270H835Q719 357 692 493Q692 494 692 496T691 499Q691 511 708 511H711Q720 511 723 510T729 506T732 497T735 481T743 456Q765 389 816 336T935 261Q944 258 944 250Q944 244 939 241T915 231T877 212Q836 186 806 152T761 85T740 35T732 4Q730 -6 727 -8T711 -11Q691 -11 691 0Q691 7 696 25Q728 151 835 230H70Q56 237 56 250Z"></path> 
       </g> 
      </g> 
     </g> 
    </svg>“I love you”,输入序列中的“我”应该与“I”对齐(贡献最大)，然而在seq2seq模型中，“我”对"I"，"love"，"you"的贡献都是一致的。</p></li></ol> 
 <p><img src="https://images2.imgbox.com/f5/4b/DWc6Me9V_o.png" style="width: 677px"><br><br></p> 
 <p><strong>Attention的发展</strong></p> 
 <h4>Show, attend and tell: Neural image caption generation with visual attention</h4> 
 <p>本文可以算是第一篇Attention论文。</p> 
 <p><img src="https://images2.imgbox.com/0e/a0/EdVOBq5X_o.png" style="width: 677px"></p> 
 <p>该任务是实现图文转换。与前面讲述的seq2seq的问题一样，在之前的图文转换任务中也是存在着难以对齐的问题。所谓难以对齐就是毫无重点。</p> 
 <p>本文提出了两种attention：</p> 
 <ol><li><p>sort Attention</p></li><li><p>hard Attention</p></li></ol> 
 <p>本文的模型结构：</p> 
 <p><img src="https://images2.imgbox.com/b9/63/edPxBYwU_o.png" style="width: 677px"></p> 
 <p>将图片通过一个CNN转换成的L 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -491 778 482" style="vertical-align: 0.02ex;width: 1.76ex;height: 1.09ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <path d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>D.这里称L个向量为L个注释向量(annotation vector)，D为特征维度，可以认为提取了图片中L个区域的特征。对这L个区域向量加权相加来表示这张图片。由于不同时刻的关注点是不同的，annotation vector还要与decoder中的隐状态进行交互，以便知道下一时刻的关注区域。</p> 
 <p><img src="https://images2.imgbox.com/ec/25/cznw2pBM_o.png" style="width: 677px"></p> 
 <p>这里编码器是VGG，解码器是LSTM。LTSM输入是不同时刻的图片的关注点信息，然后生成当前时刻的单词。</p> 
 <p><strong>Attention的计算</strong></p> 
 <p>如上所属，attention的值不仅与annotation vector 有关，还与上一时刻解码器的隐状态有关。因此有：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a6/98/e65qSrSJ_o.png"></p> 
 <p>其中t表示时刻t，i表示第i个区域，a是我们得到的attention weight分布。</p> 
 <p>f实际上是对齐函数，用于计算对齐的分数，常见的对齐函数有：dot product，general，multilayer perceptron。</p> 
 <p>1，Soft attention：直接使用attention的权重对L个向量加权相加，这么做的好处是整个问题是可微的，可以利用BP end to end。</p> 
 <p><img src="https://images2.imgbox.com/e1/cb/0sPPsZz3_o.png" style="width: 677px"></p> 
 <p>2，Hard attention：Hard attention很粗暴，挑出最大权重的向量，剔除其余向量(置0)。显然这种形式的模型是不可微的，为了实现BP，这里采用蒙特卡洛采样的方法来估计模块的梯度。</p> 
 <p><img src="https://images2.imgbox.com/ad/3d/y462FMmP_o.png" style="width: 677px"></p> 
 <p>帮助我们在t时刻选出了第i个向量 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -441 823 598.8" style="vertical-align: -0.357ex;width: 1.862ex;height: 1.355ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
      </g> 
      <g transform="translate(529, -150) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>是我们最后选中的的向量，引入一个变量 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 1214.8 729.2" style="vertical-align: -0.65ex;width: 2.748ex;height: 1.65ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path> 
      </g> 
      <g transform="translate(469, -150) scale(0.707)"> 
       <g> 
        <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
       </g> 
       <g transform="translate(361, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(639, 0)"> 
        <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
       </g> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>,当区域i被选中时取值为1，否则为0.则有：</p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -950 5565.1 2142.2" style="-webkit-overflow-scrolling: touch;vertical-align: -2.697ex;width: 12.591ex;height: 4.847ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <g> 
        <g transform="translate(17.5, 0)"> 
         <path d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path> 
        </g> 
        <g transform="translate(55.6, -29)"> 
         <path d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path> 
        </g> 
       </g> 
      </g> 
      <g transform="translate(555.6, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
     <g transform="translate(860.9, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(1916.6, 0)"> 
      <g> 
       <path d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path> 
      </g> 
      <g transform="translate(600, -1084.4) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
     <g transform="translate(3527.3, 0)"> 
      <g> 
       <path d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path> 
      </g> 
      <g transform="translate(469, -150) scale(0.707)"> 
       <g> 
        <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
       </g> 
       <g transform="translate(361, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(639, 0)"> 
        <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
       </g> 
      </g> 
     </g> 
     <g transform="translate(4742.1, 0)"> 
      <g> 
       <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
      </g> 
      <g transform="translate(529, -150) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p>问题如何生成 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 1214.8 729.2" style="vertical-align: -0.65ex;width: 2.748ex;height: 1.65ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path> 
      </g> 
      <g transform="translate(469, -150) scale(0.707)"> 
       <g> 
        <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
       </g> 
       <g transform="translate(361, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(639, 0)"> 
        <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
       </g> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>,在本文中，将 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 774.3 599.8" style="vertical-align: -0.357ex;width: 1.752ex;height: 1.357ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path> 
      </g> 
      <g transform="translate(469, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>视为隐变量，为参数是 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -750 1934 1000" style="vertical-align: -0.566ex;width: 4.375ex;height: 2.262ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <path d="M434 -231Q434 -244 428 -250H410Q281 -250 230 -184Q225 -177 222 -172T217 -161T213 -148T211 -133T210 -111T209 -84T209 -47T209 0Q209 21 209 53Q208 142 204 153Q203 154 203 155Q189 191 153 211T82 231Q71 231 68 234T65 250T68 266T82 269Q116 269 152 289T203 345Q208 356 208 377T209 529V579Q209 634 215 656T244 698Q270 724 324 740Q361 748 377 749Q379 749 390 749T408 750H428Q434 744 434 732Q434 719 431 716Q429 713 415 713Q362 710 332 689T296 647Q291 634 291 499V417Q291 370 288 353T271 314Q240 271 184 255L170 250L184 245Q202 239 220 230T262 196T290 137Q291 131 291 1Q291 -134 296 -147Q306 -174 339 -192T415 -213Q429 -213 431 -216Q434 -219 434 -231Z"></path> 
     </g> 
     <g transform="translate(500, 0)"> 
      <g> 
       <path d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path> 
      </g> 
      <g transform="translate(640, -150) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1434, 0)"> 
      <path d="M65 731Q65 745 68 747T88 750Q171 750 216 725T279 670Q288 649 289 635T291 501Q292 362 293 357Q306 312 345 291T417 269Q428 269 431 266T434 250T431 234T417 231Q380 231 345 210T298 157Q293 143 292 121T291 -28V-79Q291 -134 285 -156T256 -198Q202 -250 89 -250Q71 -250 68 -247T65 -230Q65 -224 65 -223T66 -218T69 -214T77 -213Q91 -213 108 -210T146 -200T183 -177T207 -139Q208 -134 209 3L210 139Q223 196 280 230Q315 247 330 250Q305 257 280 270Q225 304 212 352L210 362L209 498Q208 635 207 640Q195 680 154 696T77 713Q68 713 67 716T65 731Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>的多元伯努利分布(伯努利是两点分布)</p> 
 <p style="text-align: left">$$P(s_{t,i}=1|s_{t&lt;j},a)=\alpha_{t,i} $$=""</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/16/47/H5s41G2C_o.png"></p> 
 <p>这个可以认为是我们的带隐变量的目标函数。</p> 
 <p>对目标函数求梯度：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/bc/03/Fqdn4FF2_o.png"></p> 
 <p><br>用N次蒙特卡洛采用(抛银币)来近似：<br></p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/65/72/gP0xypgP_o.png"></p> 
 <p>在用蒙特卡洛方法估计梯度时可以用滑动平均来减小梯度的方差。在第k个mini-batch时，滑动平均被估计为先前对数似然伴随指数衰减的累加和：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/72/7c/iad3pDrK_o.png"></p> 
 <p><strong>总结</strong></p> 
 <p>总的来说，这里率先引入了soft attention与hard attention，通过在每一时刻给图片各个区域分配attention权重，来提升语句与特定图块的相关性。</p> 
 <p>结果：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/f4/f5/xtQJoRef_o.png" style="width: 677px"><br><br></p> 
 <p><strong>Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</strong></p> 
 <p>本文可以算是第一篇在seq2seq中引入的Attention的论文(2015.07)</p> 
 <img src="https://images2.imgbox.com/0e/73/qwWAwI3t_o.png" style="width: 677px"> 
 <p>本文同样涉及了soft attention，hard attention。求解形式与上一篇并无差异。</p> 
 <p>并且文中考虑了四种应用场景：1. Neural Machine Translation ；2. Image Caption Generation ；3. Video Description Generation ；4. End-to-End Neural Speech Recognition。<br><br></p> 
 <p><strong>Effective Approaches to Attention-based Neural Machine Translation</strong></p> 
 <p>本文比上一篇晚发表了2个月。。。</p> 
 <p>文章提出了两种attention的改进版本，即global attention和local attention。</p> 
 <ol><li><p>global attention</p></li></ol> 
 <p>global attention 在计算context vector  
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 738.3 599.8" style="vertical-align: -0.357ex;width: 1.67ex;height: 1.357ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path> 
      </g> 
      <g transform="translate(433, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>的时候会考虑encoder所产生的全部hidden state。其实就是第一篇文章的attetion方法。</p> 
 <img src="https://images2.imgbox.com/3b/f5/lqmGpNCl_o.png" style="width: 677px"> 
 <p>    2.local attention</p> 
 <p>本文认为local attention为hard attention和soft attention的混合体(优势上的混合)，因为他的计算复杂度要低于global attention，soft attention，而且与hard attention 不同的是，local attention 几乎处处可微，易于训练。</p> 
 <p>local attention克服了每个source hidden state都要扫描的缺点，计算开销大，而且对于长句不利，为了提升效率，提出了 local attention。每次只focus 一部分的source position。</p> 
 <p>这里 context vector  
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 738.3 599.8" style="vertical-align: -0.357ex;width: 1.67ex;height: 1.357ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path> 
      </g> 
      <g transform="translate(433, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>的计算只focus窗口 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -750 6718.1 1000" style="vertical-align: -0.566ex;width: 15.199ex;height: 2.262ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(278, 0)"> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1308.5, 0)"> 
      <path d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path> 
     </g> 
     <g transform="translate(2308.7, 0)"> 
      <path d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path> 
     </g> 
     <g transform="translate(3136.7, 0)"> 
      <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
     </g> 
     <g transform="translate(3581.4, 0)"> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
     <g transform="translate(4611.9, 0)"> 
      <path d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path> 
     </g> 
     <g transform="translate(5612.1, 0)"> 
      <path d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path> 
     </g> 
     <g transform="translate(6440.1, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>内的2D+1个source hidden state。设 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 808.3 636" style="vertical-align: -0.439ex;width: 1.829ex;height: 1.439ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>是一个source position index，可以理解为 attention的“焦点”，作为模型的参数，D根据经验来选择。</p> 
 <p>关于 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 808.3 636" style="vertical-align: -0.439ex;width: 1.829ex;height: 1.439ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>的计算，文章给出了两种计算方案：</p> 
 <p>1） Monotonic alignment(local-m)</p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -626 2502.8 820" style="-webkit-overflow-scrolling: touch;vertical-align: -0.439ex;width: 5.662ex;height: 1.855ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1086, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(2141.8, 0)"> 
      <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p>2)predictive alignment(local-p)</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/ef/34/Mcn3Ezza_o.png"></p> 
 <p>其中 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -683 1349.7 970.2" style="vertical-align: -0.65ex;width: 3.054ex;height: 2.195ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path> 
      </g> 
      <g transform="translate(944, -150) scale(0.707)"> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>和 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -443 890.7 730.2" style="vertical-align: -0.65ex;width: 2.015ex;height: 1.652ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path> 
      </g> 
      <g transform="translate(485, -150) scale(0.707)"> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>是模型的参数，S是source sentence的长度，易知 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -750 4144.5 1000" style="vertical-align: -0.566ex;width: 9.377ex;height: 2.262ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1086, 0)"> 
      <path d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path> 
     </g> 
     <g transform="translate(2030.8, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(2308.8, 0)"> 
      <path d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path> 
     </g> 
     <g transform="translate(2808.8, 0)"> 
      <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
     </g> 
     <g transform="translate(3253.5, 0)"> 
      <path d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path> 
     </g> 
     <g transform="translate(3866.5, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>.<br></p> 
 <p>权重 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -750 2192.3 1000" style="vertical-align: -0.566ex;width: 4.96ex;height: 2.262ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M34 156Q34 270 120 356T309 442Q379 442 421 402T478 304Q484 275 485 237V208Q534 282 560 374Q564 388 566 390T582 393Q603 393 603 385Q603 376 594 346T558 261T497 161L486 147L487 123Q489 67 495 47T514 26Q528 28 540 37T557 60Q559 67 562 68T577 70Q597 70 597 62Q597 56 591 43Q579 19 556 5T512 -10H505Q438 -10 414 62L411 69L400 61Q390 53 370 41T325 18T267 -2T203 -11Q124 -11 79 39T34 156ZM208 26Q257 26 306 47T379 90L403 112Q401 255 396 290Q382 405 304 405Q235 405 183 332Q156 292 139 224T121 120Q121 71 146 49T208 26Z"></path> 
      </g> 
      <g transform="translate(640, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
     <g transform="translate(945.3, 0)"> 
      <path d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path> 
     </g> 
     <g transform="translate(1334.3, 0)"> 
      <path d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path> 
     </g> 
     <g transform="translate(1803.3, 0)"> 
      <path d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>的计算为：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a3/e1/pIQoMbuY_o.png"></p> 
 <p>可以看出，距离中心 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -442 808.3 636" style="vertical-align: -0.439ex;width: 1.829ex;height: 1.439ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path> 
      </g> 
      <g transform="translate(503, -150) scale(0.707)"> 
       <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>越远的位置，其位置上的source hidden state 对应的权重就会被压缩地越厉害。这里 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -431 571 442" style="vertical-align: -0.025ex;width: 1.292ex;height: 1ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <path d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>设置为D/2。</p> 
 <p>这里的，</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/b6/4c/aIWLFpE2_o.png"></p> 
 <p>其中score函数其实就是第一篇里介绍的对齐函数，存在三种dot product，general，concat。</p> 
 <p>实验对比：</p> 
 <img src="https://images2.imgbox.com/cd/dc/Mf5UoVXk_o.png" style="width: 677px"> 
 <p><strong>Attention-Based Multi-Perspective Convolutional Neural Networks for Textual Similarity Measurement</strong></p> 
 <p>本文的任务是STS(semantic textual similarity)指给定一个检索句子和比较的句子，计算他们的相似度得分。<br></p> 
 <img src="https://images2.imgbox.com/56/0b/Y9XqZ00h_o.png" style="width: 677px"> 
 <p>过去的模型，把输入的句子独立对待，忽略了句子的上下文交互。attention也就是因此而引入的。</p> 
 <p>本文的基础模型结构是：MPCNN(multi-perspective con- volutional neural network model)，主要包括两个部分：1，multi-perspective sentence model；2， structured similarity measurement layer。</p> 
 <ol><li><p>multi-perspective sentence model</p></li></ol> 
 <p>multi-perspective sentence model 使用的是卷积神经网络，通过使用不同类型的卷积核，不同类型的池化方式，不同大小的卷积窗口，来得到每个句子的不同粒度的表达。</p> 
 <p>a. 卷积层有两种卷积的方式：(1)粒度为word的卷积；(2)粒度为embedding 维度上的卷积。前者相当于n-gram特征抽取，后者抽取的是向量每一维度上的信息。作者认为后面这种方式由于粒度更小有助于充分地提取出输入的特征信息。作者使用了这两种方式以获得更丰富的表达。</p> 
 <p>b. 卷积窗口大小：不同卷积窗口的大小捕捉不同n-gram的长度下的信息，这里窗口大小是{1, 2, 3，∞}, 表示输入句子中unigrams, bigrams, trigrams和不使用卷积层。</p> 
 <p>c. 池化方式：池化层可以保留一个卷积模型中最显著和最通用的特性，这里使用max，min，mean三种方式。</p> 
 <ol><li><p>Structured Similarity Measurement layer</p></li></ol> 
 <p>Structured Similarity Measurement Layer的目标是计算句子表达的相似度。</p> 
 <p>Structured Similarity Measurement Layer的目标是计算句子表达的相似度。作者认为最后生成的句子向量中的每一个部分的意义各不相同，直接应用传统的相似度计算方法如余弦相似度在两个句子向量上并不是最优的，应该对句子向量中的各个部分进行相应的比较和计算(Structured Comparision)。为了使得句子向量中的局部间的比较和计算更加有效，我们需要考虑如下方面：</p> 
 <p>(1) 是否来自相同的building block；(2) 是否来自相同卷积窗口大小下的卷积结果；(3) 是否来自相同的pooling层；(4) 是否来自相同的Feature Map；</p> 
 <p>至少满足以上两个条件时，才比较句子中的相应部分时，作者采用了两种算法比较相似性。一种只针对粒度为词的卷积，另一种则同时针对粒度为词的卷积和粒度为embedding 维度上的卷积。</p> 
 <p>在句子局部的相似度计算之后，作者叠加了两层的线性层，并在中间使用了tanh激活函数，最后使用log-softmax输出。更多的细节参考He et al. 2015。</p> 
 <p><strong>Attention-Based Input Interaction Layer</strong></p> 
 <p>本文作者在上述模型的基础上，增加了一层基于attention的交互层。其目的就是在刚做完embedding以后，给两个句子更相关的部分赋予更多的权值。</p> 
 <p>输入序列 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -853.7 4080.1 893.7" style="vertical-align: -0.09ex;width: 9.231ex;height: 2.022ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path> 
      </g> 
      <g transform="translate(613, 363) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1184.7, 0)"> 
      <path d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path> 
     </g> 
     <g transform="translate(2129.5, 0)"> 
      <g> 
       <path d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path> 
      </g> 
      <g transform="translate(759, 363) scale(0.707)"> 
       <g> 
        <g> 
         <path d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path> 
        </g> 
        <g transform="translate(298, -150) scale(0.714)"> 
         <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
        </g> 
       </g> 
       <g transform="translate(594.5, 0)"> 
        <path d="M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z"></path> 
       </g> 
       <g transform="translate(1094.5, 0)"> 
        <path d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path> 
       </g> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>,其中 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -666 3012.2 860" style="vertical-align: -0.439ex;width: 6.815ex;height: 1.946ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
     </g> 
     <g transform="translate(622.8, 0)"> 
      <path d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path> 
     </g> 
     <g transform="translate(1567.6, 0)"> 
      <path d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path> 
     </g> 
     <g transform="translate(2067.6, 0)"> 
      <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
     </g> 
     <g transform="translate(2512.2, 0)"> 
      <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg>,铜鼓计算对应向量的余弦相似度得到attention。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/a5/0d/gWWeOXTL_o.png"></p> 
 <p>得到了attention权值矩阵后，可以计算每个句子对应的attention向量，并归一化：</p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -950 8068.8 2165.5" style="-webkit-overflow-scrolling: touch;vertical-align: -2.75ex;width: 18.255ex;height: 4.899ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path> 
      </g> 
      <g transform="translate(738, 413) scale(0.707)"> 
       <path d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1141.6, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(1419.6, 0)"> 
      <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
     </g> 
     <g transform="translate(1948.6, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
     <g transform="translate(2504.3, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(3560.1, 0)"> 
      <g> 
       <path d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path> 
      </g> 
      <g transform="translate(570.3, -1107.7) scale(0.707)"> 
       <path d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path> 
      </g> 
     </g> 
     <g transform="translate(5170.8, 0)"> 
      <path d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path> 
     </g> 
     <g transform="translate(5998.8, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(6276.8, 0)"> 
      <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
     </g> 
     <g transform="translate(6805.8, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
     <g transform="translate(7083.8, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(7361.8, 0)"> 
      <path d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path> 
     </g> 
     <g transform="translate(7790.8, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -950 7968.8 2107.1" style="-webkit-overflow-scrolling: touch;vertical-align: -2.618ex;width: 18.029ex;height: 4.767ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path> 
      </g> 
      <g transform="translate(738, 413) scale(0.707)"> 
       <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1141.6, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(1419.6, 0)"> 
      <path d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path> 
     </g> 
     <g transform="translate(1848.6, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
     <g transform="translate(2404.3, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(3460.1, 0)"> 
      <g> 
       <path d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path> 
      </g> 
      <g transform="translate(535, -1050) scale(0.707)"> 
       <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
      </g> 
     </g> 
     <g transform="translate(5070.8, 0)"> 
      <path d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path> 
     </g> 
     <g transform="translate(5898.8, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(6176.8, 0)"> 
      <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
     </g> 
     <g transform="translate(6705.8, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
     <g transform="translate(6983.8, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(7261.8, 0)"> 
      <path d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path> 
     </g> 
     <g transform="translate(7690.8, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -880.4 8031.5 1130.4" style="-webkit-overflow-scrolling: touch;vertical-align: -0.566ex;width: 18.171ex;height: 2.557ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path> 
      </g> 
      <g transform="translate(750, 413) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
     <g transform="translate(1321.7, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(2377.5, 0)"> 
      <path d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path> 
     </g> 
     <g transform="translate(2846.5, 0)"> 
      <path d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path> 
     </g> 
     <g transform="translate(3331.5, 0)"> 
      <path d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path> 
     </g> 
     <g transform="translate(3881.5, 0)"> 
      <path d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path> 
     </g> 
     <g transform="translate(4242.5, 0)"> 
      <path d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path> 
     </g> 
     <g transform="translate(5120.5, 0)"> 
      <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
     </g> 
     <g transform="translate(5649.5, 0)"> 
      <path d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path> 
     </g> 
     <g transform="translate(6221.5, 0)"> 
      <path d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path> 
     </g> 
     <g transform="translate(6610.5, 0)"> 
      <g> 
       <path d="M492 213Q472 213 472 226Q472 230 477 250T482 285Q482 316 461 323T364 330H312Q311 328 277 192T243 52Q243 48 254 48T334 46Q428 46 458 48T518 61Q567 77 599 117T670 248Q680 270 683 272Q690 274 698 274Q718 274 718 261Q613 7 608 2Q605 0 322 0H133Q31 0 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H757Q764 676 764 669Q764 664 751 557T737 447Q735 440 717 440H705Q698 445 698 453L701 476Q704 500 704 528Q704 558 697 578T678 609T643 625T596 632T532 634H485Q397 633 392 631Q388 629 386 622Q385 619 355 499T324 377Q347 376 372 376H398Q464 376 489 391T534 472Q538 488 540 490T557 493Q562 493 565 493T570 492T572 491T574 487T577 483L544 351Q511 218 508 216Q505 213 492 213Z"></path> 
      </g> 
      <g transform="translate(738, 413) scale(0.707)"> 
       <path d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path> 
      </g> 
     </g> 
     <g transform="translate(7642.5, 0)"> 
      <path d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p>最后拼接起来得到attention 的re-weighted向量：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/12/67/vgg0dHvw_o.png"></p> 
 <p>作者没有添加额外的参数，只是简单的余弦距离去作为attention权值然后做归一化，并在实验中取得了不错的结果。</p> 
 <p><strong>ABCNN: Attention-Based Convolutional Neural Network for Modeling Sentence Pairs</strong></p> 
 <p>本文的任务是(sentence pair)句子配对。这包括了Answer Selection（AS），Paraphrase identification（PI），Textual entailment（TE）。</p> 
 <p>基础模型：BCNN(Basic Bi-CNN)。BCNN有四个部分：1. 输入层，2. 卷积层，3. 池化层，4. 输出层。特别要指出卷积层。这里卷积层采用的是宽卷积（Wide convolution）。即对句子的边缘部分进行，使得输出的序列长度大于输入的序列长度。(宽卷积常用于卷积核大小相对于输入向量长度较大时)</p> 
 <img src="https://images2.imgbox.com/6d/9b/qXGjqdmo_o.png" style="width: 677px"> 
 <p>这里提出了三种ABCNN</p> 
 <ol><li><p>ABCNN-1</p></li></ol> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/40/8d/OOVYhQZ5_o.png" style="width: 677px"></p> 
 <p>ttention 矩阵的计算：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/4f/3d/unFp9Gdw_o.png"></p> 
 <p>可以从上图看出矩阵中的一列代表一个词，行代表特征。</p> 
 <p>这里的match-score可以用多种方式进行计算，本文采用的是 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -864.9 3037.9 1411.3" style="vertical-align: -1.236ex;width: 6.873ex;height: 3.193ex;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g transform="translate(1342.2, 394) scale(0.707)"> 
       <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
      </g> 
      <g transform="translate(220, -370) scale(0.707)"> 
       <g> 
        <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
       </g> 
       <g transform="translate(500, 0)"> 
        <path d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path> 
       </g> 
       <g transform="translate(1278, 0)"> 
        <path d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path> 
       </g> 
       <g transform="translate(1556, 0)"> 
        <path d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path> 
       </g> 
       <g transform="translate(2128, 0)"> 
        <path d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path> 
       </g> 
       <g transform="translate(2906, 0)"> 
        <path d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path> 
       </g> 
       <g transform="translate(3396, 0)"> 
        <path d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path> 
       </g> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg>来计算。</p> 
 <p>句子中attention特征的计算：</p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -891.7 5596.1 1178.9" style="-webkit-overflow-scrolling: touch;vertical-align: -0.65ex;width: 12.661ex;height: 2.667ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path> 
      </g> 
      <g transform="translate(643, -150) scale(0.707)"> 
       <g> 
        <path d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path> 
       </g> 
       <g transform="translate(500, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(778, 0)"> 
        <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
       </g> 
      </g> 
     </g> 
     <g transform="translate(1895, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(2950.7, 0)"> 
      <g> 
       <path d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path> 
      </g> 
      <g transform="translate(944, -150) scale(0.707)"> 
       <path d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path> 
      </g> 
     </g> 
     <g transform="translate(4298.3, 0)"> 
      <g> 
       <path d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path> 
      </g> 
      <g transform="translate(750, 413) scale(0.707)"> 
       <path d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path> 
      </g> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -716 5048.3 1003.2" style="-webkit-overflow-scrolling: touch;vertical-align: -0.65ex;width: 11.421ex;height: 2.27ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z"></path> 
      </g> 
      <g transform="translate(643, -150) scale(0.707)"> 
       <g> 
        <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
       </g> 
       <g transform="translate(500, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(778, 0)"> 
        <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
       </g> 
      </g> 
     </g> 
     <g transform="translate(1895, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(2950.7, 0)"> 
      <g> 
       <path d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path> 
      </g> 
      <g transform="translate(944, -150) scale(0.707)"> 
       <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
      </g> 
     </g> 
     <g transform="translate(4298.3, 0)"> 
      <path d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p>这里的输出被送入到了卷积层。</p> 
 <ol><li><p>ABCNN-2</p></li></ol> 
 <p><img src="https://images2.imgbox.com/83/09/LFR6SeiD_o.png" style="width: 677px"></p> 
 <p>这里Attention矩阵的计算方式与ABCNN-1类似，不同的是在ABCNN-1的基础上对两个句子的unit进行求和作为unit的attention 值，即</p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -950 6805.3 1400" style="-webkit-overflow-scrolling: touch;vertical-align: -1.018ex;width: 15.397ex;height: 3.167ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
      </g> 
      <g transform="translate(529, -150) scale(0.707)"> 
       <g> 
        <path d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path> 
       </g> 
       <g transform="translate(500, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(778, 0)"> 
        <path d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path> 
       </g> 
      </g> 
     </g> 
     <g transform="translate(1698.2, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(2754, 0)"> 
      <path d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path> 
     </g> 
     <g transform="translate(4364.7, 0)"> 
      <path d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path> 
     </g> 
     <g transform="translate(5114.7, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(5392.7, 0)"> 
      <path d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path> 
     </g> 
     <g transform="translate(5804.7, 0)"> 
      <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
     </g> 
     <g transform="translate(6249.3, 0)"> 
      <path d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path> 
     </g> 
     <g transform="translate(6527.3, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p style="text-align: center"> 
  <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 -950 6805.3 1400" style="-webkit-overflow-scrolling: touch;vertical-align: -1.018ex;width: 15.397ex;height: 3.167ex;max-width: 300% !important;"> 
   <g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)"> 
    <g> 
     <g> 
      <g> 
       <path d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path> 
      </g> 
      <g transform="translate(529, -150) scale(0.707)"> 
       <g> 
        <path d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path> 
       </g> 
       <g transform="translate(500, 0)"> 
        <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
       </g> 
       <g transform="translate(778, 0)"> 
        <path d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path> 
       </g> 
      </g> 
     </g> 
     <g transform="translate(1698.2, 0)"> 
      <path d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path> 
     </g> 
     <g transform="translate(2754, 0)"> 
      <path d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path> 
     </g> 
     <g transform="translate(4364.7, 0)"> 
      <path d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path> 
     </g> 
     <g transform="translate(5114.7, 0)"> 
      <path d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path> 
     </g> 
     <g transform="translate(5392.7, 0)"> 
      <path d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path> 
     </g> 
     <g transform="translate(5670.7, 0)"> 
      <path d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path> 
     </g> 
     <g transform="translate(6115.3, 0)"> 
      <path d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path> 
     </g> 
     <g transform="translate(6527.3, 0)"> 
      <path d="M22 710V750H159V-250H22V-210H119V710H22Z"></path> 
     </g> 
    </g> 
   </g> 
  </svg></p> 
 <p>然后利用这个attention值对卷积层的输出进行加权，具体公式如下：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/d2/29/0fzH75io_o.png"></p> 
 <p>这里的输出输入到了pooling层中。</p> 
 <ol><li><p>ABCNN-3</p></li></ol> 
 <p>将上述两个结构进行叠加。在输入和池化都引入注意力。</p> 
 <p><img src="https://images2.imgbox.com/7b/47/OY11jzf1_o.png" style="width: 677px"></p> 
 <p>本文实际上提出了两种引入attention 的位置，一种是在Conv前(ABCNN-1),一种是Conv后(ABCNN-2)。从结果来看，Attention放在Conv后的效果比前面的效果更好。可能的原因是Word embedding经过Conv相当于提取了n-gram，能表示上下文。conv 之后再结合 Attention 能比单纯 input 之后的 Attention 包含更多的信息。</p> 
 <p><strong>Graph Attention Network(GAT)</strong></p> 
 <p><strong>小结1</strong></p> 
 <p>之后的一系列论文如《Multi-Attention CNN for FGVC：MA-CNN》,《Coupled Multi-Layer Attentions for Co-Extraction of Aspect and Opinion Terms》等尽管实现的任务都花里胡哨的，并引入了Attention，但是attention的使用方式还是千篇一律。</p> 
 <p><strong>Attention is all you need</strong></p> 
 <p>提出的动机：</p> 
 <ol><li><p>跳出原来千篇一律的attention形式，不使用CNN，不使用RNN，光靠attention，实现高并行化；</p></li><li><p>抓取更强的长距离依赖关系。</p></li></ol> 
 <p>创新点：</p> 
 <ol><li><p>总结了attention的通用形式；</p></li><li><p>提出了self attention，multi-head attention；</p></li><li><p>Transform结构。</p></li></ol> 
 <p><strong>总结Attention的通用格式</strong></p> 
 <p>作者将Attention理解为q，k，v的形式，</p> 
 <p><img src="https://images2.imgbox.com/94/ef/9RGzpSdc_o.png" style="width: 677px"></p> 
 <p>其实前面介绍的attention都可以套用该框架。</p> 
 <p><img src="https://images2.imgbox.com/87/11/TnHuq8VF_o.png" style="width: 677px"></p> 
 <p><strong>提出self attention, multi-head attention</strong></p> 
 <p>这里的self attention 指的是用到自身的信息来计算attention。传统的attention都是考虑用外部信息来计算attention。</p> 
 <p><img src="https://images2.imgbox.com/69/92/PCITLiSz_o.png" style="width: 677px"></p> 
 <p>这里采用的attention计算方式也与之前的不同，采用 Scaled Dot-Product 的形式。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/c6/44/mg7NAHLr_o.png"></p> 
 <p>注意：分母是为了归一化，避免造成进入softmax函数的饱和区，其梯度较小。</p> 
 <p>采用multi-head attention为的就是让不同head学习到不同的子空间语义。显然实验也证实这种形式的结果较好。</p> 
 <p><img src="https://images2.imgbox.com/b4/c9/5uRLhL3F_o.png" style="width: 677px"></p> 
 <p>在self attention中其实在做的当前文本句中单词依赖关系分数的计算。</p> 
 <p>比如“Think Machines”两个单词：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/75/f3/t7b82jIF_o.png" style="width: 677px"></p> 
 <p style="text-align: left">优点：</p> 
 <ol><li><p>由于self attention 是对整个文本句求attention的，所以他能抓取到当前单词和该文本句中所有单词的依赖关系强度。这方面的能力显然比RNN的获取长依赖的能力强大的多；</p></li><li><p>此时不在用RNN的这种串行模式，即每一步计算依赖于上一步的计算结果。因此可以像CNN一样并行处理，而CNN只能捕获局部信息，通过层叠获取全局联系增强视野。</p></li></ol> 
 <p>缺点：很显然，既是并行又能全局，但他不能捕捉语序顺序。这是很糟糕的，有点像词袋模型。因为相同单词不同词序的含义会有很大差别。为了克服这个问题，作者引入了Position embedding。这是后话了。</p> 
 <p><strong>Transform</strong></p> 
 <p>Transform是一大法宝，影响深远。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/c7/83/PStA50PL_o.png" style="width: 677px"></p> 
 <p>从上图粗看，Transform仍延续着一个Encoder一个Decoder的形式。</p> 
 <p>重要部件：</p> 
 <ol><li><p>Positional embedding。正如上面所说，self attention缺乏位置信息，这是不合理的。为了引入位置信息，这里用了一个部件position embedding。</p></li></ol> 
 <p>这里考虑每个token的position embedding的向量维度也是d维的，与input embedding的输出一样，然后将input embedding和position embedding 加起来组成最终的embedding输入到上面的encoder/decoder中去。这里的position embedding计算公式如下：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/89/a7/fqmomtH3_o.png"></p> 
 <p>其中pos表示位置的index，i表示dimension index。</p> 
 <p>Position Embedding本身是一个绝对位置的信息，但在语言中，相对位置也很重要，Google选择前述的位置向量公式的一个重要原因是：由于我们有</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/69/d9/6t3B9Vix_o.png"></p> 
 <p>这表明位置p+k的向量可以表示成位置p的向量的线性变换，这提供了表达相对位置信息的可能性。</p> 
 <ol><li><p>residual connection 。无论是encoder还是decoder，我们都能看到存在residual connection这种跳跃连接。</p></li></ol> 
 <p>随着深度的增加会导致梯度出现弥散或者爆炸，更为严重的是会导致模型退化 （也就是在训练集上性能饱和甚至下降，与过拟合不同）。深度残差网络就是为了解决退化的问题。其实引入残差连接，也是为了尽可能保留原始输入x的信息。</p> 
 <ol><li><p>Layer Normalization</p></li></ol> 
 <p>与 BN 不同，LN 是一种横向的规范化。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/05/5d/0wtcyYPP_o.png" style="width: 677px"></p> 
 <p>LN针对单个训练样本进行，不依赖于其他数据。避免了受mini batch中其他数据的影响。</p> 
 <p>BN适用于不同mini batch数据分布差异不大的情况，而且BN需要开辟变量存每个节点的均值和方差，空间消耗略大；而且 BN适用于有mini_batch的场景。</p> 
 <ol><li><p>Masked Multi-Head Attention</p></li></ol> 
 <p>这里用mask来遮蔽当前位置后面的单词。实现也很简单，采用一个上三角都为1，下三角为0的矩阵。</p> 
 <p><img src="https://images2.imgbox.com/65/66/G36uiRkh_o.png" style="width: 677px"></p> 
 <p>小结一下：本文对attention的概念进行了本质上的转变。传统的attention是在端尾计算源文本各个token对该时刻单词的贡献。而self attention将这个过程提到了端口，计算当前句子中token的相关性来充分各个token的表达其语义。简单的讲就是传统的attention是为了使输出端表达充分，而self attention 是为了使输入端表达充分。尽管他们的形式都可以用Q，K，V框架来解释。</p> 
 <p><strong>An Attentive Survey of Attention Models</strong></p> 
 <p>《An Attentive Survey of Attention Models》 是香农科技提出的一篇关于attention的综述论文。</p> 
 <p><img src="https://images2.imgbox.com/1c/a1/5x0PI2kZ_o.png" style="width: 677px"></p> 
 <p>本文给attention作出了分类，分为四种分类方法：</p> 
 <p>1，number of sequences</p> 
 <p>a)distinctive。只考虑了涉及单个输入和相应输出序列的情况（例如seq2seq中的attention）；</p> 
 <p>b)co-attention。同时对多个输入序列进行操作，并共同学习它们的注意权重，以捕获这些输入之间的交互（例如前面介绍的ABCNN）；</p> 
 <p>c)inner attention。使用注意力来学习输入序列中对应于相同输入序列中的每个标记的相关标记.(例如self attention)。</p> 
 <p>2，Number of abstraction levels</p> 
 <p>按照输入特征的抽象层次来分，这里的抽象层次可以是词粒度、短语粒度、句子粒度、文档粒度。</p> 
 <p>a)single-level。只为原始输入序列计算注意权重；</p> 
 <p>b)multi-level。注意力可以按顺序应用于输入序列的多个抽象层次[例如在两个不同的抽象层次（即单词级别和句子级别）上使用了注意力模型来完成文档分类任务]。</p> 
 <p>3，Number of positions</p> 
 <p> a)soft attention。它使用输入序列所有隐藏状态的加权平均值来构建上下文向量；</p> 
 <p>b)hard attention。其中上下文向量是从输入序列中随机采样的隐藏状态计算出来的；</p> 
 <p>c)global attention。与soft attention一样；</p> 
 <p>d)local attention。是hard attention和soft attention的一种折中。</p> 
 <p>4，Number of representations</p> 
 <p>a)multi-Representational Attention model。通过多个特征表示捕捉输入的不同方面,注意可以用来为这些不同的表示分配重要权重，这些表示可以确定最相关的方面，而忽略输入中的噪声和冗余；</p> 
 <p>b)multi-dimensional。这种attention 作用在维度上，attention的权重表示各个维度上的重要性。</p> 
 <p><img src="https://images2.imgbox.com/b4/55/3GvArMwZ_o.png" style="width: 677px"></p> 
 <p>然后作者又对带有attention的网络结构进行饿了分类。</p> 
 <p>1，Encoder-Decoder</p> 
 <p>2，Memory Networks</p> 
 <p>像问答和聊天机器人这样的应用程序需要能够从事实数据库中的信息中学习。网络的输入是一个知识数据库和一个查询，其中一些事实比其他事实更与查询相关。端到端memory networks通过使用一组内存块存储事实数据库来实现这一点，并使用attention在回答查询时在内存中为每个事实建立关联模型。</p> 
 <p>使用attention还提供了计算优势，使目标连续，并通过反向传播支持端到端训练。端到端内存网络可以看作是AM的一种泛化，它不是只在单个序列上建模注意力，而是在一个包含大量序列(事实)的数据库上建模注意力。</p> 
 <p>3，Networks without RNNs 最具代表性的就是Transformer。</p> 
 <p><strong>未完待续</strong></p> 
 <p>其实还有很多要补充的，比如Memory Network中的attention(外部记忆作为V)以及Graph neural network里的attention，尽管理论上都是一个道理，但是还要对的起标题的all。待补充。</p> 
 <p style="text-align: center"><em><strong>——</strong><strong>END</strong><strong>——</strong></em></p> 
 <p style="text-align: center"><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><img src="https://images2.imgbox.com/c4/ea/1HUFReWV_o.png" height="393" width="640" style="width: 677px"></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></p> 
 <p style="text-align: center"><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><em><img src="https://images2.imgbox.com/8a/5c/GDuwiSP6_o.png" height="241" width="640" style="height: 241px"></em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></em></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b1d0e2cd3de3b2d0d3b2a94dcf944dd8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">英特尔AI医疗实战曝光：10倍加速辅助诊断、准确度高达90%</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1250d7ed1f53484e61691dc491d9abe6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">报名丨 “中国的城市化、数字技术和创新市场” ——清华大学-麻省理工学院联合训练营开始招募啦...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>