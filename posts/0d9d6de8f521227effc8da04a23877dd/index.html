<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习代码篇（pytorch实现） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习代码篇（pytorch实现）" />
<meta property="og:description" content="文章目录 一、Dataset加载数据——获取数据及其label二、tensorboard的使用1. add_image()函数——显示image2. add_scalar()函数——显示函数 三、torchvision中transform.py的使用三、torchvision中数据集的使用四、Dataloader打包压缩——为网络提供不同的数据形式五、神经网络1. 神经网络基本骨架(简单使用)2. 卷积层(convolution layers)3. 最大池化的使用(pooling layers)4. 非线性激活(Non-linear Activations)relusigmoid 5. 线性层(Linear Layers)（全连接层）6. 搭建网络7. 通过 torch.nn.Sequential 使得网络搭建代码更加简洁8. loss function9. 优化器10. 在pytorch提供的网络模型的基础上进行修改10. 网络模型的保存和读取保存方式1保存方式2 六、完整模型的训练套路GPU加速训练 七、完整模型的验证套路 一、Dataset加载数据——获取数据及其label from torch.utils.data import Dataset from PIL import Image import os class MyData(Dataset): def __init__(self,root_dir,label_dir): self.root_dir = root_dir self.label_dir = label_dir self.path = os.path.join(self.root_dir,self.label_dir) #传递的是图片的相对地址 self.img_path_list = os.listdir(self.path) #将相对地址变为列表形式（可按index找指定的图像） def __getitem__(self, idx): img_name = self.img_path_list[idx] #图像名字 img_item = os.path.join(self.root_dir,self.label_dir,img_name) #图像全貌（相对地址要具体到单张图片） img = Image.open(img_item) label = self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0d9d6de8f521227effc8da04a23877dd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-10T17:13:32+08:00" />
<meta property="article:modified_time" content="2022-10-10T17:13:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习代码篇（pytorch实现）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Datasetlabel_4" rel="nofollow">一、Dataset加载数据——获取数据及其label</a></li><li><a href="#tensorboard_41" rel="nofollow">二、tensorboard的使用</a></li><li><ul><li><a href="#1_add_imageimage_42" rel="nofollow">1. add_image()函数——显示image</a></li><li><a href="#2_add_scalar_68" rel="nofollow">2. add_scalar()函数——显示函数</a></li></ul> 
  </li><li><a href="#torchvisiontransformpy_78" rel="nofollow">三、torchvision中transform.py的使用</a></li><li><a href="#torchvision_142" rel="nofollow">三、torchvision中数据集的使用</a></li><li><a href="#Dataloader_165" rel="nofollow">四、Dataloader打包压缩——为网络提供不同的数据形式</a></li><li><a href="#_193" rel="nofollow">五、神经网络</a></li><li><ul><li><a href="#1__194" rel="nofollow">1. 神经网络基本骨架(简单使用)</a></li><li><a href="#2_convolution_layers_211" rel="nofollow">2. 卷积层(convolution layers)</a></li><li><a href="#3_pooling_layers_262" rel="nofollow">3. 最大池化的使用(pooling layers)</a></li><li><a href="#4_Nonlinear_Activations_335" rel="nofollow">4. 非线性激活(Non-linear Activations)</a></li><li><ul><li><a href="#relu_336" rel="nofollow">relu</a></li><li><a href="#sigmoid_367" rel="nofollow">sigmoid</a></li></ul> 
   </li><li><a href="#5_Linear_Layers_372" rel="nofollow">5. 线性层(Linear Layers)（全连接层）</a></li><li><a href="#6__404" rel="nofollow">6. 搭建网络</a></li><li><a href="#7__torchnnSequential__466" rel="nofollow">7. 通过 torch.nn.Sequential 使得网络搭建代码更加简洁</a></li><li><a href="#8_loss_function_494" rel="nofollow">8. loss function</a></li><li><a href="#9__535" rel="nofollow">9. 优化器</a></li><li><a href="#10_pytorch_586" rel="nofollow">10. 在pytorch提供的网络模型的基础上进行修改</a></li><li><a href="#10__642" rel="nofollow">10. 网络模型的保存和读取</a></li><li><ul><li><a href="#1_643" rel="nofollow">保存方式1</a></li><li><a href="#2_656" rel="nofollow">保存方式2</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_670" rel="nofollow">六、完整模型的训练套路</a></li><li><ul><li><a href="#GPU_834" rel="nofollow">GPU加速训练</a></li></ul> 
  </li><li><a href="#_840" rel="nofollow">七、完整模型的验证套路</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="Datasetlabel_4"></a>一、Dataset加载数据——获取数据及其label</h2> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> Dataset
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> os
<span class="token keyword">class</span> <span class="token class-name">MyData</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>root_dir<span class="token punctuation">,</span>label_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>root_dir <span class="token operator">=</span> root_dir
        self<span class="token punctuation">.</span>label_dir <span class="token operator">=</span> label_dir
        self<span class="token punctuation">.</span>path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>label_dir<span class="token punctuation">)</span> <span class="token comment">#传递的是图片的相对地址</span>
        self<span class="token punctuation">.</span>img_path_list <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>self<span class="token punctuation">.</span>path<span class="token punctuation">)</span> <span class="token comment">#将相对地址变为列表形式（可按index找指定的图像）</span>
    <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> idx<span class="token punctuation">)</span><span class="token punctuation">:</span>
        img_name <span class="token operator">=</span> self<span class="token punctuation">.</span>img_path_list<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token comment">#图像名字</span>
        img_item <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">.</span>root_dir<span class="token punctuation">,</span>self<span class="token punctuation">.</span>label_dir<span class="token punctuation">,</span>img_name<span class="token punctuation">)</span> <span class="token comment">#图像全貌（相对地址要具体到单张图片）</span>
        img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_item<span class="token punctuation">)</span>
        label <span class="token operator">=</span> self<span class="token punctuation">.</span>label_dir
        <span class="token keyword">return</span> img<span class="token punctuation">,</span>label
    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path_list<span class="token punctuation">)</span>

root_dir <span class="token operator">=</span> <span class="token string">"dataset1/train"</span>
ants_dir <span class="token operator">=</span> <span class="token string">"ants"</span>
bees_dir <span class="token operator">=</span> <span class="token string">"bees"</span>
ant_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>ants_dir<span class="token punctuation">)</span>
bees_dataset <span class="token operator">=</span> MyData<span class="token punctuation">(</span>root_dir<span class="token punctuation">,</span>bees_dir<span class="token punctuation">)</span>
train_dataset <span class="token operator">=</span> ant_dataset <span class="token operator">+</span> bees_dataset

<span class="token keyword">print</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
img<span class="token punctuation">,</span>label <span class="token operator">=</span> train_dataset<span class="token punctuation">[</span><span class="token number">124</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span>
img<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>结果：<code>(&lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x333 at 0x1D5A0687610&gt;, 'bees')</code><br> <code>'bees'</code></p> 
<p><code>class MyData(Dataset):</code>表示这个类继承括号中的类，并且要求重写类内函数。<br> 在类的函数中含self. 的都是新建的属性</p> 
<h2><a id="tensorboard_41"></a>二、tensorboard的使用</h2> 
<h3><a id="1_add_imageimage_42"></a>1. add_image()函数——显示image</h3> 
<p>要想在tensor中查看图像，要在虚拟环境中输入：tensorboard --logdir=logs打开网址即可</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter <span class="token comment">#载入SummaryWriter类</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token comment">#调用该类中函数 生成的事件文件 存到logs这个文件夹(和py文件在同一目录下)中</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span> <span class="token comment">#用SummaryWriter类初始化对象</span>
image_path <span class="token operator">=</span> <span class="token string">"dataset1/train/ants/0013035.jpg"</span> <span class="token comment">#相对地址</span>
image_PIV<span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span> <span class="token comment">#打开图像（PIV(pic)类型）</span>

img_numpy <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>image_PIV<span class="token punctuation">)</span> <span class="token comment">#转换为numpy类型</span>
<span class="token comment">#或者这么获得numpy类型</span>
<span class="token comment"># import cv2</span>
<span class="token comment"># image_path = "dataset/train/ants/0013035.jpg"</span>
<span class="token comment"># img_numpy = cv2.imread(img_path) #生成numpy类型的img，传递的参数为相对地址</span>
<span class="token comment">#或者利用totensor转换为tensor型再传参</span>

<span class="token comment">#在tensorboard中显示图像</span>
<span class="token comment">#图像名,numpy型或者tensor型，step（前为numpy型才加上dataformats='HWC')</span>
writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">"image"</span><span class="token punctuation">,</span>img_numpy<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span>dataformats<span class="token operator">=</span><span class="token string">'HWC'</span><span class="token punctuation">)</span> 
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><strong>SummaryWriter类中的add_image()函数中传的参数是numpy类型或者tensor类型，不能是pil类型。</strong></p> 
<h3><a id="2_add_scalar_68"></a>2. add_scalar()函数——显示函数</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter <span class="token comment">#载入SummaryWriter类</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"logs"</span><span class="token punctuation">)</span> 
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#在tensorboard中显示函数</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"y=x"</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token operator">*</span>i<span class="token punctuation">,</span>i<span class="token punctuation">)</span>  <span class="token comment">#函数名，y，x</span>
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="torchvisiontransformpy_78"></a>三、torchvision中transform.py的使用</h2> 
<p><strong>transfrom对象中传的参数可以是 tensor类型，也可以是pil类型</strong></p> 
<p>头文件及初始定义：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms
img_path <span class="token operator">=</span> <span class="token string">"dataset1/train/bees/16838648_415acd9e3f.jpg"</span>
img_PIV <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span><span class="token comment">#（PIV(pic)类型）</span>
</code></pre> 
<ol><li>totensor，作用是使得pic或者numpy型 转换为tensor型</li></ol> 
<pre><code class="prism language-python"><span class="token comment">#实例化对象（transforms.py中的ToTensor类）</span>
totensor_ob <span class="token operator">=</span> transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span> 
<span class="token comment">#隐含方式 调用内置函数（可按citrl+p查看参数类型）（参数为piv类型）</span>
img_tensor <span class="token operator">=</span> totensor_ob<span class="token punctuation">(</span>img_PIV<span class="token punctuation">)</span>
</code></pre> 
<ol start="2"><li>Normalize 归一化</li></ol> 
<pre><code class="prism language-python"><span class="token comment">#每个通道的均值，每个通道的标准差（彩色图一般为3个通道数）</span>
norm_ob <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
<span class="token comment">#参数为tensor类型</span>
img_norm <span class="token operator">=</span> norm_ob<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>img_tensor<span class="token punctuation">)</span> 
<span class="token comment">#在tensor中显示</span>
<span class="token comment"># writer = SummaryWriter("logs")</span>
<span class="token comment"># writer.add_image("normalize",img_tensor,0)</span>
<span class="token comment"># writer.close()</span>
</code></pre> 
<ol start="3"><li>resize用法1</li></ol> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>img_PIV<span class="token punctuation">.</span>size<span class="token punctuation">)</span> <span class="token comment">#原先的 图片尺寸</span>
resize1_ob <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span><span class="token number">512</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#(高度，宽度)</span>
img_resize1 <span class="token operator">=</span> resize1_ob<span class="token punctuation">(</span>img_PIV<span class="token punctuation">)</span> <span class="token comment">#参数为pil类型（也可以为tensor）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>img_resize1<span class="token punctuation">)</span> <span class="token comment">#输出重置尺寸之后的 图片参数</span>
</code></pre> 
<p><strong>结果：</strong></p> 
<pre><code class="prism language-python"><span class="token punctuation">(</span><span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">450</span><span class="token punctuation">)</span><span class="token comment"># W H （宽度，高度）</span>
<span class="token operator">&lt;</span>PIL<span class="token punctuation">.</span>Image<span class="token punctuation">.</span>Image image mode<span class="token operator">=</span>RGB size<span class="token operator">=</span>512x512 at <span class="token number">0x14F0DB1C7C0</span><span class="token operator">&gt;</span>
</code></pre> 
<ol start="4"><li>resize用法2在Compose混合操作函数（之所以要用compose，是为了方便加入totensor函数，以便于在tensorboard中显示图像）</li></ol> 
<pre><code class="prism language-python"><span class="token comment">#在之前尺寸的基础上等比缩放</span>
resize2_ob <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span> <span class="token comment">#256匹配w和h较小的那个数，然后另外一个数根据比例缩放</span>
<span class="token comment">#参数为transforms类型（对象）的列表</span>
compose_ob1 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>resize2_ob<span class="token punctuation">,</span>totensor_ob<span class="token punctuation">]</span><span class="token punctuation">)</span>
img_resize2 <span class="token operator">=</span> compose_ob1<span class="token punctuation">(</span>img_PIV<span class="token punctuation">)</span> <span class="token comment">#参数为pil类型（也可以为tensor）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>img_resize2<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#输出等比缩放后的图片size,图片为tensor类型</span>
</code></pre> 
<p>结果：<code>torch.Size([3, 256, 284]) #CHW</code></p> 
<ol start="5"><li>randomcrop用在compose混合操作函数</li></ol> 
<pre><code class="prism language-python">random_ob <span class="token operator">=</span> transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">)</span> <span class="token comment">#将原图随机裁剪为（256*256）的尺寸或者传参(m，n)</span>
compose_ob2 <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>random_ob<span class="token punctuation">,</span>totensor_ob<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#实例化对象</span>
img_random <span class="token operator">=</span> compose_ob2<span class="token punctuation">(</span>img_PIV<span class="token punctuation">)</span> <span class="token comment">#参数为pil类型（也可以为tensor）</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>img_random<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#输出随即裁剪之后的图片size,图片为tensor类型</span>
</code></pre> 
<p>结果：<code>torch.Size([3, 256, 256])</code></p> 
<h2><a id="torchvision_142"></a>三、torchvision中数据集的使用</h2> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter

data_transform_ob <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#等号左边为transforms类型的对象</span>
<span class="token comment"># 数据集本身是piv类型，经过transform=data_transform_ob后，转换为tensor类型</span>
train_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_transform_ob<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#训练集</span>
test_set <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>data_transform_ob<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#测试集</span>

<span class="token comment">#生成的事件文件存到pictures这个文件夹(和py文件在同一目录下)中</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"pictures"</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    img<span class="token punctuation">,</span>label <span class="token operator">=</span> test_set<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token comment">#将test_set[i]分离，得到tensor类型的img</span>
    writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">'test_set'</span><span class="token punctuation">,</span>img<span class="token punctuation">,</span>i<span class="token punctuation">)</span> <span class="token comment">#一个图象共10步</span>
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><code>img,label = test_set[i]</code>:<br> <strong>比如test_set[5]表示cifar10测试集中按顺序数第六个图片，这个图片可能是10种类型label图片中的任意一种，图片类型不同，label也就不同。</strong></p> 
<p><strong>test_set[5]为列表形式: [img的信息，label（为数字，一个数字表示一个类型）]</strong></p> 
<h2><a id="Dataloader_165"></a>四、Dataloader打包压缩——为网络提供不同的数据形式</h2> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token comment">#1. 载入数据集</span>
test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#2. 打包数据集</span>
<span class="token comment">#batch_size=64表示一次性抓取几个数据,shuffle=True表示第二轮抓取是否打乱，drop_last=False表示到最后不足batch_size的图片是否丢掉</span>
test_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token operator">=</span>test_data<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#3. tensorboard显示</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"loaderdata"</span><span class="token punctuation">)</span>
<span class="token comment">#第一轮抓取，每一次都随机抓取batch_size张图片进行打包。</span>
step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"test1"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>
    step <span class="token operator">=</span> step<span class="token operator">+</span><span class="token number">1</span>
<span class="token comment">#第二轮抓取</span>
step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> test_loader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"test2"</span><span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> step<span class="token punctuation">)</span>
    step <span class="token operator">=</span> step <span class="token operator">+</span> <span class="token number">1</span>

writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>将数据进行打包之后，以batch_size=64为例，相当于数据集中的test_data[0[~test_data[63]（或64—127）为一组进行显示，</strong></p> 
<h2><a id="_193"></a>五、神经网络</h2> 
<h3><a id="1__194"></a>1. 神经网络基本骨架(简单使用)</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token comment">#神经网络的输入和输出，以及负责处理的类</span>
<span class="token keyword">class</span> <span class="token class-name">PXD</span> <span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#表示继承括号中的类</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> <span class="token builtin">input</span><span class="token operator">+</span><span class="token number">1</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#初始化对象</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token comment">#将1.0转换为tesor类型</span>
output <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
</code></pre> 
<p>结果：<code>tensor(2.)</code></p> 
<h3><a id="2_convolution_layers_211"></a>2. 卷积层(convolution layers)</h3> 
<ol><li>torch.Size中的各个参数：<br> torch.Size(batch_size,通道数，尺寸，尺寸)（NCHW）</li><li>只有三通道及以下的图片才可以被显示出来。</li><li>多通道转为少通道时，batch_size会增多</li><li><strong>卷积之后，图像尺寸会变小（因为padding设置为0即不填充），若填充，则保持原尺寸</strong></li><li><strong>卷积层的stride默认为1</strong></li><li><strong>卷积核 通道数 = 卷积 输入层 的 通道数<br> 卷积核 个数 = 卷积 输出层 通道数(深度)</strong><br> 在卷积层的计算中，假设输入是H x W x C, C是输入的深度(即通道数)，那么卷积核(滤波器)的通道数需要和输入的通道数相同，所以也为C，假设卷积核的大小为K x K，一个卷积核就为K x K x C。<br> 计算时卷积核的对应通道应用于输入的对应通道，这样一个卷积核应用于输入就得到一个输出通道，假设有P个K x K x C的卷积核，这样每个卷积核应用于输入都会得到一个通道，所以会输出P个通道。<br> <img src="https://images2.imgbox.com/90/f2/LGx1173y_o.jpg" alt="在这里插入图片描述"></li></ol> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter

dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">#输入通道数，输出通道数，卷积核大小，步长，是否在周围进行数据填充</span>
        self<span class="token punctuation">.</span>cov1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">#根据条件可知，卷积核的通道数为3，个数为6</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>cov1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#实例化对象</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"cov"</span><span class="token punctuation">)</span>
step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
    output <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
    <span class="token comment"># print(imgs.shape) #torch.Size([64,3,32,32])</span>
    <span class="token comment"># print(output.shape) #torch.Size([64,6,30,30])</span>
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>
    output <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># batch_size自己算</span>
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span>
    step <span class="token operator">=</span> step<span class="token operator">+</span><span class="token number">1</span>
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><strong>tensorboard中的显示：</strong></p> 
<p><img src="https://images2.imgbox.com/97/31/fwdAL7zE_o.png" alt="在这里插入图片描述"><br> 卷积：可以通过改变 <strong>卷积核的个数</strong> 改变<strong>输出图片的通道数</strong>，还可以使得<strong>输出图片的尺寸变小</strong></p> 
<h3><a id="3_pooling_layers_262"></a>3. 最大池化的使用(pooling layers)</h3> 
<ol><li>ceil_mode有两种取整方式：floor向下取整（不保留），ceiling向上取整（保留）<br> ceil_mode默认为False,即为floor取整模式，ceil_mode为True时，为ceiling取整模式<br> 所谓保留和不保留指的是：池化核在input上移动时，如果覆盖不上kernel_size池化核大小的数字，那么就涉及到了保留还是不保留的问题。</li><li>池化层的stride默认不是1，而是kernel_size的值（池化核的大小）</li><li>池化后，图像尺寸减小（也可以通过设置padding使得尺寸保持不变），但是输出通道数不变，而卷积之后输出的通道数取决于卷积核的个数。</li></ol> 
<p><strong>代码示例1：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#stride默认为kernel_size，ceil_mode默认为False</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
</code></pre> 
<p><strong>结果：</strong></p> 
<pre><code class="prism language-python">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># ceil_mode=False</span>
tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">5.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#ceil_mode=True</span>
</code></pre> 
<p><strong>代码示例2：</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> MaxPool2d
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>ceil_mode<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span> <span class="token comment">#stride默认为kernel_size</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"maxpool"</span><span class="token punctuation">)</span>
step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"input"</span><span class="token punctuation">,</span>imgs<span class="token punctuation">,</span>step<span class="token punctuation">)</span>
    output <span class="token operator">=</span> pxd<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_images<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">,</span>output<span class="token punctuation">,</span>step<span class="token punctuation">)</span> <span class="token comment">#不用调整通道数</span>
    step <span class="token operator">=</span> step<span class="token operator">+</span><span class="token number">1</span>

writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>结果：</strong><br> <img src="https://images2.imgbox.com/c6/5e/fJghUSQs_o.png" alt="在这里插入图片描述"></p> 
<ol start="3"><li>最大池化后，不改变输出通道数，但图像尺寸变小。<br> input_size：(64,3,32,32)，3个pool_size:(-1,3,3,3),output_size:(64,3,11,11)</li></ol> 
<h3><a id="4_Nonlinear_Activations_335"></a>4. 非线性激活(Non-linear Activations)</h3> 
<h4><a id="relu_336"></a>relu</h4> 
<p>relu激活函数：小于0的返回0，大于0的返回input</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> ReLU <span class="token comment">#引入截断非线性激活函数</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                      <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#NCHW，-1表示自己计算batch_size</span>

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span> <span class="token comment">#默认为False，表示不就地处理，而是赋值给output</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p><strong>结果：</strong></p> 
<pre><code class="prism language-python">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">0.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
          <span class="token punctuation">[</span><span class="token number">0.</span><span class="token punctuation">,</span> <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="sigmoid_367"></a>sigmoid</h4> 
<p>sigmoid激活函数：output为0到1，为较平滑的范围。<br> 可以使得被处理后的图片亮度降低，失去高光。<br> 代码使用模式与relu相同</p> 
<h3><a id="5_Linear_Layers_372"></a>5. 线性层(Linear Layers)（全连接层）</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token comment">#线性层可以使得1</span>
dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span>drop_last<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span> <span class="token comment">#size of each input sample，size of each output sample</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
    imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
    <span class="token keyword">print</span><span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>   <span class="token comment">#torch.Size([64, 3, 32, 32])</span>
    output <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token comment">#torch.Size([64, 3, 32, 10]) NCHW</span>

</code></pre> 
<p>线性层的目的是：<br> 改变图像前后的宽度width，高度height不变<br> 矩阵中来看：改变的是列数（维数），行数不变<br> in_features为原图像的宽度（列数）<br> 线性层实质：<br> 将展平的特征行向量，经过全连接层后，改变了宽度（列数）（维度）</p> 
<h3><a id="6__404"></a>6. 搭建网络</h3> 
<p>要通过搭建网络完成如下操作：<br> <img src="https://images2.imgbox.com/45/33/HusJYphq_o.png" alt="在这里插入图片描述"><br> 计算padding要用到的公式：<br> <img src="https://images2.imgbox.com/aa/4b/c66BLDGz_o.png" alt="在这里插入图片描述"><br> 图片input在神经网络最后阶段，最后经过flatten()后，会被平展成为1行1024列的特征矩阵，高度H为1，宽度W为1024，在经过两个线性层，变为1行10列的特征矩阵。<br> <strong>注意：</strong><br> 输入input为图片，也具体化为x，图片的参数有像素，通道数等等。<br> 神经网络中有权重参数，为w，与input的像素点相乘，会被不断更新。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span>MaxPool2d<span class="token punctuation">,</span>Flatten<span class="token punctuation">,</span>Linear

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool1 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cov2 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool2 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>maxpool3 <span class="token operator">=</span> MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>flatten <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#平展</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>cov2<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool2<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool3<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pxd<span class="token punctuation">)</span>
<span class="token comment">#检验网络的正确性(不报错则证明正确)：</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p><strong>结果：</strong></p> 
<pre><code class="prism language-python">PXD<span class="token punctuation">(</span>
  <span class="token punctuation">(</span>model1<span class="token punctuation">)</span><span class="token punctuation">:</span> Sequential<span class="token punctuation">(</span>
    <span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span> MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> dilation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> ceil_mode<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Flatten<span class="token punctuation">(</span>start_dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> end_dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span> Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
  <span class="token punctuation">)</span>
<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span> 
</code></pre> 
<h3><a id="7__torchnnSequential__466"></a>7. 通过 torch.nn.Sequential 使得网络搭建代码更加简洁</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pxd<span class="token punctuation">)</span>
<span class="token comment">#检验网络的正确性(不报错则证明正确)：</span>
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
output <span class="token operator">=</span> pxd<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="8_loss_function_494"></a>8. loss function</h3> 
<p>作用1 ：计算实际输出和目标之间的差距<br> 作用2 ：为我们更新输出提供一定的依据（反向传播）</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> L1Loss<span class="token punctuation">,</span>MSELoss<span class="token punctuation">,</span>CrossEntropyLoss

inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span><span class="token number">2.</span><span class="token punctuation">,</span><span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#输入</span>
targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1.</span><span class="token punctuation">,</span><span class="token number">2.</span><span class="token punctuation">,</span><span class="token number">5.</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#目标</span>

inputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
targets <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>targets<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#1. L1Loss</span>
loss1 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#计算输入和目标差值的和的平均值</span>
result1 <span class="token operator">=</span> loss1<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result1<span class="token punctuation">)</span>
loss2 <span class="token operator">=</span> L1Loss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span> <span class="token comment">#计算输入和目标差值的和</span>
result2 <span class="token operator">=</span> loss2<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result2<span class="token punctuation">)</span>

<span class="token comment">#2. MSELoss</span>
loss3 <span class="token operator">=</span> MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#计算输入和目标方差的平均值</span>
result3 <span class="token operator">=</span> loss3<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result3<span class="token punctuation">)</span> 

<span class="token comment">#3. CrossEntropyLoss 交叉熵</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>x<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#1个batch_size，3类 (N,W)</span>
loss_cross <span class="token operator">=</span> CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
result4 <span class="token operator">=</span> loss_cross<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>result4<span class="token punctuation">)</span>
</code></pre> 
<p><strong>结果：</strong></p> 
<pre><code class="prism language-python">tensor<span class="token punctuation">(</span><span class="token number">0.6667</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">2.</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">1.3333</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">1.1019</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="9__535"></a>9. 优化器</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#这一步的目的是加载图片数据集，得到targets方便计算损失，得到imgs以便得到输出</span>
dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#初始化损失</span>
optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>pxd<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span> <span class="token comment">#选择优化器，参数：模型，学习率，不同优化器后面的参数不同</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#训练20轮</span>
    running_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
        outputs <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
        result_loss <span class="token operator">=</span> loss<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span> <span class="token comment">#计算损失</span>
        optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#梯度清零</span>
        result_loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#反向传播，更新参数</span>
        optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#优化器进行优化</span>
        running_loss <span class="token operator">=</span> running_loss <span class="token operator">+</span> result_loss
    <span class="token keyword">print</span><span class="token punctuation">(</span>running_loss<span class="token punctuation">)</span> <span class="token comment">#计算每一轮损失函数的值</span>
</code></pre> 
<p><strong>结果：</strong></p> 
<pre><code class="prism language-python">tensor<span class="token punctuation">(</span><span class="token number">360.3538</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">354.5248</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">334.0772</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token number">319.1064</span><span class="token punctuation">,</span> grad_fn<span class="token operator">=</span><span class="token operator">&lt;</span>AddBackward0<span class="token operator">&gt;</span><span class="token punctuation">)</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token comment">#可见，通过训练学习，损失越来越小，</span>
</code></pre> 
<h3><a id="10_pytorch_586"></a>10. 在pytorch提供的网络模型的基础上进行修改</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
vgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vgg16<span class="token punctuation">)</span>
<span class="token comment"># 结果：</span>
<span class="token comment"># VGG(</span>
<span class="token comment">#   (features): Sequential(</span>
<span class="token comment">#     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (1): ReLU(inplace=True)</span>
<span class="token comment">#     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (3): ReLU(inplace=True)</span>
<span class="token comment">#     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span>
<span class="token comment">#     (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (6): ReLU(inplace=True)</span>
<span class="token comment">#     (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (8): ReLU(inplace=True)</span>
<span class="token comment">#     (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span>
<span class="token comment">#     (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (11): ReLU(inplace=True)</span>
<span class="token comment">#     (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (13): ReLU(inplace=True)</span>
<span class="token comment">#     (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (15): ReLU(inplace=True)</span>
<span class="token comment">#     (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span>
<span class="token comment">#     (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (18): ReLU(inplace=True)</span>
<span class="token comment">#     (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (20): ReLU(inplace=True)</span>
<span class="token comment">#     (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (22): ReLU(inplace=True)</span>
<span class="token comment">#     (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span>
<span class="token comment">#     (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (25): ReLU(inplace=True)</span>
<span class="token comment">#     (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (27): ReLU(inplace=True)</span>
<span class="token comment">#     (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</span>
<span class="token comment">#     (29): ReLU(inplace=True)</span>
<span class="token comment">#     (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span>
<span class="token comment">#   )</span>
<span class="token comment">#   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))</span>
<span class="token comment">#   (classifier): Sequential(</span>
<span class="token comment">#     (0): Linear(in_features=25088, out_features=4096, bias=True)</span>
<span class="token comment">#     (1): ReLU(inplace=True)</span>
<span class="token comment">#     (2): Dropout(p=0.5, inplace=False)</span>
<span class="token comment">#     (3): Linear(in_features=4096, out_features=4096, bias=True)</span>
<span class="token comment">#     (4): ReLU(inplace=True)</span>
<span class="token comment">#     (5): Dropout(p=0.5, inplace=False)</span>
<span class="token comment">#     (6): Linear(in_features=4096, out_features=1000, bias=True)</span>
<span class="token comment">#   )</span>
<span class="token comment"># )</span>
</code></pre> 
<ol><li><code>vgg16.classifier.add_module('add_linear',nn.Linear(1000,10)) #通过添加线性层，使得分类减少（维数减少）</code></li><li><code>vgg16.classifier.add_module('add_linear',nn.Linear(1000,10)) #通过添加线性层，使得分类减少（维数减少）</code></li></ol> 
<h3><a id="10__642"></a>10. 网络模型的保存和读取</h3> 
<h4><a id="1_643"></a>保存方式1</h4> 
<p>保存：</p> 
<pre><code class="prism language-python">vgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#如果是自己写的网络模型,此步不写</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">,</span><span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span> <span class="token comment">#网络模型，名字</span>
</code></pre> 
<p>加载：</p> 
<pre><code class="prism language-python"><span class="token comment">#如果是自己写的模型,需要在这一行写上神经网络或者头文件中from model import*</span>
<span class="token comment">#但是不用再实例化了</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"vgg16_method1.pth"</span><span class="token punctuation">)</span> <span class="token comment">#相对地址  model为实例化的网络模型 对象</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="2_656"></a>保存方式2</h4> 
<p>保存：</p> 
<pre><code class="prism language-python">vgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>vgg16<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span> <span class="token comment">#网络模型，名字</span>
</code></pre> 
<p>加载：</p> 
<pre><code class="prism language-python">vgg16 <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span><span class="token punctuation">)</span>
vgg16<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"vgg16_method2.pth"</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#相对地址</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>vgg16<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_670"></a>六、完整模型的训练套路</h2> 
<p><code>print("-------第 {}轮训练开始-------".format(i+1))</code> 字符串函数，用 i+1 替换 {}<br> <code>accuracy = (outputs.argmax(1) == targets).sum()</code> 用于计算每一次训练的正确率，1表示按行看寻最大值</p> 
<p><strong>训练的基本思路：</strong><br> 我们要训练的对象是神经网络，我们先初步构建神经网络，如卷积，池化等，然后第一轮让训练集通过创建好的神经网络的这些层，使得训练集的图片变为特征图（类似于高亮变灰白）（使得容易训练神经网络），然后让<strong>特征图(outputs)</strong> 和 <strong>targets</strong>相比来通过损失函数获得损失，然后再经过优化器优化、损失反向传播 使得神经网络中的层的参数逐渐被优化更新，然后经过n轮训练，直到更加接近target。</p> 
<p>如何知道神经网络被训练的效果怎么样呢？（是否适应模型）<br> 通过测试集。 让测试集经过神经网络，看看每一轮的损失或者正确率（分类问题常用）如何，进而判断训练效果。</p> 
<p>为什么要在每一轮过后要保存网络模型呢?<br> 因为神经网络在每一轮训练过后参数都会被优化更新，网络模型实质上发生了变化。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear<span class="token punctuation">,</span> Sequential
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token comment">#device = torch.device("cuda")   也表示在gpu中训练</span>

<span class="token comment">#dataset 准备数据集</span>
train_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_dataset <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">"./dataset2"</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">#length 长度</span>
train_dataset_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">)</span>
test_dataset_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_dataset<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练数据集的长度为{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_dataset_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"测试数据集的长度为{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_dataset_size<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#dataloader 加载数据集</span>
train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token comment">#实例化网络模型</span>
<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
pxd <span class="token operator">=</span> PXD<span class="token punctuation">(</span><span class="token punctuation">)</span>
pxd <span class="token operator">=</span> pxd<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#GPU训练 #pxd = pxd.to(device)</span>

<span class="token comment">#损失函数</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#交叉熵</span>
loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#GPU训练 #loss_fn = loss_fn.to(device)</span>

<span class="token comment">#添加tensorboard便于观察损失函数变化</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">"loss"</span><span class="token punctuation">)</span>

<span class="token comment">#优化器</span>
learning_rate <span class="token operator">=</span> <span class="token number">1e-2</span> <span class="token comment">#0.01</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>pxd<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span> <span class="token comment">#选用sgd优化器</span>

<span class="token comment">#设置神经网络的一些参数</span>
total_train_step <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment">#训练的次数</span>
total_test_step <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment">#测试的次数</span>
epoch <span class="token operator">=</span> <span class="token number">10</span> <span class="token comment">#训练的轮数</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-------第 {}轮训练开始-------"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#训练步骤开始</span>
    pxd<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#GPU           #imgs = imgs.to(device)</span>
        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#GPU     #targets = targets.to(device)</span>
        outputs <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>  <span class="token comment">#让输入通过层层特征提取网络（前向传播）</span>
        <span class="token comment">#特征提取：输入的像素点矩阵x * 权重参数矩阵w的过程，像素矩阵x的行列（形状）会发生变化，权重矩阵w的元素值将来会被不断更新。</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span> <span class="token comment">#计算在dataloader中一次训练的损失（每一轮输出的得分和真实值作比较的过程）</span>

        <span class="token comment">#优化器优化</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#梯度清零</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#反向传播，求解损失函数梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#更新权重参数</span>

        total_train_step <span class="token operator">=</span> total_train_step <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token keyword">if</span><span class="token punctuation">(</span>total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练次数：{},此次训练的Loss：{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"train_loss"</span><span class="token punctuation">,</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>total_train_step<span class="token punctuation">)</span>

    <span class="token comment">#验证步骤开始（验证训练结果怎么样）</span>
    pxd<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_test_loss <span class="token operator">=</span> <span class="token number">0</span>
    total_test_accuracy <span class="token operator">=</span> <span class="token number">0</span>
    	<span class="token comment">#无梯度的目的是:正处在验证阶段,所以不用对梯度进行调整,无需优化神经网络参数,也可以节省内存</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span>
            imgs<span class="token punctuation">,</span>targets <span class="token operator">=</span> data
        	imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#GPU          #imgs = imgs.to(device)</span>
        	targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#GPU    #targets = targets.to(device)</span>
            outputs <span class="token operator">=</span> pxd<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
            <span class="token comment">#特征提取网络经过该轮训练，神经网络参数w被更新，将输入图片放入该网络后的到的得分值被记录下来</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span>targets<span class="token punctuation">)</span> <span class="token comment">#计算损失</span>
            total_test_loss <span class="token operator">=</span> total_test_loss <span class="token operator">+</span> loss
            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#正确率的分子</span>
            total_test_accuracy <span class="token operator">=</span> total_test_accuracy <span class="token operator">+</span> accuracy

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的loss:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"整体测试集上的正确率:{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_accuracy<span class="token operator">/</span>test_dataset_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_loss"</span><span class="token punctuation">,</span>total_test_loss<span class="token punctuation">,</span>total_test_step<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">"test_accuracy"</span><span class="token punctuation">,</span> total_test_accuracy<span class="token operator">/</span>test_dataset_size<span class="token punctuation">,</span> total_test_step<span class="token punctuation">)</span>
    total_test_step <span class="token operator">=</span> total_test_step <span class="token operator">+</span> <span class="token number">1</span>

    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>pxd<span class="token punctuation">,</span><span class="token string">"tudui_{}.pth"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型已保存"</span><span class="token punctuation">)</span>

writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>前三轮次的结果：</strong></p> 
<pre><code class="prism language-python">Files already downloaded <span class="token keyword">and</span> verified
Files already downloaded <span class="token keyword">and</span> verified
训练数据集的长度为<span class="token number">50000</span>
测试数据集的长度为<span class="token number">10000</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>第 <span class="token number">1</span>轮训练开始<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
训练次数：<span class="token number">100</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">2.287644147872925</span>
训练次数：<span class="token number">200</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">2.281564712524414</span>
训练次数：<span class="token number">300</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">2.258236885070801</span>
训练次数：<span class="token number">400</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">2.173457145690918</span>
训练次数：<span class="token number">500</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">2.0533664226531982</span>
训练次数：<span class="token number">600</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">2.0135819911956787</span>
训练次数：<span class="token number">700</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.9880279302597046</span>
整体测试集上的loss<span class="token punctuation">:</span><span class="token number">314.1552734375</span>
整体测试集上的正确率<span class="token punctuation">:</span><span class="token number">0.28039997816085815</span>
模型已保存
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>第 <span class="token number">2</span>轮训练开始<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
训练次数：<span class="token number">800</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.8499757051467896</span>
训练次数：<span class="token number">900</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.823794960975647</span>
训练次数：<span class="token number">1000</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.880897879600525</span>
训练次数：<span class="token number">1100</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.9815046787261963</span>
训练次数：<span class="token number">1200</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.7078672647476196</span>
训练次数：<span class="token number">1300</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.6430387496948242</span>
训练次数：<span class="token number">1400</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.7231780290603638</span>
训练次数：<span class="token number">1500</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.7968997955322266</span>
整体测试集上的loss<span class="token punctuation">:</span><span class="token number">301.3468017578125</span>
整体测试集上的正确率<span class="token punctuation">:</span><span class="token number">0.3149999976158142</span>
模型已保存
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>第 <span class="token number">3</span>轮训练开始<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
训练次数：<span class="token number">1600</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.7480535507202148</span>
训练次数：<span class="token number">1700</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.638698697090149</span>
训练次数：<span class="token number">1800</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.9216716289520264</span>
训练次数：<span class="token number">1900</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.7019065618515015</span>
训练次数：<span class="token number">2000</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.8428000211715698</span>
训练次数：<span class="token number">2100</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.5035483837127686</span>
训练次数：<span class="token number">2200</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.5163278579711914</span>
训练次数：<span class="token number">2300</span><span class="token punctuation">,</span>此次训练的Loss：<span class="token number">1.7925814390182495</span>
整体测试集上的loss<span class="token punctuation">:</span><span class="token number">267.4210205078125</span>
整体测试集上的正确率<span class="token punctuation">:</span><span class="token number">0.3807999789714813</span>
模型已保存
</code></pre> 
<p>通过每一轮训练后的结果，我们可以观察到测试集上的整体loss在逐轮次下降、正确率逐轮次提高，表明神经网络经过每一轮的训练，神经网络的参数在不断被优化，损失越来越小，神经网络越来越适应模型。</p> 
<h3><a id="GPU_834"></a>GPU加速训练</h3> 
<p><strong>只能在以下环节中利用GPU加速：</strong></p> 
<ol><li>网络模型</li><li>数据（imgs，targets）（输入，标注(eg:‘dogs’)）</li><li>损失函数</li></ol> 
<h2><a id="_840"></a>七、完整模型的验证套路</h2> 
<p>类似于训练套路中的测试集那里</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> PIL <span class="token keyword">import</span>  Image
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> Sequential<span class="token punctuation">,</span> Conv2d<span class="token punctuation">,</span> MaxPool2d<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> Linear

img_path <span class="token operator">=</span> <span class="token string">"./pictures/dog.png"</span>
image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span> <span class="token comment">#以pil类型打开</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span>
transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> transform<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
image <span class="token operator">=</span> image<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#因为网络模型是用gpu训练的，所以测试的输入图片应该.cuda()</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

<span class="token comment">#使用第一种方式加载网络</span>
<span class="token keyword">class</span> <span class="token class-name">PXD</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model1 <span class="token operator">=</span> Sequential<span class="token punctuation">(</span>Conv2d<span class="token punctuation">(</span>in_channels<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>out_channels<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span>kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span>stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span><span class="token number">1024</span><span class="token punctuation">,</span>out_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                 Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        output <span class="token operator">=</span> self<span class="token punctuation">.</span>model1<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"tudui_9.pth"</span><span class="token punctuation">)</span> <span class="token comment">#传参为神经网络的相对地址，实例化</span>

image <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>image<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#此步使得batch_size变为1,很重要,容易忽略!!!</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    output <span class="token operator">=</span> model<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#输出tensor最大的标签</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5525369a9b4ec73444632ccf122049f9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Mybatis 源码分析（一）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0ac7bb41f7c788e64110cfb3c95d14af/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">dataGridVie控件绑定List＜T＞数据</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>