<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PyTorch|构建自己的卷积神经网络——nn.Sequential() - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PyTorch|构建自己的卷积神经网络——nn.Sequential()" />
<meta property="og:description" content="之前在构建神经网络时，我们一般是采用这种方式，就像这样：
class Network1(nn.Module): def __init__(self): super(Network1,self).__init__() self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5) self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5) self.fc1 = nn.Linear(in_features= 12*20*20, out_features=120) self.out = nn.Linear(in_features=120, out_features=10) def forward(self, t): t=self.conv1(t) t=self.conv2(t) t=t.flatten(start_dim=1) t=self.fc1(t) t=self.out(t) return t 在__init__()模块中，一系列的层被定义，比如卷积层，全连接层...在forward()方法中，我们对这些层进行操作，使得数据在网络中进行传播。
随着层的增加，以及池化操作，激活函数操作的增加，代码似乎变得很复杂。
在PyTorch中，提供了一种序列容器，叫做nn.Sequential(),它可以按照网络模块被添加的顺序依次执行。
于是上面的代码可以以这样的方式重写：​​​​​​​
class Network2(nn.Module): def __init__(self): super(Network2,self).__init__() self.layer1=nn.Sequential(nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5), nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5), nn.Flatten(), nn.Linear(in_features= 12*20*20, out_features=120), nn.Linear(in_features=120, out_features=10) ) def forward(self,t): t=self.layer1(t) return t 让我们将一张图片输入到这两个网络中，看看会发生什么？​​​​​​​
path=&#34;E:\\3-10\\input1.jpg&#34;img=Image.open(path)img=img.resize((28,28))#改变图片尺寸img=np.array(img)#转换为ndarrayimg=torch.tensor(img,dtype=torch.float32)#转换为张量img=img.permute(2,0,1)#改变维度顺序 img=img.unsqueeze(0)#增加批次维度img.size()​​​​​​ torch.manual_seed(10)#随机数种子net1=Network1()torch.manual_seed(10)net2=Network2()net1(img),net2(img) (tensor([[ 8.6586, 5.6796, -10." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/3c4bc51071ab05860f00f4bfdc493a2c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-07T20:00:53+08:00" />
<meta property="article:modified_time" content="2024-01-07T20:00:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PyTorch|构建自己的卷积神经网络——nn.Sequential()</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p class="img-center"><img alt="图片" height="377" src="https://images2.imgbox.com/f0/90/iWima82C_o.jpg" width="941"></p> 
<p>之前在构建神经网络时，我们一般是采用这种方式，就像这样：</p> 
<pre><code>class Network1(nn.Module):</code><code>    def __init__(self):</code><code>        super(Network1,self).__init__()</code><code>        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)</code><code>        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)</code><code>        self.fc1 = nn.Linear(in_features= 12*20*20, out_features=120)</code><code>        self.out = nn.Linear(in_features=120, out_features=10)</code><code>    </code><code>    def forward(self, t):</code><code>        t=self.conv1(t)</code><code>        t=self.conv2(t)</code><code>        t=t.flatten(start_dim=1)</code><code>        t=self.fc1(t)</code><code>        t=self.out(t)</code><code>        return t</code></pre> 
<p>在__init__()模块中，一系列的层被定义，比如卷积层，全连接层...在forward()方法中，我们对这些层进行操作，使得数据在网络中进行传播。</p> 
<p><strong>随着层的增加，以及池化操作，激活函数操作的增加，代码似乎变得很复杂。</strong></p> 
<p>在PyTorch中，提供了一种序列容器，叫做<strong>nn.Sequential()</strong>,它可以按照网络模块被添加的顺序依次执行。</p> 
<p>于是上面的代码可以以这样的方式重写：​​​​​​​</p> 
<pre><code>class Network2(nn.Module):</code><code>    def __init__(self):</code><code>        super(Network2,self).__init__()</code><code>        self.layer1=nn.Sequential(nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),</code><code>                                      nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),</code><code>                                      nn.Flatten(),</code><code>                                      nn.Linear(in_features= 12*20*20, out_features=120),</code><code>                                      nn.Linear(in_features=120, out_features=10)    </code><code>                                     )</code><code>    def forward(self,t):</code><code>        t=self.layer1(t)</code><code>        return t</code></pre> 
<p>让我们将一张图片输入到这两个网络中，看看会发生什么？​​​​​​​</p> 
<pre><code>path="E:\\3-10\\input1.jpg"</code><code>img=Image.open(path)</code><code>img=img.resize((28,28))#改变图片尺寸</code><code>img=np.array(img)#转换为ndarray</code><code>img=torch.tensor(img,dtype=torch.float32)#转换为张量</code><code>img=img.permute(2,0,1)#改变维度顺序</code>
<code>img=img.unsqueeze(0)#增加批次维度</code><code>img.size()</code>​​​​​​</pre> 
<pre><code>torch.manual_seed(10)#随机数种子</code><code>net1=Network1()</code><code>torch.manual_seed(10)</code><code>net2=Network2()</code><code>net1(img),net2(img)</code>
<code>(tensor([[  8.6586,   5.6796, -10.6183, -14.5155,  -5.1435,  -1.2218, -35.0356,</code><code>            9.9759, -15.0035, -31.1104]], grad_fn=&lt;AddmmBackward0&gt;),</code><code> tensor([[  8.6586,   5.6796, -10.6183, -14.5155,  -5.1435,  -1.2218, -35.0356,</code><code>            9.9759, -15.0035, -31.1104]], grad_fn=&lt;AddmmBackward0&gt;))</code>
</pre> 
<p>注：由于每次初始化网络时，权重是随机的，所以要设置一个<strong>随机数种子</strong>，使得两个网络以一种固定的权重初始化，以确保两个网络在接受数据输入前完全相同。</p> 
<p><strong>结果很显然，两种网络输出了同样的结果！</strong></p> 
<p><br> 第一种构建网络的方法让层和操作隔离开来，使得我们在构建网络时不同部分时专注于一点即可，而第二种方法则是直接按照顺序直接构建了网络，看起来似乎更简洁。</p> 
<p>当然，以什么方式构建网络完全取决于习惯，这并不会对结果造成任何影响！</p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/46832472c537b4bb4dd8097bb7af752f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【LeetCode739】每日温度</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/139aa15a6e3ac9704789278000167da1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">第三十八周周报：文献阅读 &#43;BILSTM&#43;GRU&#43;Seq2seq</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>