<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【图像识别】基于pytorch 的入门demo——CIFAR10数据集识别及其可视化 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【图像识别】基于pytorch 的入门demo——CIFAR10数据集识别及其可视化" />
<meta property="og:description" content="目录
环境配置
1.数据集
2.模型训练
3.训练结果
4.Batch_size的作用
5.参考资料
pytorch使用是动态图计算思想，符合一般的计算逻辑，集成了caffe，容易上手灵活方便，方便使用GPU 加速、自动求导数，更适用于学术界。tensorflow采用的是静态图计算思想，静态图需要提前定义计算图，然后使用创建的计算图运算，运算过程中不利于查看中间变量，但是框架的生态成熟，部署便利，更适合工业界。pytorch自然语言处理包：AllenNLP，计算机视觉包：Torchvision。
环境配置 win10 &#43; GTX 1660Ti &#43;Anaconda3 &#43;Spyder&#43;Pytorch1.0
Pytorch的配置非常简单，非常友好。 直接登录官网，https://pytorch.org/ 选择配置环境，执行Command即可。
spyder配置opencv环境，在Anaconda prompt中输入：
conda install –c https://conda.binstar.org/menpo opencv 1.数据集 CIFAR-10和CIFAR-100是带有标签的数据集（详情：http://groups.csail.mit.edu/vision/TinyImages/）
CIFAR-10数据集共有60000张彩色图像，每张大小：32*32*3，分为10个类，具体见图，每类6000张图。
训练集：50000张，构成了500个训练批batch，每一批batch_size为100张。
测试集：10000张，构成一个batch。每一类随机取1000张，共10类*1000=10000张。
10个类别
另外，pytorch的内置数据集很多：torchvision.datasets
class torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False) class torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=False) class torchvision.datasets.EMNIST(root, split, **kwargs) class torchvision.datasets.CocoCaptions(root, annFile, transform=None, target_transform=None) class torchvision.datasets.CocoDetection(root, annFile, transform=None, target_transform=None) class torchvision.datasets.LSUN(root, classes=&#39;train&#39;, transform=None, target_transform=None) class torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=) class torchvision." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f809a90c271fee371f7bf1d1d27b862b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-06-13T20:48:50+08:00" />
<meta property="article:modified_time" content="2019-06-13T20:48:50+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【图像识别】基于pytorch 的入门demo——CIFAR10数据集识别及其可视化</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE-toc" style="margin-left:40px;"><a href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE" rel="nofollow">环境配置</a></p> 
<p id="1.%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#1.%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">1.数据集</a></p> 
<p id="2.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83-toc" style="margin-left:40px;"><a href="#2.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83" rel="nofollow">2.模型训练</a></p> 
<p id="3.%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#3.%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C" rel="nofollow">3.训练结果</a></p> 
<p id="4.Batch_size%E7%9A%84%E4%BD%9C%E7%94%A8-toc" style="margin-left:40px;"><a href="#4.Batch_size%E7%9A%84%E4%BD%9C%E7%94%A8" rel="nofollow">4.Batch_size的作用</a></p> 
<p id="5.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99-toc" style="margin-left:40px;"><a href="#5.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99" rel="nofollow">5.参考资料</a></p> 
<hr id="hr-toc"> 
<p> </p> 
<p style="text-align:center;"><img alt="" class="has" height="204" src="https://images2.imgbox.com/0b/24/JRPKhKZd_o.png" width="409"></p> 
<p>        pytorch使用是动态图计算思想，符合一般的计算逻辑，集成了caffe，容易上手灵活方便，方便使用GPU 加速、自动求导数，更适用于学术界。tensorflow采用的是静态图计算思想，静态图需要提前定义计算图，然后使用创建的计算图运算，运算过程中不利于查看中间变量，但是框架的生态成熟，部署便利，更适合工业界。pytorch自然语言处理包：AllenNLP，计算机视觉包：Torchvision。</p> 
<p style="text-align:center;"><img alt="" class="has" height="201" src="https://images2.imgbox.com/1a/78/bM8a3iNq_o.png" width="536"></p> 
<h3><strong>环境配置</strong></h3> 
<p>             win10 + GTX 1660Ti +Anaconda3 +Spyder+Pytorch1.0</p> 
<p>              Pytorch的配置非常简单，非常友好。 直接登录官网，<a href="https://pytorch.org/" rel="nofollow">https://pytorch.org/</a>   选择配置环境，执行Command即可。</p> 
<p style="text-align:center;"><img alt="" class="has" height="354" src="https://images2.imgbox.com/f3/70/wUc2MRf4_o.png" width="536"></p> 
<p>     spyder配置opencv环境，在Anaconda prompt中输入：</p> 
<pre class="has"><code>conda install –c https://conda.binstar.org/menpo opencv</code></pre> 
<h3 id="1.%E6%95%B0%E6%8D%AE%E9%9B%86"><strong>1.数据集</strong></h3> 
<p><strong>     </strong>CIFAR-10和CIFAR-100是带有标签的数据集（详情：http://groups.csail.mit.edu/vision/TinyImages/）</p> 
<p>  <strong>   </strong>CIFAR-10数据集共有60000张彩色图像，每张大小：32*32*3，分为10个类，具体见图，每类6000张图。</p> 
<p>     训练集：50000张，构成了500个训练批batch，每一批batch_size为100张。</p> 
<p>     测试集：10000张，构成一个batch。每一类随机取1000张，共10类*1000=10000张。</p> 
<p style="text-align:center;"><img alt="" class="has" height="403" src="https://images2.imgbox.com/44/5d/KDHAvHyJ_o.png" width="531"></p> 
<p>                                                                                          10个类别</p> 
<p>另外，pytorch的内置数据集很多：<a href="https://pytorch.org/docs/stable/torchvision/datasets.html" rel="nofollow">torchvision.datasets</a></p> 
<pre class="has"><code>class torchvision.datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)
class torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=False)
class torchvision.datasets.EMNIST(root, split, **kwargs)
class torchvision.datasets.CocoCaptions(root, annFile, transform=None, target_transform=None)
class torchvision.datasets.CocoDetection(root, annFile, transform=None, target_transform=None)
class torchvision.datasets.LSUN(root, classes='train', transform=None, target_transform=None)
class torchvision.datasets.ImageFolder(root, transform=None, target_transform=None, loader=)
class torchvision.datasets.DatasetFolder(root, loader, extensions, transform=None, target_transform=None)
class torchvision.datasets.CIFAR10(root, train=True, transform=None, target_transform=None, download=False)
class torchvision.datasets.CIFAR100(root, train=True, transform=None, target_transform=None, download=False)
class torchvision.datasets.STL10(root, split='train', transform=None, target_transform=None, download=False)
class torchvision.datasets.SVHN(root, split='train', transform=None, target_transform=None, download=False)
class torchvision.datasets.PhotoTour(root, name, train=True, transform=None, download=False)
</code></pre> 
<h3 id="2.%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83">2.<strong>模型训练</strong></h3> 
<p><strong>     2.1 模型选择：</strong></p> 
<p>             一方面可以自己定义自己Net，另外也可以使用PyTorch的torchvision.models提供的模型。</p> 
<pre class="has"><code>import torchvision.models as models
resnet18 = models.resnet18(pretrained=True)
alexnet = models.alexnet(pretrained=True)
squeezenet = models.squeezenet1_0(pretrained=True)
vgg16 = models.vgg16(pretrained=True)
densenet = models.densenet161(pretrained=True)
inception = models.inception_v3(pretrained=True)
</code></pre> 
<p><strong>      </strong>此外，pytorch 刚刚发布了hub功能，见 <a href="https://pytorch.org/hub" rel="nofollow">https://pytorch.org/hub</a></p> 
<pre class="has"><code>model=torch.hub.load(model)</code></pre> 
<p><strong>   2.2模型可视化</strong></p> 
<p><strong>   </strong>下方的代码为网上搜集到的，PS：可以使用netron工具进行模型可视化，用工具直接打开cifar10.pkl即可。</p> 
<p>    工具链接：<a href="https://github.com/lutzroeder/Netron">https://github.com/lutzroeder/Netron</a> ,可视化后的模型如下：</p> 
<p><img alt="" class="has" height="504" src="https://images2.imgbox.com/b7/f4/aiZPwBCf_o.png" width="217"><img alt="" class="has" height="417" src="https://images2.imgbox.com/4f/83/bFR3yEYr_o.png" width="211"><img alt="" class="has" height="504" src="https://images2.imgbox.com/2c/de/3RUnxBMM_o.png" width="178"></p> 
<p> </p> 
<p><strong>   2.3训练过程：</strong></p> 
<p>                 1.构建模型框架<br>                  2.迭代输入数据集  <br>                  3.计算前向损失(loss) <br>                  4.误差反向传播，更新网络的参数</p> 
<p>   2.4<strong>参数设置：</strong></p> 
<p>                  见代码</p> 
<pre class="has"><code>import torch                   #torch的包
import torch.nn as nn
import torch.nn.functional as F
import torchvision           #基于torch的计算技术视觉相关的开发包
import torchvision.transforms as transforms
import torch.optim as optim

import cv2 as cv
import numpy as np
import time
import matplotlib.pyplot as plt

from visdom import Visdom
import numpy as np

viz = Visdom(env='loss')
x1,y1=0,0
win = viz.line(
    X=np.array([x1]),
    Y=np.array([y1]),
    opts=dict(title='loss'))

#参数设置
batch_size = 50

start = time.time()
#1、对数据进行预处理
transform = transforms.Compose(   
    [transforms.ToTensor(),       #转为tensor
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])#归一化
# =============================================================================
# transforms.Compose： 
#         将多种操作组合在一起，此处将数据转换为tensor和数据归一化组合为函数tansform
# =============================================================================

#2、加载数据
#2.1下载训练集，并预处理
trainset = torchvision.datasets.CIFAR10(root='./', train=True,
                                        download=True, transform=transform)
#2.2加载训练集，并打乱图像的序号
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=False, num_workers=2)

#2.3下载测试集，并预处理
testset = torchvision.datasets.CIFAR10(root='./', train=False,
                                       download=True, transform=transform)

#2.4加载测试集，由于是测试无需打乱图像序号
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

#2.5加载label,使用元组，不可改变
classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')
 
end = time.time()
print("运行时间:%.2f秒"%(end-start))

#3构建深度学习网络架构
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, 3, padding = 1)
        self.conv2 = nn.Conv2d(64, 64, 3, padding =1)
        self.conv3 = nn.Conv2d(64, 128, 3, padding = 1)
        self.conv4 = nn.Conv2d(128, 128, 3, padding = 1)
        self.conv5 = nn.Conv2d(128, 256, 3, padding = 1)
        self.conv6 = nn.Conv2d(256, 256, 3, padding = 1)
        self.maxpool = nn.MaxPool2d(2, 2)
        self.avgpool = nn.AvgPool2d(2, 2)
        self.globalavgpool = nn.AvgPool2d(8, 8)
        self.bn1 = nn.BatchNorm2d(64)
        self.bn2 = nn.BatchNorm2d(128)
        self.bn3 = nn.BatchNorm2d(256)
        self.dropout50 = nn.Dropout(0.5)
        self.dropout10 = nn.Dropout(0.1)
        self.fc = nn.Linear(256, 10)
 
    def forward(self, x):
        x = self.bn1(F.relu(self.conv1(x)))
        x = self.bn1(F.relu(self.conv2(x)))
        x = self.maxpool(x)
        x = self.dropout10(x)
        x = self.bn2(F.relu(self.conv3(x)))
        x = self.bn2(F.relu(self.conv4(x)))
        x = self.avgpool(x)
        x = self.dropout10(x)
        x = self.bn3(F.relu(self.conv5(x)))
        x = self.bn3(F.relu(self.conv6(x)))
        x = self.globalavgpool(x)
        x = self.dropout50(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x
    
    
if __name__ == '__main__': 
    net = Net()
    criterion = nn.CrossEntropyLoss()    #交叉熵损失函数
    optimizer = optim.Adam(net.parameters(), lr=0.1)#lr=0.001  
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    net.to(device)
     
    for epoch in range(1):
        running_loss = 0.

        for i, data in enumerate(trainloader): 
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print('[%d, %5d] loss: %.4f' %(epoch + 1, (i+1)*batch_size, loss.item()))
            x1+=i
            viz.line(
                    X=np.array([x1]),
                    Y=np.array([loss.item()]),
                    win=win,#win要保持一致
                    update='append')
            
    print('Finished Training') 
    torch.save(net, 'cifar10.pkl')
    # net = torch.load('cifar10.pkl')
  
    correct = 0
    total = 0
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    
    print('Accuracy of the network on the 10000 test images: %d %%' % (
        100 * correct / total))
    
    class_correct = list(0. for i in range(10))
    class_total = list(0. for i in range(10))
    
    with torch.no_grad():
        for data in testloader:
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs, 1)
            c = (predicted == labels).squeeze()
            for i in range(4):
                label = labels[i]
                class_correct[label] += c[i].item()
                class_total[label] += 1
 
 
    for i in range(10):
        print('Accuracy of %5s : %2d %%' % (
            classes[i], 100 * class_correct[i] / class_total[i]))

</code></pre> 
<p style="text-align:center;"><img alt="" class="has" height="383" src="https://images2.imgbox.com/0c/68/SuYJYH5e_o.png" width="518"></p> 
<p><strong>2.5 训练过程可视化</strong></p> 
<p>      打开Anaconda Prompt输入命令。（<code>conda install visdom</code>命令安装失败）</p> 
<pre class="has"><code>pip install visdom</code></pre> 
<p>     启动服务：</p> 
<pre class="has"><code>python -m visdom.server</code></pre> 
<p>     打开浏览器：</p> 
<pre class="has"><code>http://localhost:8097/</code></pre> 
<p style="text-align:center;"><img alt="" class="has" height="364" src="https://images2.imgbox.com/be/4e/PDv91GBL_o.png" width="691"></p> 
<h3 id="3.%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C"><strong>3.训练结果</strong></h3> 
<p style="text-align:center;"><img alt="" class="has" height="196" src="https://images2.imgbox.com/b3/9b/w76X0QZT_o.png" width="599"></p> 
<p>         GPU上训练就是快呀！！！CPU i3 三个半小时左右跑完，GTX 1660 TI 三分钟左右就出一次结果。</p> 
<h3 id="4.Batch_size%E7%9A%84%E4%BD%9C%E7%94%A8"><strong>4.Batch_size的作用</strong></h3> 
<table border="1" cellspacing="0" style="width:441.1pt;"><tbody><tr><td style="vertical-align:top;"> <p style="margin-left:0cm;">Batch_size=100;</p> <p style="margin-left:0cm;">测试结果</p> <p style="margin-left:0cm;">Accuracy of the network on the 10000 test images:<strong> 67 %</strong></p> <p style="margin-left:0cm;">Accuracy of plane : 65 %</p> <p style="margin-left:0cm;">Accuracy of   car : 84 %</p> <p style="margin-left:0cm;">Accuracy of  bird : 52 %</p> <p style="margin-left:0cm;">Accuracy of   cat : 46 %</p> <p style="margin-left:0cm;">Accuracy of  deer : 44 %</p> <p style="margin-left:0cm;">Accuracy of   dog : 43 %</p> <p style="margin-left:0cm;">Accuracy of  frog : 79 %</p> <p style="margin-left:0cm;">Accuracy of horse : 78 %</p> <p style="margin-left:0cm;">Accuracy of  ship : 77 %</p> <p style="margin-left:0cm;">Accuracy of truck : 75 %</p> </td><td style="vertical-align:top;"> <p style="margin-left:0cm;">Batch_size=50;</p> <p style="margin-left:0cm;">测试结果</p> <p style="margin-left:0cm;">Accuracy of the network on the 10000 test images: <strong>66 %</strong></p> <p style="margin-left:0cm;">Accuracy of plane : <span style="color:#ff0000;">76 %</span></p> <p style="margin-left:0cm;">Accuracy of   car : <span style="color:#ff0000;">82 %</span></p> <p style="margin-left:0cm;">Accuracy of  bird : 37 %</p> <p style="margin-left:0cm;">Accuracy of   cat : 25 %</p> <p style="margin-left:0cm;">Accuracy of  deer : <span style="color:#ff0000;">56 %</span></p> <p style="margin-left:0cm;">Accuracy of   dog :<span style="color:#ff0000;"> 57 %</span></p> <p style="margin-left:0cm;">Accuracy of  frog : <span style="color:#ff0000;">72 %</span></p> <p style="margin-left:0cm;">Accuracy of horse : 67 %</p> <p style="margin-left:0cm;">Accuracy of  ship : 76 %</p> <p style="margin-left:0cm;">Accuracy of truck : <span style="color:#ff0000;">87 %</span></p> </td><td style="vertical-align:top;"> <p style="margin-left:0cm;">Batch_size=10;</p> <p style="margin-left:0cm;">测试结果</p> <p style="margin-left:0cm;">Accuracy of the network on the 10000 test images: <strong>62 %</strong></p> <p style="margin-left:0cm;">Accuracy of plane : 59 %</p> <p style="margin-left:0cm;">Accuracy of   car : 77 %</p> <p style="margin-left:0cm;">Accuracy of  bird : 49 %</p> <p style="margin-left:0cm;">Accuracy of   cat : 37 %</p> <p style="margin-left:0cm;">Accuracy of  deer : <span style="color:#ff0000;">50 %</span></p> <p style="margin-left:0cm;">Accuracy of   dog : <span style="color:#ff0000;">52 %</span></p> <p style="margin-left:0cm;">Accuracy of  frog : 69 %</p> <p style="margin-left:0cm;">Accuracy of horse : 73 %</p> <p style="margin-left:0cm;">Accuracy of  ship : 75 %</p> <p style="margin-left:0cm;">Accuracy of truck : <span style="color:#ff0000;">77 %</span></p> </td></tr></tbody></table> 
<p style="margin-left:0cm;">结论与思考:</p> 
<ol><li>在一定范围内，batch_size越大，越有利于模型的快速收敛，较大的batch _size更接近训练集的整体数据结构，因此，可以保证迭代过程中的梯度方向越准确，最后网络收敛情况就会好。</li><li>然而，并不是batch_size越大越好，使用large-batch训练得到的网络具有较差的泛化能力。训练集的数据结构和测试集的数据结构是相似的，但是二者并不是完全的相同，large-batch有利于提高训练集的收敛精度，但是模型过于刻画了训练集的数据结构，势必导致对测试集的数据模型的刻画能力降低。</li><li>batch_size的减小，整体识别率下降，但是对部分类别的识别率升高了，猜测根batch的数据分布接近训练集的分布有关，改变了SGD的梯度下降方向，随着batch_size减小，增加了迭代次数，使得模型收敛更精确。</li><li>训练的核心在于构建具有足够代表性的训练集，并用模型去刻画训练集的数据结构，且该模型对非显著特征应当具有泛化学习能力。</li></ol> 
<p style="text-align:center;"><img alt="" class="has" height="75" src="https://images2.imgbox.com/27/6b/eXyoSViT_o.png" width="578"></p> 
<h3 id="5.%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><strong>5.参考资料</strong></h3> 
<p>1、<a href="https://blog.csdn.net/Kansas_Jason/article/details/84503367">https://blog.csdn.net/Kansas_Jason/article/details/84503367</a></p> 
<p>2、<a href="https://blog.csdn.net/shareviews/article/details/83094783">https://blog.csdn.net/shareviews/article/details/83094783</a>（推荐一看）</p> 
<p>3、<a href="https://blog.csdn.net/leviopku/article/details/81980249">https://blog.csdn.net/leviopku/article/details/81980249</a>（Netron可视化工具）</p> 
<p>4、 莫烦大神网页：<a href="https://morvanzhou.github.io/" rel="nofollow">https://morvanzhou.github.io/</a></p> 
<p>5、Pytorch中文网：https://ptorch.com/</p> 
<p>6、Pytorch中文文档：https://ptorch.com/docs/1/</p> 
<p>7、Pytorch中文论坛：https://discuss.ptorch.com/</p> 
<p>8、深度学习模型可视化工具：<a href="https://blog.csdn.net/baidu_40840693/article/details/83006347">https://blog.csdn.net/baidu_40840693/article/details/83006347</a></p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fbee4161f7ab26b73ffa69102279ffc7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Opencv笔记 v1.0</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/176c20cbb27ebb68fc84e0ffeb034e19/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">win10护眼色设置（注册表）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>