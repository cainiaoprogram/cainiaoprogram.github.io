<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[语义分割] DeepLab v3（Cascaded model、ASPP model、两种ASPP对比、Multi-grid、训练细节） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[语义分割] DeepLab v3（Cascaded model、ASPP model、两种ASPP对比、Multi-grid、训练细节）" />
<meta property="og:description" content="Rethinking Atrous Convolution for Semantic Image Segmentation 论文地址：Rethinking Atrous Convolution for Semantic Image SegmentationPytorch 实现代码：pytorch_segmentation/deeplab_v3 这是一篇 2017 年发表在 CVPR 上的文章。相比 DeepLab V2 有三点变化：①引入了 Multi-grid；②改进了 ASPP 结构；③移除 CRFs 后处理。
① 引入 Multi-grid：Multi-grid 的引入旨在进一步改进膨胀卷积的使用方式，提高语义分割模型在不同尺度上的性能。相较于之前的版本（如 DeepLab V2），DeepLab V3 引入了多尺度的膨胀率设置，解决了在过去膨胀卷积中固定膨胀率所带来的局限性。在 DeepLab V3 中，网络的部分层使用了不同的膨胀率，从而允许模型在不同尺度上捕捉更丰富的上下文信息，有效地分割不同大小的目标。
② 改进了 ASPP 结构（Atrous Spatial Pyramid Pooling）：ASPP 结构用于在特征图的不同尺度上捕获多尺度上下文信息。在 DeepLab V3 中，ASPP 结构得到了改进，除了原来的多个膨胀系数的膨胀卷积外，还引入了图像级特征（全局平均池化），这样在 ASPP 模块中既能获取局部细节信息，也能融合全局上下文信息。这种改进有助于提高模型的感知范围和语义信息，从而改善分割性能。
③ 移除 CRFs 后处理（Conditional Random Fields）：在 DeepLab V2 中，使用 CRF 进行后处理是为了进一步优化语义分割结果，特别是在边界细节上进行平滑处理。然而 CRF 的计算代价较高，并且会增加模型的复杂性。DeepLab V3 移除了 CRF 后处理步骤，而是通过引入 Multi-grid 和改进 ASPP 结构来在模型中直接获得更全面和精确的特征表示，从而减少了 CRF 的需求。这样一来，DeepLab V3 在保持高性能的同时，简化了模型结构和训练过程。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0cec8f24213ca0f5df2d9cb8781bd79d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-02T15:38:20+08:00" />
<meta property="article:modified_time" content="2023-08-02T15:38:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[语义分割] DeepLab v3（Cascaded model、ASPP model、两种ASPP对比、Multi-grid、训练细节）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <center> 
 <font size="6">Rethinking Atrous Convolution for Semantic Image Segmentation</font> 
</center> 
<ul><li><strong>论文地址</strong>：<a href="https://arxiv.org/abs/1706.05587" rel="nofollow">Rethinking Atrous Convolution for Semantic Image Segmentation</a></li><li><strong>Pytorch 实现代码</strong>：<a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_segmentation/deeplab_v3">pytorch_segmentation/deeplab_v3</a></li></ul> 
<blockquote> 
 <p>这是一篇 2017 年发表在 CVPR 上的文章。相比 DeepLab V2 有三点变化：①引入了 Multi-grid；②改进了 ASPP 结构；③移除 CRFs 后处理。</p> 
</blockquote> 
<p>① <strong>引入 Multi-grid</strong>：Multi-grid 的引入旨在进一步改进膨胀卷积的使用方式，提高语义分割模型在不同尺度上的性能。相较于之前的版本（如 DeepLab V2），DeepLab V3 引入了多尺度的膨胀率设置，解决了在过去膨胀卷积中固定膨胀率所带来的局限性。在 DeepLab V3 中，网络的部分层使用了不同的膨胀率，从而允许模型在不同尺度上捕捉更丰富的上下文信息，有效地分割不同大小的目标。</p> 
<p>② <strong>改进了 ASPP 结构（Atrous Spatial Pyramid Pooling）</strong>：ASPP 结构用于在特征图的不同尺度上捕获多尺度上下文信息。在 DeepLab V3 中，ASPP 结构得到了改进，除了原来的多个膨胀系数的膨胀卷积外，<strong>还引入了图像级特征（全局平均池化）</strong>，这样在 ASPP 模块中既能获取局部细节信息，也能融合全局上下文信息。这种改进有助于提高模型的感知范围和语义信息，从而改善分割性能。</p> 
<p>③ <strong>移除 CRFs 后处理（Conditional Random Fields）</strong>：在 DeepLab V2 中，使用 CRF 进行后处理是为了进一步优化语义分割结果，特别是在边界细节上进行平滑处理。<strong>然而 CRF 的计算代价较高，并且会增加模型的复杂性</strong>。DeepLab V3 移除了 CRF 后处理步骤，而是通过引入 Multi-grid 和改进 ASPP 结构来在模型中直接获得更全面和精确的特征表示，从而减少了 CRF 的需求。这样一来，DeepLab V3 在保持高性能的同时，简化了模型结构和训练过程。</p> 
<hr> 
<h2><a id="DeepLab_v3__15"></a>DeepLab v3 概况</h2> 
<p>DeepLab v3是一个语义分割模型，其核心思想是使用深度卷积神经网络来实现高精度的语义分割任务。它是DeepLab系列模型的第三个版本，针对之前版本的一些缺点进行了改进。</p> 
<p>DeepLab v3的核心思想包括以下几个关键点：</p> 
<ol><li> <p><strong>膨胀卷积（Dilated Convolution）</strong>：为了增加感受野（Receptive Field）的大小，DeepLab v3引入了膨胀卷积。传统的卷积操作在特征提取时只考虑局部邻域信息，而膨胀卷积通过在卷积核中引入空洞（或称为膨胀率），使得卷积核可以在更大范围内获取特征信息，从而捕捉更广阔的上下文信息。</p> </li><li> <p><strong>多尺度信息融合</strong>：DeepLab v3采用了多尺度信息融合的方法，通过在不同尺度下对特征图进行空间金字塔池化操作，得到不同分辨率的特征图。然后，通过上采样和融合这些特征图，使得模型能够在不同尺度下获得更为丰富的信息，有利于对目标进行更准确的分割。</p> </li><li> <p><strong>全局平均池化（Global Average Pooling）</strong>：DeepLab v3在最后的特征图上使用全局平均池化来获得整体图像的全局信息。这有助于进一步提升模型的上下文感知能力，对于包含大范围目标的图像尤为重要。</p> </li><li> <p><strong>条件随机场（Conditional Random Field，CRF）</strong>：在得到初步的语义分割结果后，DeepLab v3采用了条件随机场来进行后处理。CRF能够利用像素之间的空间相关性和颜色相似性，对分割结果进行平滑，减少一些细节上的错误。</p> </li></ol> 
<p>综合以上几点，DeepLab v3能够有效地捕获图像中的上下文信息和多尺度特征，并对这些特征进行充分融合和处理，从而在语义分割任务中达到较高的准确率。</p> 
<hr> 
<h2><a id="Abstract_33"></a>Abstract</h2> 
<p>在这项工作中，我们重新考虑了膨胀卷积（Atrous Convolution），这是一种强大的工具，可以明确地调整卷积核的感受野，并控制 CNNs 计算的特征响应的分辨率，用于语义图像分割的应用。为了解决在多个尺度上分割对象的问题，我们设计了使用膨胀卷积的模块，这些模块串联或并行地采用多个膨胀率 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         r 
        
       
      
        r 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span></span></span></span></span> 来捕获多尺度上下文。此外，我们对之前提出的空洞空间金字塔池化（Atrous Spatial Pyramid Pooling，ASPP）模块进行增强，该模块可以在多个尺度上探测卷积特征，并融合包含全局上下文的图像级特征，实现性能的进一步提升。我们还详细阐述了实现细节，并分享了训练系统的经验。所提出的 “DeepLabv3” 系统在没有 DenseCRF 后处理的情况下明显优于我们之前的 DeepLab 版本，并在 PASCAL VOC 2012 语义图像分割基准测试中达到了与其他最先进模型相当的性能。</p> 
<h2><a id="1__37"></a>1. 用于捕获多尺度上下文信息的可选架构</h2> 
<p><img src="https://images2.imgbox.com/18/97/MsJAY2Sv_o.png" alt="在这里插入图片描述" height="250"></p> 
<center> 
 <b>图2. 用于捕获多尺度上下文的备选架构</b> 
</center> 
<br> 
<ul><li>(a) <strong>图像金字塔</strong>：这是我们最容易想到的一种方式，即将图片缩放到不同的尺度后再分别送入网络进行推理；最终再进行融合。</li><li>(b) <strong>编解码器</strong>：首先按照 Backbone 对输入图片进行一系列的下采样，最后再将最终的特征图进行一系列上采样；在上采样的过程中会和 Backbone 中得到的特征图进行融合；依次类推直至还原回原图大小。</li><li>(c) <strong>DeepLab v1 中的方法</strong>：将 Backbone 中最后几个卷积层的 <code>stride</code> 设置为 1；然后再引入膨胀卷积以增大网络的感受野。</li><li>(d) <strong>DeepLab v2 中的方法</strong>：引入 ASPP（空洞空间金字塔池化）以增加模型获取多尺度信息的能力。</li></ul> 
<h2><a id="2_DeepLab_v3__48"></a>2. DeepLab v3 的两种模型结构</h2> 
<ol><li>Cascaded Model：级联的模型</li><li>ASPP Model：空洞空间金字塔模型</li></ol> 
<blockquote> 
 <ul><li>在 Cascaded model 中是没有使用 ASPP 模块的</li><li>在 ASPP model 中是没有使用 Cascaded blocks 模块的</li></ul> 
</blockquote> 
<blockquote> 
 <p>注意，虽然文中提出了两种结构，但<mark>作者说 ASPP model 比 Cascaded model 略好点</mark>。包括在 Github 上开源的一些代码，大部分也是用的 ASPP model。</p> 
</blockquote> 
<h3><a id="21_Cascaded_Model_58"></a>2.1 Cascaded Model</h3> 
<p><img src="https://images2.imgbox.com/51/0b/LRrUF0NO_o.png" alt="在这里插入图片描述"></p> 
<p>论文中提出的 Cascaded model 指的是上图。其中 Block1、Block2、Block3、Block4 是原始 ResNet 网络中的层结构，但在 Block4 中将第一个残差结构里的 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         3 
        
       
         × 
        
       
         3 
        
       
      
        3\times 3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">3</span></span></span></span></span> 卷积层以及捷径分支上的 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         × 
        
       
         1 
        
       
      
        1\times 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span> 卷积层步距 <code>stride</code> 由 2 改成了 1（即不进行下采样），并且<u>所有残差结构里的 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          3 
         
        
          × 
         
        
          3 
         
        
       
         3\times 3 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">3</span></span></span></span></span> 普通卷积层都换成了 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          3 
         
        
          × 
         
        
          3 
         
        
       
         3\times 3 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">3</span></span></span></span></span> 膨胀卷积层</u>。Block5、Block6 和 Block7 是额外新增的层结构，<strong>它们的结构和 Block4 是一模一样的，即由三个使用了膨胀卷积的残差结构构成</strong>。</p> 
<blockquote> 
 <p><strong>注意</strong>❗️原论文说在训练 Cascaded model 时 <code>output_stride=16</code>（即特征层相对输入图片的下采样率），但验证时使用的 <code>output_stride=8</code>。因为 <code>output_stride=16</code> 时最终得到的特征层 <code>H</code> 和 <code>W</code> 会更小，这意味着可以设置更大的 <code>batch_size</code> 并且能够加快训练速度。但特征层 <code>H</code> 和 <code>W</code> 变小会导致特征层丢失细节信息（文中说变的更“粗糙”），所以在验证时采用的 <code>output_stride=8</code>。其实只要你 <code>GPU</code> 显存足够大，算力足够强也可以直接把 <code>output_stride</code>设置成 8。—— <strong>简单来说，训练的时候作者使用了 16 倍下采样率，而验证的时候使用了 8 倍下采样率</strong>。但我们不用这样折中，我们直接将下采样率设置为 8 倍即可。</p> 
</blockquote> 
<p>另外需要注意❗️的是，图中标注的 <code>rate</code> 并不是膨胀卷积真正采用的膨胀系数。 真正采用的膨胀系数应该是图中的 <code>rate</code> 乘上 <code>Multi-Grid</code>参数，比如 Block4 中 <code>rate=2</code>，<code>Multi-Grid=(1, 2, 4)</code>，那么真正采用的膨胀系数是 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         2 
        
       
         × 
        
       
         ( 
        
       
         1 
        
       
         , 
        
       
         2 
        
       
         , 
        
       
         4 
        
       
         ) 
        
       
         = 
        
       
         ( 
        
       
         2 
        
       
         , 
        
       
         4 
        
       
         , 
        
       
         8 
        
       
         ) 
        
       
      
        2 \times (1, 2, 4) = (2, 4, 8) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">4</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">8</span><span class="mclose">)</span></span></span></span></span>。关于Multi-Grid参数后面会提到。</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           r 
          
          
          
            a 
           
          
            c 
           
          
            t 
           
          
            u 
           
          
            a 
           
          
            l 
           
          
            l 
           
          
            y 
           
          
         
        
          = 
         
         
         
           r 
          
         
           a 
          
         
           t 
          
         
           e 
          
         
        
          × 
         
         
         
           M 
          
         
           u 
          
         
           l 
          
         
           t 
          
         
           i 
          
         
           G 
          
         
           r 
          
         
           i 
          
         
           d 
          
         
        
       
         r_\mathrm{actually} = \mathrm{rate} \times \mathrm{MultiGrid} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight" style="margin-right: 0.0139em;">actually</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6984em; vertical-align: -0.0833em;"></span><span class="mord"><span class="mord mathrm">rate</span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord"><span class="mord mathrm">MultiGrid</span></span></span></span></span></span></span></p> 
<h3><a id="22_ASPP_Model_72"></a>2.2 ASPP Model</h3> 
<h4><a id="221__74"></a>2.2.1 整体模型结构</h4> 
<p>虽然论文大篇幅的内容都在讲 Cascaded Model 及其对应的实验，但实际使用的最多的还是 ASPP Model，其模型结构如下图所示。</p> 
<p><img src="https://images2.imgbox.com/30/f4/4rIXB4uh_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>注意❗️和 Cascaded Model 一样，原论文中说在训练时 <code>output_stride=16</code>（即特征层相对输入图片的下采样率），但验证时使用的 <code>output_stride=8</code>。但在 PyTorch 官方实现的 DeepLabV3 源码中就直接把 <code>output_stride</code> 设置成 8 进行训练的。</p> 
</blockquote> 
<h4><a id="222__ASPP__83"></a>2.2.2 两种版本 ASPP 的对比</h4> 
<h5><a id="2221_ASPPV2__85"></a>2.2.2.1 ASPP（V2 版本）</h5> 
<p>首先回顾 <a href="https://blog.csdn.net/weixin_44878336/article/details/131973362">DeepLab V2</a> 中的 ASPP 结构，DeepLab V2 中的 ASPP 结构其实就是 <font color="red">通过四个并行的膨胀卷积层</font>，每个分支上的膨胀卷积层所采用的<strong>膨胀系数不同</strong>（注意，这里的膨胀卷积层后没有跟 BatchNorm 并且使用了偏执 Bias）。接着通过 <code>add</code> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ⊕ 
        
       
      
        \oplus 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6667em; vertical-align: -0.0833em;"></span><span class="mord">⊕</span></span></span></span></span> 相加的方式融合四个分支上的输出。</p> 
<p><img src="https://images2.imgbox.com/50/4c/C3Fbk2ro_o.png" alt="在这里插入图片描述" height="380"></p> 
<blockquote> 
 <p>ASPP（V2 版本）中的膨胀卷积层带有偏执 Bias 但没有跟 BN层</p> 
</blockquote> 
<h5><a id="2222_ASPPV3__93"></a>2.2.2.2 ASPP（V3 版本）</h5> 
<p>我们再来看下 DeepLab V3 中的 ASPP 结构，如下图所示。</p> 
<p><img src="https://images2.imgbox.com/89/0c/o9PBfznQ_o.png" alt="在这里插入图片描述" height="660"></p> 
<blockquote> 
 <p>ASPP（V3 版本）中的膨胀卷积是经典的汉堡包结构：Conv → BN → Activation</p> 
</blockquote> 
<p>这里的 ASPP 结构有 5 个并行分支，分别是：</p> 
<p><font color="green">①</font> 一个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         × 
        
       
         1 
        
       
      
        1\times 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span> 的卷积层<br><font color="pink">② ~ ④ </font>三个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         3 
        
       
         × 
        
       
         3 
        
       
      
        3\times 3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">3</span></span></span></span></span> 的膨胀卷积层（膨胀率是不同的）<br><font color="purple">⑤</font> 一个全局平均池化层（后面还跟有一个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         × 
        
       
         1 
        
       
      
        1\times 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span> 的卷积层，然后通过双线性插值的方法还原回输入的 <code>W</code> 和 <code>H</code>）。</p> 
<blockquote> 
 <p>关于最后一个全局池化分支作者说是为了增加一个全局上下文信息（Global Contextual Information）。</p> 
</blockquote> 
<p>之后通过 <code>Concat</code> 的方式将这 5 个分支的输出进行拼接（沿着 <code>channel</code> 方向），最后再通过一个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         × 
        
       
         1 
        
       
      
        1\times 1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span> 的卷积层进一步融合信息。</p> 
<h2><a id="3_Multigrid_109"></a>3. Multi-grid（多级网格方法）</h2> 
<p>在之前的 DeepLab v1 和 v2 模型中虽然一直在使用膨胀卷积，但膨胀系数的设置都比较随意。在 DeepLab V3 中作者有去做一些相关实验看如何设置更合理。下表是以 Cascaded Model（ResNet-101 作为 Backbone 为例）为实验对象，研究采<strong>用不同数量的 Cascaded blocks 模型</strong>以及 <strong>Cascaded blocks 采用不同的 Multi-Grid 参数</strong>的效果（mean IoU）。</p> 
<p><img src="https://images2.imgbox.com/3b/ca/AqVreDuh_o.png" alt="在这里插入图片描述" height="250"></p> 
<center> 
 <b>Table 3. 在输出步幅（下采样倍数）为 16 时，使用多级网格方法（Multi-grid）对 ResNet-101 进行 Cascaded blocks 数量的不同配置。最佳模型性能用粗体显示</b> 
</center> 
<br> 
<blockquote> 
 <p>注意❗️</p> 
 <ul><li>block5 ~ block7 都是和 block4 结构一样，只不过膨胀系数变了</li><li>刚刚在讲 Cascaded model 时有提到，blocks 中真正采用的膨胀系数应该是图中的 rate 乘上这里的 Multi-Grid 参数</li><li>这个图怎么看？ 
   <ul><li><strong>Multi-Grid（纵）</strong>：每次采用的 block5 ~ block7 的 Multi-Grid 参数（即便对应的 block 不存在）</li><li><strong>block4（纵）</strong>：使用 block4，没有 block5 ~ block7</li><li><strong>block5（纵）</strong>：使用 block4 和 block5，没有 block6 ~ block7</li><li><strong>block6（纵）</strong>：使用 block4 ~ block6，没有 block7</li><li><strong>block7（纵）</strong>：使用 block4 ~ block7（都使用了）</li></ul> </li><li>输出步幅（<code>output stride</code>）：下采样倍数</li></ul> 
</blockquote> 
<p>通过实验发现：</p> 
<ul><li>当采用三个额外的 Block 时（即额外添加 Block5、Block6 和 Block7）将 Multi-Grid 设置成 <code>(1, 2, 1)</code> 效果最好 —— <font color="blue">Cascaded Model 最佳模型</font></li><li>另外如果不添加任何额外 Block（即没有Block5、Block6 和 Block7）将 Multi-Grid 设置成 <code>(1, 2, 4)</code> 效果最好 —— <font color="red">ASPP Model 最佳模型</font><br> 这是因为在 ASPP model 中是没有额外添加 Block 层的，后面讲 ASPP model 的消融实验时采用的就是 Multi-Grid 等于 <code>(1, 2, 4)</code> 的情况。</li></ul> 
<h2><a id="4__137"></a>4. 消融实验</h2> 
<h3><a id="41_Cascaded_model_139"></a>4.1 Cascaded model（联级模型）消融实验</h3> 
<p>下表是有关 Cascaded model 的消融实验。</p> 
<p><img src="https://images2.imgbox.com/e8/7d/MTTedUts_o.png" alt="在这里插入图片描述" height="150"></p> 
<center> 
 <b>Table 4. 在验证集上的推理策略。MG：多级网格（Multi-grid）。OS：输出步幅（output stride，下采样倍数）。MS：测试期间使用多尺度输入。Flip：添加左右翻转的输入</b> 
</center> 
<br> 
<p>其中：</p> 
<ul><li>MG 代表 Multi-Grid，刚刚在上面也有说在 Cascaded model 中采用 <code>MG(1, 2, 1)</code> 是最好的。</li><li>OS 代表 output_stride（<strong>下采样倍数</strong>），刚刚在上面也有提到过验证时将 <code>output_stride</code> 设置成 8 效果会更好</li><li>MS 代表多尺度，和 DeepLab V2 中类似。不过在 DeepLab V3 中采用的尺度更多 <code>scales = {0.5, 0.75, 1.0, 1.25, 1.5, 1.75}</code></li><li>Flip 代表增加一个水平翻转后的图像输入</li></ul> 
<h3><a id="42_ASPP_model__155"></a>4.2 ASPP model 消融实验</h3> 
<p>下表是有关ASPP model的消融实验。</p> 
<p><img src="https://images2.imgbox.com/e8/35/PvkF3BZL_o.png" alt="在这里插入图片描述" height="150"></p> 
<center> 
 <b>Table 6. 在验证集上的推理策略：MG：多级网格（Multi-grid）。ASPP：空洞空间金字塔池化（Atrous spatial pyramid pooling）。OS：输出步幅（output stride，下采样倍数）。MS：测试期间使用多尺度输入。Flip：添加左右翻转的输入。COCO：在MS-COCO上预训练的模型</b> 
</center> 
<br> 
<p>其中：</p> 
<ul><li>MG 代表 Multi-Grid，刚刚在上面也有说在 ASPP model 中采用 <code>MG(1, 2, 4)</code> 是最好的</li><li>ASPP 前面讲过</li><li>Image Pooling 代表在 ASPP 中加入全局平均池化层分支</li><li>OS 代表 output_stride，刚刚在上面也有提到过验证时将 <code>output_stride</code> 设置成 8 效果会更好</li><li>MS 代表多尺度，和 DeepLab V2 中类似。不过在 DeepLab V3 中采用的尺度更多 <code>scales = {0.5, 0.75, 1.0, 1.25, 1.5, 1.75}</code></li><li>Flip 代表增加一个水平翻转后的图像输入</li><li>COCO 代表在 COCO 数据集上进行预训练</li></ul> 
<h2><a id="5__176"></a>5. 训练细节</h2> 
<p>下表是原论文中给出的关于 DeepLab V3 在 Pascal VOC2012 测试数据集上的 mean IOU。</p> 
<p><img src="https://images2.imgbox.com/4c/d2/Zn2NzZjt_o.png" alt="在这里插入图片描述" width="400"></p> 
<p>通过对比发现，其实 DeepLab V3 和 V2 比起来提升了大约 6 个点。但这里的 DeepLab V3 貌似并没有明确指出具体是 Cascaded model 还是 ASPP model，个人觉得大概率是指的 ASPP model。然后仔细想想这 6 个点到底是怎么提升的，如果仅通过引入 Multi-Grid，改进 ASPP 模块以及在 MSC 中使用更多的尺度应该不会提升这么多个点。所以我能想到的就是在训练过程中的某些改动导致 mean IOU 提升了。</p> 
<p>论文中 <code>A. Effect of hyper-parameters</code> 部分，其中作者有说：</p> 
<ul><li>在训练过程中增大了训练输入图片的尺寸（论文中有个观点大家需要注意下，即<mark>采用大的膨胀系数时，输入的图像尺寸不能太小，否则 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           3 
          
         
           × 
          
         
           3 
          
         
        
          3\times 3 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">3</span></span></span></span></span> 的膨胀卷积可能退化成 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           1 
          
         
           × 
          
         
           1 
          
         
        
          1\times 1 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span> 的普通卷积</mark>。</li><li><font color="green">计算损失时，是将预测的结果通过上采样还原回原尺度后（即网络最后的双线性插值上采样 8 倍）再和真实标签图像计算损失</font>。根据 Table 8 中的实验可以提升 1 个多点。<br> 而之前在 V1 和 V2 中是将真实标签图像下采用 8 倍后就和没有进行上采样的预测结果计算损失（当时这么做的目的是为了加快训练）。</li><li>训练完毕后，冻结 BN 层的参数，然后再去 fine-tuning 下网络的其它层，根据 Table 8 中的实验可以提升 1 个多点。</li></ul> 
<h2><a id="6_PyTorch__DeepLab_V3__191"></a>6. PyTorch 官方实现 DeepLab V3 模型结构</h2> 
<p>下图是 <a href="https://blog.csdn.net/qq_37541097?type=blog">霹雳吧啦WZ</a> 根据 PyTorch 官方实现的 DeepLab V3 源码绘制的网络结构（与原论文有些许差异）：</p> 
<ul><li>在 PyTorch 官方实现的 DeepLab V3 中，并没有使用 Multi-Grid</li><li>在 PyTorch 官方实现的 DeepLab V3 中多了一个 FCNHead 辅助训练分支，可以选择不使用</li><li>在 PyTorch 官方实现的 DeepLab V3 中无论是训练还是验证 <code>output_stride</code> 都使用的 8</li><li>ASPP 中三个膨胀卷积分支的膨胀系数是 <code>{12, 24, 36}</code>，因为论文中说当 <code>output_stride=8</code> 时膨胀系数要翻倍</li></ul> 
<p><img src="https://images2.imgbox.com/49/b2/28KSkPtP_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_202"></a>知识来源</h2> 
<ol><li><a href="https://blog.csdn.net/qq_37541097/article/details/121797301">https://blog.csdn.net/qq_37541097/article/details/121797301</a></li><li><a href="https://www.bilibili.com/video/BV1Jb4y1q7j7" rel="nofollow">https://www.bilibili.com/video/BV1Jb4y1q7j7</a></li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ba31b3cc992e94885d0a64e0ff41196a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">stm32串口通信，收发字符串，并对其进行解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/59a6c410b83db0128e80d578adbe13b7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">转载：上传网易云盘音频，不会自动改名</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>