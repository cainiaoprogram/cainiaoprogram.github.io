<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python爬虫基础requests库的使用以及参数详解 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python爬虫基础requests库的使用以及参数详解" />
<meta property="og:description" content="文章目录 1、简单介绍requests的使用方法2、爬虫中六种常用的异常处理。3、requests库的七个主要方法。3.1 七个主要方法3.2 HTTP协议对资源的操作 4、requests库方法的参数详解4.1 request()参数（requests.request(method, url, **kwargs)）4.1.1 method4.1.2 url4.1.3 **kwargs对应的13个参数4.1.4 具体使用方法 4.2 其他六个方法的参数 1、简单介绍requests的使用方法 以百度网站为例：
import requests r = requests.get(&#39;http://www.baidu.com&#39;) print(r.status_code) 调用status_code后，会返回一个值，如果返回值为200，则代表访问成功。
接着使用text查看内容：
print(r.text) 我们会发现有许多乱码，因此就需要改变编码方式。
print(r.encoding) print(r.apparent_encoding) r.encoding = r.apparent_encoding # 也可以这样写 # r.encoding = &#39;utf-8&#39; encoding方法是从HTTPheader中猜测响应内容的编码，但如果header中不存在charset字段，就默认编码为ISO-8859-1，而apparent_encoding则是从内容中分析编码，只需将它赋给encoding 即可。
下面是爬虫通用代码框架：
import requests try: url = &#39;http://www.baidu.com&#39; r = requests.get(url) r.raise_for_status() r.encoding = r.apparent_encoding print(r.text) except: print(&#34;爬取失败&#34;) r.raise_for_status()用来判断status_code的返回值，如果不是200，则返回一个HTTPError异常。
2、爬虫中六种常用的异常处理。 异常说明requests.ConnectionError网络连接错误异常， 如DNS查询失败，拒接连接等requests.HTTPErrorHTTP错误异常requests.URLRequiredURL缺失异常requests.TooManyRedirects超过最大重定向次数，产生重定向异常requests.ConnectTimeout连接远程服务时，超时异常requests.Timeout请求URL超时， 产生超时异常 3、requests库的七个主要方法。 3.1 七个主要方法 方法说明requests.request()构造一个请求，支撑以下各种方法的基础方法requests.get()获取HTML网页的主要方法，对应于HTTP的GETrequests.head()获取HTML网页头信息的方法， 对应HTTP的HEADrequests.post()向HTML网页提交POST请求的方法， 对应于HTTP的POSTrequests.put()向HTML网页提交PUT请求的方法，对应于HTTP的PUTrequests.patch()向HTML网页提交局部修改请求，对应于HTTP的PATCHrequests.delete()向HTML页面提交删除请求，对应于HTTP的DELETE 3.2 HTTP协议对资源的操作 方法说明GET请求获取URL位置资源HEAD请求获取URL位置资源的响应报告，即获得该资源的头部信息POST请求向URL位置的资源后添加新的数据PUT请求向URL位置储存一个资源，覆盖原URL位置的资源PATCH请求局部更新URL位置的资源，即改变该处资源的部分内容DELETE请求删除URL位置储存的资源 4、requests库方法的参数详解 4." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/1907424db0e9474a515525e4ecc08ec2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-16T19:34:30+08:00" />
<meta property="article:modified_time" content="2020-05-16T19:34:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python爬虫基础requests库的使用以及参数详解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1requests_1" rel="nofollow">1、简单介绍requests的使用方法</a></li><li><a href="#2_43" rel="nofollow">2、爬虫中六种常用的异常处理。</a></li><li><a href="#3requests_52" rel="nofollow">3、requests库的七个主要方法。</a></li><li><ul><li><a href="#31__53" rel="nofollow">3.1 七个主要方法</a></li><li><a href="#32__HTTP_63" rel="nofollow">3.2 HTTP协议对资源的操作</a></li></ul> 
  </li><li><a href="#4requests_73" rel="nofollow">4、requests库方法的参数详解</a></li><li><ul><li><a href="#41__requestrequestsrequestmethod_url_kwargs_74" rel="nofollow">4.1 request()参数（requests.request(method, url, **kwargs)）</a></li><li><ul><li><a href="#411_method_75" rel="nofollow">4.1.1 method</a></li><li><a href="#412_url_77" rel="nofollow">4.1.2 url</a></li><li><a href="#413_kwargs13_79" rel="nofollow">4.1.3 **kwargs对应的13个参数</a></li><li><a href="#414__96" rel="nofollow">4.1.4 具体使用方法</a></li></ul> 
   </li><li><a href="#42__120" rel="nofollow">4.2 其他六个方法的参数</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1requests_1"></a>1、简单介绍requests的使用方法</h2> 
<p>以百度网站为例：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'http://www.baidu.com'</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>status_code<span class="token punctuation">)</span>
</code></pre> 
<p>调用status_code后，会返回一个值，如果返回值为200，则代表访问成功。<br> 接着使用text查看内容：</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
</code></pre> 
<p>我们会发现有许多乱码，因此就需要改变编码方式。</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>encoding<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>apparent_encoding<span class="token punctuation">)</span>
r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding
<span class="token comment"># 也可以这样写</span>
<span class="token comment"># r.encoding = 'utf-8'</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/26/1d/Kj4eVSck_o.png" alt="在这里插入图片描述"><br> encoding方法是从HTTPheader中猜测响应内容的编码，但如果header中不存在charset字段，就默认编码为ISO-8859-1，而apparent_encoding则是从内容中分析编码，只需将它赋给encoding 即可。</p> 
<p>下面是爬虫通用代码框架：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
<span class="token keyword">try</span><span class="token punctuation">:</span>
    url <span class="token operator">=</span> <span class="token string">'http://www.baidu.com'</span>
    r <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
    r<span class="token punctuation">.</span>raise_for_status<span class="token punctuation">(</span><span class="token punctuation">)</span>
    r<span class="token punctuation">.</span>encoding <span class="token operator">=</span> r<span class="token punctuation">.</span>apparent_encoding
    <span class="token keyword">print</span><span class="token punctuation">(</span>r<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
<span class="token keyword">except</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"爬取失败"</span><span class="token punctuation">)</span>
</code></pre> 
<p>r.raise_for_status()用来判断status_code的返回值，如果不是200，则返回一个HTTPError异常。</p> 
<h2><a id="2_43"></a>2、爬虫中六种常用的异常处理。</h2> 
<table><thead><tr><th>异常</th><th>说明</th></tr></thead><tbody><tr><td>requests.ConnectionError</td><td>网络连接错误异常， 如DNS查询失败，拒接连接等</td></tr><tr><td>requests.HTTPError</td><td>HTTP错误异常</td></tr><tr><td>requests.URLRequired</td><td>URL缺失异常</td></tr><tr><td>requests.TooManyRedirects</td><td>超过最大重定向次数，产生重定向异常</td></tr><tr><td>requests.ConnectTimeout</td><td>连接远程服务时，超时异常</td></tr><tr><td>requests.Timeout</td><td>请求URL超时， 产生超时异常</td></tr></tbody></table> 
<h2><a id="3requests_52"></a>3、requests库的七个主要方法。</h2> 
<h3><a id="31__53"></a>3.1 七个主要方法</h3> 
<table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>requests.request()</td><td>构造一个请求，支撑以下各种方法的基础方法</td></tr><tr><td>requests.get()</td><td>获取HTML网页的主要方法，对应于HTTP的GET</td></tr><tr><td>requests.head()</td><td>获取HTML网页头信息的方法， 对应HTTP的HEAD</td></tr><tr><td>requests.post()</td><td>向HTML网页提交POST请求的方法， 对应于HTTP的POST</td></tr><tr><td>requests.put()</td><td>向HTML网页提交PUT请求的方法，对应于HTTP的PUT</td></tr><tr><td>requests.patch()</td><td>向HTML网页提交局部修改请求，对应于HTTP的PATCH</td></tr><tr><td>requests.delete()</td><td>向HTML页面提交删除请求，对应于HTTP的DELETE</td></tr></tbody></table> 
<h3><a id="32__HTTP_63"></a>3.2 HTTP协议对资源的操作</h3> 
<table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>GET</td><td>请求获取URL位置资源</td></tr><tr><td>HEAD</td><td>请求获取URL位置资源的响应报告，即获得该资源的头部信息</td></tr><tr><td>POST</td><td>请求向URL位置的资源后添加新的数据</td></tr><tr><td>PUT</td><td>请求向URL位置储存一个资源，覆盖原URL位置的资源</td></tr><tr><td>PATCH</td><td>请求局部更新URL位置的资源，即改变该处资源的部分内容</td></tr><tr><td>DELETE</td><td>请求删除URL位置储存的资源</td></tr></tbody></table> 
<h2><a id="4requests_73"></a>4、requests库方法的参数详解</h2> 
<h3><a id="41__requestrequestsrequestmethod_url_kwargs_74"></a>4.1 request()参数（requests.request(method, url, **kwargs)）</h3> 
<h4><a id="411_method_75"></a>4.1.1 method</h4> 
<p>请求方式，对应GET、POST、PUT等七种操作方法</p> 
<h4><a id="412_url_77"></a>4.1.2 url</h4> 
<p>文本连接</p> 
<h4><a id="413_kwargs13_79"></a>4.1.3 **kwargs对应的13个参数</h4> 
<table><thead><tr><th>参数</th><th>说明</th></tr></thead><tbody><tr><td>params</td><td>字典或字节序列，作为参数增加到url中</td></tr><tr><td>data</td><td>字典，字节序列或文件对象，作为request的内容</td></tr><tr><td>json</td><td>JSON格式的数据，作为request的内容</td></tr><tr><td>headers</td><td>字典，HTTP定制头</td></tr><tr><td>cookies</td><td>字典或CookieJar， request中的cookie</td></tr><tr><td>auth</td><td>元组，支持HTTp认证功能</td></tr><tr><td>files</td><td>字典类型，传输文件</td></tr><tr><td>timeout</td><td>设定超时时间，秒为单位</td></tr><tr><td>proxies</td><td>字典类型，设定访问代理服务器，可以增加登录认证</td></tr><tr><td>allow_redirects</td><td>重定向开关，默认为True</td></tr><tr><td>stream</td><td>获取内容立即下载开关，默认为True</td></tr><tr><td>verify</td><td>认证SSL证书开关，默认为True</td></tr><tr><td>cert</td><td>本地SSL证书路径</td></tr></tbody></table> 
<h4><a id="414__96"></a>4.1.4 具体使用方法</h4> 
<p>以params和headers为例，其他类似：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests

kv1 <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'key1'</span><span class="token punctuation">:</span> <span class="token string">'value1'</span><span class="token punctuation">,</span> <span class="token string">'key2'</span><span class="token punctuation">:</span> <span class="token string">'value2'</span><span class="token punctuation">}</span>
kv2 <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'User-Agent'</span><span class="token punctuation">:</span> <span class="token string">'chrome'</span><span class="token punctuation">}</span>
url <span class="token operator">=</span> <span class="token string">'http://www.baidu.com'</span>
r1 <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">"GET"</span><span class="token punctuation">,</span> url<span class="token punctuation">,</span> params<span class="token operator">=</span>kv1<span class="token punctuation">)</span>
r2 <span class="token operator">=</span> requests<span class="token punctuation">.</span>request<span class="token punctuation">(</span><span class="token string">'POST'</span><span class="token punctuation">,</span> url<span class="token punctuation">,</span> headers<span class="token operator">=</span>kv2<span class="token punctuation">)</span>

<span class="token comment"># 使用params后</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>r1<span class="token punctuation">.</span>url<span class="token punctuation">)</span>

<span class="token comment"># 原User-Agent显示为python爬虫</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>r1<span class="token punctuation">.</span>request<span class="token punctuation">.</span>headers<span class="token punctuation">)</span>

<span class="token comment"># 伪装为谷歌浏览器chrome进行访问后的User-Agent</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>r2<span class="token punctuation">.</span>request<span class="token punctuation">.</span>headers<span class="token punctuation">)</span>

</code></pre> 
<p>结果：<br> <img src="https://images2.imgbox.com/cc/5a/RU039Zhf_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="42__120"></a>4.2 其他六个方法的参数</h3> 
<table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>1、</td><td>requests.get(url, params=None, **kwargs)</td></tr><tr><td>2、</td><td>requests.head(url, **kwargs)</td></tr><tr><td>3、</td><td>requests.post(url, data=None, json=None, **kwargs)</td></tr><tr><td>4、</td><td>requests.put(url, data=None, **kwargs)</td></tr><tr><td>5、</td><td>requests.patch(url, data=None, **kwargs)</td></tr><tr><td>6、</td><td>requests.delete(url, **kwargs)</td></tr></tbody></table> 
<p>对应参数即为上面内容。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7962a124d95905fb06ef0c46981f1434/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Https解决的问题及其连接过程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/54a2fc107159b90c99c598087e4fb9ac/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">js 24小时制  给定多个时间段 计算剩下的时间段</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>