<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>æ·±åº¦å­¦ä¹  Day23â€”â€”J3DenseNetç®—æ³•å®æˆ˜ä¸è§£æ - èœé¸Ÿç¨‹åºå‘˜åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="æ·±åº¦å­¦ä¹  Day23â€”â€”J3DenseNetç®—æ³•å®æˆ˜ä¸è§£æ" />
<meta property="og:description" content="ğŸ¨ æœ¬æ–‡ä¸ºğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥ ä¸­çš„å­¦ä¹ è®°å½•åšå®¢ğŸ– åŸä½œè€…ï¼šKåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶ğŸš€ æ–‡ç« æ¥æºï¼šKåŒå­¦çš„å­¦ä¹ åœˆå­ æ–‡ç« ç›®å½• å‰è¨€1 æˆ‘çš„ç¯å¢ƒ2 pytorchå®ç°DenseNetç®—æ³•2.1 å‰æœŸå‡†å¤‡2.1.1 å¼•å…¥åº“2.1.2 è®¾ç½®GPUï¼ˆå¦‚æœè®¾å¤‡ä¸Šæ”¯æŒGPUå°±ä½¿ç”¨GPU,å¦åˆ™ä½¿ç”¨CPUï¼‰2.1.3 å¯¼å…¥æ•°æ®2.1.4 å¯è§†åŒ–æ•°æ®2.1.4 å›¾åƒæ•°æ®å˜æ¢2.1.4 åˆ’åˆ†æ•°æ®é›†2.1.4 åŠ è½½æ•°æ®2.1.4 æŸ¥çœ‹æ•°æ® 2.2 æ­å»ºdensenet121æ¨¡å‹2.3 è®­ç»ƒæ¨¡å‹2.3.1 è®¾ç½®è¶…å‚æ•°2.3.2 ç¼–å†™è®­ç»ƒå‡½æ•°2.3.3 ç¼–å†™æµ‹è¯•å‡½æ•°2.3.4 æ­£å¼è®­ç»ƒ 2.4 ç»“æœå¯è§†åŒ–2.4 æŒ‡å®šå›¾ç‰‡è¿›è¡Œé¢„æµ‹2.6 æ¨¡å‹è¯„ä¼° 3 tensorflowå®ç°DenseNetç®—æ³•3.1.å¼•å…¥åº“3.2.è®¾ç½®GPUï¼ˆå¦‚æœä½¿ç”¨çš„æ˜¯CPUå¯ä»¥å¿½ç•¥è¿™æ­¥ï¼‰3.3.å¯¼å…¥æ•°æ®3.4.æŸ¥çœ‹æ•°æ®3.5.åŠ è½½æ•°æ®3.6.å†æ¬¡æ£€æŸ¥æ•°æ®3.7.é…ç½®æ•°æ®é›†3.8.å¯è§†åŒ–æ•°æ®3.9.æ„å»ºDenseNetç½‘ç»œ3.10.ç¼–è¯‘æ¨¡å‹3.11.è®­ç»ƒæ¨¡å‹3.12.æ¨¡å‹è¯„ä¼°3.13.å›¾åƒé¢„æµ‹ 4 çŸ¥è¯†ç‚¹è¯¦è§£4.1 DenseNetç®—æ³•è¯¦è§£4.1.1 å‰è¨€4.1.2 è®¾è®¡ç†å¿µ4.1.2.1 æ ‡å‡†ç¥ç»ç½‘ç»œ4.1.2.2 ResNet4.1.2.3 DenseNet4.1.3 ç½‘ç»œç»“æ„4.1.4 æ•ˆæœå¯¹æ¯”4.1.5 ä½¿ç”¨Pytrochå®ç°DenseNet121 æ€»ç»“ å‰è¨€ å…³é”®å­—ï¼š pytorchå®ç°DenseNetç®—æ³•ï¼Œtensorflowå®ç°DenseNetç®—æ³•ï¼ŒDenseNetç®—æ³•è¯¦è§£
1 æˆ‘çš„ç¯å¢ƒ ç”µè„‘ç³»ç»Ÿï¼šWindows 11è¯­è¨€ç¯å¢ƒï¼špython 3.8.6ç¼–è¯‘å™¨ï¼špycharm2020.2.3æ·±åº¦å­¦ä¹ ç¯å¢ƒï¼š
torch == 1.9.1&#43;cu111
torchvision == 0.10.1&#43;cu111
TensorFlow 2.10.1æ˜¾å¡ï¼šNVIDIA GeForce RTX 4070 2 pytorchå®ç°DenseNetç®—æ³• 2.1 å‰æœŸå‡†å¤‡ 2.1.1 å¼•å…¥åº“ import torch import torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b9e9f14546e14d2c2a2077853bcb1748/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-04T16:07:45+08:00" />
<meta property="article:modified_time" content="2024-01-04T16:07:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="èœé¸Ÿç¨‹åºå‘˜åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">èœé¸Ÿç¨‹åºå‘˜åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">æ·±åº¦å­¦ä¹  Day23â€”â€”J3DenseNetç®—æ³•å®æˆ˜ä¸è§£æ</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <ul><li><strong>ğŸ¨ æœ¬æ–‡ä¸º<a href="https://mp.weixin.qq.com/s/AtyZUu_j2k_ScNH6e732ow" rel="nofollow">ğŸ”—365å¤©æ·±åº¦å­¦ä¹ è®­ç»ƒè¥</a> ä¸­çš„å­¦ä¹ è®°å½•åšå®¢</strong></li><li><strong>ğŸ– åŸä½œè€…ï¼š<a href="https://mtyjkh.blog.csdn.net/" rel="nofollow">KåŒå­¦å•Š | æ¥è¾…å¯¼ã€é¡¹ç›®å®šåˆ¶</a></strong></li><li><strong>ğŸš€ æ–‡ç« æ¥æºï¼š<a href="https://www.yuque.com/mingtian-fkmxf/zxwb45" rel="nofollow">KåŒå­¦çš„å­¦ä¹ åœˆå­</a></strong></li></ul> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>æ–‡ç« ç›®å½•</h4> 
 <ul><li><a href="#_10" rel="nofollow">å‰è¨€</a></li><li><a href="#1__13" rel="nofollow">1 æˆ‘çš„ç¯å¢ƒ</a></li><li><a href="#2_pytorchDenseNet_23" rel="nofollow">2 pytorchå®ç°DenseNetç®—æ³•</a></li><li><ul><li><a href="#21__24" rel="nofollow">2.1 å‰æœŸå‡†å¤‡</a></li><li><ul><li><a href="#211__25" rel="nofollow">2.1.1 å¼•å…¥åº“</a></li><li><a href="#212_GPUGPUGPUCPU_51" rel="nofollow">2.1.2 è®¾ç½®GPUï¼ˆå¦‚æœè®¾å¤‡ä¸Šæ”¯æŒGPUå°±ä½¿ç”¨GPU,å¦åˆ™ä½¿ç”¨CPUï¼‰</a></li><li><a href="#213__65" rel="nofollow">2.1.3 å¯¼å…¥æ•°æ®</a></li><li><a href="#214__82" rel="nofollow">2.1.4 å¯è§†åŒ–æ•°æ®</a></li><li><a href="#214__103" rel="nofollow">2.1.4 å›¾åƒæ•°æ®å˜æ¢</a></li><li><a href="#214__137" rel="nofollow">2.1.4 åˆ’åˆ†æ•°æ®é›†</a></li><li><a href="#214___157" rel="nofollow">2.1.4 åŠ è½½æ•°æ®</a></li><li><a href="#214__172" rel="nofollow">2.1.4 æŸ¥çœ‹æ•°æ®</a></li></ul> 
   </li><li><a href="#22_densenet121_189" rel="nofollow">2.2 æ­å»ºdensenet121æ¨¡å‹</a></li><li><a href="#23__1228" rel="nofollow">2.3 è®­ç»ƒæ¨¡å‹</a></li><li><ul><li><a href="#231__1229" rel="nofollow">2.3.1 è®¾ç½®è¶…å‚æ•°</a></li><li><a href="#232__1246" rel="nofollow">2.3.2 ç¼–å†™è®­ç»ƒå‡½æ•°</a></li><li><a href="#233__1279" rel="nofollow">2.3.3 ç¼–å†™æµ‹è¯•å‡½æ•°</a></li><li><a href="#234__1308" rel="nofollow">2.3.4 æ­£å¼è®­ç»ƒ</a></li></ul> 
   </li><li><a href="#24__1371" rel="nofollow">2.4 ç»“æœå¯è§†åŒ–</a></li><li><a href="#24__1395" rel="nofollow">2.4 æŒ‡å®šå›¾ç‰‡è¿›è¡Œé¢„æµ‹</a></li><li><a href="#26__1433" rel="nofollow">2.6 æ¨¡å‹è¯„ä¼°</a></li></ul> 
  </li><li><a href="#3_tensorflowDenseNet_1448" rel="nofollow">3 tensorflowå®ç°DenseNetç®—æ³•</a></li><li><ul><li><a href="#31_1449" rel="nofollow">3.1.å¼•å…¥åº“</a></li><li><a href="#32GPUCPU_1473" rel="nofollow">3.2.è®¾ç½®GPUï¼ˆå¦‚æœä½¿ç”¨çš„æ˜¯CPUå¯ä»¥å¿½ç•¥è¿™æ­¥ï¼‰</a></li><li><a href="#33_1491" rel="nofollow">3.3.å¯¼å…¥æ•°æ®</a></li><li><a href="#34_1498" rel="nofollow">3.4.æŸ¥çœ‹æ•°æ®</a></li><li><a href="#35_1521" rel="nofollow">3.5.åŠ è½½æ•°æ®</a></li><li><a href="#36_1557" rel="nofollow">3.6.å†æ¬¡æ£€æŸ¥æ•°æ®</a></li><li><a href="#37_1574" rel="nofollow">3.7.é…ç½®æ•°æ®é›†</a></li><li><a href="#38_1583" rel="nofollow">3.8.å¯è§†åŒ–æ•°æ®</a></li><li><a href="#39DenseNet_1599" rel="nofollow">3.9.æ„å»ºDenseNetç½‘ç»œ</a></li><li><a href="#310_2708" rel="nofollow">3.10.ç¼–è¯‘æ¨¡å‹</a></li><li><a href="#311_2719" rel="nofollow">3.11.è®­ç»ƒæ¨¡å‹</a></li><li><a href="#312_2778" rel="nofollow">3.12.æ¨¡å‹è¯„ä¼°</a></li><li><a href="#313_2803" rel="nofollow">3.13.å›¾åƒé¢„æµ‹</a></li></ul> 
  </li><li><a href="#4__2831" rel="nofollow">4 çŸ¥è¯†ç‚¹è¯¦è§£</a></li><li><ul><li><a href="#41_DenseNet_2832" rel="nofollow">4.1 DenseNetç®—æ³•è¯¦è§£</a></li><li><ul><li><a href="#411__2833" rel="nofollow">4.1.1 å‰è¨€</a></li><li><a href="#412__2845" rel="nofollow">4.1.2 è®¾è®¡ç†å¿µ</a></li><li><a href="#4121__2853" rel="nofollow">4.1.2.1 æ ‡å‡†ç¥ç»ç½‘ç»œ</a></li><li><a href="#4122_ResNet_2860" rel="nofollow">4.1.2.2 ResNet</a></li><li><a href="#4123_DenseNet_2867" rel="nofollow">4.1.2.3 DenseNet</a></li><li><a href="#413__2878" rel="nofollow">4.1.3 ç½‘ç»œç»“æ„</a></li><li><a href="#414__2911" rel="nofollow">4.1.4 æ•ˆæœå¯¹æ¯”</a></li><li><a href="#415_PytrochDenseNet121_2916" rel="nofollow">4.1.5 ä½¿ç”¨Pytrochå®ç°DenseNet121</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_2929" rel="nofollow">æ€»ç»“</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_10"></a>å‰è¨€</h2> 
<p>å…³é”®å­—ï¼š pytorchå®ç°DenseNetç®—æ³•ï¼Œtensorflowå®ç°DenseNetç®—æ³•ï¼ŒDenseNetç®—æ³•è¯¦è§£</p> 
<h2><a id="1__13"></a>1 æˆ‘çš„ç¯å¢ƒ</h2> 
<ul><li>ç”µè„‘ç³»ç»Ÿï¼šWindows 11</li><li>è¯­è¨€ç¯å¢ƒï¼špython 3.8.6</li><li>ç¼–è¯‘å™¨ï¼špycharm2020.2.3</li><li>æ·±åº¦å­¦ä¹ ç¯å¢ƒï¼š<br> torch == 1.9.1+cu111<br> torchvision == 0.10.1+cu111<br> TensorFlow 2.10.1</li><li>æ˜¾å¡ï¼šNVIDIA GeForce RTX 4070</li></ul> 
<h2><a id="2_pytorchDenseNet_23"></a>2 pytorchå®ç°DenseNetç®—æ³•</h2> 
<h3><a id="21__24"></a>2.1 å‰æœŸå‡†å¤‡</h3> 
<h4><a id="211__25"></a>2.1.1 å¼•å…¥åº“</h4> 
<pre><code class="prism language-python">
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> time
<span class="token keyword">import</span> copy
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span> datasets
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> torchsummary <span class="token keyword">as</span> summary
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
<span class="token keyword">import</span> re
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>model_zoo <span class="token keyword">as</span> model_zoo
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.dpi'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>  <span class="token comment"># åˆ†è¾¨ç‡</span>
<span class="token keyword">import</span> warnings

warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>  <span class="token comment"># å¿½ç•¥ä¸€äº›warningå†…å®¹ï¼Œæ— éœ€æ‰“å°</span>

</code></pre> 
<h4><a id="212_GPUGPUGPUCPU_51"></a>2.1.2 è®¾ç½®GPUï¼ˆå¦‚æœè®¾å¤‡ä¸Šæ”¯æŒGPUå°±ä½¿ç”¨GPU,å¦åˆ™ä½¿ç”¨CPUï¼‰</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""å‰æœŸå‡†å¤‡-è®¾ç½®GPU"""</span>
<span class="token comment"># å¦‚æœè®¾å¤‡ä¸Šæ”¯æŒGPUå°±ä½¿ç”¨GPU,å¦åˆ™ä½¿ç”¨CPU</span>
 device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
 <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Using {} device"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>Using cuda device
</code></pre> 
<h4><a id="213__65"></a>2.1.3 å¯¼å…¥æ•°æ®</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-å¯¼å…¥æ•°æ®'''</span>
data_dir <span class="token operator">=</span> <span class="token string">r"D:\DeepLearning\data\bird\bird_photos"</span>
data_dir <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>

data_paths <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
classeNames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\\"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> path <span class="token keyword">in</span> data_paths<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classeNames<span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>['Bananaquit', 'Black Skimmer', 'Black Throated Bushtiti', 'Cockatoo']

</code></pre> 
<h4><a id="214__82"></a>2.1.4 å¯è§†åŒ–æ•°æ®</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-å¯è§†åŒ–æ•°æ®'''</span>
subfolder <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"Cockatoo"</span>
image_files <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> subfolder<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> p<span class="token punctuation">.</span>suffix <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">".jpg"</span><span class="token punctuation">,</span> <span class="token string">".png"</span><span class="token punctuation">,</span> <span class="token string">".jpeg"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_files<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    image_file <span class="token operator">=</span> image_files<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>image_file<span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
<span class="token comment"># æ˜¾ç¤ºå›¾ç‰‡</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/7b/92/WUyPiXcP_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h4><a id="214__103"></a>2.1.4 å›¾åƒæ•°æ®å˜æ¢</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-å›¾åƒæ•°æ®å˜æ¢'''</span>
total_datadir <span class="token operator">=</span> data_dir

<span class="token comment"># å…³äºtransforms.Composeçš„æ›´å¤šä»‹ç»å¯ä»¥å‚è€ƒï¼šhttps://blog.csdn.net/qq_38251616/article/details/124878863</span>
train_transforms <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># å°†è¾“å…¥å›¾ç‰‡resizeæˆç»Ÿä¸€å°ºå¯¸</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># å°†PIL Imageæˆ–numpy.ndarrayè½¬æ¢ä¸ºtensorï¼Œå¹¶å½’ä¸€åŒ–åˆ°[0,1]ä¹‹é—´</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>  <span class="token comment"># æ ‡å‡†åŒ–å¤„ç†--&gt;è½¬æ¢ä¸ºæ ‡å‡†æ­£å¤ªåˆ†å¸ƒï¼ˆé«˜æ–¯åˆ†å¸ƒï¼‰ï¼Œä½¿æ¨¡å‹æ›´å®¹æ˜“æ”¶æ•›</span>
        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># å…¶ä¸­ mean=[0.485,0.456,0.406]ä¸std=[0.229,0.224,0.225] ä»æ•°æ®é›†ä¸­éšæœºæŠ½æ ·è®¡ç®—å¾—åˆ°çš„ã€‚</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
total_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>total_datadir<span class="token punctuation">,</span> transform<span class="token operator">=</span>train_transforms<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>total_data<span class="token punctuation">.</span>class_to_idx<span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>Dataset ImageFolder
    Number of datapoints: 565
    Root location: D:\DeepLearning\data\bird\bird_photos
    StandardTransform
Transform: Compose(
               Resize(size=[224, 224], interpolation=bilinear, max_size=None, antialias=None)
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           )
{'Bananaquit': 0, 'Black Skimmer': 1, 'Black Throated Bushtiti': 2, 'Cockatoo': 3}

</code></pre> 
<h4><a id="214__137"></a>2.1.4 åˆ’åˆ†æ•°æ®é›†</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-åˆ’åˆ†æ•°æ®é›†'''</span>
train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># train_sizeè¡¨ç¤ºè®­ç»ƒé›†å¤§å°ï¼Œé€šè¿‡å°†æ€»ä½“æ•°æ®é•¿åº¦çš„80%è½¬æ¢ä¸ºæ•´æ•°å¾—åˆ°ï¼›</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span> <span class="token operator">-</span> train_size  <span class="token comment"># test_sizeè¡¨ç¤ºæµ‹è¯•é›†å¤§å°ï¼Œæ˜¯æ€»ä½“æ•°æ®é•¿åº¦å‡å»è®­ç»ƒé›†å¤§å°ã€‚</span>
<span class="token comment"># ä½¿ç”¨torch.utils.data.random_split()æ–¹æ³•è¿›è¡Œæ•°æ®é›†åˆ’åˆ†ã€‚è¯¥æ–¹æ³•å°†æ€»ä½“æ•°æ®total_dataæŒ‰ç…§æŒ‡å®šçš„å¤§å°æ¯”ä¾‹ï¼ˆ[train_size, test_size]ï¼‰éšæœºåˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œ</span>
<span class="token comment"># å¹¶å°†åˆ’åˆ†ç»“æœåˆ†åˆ«èµ‹å€¼ç»™train_datasetå’Œtest_datasetä¸¤ä¸ªå˜é‡ã€‚</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>total_data<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_dataset={}\ntest_dataset={}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> test_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_size={}\ntest_size={}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>train_dataset=&lt;torch.utils.data.dataset.Subset object at 0x000001309DFA26D0&gt;
test_dataset=&lt;torch.utils.data.dataset.Subset object at 0x000001309DFA2760&gt;
train_size=452
test_size=113
</code></pre> 
<h4><a id="214___157"></a>2.1.4 åŠ è½½æ•°æ®</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-åŠ è½½æ•°æ®'''</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>

train_dl <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                                       batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                       shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                       num_workers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
test_dl <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>
                                      batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                      shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                      num_workers<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="214__172"></a>2.1.4 æŸ¥çœ‹æ•°æ®</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-æŸ¥çœ‹æ•°æ®'''</span>
<span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> test_dl<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shape of X [N, C, H, W]: "</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shape of y: "</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
    <span class="token keyword">break</span>
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>Shape of X [N, C, H, W]:  torch.Size([32, 3, 224, 224])
Shape of y:  torch.Size([32]) torch.int64
</code></pre> 
<h3><a id="22_densenet121_189"></a>2.2 æ­å»ºdensenet121æ¨¡å‹</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""æ„å»ºDenseNetç½‘ç»œ"""</span>
<span class="token comment"># è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨äº†Pytorchçš„æ¡†æ¶æ¥å®ç°DenseNetï¼Œ</span>
<span class="token comment"># é¦–å…ˆå®ç°DenseBlockä¸­çš„å†…éƒ¨ç»“æ„ï¼Œè¿™é‡Œæ˜¯BN+ReLU+1Ã—1Conv+BN+ReLU+3Ã—3Convç»“æ„ï¼Œæœ€åä¹ŸåŠ å…¥dropoutå±‚ç”¨äºè®­ç»ƒè¿‡ç¨‹ã€‚</span>
<span class="token keyword">class</span> <span class="token class-name">_DenseLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Basic unit of DenseBlock (using bottleneck layer) """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">,</span> bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span>
                                           kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span>
                                           kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>drop_rate <span class="token operator">=</span> drop_rate

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        new_features <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>drop_rate <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            new_features <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>new_features<span class="token punctuation">,</span> p<span class="token operator">=</span>self<span class="token punctuation">.</span>drop_rate<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> new_features<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


<span class="token comment"># å®ç°DenseBlockæ¨¡å—ï¼Œå†…éƒ¨æ˜¯å¯†é›†è¿æ¥æ–¹å¼ï¼ˆè¾“å…¥ç‰¹å¾æ•°çº¿æ€§å¢é•¿ï¼‰ï¼š</span>
<span class="token keyword">class</span> <span class="token class-name">_DenseBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""DenseBlock """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layer <span class="token operator">=</span> _DenseLayer<span class="token punctuation">(</span>
                num_input_features <span class="token operator">+</span> i <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'denselayer%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> layer<span class="token punctuation">)</span>


<span class="token comment"># å®ç°Transitionå±‚ï¼Œå®ƒä¸»è¦æ˜¯ä¸€ä¸ªå·ç§¯å±‚å’Œä¸€ä¸ªæ± åŒ–å±‚ï¼š</span>
<span class="token keyword">class</span> <span class="token class-name">_Transition</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> num_output_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_Transition<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">,</span> num_output_features<span class="token punctuation">,</span>
                                          kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'pool'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># æœ€åæˆ‘ä»¬å®ç°DenseNetç½‘ç»œï¼š</span>
<span class="token keyword">class</span> <span class="token class-name">DenseNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">r"""Densenet-BC model class, based on
    `"Densely Connected Convolutional Networks" &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;`
    Args:
        growth_rate (int) - how many filters to add each layer (`k` in paper)
        block_config (list of 3 or 4 ints) - how many layers in each pooling block
        num_init_features (int) - the number of filters to learn in the first convolution layer
        bn_size (int) - multiplicative factor for number of bottle neck layers
            (i.e. bn_size * k features in the bottleneck layer)
        drop_rate (float) - dropout rate after each dense layer
        num_classes (int) - number of classification classes
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> block_config<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 num_init_features<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">,</span> bn_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> compression<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> drop_rate<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                 num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>DenseNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># First Conv2d</span>
        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
            <span class="token punctuation">(</span><span class="token string">'conv0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> num_init_features<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">'norm0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_init_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">'relu0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">'pool0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


        <span class="token comment"># Each denseblock</span>
        num_features <span class="token operator">=</span> num_init_features
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> num_layers <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>block_config<span class="token punctuation">)</span><span class="token punctuation">:</span>
            block <span class="token operator">=</span> _DenseBlock<span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'denseblock%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> block<span class="token punctuation">)</span>
            num_features <span class="token operator">+=</span> num_layers <span class="token operator">*</span> growth_rate
            <span class="token keyword">if</span> i <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>block_config<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>
                transition <span class="token operator">=</span> _Transition<span class="token punctuation">(</span>num_input_features<span class="token operator">=</span>num_features<span class="token punctuation">,</span>
                                         num_output_features<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>num_features <span class="token operator">*</span> compression<span class="token punctuation">)</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'transition%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transition<span class="token punctuation">)</span>
                num_features <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>num_features <span class="token operator">*</span> compression<span class="token punctuation">)</span>

        <span class="token comment"># Final bn+relu</span>
        self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm5'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu5'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># classification layer</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

        <span class="token comment"># params initialization</span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        features <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>features<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>features<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out



model_urls <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'densenet121'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet121-a639ec97.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'densenet169'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet169-b2777c0a.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'densenet201'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet201-c1103571.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'densenet161'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet161-8d451a50.pth'</span><span class="token punctuation">}</span>


<span class="token keyword">def</span> <span class="token function">densenet121</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""DenseNet121"""</span>
    model <span class="token operator">=</span> DenseNet<span class="token punctuation">(</span>num_init_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> block_config<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>	<span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    <span class="token keyword">if</span> pretrained<span class="token punctuation">:</span>
        <span class="token comment"># '.'s are no longer allowed in module names, but pervious _DenseLayer</span>
        <span class="token comment"># has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.</span>
        <span class="token comment"># They are also in the checkpoints in model_urls. This pattern is used</span>
        <span class="token comment"># to find such keys.</span>
        pattern <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
            <span class="token string">r'^(.*denselayer\d+\.(?:norm|relu|conv))\.((?:[12])\.(?:weight|bias|running_mean|running_var))$'</span><span class="token punctuation">)</span>
        state_dict <span class="token operator">=</span> model_zoo<span class="token punctuation">.</span>load_url<span class="token punctuation">(</span>model_urls<span class="token punctuation">[</span><span class="token string">'densenet121'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>state_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            res <span class="token operator">=</span> pattern<span class="token punctuation">.</span><span class="token keyword">match</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span>
            <span class="token keyword">if</span> res<span class="token punctuation">:</span>
                new_key <span class="token operator">=</span> res<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> res<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
                state_dict<span class="token punctuation">[</span>new_key<span class="token punctuation">]</span> <span class="token operator">=</span> state_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
                <span class="token keyword">del</span> state_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

<span class="token triple-quoted-string string">"""æ­å»ºdensenet121æ¨¡å‹"""</span>
<span class="token comment"># model = densenet121().to(device)  </span>
model <span class="token operator">=</span> densenet121<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>summary<span class="token punctuation">.</span>summary<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># æŸ¥çœ‹æ¨¡å‹çš„å‚æ•°é‡ä»¥åŠç›¸å…³æŒ‡æ ‡</span>
    
</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>DenseNet(
  (features): Sequential(
    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu0): ReLU(inplace=True)
    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (denseblock1): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition1): _Transition(
      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock2): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition2): _Transition(
      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock3): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer17): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer18): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer19): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer20): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer21): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer22): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer23): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer24): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (transition3): _Transition(
      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
    (denseblock4): _DenseBlock(
      (denselayer1): _DenseLayer(
        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer2): _DenseLayer(
        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer3): _DenseLayer(
        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer4): _DenseLayer(
        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer5): _DenseLayer(
        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer6): _DenseLayer(
        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer7): _DenseLayer(
        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer8): _DenseLayer(
        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer9): _DenseLayer(
        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer10): _DenseLayer(
        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer11): _DenseLayer(
        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer12): _DenseLayer(
        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer13): _DenseLayer(
        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer14): _DenseLayer(
        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer15): _DenseLayer(
        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
      (denselayer16): _DenseLayer(
        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      )
    )
    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu5): ReLU(inplace=True)
  )
  (classifier): Linear(in_features=1024, out_features=1000, bias=True)
)
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
       BatchNorm2d-5           [-1, 64, 56, 56]             128
              ReLU-6           [-1, 64, 56, 56]               0
            Conv2d-7          [-1, 128, 56, 56]           8,192
       BatchNorm2d-8          [-1, 128, 56, 56]             256
              ReLU-9          [-1, 128, 56, 56]               0
           Conv2d-10           [-1, 32, 56, 56]          36,864
      BatchNorm2d-11           [-1, 96, 56, 56]             192
             ReLU-12           [-1, 96, 56, 56]               0
           Conv2d-13          [-1, 128, 56, 56]          12,288
      BatchNorm2d-14          [-1, 128, 56, 56]             256
             ReLU-15          [-1, 128, 56, 56]               0
           Conv2d-16           [-1, 32, 56, 56]          36,864
      BatchNorm2d-17          [-1, 128, 56, 56]             256
             ReLU-18          [-1, 128, 56, 56]               0
           Conv2d-19          [-1, 128, 56, 56]          16,384
      BatchNorm2d-20          [-1, 128, 56, 56]             256
             ReLU-21          [-1, 128, 56, 56]               0
           Conv2d-22           [-1, 32, 56, 56]          36,864
      BatchNorm2d-23          [-1, 160, 56, 56]             320
             ReLU-24          [-1, 160, 56, 56]               0
           Conv2d-25          [-1, 128, 56, 56]          20,480
      BatchNorm2d-26          [-1, 128, 56, 56]             256
             ReLU-27          [-1, 128, 56, 56]               0
           Conv2d-28           [-1, 32, 56, 56]          36,864
      BatchNorm2d-29          [-1, 192, 56, 56]             384
             ReLU-30          [-1, 192, 56, 56]               0
           Conv2d-31          [-1, 128, 56, 56]          24,576
      BatchNorm2d-32          [-1, 128, 56, 56]             256
             ReLU-33          [-1, 128, 56, 56]               0
           Conv2d-34           [-1, 32, 56, 56]          36,864
      BatchNorm2d-35          [-1, 224, 56, 56]             448
             ReLU-36          [-1, 224, 56, 56]               0
           Conv2d-37          [-1, 128, 56, 56]          28,672
      BatchNorm2d-38          [-1, 128, 56, 56]             256
             ReLU-39          [-1, 128, 56, 56]               0
           Conv2d-40           [-1, 32, 56, 56]          36,864
      BatchNorm2d-41          [-1, 256, 56, 56]             512
             ReLU-42          [-1, 256, 56, 56]               0
           Conv2d-43          [-1, 128, 56, 56]          32,768
        AvgPool2d-44          [-1, 128, 28, 28]               0
      BatchNorm2d-45          [-1, 128, 28, 28]             256
             ReLU-46          [-1, 128, 28, 28]               0
           Conv2d-47          [-1, 128, 28, 28]          16,384
      BatchNorm2d-48          [-1, 128, 28, 28]             256
             ReLU-49          [-1, 128, 28, 28]               0
           Conv2d-50           [-1, 32, 28, 28]          36,864
      BatchNorm2d-51          [-1, 160, 28, 28]             320
             ReLU-52          [-1, 160, 28, 28]               0
           Conv2d-53          [-1, 128, 28, 28]          20,480
      BatchNorm2d-54          [-1, 128, 28, 28]             256
             ReLU-55          [-1, 128, 28, 28]               0
           Conv2d-56           [-1, 32, 28, 28]          36,864
      BatchNorm2d-57          [-1, 192, 28, 28]             384
             ReLU-58          [-1, 192, 28, 28]               0
           Conv2d-59          [-1, 128, 28, 28]          24,576
      BatchNorm2d-60          [-1, 128, 28, 28]             256
             ReLU-61          [-1, 128, 28, 28]               0
           Conv2d-62           [-1, 32, 28, 28]          36,864
      BatchNorm2d-63          [-1, 224, 28, 28]             448
             ReLU-64          [-1, 224, 28, 28]               0
           Conv2d-65          [-1, 128, 28, 28]          28,672
      BatchNorm2d-66          [-1, 128, 28, 28]             256
             ReLU-67          [-1, 128, 28, 28]               0
           Conv2d-68           [-1, 32, 28, 28]          36,864
      BatchNorm2d-69          [-1, 256, 28, 28]             512
             ReLU-70          [-1, 256, 28, 28]               0
           Conv2d-71          [-1, 128, 28, 28]          32,768
      BatchNorm2d-72          [-1, 128, 28, 28]             256
             ReLU-73          [-1, 128, 28, 28]               0
           Conv2d-74           [-1, 32, 28, 28]          36,864
      BatchNorm2d-75          [-1, 288, 28, 28]             576
             ReLU-76          [-1, 288, 28, 28]               0
           Conv2d-77          [-1, 128, 28, 28]          36,864
      BatchNorm2d-78          [-1, 128, 28, 28]             256
             ReLU-79          [-1, 128, 28, 28]               0
           Conv2d-80           [-1, 32, 28, 28]          36,864
      BatchNorm2d-81          [-1, 320, 28, 28]             640
             ReLU-82          [-1, 320, 28, 28]               0
           Conv2d-83          [-1, 128, 28, 28]          40,960
      BatchNorm2d-84          [-1, 128, 28, 28]             256
             ReLU-85          [-1, 128, 28, 28]               0
           Conv2d-86           [-1, 32, 28, 28]          36,864
      BatchNorm2d-87          [-1, 352, 28, 28]             704
             ReLU-88          [-1, 352, 28, 28]               0
           Conv2d-89          [-1, 128, 28, 28]          45,056
      BatchNorm2d-90          [-1, 128, 28, 28]             256
             ReLU-91          [-1, 128, 28, 28]               0
           Conv2d-92           [-1, 32, 28, 28]          36,864
      BatchNorm2d-93          [-1, 384, 28, 28]             768
             ReLU-94          [-1, 384, 28, 28]               0
           Conv2d-95          [-1, 128, 28, 28]          49,152
      BatchNorm2d-96          [-1, 128, 28, 28]             256
             ReLU-97          [-1, 128, 28, 28]               0
           Conv2d-98           [-1, 32, 28, 28]          36,864
      BatchNorm2d-99          [-1, 416, 28, 28]             832
            ReLU-100          [-1, 416, 28, 28]               0
          Conv2d-101          [-1, 128, 28, 28]          53,248
     BatchNorm2d-102          [-1, 128, 28, 28]             256
            ReLU-103          [-1, 128, 28, 28]               0
          Conv2d-104           [-1, 32, 28, 28]          36,864
     BatchNorm2d-105          [-1, 448, 28, 28]             896
            ReLU-106          [-1, 448, 28, 28]               0
          Conv2d-107          [-1, 128, 28, 28]          57,344
     BatchNorm2d-108          [-1, 128, 28, 28]             256
            ReLU-109          [-1, 128, 28, 28]               0
          Conv2d-110           [-1, 32, 28, 28]          36,864
     BatchNorm2d-111          [-1, 480, 28, 28]             960
            ReLU-112          [-1, 480, 28, 28]               0
          Conv2d-113          [-1, 128, 28, 28]          61,440
     BatchNorm2d-114          [-1, 128, 28, 28]             256
            ReLU-115          [-1, 128, 28, 28]               0
          Conv2d-116           [-1, 32, 28, 28]          36,864
     BatchNorm2d-117          [-1, 512, 28, 28]           1,024
            ReLU-118          [-1, 512, 28, 28]               0
          Conv2d-119          [-1, 256, 28, 28]         131,072
       AvgPool2d-120          [-1, 256, 14, 14]               0
     BatchNorm2d-121          [-1, 256, 14, 14]             512
            ReLU-122          [-1, 256, 14, 14]               0
          Conv2d-123          [-1, 128, 14, 14]          32,768
     BatchNorm2d-124          [-1, 128, 14, 14]             256
            ReLU-125          [-1, 128, 14, 14]               0
          Conv2d-126           [-1, 32, 14, 14]          36,864
     BatchNorm2d-127          [-1, 288, 14, 14]             576
            ReLU-128          [-1, 288, 14, 14]               0
          Conv2d-129          [-1, 128, 14, 14]          36,864
     BatchNorm2d-130          [-1, 128, 14, 14]             256
            ReLU-131          [-1, 128, 14, 14]               0
          Conv2d-132           [-1, 32, 14, 14]          36,864
     BatchNorm2d-133          [-1, 320, 14, 14]             640
            ReLU-134          [-1, 320, 14, 14]               0
          Conv2d-135          [-1, 128, 14, 14]          40,960
     BatchNorm2d-136          [-1, 128, 14, 14]             256
            ReLU-137          [-1, 128, 14, 14]               0
          Conv2d-138           [-1, 32, 14, 14]          36,864
     BatchNorm2d-139          [-1, 352, 14, 14]             704
            ReLU-140          [-1, 352, 14, 14]               0
          Conv2d-141          [-1, 128, 14, 14]          45,056
     BatchNorm2d-142          [-1, 128, 14, 14]             256
            ReLU-143          [-1, 128, 14, 14]               0
          Conv2d-144           [-1, 32, 14, 14]          36,864
     BatchNorm2d-145          [-1, 384, 14, 14]             768
            ReLU-146          [-1, 384, 14, 14]               0
          Conv2d-147          [-1, 128, 14, 14]          49,152
     BatchNorm2d-148          [-1, 128, 14, 14]             256
            ReLU-149          [-1, 128, 14, 14]               0
          Conv2d-150           [-1, 32, 14, 14]          36,864
     BatchNorm2d-151          [-1, 416, 14, 14]             832
            ReLU-152          [-1, 416, 14, 14]               0
          Conv2d-153          [-1, 128, 14, 14]          53,248
     BatchNorm2d-154          [-1, 128, 14, 14]             256
            ReLU-155          [-1, 128, 14, 14]               0
          Conv2d-156           [-1, 32, 14, 14]          36,864
     BatchNorm2d-157          [-1, 448, 14, 14]             896
            ReLU-158          [-1, 448, 14, 14]               0
          Conv2d-159          [-1, 128, 14, 14]          57,344
     BatchNorm2d-160          [-1, 128, 14, 14]             256
            ReLU-161          [-1, 128, 14, 14]               0
          Conv2d-162           [-1, 32, 14, 14]          36,864
     BatchNorm2d-163          [-1, 480, 14, 14]             960
            ReLU-164          [-1, 480, 14, 14]               0
          Conv2d-165          [-1, 128, 14, 14]          61,440
     BatchNorm2d-166          [-1, 128, 14, 14]             256
            ReLU-167          [-1, 128, 14, 14]               0
          Conv2d-168           [-1, 32, 14, 14]          36,864
     BatchNorm2d-169          [-1, 512, 14, 14]           1,024
            ReLU-170          [-1, 512, 14, 14]               0
          Conv2d-171          [-1, 128, 14, 14]          65,536
     BatchNorm2d-172          [-1, 128, 14, 14]             256
            ReLU-173          [-1, 128, 14, 14]               0
          Conv2d-174           [-1, 32, 14, 14]          36,864
     BatchNorm2d-175          [-1, 544, 14, 14]           1,088
            ReLU-176          [-1, 544, 14, 14]               0
          Conv2d-177          [-1, 128, 14, 14]          69,632
     BatchNorm2d-178          [-1, 128, 14, 14]             256
            ReLU-179          [-1, 128, 14, 14]               0
          Conv2d-180           [-1, 32, 14, 14]          36,864
     BatchNorm2d-181          [-1, 576, 14, 14]           1,152
            ReLU-182          [-1, 576, 14, 14]               0
          Conv2d-183          [-1, 128, 14, 14]          73,728
     BatchNorm2d-184          [-1, 128, 14, 14]             256
            ReLU-185          [-1, 128, 14, 14]               0
          Conv2d-186           [-1, 32, 14, 14]          36,864
     BatchNorm2d-187          [-1, 608, 14, 14]           1,216
            ReLU-188          [-1, 608, 14, 14]               0
          Conv2d-189          [-1, 128, 14, 14]          77,824
     BatchNorm2d-190          [-1, 128, 14, 14]             256
            ReLU-191          [-1, 128, 14, 14]               0
          Conv2d-192           [-1, 32, 14, 14]          36,864
     BatchNorm2d-193          [-1, 640, 14, 14]           1,280
            ReLU-194          [-1, 640, 14, 14]               0
          Conv2d-195          [-1, 128, 14, 14]          81,920
     BatchNorm2d-196          [-1, 128, 14, 14]             256
            ReLU-197          [-1, 128, 14, 14]               0
          Conv2d-198           [-1, 32, 14, 14]          36,864
     BatchNorm2d-199          [-1, 672, 14, 14]           1,344
            ReLU-200          [-1, 672, 14, 14]               0
          Conv2d-201          [-1, 128, 14, 14]          86,016
     BatchNorm2d-202          [-1, 128, 14, 14]             256
            ReLU-203          [-1, 128, 14, 14]               0
          Conv2d-204           [-1, 32, 14, 14]          36,864
     BatchNorm2d-205          [-1, 704, 14, 14]           1,408
            ReLU-206          [-1, 704, 14, 14]               0
          Conv2d-207          [-1, 128, 14, 14]          90,112
     BatchNorm2d-208          [-1, 128, 14, 14]             256
            ReLU-209          [-1, 128, 14, 14]               0
          Conv2d-210           [-1, 32, 14, 14]          36,864
     BatchNorm2d-211          [-1, 736, 14, 14]           1,472
            ReLU-212          [-1, 736, 14, 14]               0
          Conv2d-213          [-1, 128, 14, 14]          94,208
     BatchNorm2d-214          [-1, 128, 14, 14]             256
            ReLU-215          [-1, 128, 14, 14]               0
          Conv2d-216           [-1, 32, 14, 14]          36,864
     BatchNorm2d-217          [-1, 768, 14, 14]           1,536
            ReLU-218          [-1, 768, 14, 14]               0
          Conv2d-219          [-1, 128, 14, 14]          98,304
     BatchNorm2d-220          [-1, 128, 14, 14]             256
            ReLU-221          [-1, 128, 14, 14]               0
          Conv2d-222           [-1, 32, 14, 14]          36,864
     BatchNorm2d-223          [-1, 800, 14, 14]           1,600
            ReLU-224          [-1, 800, 14, 14]               0
          Conv2d-225          [-1, 128, 14, 14]         102,400
     BatchNorm2d-226          [-1, 128, 14, 14]             256
            ReLU-227          [-1, 128, 14, 14]               0
          Conv2d-228           [-1, 32, 14, 14]          36,864
     BatchNorm2d-229          [-1, 832, 14, 14]           1,664
            ReLU-230          [-1, 832, 14, 14]               0
          Conv2d-231          [-1, 128, 14, 14]         106,496
     BatchNorm2d-232          [-1, 128, 14, 14]             256
            ReLU-233          [-1, 128, 14, 14]               0
          Conv2d-234           [-1, 32, 14, 14]          36,864
     BatchNorm2d-235          [-1, 864, 14, 14]           1,728
            ReLU-236          [-1, 864, 14, 14]               0
          Conv2d-237          [-1, 128, 14, 14]         110,592
     BatchNorm2d-238          [-1, 128, 14, 14]             256
            ReLU-239          [-1, 128, 14, 14]               0
          Conv2d-240           [-1, 32, 14, 14]          36,864
     BatchNorm2d-241          [-1, 896, 14, 14]           1,792
            ReLU-242          [-1, 896, 14, 14]               0
          Conv2d-243          [-1, 128, 14, 14]         114,688
     BatchNorm2d-244          [-1, 128, 14, 14]             256
            ReLU-245          [-1, 128, 14, 14]               0
          Conv2d-246           [-1, 32, 14, 14]          36,864
     BatchNorm2d-247          [-1, 928, 14, 14]           1,856
            ReLU-248          [-1, 928, 14, 14]               0
          Conv2d-249          [-1, 128, 14, 14]         118,784
     BatchNorm2d-250          [-1, 128, 14, 14]             256
            ReLU-251          [-1, 128, 14, 14]               0
          Conv2d-252           [-1, 32, 14, 14]          36,864
     BatchNorm2d-253          [-1, 960, 14, 14]           1,920
            ReLU-254          [-1, 960, 14, 14]               0
          Conv2d-255          [-1, 128, 14, 14]         122,880
     BatchNorm2d-256          [-1, 128, 14, 14]             256
            ReLU-257          [-1, 128, 14, 14]               0
          Conv2d-258           [-1, 32, 14, 14]          36,864
     BatchNorm2d-259          [-1, 992, 14, 14]           1,984
            ReLU-260          [-1, 992, 14, 14]               0
          Conv2d-261          [-1, 128, 14, 14]         126,976
     BatchNorm2d-262          [-1, 128, 14, 14]             256
            ReLU-263          [-1, 128, 14, 14]               0
          Conv2d-264           [-1, 32, 14, 14]          36,864
     BatchNorm2d-265         [-1, 1024, 14, 14]           2,048
            ReLU-266         [-1, 1024, 14, 14]               0
          Conv2d-267          [-1, 512, 14, 14]         524,288
       AvgPool2d-268            [-1, 512, 7, 7]               0
     BatchNorm2d-269            [-1, 512, 7, 7]           1,024
            ReLU-270            [-1, 512, 7, 7]               0
          Conv2d-271            [-1, 128, 7, 7]          65,536
     BatchNorm2d-272            [-1, 128, 7, 7]             256
            ReLU-273            [-1, 128, 7, 7]               0
          Conv2d-274             [-1, 32, 7, 7]          36,864
     BatchNorm2d-275            [-1, 544, 7, 7]           1,088
            ReLU-276            [-1, 544, 7, 7]               0
          Conv2d-277            [-1, 128, 7, 7]          69,632
     BatchNorm2d-278            [-1, 128, 7, 7]             256
            ReLU-279            [-1, 128, 7, 7]               0
          Conv2d-280             [-1, 32, 7, 7]          36,864
     BatchNorm2d-281            [-1, 576, 7, 7]           1,152
            ReLU-282            [-1, 576, 7, 7]               0
          Conv2d-283            [-1, 128, 7, 7]          73,728
     BatchNorm2d-284            [-1, 128, 7, 7]             256
            ReLU-285            [-1, 128, 7, 7]               0
          Conv2d-286             [-1, 32, 7, 7]          36,864
     BatchNorm2d-287            [-1, 608, 7, 7]           1,216
            ReLU-288            [-1, 608, 7, 7]               0
          Conv2d-289            [-1, 128, 7, 7]          77,824
     BatchNorm2d-290            [-1, 128, 7, 7]             256
            ReLU-291            [-1, 128, 7, 7]               0
          Conv2d-292             [-1, 32, 7, 7]          36,864
     BatchNorm2d-293            [-1, 640, 7, 7]           1,280
            ReLU-294            [-1, 640, 7, 7]               0
          Conv2d-295            [-1, 128, 7, 7]          81,920
     BatchNorm2d-296            [-1, 128, 7, 7]             256
            ReLU-297            [-1, 128, 7, 7]               0
          Conv2d-298             [-1, 32, 7, 7]          36,864
     BatchNorm2d-299            [-1, 672, 7, 7]           1,344
            ReLU-300            [-1, 672, 7, 7]               0
          Conv2d-301            [-1, 128, 7, 7]          86,016
     BatchNorm2d-302            [-1, 128, 7, 7]             256
            ReLU-303            [-1, 128, 7, 7]               0
          Conv2d-304             [-1, 32, 7, 7]          36,864
     BatchNorm2d-305            [-1, 704, 7, 7]           1,408
            ReLU-306            [-1, 704, 7, 7]               0
          Conv2d-307            [-1, 128, 7, 7]          90,112
     BatchNorm2d-308            [-1, 128, 7, 7]             256
            ReLU-309            [-1, 128, 7, 7]               0
          Conv2d-310             [-1, 32, 7, 7]          36,864
     BatchNorm2d-311            [-1, 736, 7, 7]           1,472
            ReLU-312            [-1, 736, 7, 7]               0
          Conv2d-313            [-1, 128, 7, 7]          94,208
     BatchNorm2d-314            [-1, 128, 7, 7]             256
            ReLU-315            [-1, 128, 7, 7]               0
          Conv2d-316             [-1, 32, 7, 7]          36,864
     BatchNorm2d-317            [-1, 768, 7, 7]           1,536
            ReLU-318            [-1, 768, 7, 7]               0
          Conv2d-319            [-1, 128, 7, 7]          98,304
     BatchNorm2d-320            [-1, 128, 7, 7]             256
            ReLU-321            [-1, 128, 7, 7]               0
          Conv2d-322             [-1, 32, 7, 7]          36,864
     BatchNorm2d-323            [-1, 800, 7, 7]           1,600
            ReLU-324            [-1, 800, 7, 7]               0
          Conv2d-325            [-1, 128, 7, 7]         102,400
     BatchNorm2d-326            [-1, 128, 7, 7]             256
            ReLU-327            [-1, 128, 7, 7]               0
          Conv2d-328             [-1, 32, 7, 7]          36,864
     BatchNorm2d-329            [-1, 832, 7, 7]           1,664
            ReLU-330            [-1, 832, 7, 7]               0
          Conv2d-331            [-1, 128, 7, 7]         106,496
     BatchNorm2d-332            [-1, 128, 7, 7]             256
            ReLU-333            [-1, 128, 7, 7]               0
          Conv2d-334             [-1, 32, 7, 7]          36,864
     BatchNorm2d-335            [-1, 864, 7, 7]           1,728
            ReLU-336            [-1, 864, 7, 7]               0
          Conv2d-337            [-1, 128, 7, 7]         110,592
     BatchNorm2d-338            [-1, 128, 7, 7]             256
            ReLU-339            [-1, 128, 7, 7]               0
          Conv2d-340             [-1, 32, 7, 7]          36,864
     BatchNorm2d-341            [-1, 896, 7, 7]           1,792
            ReLU-342            [-1, 896, 7, 7]               0
          Conv2d-343            [-1, 128, 7, 7]         114,688
     BatchNorm2d-344            [-1, 128, 7, 7]             256
            ReLU-345            [-1, 128, 7, 7]               0
          Conv2d-346             [-1, 32, 7, 7]          36,864
     BatchNorm2d-347            [-1, 928, 7, 7]           1,856
            ReLU-348            [-1, 928, 7, 7]               0
          Conv2d-349            [-1, 128, 7, 7]         118,784
     BatchNorm2d-350            [-1, 128, 7, 7]             256
            ReLU-351            [-1, 128, 7, 7]               0
          Conv2d-352             [-1, 32, 7, 7]          36,864
     BatchNorm2d-353            [-1, 960, 7, 7]           1,920
            ReLU-354            [-1, 960, 7, 7]               0
          Conv2d-355            [-1, 128, 7, 7]         122,880
     BatchNorm2d-356            [-1, 128, 7, 7]             256
            ReLU-357            [-1, 128, 7, 7]               0
          Conv2d-358             [-1, 32, 7, 7]          36,864
     BatchNorm2d-359            [-1, 992, 7, 7]           1,984
            ReLU-360            [-1, 992, 7, 7]               0
          Conv2d-361            [-1, 128, 7, 7]         126,976
     BatchNorm2d-362            [-1, 128, 7, 7]             256
            ReLU-363            [-1, 128, 7, 7]               0
          Conv2d-364             [-1, 32, 7, 7]          36,864
     BatchNorm2d-365           [-1, 1024, 7, 7]           2,048
            ReLU-366           [-1, 1024, 7, 7]               0
          Linear-367                 [-1, 1000]       1,025,000
================================================================
Total params: 7,978,856
Trainable params: 7,978,856
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 294.58
Params size (MB): 30.44
Estimated Total Size (MB): 325.59
----------------------------------------------------------------


</code></pre> 
<h3><a id="23__1228"></a>2.3 è®­ç»ƒæ¨¡å‹</h3> 
<h4><a id="231__1229"></a>2.3.1 è®¾ç½®è¶…å‚æ•°</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""è®­ç»ƒæ¨¡å‹--è®¾ç½®è¶…å‚æ•°"""</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># åˆ›å»ºæŸå¤±å‡½æ•°ï¼Œè®¡ç®—å®é™…è¾“å‡ºå’ŒçœŸå®ç›¸å·®å¤šå°‘ï¼Œäº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œäº‹å®ä¸Šï¼Œå®ƒå°±æ˜¯åšå›¾ç‰‡åˆ†ç±»ä»»åŠ¡æ—¶å¸¸ç”¨çš„æŸå¤±å‡½æ•°</span>
learn_rate <span class="token operator">=</span> <span class="token number">1e-4</span>  <span class="token comment"># å­¦ä¹ ç‡</span>
optimizer1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learn_rate<span class="token punctuation">)</span><span class="token comment"># ä½œç”¨æ˜¯å®šä¹‰ä¼˜åŒ–å™¨ï¼Œç”¨æ¥è®­ç»ƒæ—¶å€™ä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼›å…¶ä¸­ï¼ŒSGDè¡¨ç¤ºéšæœºæ¢¯åº¦ä¸‹é™ï¼Œç”¨äºæ§åˆ¶å®é™…è¾“å‡ºyä¸çœŸå®yä¹‹é—´çš„ç›¸å·®æœ‰å¤šå¤§</span>
optimizer2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learn_rate<span class="token punctuation">)</span>  
lr_opt <span class="token operator">=</span> optimizer2
model_opt <span class="token operator">=</span> optimizer2
<span class="token comment"># è°ƒç”¨å®˜æ–¹åŠ¨æ€å­¦ä¹ ç‡æ¥å£æ—¶ä½¿ç”¨2</span>
lambda1 <span class="token operator">=</span> <span class="token keyword">lambda</span> epoch <span class="token punctuation">:</span> <span class="token number">0.92</span> <span class="token operator">**</span> <span class="token punctuation">(</span>epoch <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>lr_opt<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span>lambda1<span class="token punctuation">)</span> <span class="token comment">#é€‰å®šè°ƒæ•´æ–¹æ³•</span>

</code></pre> 
<h4><a id="232__1246"></a>2.3.2 ç¼–å†™è®­ç»ƒå‡½æ•°</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""è®­ç»ƒæ¨¡å‹--ç¼–å†™è®­ç»ƒå‡½æ•°"""</span>
<span class="token comment"># è®­ç»ƒå¾ªç¯</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>  <span class="token comment"># è®­ç»ƒé›†çš„å¤§å°ï¼Œä¸€å…±60000å¼ å›¾ç‰‡</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>  <span class="token comment"># æ‰¹æ¬¡æ•°ç›®ï¼Œ1875ï¼ˆ60000/32ï¼‰</span>

    train_loss<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>  <span class="token comment"># åˆå§‹åŒ–è®­ç»ƒæŸå¤±å’Œæ­£ç¡®ç‡</span>

    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>  <span class="token comment"># åŠ è½½æ•°æ®åŠ è½½å™¨ï¼Œå¾—åˆ°é‡Œé¢çš„ Xï¼ˆå›¾ç‰‡æ•°æ®ï¼‰å’Œ yï¼ˆçœŸå®æ ‡ç­¾ï¼‰</span>
        X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># ç”¨äºå°†æ•°æ®å­˜åˆ°æ˜¾å¡</span>

        <span class="token comment"># è®¡ç®—é¢„æµ‹è¯¯å·®</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>  <span class="token comment"># ç½‘ç»œè¾“å‡º</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># è®¡ç®—ç½‘ç»œè¾“å‡ºå’ŒçœŸå®å€¼ä¹‹é—´çš„å·®è·ï¼Œtargetsä¸ºçœŸå®å€¼ï¼Œè®¡ç®—äºŒè€…å·®å€¼å³ä¸ºæŸå¤±</span>

        <span class="token comment"># åå‘ä¼ æ’­</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># æ¸…ç©ºè¿‡å¾€æ¢¯åº¦</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># åå‘ä¼ æ’­ï¼Œè®¡ç®—å½“å‰æ¢¯åº¦</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># æ ¹æ®æ¢¯åº¦æ›´æ–°ç½‘ç»œå‚æ•°</span>

        <span class="token comment"># è®°å½•accä¸loss</span>
        train_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    train_acc <span class="token operator">/=</span> size
    train_loss <span class="token operator">/=</span> num_batches

    <span class="token keyword">return</span> train_acc<span class="token punctuation">,</span> train_loss
</code></pre> 
<h4><a id="233__1279"></a>2.3.3 ç¼–å†™æµ‹è¯•å‡½æ•°</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""è®­ç»ƒæ¨¡å‹--ç¼–å†™æµ‹è¯•å‡½æ•°"""</span>
<span class="token comment"># æµ‹è¯•å‡½æ•°å’Œè®­ç»ƒå‡½æ•°å¤§è‡´ç›¸åŒï¼Œä½†æ˜¯ç”±äºä¸è¿›è¡Œæ¢¯åº¦ä¸‹é™å¯¹ç½‘ç»œæƒé‡è¿›è¡Œæ›´æ–°ï¼Œæ‰€ä»¥ä¸éœ€è¦ä¼ å…¥ä¼˜åŒ–å™¨</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>  <span class="token comment"># æµ‹è¯•é›†çš„å¤§å°ï¼Œä¸€å…±10000å¼ å›¾ç‰‡</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>  <span class="token comment"># æ‰¹æ¬¡æ•°ç›®ï¼Œ313ï¼ˆ10000/32=312.5ï¼Œå‘ä¸Šå–æ•´ï¼‰</span>
    test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>

    <span class="token comment"># å½“ä¸è¿›è¡Œè®­ç»ƒæ—¶ï¼Œåœæ­¢æ¢¯åº¦æ›´æ–°ï¼ŒèŠ‚çœè®¡ç®—å†…å­˜æ¶ˆè€—</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># æµ‹è¯•æ—¶æ¨¡å‹å‚æ•°ä¸ç”¨æ›´æ–°ï¼Œæ‰€ä»¥ no_gradï¼Œæ•´ä¸ªæ¨¡å‹å‚æ•°æ­£å‘æ¨å°±okï¼Œä¸åå‘æ›´æ–°å‚æ•°</span>
        <span class="token keyword">for</span> imgs<span class="token punctuation">,</span> target <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            imgs<span class="token punctuation">,</span> target <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            <span class="token comment"># è®¡ç®—loss</span>
            target_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>target_pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

            test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            test_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>target_pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> target<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#ç»Ÿè®¡é¢„æµ‹æ­£ç¡®çš„ä¸ªæ•°</span>

    test_acc <span class="token operator">/=</span> size
    test_loss <span class="token operator">/=</span> num_batches

    <span class="token keyword">return</span> test_acc<span class="token punctuation">,</span> test_loss

</code></pre> 
<h4><a id="234__1308"></a>2.3.4 æ­£å¼è®­ç»ƒ</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""è®­ç»ƒæ¨¡å‹--æ­£å¼è®­ç»ƒ"""</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
train_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
best_test_acc<span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    milliseconds_t1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span>

    <span class="token comment"># æ›´æ–°å­¦ä¹ ç‡ï¼ˆä½¿ç”¨è‡ªå®šä¹‰å­¦ä¹ ç‡æ—¶ä½¿ç”¨ï¼‰</span>
    <span class="token comment"># adjust_learning_rate(lr_opt, epoch, learn_rate)</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_train_acc<span class="token punctuation">,</span> epoch_train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> model_opt<span class="token punctuation">)</span>
    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># æ›´æ–°å­¦ä¹ ç‡ï¼ˆè°ƒç”¨å®˜æ–¹åŠ¨æ€å­¦ä¹ ç‡æ¥å£æ—¶ä½¿ç”¨ï¼‰</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

    train_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_train_acc<span class="token punctuation">)</span>
    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_train_loss<span class="token punctuation">)</span>
    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_test_acc<span class="token punctuation">)</span>
    test_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_test_loss<span class="token punctuation">)</span>

    <span class="token comment"># è·å–å½“å‰çš„å­¦ä¹ ç‡</span>
    lr <span class="token operator">=</span> lr_opt<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'param_groups'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>

    milliseconds_t2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span>
    template <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'Epoch:{:2d}, duration:{}ms, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%ï¼ŒTest_loss:{:.3f}, Lr:{:.2E}'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_test_acc <span class="token operator">&lt;</span> epoch_test_acc<span class="token punctuation">:</span>
        best_test_acc <span class="token operator">=</span> epoch_test_acc
        <span class="token comment">#å¤‡ä»½æœ€å¥½çš„æ¨¡å‹</span>
        best_model <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
        template <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token string">'Epoch:{:2d}, duration:{}ms, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%ï¼ŒTest_loss:{:.3f}, Lr:{:.2E},Update the best model'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> milliseconds_t2<span class="token operator">-</span>milliseconds_t1<span class="token punctuation">,</span> epoch_train_acc <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> epoch_train_loss<span class="token punctuation">,</span> epoch_test_acc <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> epoch_test_loss<span class="token punctuation">,</span> lr<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># ä¿å­˜æœ€ä½³æ¨¡å‹åˆ°æ–‡ä»¶ä¸­</span>
PATH <span class="token operator">=</span> <span class="token string">'./best_model.pth'</span>  <span class="token comment"># ä¿å­˜çš„å‚æ•°æ–‡ä»¶å</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Done'</span><span class="token punctuation">)</span>
</code></pre> 
<p>è¾“å‡ºæœ€é«˜ç²¾åº¦ä¸ºTest_acc:100%</p> 
<pre><code>Epoch: 1, duration:5339ms, Train_acc:32.5%, Train_loss:4.717, Test_acc:94.7%ï¼ŒTest_loss:0.666, Lr:1.00E-04,Update the best model
Epoch: 2, duration:4585ms, Train_acc:98.5%, Train_loss:0.255, Test_acc:98.2%ï¼ŒTest_loss:0.120, Lr:1.00E-04,Update the best model
Epoch: 3, duration:4651ms, Train_acc:100.0%, Train_loss:0.037, Test_acc:99.1%ï¼ŒTest_loss:0.057, Lr:1.00E-04,Update the best model
Epoch: 4, duration:4610ms, Train_acc:99.8%, Train_loss:0.039, Test_acc:100.0%ï¼ŒTest_loss:0.040, Lr:1.00E-04,Update the best model
Epoch: 5, duration:4520ms, Train_acc:99.8%, Train_loss:0.032, Test_acc:100.0%ï¼ŒTest_loss:0.047, Lr:1.00E-04
Epoch: 6, duration:4528ms, Train_acc:100.0%, Train_loss:0.055, Test_acc:100.0%ï¼ŒTest_loss:0.038, Lr:1.00E-04
Epoch: 7, duration:4541ms, Train_acc:100.0%, Train_loss:0.021, Test_acc:100.0%ï¼ŒTest_loss:0.022, Lr:1.00E-04
Epoch: 8, duration:4568ms, Train_acc:100.0%, Train_loss:0.066, Test_acc:100.0%ï¼ŒTest_loss:0.018, Lr:1.00E-04
Epoch: 9, duration:4515ms, Train_acc:99.8%, Train_loss:0.084, Test_acc:100.0%ï¼ŒTest_loss:0.022, Lr:1.00E-04
Epoch:10, duration:4602ms, Train_acc:99.6%, Train_loss:0.136, Test_acc:100.0%ï¼ŒTest_loss:0.028, Lr:1.00E-04
</code></pre> 
<p>è¿™é‡Œä½¿ç”¨äº†é¢„è®­ç»ƒæ¨¡å‹ï¼Œæ•ˆæœç‰¹åˆ«å¥½</p> 
<h3><a id="24__1371"></a>2.4 ç»“æœå¯è§†åŒ–</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""è®­ç»ƒæ¨¡å‹--ç»“æœå¯è§†åŒ–"""</span>
epochs_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Accuracy'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> test_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/4e/a0/URIqfM1W_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="24__1395"></a>2.4 æŒ‡å®šå›¾ç‰‡è¿›è¡Œé¢„æµ‹</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">predict_one_image</span><span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> model<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    test_img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>test_img<span class="token punctuation">)</span>  <span class="token comment"># å±•ç¤ºé¢„æµ‹çš„å›¾ç‰‡</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_img <span class="token operator">=</span> transform<span class="token punctuation">(</span>test_img<span class="token punctuation">)</span>
    img <span class="token operator">=</span> test_img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

    _<span class="token punctuation">,</span> pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    pred_class <span class="token operator">=</span> classes<span class="token punctuation">[</span>pred<span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'é¢„æµ‹ç»“æœæ˜¯ï¼š</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>pred_class<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
 
<span class="token comment"># å°†å‚æ•°åŠ è½½åˆ°modelå½“ä¸­</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""æŒ‡å®šå›¾ç‰‡è¿›è¡Œé¢„æµ‹"""</span>
classes <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>total_data<span class="token punctuation">.</span>class_to_idx<span class="token punctuation">)</span>
<span class="token comment"># é¢„æµ‹è®­ç»ƒé›†ä¸­çš„æŸå¼ ç…§ç‰‡</span>
predict_one_image<span class="token punctuation">(</span>image_path<span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">(</span>Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"Cockatoo/001.jpg"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  model<span class="token operator">=</span>model<span class="token punctuation">,</span>
                  transform<span class="token operator">=</span>train_transforms<span class="token punctuation">,</span>
                  classes<span class="token operator">=</span>classes<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/8d/7d/AgtJIxwq_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>è¾“å‡º</p> 
<pre><code>é¢„æµ‹ç»“æœæ˜¯ï¼šCockatoo
</code></pre> 
<h3><a id="26__1433"></a>2.6 æ¨¡å‹è¯„ä¼°</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""æ¨¡å‹è¯„ä¼°"""</span>
best_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dl<span class="token punctuation">,</span> best_model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>
<span class="token comment"># æŸ¥çœ‹æ˜¯å¦ä¸æˆ‘ä»¬è®°å½•çš„æœ€é«˜å‡†ç¡®ç‡ä¸€è‡´</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss<span class="token punctuation">)</span>


</code></pre> 
<p>è¾“å‡º</p> 
<pre><code>1.0 0.05105462612118572

</code></pre> 
<h2><a id="3_tensorflowDenseNet_1448"></a>3 tensorflowå®ç°DenseNetç®—æ³•</h2> 
<h3><a id="31_1449"></a>3.1.å¼•å…¥åº“</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token comment"># æ”¯æŒä¸­æ–‡</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers<span class="token punctuation">,</span> models<span class="token punctuation">,</span> Input
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Input<span class="token punctuation">,</span> Activation<span class="token punctuation">,</span> BatchNormalization<span class="token punctuation">,</span> Flatten
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense<span class="token punctuation">,</span> Conv2D<span class="token punctuation">,</span> MaxPooling2D<span class="token punctuation">,</span> ZeroPadding2D<span class="token punctuation">,</span> GlobalMaxPooling2D<span class="token punctuation">,</span> AveragePooling2D<span class="token punctuation">,</span> Flatten<span class="token punctuation">,</span> \
    Dropout<span class="token punctuation">,</span> BatchNormalization<span class="token punctuation">,</span> GlobalAveragePooling2D
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model
<span class="token keyword">from</span> keras <span class="token keyword">import</span> regularizers
<span class="token keyword">from</span> tensorflow <span class="token keyword">import</span> keras
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> ModelCheckpoint
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> warnings

warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>  <span class="token comment"># å¿½ç•¥ä¸€äº›warningå†…å®¹ï¼Œæ— éœ€æ‰“å°</span>
</code></pre> 
<h3><a id="32GPUCPU_1473"></a>3.2.è®¾ç½®GPUï¼ˆå¦‚æœä½¿ç”¨çš„æ˜¯CPUå¯ä»¥å¿½ç•¥è¿™æ­¥ï¼‰</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-è®¾ç½®GPUï¼ˆå¦‚æœä½¿ç”¨çš„æ˜¯CPUå¯ä»¥å¿½ç•¥è¿™æ­¥ï¼‰'''</span>
<span class="token comment"># æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>test<span class="token punctuation">.</span>is_built_with_cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
gpus <span class="token operator">=</span> tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>list_physical_devices<span class="token punctuation">(</span><span class="token string">"GPU"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gpus<span class="token punctuation">)</span>
<span class="token keyword">if</span> gpus<span class="token punctuation">:</span>
    gpu0 <span class="token operator">=</span> gpus<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># å¦‚æœæœ‰å¤šä¸ªGPUï¼Œä»…ä½¿ç”¨ç¬¬0ä¸ªGPU</span>
    tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>set_memory_growth<span class="token punctuation">(</span>gpu0<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># è®¾ç½®GPUæ˜¾å­˜ç”¨é‡æŒ‰éœ€ä½¿ç”¨</span>
    tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>set_visible_devices<span class="token punctuation">(</span><span class="token punctuation">[</span>gpu0<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"GPU"</span><span class="token punctuation">)</span>
</code></pre> 
<p>æ‰§è¡Œç»“æœ</p> 
<pre><code>True
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
</code></pre> 
<h3><a id="33_1491"></a>3.3.å¯¼å…¥æ•°æ®</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-å¯¼å…¥æ•°æ®'''</span>
data_dir <span class="token operator">=</span> <span class="token string">r"D:\DeepLearning\data\bird\bird_photos"</span>
data_dir <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="34_1498"></a>3.4.æŸ¥çœ‹æ•°æ®</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''å‰æœŸå·¥ä½œ-æŸ¥çœ‹æ•°æ®'''</span>
image_count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*/*.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"å›¾ç‰‡æ€»æ•°ä¸ºï¼š"</span><span class="token punctuation">,</span> image_count<span class="token punctuation">)</span>
image_list <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'Bananaquit/*.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>image_list<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># æŸ¥çœ‹å›¾åƒå®ä¾‹çš„å±æ€§</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">,</span> image<span class="token punctuation">.</span>size<span class="token punctuation">,</span> image<span class="token punctuation">.</span>mode<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>æ‰§è¡Œç»“æœï¼š</p> 
<pre><code>å›¾ç‰‡æ€»æ•°ä¸ºï¼š 565
JPEG (224, 224) RGB
</code></pre> 
<p><img src="https://images2.imgbox.com/06/49/ruH8Jlct_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="35_1521"></a>3.5.åŠ è½½æ•°æ®</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''æ•°æ®é¢„å¤„ç†-åŠ è½½æ•°æ®'''</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>
img_height <span class="token operator">=</span> <span class="token number">224</span>
img_width <span class="token operator">=</span> <span class="token number">224</span>
<span class="token triple-quoted-string string">"""
å…³äºimage_dataset_from_directory()çš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒæ–‡ç« ï¼šhttps://mtyjkh.blog.csdn.net/article/details/117018789
"""</span>
train_ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image_dataset_from_directory<span class="token punctuation">(</span>
    data_dir<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>
    subset<span class="token operator">=</span><span class="token string">"training"</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span><span class="token number">123</span><span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>img_height<span class="token punctuation">,</span> img_width<span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
val_ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image_dataset_from_directory<span class="token punctuation">(</span>
    data_dir<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>
    subset<span class="token operator">=</span><span class="token string">"validation"</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span><span class="token number">123</span><span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>img_height<span class="token punctuation">,</span> img_width<span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
class_names <span class="token operator">=</span> train_ds<span class="token punctuation">.</span>class_names
<span class="token keyword">print</span><span class="token punctuation">(</span>class_names<span class="token punctuation">)</span>
</code></pre> 
<p>è¿è¡Œç»“æœï¼š</p> 
<pre><code class="prism language-html">Found 565 files belonging to 4 classes.
Using 452 files for training.
Found 565 files belonging to 4 classes.
Using 113 files for validation.
['Bananaquit', 'Black Skimmer', 'Black Throated Bushtiti', 'Cockatoo']

</code></pre> 
<h3><a id="36_1557"></a>3.6.å†æ¬¡æ£€æŸ¥æ•°æ®</h3> 
<pre><code class="prism language-python{.line-numbers}">'''æ•°æ®é¢„å¤„ç†-å†æ¬¡æ£€æŸ¥æ•°æ®'''
# Image_batchæ˜¯å½¢çŠ¶çš„å¼ é‡(16, 336, 336, 3)ã€‚è¿™æ˜¯ä¸€æ‰¹å½¢çŠ¶336x336x3çš„16å¼ å›¾ç‰‡ï¼ˆæœ€åä¸€ç»´æŒ‡çš„æ˜¯å½©è‰²é€šé“RGBï¼‰ã€‚
# Label_batchæ˜¯å½¢çŠ¶ï¼ˆ16ï¼Œï¼‰çš„å¼ é‡ï¼Œè¿™äº›æ ‡ç­¾å¯¹åº”16å¼ å›¾ç‰‡
for image_batch, labels_batch in train_ds:
    print(image_batch.shape)
    print(labels_batch.shape)
    break
</code></pre> 
<p>è¿è¡Œç»“æœ</p> 
<pre><code>(32, 224, 224, 3)
(32,)
</code></pre> 
<h3><a id="37_1574"></a>3.7.é…ç½®æ•°æ®é›†</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''æ•°æ®é¢„å¤„ç†-é…ç½®æ•°æ®é›†'''</span>
AUTOTUNE <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>AUTOTUNE
train_ds <span class="token operator">=</span> train_ds<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>AUTOTUNE<span class="token punctuation">)</span>
val_ds <span class="token operator">=</span> val_ds<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>AUTOTUNE<span class="token punctuation">)</span>

</code></pre> 
<h3><a id="38_1583"></a>3.8.å¯è§†åŒ–æ•°æ®</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''æ•°æ®é¢„å¤„ç†-å¯è§†åŒ–æ•°æ®'''</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_ds<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"uint8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>class_names<span class="token punctuation">[</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
<span class="token comment"># æ˜¾ç¤ºå›¾ç‰‡</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/c9/a2/kq0H2R2L_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="39DenseNet_1599"></a>3.9.æ„å»ºDenseNetç½‘ç»œ</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""æ„å»ºDenseNetç½‘ç»œ"""</span>
<span class="token keyword">def</span> <span class="token function">conv_fn</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> growth_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span>growth_rate<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    <span class="token keyword">return</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Concatenate<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> x1<span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">dense_block</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> block<span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>block<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> conv_fn<span class="token punctuation">(</span>x<span class="token punctuation">,</span> growth_rate<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x


k <span class="token operator">=</span> keras<span class="token punctuation">.</span>backend
<span class="token keyword">def</span> <span class="token function">trans_block</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> theta<span class="token punctuation">)</span><span class="token punctuation">:</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>k<span class="token punctuation">.</span>int_shape<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token operator">*</span> theta<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    x1 <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>AveragePooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"valid"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x1<span class="token punctuation">)</span>
    <span class="token keyword">return</span> x1


<span class="token keyword">def</span> <span class="token function">densenet</span><span class="token punctuation">(</span>input_shape<span class="token punctuation">,</span> block<span class="token punctuation">,</span> n_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 56*56*64</span>
    x_input <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span>input_shape<span class="token punctuation">)</span>
    x <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">,</span> use_bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>
    x <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>MaxPooling2D<span class="token punctuation">(</span>pool_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"same"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> dense_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> block<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> trans_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># 28*28</span>
    x <span class="token operator">=</span> dense_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> block<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> trans_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># 14*14</span>
    x <span class="token operator">=</span> dense_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> block<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> trans_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>  <span class="token comment"># 7*7</span>
    x <span class="token operator">=</span> dense_block<span class="token punctuation">(</span>x<span class="token punctuation">,</span> block<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Activation<span class="token punctuation">(</span><span class="token string">"relu"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    x <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>GlobalAveragePooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    outputs <span class="token operator">=</span> keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span>n_classes<span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">"softmax"</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    model <span class="token operator">=</span> keras<span class="token punctuation">.</span>models<span class="token punctuation">.</span>Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span><span class="token punctuation">[</span>x_input<span class="token punctuation">]</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>outputs<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model


model_121 <span class="token operator">=</span> densenet<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># DenseNet-121</span>
model_169 <span class="token operator">=</span> densenet<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># DenseNet-169</span>
model_201 <span class="token operator">=</span> densenet<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># DenseNet-201</span>
model_269 <span class="token operator">=</span> densenet<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">48</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># DenseNet-269</span>
model <span class="token operator">=</span> model_121
model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>ç½‘ç»œç»“æ„ç»“æœå¦‚ä¸‹ï¼š</p> 
<pre><code>Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               
                                )]                                                                
                                                                                                  
 conv2d (Conv2D)                (None, 112, 112, 64  9408        ['input_1[0][0]']                
                                )                                                                 
                                                                                                  
 batch_normalization (BatchNorm  (None, 112, 112, 64  256        ['conv2d[0][0]']                 
 alization)                     )                                                                 
                                                                                                  
 max_pooling2d (MaxPooling2D)   (None, 56, 56, 64)   0           ['batch_normalization[0][0]']    
                                                                                                  
 batch_normalization_1 (BatchNo  (None, 56, 56, 64)  256         ['max_pooling2d[0][0]']          
 rmalization)                                                                                     
                                                                                                  
 activation (Activation)        (None, 56, 56, 64)   0           ['batch_normalization_1[0][0]']  
                                                                                                  
 conv2d_1 (Conv2D)              (None, 56, 56, 128)  8192        ['activation[0][0]']             
                                                                                                  
 batch_normalization_2 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_1[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 activation_1 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_2[0][0]']  
                                                                                                  
 conv2d_2 (Conv2D)              (None, 56, 56, 32)   36864       ['activation_1[0][0]']           
                                                                                                  
 concatenate (Concatenate)      (None, 56, 56, 96)   0           ['max_pooling2d[0][0]',          
                                                                  'conv2d_2[0][0]']               
                                                                                                  
 batch_normalization_3 (BatchNo  (None, 56, 56, 96)  384         ['concatenate[0][0]']            
 rmalization)                                                                                     
                                                                                                  
 activation_2 (Activation)      (None, 56, 56, 96)   0           ['batch_normalization_3[0][0]']  
                                                                                                  
 conv2d_3 (Conv2D)              (None, 56, 56, 128)  12288       ['activation_2[0][0]']           
                                                                                                  
 batch_normalization_4 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_3[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 activation_3 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_4[0][0]']  
                                                                                                  
 conv2d_4 (Conv2D)              (None, 56, 56, 32)   36864       ['activation_3[0][0]']           
                                                                                                  
 concatenate_1 (Concatenate)    (None, 56, 56, 128)  0           ['concatenate[0][0]',            
                                                                  'conv2d_4[0][0]']               
                                                                                                  
 batch_normalization_5 (BatchNo  (None, 56, 56, 128)  512        ['concatenate_1[0][0]']          
 rmalization)                                                                                     
                                                                                                  
 activation_4 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_5[0][0]']  
                                                                                                  
 conv2d_5 (Conv2D)              (None, 56, 56, 128)  16384       ['activation_4[0][0]']           
                                                                                                  
 batch_normalization_6 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_5[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 activation_5 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_6[0][0]']  
                                                                                                  
 conv2d_6 (Conv2D)              (None, 56, 56, 32)   36864       ['activation_5[0][0]']           
                                                                                                  
 concatenate_2 (Concatenate)    (None, 56, 56, 160)  0           ['concatenate_1[0][0]',          
                                                                  'conv2d_6[0][0]']               
                                                                                                  
 batch_normalization_7 (BatchNo  (None, 56, 56, 160)  640        ['concatenate_2[0][0]']          
 rmalization)                                                                                     
                                                                                                  
 activation_6 (Activation)      (None, 56, 56, 160)  0           ['batch_normalization_7[0][0]']  
                                                                                                  
 conv2d_7 (Conv2D)              (None, 56, 56, 128)  20480       ['activation_6[0][0]']           
                                                                                                  
 batch_normalization_8 (BatchNo  (None, 56, 56, 128)  512        ['conv2d_7[0][0]']               
 rmalization)                                                                                     
                                                                                                  
 activation_7 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_8[0][0]']  
                                                                                                  
 conv2d_8 (Conv2D)              (None, 56, 56, 32)   36864       ['activation_7[0][0]']           
                                                                                                  
 concatenate_3 (Concatenate)    (None, 56, 56, 192)  0           ['concatenate_2[0][0]',          
                                                                  'conv2d_8[0][0]']               
                                                                                                  
 batch_normalization_9 (BatchNo  (None, 56, 56, 192)  768        ['concatenate_3[0][0]']          
 rmalization)                                                                                     
                                                                                                  
 activation_8 (Activation)      (None, 56, 56, 192)  0           ['batch_normalization_9[0][0]']  
                                                                                                  
 conv2d_9 (Conv2D)              (None, 56, 56, 128)  24576       ['activation_8[0][0]']           
                                                                                                  
 batch_normalization_10 (BatchN  (None, 56, 56, 128)  512        ['conv2d_9[0][0]']               
 ormalization)                                                                                    
                                                                                                  
 activation_9 (Activation)      (None, 56, 56, 128)  0           ['batch_normalization_10[0][0]'] 
                                                                                                  
 conv2d_10 (Conv2D)             (None, 56, 56, 32)   36864       ['activation_9[0][0]']           
                                                                                                  
 concatenate_4 (Concatenate)    (None, 56, 56, 224)  0           ['concatenate_3[0][0]',          
                                                                  'conv2d_10[0][0]']              
                                                                                                  
 batch_normalization_11 (BatchN  (None, 56, 56, 224)  896        ['concatenate_4[0][0]']          
 ormalization)                                                                                    
                                                                                                  
 activation_10 (Activation)     (None, 56, 56, 224)  0           ['batch_normalization_11[0][0]'] 
                                                                                                  
 conv2d_11 (Conv2D)             (None, 56, 56, 128)  28672       ['activation_10[0][0]']          
                                                                                                  
 batch_normalization_12 (BatchN  (None, 56, 56, 128)  512        ['conv2d_11[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_11 (Activation)     (None, 56, 56, 128)  0           ['batch_normalization_12[0][0]'] 
                                                                                                  
 conv2d_12 (Conv2D)             (None, 56, 56, 32)   36864       ['activation_11[0][0]']          
                                                                                                  
 concatenate_5 (Concatenate)    (None, 56, 56, 256)  0           ['concatenate_4[0][0]',          
                                                                  'conv2d_12[0][0]']              
                                                                                                  
 batch_normalization_13 (BatchN  (None, 56, 56, 256)  1024       ['concatenate_5[0][0]']          
 ormalization)                                                                                    
                                                                                                  
 activation_12 (Activation)     (None, 56, 56, 256)  0           ['batch_normalization_13[0][0]'] 
                                                                                                  
 conv2d_13 (Conv2D)             (None, 56, 56, 128)  32768       ['activation_12[0][0]']          
                                                                                                  
 average_pooling2d (AveragePool  (None, 28, 28, 128)  0          ['conv2d_13[0][0]']              
 ing2D)                                                                                           
                                                                                                  
 batch_normalization_14 (BatchN  (None, 28, 28, 128)  512        ['average_pooling2d[0][0]']      
 ormalization)                                                                                    
                                                                                                  
 activation_13 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_14[0][0]'] 
                                                                                                  
 conv2d_14 (Conv2D)             (None, 28, 28, 128)  16384       ['activation_13[0][0]']          
                                                                                                  
 batch_normalization_15 (BatchN  (None, 28, 28, 128)  512        ['conv2d_14[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_14 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_15[0][0]'] 
                                                                                                  
 conv2d_15 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_14[0][0]']          
                                                                                                  
 concatenate_6 (Concatenate)    (None, 28, 28, 160)  0           ['average_pooling2d[0][0]',      
                                                                  'conv2d_15[0][0]']              
                                                                                                  
 batch_normalization_16 (BatchN  (None, 28, 28, 160)  640        ['concatenate_6[0][0]']          
 ormalization)                                                                                    
                                                                                                  
 activation_15 (Activation)     (None, 28, 28, 160)  0           ['batch_normalization_16[0][0]'] 
                                                                                                  
 conv2d_16 (Conv2D)             (None, 28, 28, 128)  20480       ['activation_15[0][0]']          
                                                                                                  
 batch_normalization_17 (BatchN  (None, 28, 28, 128)  512        ['conv2d_16[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_16 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_17[0][0]'] 
                                                                                                  
 conv2d_17 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_16[0][0]']          
                                                                                                  
 concatenate_7 (Concatenate)    (None, 28, 28, 192)  0           ['concatenate_6[0][0]',          
                                                                  'conv2d_17[0][0]']              
                                                                                                  
 batch_normalization_18 (BatchN  (None, 28, 28, 192)  768        ['concatenate_7[0][0]']          
 ormalization)                                                                                    
                                                                                                  
 activation_17 (Activation)     (None, 28, 28, 192)  0           ['batch_normalization_18[0][0]'] 
                                                                                                  
 conv2d_18 (Conv2D)             (None, 28, 28, 128)  24576       ['activation_17[0][0]']          
                                                                                                  
 batch_normalization_19 (BatchN  (None, 28, 28, 128)  512        ['conv2d_18[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_18 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_19[0][0]'] 
                                                                                                  
 conv2d_19 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_18[0][0]']          
                                                                                                  
 concatenate_8 (Concatenate)    (None, 28, 28, 224)  0           ['concatenate_7[0][0]',          
                                                                  'conv2d_19[0][0]']              
                                                                                                  
 batch_normalization_20 (BatchN  (None, 28, 28, 224)  896        ['concatenate_8[0][0]']          
 ormalization)                                                                                    
                                                                                                  
 activation_19 (Activation)     (None, 28, 28, 224)  0           ['batch_normalization_20[0][0]'] 
                                                                                                  
 conv2d_20 (Conv2D)             (None, 28, 28, 128)  28672       ['activation_19[0][0]']          
                                                                                                  
 batch_normalization_21 (BatchN  (None, 28, 28, 128)  512        ['conv2d_20[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_20 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_21[0][0]'] 
                                                                                                  
 conv2d_21 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_20[0][0]']          
                                                                                                  
 concatenate_9 (Concatenate)    (None, 28, 28, 256)  0           ['concatenate_8[0][0]',          
                                                                  'conv2d_21[0][0]']              
                                                                                                  
 batch_normalization_22 (BatchN  (None, 28, 28, 256)  1024       ['concatenate_9[0][0]']          
 ormalization)                                                                                    
                                                                                                  
 activation_21 (Activation)     (None, 28, 28, 256)  0           ['batch_normalization_22[0][0]'] 
                                                                                                  
 conv2d_22 (Conv2D)             (None, 28, 28, 128)  32768       ['activation_21[0][0]']          
                                                                                                  
 batch_normalization_23 (BatchN  (None, 28, 28, 128)  512        ['conv2d_22[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_22 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_23[0][0]'] 
                                                                                                  
 conv2d_23 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_22[0][0]']          
                                                                                                  
 concatenate_10 (Concatenate)   (None, 28, 28, 288)  0           ['concatenate_9[0][0]',          
                                                                  'conv2d_23[0][0]']              
                                                                                                  
 batch_normalization_24 (BatchN  (None, 28, 28, 288)  1152       ['concatenate_10[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_23 (Activation)     (None, 28, 28, 288)  0           ['batch_normalization_24[0][0]'] 
                                                                                                  
 conv2d_24 (Conv2D)             (None, 28, 28, 128)  36864       ['activation_23[0][0]']          
                                                                                                  
 batch_normalization_25 (BatchN  (None, 28, 28, 128)  512        ['conv2d_24[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_24 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_25[0][0]'] 
                                                                                                  
 conv2d_25 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_24[0][0]']          
                                                                                                  
 concatenate_11 (Concatenate)   (None, 28, 28, 320)  0           ['concatenate_10[0][0]',         
                                                                  'conv2d_25[0][0]']              
                                                                                                  
 batch_normalization_26 (BatchN  (None, 28, 28, 320)  1280       ['concatenate_11[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_25 (Activation)     (None, 28, 28, 320)  0           ['batch_normalization_26[0][0]'] 
                                                                                                  
 conv2d_26 (Conv2D)             (None, 28, 28, 128)  40960       ['activation_25[0][0]']          
                                                                                                  
 batch_normalization_27 (BatchN  (None, 28, 28, 128)  512        ['conv2d_26[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_26 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_27[0][0]'] 
                                                                                                  
 conv2d_27 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_26[0][0]']          
                                                                                                  
 concatenate_12 (Concatenate)   (None, 28, 28, 352)  0           ['concatenate_11[0][0]',         
                                                                  'conv2d_27[0][0]']              
                                                                                                  
 batch_normalization_28 (BatchN  (None, 28, 28, 352)  1408       ['concatenate_12[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_27 (Activation)     (None, 28, 28, 352)  0           ['batch_normalization_28[0][0]'] 
                                                                                                  
 conv2d_28 (Conv2D)             (None, 28, 28, 128)  45056       ['activation_27[0][0]']          
                                                                                                  
 batch_normalization_29 (BatchN  (None, 28, 28, 128)  512        ['conv2d_28[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_28 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_29[0][0]'] 
                                                                                                  
 conv2d_29 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_28[0][0]']          
                                                                                                  
 concatenate_13 (Concatenate)   (None, 28, 28, 384)  0           ['concatenate_12[0][0]',         
                                                                  'conv2d_29[0][0]']              
                                                                                                  
 batch_normalization_30 (BatchN  (None, 28, 28, 384)  1536       ['concatenate_13[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_29 (Activation)     (None, 28, 28, 384)  0           ['batch_normalization_30[0][0]'] 
                                                                                                  
 conv2d_30 (Conv2D)             (None, 28, 28, 128)  49152       ['activation_29[0][0]']          
                                                                                                  
 batch_normalization_31 (BatchN  (None, 28, 28, 128)  512        ['conv2d_30[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_30 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_31[0][0]'] 
                                                                                                  
 conv2d_31 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_30[0][0]']          
                                                                                                  
 concatenate_14 (Concatenate)   (None, 28, 28, 416)  0           ['concatenate_13[0][0]',         
                                                                  'conv2d_31[0][0]']              
                                                                                                  
 batch_normalization_32 (BatchN  (None, 28, 28, 416)  1664       ['concatenate_14[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_31 (Activation)     (None, 28, 28, 416)  0           ['batch_normalization_32[0][0]'] 
                                                                                                  
 conv2d_32 (Conv2D)             (None, 28, 28, 128)  53248       ['activation_31[0][0]']          
                                                                                                  
 batch_normalization_33 (BatchN  (None, 28, 28, 128)  512        ['conv2d_32[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_32 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_33[0][0]'] 
                                                                                                  
 conv2d_33 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_32[0][0]']          
                                                                                                  
 concatenate_15 (Concatenate)   (None, 28, 28, 448)  0           ['concatenate_14[0][0]',         
                                                                  'conv2d_33[0][0]']              
                                                                                                  
 batch_normalization_34 (BatchN  (None, 28, 28, 448)  1792       ['concatenate_15[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_33 (Activation)     (None, 28, 28, 448)  0           ['batch_normalization_34[0][0]'] 
                                                                                                  
 conv2d_34 (Conv2D)             (None, 28, 28, 128)  57344       ['activation_33[0][0]']          
                                                                                                  
 batch_normalization_35 (BatchN  (None, 28, 28, 128)  512        ['conv2d_34[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_34 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_35[0][0]'] 
                                                                                                  
 conv2d_35 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_34[0][0]']          
                                                                                                  
 concatenate_16 (Concatenate)   (None, 28, 28, 480)  0           ['concatenate_15[0][0]',         
                                                                  'conv2d_35[0][0]']              
                                                                                                  
 batch_normalization_36 (BatchN  (None, 28, 28, 480)  1920       ['concatenate_16[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_35 (Activation)     (None, 28, 28, 480)  0           ['batch_normalization_36[0][0]'] 
                                                                                                  
 conv2d_36 (Conv2D)             (None, 28, 28, 128)  61440       ['activation_35[0][0]']          
                                                                                                  
 batch_normalization_37 (BatchN  (None, 28, 28, 128)  512        ['conv2d_36[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_36 (Activation)     (None, 28, 28, 128)  0           ['batch_normalization_37[0][0]'] 
                                                                                                  
 conv2d_37 (Conv2D)             (None, 28, 28, 32)   36864       ['activation_36[0][0]']          
                                                                                                  
 concatenate_17 (Concatenate)   (None, 28, 28, 512)  0           ['concatenate_16[0][0]',         
                                                                  'conv2d_37[0][0]']              
                                                                                                  
 batch_normalization_38 (BatchN  (None, 28, 28, 512)  2048       ['concatenate_17[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_37 (Activation)     (None, 28, 28, 512)  0           ['batch_normalization_38[0][0]'] 
                                                                                                  
 conv2d_38 (Conv2D)             (None, 28, 28, 256)  131072      ['activation_37[0][0]']          
                                                                                                  
 average_pooling2d_1 (AveragePo  (None, 14, 14, 256)  0          ['conv2d_38[0][0]']              
 oling2D)                                                                                         
                                                                                                  
 batch_normalization_39 (BatchN  (None, 14, 14, 256)  1024       ['average_pooling2d_1[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_38 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_39[0][0]'] 
                                                                                                  
 conv2d_39 (Conv2D)             (None, 14, 14, 128)  32768       ['activation_38[0][0]']          
                                                                                                  
 batch_normalization_40 (BatchN  (None, 14, 14, 128)  512        ['conv2d_39[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_39 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_40[0][0]'] 
                                                                                                  
 conv2d_40 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_39[0][0]']          
                                                                                                  
 concatenate_18 (Concatenate)   (None, 14, 14, 288)  0           ['average_pooling2d_1[0][0]',    
                                                                  'conv2d_40[0][0]']              
                                                                                                  
 batch_normalization_41 (BatchN  (None, 14, 14, 288)  1152       ['concatenate_18[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_40 (Activation)     (None, 14, 14, 288)  0           ['batch_normalization_41[0][0]'] 
                                                                                                  
 conv2d_41 (Conv2D)             (None, 14, 14, 128)  36864       ['activation_40[0][0]']          
                                                                                                  
 batch_normalization_42 (BatchN  (None, 14, 14, 128)  512        ['conv2d_41[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_41 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_42[0][0]'] 
                                                                                                  
 conv2d_42 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_41[0][0]']          
                                                                                                  
 concatenate_19 (Concatenate)   (None, 14, 14, 320)  0           ['concatenate_18[0][0]',         
                                                                  'conv2d_42[0][0]']              
                                                                                                  
 batch_normalization_43 (BatchN  (None, 14, 14, 320)  1280       ['concatenate_19[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_42 (Activation)     (None, 14, 14, 320)  0           ['batch_normalization_43[0][0]'] 
                                                                                                  
 conv2d_43 (Conv2D)             (None, 14, 14, 128)  40960       ['activation_42[0][0]']          
                                                                                                  
 batch_normalization_44 (BatchN  (None, 14, 14, 128)  512        ['conv2d_43[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_43 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_44[0][0]'] 
                                                                                                  
 conv2d_44 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_43[0][0]']          
                                                                                                  
 concatenate_20 (Concatenate)   (None, 14, 14, 352)  0           ['concatenate_19[0][0]',         
                                                                  'conv2d_44[0][0]']              
                                                                                                  
 batch_normalization_45 (BatchN  (None, 14, 14, 352)  1408       ['concatenate_20[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_44 (Activation)     (None, 14, 14, 352)  0           ['batch_normalization_45[0][0]'] 
                                                                                                  
 conv2d_45 (Conv2D)             (None, 14, 14, 128)  45056       ['activation_44[0][0]']          
                                                                                                  
 batch_normalization_46 (BatchN  (None, 14, 14, 128)  512        ['conv2d_45[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_45 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_46[0][0]'] 
                                                                                                  
 conv2d_46 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_45[0][0]']          
                                                                                                  
 concatenate_21 (Concatenate)   (None, 14, 14, 384)  0           ['concatenate_20[0][0]',         
                                                                  'conv2d_46[0][0]']              
                                                                                                  
 batch_normalization_47 (BatchN  (None, 14, 14, 384)  1536       ['concatenate_21[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_46 (Activation)     (None, 14, 14, 384)  0           ['batch_normalization_47[0][0]'] 
                                                                                                  
 conv2d_47 (Conv2D)             (None, 14, 14, 128)  49152       ['activation_46[0][0]']          
                                                                                                  
 batch_normalization_48 (BatchN  (None, 14, 14, 128)  512        ['conv2d_47[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_47 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_48[0][0]'] 
                                                                                                  
 conv2d_48 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_47[0][0]']          
                                                                                                  
 concatenate_22 (Concatenate)   (None, 14, 14, 416)  0           ['concatenate_21[0][0]',         
                                                                  'conv2d_48[0][0]']              
                                                                                                  
 batch_normalization_49 (BatchN  (None, 14, 14, 416)  1664       ['concatenate_22[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_48 (Activation)     (None, 14, 14, 416)  0           ['batch_normalization_49[0][0]'] 
                                                                                                  
 conv2d_49 (Conv2D)             (None, 14, 14, 128)  53248       ['activation_48[0][0]']          
                                                                                                  
 batch_normalization_50 (BatchN  (None, 14, 14, 128)  512        ['conv2d_49[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_49 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_50[0][0]'] 
                                                                                                  
 conv2d_50 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_49[0][0]']          
                                                                                                  
 concatenate_23 (Concatenate)   (None, 14, 14, 448)  0           ['concatenate_22[0][0]',         
                                                                  'conv2d_50[0][0]']              
                                                                                                  
 batch_normalization_51 (BatchN  (None, 14, 14, 448)  1792       ['concatenate_23[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_50 (Activation)     (None, 14, 14, 448)  0           ['batch_normalization_51[0][0]'] 
                                                                                                  
 conv2d_51 (Conv2D)             (None, 14, 14, 128)  57344       ['activation_50[0][0]']          
                                                                                                  
 batch_normalization_52 (BatchN  (None, 14, 14, 128)  512        ['conv2d_51[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_51 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_52[0][0]'] 
                                                                                                  
 conv2d_52 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_51[0][0]']          
                                                                                                  
 concatenate_24 (Concatenate)   (None, 14, 14, 480)  0           ['concatenate_23[0][0]',         
                                                                  'conv2d_52[0][0]']              
                                                                                                  
 batch_normalization_53 (BatchN  (None, 14, 14, 480)  1920       ['concatenate_24[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_52 (Activation)     (None, 14, 14, 480)  0           ['batch_normalization_53[0][0]'] 
                                                                                                  
 conv2d_53 (Conv2D)             (None, 14, 14, 128)  61440       ['activation_52[0][0]']          
                                                                                                  
 batch_normalization_54 (BatchN  (None, 14, 14, 128)  512        ['conv2d_53[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_53 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_54[0][0]'] 
                                                                                                  
 conv2d_54 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_53[0][0]']          
                                                                                                  
 concatenate_25 (Concatenate)   (None, 14, 14, 512)  0           ['concatenate_24[0][0]',         
                                                                  'conv2d_54[0][0]']              
                                                                                                  
 batch_normalization_55 (BatchN  (None, 14, 14, 512)  2048       ['concatenate_25[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_54 (Activation)     (None, 14, 14, 512)  0           ['batch_normalization_55[0][0]'] 
                                                                                                  
 conv2d_55 (Conv2D)             (None, 14, 14, 128)  65536       ['activation_54[0][0]']          
                                                                                                  
 batch_normalization_56 (BatchN  (None, 14, 14, 128)  512        ['conv2d_55[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_55 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_56[0][0]'] 
                                                                                                  
 conv2d_56 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_55[0][0]']          
                                                                                                  
 concatenate_26 (Concatenate)   (None, 14, 14, 544)  0           ['concatenate_25[0][0]',         
                                                                  'conv2d_56[0][0]']              
                                                                                                  
 batch_normalization_57 (BatchN  (None, 14, 14, 544)  2176       ['concatenate_26[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_56 (Activation)     (None, 14, 14, 544)  0           ['batch_normalization_57[0][0]'] 
                                                                                                  
 conv2d_57 (Conv2D)             (None, 14, 14, 128)  69632       ['activation_56[0][0]']          
                                                                                                  
 batch_normalization_58 (BatchN  (None, 14, 14, 128)  512        ['conv2d_57[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_57 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_58[0][0]'] 
                                                                                                  
 conv2d_58 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_57[0][0]']          
                                                                                                  
 concatenate_27 (Concatenate)   (None, 14, 14, 576)  0           ['concatenate_26[0][0]',         
                                                                  'conv2d_58[0][0]']              
                                                                                                  
 batch_normalization_59 (BatchN  (None, 14, 14, 576)  2304       ['concatenate_27[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_58 (Activation)     (None, 14, 14, 576)  0           ['batch_normalization_59[0][0]'] 
                                                                                                  
 conv2d_59 (Conv2D)             (None, 14, 14, 128)  73728       ['activation_58[0][0]']          
                                                                                                  
 batch_normalization_60 (BatchN  (None, 14, 14, 128)  512        ['conv2d_59[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_59 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_60[0][0]'] 
                                                                                                  
 conv2d_60 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_59[0][0]']          
                                                                                                  
 concatenate_28 (Concatenate)   (None, 14, 14, 608)  0           ['concatenate_27[0][0]',         
                                                                  'conv2d_60[0][0]']              
                                                                                                  
 batch_normalization_61 (BatchN  (None, 14, 14, 608)  2432       ['concatenate_28[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_60 (Activation)     (None, 14, 14, 608)  0           ['batch_normalization_61[0][0]'] 
                                                                                                  
 conv2d_61 (Conv2D)             (None, 14, 14, 128)  77824       ['activation_60[0][0]']          
                                                                                                  
 batch_normalization_62 (BatchN  (None, 14, 14, 128)  512        ['conv2d_61[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_61 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_62[0][0]'] 
                                                                                                  
 conv2d_62 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_61[0][0]']          
                                                                                                  
 concatenate_29 (Concatenate)   (None, 14, 14, 640)  0           ['concatenate_28[0][0]',         
                                                                  'conv2d_62[0][0]']              
                                                                                                  
 batch_normalization_63 (BatchN  (None, 14, 14, 640)  2560       ['concatenate_29[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_62 (Activation)     (None, 14, 14, 640)  0           ['batch_normalization_63[0][0]'] 
                                                                                                  
 conv2d_63 (Conv2D)             (None, 14, 14, 128)  81920       ['activation_62[0][0]']          
                                                                                                  
 batch_normalization_64 (BatchN  (None, 14, 14, 128)  512        ['conv2d_63[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_63 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_64[0][0]'] 
                                                                                                  
 conv2d_64 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_63[0][0]']          
                                                                                                  
 concatenate_30 (Concatenate)   (None, 14, 14, 672)  0           ['concatenate_29[0][0]',         
                                                                  'conv2d_64[0][0]']              
                                                                                                  
 batch_normalization_65 (BatchN  (None, 14, 14, 672)  2688       ['concatenate_30[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_64 (Activation)     (None, 14, 14, 672)  0           ['batch_normalization_65[0][0]'] 
                                                                                                  
 conv2d_65 (Conv2D)             (None, 14, 14, 128)  86016       ['activation_64[0][0]']          
                                                                                                  
 batch_normalization_66 (BatchN  (None, 14, 14, 128)  512        ['conv2d_65[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_65 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_66[0][0]'] 
                                                                                                  
 conv2d_66 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_65[0][0]']          
                                                                                                  
 concatenate_31 (Concatenate)   (None, 14, 14, 704)  0           ['concatenate_30[0][0]',         
                                                                  'conv2d_66[0][0]']              
                                                                                                  
 batch_normalization_67 (BatchN  (None, 14, 14, 704)  2816       ['concatenate_31[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_66 (Activation)     (None, 14, 14, 704)  0           ['batch_normalization_67[0][0]'] 
                                                                                                  
 conv2d_67 (Conv2D)             (None, 14, 14, 128)  90112       ['activation_66[0][0]']          
                                                                                                  
 batch_normalization_68 (BatchN  (None, 14, 14, 128)  512        ['conv2d_67[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_67 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_68[0][0]'] 
                                                                                                  
 conv2d_68 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_67[0][0]']          
                                                                                                  
 concatenate_32 (Concatenate)   (None, 14, 14, 736)  0           ['concatenate_31[0][0]',         
                                                                  'conv2d_68[0][0]']              
                                                                                                  
 batch_normalization_69 (BatchN  (None, 14, 14, 736)  2944       ['concatenate_32[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_68 (Activation)     (None, 14, 14, 736)  0           ['batch_normalization_69[0][0]'] 
                                                                                                  
 conv2d_69 (Conv2D)             (None, 14, 14, 128)  94208       ['activation_68[0][0]']          
                                                                                                  
 batch_normalization_70 (BatchN  (None, 14, 14, 128)  512        ['conv2d_69[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_69 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_70[0][0]'] 
                                                                                                  
 conv2d_70 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_69[0][0]']          
                                                                                                  
 concatenate_33 (Concatenate)   (None, 14, 14, 768)  0           ['concatenate_32[0][0]',         
                                                                  'conv2d_70[0][0]']              
                                                                                                  
 batch_normalization_71 (BatchN  (None, 14, 14, 768)  3072       ['concatenate_33[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_70 (Activation)     (None, 14, 14, 768)  0           ['batch_normalization_71[0][0]'] 
                                                                                                  
 conv2d_71 (Conv2D)             (None, 14, 14, 128)  98304       ['activation_70[0][0]']          
                                                                                                  
 batch_normalization_72 (BatchN  (None, 14, 14, 128)  512        ['conv2d_71[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_71 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_72[0][0]'] 
                                                                                                  
 conv2d_72 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_71[0][0]']          
                                                                                                  
 concatenate_34 (Concatenate)   (None, 14, 14, 800)  0           ['concatenate_33[0][0]',         
                                                                  'conv2d_72[0][0]']              
                                                                                                  
 batch_normalization_73 (BatchN  (None, 14, 14, 800)  3200       ['concatenate_34[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_72 (Activation)     (None, 14, 14, 800)  0           ['batch_normalization_73[0][0]'] 
                                                                                                  
 conv2d_73 (Conv2D)             (None, 14, 14, 128)  102400      ['activation_72[0][0]']          
                                                                                                  
 batch_normalization_74 (BatchN  (None, 14, 14, 128)  512        ['conv2d_73[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_73 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_74[0][0]'] 
                                                                                                  
 conv2d_74 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_73[0][0]']          
                                                                                                  
 concatenate_35 (Concatenate)   (None, 14, 14, 832)  0           ['concatenate_34[0][0]',         
                                                                  'conv2d_74[0][0]']              
                                                                                                  
 batch_normalization_75 (BatchN  (None, 14, 14, 832)  3328       ['concatenate_35[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_74 (Activation)     (None, 14, 14, 832)  0           ['batch_normalization_75[0][0]'] 
                                                                                                  
 conv2d_75 (Conv2D)             (None, 14, 14, 128)  106496      ['activation_74[0][0]']          
                                                                                                  
 batch_normalization_76 (BatchN  (None, 14, 14, 128)  512        ['conv2d_75[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_75 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_76[0][0]'] 
                                                                                                  
 conv2d_76 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_75[0][0]']          
                                                                                                  
 concatenate_36 (Concatenate)   (None, 14, 14, 864)  0           ['concatenate_35[0][0]',         
                                                                  'conv2d_76[0][0]']              
                                                                                                  
 batch_normalization_77 (BatchN  (None, 14, 14, 864)  3456       ['concatenate_36[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_76 (Activation)     (None, 14, 14, 864)  0           ['batch_normalization_77[0][0]'] 
                                                                                                  
 conv2d_77 (Conv2D)             (None, 14, 14, 128)  110592      ['activation_76[0][0]']          
                                                                                                  
 batch_normalization_78 (BatchN  (None, 14, 14, 128)  512        ['conv2d_77[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_77 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_78[0][0]'] 
                                                                                                  
 conv2d_78 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_77[0][0]']          
                                                                                                  
 concatenate_37 (Concatenate)   (None, 14, 14, 896)  0           ['concatenate_36[0][0]',         
                                                                  'conv2d_78[0][0]']              
                                                                                                  
 batch_normalization_79 (BatchN  (None, 14, 14, 896)  3584       ['concatenate_37[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_78 (Activation)     (None, 14, 14, 896)  0           ['batch_normalization_79[0][0]'] 
                                                                                                  
 conv2d_79 (Conv2D)             (None, 14, 14, 128)  114688      ['activation_78[0][0]']          
                                                                                                  
 batch_normalization_80 (BatchN  (None, 14, 14, 128)  512        ['conv2d_79[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_79 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_80[0][0]'] 
                                                                                                  
 conv2d_80 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_79[0][0]']          
                                                                                                  
 concatenate_38 (Concatenate)   (None, 14, 14, 928)  0           ['concatenate_37[0][0]',         
                                                                  'conv2d_80[0][0]']              
                                                                                                  
 batch_normalization_81 (BatchN  (None, 14, 14, 928)  3712       ['concatenate_38[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_80 (Activation)     (None, 14, 14, 928)  0           ['batch_normalization_81[0][0]'] 
                                                                                                  
 conv2d_81 (Conv2D)             (None, 14, 14, 128)  118784      ['activation_80[0][0]']          
                                                                                                  
 batch_normalization_82 (BatchN  (None, 14, 14, 128)  512        ['conv2d_81[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_81 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_82[0][0]'] 
                                                                                                  
 conv2d_82 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_81[0][0]']          
                                                                                                  
 concatenate_39 (Concatenate)   (None, 14, 14, 960)  0           ['concatenate_38[0][0]',         
                                                                  'conv2d_82[0][0]']              
                                                                                                  
 batch_normalization_83 (BatchN  (None, 14, 14, 960)  3840       ['concatenate_39[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_82 (Activation)     (None, 14, 14, 960)  0           ['batch_normalization_83[0][0]'] 
                                                                                                  
 conv2d_83 (Conv2D)             (None, 14, 14, 128)  122880      ['activation_82[0][0]']          
                                                                                                  
 batch_normalization_84 (BatchN  (None, 14, 14, 128)  512        ['conv2d_83[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_83 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_84[0][0]'] 
                                                                                                  
 conv2d_84 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_83[0][0]']          
                                                                                                  
 concatenate_40 (Concatenate)   (None, 14, 14, 992)  0           ['concatenate_39[0][0]',         
                                                                  'conv2d_84[0][0]']              
                                                                                                  
 batch_normalization_85 (BatchN  (None, 14, 14, 992)  3968       ['concatenate_40[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_84 (Activation)     (None, 14, 14, 992)  0           ['batch_normalization_85[0][0]'] 
                                                                                                  
 conv2d_85 (Conv2D)             (None, 14, 14, 128)  126976      ['activation_84[0][0]']          
                                                                                                  
 batch_normalization_86 (BatchN  (None, 14, 14, 128)  512        ['conv2d_85[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_85 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_86[0][0]'] 
                                                                                                  
 conv2d_86 (Conv2D)             (None, 14, 14, 32)   36864       ['activation_85[0][0]']          
                                                                                                  
 concatenate_41 (Concatenate)   (None, 14, 14, 1024  0           ['concatenate_40[0][0]',         
                                )                                 'conv2d_86[0][0]']              
                                                                                                  
 batch_normalization_87 (BatchN  (None, 14, 14, 1024  4096       ['concatenate_41[0][0]']         
 ormalization)                  )                                                                 
                                                                                                  
 activation_86 (Activation)     (None, 14, 14, 1024  0           ['batch_normalization_87[0][0]'] 
                                )                                                                 
                                                                                                  
 conv2d_87 (Conv2D)             (None, 14, 14, 512)  524288      ['activation_86[0][0]']          
                                                                                                  
 average_pooling2d_2 (AveragePo  (None, 7, 7, 512)   0           ['conv2d_87[0][0]']              
 oling2D)                                                                                         
                                                                                                  
 batch_normalization_88 (BatchN  (None, 7, 7, 512)   2048        ['average_pooling2d_2[0][0]']    
 ormalization)                                                                                    
                                                                                                  
 activation_87 (Activation)     (None, 7, 7, 512)    0           ['batch_normalization_88[0][0]'] 
                                                                                                  
 conv2d_88 (Conv2D)             (None, 7, 7, 128)    65536       ['activation_87[0][0]']          
                                                                                                  
 batch_normalization_89 (BatchN  (None, 7, 7, 128)   512         ['conv2d_88[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_88 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_89[0][0]'] 
                                                                                                  
 conv2d_89 (Conv2D)             (None, 7, 7, 32)     36864       ['activation_88[0][0]']          
                                                                                                  
 concatenate_42 (Concatenate)   (None, 7, 7, 544)    0           ['average_pooling2d_2[0][0]',    
                                                                  'conv2d_89[0][0]']              
                                                                                                  
 batch_normalization_90 (BatchN  (None, 7, 7, 544)   2176        ['concatenate_42[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_89 (Activation)     (None, 7, 7, 544)    0           ['batch_normalization_90[0][0]'] 
                                                                                                  
 conv2d_90 (Conv2D)             (None, 7, 7, 128)    69632       ['activation_89[0][0]']          
                                                                                                  
 batch_normalization_91 (BatchN  (None, 7, 7, 128)   512         ['conv2d_90[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_90 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_91[0][0]'] 
                                                                                                  
 conv2d_91 (Conv2D)             (None, 7, 7, 32)     36864       ['activation_90[0][0]']          
                                                                                                  
 concatenate_43 (Concatenate)   (None, 7, 7, 576)    0           ['concatenate_42[0][0]',         
                                                                  'conv2d_91[0][0]']              
                                                                                                  
 batch_normalization_92 (BatchN  (None, 7, 7, 576)   2304        ['concatenate_43[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_91 (Activation)     (None, 7, 7, 576)    0           ['batch_normalization_92[0][0]'] 
                                                                                                  
 conv2d_92 (Conv2D)             (None, 7, 7, 128)    73728       ['activation_91[0][0]']          
                                                                                                  
 batch_normalization_93 (BatchN  (None, 7, 7, 128)   512         ['conv2d_92[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_92 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_93[0][0]'] 
                                                                                                  
 conv2d_93 (Conv2D)             (None, 7, 7, 32)     36864       ['activation_92[0][0]']          
                                                                                                  
 concatenate_44 (Concatenate)   (None, 7, 7, 608)    0           ['concatenate_43[0][0]',         
                                                                  'conv2d_93[0][0]']              
                                                                                                  
 batch_normalization_94 (BatchN  (None, 7, 7, 608)   2432        ['concatenate_44[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_93 (Activation)     (None, 7, 7, 608)    0           ['batch_normalization_94[0][0]'] 
                                                                                                  
 conv2d_94 (Conv2D)             (None, 7, 7, 128)    77824       ['activation_93[0][0]']          
                                                                                                  
 batch_normalization_95 (BatchN  (None, 7, 7, 128)   512         ['conv2d_94[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_94 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_95[0][0]'] 
                                                                                                  
 conv2d_95 (Conv2D)             (None, 7, 7, 32)     36864       ['activation_94[0][0]']          
                                                                                                  
 concatenate_45 (Concatenate)   (None, 7, 7, 640)    0           ['concatenate_44[0][0]',         
                                                                  'conv2d_95[0][0]']              
                                                                                                  
 batch_normalization_96 (BatchN  (None, 7, 7, 640)   2560        ['concatenate_45[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_95 (Activation)     (None, 7, 7, 640)    0           ['batch_normalization_96[0][0]'] 
                                                                                                  
 conv2d_96 (Conv2D)             (None, 7, 7, 128)    81920       ['activation_95[0][0]']          
                                                                                                  
 batch_normalization_97 (BatchN  (None, 7, 7, 128)   512         ['conv2d_96[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_96 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_97[0][0]'] 
                                                                                                  
 conv2d_97 (Conv2D)             (None, 7, 7, 32)     36864       ['activation_96[0][0]']          
                                                                                                  
 concatenate_46 (Concatenate)   (None, 7, 7, 672)    0           ['concatenate_45[0][0]',         
                                                                  'conv2d_97[0][0]']              
                                                                                                  
 batch_normalization_98 (BatchN  (None, 7, 7, 672)   2688        ['concatenate_46[0][0]']         
 ormalization)                                                                                    
                                                                                                  
 activation_97 (Activation)     (None, 7, 7, 672)    0           ['batch_normalization_98[0][0]'] 
                                                                                                  
 conv2d_98 (Conv2D)             (None, 7, 7, 128)    86016       ['activation_97[0][0]']          
                                                                                                  
 batch_normalization_99 (BatchN  (None, 7, 7, 128)   512         ['conv2d_98[0][0]']              
 ormalization)                                                                                    
                                                                                                  
 activation_98 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_99[0][0]'] 
                                                                                                  
 conv2d_99 (Conv2D)             (None, 7, 7, 32)     36864       ['activation_98[0][0]']          
                                                                                                  
 concatenate_47 (Concatenate)   (None, 7, 7, 704)    0           ['concatenate_46[0][0]',         
                                                                  'conv2d_99[0][0]']              
                                                                                                  
 batch_normalization_100 (Batch  (None, 7, 7, 704)   2816        ['concatenate_47[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_99 (Activation)     (None, 7, 7, 704)    0           ['batch_normalization_100[0][0]']
                                                                                                  
 conv2d_100 (Conv2D)            (None, 7, 7, 128)    90112       ['activation_99[0][0]']          
                                                                                                  
 batch_normalization_101 (Batch  (None, 7, 7, 128)   512         ['conv2d_100[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_100 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_101[0][0]']
                                                                                                  
 conv2d_101 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_100[0][0]']         
                                                                                                  
 concatenate_48 (Concatenate)   (None, 7, 7, 736)    0           ['concatenate_47[0][0]',         
                                                                  'conv2d_101[0][0]']             
                                                                                                  
 batch_normalization_102 (Batch  (None, 7, 7, 736)   2944        ['concatenate_48[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_101 (Activation)    (None, 7, 7, 736)    0           ['batch_normalization_102[0][0]']
                                                                                                  
 conv2d_102 (Conv2D)            (None, 7, 7, 128)    94208       ['activation_101[0][0]']         
                                                                                                  
 batch_normalization_103 (Batch  (None, 7, 7, 128)   512         ['conv2d_102[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_102 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_103[0][0]']
                                                                                                  
 conv2d_103 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_102[0][0]']         
                                                                                                  
 concatenate_49 (Concatenate)   (None, 7, 7, 768)    0           ['concatenate_48[0][0]',         
                                                                  'conv2d_103[0][0]']             
                                                                                                  
 batch_normalization_104 (Batch  (None, 7, 7, 768)   3072        ['concatenate_49[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_103 (Activation)    (None, 7, 7, 768)    0           ['batch_normalization_104[0][0]']
                                                                                                  
 conv2d_104 (Conv2D)            (None, 7, 7, 128)    98304       ['activation_103[0][0]']         
                                                                                                  
 batch_normalization_105 (Batch  (None, 7, 7, 128)   512         ['conv2d_104[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_104 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_105[0][0]']
                                                                                                  
 conv2d_105 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_104[0][0]']         
                                                                                                  
 concatenate_50 (Concatenate)   (None, 7, 7, 800)    0           ['concatenate_49[0][0]',         
                                                                  'conv2d_105[0][0]']             
                                                                                                  
 batch_normalization_106 (Batch  (None, 7, 7, 800)   3200        ['concatenate_50[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_105 (Activation)    (None, 7, 7, 800)    0           ['batch_normalization_106[0][0]']
                                                                                                  
 conv2d_106 (Conv2D)            (None, 7, 7, 128)    102400      ['activation_105[0][0]']         
                                                                                                  
 batch_normalization_107 (Batch  (None, 7, 7, 128)   512         ['conv2d_106[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_106 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_107[0][0]']
                                                                                                  
 conv2d_107 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_106[0][0]']         
                                                                                                  
 concatenate_51 (Concatenate)   (None, 7, 7, 832)    0           ['concatenate_50[0][0]',         
                                                                  'conv2d_107[0][0]']             
                                                                                                  
 batch_normalization_108 (Batch  (None, 7, 7, 832)   3328        ['concatenate_51[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_107 (Activation)    (None, 7, 7, 832)    0           ['batch_normalization_108[0][0]']
                                                                                                  
 conv2d_108 (Conv2D)            (None, 7, 7, 128)    106496      ['activation_107[0][0]']         
                                                                                                  
 batch_normalization_109 (Batch  (None, 7, 7, 128)   512         ['conv2d_108[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_108 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_109[0][0]']
                                                                                                  
 conv2d_109 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_108[0][0]']         
                                                                                                  
 concatenate_52 (Concatenate)   (None, 7, 7, 864)    0           ['concatenate_51[0][0]',         
                                                                  'conv2d_109[0][0]']             
                                                                                                  
 batch_normalization_110 (Batch  (None, 7, 7, 864)   3456        ['concatenate_52[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_109 (Activation)    (None, 7, 7, 864)    0           ['batch_normalization_110[0][0]']
                                                                                                  
 conv2d_110 (Conv2D)            (None, 7, 7, 128)    110592      ['activation_109[0][0]']         
                                                                                                  
 batch_normalization_111 (Batch  (None, 7, 7, 128)   512         ['conv2d_110[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_110 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_111[0][0]']
                                                                                                  
 conv2d_111 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_110[0][0]']         
                                                                                                  
 concatenate_53 (Concatenate)   (None, 7, 7, 896)    0           ['concatenate_52[0][0]',         
                                                                  'conv2d_111[0][0]']             
                                                                                                  
 batch_normalization_112 (Batch  (None, 7, 7, 896)   3584        ['concatenate_53[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_111 (Activation)    (None, 7, 7, 896)    0           ['batch_normalization_112[0][0]']
                                                                                                  
 conv2d_112 (Conv2D)            (None, 7, 7, 128)    114688      ['activation_111[0][0]']         
                                                                                                  
 batch_normalization_113 (Batch  (None, 7, 7, 128)   512         ['conv2d_112[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_112 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_113[0][0]']
                                                                                                  
 conv2d_113 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_112[0][0]']         
                                                                                                  
 concatenate_54 (Concatenate)   (None, 7, 7, 928)    0           ['concatenate_53[0][0]',         
                                                                  'conv2d_113[0][0]']             
                                                                                                  
 batch_normalization_114 (Batch  (None, 7, 7, 928)   3712        ['concatenate_54[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_113 (Activation)    (None, 7, 7, 928)    0           ['batch_normalization_114[0][0]']
                                                                                                  
 conv2d_114 (Conv2D)            (None, 7, 7, 128)    118784      ['activation_113[0][0]']         
                                                                                                  
 batch_normalization_115 (Batch  (None, 7, 7, 128)   512         ['conv2d_114[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_114 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_115[0][0]']
                                                                                                  
 conv2d_115 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_114[0][0]']         
                                                                                                  
 concatenate_55 (Concatenate)   (None, 7, 7, 960)    0           ['concatenate_54[0][0]',         
                                                                  'conv2d_115[0][0]']             
                                                                                                  
 batch_normalization_116 (Batch  (None, 7, 7, 960)   3840        ['concatenate_55[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_115 (Activation)    (None, 7, 7, 960)    0           ['batch_normalization_116[0][0]']
                                                                                                  
 conv2d_116 (Conv2D)            (None, 7, 7, 128)    122880      ['activation_115[0][0]']         
                                                                                                  
 batch_normalization_117 (Batch  (None, 7, 7, 128)   512         ['conv2d_116[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_116 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_117[0][0]']
                                                                                                  
 conv2d_117 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_116[0][0]']         
                                                                                                  
 concatenate_56 (Concatenate)   (None, 7, 7, 992)    0           ['concatenate_55[0][0]',         
                                                                  'conv2d_117[0][0]']             
                                                                                                  
 batch_normalization_118 (Batch  (None, 7, 7, 992)   3968        ['concatenate_56[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_117 (Activation)    (None, 7, 7, 992)    0           ['batch_normalization_118[0][0]']
                                                                                                  
 conv2d_118 (Conv2D)            (None, 7, 7, 128)    126976      ['activation_117[0][0]']         
                                                                                                  
 batch_normalization_119 (Batch  (None, 7, 7, 128)   512         ['conv2d_118[0][0]']             
 Normalization)                                                                                   
                                                                                                  
 activation_118 (Activation)    (None, 7, 7, 128)    0           ['batch_normalization_119[0][0]']
                                                                                                  
 conv2d_119 (Conv2D)            (None, 7, 7, 32)     36864       ['activation_118[0][0]']         
                                                                                                  
 concatenate_57 (Concatenate)   (None, 7, 7, 1024)   0           ['concatenate_56[0][0]',         
                                                                  'conv2d_119[0][0]']             
                                                                                                  
 batch_normalization_120 (Batch  (None, 7, 7, 1024)  4096        ['concatenate_57[0][0]']         
 Normalization)                                                                                   
                                                                                                  
 activation_119 (Activation)    (None, 7, 7, 1024)   0           ['batch_normalization_120[0][0]']
                                                                                                  
 global_average_pooling2d (Glob  (None, 1024)        0           ['activation_119[0][0]']         
 alAveragePooling2D)                                                                              
                                                                                                  
 dense (Dense)                  (None, 1000)         1025000     ['global_average_pooling2d[0][0]'
                                                                 ]                                
                                                                                                  
==================================================================================================
Total params: 8,062,504
Trainable params: 7,978,856
Non-trainable params: 83,648
__________________________________________________________________________________________________
</code></pre> 
<h3><a id="310_2708"></a>3.10.ç¼–è¯‘æ¨¡å‹</h3> 
<pre><code class="prism language-python"><span class="token comment">#è®¾ç½®åˆå§‹å­¦ä¹ ç‡</span>
initial_learning_rate <span class="token operator">=</span> <span class="token number">1e-4</span>
opt <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>initial_learning_rate<span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>opt<span class="token punctuation">,</span>
              loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


</code></pre> 
<h3><a id="311_2719"></a>3.11.è®­ç»ƒæ¨¡å‹</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''è®­ç»ƒæ¨¡å‹'''</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
history <span class="token operator">=</span> model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>
    train_ds<span class="token punctuation">,</span>
    validation_data<span class="token operator">=</span>val_ds<span class="token punctuation">,</span>
    epochs<span class="token operator">=</span>epochs
<span class="token punctuation">)</span>
</code></pre> 
<p>è®­ç»ƒè®°å½•å¦‚ä¸‹ï¼š</p> 
<pre><code>Epoch 1/10
15/15 [==============================] - ETA: 0s - loss: 5.1516 - accuracy: 0.4735
Epoch 1: val_accuracy improved from -inf to 0.30310, saving model to best_model.h5
15/15 [==============================] - 19s 345ms/step - loss: 5.1516 - accuracy: 0.4735 - val_loss: 5.6926 - val_accuracy: 0.3031
Epoch 2/10
15/15 [==============================] - ETA: 0s - loss: 2.6124 - accuracy: 0.7102
Epoch 2: val_accuracy did not improve from 0.30310
15/15 [==============================] - 3s 211ms/step - loss: 2.6124 - accuracy: 0.7102 - val_loss: 5.7346 - val_accuracy: 0.3009
Epoch 3/10
15/15 [==============================] - ETA: 0s - loss: 1.3227 - accuracy: 0.7987
Epoch 3: val_accuracy improved from 0.30310 to 0.35841, saving model to best_model.h5
15/15 [==============================] - 3s 234ms/step - loss: 1.3227 - accuracy: 0.7987 - val_loss: 5.5666 - val_accuracy: 0.3584
Epoch 4/10
14/15 [===========================&gt;..] - ETA: 0s - loss: 0.7132 - accuracy: 0.8862
Epoch 4: val_accuracy improved from 0.35841 to 0.43584, saving model to best_model.h5
15/15 [==============================] - 3s 230ms/step - loss: 0.7095 - accuracy: 0.8872 - val_loss: 5.0263 - val_accuracy: 0.4358
Epoch 5/10
15/15 [==============================] - ETA: 0s - loss: 0.4048 - accuracy: 0.9248
Epoch 5: val_accuracy improved from 0.43584 to 0.52434, saving model to best_model.h5
15/15 [==============================] - 3s 233ms/step - loss: 0.4048 - accuracy: 0.9248 - val_loss: 4.4517 - val_accuracy: 0.5243
Epoch 6/10
15/15 [==============================] - ETA: 0s - loss: 0.2979 - accuracy: 0.9425
Epoch 6: val_accuracy improved from 0.52434 to 0.63274, saving model to best_model.h5
15/15 [==============================] - 3s 234ms/step - loss: 0.2979 - accuracy: 0.9425 - val_loss: 3.6860 - val_accuracy: 0.6327
Epoch 7/10
15/15 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.9336
Epoch 7: val_accuracy did not improve from 0.63274
15/15 [==============================] - 3s 206ms/step - loss: 0.2562 - accuracy: 0.9336 - val_loss: 3.1774 - val_accuracy: 0.4823
Epoch 8/10
14/15 [===========================&gt;..] - ETA: 0s - loss: 0.1304 - accuracy: 0.9777
Epoch 8: val_accuracy did not improve from 0.63274
15/15 [==============================] - 3s 206ms/step - loss: 0.1313 - accuracy: 0.9757 - val_loss: 2.8684 - val_accuracy: 0.3562
Epoch 9/10
15/15 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9801
Epoch 9: val_accuracy did not improve from 0.63274
15/15 [==============================] - 3s 204ms/step - loss: 0.1086 - accuracy: 0.9801 - val_loss: 2.4839 - val_accuracy: 0.4049
Epoch 10/10
15/15 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9889
Epoch 10: val_accuracy did not improve from 0.63274
15/15 [==============================] - 3s 204ms/step - loss: 0.0784 - accuracy: 0.9889 - val_loss: 2.3421 - val_accuracy: 0.3982




</code></pre> 
<h3><a id="312_2778"></a>3.12.æ¨¡å‹è¯„ä¼°</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''æ¨¡å‹è¯„ä¼°'''</span>
acc <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
val_acc <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_accuracy'</span><span class="token punctuation">]</span>
loss <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>
val_loss <span class="token operator">=</span> history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span>
epochs_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> val_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/4e/5c/Uf6LauV8_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h3><a id="313_2803"></a>3.13.å›¾åƒé¢„æµ‹</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''æŒ‡å®šå›¾ç‰‡è¿›è¡Œé¢„æµ‹'''</span>
<span class="token comment"># é‡‡ç”¨åŠ è½½çš„æ¨¡å‹ï¼ˆnew_modelï¼‰æ¥çœ‹é¢„æµ‹ç»“æœ</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># å›¾å½¢çš„å®½ä¸º10é«˜ä¸º5</span>
plt<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">"é¢„æµ‹ç»“æœå±•ç¤º"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> val_ds<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># æ˜¾ç¤ºå›¾ç‰‡</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"uint8"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># éœ€è¦ç»™å›¾ç‰‡å¢åŠ ä¸€ä¸ªç»´åº¦</span>
        img_array <span class="token operator">=</span> tf<span class="token punctuation">.</span>expand_dims<span class="token punctuation">(</span>images<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># ä½¿ç”¨æ¨¡å‹é¢„æµ‹å›¾ç‰‡ä¸­çš„äººç‰©</span>
        predictions <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>img_array<span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>class_names<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>predictions<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span>

        plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/9a/4f/kpj2ETVJ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="4__2831"></a>4 çŸ¥è¯†ç‚¹è¯¦è§£</h2> 
<h3><a id="41_DenseNet_2832"></a>4.1 DenseNetç®—æ³•è¯¦è§£</h3> 
<h4><a id="411__2833"></a>4.1.1 å‰è¨€</h4> 
<p>â€ƒâ€ƒåœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰å·²ç»æˆä¸ºæœ€ä¸»æµçš„æ–¹æ³•ï¼Œæ¯”å¦‚GoogleNetï¼ŒVGG-16ï¼ŒIncepetionç­‰æ¨¡å‹ã€‚CNNå²ä¸Šçš„ä¸€ä¸ªé‡Œç¨‹ç¢‘äº‹ä»¶æ˜¯ResNetæ¨¡å‹çš„å‡ºç°ï¼ŒResNetå¯ä»¥è®­ç»ƒå‡ºæ›´æ·±çš„CNNæ¨¡å‹ï¼Œä»è€Œå®ç°æ›´é«˜çš„å‡†ç¡®ç‡ã€‚ResNetæ¨¡å‹çš„æ ¸å¿ƒæ˜¯é€šè¿‡å»ºç«‹å‰é¢å±‚ä¸åé¢å±‚ä¹‹é—´çš„â€œçŸ­è·¯è¿æ¥â€ï¼ˆshortcut, skip connectionï¼‰ï¼Œè¿›è€Œè®­ç»ƒå‡ºæ›´æ·±çš„CNNç½‘ç»œã€‚</p> 
<p>â€ƒâ€ƒDenseNetæ¨¡å‹çš„åŸºæœ¬æ€è·¯ä¸ResNetä¸€è‡´ï¼Œä½†æ˜¯å®ƒå»ºç«‹çš„æ˜¯å‰é¢æ‰€æœ‰å±‚ä¸åé¢å±‚çš„ç´§å¯†è¿æ¥ï¼ˆdense connectionï¼‰ï¼Œå®ƒçš„åç§°ä¹Ÿæ˜¯ç”±æ­¤è€Œæ¥ã€‚DenseNetçš„å¦ä¸€å¤§ç‰¹è‰²æ˜¯é€šè¿‡ç‰¹å¾åœ¨channelä¸Šçš„çš„è¿æ¥æ¥å®ç°ç‰¹å¾é‡ç”¨ï¼ˆfeature reuseï¼‰ã€‚è¿™äº›ç‰¹ç‚¹è®©DenseNetåœ¨å‚æ•°å’Œè®¡ç®—æˆæœ¬æ›´å°‘çš„æƒ…å½¢ä¸‹å®ç°æ¯”ResNetæ›´ä¼˜çš„æ€§èƒ½ï¼ŒDenseNetä¹Ÿå› æ­¤æ–©è·CVPR2017çš„æœ€ä½³è®ºæ–‡å¥–ã€‚<br> <img src="https://images2.imgbox.com/c7/d6/CjfVl1hX_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾1 Denseæ¨¡å—ï¼ˆ5-layer,growth rate of k=4ï¼‰ 
</center> 
<p>â€ƒâ€ƒå…¶ä¸­DenseNetè®ºæ–‡åŸæ–‡åœ°å€ä¸ºï¼šhttps://arxiv.org/pdf/1608.06993v5.pdf</p> 
<h4><a id="412__2845"></a>4.1.2 è®¾è®¡ç†å¿µ</h4> 
<p>â€ƒâ€ƒç›¸æ¯”ResNetï¼ŒDenseNetæå‡ºäº†ä¸€ä¸ªæ›´æ¿€è¿›çš„å¯†é›†è¿æ¥æœºåˆ¶ï¼šå³äº’ç›¸è¿æ¥æ‰€æœ‰çš„å±‚ï¼Œå…·ä½“æ¥è¯´å°±æ˜¯æ¯ä¸ªå±‚éƒ½ä¼šæ¥å—å‰é¢æ‰€æœ‰å±‚ä½œä¸ºé¢å¤–çš„è¾“å…¥ã€‚</p> 
<p>â€ƒâ€ƒå›¾3ä¸ºResNetç½‘ç»œçš„æ®‹å·®è¿æ¥æœºåˆ¶ï¼Œä½œä¸ºå¯¹æ¯”ï¼Œå›¾4ä¸ºDenseNetçš„å¯†é›†è¿æ¥æœºåˆ¶ã€‚å¯ä»¥çœ‹åˆ°ï¼ŒResNetæ˜¯æ¯ä¸ªå±‚ä¸å‰é¢çš„æŸå±‚ï¼ˆä¸€èˆ¬æ˜¯2~4å±‚ï¼‰çŸ­è·¯è¿æ¥åœ¨ä¸€èµ·ï¼Œè¿æ¥æ–¹å¼æ˜¯é€šè¿‡å…ƒç´ ç›¸åŠ ã€‚è€Œåœ¨DenseNetä¸­ï¼Œæ¯ä¸ªå±‚éƒ½ä¼šä¸å‰é¢æ‰€æœ‰å±‚åœ¨channelç»´åº¦ä¸Šé“¾æ¥ï¼ˆconcatï¼‰åœ¨ä¸€èµ·ï¼ˆå³å…ƒç´ å åŠ ï¼‰ï¼Œå¹¶ä½œä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ã€‚</p> 
<p>â€ƒâ€ƒå¯¹äºä¸€ä¸ª<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         L 
        
       
      
        L 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span>å±‚çš„ç½‘ç»œï¼ŒDenseNetå…±åŒ…å«<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
         
         
           L 
          
         
           ( 
          
         
           L 
          
         
           + 
          
         
           1 
          
         
           ) 
          
         
        
          2 
         
        
       
      
        \frac{L(L+1)}{2} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.355em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.01em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.485em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight">L</span><span class="mbin mtight">+</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>ä¸ªè¿æ¥ï¼Œç›¸æ¯”ResNetï¼Œè¿™æ˜¯ä¸€ç§å¯†é›†è¿æ¥ã€‚è€Œä¸”DenseNetæ˜¯ç›´æ¥concatæ¥è‡ªä¸åŒå±‚çš„ç‰¹å¾å›¾ï¼Œè¿™å¯ä»¥å®ç°ç‰¹å¾é‡ç”¨ï¼Œæå‡æ•ˆç‡ï¼Œè¿™ä¸€ç‰¹ç‚¹æ˜¯DenseNetä¸ResNetæœ€ä¸»è¦çš„åŒºåˆ«ã€‚</p> 
<h4><a id="4121__2853"></a>4.1.2.1 æ ‡å‡†ç¥ç»ç½‘ç»œ</h4> 
<p><img src="https://images2.imgbox.com/98/7a/GZrrMZHA_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾2 æ ‡å‡†çš„ç¥ç»ç½‘ç»œä¼ æ’­è¿‡ç¨‹ 
</center> 
<p>â€ƒâ€ƒå›¾2æ˜¯ä¸€ä¸ªæ ‡å‡†çš„ç¥ç»ç½‘ç»œä¼ æ’­è¿‡ç¨‹ç¤ºæ„å›¾ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„å…¬å¼æ˜¯<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          l 
         
        
       
         = 
        
        
        
          H 
         
        
          l 
         
        
       
         ( 
        
        
        
          X 
         
         
         
           l 
          
         
           âˆ’ 
          
         
           1 
          
         
        
       
         ) 
        
       
      
        X_l=H_l(X_{l-1}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0813em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>ï¼Œå…¶ä¸­ <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          H 
         
        
          l 
         
        
       
      
        H_l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0813em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>æ˜¯ä¸€ä¸ªç»„åˆå‡½æ•°ï¼Œé€šå¸¸åŒ…æ‹¬BNã€ReLuã€Poolingã€Convç­‰æ“ä½œï¼Œ<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
         
         
           l 
          
         
           âˆ’ 
          
         
           1 
          
         
        
       
      
        X_{l-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>æ˜¯ç¬¬<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
      
        l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span></span></span></span></span>å±‚çš„è¾“å…¥çš„ç‰¹å¾å›¾ï¼ˆæ¥è‡ªäºl-1å±‚çš„è¾“å‡ºï¼‰,<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          l 
         
        
       
      
        X_l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>æ˜¯ç¬¬<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
      
        l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span></span></span></span></span>å±‚çš„è¾“å‡ºçš„ç‰¹å¾å›¾ã€‚</p> 
<h4><a id="4122_ResNet_2860"></a>4.1.2.2 ResNet</h4> 
<p><img src="https://images2.imgbox.com/73/cf/Dbh6aajW_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾3 ResNetç½‘ç»œçš„çŸ­è·¯è¿æ¥æœºåˆ¶ï¼ˆ+ä»£è¡¨å…ƒç´ çº§ç›¸åŠ æ“ä½œï¼‰ 
</center> 
<p>â€ƒâ€ƒå›¾3æ˜¯ResNetçš„ç½‘ç»œè¿æ¥æœºåˆ¶ï¼Œç”±å›¾å¯çŸ¥æ˜¯è·¨å±‚ç›¸åŠ ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„å…¬å¼æ˜¯<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          l 
         
        
       
         = 
        
        
        
          H 
         
        
          l 
         
        
       
         ( 
        
        
        
          X 
         
         
         
           l 
          
         
           âˆ’ 
          
         
           1 
          
         
        
       
         ) 
        
       
         + 
        
        
        
          X 
         
         
         
           l 
          
         
           âˆ’ 
          
         
           1 
          
         
        
       
      
        X_l=H_l(X_{l-1})+X_{l-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0813em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8917em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span></p> 
<h4><a id="4123_DenseNet_2867"></a>4.1.2.3 DenseNet</h4> 
<p><img src="https://images2.imgbox.com/2e/19/sN3NfbpJ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾4 DenseNetç½‘ç»œçš„å¯†é›†è¿æ¥æœºåˆ¶ï¼ˆå…¶ä¸­Cä»£è¡¨å±‚çº§çš„concatæ“ä½œï¼‰ 
</center> 
<p>â€ƒâ€ƒå›¾4ä¸ºDenseNetçš„è¿æ¥æœºåˆ¶ï¼Œé‡‡ç”¨è·¨é€šé“çš„concatçš„å½¢å¼è¿æ¥ï¼Œä¼šè¿æ¥å‰é¢æ‰€æœ‰å±‚ä½œä¸ºè¾“å…¥ï¼Œè¾“å…¥å’Œè¾“å‡ºçš„å…¬å¼æ˜¯<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          l 
         
        
       
         = 
        
        
        
          H 
         
        
          l 
         
        
       
         ( 
        
        
        
          X 
         
        
          0 
         
        
       
         , 
        
        
        
          X 
         
        
          1 
         
        
       
         , 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         , 
        
        
        
          X 
         
         
         
           l 
          
         
           âˆ’ 
          
         
           1 
          
         
        
       
         ) 
        
       
      
        X_l=H_l(X_0,X_1,...,X_{l-1}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0813em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>ã€‚è¿™é‡Œè¦æ³¨æ„æ‰€æœ‰å±‚çš„è¾“å…¥éƒ½æ¥æºäºå‰é¢æ‰€æœ‰å±‚åœ¨channelç»´åº¦çš„concatï¼Œä»¥ä¸‹åŠ¨å›¾å½¢è±¡è¡¨ç¤ºè¿™ä¸€æ“ä½œã€‚<br> <img src="https://images2.imgbox.com/bf/29/LtoPfvfr_o.gif" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾5 DenseNetå‰å‘è¿‡ç¨‹ 
</center> 
<h4><a id="413__2878"></a>4.1.3 ç½‘ç»œç»“æ„</h4> 
<pre><code>ç½‘ç»œçš„å…·ä½“å®ç°ç»†èŠ‚å¦‚å›¾6æ‰€ç¤ºã€‚
</code></pre> 
<p><img src="https://images2.imgbox.com/f7/fe/KRs1UlZr_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾6 DenseNetçš„ç½‘ç»œç»“æ„ 
</center> 
<p>â€ƒâ€ƒCNNç½‘ç»œä¸€èˆ¬è¦ç»è¿‡Poolingæˆ–è€…stride&gt;1çš„Convæ¥é™ä½ç‰¹å¾å›¾çš„å¤§å°ï¼Œè€ŒDenseNetçš„å¯†é›†è¿æ¥æ–¹å¼éœ€è¦ç‰¹å¾å›¾å¤§å°ä¿æŒä¸€è‡´ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼ŒDenseNetç½‘ç»œä¸­ä½¿ç”¨DenseBlock+Transitionçš„ç»“æ„ï¼Œå…¶ä¸­DenseBlockæ˜¯åŒ…å«å¾ˆå¤šå±‚çš„æ¨¡å—ï¼Œæ¯ä¸ªå±‚çš„ç‰¹å¾å›¾å¤§å°ç›¸åŒï¼Œå±‚ä¸å±‚ä¹‹é—´é‡‡ç”¨å¯†é›†è¿æ¥æ–¹å¼ã€‚è€ŒTransitionå±‚æ˜¯è¿æ¥ä¸¤ä¸ªç›¸é‚»çš„DenseBlockï¼Œå¹¶ä¸”é€šè¿‡Poolingä½¿ç‰¹å¾å›¾å¤§å°é™ä½ã€‚å›¾7ç»™å‡ºäº†DenseNetçš„ç½‘ç»œç»“æ„ï¼Œå®ƒå…±åŒ…å«4ä¸ªDenseBlockï¼Œå„ä¸ªDenseBlockä¹‹é—´é€šè¿‡Transitionå±‚è¿æ¥åœ¨ä¸€èµ·ã€‚</p> 
<p><img src="https://images2.imgbox.com/97/bb/cFi9BrzS_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾7 ä½¿ç”¨DenseBlock+Transitionçš„DenseNetç½‘ç»œ 
</center> 
<p>â€ƒâ€ƒåœ¨DenseBlockä¸­ï¼Œå„ä¸ªå±‚çš„ç‰¹å¾å›¾å¤§å°ä¸€è‡´ï¼Œå¯ä»¥åœ¨channelç»´åº¦ä¸Šè¿æ¥ã€‚DenseBlockä¸­çš„éçº¿æ€§ç»„åˆå‡½æ•°<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         H 
        
       
         ( 
        
       
         â‹… 
        
       
         ) 
        
       
      
        H(\cdot) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0813em;">H</span><span class="mopen">(</span><span class="mord">â‹…</span><span class="mclose">)</span></span></span></span></span>çš„æ˜¯<strong>BN+ReLU+3x3Conv</strong>çš„ç»“æ„ï¼Œå¦‚å›¾8æ‰€ç¤ºã€‚å¦å¤–ï¼Œä¸ResNetä¸åŒï¼Œæ‰€æœ‰DenseBlockä¸­å„ä¸ªå±‚å·ç§¯ä¹‹åå‡è¾“å‡ºkä¸ªç‰¹å¾å›¾ï¼Œå³å¾—åˆ°çš„ç‰¹å¾å›¾çš„channelæ•°ä¸ºkï¼Œæˆ–è€…è¯´é‡‡ç”¨kä¸ªå·ç§¯æ ¸ã€‚kåœ¨DenseNetç§°ä¸ºgrowth rateï¼Œè¿™æ˜¯ä¸€ä¸ªè¶…å‚æ•°ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ä½¿ç”¨è¾ƒå°çš„kï¼ˆæ¯”å¦‚12ï¼‰ï¼Œå°±å¯ä»¥å¾—åˆ°è¾ƒä½³çš„æ€§èƒ½ã€‚å‡å®šè¾“å…¥å±‚çš„ç‰¹å¾å›¾çš„channelæ•°ä¸º<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          0 
         
        
       
      
        k_0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>ï¼Œé‚£ä¹ˆ<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
      
        l 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span></span></span></span></span>å±‚è¾“å…¥çš„channelæ•°ä¸º<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          k 
         
        
          0 
         
        
       
         + 
        
        
        
          k 
         
         
         
           ( 
          
         
           1 
          
         
           , 
          
         
           2 
          
         
           , 
          
         
           . 
          
         
           . 
          
         
           . 
          
         
           , 
          
         
           l 
          
         
           âˆ’ 
          
         
           1 
          
         
           ) 
          
         
        
       
      
        k_0+k_{(1,2,...,l-1)} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0496em; vertical-align: -0.3552em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0315em;">k</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.5198em; margin-left: -0.0315em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mpunct mtight">,</span><span class="mord mtight">2</span><span class="mpunct mtight">,</span><span class="mord mtight">...</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right: 0.0197em;">l</span><span class="mbin mtight">âˆ’</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3552em;"><span class=""></span></span></span></span></span></span></span></span></span></span>ï¼Œå› æ­¤éšç€å±‚æ•°çš„å¢åŠ ï¼Œå°½ç®¡è®¾å®šçš„è¾ƒå°ï¼ŒDenseBlockçš„è¾“å…¥ä¼šéå¸¸å¤šï¼Œä¸è¿‡è¿™æ˜¯ç”±äºç‰¹å¾é‡ç”¨æ‰€é€ æˆçš„ï¼Œæ¯ä¸ªå±‚ä»…æœ‰ä¸ªkç‰¹å¾æ˜¯è‡ªå·±ç‹¬æœ‰çš„ã€‚</p> 
<p><img src="https://images2.imgbox.com/02/bd/kcJABPFi_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾8 DenseBlockä¸­çš„éçº¿æ€§è½¬æ¢ç»“æ„ 
</center> 
<p>â€ƒâ€ƒç”±äºåé¢å±‚çš„è¾“å…¥ä¼šéå¸¸å¤§ï¼ŒDenseBlockå†…éƒ¨é‡‡ç”¨bottleneckå±‚æ¥å‡å°‘è®¡ç®—é‡ï¼Œä¸»è¦æ˜¯åŸæœ‰çš„ç»“æ„ä¸­å¢åŠ 1x1Convï¼Œå¦‚å›¾9æ‰€ç¤ºï¼Œå³<strong>BN+ReLU+1x1Conv+BN+ReLU+3x3Conv</strong>ï¼Œç§°ä¸ºDenseNet-Bç»“æ„ã€‚å…¶ä¸­1x1Convå¾—åˆ°4kä¸ªç‰¹å¾å›¾ï¼Œå®ƒèµ·åˆ°çš„ä½œç”¨æ˜¯é™ä½ç‰¹å¾æ•°é‡ï¼Œä»è€Œæå‡è®¡ç®—æ•ˆç‡ã€‚</p> 
<p><img src="https://images2.imgbox.com/fb/79/gP0n71z0_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾9 ä½¿ç”¨bottleneckå±‚çš„DenseBlockç»“æ„ 
</center> 
<p>â€ƒâ€ƒå¯¹äºTrasitionå±‚ï¼Œå®ƒä¸»è¦æ˜¯è¿æ¥ä¸¤ä¸ªç›¸é‚»çš„DenseBlockï¼Œå¹¶ä¸”é™ä½ç‰¹å¾å›¾å¤§å°ã€‚Transitionå±‚åŒ…æ‹¬ä¸€ä¸ª1x1çš„å·ç§¯å’Œ2x2çš„AvgPoolingï¼Œç»“æ„ä¸º<strong>BN+ReLU+1x1Conv+2x2AvgPooling</strong>ã€‚å¦å¤–ï¼ŒTransitionå±‚å¯ä»¥èµ·åˆ°å‹ç¼©æ¨¡å‹çš„ä½œç”¨ã€‚å‡å®šTransitionå±‚çš„ä¸Šæ¥DenseBlockå¾—åˆ°ç‰¹å¾å›¾channelsæ•°ä¸º<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         m 
        
       
      
        m 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">m</span></span></span></span></span>ï¼ŒTransitionå±‚å¯ä»¥äº§ç”Ÿä¸ª<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         âŒŠ 
        
        
        
          Î¸ 
         
        
          m 
         
        
       
         âŒ‹ 
        
       
      
        \lfloor\theta_m\rfloor 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">âŒŠ</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">Î¸</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">m</span></span></span></span><span class="vlist-s">â€‹</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">âŒ‹</span></span></span></span></span>ç‰¹å¾ï¼ˆé€šè¿‡å·ç§¯å±‚ï¼‰ï¼Œå…¶ä¸­<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Î¸ 
        
       
         âˆˆ 
        
       
         ( 
        
       
         0 
        
       
         , 
        
       
         1 
        
       
         ] 
        
       
      
        \theta\in(0,1] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7335em; vertical-align: -0.0391em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">Î¸</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">âˆˆ</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span></span>æ˜¯å‹ç¼©ç³»æ•°ï¼ˆcompression rateï¼‰ã€‚å½“<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Î¸ 
        
       
         &lt; 
        
       
         = 
        
       
         1 
        
       
      
        \theta&lt;=1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7335em; vertical-align: -0.0391em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">Î¸</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>æ—¶ï¼Œç‰¹å¾ä¸ªæ•°ç»è¿‡Transitionå±‚æ²¡æœ‰å˜åŒ–ï¼Œå³æ— å‹ç¼©ï¼Œè€Œå½“å‹ç¼©ç³»æ•°å°äº1æ—¶ï¼Œè¿™ç§ç»“æ„ç§°ä¸ºDenseNet-Cï¼Œæ–‡ä¸­ä½¿ç”¨<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Î¸ 
        
       
         = 
        
       
         0.5 
        
       
      
        \theta=0.5 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">Î¸</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.5</span></span></span></span></span>ã€‚å¯¹äºä½¿ç”¨bootleneckå±‚çš„DenseBlockç»“æ„å’Œå‹ç¼©ç³»æ•°å°äº1çš„Transitionç»„åˆæœºæ„ç§°ä¸ºDenseNet-BCã€‚</p> 
<p>â€ƒâ€ƒå¯¹äºImageNetæ•°æ®é›†ï¼Œå›¾ç‰‡è¾“å…¥å¤§å°ä¸º224x224ï¼Œç½‘ç»œç»“æ„é‡‡ç”¨åŒ…å«4ä¸ªDenseBlockçš„DenseNet-BCï¼Œå…¶é¦–å…ˆæ˜¯ä¸€ä¸ªstride=2çš„7x7å·ç§¯å±‚ï¼Œç„¶åæ˜¯ä¸€ä¸ªstride=2çš„3x3MaxPoolingå±‚ï¼Œåé¢æ‰è¿›å…¥DenseBlockã€‚ImageNetæ•°æ®é›†æ‰€é‡‡ç”¨çš„ç½‘ç»œé…ç½®å¦‚è¡¨1æ‰€ç¤ºï¼š</p> 
<p><img src="https://images2.imgbox.com/7f/1d/OByYfq87_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  è¡¨1 ImageNetæ•°æ®é›†ä¸Šæ‰€é‡‡ç”¨çš„DenseNetç»“æ„ 
</center> 
<h4><a id="414__2911"></a>4.1.4 æ•ˆæœå¯¹æ¯”</h4> 
<p><img src="https://images2.imgbox.com/3b/cf/yn9t8qdE_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾10 åœ¨CIFA-10æ•°æ®é›†ä¸ŠResNet vs DenseNet 
</center> 
<h4><a id="415_PytrochDenseNet121_2916"></a>4.1.5 ä½¿ç”¨Pytrochå®ç°DenseNet121</h4> 
<p><img src="https://images2.imgbox.com/60/1c/DjoRegDH_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<center>
  å›¾11 DenseNet121ç½‘ç»œæ¶æ„ 
</center> 
<p>â€ƒâ€ƒå›¾11ä¸ºDenseNet121çš„å…·ä½“ç½‘ç»œç»“æ„ï¼Œå®ƒä¸è¡¨1ä¸­çš„DenseNet121ç›¸å¯¹åº”ã€‚å·¦è¾¹æ˜¯æ•´ä¸ªDenseNet121çš„ç½‘ç»œç»“æ„ï¼Œå…¶ä¸­ç²‰è‰²ä¸ºDenseBlockï¼Œæœ€å³ä¾§ä¸ºå…¶è¯¦ç»†ç»“æ„ï¼Œç°è‰²ä¸ºTransitionï¼Œä¸­é—´ä¸ºå…¶è¯¦ç»†ç»“æ„ã€‚<br> â€ƒâ€ƒè¿™é‡Œæˆ‘ä»¬é‡‡ç”¨Pytorchæ¡†æ¶æ¥å®ç°DenseNetï¼Œé¦–å…ˆå®ç°DenseBlockä¸­çš„å†…éƒ¨ç»“æ„ï¼Œè¿™é‡Œæ˜¯<strong>BN+ReLU+1x1Conv+BN+ReLU+3x3Conv</strong>ç»“æ„ï¼Œæœ€åä¹ŸåŠ å…¥dropoutå±‚ä»¥ç”¨äºè®­ç»ƒè¿‡ç¨‹ã€‚<br> â€ƒâ€ƒé€‰æ‹©ä¸åŒç½‘ç»œå‚æ•°ï¼Œå°±å¯ä»¥å®ç°ä¸åŒæ·±åº¦çš„DenseNetã€‚</p> 
<p><strong>DenseNet121ç½‘ç»œç»“æ„å›¾</strong><br> <img src="https://images2.imgbox.com/b0/3b/WlUNzDlq_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="_2929"></a>æ€»ç»“</h2> 
<p>â€ƒâ€ƒé€šè¿‡æœ¬æ–‡çš„å­¦ä¹ ï¼Œåˆ†åˆ«é‡‡ç”¨pytorchå’Œtensorflowæ¡†æ¶å®ç°desennetç®—æ³•ï¼Œå‘ç°é‡‡ç”¨pytorchå¯ä»¥å®ç°å¾ˆé«˜çš„è¯†åˆ«ç‡ï¼Œè€Œtenserflowåªèƒ½è¾¾åˆ°50%å·¦å³ï¼Œç»è¿‡æŸ¥é˜…ç›¸å…³èµ„æ–™ï¼Œå‘ç°æœ‰å¯èƒ½æ˜¯tensorflowæ¡†æ¶ä¸­BatchNormalizationå±‚æœ‰é—®é¢˜ï¼Œæµ‹è¯•æ•°æ®é‡‡ç”¨è®­ç»ƒæ•°æ®ï¼Œå‘ç°åœ¨å±è”½BatchNormalizationå±‚åï¼Œæµ‹è¯•ç²¾åº¦ä¸è®­ç»ƒç²¾åº¦å·®ä¸å¤šï¼Œè€Œä¿ç•™BatchNormalizationå±‚ï¼Œæµ‹è¯•ç²¾åº¦å°±å¾ˆä½ï¼Œå¯ä»¥ç¡®å®šå°±æ˜¯BatchNormalizationçš„åŸå› ã€‚ä¹‹å‰å°±æœ‰çœ‹åˆ°tensorflow 2.3ç‰ˆæœ¬BNå±‚æœ‰é—®é¢˜ï¼Œè€Œtensorflow 1.xåˆ™æ­£å¸¸ã€‚å› æ­¤åœ¨éœ€è¦ä½¿ç”¨tensorflow æ­å»ºç½‘ç»œæ—¶ï¼Œå°½é‡é€‰æ‹©1.xç‰ˆæœ¬ï¼Œæœ¬äººæœªå¯¹è¯¥ç»“æœè¿›è¡ŒéªŒè¯ã€‚</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6f994613197e942a832e1cdd7dfb535a/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">å¤§åˆ›é¡¹ç›®æ¨è æ·±åº¦å­¦ä¹ å«æ˜Ÿé¥æ„Ÿå›¾åƒæ£€æµ‹ä¸è¯†åˆ« -opencv python ç›®æ ‡æ£€æµ‹</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a72a074588728e26a4334c2fa8e137ab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">yolov8äººè„¸è¯†åˆ«-è„¸éƒ¨å…³é”®ç‚¹æ£€æµ‹ï¼ˆä»£ç &#43;åŸç†ï¼‰</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 èœé¸Ÿç¨‹åºå‘˜åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>