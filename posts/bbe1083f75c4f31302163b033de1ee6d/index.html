<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>简单高效的模型小挂件——CBAM - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="简单高效的模型小挂件——CBAM" />
<meta property="og:description" content="论文传送门: CBAM: Convolutional Block Attention Module
代码(Pytorch): https://github.com/Jongchan/attention-module
Content Introduction
Convolutional Block Attention Module
Channel attention moduleSpatial attention moduleArrangement of attention modules Experiment
Image Classification on ImageNet-1KMS COCO and VOC 2007 Object Detection Conclusion
Introduction 卷积神经网络发展到现在, 各路大佬主要在网络的三个重要的维度发光发热——深度(depth), 宽度(width), 基数(cardinality*). VGG通过不断堆叠多个相同的模块获得深层网络; ResNet 巧妙地通过 residual blocks 和 skip connection 构造出更深的网络; 而 GoogLeNet 注意到了 width 这个重要的因素; Xception 和ResNext 则是不断增加网络的 cardinality. 后者不仅能减少参数, 还能拥有比前两者更好的表达能力. 这次作者则从另一个截然不同的角度 attention 提出了 CBAM 这个可以在模型中即插即用的小模块.
cardinality*: 这个概念在 ResNeXt 的论文中被提出, 定义为the size of the set of transformations, 在 ResNext 中指其 block 的分支数量." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/bbe1083f75c4f31302163b033de1ee6d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-01T09:48:28+08:00" />
<meta property="article:modified_time" content="2020-11-01T09:48:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">简单高效的模型小挂件——CBAM</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>论文传送门: <a href="https://arxiv.org/abs/1807.06521" rel="nofollow">CBAM: Convolutional Block Attention Module</a><br> 代码(Pytorch): <a href="https://github.com/Jongchan/attention-module">https://github.com/Jongchan/attention-module</a></p> 
<h3><a id="Content_3"></a>Content</h3> 
<p><a href="#introduction" rel="nofollow">Introduction</a><br> <a href="#cbam" rel="nofollow">Convolutional Block Attention Module</a></p> 
<ul><li><a href="#channel" rel="nofollow">Channel attention module</a></li><li><a href="#spatial" rel="nofollow">Spatial attention module</a></li><li><a href="#arrangement" rel="nofollow">Arrangement of attention modules</a></li></ul> 
<p><a href="#experiment" rel="nofollow">Experiment</a></p> 
<ul><li><a href="#class" rel="nofollow">Image Classification on ImageNet-1K</a></li><li><a href="#detection" rel="nofollow">MS COCO and VOC 2007 Object Detection</a></li></ul> 
<p><a href="#conclusion" rel="nofollow">Conclusion</a></p> 
<h3><a id="span_idintroductionIntroductionspan_17"></a><span id="introduction">Introduction</span></h3> 
<p>卷积神经网络发展到现在, 各路大佬主要在网络的三个重要的维度发光发热——深度(depth), 宽度(width), 基数(cardinality*). VGG通过不断堆叠多个相同的模块获得深层网络; ResNet 巧妙地通过 residual blocks 和 skip connection 构造出更深的网络; 而 GoogLeNet 注意到了 width 这个重要的因素; Xception 和ResNext 则是不断增加网络的 cardinality. 后者不仅能减少参数, 还能拥有比前两者更好的表达能力. 这次作者则从另一个截然不同的角度 attention 提出了 CBAM 这个可以在模型中即插即用的小模块.<br> <code>cardinality</code>*: 这个概念在 ResNeXt 的<a href="https://arxiv.org/abs/1611.05431" rel="nofollow">论文</a>中被提出, 定义为<code>the size of the set of transformations</code>, 在 ResNext 中指其 block 的分支数量.</p> 
<p><img src="https://images2.imgbox.com/19/fd/ffX66SvP_o.png" alt="在这里插入图片描述"></p> 
<p>这是一篇 ECCV2018 的的论文, CBAM 即是 Convolutional Block Attention Module, 分别通过 channel 和 spatial 两个轴增强特征图中的有用特征, 并且抑制无用特征, 从而告诉模型应该注意哪个区域. 人在第一眼接触图像时, 视觉系统并不会马上处理全局的信息, 而是会选择性地关注一些突出的局部信息. 比如一张小狗躺在草地上的照片, 人第一眼看去不会发现草地上哪根草是竖起来的, 哪根是弯下去的, 而是会选择性地先观察哪只小狗长什么样. 所以 attention 的设计合情合理.<br> 先前的 <a href="https://arxiv.org/abs/1704.06904" rel="nofollow">Residual Attention Network</a> 使用了 encoder-decoder 方式的 attention 模块重定义 feature map (就像食品再加工那样), 不但性能很好, 还有不错的鲁棒性. 而 CBAM 则是通过从 channel 和 spatial 两个维度分解上面的过程得到的, 且能做到在其他网络中即插即用.</p> 
<h3><a id="span_idcbamConvolutional_Block_Attention_Modulespan_28"></a><span id="cbam">Convolutional Block Attention Module</span></h3> 
<p>先设 feature map 为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         F 
        
       
         ϵ 
        
        
        
          R 
         
         
         
           C 
          
         
           ∗ 
          
         
           H 
          
         
           ∗ 
          
         
           W 
          
         
        
       
      
        F \epsilon R^{C *H*W} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.841331em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="mord mathdefault">ϵ</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">C</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.08125em;">H</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">W</span></span></span></span></span></span></span></span></span></span></span></span></span> , CBAM依次推断出一个一维 attention map: <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          M 
         
        
          c 
         
        
       
         ϵ 
        
        
        
          R 
         
         
         
           C 
          
         
           ∗ 
          
         
           1 
          
         
           ∗ 
          
         
           1 
          
         
        
       
      
        M_c \epsilon R^{C*1*1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.991331em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.10903em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathdefault">ϵ</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">C</span><span class="mbin mtight">∗</span><span class="mord mtight">1</span><span class="mbin mtight">∗</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span> 和一个二维的 spatial map: <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          M 
         
        
          c 
         
        
       
         ϵ 
        
        
        
          R 
         
         
         
           1 
          
         
           ∗ 
          
         
           H 
          
         
           ∗ 
          
         
           W 
          
         
        
       
      
        M_c \epsilon R^{1*H*W} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.991331em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: -0.10903em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathdefault">ϵ</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.08125em;">H</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">W</span></span></span></span></span></span></span></span></span></span></span></span></span>, 整体的数学公式为:<br> <img src="https://images2.imgbox.com/44/fc/cAGP7VR0_o.png" alt="在这里插入图片描述"></p> 
<p>两条公式分别是 channel attention 和 spatial attention 操作. 其中 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ⨂ 
        
       
      
        \bigotimes 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.00001em; vertical-align: -0.25001em;"></span><span class="mop op-symbol small-op" style="position: relative; top: -5e-06em;">⨂</span></span></span></span></span> 表示 element-wise multiplication , 即对应元素相乘. 这个也很好理解, 重要的区域给他乘一个大一点的数, 不重要的就乘一个小一点的数. <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         F 
        
       
      
        F 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span></span></span></span></span> 经过重定义后得到 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           ′ 
          
         
           ′ 
          
         
        
       
      
        F'' 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.751892em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.751892em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span><span class="mord mtight">′</span></span></span></span></span></span></span></span></span></span></span></span></span>. 接下来分开看下 channel 和 spatial 两个维度的具体操作.</p> 
<p><img src="https://images2.imgbox.com/31/52/WE8o3EkA_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="span_idchannelChannel_attention_modulespan_36"></a><span id="channel">Channel attention module</span></h4> 
<p>channel attention 主要关注输入特征图中 ‘what’ is meaningful , 并且计算其各个 channel 之间的内在关系. 为了集成每个channel 上的空间信息, 对 input feature <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         F 
        
       
      
        F 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span></span></span></span></span> 使用了常规的 average-pooling 并得到 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           a 
          
         
           v 
          
         
           g 
          
         
        
          c 
         
        
       
      
        F^c_{avg} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06644em; vertical-align: -0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">g</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span></span></span></span></span>; 同时为了获得 object 更精细的特征而使用常规 max-pooling 并得到 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           m 
          
         
           a 
          
         
           x 
          
         
        
          c 
         
        
       
      
        F^c_{max} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.93033em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span>. 如上图, 接着将 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           a 
          
         
           v 
          
         
           g 
          
         
        
          c 
         
        
       
      
        F^c_{avg} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06644em; vertical-align: -0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">g</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           m 
          
         
           a 
          
         
           x 
          
         
        
          c 
         
        
       
      
        F^c_{max} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.93033em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 接入一个 shared network 中, 由只有一层隐藏层的多层感知机(MLP)构成. 为减少参数, 将 Shared MLP 的中间那层的大小设为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
         
         
           C 
          
         
           / 
          
         
           r 
          
         
           ∗ 
          
         
           1 
          
         
           ∗ 
          
         
           1 
          
         
        
       
      
        R^{C/r*1*1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.888em; vertical-align: 0em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.888em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">C</span><span class="mord mtight">/</span><span class="mord mathdefault mtight" style="margin-right: 0.02778em;">r</span><span class="mbin mtight">∗</span><span class="mord mtight">1</span><span class="mbin mtight">∗</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span></span> (r 是一个衰减比率). 然后将经过 Shared MLP 后的 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         n 
        
       
         e 
        
       
         w 
        
       
         _ 
        
        
        
          F 
         
         
         
           a 
          
         
           v 
          
         
           g 
          
         
        
          c 
         
        
       
      
        new\_F^c_{avg} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06644em; vertical-align: -0.383108em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="mord" style="margin-right: 0.02778em;">_</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">g</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         n 
        
       
         e 
        
       
         w 
        
       
         _ 
        
        
        
          F 
         
         
         
           m 
          
         
           a 
          
         
           x 
          
         
        
          c 
         
        
       
      
        new\_F^c_{max} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.99333em; vertical-align: -0.31em;"></span><span class="mord mathdefault">n</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right: 0.02691em;">w</span><span class="mord" style="margin-right: 0.02778em;">_</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 进行 element-wise summation (对应元素相加)得到 Channel Attention. channel attention map 表示的其实是特征图的各个 channel 之间的内在关系, 即哪些 channel 是值得关注的, 哪些 channel 是应该忽略的. 整个流程用公式表示为:<br> <img src="https://images2.imgbox.com/60/32/UTDJ8oju_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="span_idspatialSpatial_attention_modulespan_39"></a><span id="spatial">Spatial attention module</span></h4> 
<p>spatial attention 探讨的则是在空间层面 feature map 的内在关系, 即哪些区域是重要的, 哪些是不重要的, 算是 channel attention 的互补方法. 算法上要更简单些, 为了得到 feature map 的通道信息, 先同时沿着 channel axis 对其进行 average-pooling 和 max-pooling 操作分别得到 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           a 
          
         
           v 
          
         
           g 
          
         
        
          s 
         
        
       
         ϵ 
        
        
        
          R 
         
         
         
           1 
          
         
           ∗ 
          
         
           H 
          
         
           ∗ 
          
         
           W 
          
         
        
       
      
        F^s_{avg} \epsilon R^{1*H*W} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.22444em; vertical-align: -0.383108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">g</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.383108em;"><span class=""></span></span></span></span></span></span><span class="mord mathdefault">ϵ</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.08125em;">H</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">W</span></span></span></span></span></span></span></span></span></span></span></span></span> 和 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
         
         
           m 
          
         
           a 
          
         
           x 
          
         
        
          s 
         
        
       
         ϵ 
        
        
        
          R 
         
         
         
           1 
          
         
           ∗ 
          
         
           H 
          
         
           ∗ 
          
         
           W 
          
         
        
       
      
        F^s_{max} \epsilon R^{1*H*W} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.08833em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -2.453em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">m</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">x</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">s</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mord mathdefault">ϵ</span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.841331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.08125em;">H</span><span class="mbin mtight">∗</span><span class="mord mathdefault mtight" style="margin-right: 0.13889em;">W</span></span></span></span></span></span></span></span></span></span></span></span></span>, 然后将二者 concatenate, 接着经过一个标准卷积层就得到了, spatial attention map. 公式表示为:<br> <img src="https://images2.imgbox.com/bb/f3/keOhDusk_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="span_idarrangementArrangement_of_attention_modulesspan_42"></a><span id="arrangement">Arrangement of attention modules</span></h4> 
<p>经实验, 作者发现将 channel attention 和 spatial attention 级联的性能会比并行的好, 且在级联时把 channel attention 放在前面效果会更好.<br> <img src="https://images2.imgbox.com/04/27/k81ncXmm_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="span_idexperimentExperimentspan_46"></a><span id="experiment">Experiment</span></h3> 
<p>作者选择在 ImageNet-1K 上验证分类性能, 在 MS COCO 和 VOC 2007 上验证检测性能.</p> 
<h4><a id="span_idclassImage_Classification_on_ImageNet1Kspanhttpsimgblogcsdnimgcn20201101085758746pngxossprocessimagewatermarktype_ZmFuZ3poZW5naGVpdGkshadow_10text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NTYxMjc2Mwsize_16color_FFFFFFt_70pic_center_48"></a><span id="class">Image Classification on ImageNet-1K</span><img src="https://images2.imgbox.com/90/4b/QaVvVzVX_o.png" alt="在这里插入图片描述"></h4> 
<p><img src="https://images2.imgbox.com/f6/ad/plhjq5HI_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3d/44/jDVrYLBw_o.png" alt="在这里插入图片描述"><br> 这几个实验都验证了上面算法设计思路的正确性.<br> <img src="https://images2.imgbox.com/87/a6/ey0Nxsdh_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0c/3f/164TKnKv_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="span_iddetectionMS_COCO_and_VOC_2007_Object_Detectionspan_54"></a><span id="detection">MS COCO and VOC 2007 Object Detection</span></h4> 
<p><img src="https://images2.imgbox.com/71/5c/UOs4gcuT_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="span_idconclusionConclusionspan_56"></a><span id="conclusion">Conclusion</span></h3> 
<p>从人眼视觉的注意力机制出发, 作者设计了一个 convolutional bottleneck attention module (CBAM) 对特征进行增强或者抑制, 提高了模型的特征表达能力 . CBAM 由 channel attention module 和 spatial attention module 级联构成, 在提升模型性能的同时还保持了较小的开销.</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/004924f7a5f85bff4bdcfe7e43549aee/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">光谱测量数据处理（matlab）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1af151387a40553ed086d7792102d938/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python是什么怎么用-什么是python items函数？怎么使用它？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>