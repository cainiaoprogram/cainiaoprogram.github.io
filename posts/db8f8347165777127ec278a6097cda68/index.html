<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python爬虫】基于selenium库爬取京东商品数据——以“七夕”为例 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python爬虫】基于selenium库爬取京东商品数据——以“七夕”为例" />
<meta property="og:description" content="小白学爬虫，费了一番功夫终于成功了哈哈！本文将结合本人踩雷经历，分享给各位学友~
一、导包 import time import csv from selenium import webdriver 二、创建csv文件 用写入方式打开名为data的csv文件，并确定将要提取的五项数据。
f = open(&#39;data.csv&#39;,mode = &#39;w&#39;,encoding =&#39;utf-8&#39;,newline = &#39;&#39;) #将表头信息写入文件 csv_writer = csv.DictWriter(f,fieldnames = [&#39;标题&#39;,&#39;价格&#39;,&#39;评论&#39;,&#39;店名&#39;,&#39;详情页&#39;]) csv_writer.writeheader() 三、搜索商品页并加载数据 #实例化浏览器对象 driver = webdriver.Edge(&#39;C:\Windows\SystemApps\Microsoft.MicrosoftEdge_8wekyb3d8bbwe\msedgedriver.exe&#39;) #访问京东网址 driver.get(&#39;https://www.jd.com/&#39;) #定位搜索框，并输入查找内容‘七夕’ driver.find_element_by_id(&#39;key&#39;).send_keys(&#39;七夕&#39;) #点击搜索按钮 driver.find_element_by_class_name(&#39;button&#39;).click() #等待界面数据加载 driver.implicitly_wait(10) #有些网页是鼠标一边下移一边加载，该函数使页面数据全部加载 def drop_down(): for x in range(1,12,2): time.sleep(1) j = x / 9 # document.documetnElement,scrollTop 指定滚动条的位置 # document.documentElement.scrollHeight 获取浏览器页面的最大高度 js = &#39;document.documentElement.scrollTop = document.documentElement.scrollHeight * %f&#39; % j driver.execute_script(js) 上面第一行代码值得一提，driver = webdriver." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/db8f8347165777127ec278a6097cda68/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-22T01:22:47+08:00" />
<meta property="article:modified_time" content="2023-08-22T01:22:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python爬虫】基于selenium库爬取京东商品数据——以“七夕”为例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>小白学爬虫，费了一番功夫终于成功了哈哈！本文将结合本人踩雷经历，分享给各位学友~</p> 
<h2>一、导包</h2> 
<pre><code class="language-python">import time
import csv
from selenium import webdriver</code></pre> 
<h2>二、创建csv文件</h2> 
<p>用写入方式打开名为data的csv文件，并确定将要提取的五项数据。</p> 
<pre><code class="language-python">f = open('data.csv',mode = 'w',encoding ='utf-8',newline = '')
#将表头信息写入文件
csv_writer = csv.DictWriter(f,fieldnames = ['标题','价格','评论','店名','详情页'])
csv_writer.writeheader()</code></pre> 
<h2>三、搜索商品页并加载数据</h2> 
<pre><code class="language-python">#实例化浏览器对象
driver = webdriver.Edge('C:\Windows\SystemApps\Microsoft.MicrosoftEdge_8wekyb3d8bbwe\msedgedriver.exe')
#访问京东网址
driver.get('https://www.jd.com/')
#定位搜索框，并输入查找内容‘七夕’
driver.find_element_by_id('key').send_keys('七夕')
#点击搜索按钮
driver.find_element_by_class_name('button').click()
#等待界面数据加载
driver.implicitly_wait(10)

#有些网页是鼠标一边下移一边加载，该函数使页面数据全部加载
def drop_down():
    for x in range(1,12,2):
        time.sleep(1)
        j = x / 9
        # document.documetnElement,scrollTop 指定滚动条的位置
        # document.documentElement.scrollHeight 获取浏览器页面的最大高度
        js = 'document.documentElement.scrollTop = document.documentElement.scrollHeight * %f' % j
        driver.execute_script(js)</code></pre> 
<p>上面第一行代码值得一提，driver =  webdriver.Edge()括号内为Edge浏览器驱动程序地址，需要在Edge浏览器设置中查找Edge浏览器版本，并下载对应版本的驱动程序，具体操作如下：</p> 
<h3>1.在设置中找到Edge浏览器对应版本</h3> 
<p><img alt="" height="768" src="https://images2.imgbox.com/6f/07/96HK2xHh_o.png" width="1200"></p> 
<h3>2.下载驱动程序</h3> 
<h4>驱动路径来源（读者需自行替换）：</h4> 
<p><span style="color:#ed7976;">Step1</span>：根据官网提供网址 <a href="https://developer.microsoft.com/en-us/microsoft-edge/tools/webdriver/" rel="nofollow" title="Microsoft Edge WebDriver - Microsoft Edge Developer">Microsoft Edge WebDriver - Microsoft Edge Developer</a></p> 
<p>找到和自己Edge浏览器版本一致的驱动程序。这里等待时间稍微有点长，请耐心等待。</p> 
<p><span style="color:#ed7976;">Step2</span>：将安装包解压到<span style="color:#b95514;">不包含中文</span>的路径下，获得msedgedriver.exe文件</p> 
<p><span style="color:#ed7976;">Step3：</span>将完整路径填入到<span style="color:#b95514;">driver = webdriver.Edge()</span>括号内，注意路径需包含\msedgedriver.exe</p> 
<p></p> 
<p>第三行代码定位搜索框的流程也介绍一下：</p> 
<p>首先，打开京东，在空白处右击，单击“检查”，弹出框图如下</p> 
<p><img alt="" height="768" src="https://images2.imgbox.com/30/e6/7m9Mb3q9_o.png" width="1200"></p> 
<p> 单击弹出框框左上角的标识，并将鼠标放在搜索框中，再单击一下固定位置，找到对应代码。</p> 
<p><img alt="" height="768" src="https://images2.imgbox.com/9c/f5/Vnuq7cPs_o.png" width="1200"></p> 
<p> 找到其中的id为‘key’，可根据该项特征定位搜索框。第四行代码定位搜索按钮采取相同方式定位，不同的是搜索按钮根据类名定位，找到class = “……”中的内容即可。</p> 
<p> </p> 
<h3>四、获取多页数据并逐行写入csv文件</h3> 
<pre><code class="language-python">#提取第1~7页的内容
for page in range(1,7):
    #调用函数
    drop_down()
    #获取所有商品对应标签（列表），注意此处是elements而不是element
    lis = driver.find_elements_by_css_selector('.gl-item')
    #print(lis)
    #将列表元素一个个拿出来
    for li in lis:
        title = li.find_element_by_css_selector('.p-name em').text.replace('\n','')
        price = li.find_element_by_css_selector('.p-price strong i').text
        comment = li.find_element_by_css_selector('.p-commit strong').text
        shop = li.find_element_by_css_selector('.p-shop span a').text
        link = li.find_element_by_css_selector('.p-img a').get_attribute('href')
            
        dit = {
               '标题':title,
               '价格':price,
               '评论':comment,
               '店名':shop,
               '详情页':link
              }
        #写入csv
        csv_writer.writerow(dit)
        #及时刷新缓冲区
        f.flush()
        print(dit)
    #点击下一页按钮    
    driver.find_element_by_class_name('pn-next').click()</code></pre> 
<p>发现出现了find_element_by_css_selector('……')，那省略号的内容又该在哪儿找呢？我们以代码lis = driver.find_elements_by_css_selector('.gl-item')为例说明一下。</p> 
<p>在首页搜索“七夕”，得到商品页。</p> 
<p><img alt="" height="768" src="https://images2.imgbox.com/a6/d5/w9IJ21eD_o.png" width="1200"></p> 
<p>同样右击，单击“检查”，单击弹出框左上角标识，把鼠标移动到商品上（要全部框选），单击一下固定代码位置 ，再查看右侧框中选项。</p> 
<p><img alt="" height="768" src="https://images2.imgbox.com/02/7e/J6wnjtLa_o.png" width="1200"></p> 
<p> 虽然含有 .goods-list-v2 和 .gl-item 两项，然而，.gl-item足以标记所有商品，故省略号仅填.gl-item即可。</p> 
<h3>五、代码汇总</h3> 
<pre><code class="language-python">import time
import csv
from selenium import webdriver


f = open('data.csv',mode = 'w',encoding ='utf-8',newline = '')
#将表头信息写入文件
csv_writer = csv.DictWriter(f,fieldnames = ['标题','价格','评论','店名','详情页'])
csv_writer.writeheader()

#实例化浏览器对象（第一句需要修改，具体方法见上文）
driver = webdriver.Edge('C:\Windows\SystemApps\Microsoft.MicrosoftEdge_8wekyb3d8bbwe\msedgedriver.exe')
#访问京东网址
driver.get('https://www.jd.com/')
#定位搜索框，并输入查找内容‘七夕’
driver.find_element_by_id('key').send_keys('七夕')
#点击搜索按钮
driver.find_element_by_class_name('button').click()
#等待界面数据加载
driver.implicitly_wait(10)

#有些网页是鼠标一边下移一边加载，该函数使页面数据全部加载
def drop_down():
    for x in range(1,12,2):
        time.sleep(1)
        j = x / 9
        # document.documetnElement,scrollTop 指定滚动条的位置
        # document.documentElement.scrollHeight 获取浏览器页面的最大高度
        js = 'document.documentElement.scrollTop = document.documentElement.scrollHeight * %f' % j
        driver.execute_script(js)

#提取第1~7页的内容
for page in range(1,7):
    #调用函数
    drop_down()
    #获取所有商品对应标签（列表），注意此处是elements而不是element
    lis = driver.find_elements_by_css_selector('.gl-item')
    #print(lis)
    #将列表元素一个个拿出来
    for li in lis:
        title = li.find_element_by_css_selector('.p-name em').text.replace('\n','')
        price = li.find_element_by_css_selector('.p-price strong i').text
        comment = li.find_element_by_css_selector('.p-commit strong').text
        shop = li.find_element_by_css_selector('.p-shop span a').text
        link = li.find_element_by_css_selector('.p-img a').get_attribute('href')
            
        dit = {
               '标题':title,
               '价格':price,
               '评论':comment,
               '店名':shop,
               '详情页':link
              }
        #写入csv
        csv_writer.writerow(dit)
        #及时刷新缓冲区
        f.flush()
        print(dit)
    #点击下一页按钮    
    driver.find_element_by_class_name('pn-next').click()</code></pre> 
<p> 感谢读者大大读到此处~学习辛苦啦！</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5440483c267ec26acc0427251d30e933/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深入理解ForkJoin</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/67d68ae6e4e582b11c7a17faa6e8880d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何选择导入默认导出还是命名导出？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>