<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CycleGAN-两个领域非匹配图像的相互转换 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CycleGAN-两个领域非匹配图像的相互转换" />
<meta property="og:description" content="1. CycleGAN的简介 pix2pix可以很好地处理匹配数据集图像转换，但是在很多情况下匹配数据集是没有的或者是很难收集到的，但是我们可以很容易的得到两个领域大量的非匹配数据。2017年有两篇非常相似的论文CycleGAN和DiscoGAN，提出了一种解决非匹配数据集的图像转换方案。而且CycleGAN在转换的过程中，只是将A领域图像的某些特性转换成B领域的一些特性，图像的其余大部分内容都没有改变。CycleGAN 能实现两个相近数据集之间的转换。
2. CycleGAN的网络结构 CycleGAN网络结构的拆分
该结构中，生成器相当于一个自编码网络，前半部分进行编码，后半部分进行解码，而且生成器G和生成器F的结构完全相同，其中生成器G负责实现由X到Y的转换，生成器F负责实现由Y到X的转换，它们的输入、输出的大小均为（batch_size, n_channel, cols, rows），判别器的输入为（batch_size, n_channel, cols, rows）, 判别器的输出为（batch_size, 1, s1, s2）。
3. CycleGAN的损失函数 （1）对抗损失
对抗损失的作用是，使生成的目标领域的图像和目标领域的真实图像尽可能地接近。
（2）循环损失
循环损失的作用是，使生成的图像尽可能多的保留原始图像的内容。
在网络训练的过程中是将G和F联合起来一起训练的，Dx和Dy是单独进行训练的。
G-F联合网络的损失函数为：
fake_B = G_AB(real_A)
loss_GAN_AB = torch.nn.MSELoss(D_B(fake_B), valid)
fake_A = G_BA(real_B)
loss_GAN_BA = torch.nn.MSELoss(D_A(fake_A), valid)
loss_G_GAN = (loss_GAN_AB &#43; loss_GAN_BA) / 2 # 生成器的对抗损失
recov_A = G_BA(fake_B)
loss_cycle_A = torch.nn.L1Loss(recov_A, real_A)
recov_cycle_B = G_AB(fake_A)
loss_cycle_B = torch.nn.L1Loss(recov_B, real_B)
loss_cycle = (loss_cycle_A &#43; loss_cycle_B) / 2 # 生成器的循环损失" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/162636d35beda0f59602a857650ef266/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-23T16:54:47+08:00" />
<meta property="article:modified_time" content="2023-12-23T16:54:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CycleGAN-两个领域非匹配图像的相互转换</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1. CycleGAN的简介</h2> 
<p>        pix2pix可以很好地处理匹配数据集图像转换，但是在很多情况下匹配数据集是没有的或者是很难收集到的，但是我们可以很容易的得到两个领域大量的非匹配数据。2017年有两篇非常相似的论文CycleGAN和DiscoGAN，提出了一种解决非匹配数据集的图像转换方案。而且CycleGAN在转换的过程中，只是将A领域图像的某些特性转换成B领域的一些特性，图像的其余大部分内容都没有改变。CycleGAN 能实现两个相近数据集之间的转换。</p> 
<p></p> 
<h2>2. CycleGAN的网络结构</h2> 
<p class="img-center"><img alt="" height="468" src="https://images2.imgbox.com/df/d0/Nw84bgjP_o.png" width="553"></p> 
<p style="text-align:center;">CycleGAN网络结构的拆分</p> 
<p>        该结构中，生成器相当于一个自编码网络，前半部分进行编码，后半部分进行解码，而且生成器G和生成器F的结构完全相同，其中生成器G负责实现由X到Y的转换，生成器F负责实现由Y到X的转换，它们的输入、输出的大小均为（batch_size, n_channel, cols, rows），判别器的输入为（batch_size, n_channel, cols, rows）, 判别器的输出为（batch_size, 1, s1, s2）。</p> 
<p></p> 
<h2>3. CycleGAN的损失函数</h2> 
<p><strong>（1）对抗损失</strong></p> 
<p><img alt="" height="110" src="https://images2.imgbox.com/5f/88/azeWtmbL_o.png" width="712"></p> 
<p>对抗损失的作用是，使生成的目标领域的图像和目标领域的真实图像尽可能地接近。</p> 
<p><strong>（2）循环损失</strong></p> 
<p><img alt="" height="56" src="https://images2.imgbox.com/60/7b/g7m8RAoo_o.png" width="675"></p> 
<p>循环损失的作用是，使生成的图像尽可能多的保留原始图像的内容。</p> 
<p><strong>在网络训练的过程中是将G和F联合起来一起训练的，Dx</strong><strong>和Dy</strong><strong>是单独进行训练的。</strong></p> 
<p>G-F联合网络的损失函数为：</p> 
<p><img alt="" height="36" src="https://images2.imgbox.com/f4/47/OxEDhXSK_o.png" width="639"></p> 
<blockquote> 
 <p>fake_B = G_AB(real_A)</p> 
 <p>loss_GAN_AB = torch.nn.MSELoss(D_B(fake_B), valid)</p> 
 <p>fake_A = G_BA(real_B)</p> 
 <p>loss_GAN_BA = torch.nn.MSELoss(D_A(fake_A), valid)</p> 
 <p>loss_G_GAN = (loss_GAN_AB + loss_GAN_BA) / 2      #  生成器的对抗损失</p> 
 <p>recov_A = G_BA(fake_B)</p> 
 <p>loss_cycle_A = torch.nn.L1Loss(recov_A, real_A)</p> 
 <p>recov_cycle_B = G_AB(fake_A)</p> 
 <p>loss_cycle_B = torch.nn.L1Loss(recov_B, real_B)</p> 
 <p>loss_cycle = (loss_cycle_A + loss_cycle_B) / 2          #  生成器的循环损失</p> 
 <p>Loss_G = loss_G_GAN + lambda_cycle * loss_cycle</p> 
</blockquote> 
<p><img alt="" height="50" src="https://images2.imgbox.com/93/a2/OjUWwxG7_o.png" width="454"></p> 
<blockquote> 
 <p>loss_real = torch.nn.MSELoss(D_A(real_A), valid)</p> 
 <p>fake_A = fake_A_buffer.push_and_pop(fake_A)</p> 
 <p>loss_fake = torch.nn.MSELoss(D_A(fake_A.detach()), fake)</p> 
 <p>loss_D_A = (loss_real + loss_fake) / 2</p> 
</blockquote> 
<p><img alt="" height="46" src="https://images2.imgbox.com/6b/b5/f0YFynQG_o.png" width="445"></p> 
<blockquote> 
 <p>loss_real = torch.nn.MSELoss(D_B(real_B), valid)</p> 
 <p>fake_B = fake_B_buffer.push_and_pop(fake_B)</p> 
 <p>loss_fake = torch.nn.MSELoss(D_B(fake_B.detach(), fake)</p> 
 <p>loss_D_B = (loss_real + loss_fake) / 2</p> 
</blockquote> 
<p>引自：</p> 
<p><a class="has-card" href="https://www.jianshu.com/p/40ddf1d9c8ef" rel="nofollow" title="CycleGAN-两个领域非匹配图像的相互转换 - 简书"><span class="link-card-box"><span class="link-title">CycleGAN-两个领域非匹配图像的相互转换 - 简书</span><span class="link-desc">1. CycleGAN的简介 pix2pix可以很好地处理匹配数据集图像转换，但是在很多情况下匹配数据集是没有的或者是很难收集到的，但是我们可以很容易的得到两个领域大...</span><span class="link-link"><img class="link-link-icon" src="https://images2.imgbox.com/fb/da/OW5003da_o.png" alt="icon-default.png?t=N7T8">https://www.jianshu.com/p/40ddf1d9c8ef</span></span></a> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/820475234838e565a5a2af54c934d497/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Spring security之授权</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/23a8e0a9a013a610431efaea65442234/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">openai最新探索：超级对齐是否可行？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>