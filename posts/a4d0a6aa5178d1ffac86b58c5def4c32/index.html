<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Deep Learning Object Detection - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Deep Learning Object Detection" />
<meta property="og:description" content="1 图像分类和目标识别的区别
分类（左）和目标检测（右）之间的差异是直观和直接的。对于图像分类，将整个图像分类为单个标签。在对象检测的情况下，我们的神经网络定位图像中的（潜在多个）对象。
因此，我们可以认为图像分类为：
一个图像 一类标签（整幅图像）
对象检测：不管是否通过深度学习或其他计算机视觉技术来执行，都建立在图像分类上，并试图精确地定位图像中每个对象出现的位置。
当执行对象检测时，给定输入图像，我们希望获得：
1.一个包围盒的列表，或图像中每个对象的（x，y）坐标
2.与每个边界框关联的类标签
3.与每个边界框和类标签相关联的概率/置信分数
方法一：传统的目标检测流程
该方法不完全是端对端的深度学习目标检测
1.固定大小的滑动窗口，从左到右，从上到下滑动以定位不同位置的对象。
2.在不同尺度下检测物体的图像金字塔
3.基于预训练（分类）卷积神经网络的分类
在每一步的滑动窗口&#43;图像金字塔，都需要提取ROI，将它输入到CNN，输出为ROI的分类。
如果标签L的分类概率高于某个阈值T，则将ROI的包围盒标记为标签（L）。每一个滑动窗口和图像金字塔都重复这个过程，我们得到输出对象检测器。最后，我们将非极大值抑制应用于产生最终输出检测的边界框：
一般这样的方法慢且容易出错。然而，值得学习的是如何应用这种方法，因为它可以将任意的图像分类网络转换成对象检测器，避免了需要明确地训练端到端的深度学习对象检测器。
方法2：
对象检测框架的基本网络
深度学习对象检测的第二种方法在深度学习对象检测框架（faster-RCNN、SSD或YOLO）中处理预先训练的分类网络作为基础网络。
好处是可以创建一个完整的端到端的基于深度学习的对象检测器。
缺点是它需要对学习对象探测器的工作有多深的了解——我们将在下一节中对此进行更多的讨论。
深度学习对象检测器的组件
未完待续..." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a4d0a6aa5178d1ffac86b58c5def4c32/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-08-01T19:52:02+08:00" />
<meta property="article:modified_time" content="2018-08-01T19:52:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Deep Learning Object Detection</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>1 图像分类和目标识别的区别</p> 
<p><img alt="" class="has" height="303" src="https://images2.imgbox.com/04/2f/lm45UJsz_o.png" width="453"></p> 
<p>       分类（左）和目标检测（右）之间的差异是直观和直接的。对于图像分类，将整个图像分类为单个标签。在对象检测的情况下，我们的神经网络定位图像中的（潜在多个）对象。</p> 
<p>因此，我们可以认为图像分类为：</p> 
<p>一个图像   一类标签（整幅图像）</p> 
<p>对象检测：不管是否通过深度学习或其他计算机视觉技术来执行，都建立在图像分类上，并试图精确地定位图像中每个对象出现的位置。</p> 
<p>当执行对象检测时，给定输入图像，我们希望获得：</p> 
<p>         1.一个包围盒的列表，或图像中每个对象的（x，y）坐标<br>          2.与每个边界框关联的类标签<br>          3.与每个边界框和类标签相关联的概率/置信分数</p> 
<p>方法一：传统的目标检测流程</p> 
<p>该方法不完全是端对端的深度学习目标检测</p> 
<p>      1.固定大小的滑动窗口，从左到右，从上到下滑动以定位不同位置的对象。<br>       2.在不同尺度下检测物体的图像金字塔<br>       3.基于预训练（分类）卷积神经网络的分类<br> 在每一步的滑动窗口+图像金字塔，都需要提取ROI，将它输入到CNN，输出为ROI的分类。<br>        如果标签L的分类概率高于某个阈值T，则将ROI的包围盒标记为标签（L）。每一个滑动窗口和图像金字塔都重复这个过程，我们得到输出对象检测器。最后，我们将<strong>非极大值抑制</strong>应用于产生最终输出检测的边界框：</p> 
<p><img alt="" class="has" height="313" src="https://images2.imgbox.com/11/51/c9tdzogQ_o.png" width="520"></p> 
<p>        一般这样的方法慢且容易出错。然而，值得学习的是如何应用这种方法，因为它可以将任意的图像分类网络转换成对象检测器，避免了需要明确地训练端到端的深度学习对象检测器。</p> 
<p>方法2：</p> 
<p>对象检测框架的基本网络<br>     深度学习对象检测的第二种方法在深度学习对象检测框架（faster-RCNN、SSD或YOLO）中处理预先训练的分类网络作为基础网络。<br>     好处是可以创建一个完整的端到端的基于深度学习的对象检测器。<br>     缺点是它需要对学习对象探测器的工作有多深的了解——我们将在下一节中对此进行更多的讨论。<br> 深度学习对象检测器的组件</p> 
<p><img alt="" class="has" height="292" src="https://images2.imgbox.com/42/d5/8NwfYTvH_o.png" width="612"></p> 
<p>未完待续...</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5fa70a81db42cfe52dce06507d262be6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">傻瓜都能看懂的高并发量服务器架构</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/625f884107e5c2589045d32a5ff3e07f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Fullnat的环境搭建和负载均衡配置</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>