<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习 Day24——J3-1DenseNet算法实战与解析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习 Day24——J3-1DenseNet算法实战与解析" />
<meta property="og:description" content="🍨 本文为🔗365天深度学习训练营 中的学习记录博客🍖 原作者：K同学啊 | 接辅导、项目定制🚀 文章来源：K同学的学习圈子 文章目录 前言1 我的环境2 pytorch实现DenseNet算法2.1 前期准备2.1.1 引入库2.1.2 设置GPU（如果设备上支持GPU就使用GPU,否则使用CPU）2.1.3 导入数据2.1.4 可视化数据2.1.4 图像数据变换2.1.4 划分数据集2.1.4 加载数据2.1.4 查看数据 2.2 搭建densenet121模型2.3 训练模型2.3.1 设置超参数2.3.2 编写训练函数2.3.3 编写测试函数2.3.4 正式训练 2.4 结果可视化2.4 指定图片进行预测2.6 模型评估 3 知识点详解3.1 nn.Sequential和nn.Module区别与选择3.1.1 nn.Sequential3.1.2 nn.Module3.1.3 对比3.1.4 总结 3.2 python中OrderedDict的使用 总结 前言 关键字： pytorch实现DenseNet算法，nn.Sequential和nn.Module区别与选择，python中OrderedDict的使用
1 我的环境 电脑系统：Windows 11语言环境：python 3.8.6编译器：pycharm2020.2.3深度学习环境：
torch == 1.9.1&#43;cu111
torchvision == 0.10.1&#43;cu111
TensorFlow 2.10.1显卡：NVIDIA GeForce RTX 4070 2 pytorch实现DenseNet算法 2.1 前期准备 2.1.1 引入库 import torch import torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9ab461a0f3d8c2b5e11d612e5508617b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-05T00:49:16+08:00" />
<meta property="article:modified_time" content="2024-01-05T00:49:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习 Day24——J3-1DenseNet算法实战与解析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <ul><li><strong>🍨 本文为<a href="https://mp.weixin.qq.com/s/AtyZUu_j2k_ScNH6e732ow" rel="nofollow">🔗365天深度学习训练营</a> 中的学习记录博客</strong></li><li><strong>🍖 原作者：<a href="https://mtyjkh.blog.csdn.net/" rel="nofollow">K同学啊 | 接辅导、项目定制</a></strong></li><li><strong>🚀 文章来源：<a href="https://www.yuque.com/mingtian-fkmxf/zxwb45" rel="nofollow">K同学的学习圈子</a></strong></li></ul> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_10" rel="nofollow">前言</a></li><li><a href="#1__13" rel="nofollow">1 我的环境</a></li><li><a href="#2_pytorchDenseNet_23" rel="nofollow">2 pytorch实现DenseNet算法</a></li><li><ul><li><a href="#21__24" rel="nofollow">2.1 前期准备</a></li><li><ul><li><a href="#211__25" rel="nofollow">2.1.1 引入库</a></li><li><a href="#212_GPUGPUGPUCPU_51" rel="nofollow">2.1.2 设置GPU（如果设备上支持GPU就使用GPU,否则使用CPU）</a></li><li><a href="#213__65" rel="nofollow">2.1.3 导入数据</a></li><li><a href="#214__82" rel="nofollow">2.1.4 可视化数据</a></li><li><a href="#214__104" rel="nofollow">2.1.4 图像数据变换</a></li><li><a href="#214__138" rel="nofollow">2.1.4 划分数据集</a></li><li><a href="#214___158" rel="nofollow">2.1.4 加载数据</a></li><li><a href="#214__173" rel="nofollow">2.1.4 查看数据</a></li></ul> 
   </li><li><a href="#22_densenet121_190" rel="nofollow">2.2 搭建densenet121模型</a></li><li><a href="#23__726" rel="nofollow">2.3 训练模型</a></li><li><ul><li><a href="#231__727" rel="nofollow">2.3.1 设置超参数</a></li><li><a href="#232__744" rel="nofollow">2.3.2 编写训练函数</a></li><li><a href="#233__777" rel="nofollow">2.3.3 编写测试函数</a></li><li><a href="#234__806" rel="nofollow">2.3.4 正式训练</a></li></ul> 
   </li><li><a href="#24__879" rel="nofollow">2.4 结果可视化</a></li><li><a href="#24__904" rel="nofollow">2.4 指定图片进行预测</a></li><li><a href="#26__944" rel="nofollow">2.6 模型评估</a></li></ul> 
  </li><li><a href="#3__961" rel="nofollow">3 知识点详解</a></li><li><ul><li><a href="#31_nnSequentialnnModule_962" rel="nofollow">3.1 nn.Sequential和nn.Module区别与选择</a></li><li><ul><li><a href="#311_nnSequential_963" rel="nofollow">3.1.1 nn.Sequential</a></li><li><a href="#312_nnModule_985" rel="nofollow">3.1.2 nn.Module</a></li><li><a href="#313__1011" rel="nofollow">3.1.3 对比</a></li><li><a href="#314__1069" rel="nofollow">3.1.4 总结</a></li></ul> 
   </li><li><a href="#32_pythonOrderedDict_1075" rel="nofollow">3.2 python中OrderedDict的使用</a></li></ul> 
  </li><li><a href="#_1173" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_10"></a>前言</h2> 
<p>关键字： pytorch实现DenseNet算法，nn.Sequential和nn.Module区别与选择，python中OrderedDict的使用</p> 
<h2><a id="1__13"></a>1 我的环境</h2> 
<ul><li>电脑系统：Windows 11</li><li>语言环境：python 3.8.6</li><li>编译器：pycharm2020.2.3</li><li>深度学习环境：<br> torch == 1.9.1+cu111<br> torchvision == 0.10.1+cu111<br> TensorFlow 2.10.1</li><li>显卡：NVIDIA GeForce RTX 4070</li></ul> 
<h2><a id="2_pytorchDenseNet_23"></a>2 pytorch实现DenseNet算法</h2> 
<h3><a id="21__24"></a>2.1 前期准备</h3> 
<h4><a id="211__25"></a>2.1.1 引入库</h4> 
<pre><code class="prism language-python">
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> time
<span class="token keyword">import</span> copy
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span> datasets
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> torchsummary <span class="token keyword">as</span> summary
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
<span class="token keyword">import</span> re
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>model_zoo <span class="token keyword">as</span> model_zoo
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># 用来正常显示中文标签</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># 用来正常显示负号</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.dpi'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span>  <span class="token comment"># 分辨率</span>
<span class="token keyword">import</span> warnings

warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>  <span class="token comment"># 忽略一些warning内容，无需打印</span>

</code></pre> 
<h4><a id="212_GPUGPUGPUCPU_51"></a>2.1.2 设置GPU（如果设备上支持GPU就使用GPU,否则使用CPU）</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""前期准备-设置GPU"""</span>
<span class="token comment"># 如果设备上支持GPU就使用GPU,否则使用CPU</span>
 device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>
 <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Using {} device"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>输出</p> 
<pre><code>Using cuda device
</code></pre> 
<h4><a id="213__65"></a>2.1.3 导入数据</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-导入数据'''</span>
data_dir <span class="token operator">=</span> <span class="token string">r"D:\DeepLearning\data\BreastCancer"</span>
data_dir <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>

data_paths <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
classeNames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"\\"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token keyword">for</span> path <span class="token keyword">in</span> data_paths<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classeNames<span class="token punctuation">)</span>
</code></pre> 
<p>输出</p> 
<pre><code>['.DS_Store', '0', '1']

</code></pre> 
<h4><a id="214__82"></a>2.1.4 可视化数据</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-可视化数据'''</span>
subfolder <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"1"</span>
image_files <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>p<span class="token punctuation">.</span>resolve<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> p <span class="token keyword">in</span> subfolder<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*'</span><span class="token punctuation">)</span> <span class="token keyword">if</span> p<span class="token punctuation">.</span>suffix <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">".jpg"</span><span class="token punctuation">,</span> <span class="token string">".png"</span><span class="token punctuation">,</span> <span class="token string">".jpeg"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_files<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">12</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    image_file <span class="token operator">=</span> image_files<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
    ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>image_file<span class="token punctuation">)</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">"off"</span><span class="token punctuation">)</span>
<span class="token comment"># 显示图片</span>
plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d7/b6/DZko4fdQ_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="214__104"></a>2.1.4 图像数据变换</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-图像数据变换'''</span>
total_datadir <span class="token operator">=</span> data_dir

<span class="token comment"># 关于transforms.Compose的更多介绍可以参考：https://blog.csdn.net/qq_38251616/article/details/124878863</span>
train_transforms <span class="token operator">=</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 将输入图片resize成统一尺寸</span>
    transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 将PIL Image或numpy.ndarray转换为tensor，并归一化到[0,1]之间</span>
    transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>  <span class="token comment"># 标准化处理--&gt;转换为标准正太分布（高斯分布），使模型更容易收敛</span>
        mean<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        std<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 其中 mean=[0.485,0.456,0.406]与std=[0.229,0.224,0.225] 从数据集中随机抽样计算得到的。</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
total_data <span class="token operator">=</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>total_datadir<span class="token punctuation">,</span> transform<span class="token operator">=</span>train_transforms<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>total_data<span class="token punctuation">.</span>class_to_idx<span class="token punctuation">)</span>
</code></pre> 
<p>输出</p> 
<pre><code>Dataset ImageFolder
    Number of datapoints: 13403
    Root location: D:\DeepLearning\data\BreastCancer
    StandardTransform
Transform: Compose(
               Resize(size=[224, 224], interpolation=bilinear, max_size=None, antialias=None)
               ToTensor()
               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
           )
{'0': 0, '1': 1}

</code></pre> 
<h4><a id="214__138"></a>2.1.4 划分数据集</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-划分数据集'''</span>
train_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token number">0.8</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># train_size表示训练集大小，通过将总体数据长度的80%转换为整数得到；</span>
test_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>total_data<span class="token punctuation">)</span> <span class="token operator">-</span> train_size  <span class="token comment"># test_size表示测试集大小，是总体数据长度减去训练集大小。</span>
<span class="token comment"># 使用torch.utils.data.random_split()方法进行数据集划分。该方法将总体数据total_data按照指定的大小比例（[train_size, test_size]）随机划分为训练集和测试集，</span>
<span class="token comment"># 并将划分结果分别赋值给train_dataset和test_dataset两个变量。</span>
train_dataset<span class="token punctuation">,</span> test_dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>random_split<span class="token punctuation">(</span>total_data<span class="token punctuation">,</span> <span class="token punctuation">[</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_dataset={}\ntest_dataset={}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span> test_dataset<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_size={}\ntest_size={}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>train_size<span class="token punctuation">,</span> test_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>输出</p> 
<pre><code>train_dataset=&lt;torch.utils.data.dataset.Subset object at 0x000001AB3AD06BE0&gt;
test_dataset=&lt;torch.utils.data.dataset.Subset object at 0x000001AB3AD06B20&gt;
train_size=10722
test_size=2681
</code></pre> 
<h4><a id="214___158"></a>2.1.4 加载数据</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-加载数据'''</span>
batch_size <span class="token operator">=</span> <span class="token number">32</span>

train_dl <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>train_dataset<span class="token punctuation">,</span>
                                       batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                       shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                       num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
test_dl <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>test_dataset<span class="token punctuation">,</span>
                                      batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                      shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
                                      num_workers<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="214__173"></a>2.1.4 查看数据</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-查看数据'''</span>
<span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> test_dl<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shape of X [N, C, H, W]: "</span><span class="token punctuation">,</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shape of y: "</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
    <span class="token keyword">break</span>
</code></pre> 
<p>输出</p> 
<pre><code>Shape of X [N, C, H, W]:  torch.Size([32, 3, 224, 224])
Shape of y:  torch.Size([32]) torch.int64
</code></pre> 
<h3><a id="22_densenet121_190"></a>2.2 搭建densenet121模型</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""构建DenseNet网络"""</span>
<span class="token comment"># 这里我们采用了Pytorch的框架来实现DenseNet，</span>
<span class="token comment"># 首先实现DenseBlock中的内部结构，这里是BN+ReLU+1×1Conv+BN+ReLU+3×3Conv结构，最后也加入dropout层用于训练过程。</span>
<span class="token keyword">class</span> <span class="token class-name">_DenseLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Basic unit of DenseBlock (using bottleneck layer) """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">,</span> bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span>
                                           kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>bn_size <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span>
                                           kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        self<span class="token punctuation">.</span>drop_rate <span class="token operator">=</span> drop_rate

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        new_features <span class="token operator">=</span> <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>forward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>drop_rate <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            new_features <span class="token operator">=</span> F<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>new_features<span class="token punctuation">,</span> p<span class="token operator">=</span>self<span class="token punctuation">.</span>drop_rate<span class="token punctuation">,</span> training<span class="token operator">=</span>self<span class="token punctuation">.</span>training<span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> new_features<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>


<span class="token comment"># 实现DenseBlock模块，内部是密集连接方式（输入特征数线性增长）：</span>
<span class="token keyword">class</span> <span class="token class-name">_DenseBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""DenseBlock """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_DenseBlock<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            layer <span class="token operator">=</span> _DenseLayer<span class="token punctuation">(</span>
                num_input_features <span class="token operator">+</span> i <span class="token operator">*</span> growth_rate<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'denselayer%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> layer<span class="token punctuation">)</span>


<span class="token comment"># 实现Transition层，它主要是一个卷积层和一个池化层：</span>
<span class="token keyword">class</span> <span class="token class-name">_Transition</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_input_features<span class="token punctuation">,</span> num_output_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>_Transition<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'conv'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>num_input_features<span class="token punctuation">,</span> num_output_features<span class="token punctuation">,</span>
                                          kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'pool'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># 最后我们实现DenseNet网络：</span>
<span class="token keyword">class</span> <span class="token class-name">DenseNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">r"""Densenet-BC model class, based on
    `"Densely Connected Convolutional Networks" &lt;https://arxiv.org/pdf/1608.06993.pdf&gt;`
    Args:
        growth_rate (int) - how many filters to add each layer (`k` in paper)
        block_config (list of 3 or 4 ints) - how many layers in each pooling block
        num_init_features (int) - the number of filters to learn in the first convolution layer
        bn_size (int) - multiplicative factor for number of bottle neck layers
            (i.e. bn_size * k features in the bottleneck layer)
        drop_rate (float) - dropout rate after each dense layer
        num_classes (int) - number of classification classes
    """</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> block_config<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                 num_init_features<span class="token operator">=</span><span class="token number">24</span><span class="token punctuation">,</span> bn_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> compression<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">,</span> drop_rate<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>
                 num_classes<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>DenseNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># First Conv2d</span>
        self<span class="token punctuation">.</span>features <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
            <span class="token punctuation">(</span><span class="token string">'conv0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> num_init_features<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">'norm0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_init_features<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">'relu0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token punctuation">(</span><span class="token string">'pool0'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


        <span class="token comment"># Each denseblock</span>
        num_features <span class="token operator">=</span> num_init_features
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> num_layers <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>block_config<span class="token punctuation">)</span><span class="token punctuation">:</span>
            block <span class="token operator">=</span> _DenseBlock<span class="token punctuation">(</span>num_layers<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> bn_size<span class="token punctuation">,</span> growth_rate<span class="token punctuation">,</span> drop_rate<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'denseblock%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> block<span class="token punctuation">)</span>
            num_features <span class="token operator">+=</span> num_layers <span class="token operator">*</span> growth_rate
            <span class="token keyword">if</span> i <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>block_config<span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>
                transition <span class="token operator">=</span> _Transition<span class="token punctuation">(</span>num_input_features<span class="token operator">=</span>num_features<span class="token punctuation">,</span>
                                         num_output_features<span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">(</span>num_features <span class="token operator">*</span> compression<span class="token punctuation">)</span><span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'transition%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> transition<span class="token punctuation">)</span>
                num_features <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>num_features <span class="token operator">*</span> compression<span class="token punctuation">)</span>

        <span class="token comment"># Final bn+relu</span>
        self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'norm5'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>num_features<span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>features<span class="token punctuation">.</span>add_module<span class="token punctuation">(</span><span class="token string">'relu5'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># classification layer</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_features<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>

        <span class="token comment"># params initialization</span>
        <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>modules<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>kaiming_normal_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>m<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">)</span><span class="token punctuation">:</span>
                nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>m<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        features <span class="token operator">=</span> self<span class="token punctuation">.</span>features<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        out <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>features<span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>features<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out



model_urls <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">'densenet121'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet121-a639ec97.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'densenet169'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet169-b2777c0a.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'densenet201'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet201-c1103571.pth'</span><span class="token punctuation">,</span>
    <span class="token string">'densenet161'</span><span class="token punctuation">:</span> <span class="token string">'https://download.pytorch.org/models/densenet161-8d451a50.pth'</span><span class="token punctuation">}</span>


<span class="token keyword">def</span> <span class="token function">densenet121</span><span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""DenseNet121"""</span>
    model <span class="token operator">=</span> DenseNet<span class="token punctuation">(</span>num_init_features<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> growth_rate<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> block_config<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">6</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">24</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>	<span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
    <span class="token keyword">if</span> pretrained<span class="token punctuation">:</span>
        <span class="token comment"># '.'s are no longer allowed in module names, but pervious _DenseLayer</span>
        <span class="token comment"># has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.</span>
        <span class="token comment"># They are also in the checkpoints in model_urls. This pattern is used</span>
        <span class="token comment"># to find such keys.</span>
        pattern <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>
            <span class="token string">r'^(.*denselayer\d+\.(?:norm|relu|conv))\.((?:[12])\.(?:weight|bias|running_mean|running_var))$'</span><span class="token punctuation">)</span>
        state_dict <span class="token operator">=</span> model_zoo<span class="token punctuation">.</span>load_url<span class="token punctuation">(</span>model_urls<span class="token punctuation">[</span><span class="token string">'densenet121'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>state_dict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            res <span class="token operator">=</span> pattern<span class="token punctuation">.</span><span class="token keyword">match</span><span class="token punctuation">(</span>key<span class="token punctuation">)</span>
            <span class="token keyword">if</span> res<span class="token punctuation">:</span>
                new_key <span class="token operator">=</span> res<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> res<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
                state_dict<span class="token punctuation">[</span>new_key<span class="token punctuation">]</span> <span class="token operator">=</span> state_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
                <span class="token keyword">del</span> state_dict<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
        model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict<span class="token punctuation">)</span>
    <span class="token keyword">return</span> model

<span class="token triple-quoted-string string">"""搭建densenet121模型"""</span>
<span class="token comment"># model = densenet121().to(device)  </span>
model <span class="token operator">=</span> densenet121<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 使用预训练模型</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>summary<span class="token punctuation">.</span>summary<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 查看模型的参数量以及相关指标</span>
    
</code></pre> 
<p>输出</p> 
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
       BatchNorm2d-5           [-1, 64, 56, 56]             128
              ReLU-6           [-1, 64, 56, 56]               0
            Conv2d-7          [-1, 128, 56, 56]           8,192
       BatchNorm2d-8          [-1, 128, 56, 56]             256
              ReLU-9          [-1, 128, 56, 56]               0
           Conv2d-10           [-1, 32, 56, 56]          36,864
      BatchNorm2d-11           [-1, 96, 56, 56]             192
             ReLU-12           [-1, 96, 56, 56]               0
           Conv2d-13          [-1, 128, 56, 56]          12,288
      BatchNorm2d-14          [-1, 128, 56, 56]             256
             ReLU-15          [-1, 128, 56, 56]               0
           Conv2d-16           [-1, 32, 56, 56]          36,864
      BatchNorm2d-17          [-1, 128, 56, 56]             256
             ReLU-18          [-1, 128, 56, 56]               0
           Conv2d-19          [-1, 128, 56, 56]          16,384
      BatchNorm2d-20          [-1, 128, 56, 56]             256
             ReLU-21          [-1, 128, 56, 56]               0
           Conv2d-22           [-1, 32, 56, 56]          36,864
      BatchNorm2d-23          [-1, 160, 56, 56]             320
             ReLU-24          [-1, 160, 56, 56]               0
           Conv2d-25          [-1, 128, 56, 56]          20,480
      BatchNorm2d-26          [-1, 128, 56, 56]             256
             ReLU-27          [-1, 128, 56, 56]               0
           Conv2d-28           [-1, 32, 56, 56]          36,864
      BatchNorm2d-29          [-1, 192, 56, 56]             384
             ReLU-30          [-1, 192, 56, 56]               0
           Conv2d-31          [-1, 128, 56, 56]          24,576
      BatchNorm2d-32          [-1, 128, 56, 56]             256
             ReLU-33          [-1, 128, 56, 56]               0
           Conv2d-34           [-1, 32, 56, 56]          36,864
      BatchNorm2d-35          [-1, 224, 56, 56]             448
             ReLU-36          [-1, 224, 56, 56]               0
           Conv2d-37          [-1, 128, 56, 56]          28,672
      BatchNorm2d-38          [-1, 128, 56, 56]             256
             ReLU-39          [-1, 128, 56, 56]               0
           Conv2d-40           [-1, 32, 56, 56]          36,864
      BatchNorm2d-41          [-1, 256, 56, 56]             512
             ReLU-42          [-1, 256, 56, 56]               0
           Conv2d-43          [-1, 128, 56, 56]          32,768
        AvgPool2d-44          [-1, 128, 28, 28]               0
      BatchNorm2d-45          [-1, 128, 28, 28]             256
             ReLU-46          [-1, 128, 28, 28]               0
           Conv2d-47          [-1, 128, 28, 28]          16,384
      BatchNorm2d-48          [-1, 128, 28, 28]             256
             ReLU-49          [-1, 128, 28, 28]               0
           Conv2d-50           [-1, 32, 28, 28]          36,864
      BatchNorm2d-51          [-1, 160, 28, 28]             320
             ReLU-52          [-1, 160, 28, 28]               0
           Conv2d-53          [-1, 128, 28, 28]          20,480
      BatchNorm2d-54          [-1, 128, 28, 28]             256
             ReLU-55          [-1, 128, 28, 28]               0
           Conv2d-56           [-1, 32, 28, 28]          36,864
      BatchNorm2d-57          [-1, 192, 28, 28]             384
             ReLU-58          [-1, 192, 28, 28]               0
           Conv2d-59          [-1, 128, 28, 28]          24,576
      BatchNorm2d-60          [-1, 128, 28, 28]             256
             ReLU-61          [-1, 128, 28, 28]               0
           Conv2d-62           [-1, 32, 28, 28]          36,864
      BatchNorm2d-63          [-1, 224, 28, 28]             448
             ReLU-64          [-1, 224, 28, 28]               0
           Conv2d-65          [-1, 128, 28, 28]          28,672
      BatchNorm2d-66          [-1, 128, 28, 28]             256
             ReLU-67          [-1, 128, 28, 28]               0
           Conv2d-68           [-1, 32, 28, 28]          36,864
      BatchNorm2d-69          [-1, 256, 28, 28]             512
             ReLU-70          [-1, 256, 28, 28]               0
           Conv2d-71          [-1, 128, 28, 28]          32,768
      BatchNorm2d-72          [-1, 128, 28, 28]             256
             ReLU-73          [-1, 128, 28, 28]               0
           Conv2d-74           [-1, 32, 28, 28]          36,864
      BatchNorm2d-75          [-1, 288, 28, 28]             576
             ReLU-76          [-1, 288, 28, 28]               0
           Conv2d-77          [-1, 128, 28, 28]          36,864
      BatchNorm2d-78          [-1, 128, 28, 28]             256
             ReLU-79          [-1, 128, 28, 28]               0
           Conv2d-80           [-1, 32, 28, 28]          36,864
      BatchNorm2d-81          [-1, 320, 28, 28]             640
             ReLU-82          [-1, 320, 28, 28]               0
           Conv2d-83          [-1, 128, 28, 28]          40,960
      BatchNorm2d-84          [-1, 128, 28, 28]             256
             ReLU-85          [-1, 128, 28, 28]               0
           Conv2d-86           [-1, 32, 28, 28]          36,864
      BatchNorm2d-87          [-1, 352, 28, 28]             704
             ReLU-88          [-1, 352, 28, 28]               0
           Conv2d-89          [-1, 128, 28, 28]          45,056
      BatchNorm2d-90          [-1, 128, 28, 28]             256
             ReLU-91          [-1, 128, 28, 28]               0
           Conv2d-92           [-1, 32, 28, 28]          36,864
      BatchNorm2d-93          [-1, 384, 28, 28]             768
             ReLU-94          [-1, 384, 28, 28]               0
           Conv2d-95          [-1, 128, 28, 28]          49,152
      BatchNorm2d-96          [-1, 128, 28, 28]             256
             ReLU-97          [-1, 128, 28, 28]               0
           Conv2d-98           [-1, 32, 28, 28]          36,864
      BatchNorm2d-99          [-1, 416, 28, 28]             832
            ReLU-100          [-1, 416, 28, 28]               0
          Conv2d-101          [-1, 128, 28, 28]          53,248
     BatchNorm2d-102          [-1, 128, 28, 28]             256
            ReLU-103          [-1, 128, 28, 28]               0
          Conv2d-104           [-1, 32, 28, 28]          36,864
     BatchNorm2d-105          [-1, 448, 28, 28]             896
            ReLU-106          [-1, 448, 28, 28]               0
          Conv2d-107          [-1, 128, 28, 28]          57,344
     BatchNorm2d-108          [-1, 128, 28, 28]             256
            ReLU-109          [-1, 128, 28, 28]               0
          Conv2d-110           [-1, 32, 28, 28]          36,864
     BatchNorm2d-111          [-1, 480, 28, 28]             960
            ReLU-112          [-1, 480, 28, 28]               0
          Conv2d-113          [-1, 128, 28, 28]          61,440
     BatchNorm2d-114          [-1, 128, 28, 28]             256
            ReLU-115          [-1, 128, 28, 28]               0
          Conv2d-116           [-1, 32, 28, 28]          36,864
     BatchNorm2d-117          [-1, 512, 28, 28]           1,024
            ReLU-118          [-1, 512, 28, 28]               0
          Conv2d-119          [-1, 256, 28, 28]         131,072
       AvgPool2d-120          [-1, 256, 14, 14]               0
     BatchNorm2d-121          [-1, 256, 14, 14]             512
            ReLU-122          [-1, 256, 14, 14]               0
          Conv2d-123          [-1, 128, 14, 14]          32,768
     BatchNorm2d-124          [-1, 128, 14, 14]             256
            ReLU-125          [-1, 128, 14, 14]               0
          Conv2d-126           [-1, 32, 14, 14]          36,864
     BatchNorm2d-127          [-1, 288, 14, 14]             576
            ReLU-128          [-1, 288, 14, 14]               0
          Conv2d-129          [-1, 128, 14, 14]          36,864
     BatchNorm2d-130          [-1, 128, 14, 14]             256
            ReLU-131          [-1, 128, 14, 14]               0
          Conv2d-132           [-1, 32, 14, 14]          36,864
     BatchNorm2d-133          [-1, 320, 14, 14]             640
            ReLU-134          [-1, 320, 14, 14]               0
          Conv2d-135          [-1, 128, 14, 14]          40,960
     BatchNorm2d-136          [-1, 128, 14, 14]             256
            ReLU-137          [-1, 128, 14, 14]               0
          Conv2d-138           [-1, 32, 14, 14]          36,864
     BatchNorm2d-139          [-1, 352, 14, 14]             704
            ReLU-140          [-1, 352, 14, 14]               0
          Conv2d-141          [-1, 128, 14, 14]          45,056
     BatchNorm2d-142          [-1, 128, 14, 14]             256
            ReLU-143          [-1, 128, 14, 14]               0
          Conv2d-144           [-1, 32, 14, 14]          36,864
     BatchNorm2d-145          [-1, 384, 14, 14]             768
            ReLU-146          [-1, 384, 14, 14]               0
          Conv2d-147          [-1, 128, 14, 14]          49,152
     BatchNorm2d-148          [-1, 128, 14, 14]             256
            ReLU-149          [-1, 128, 14, 14]               0
          Conv2d-150           [-1, 32, 14, 14]          36,864
     BatchNorm2d-151          [-1, 416, 14, 14]             832
            ReLU-152          [-1, 416, 14, 14]               0
          Conv2d-153          [-1, 128, 14, 14]          53,248
     BatchNorm2d-154          [-1, 128, 14, 14]             256
            ReLU-155          [-1, 128, 14, 14]               0
          Conv2d-156           [-1, 32, 14, 14]          36,864
     BatchNorm2d-157          [-1, 448, 14, 14]             896
            ReLU-158          [-1, 448, 14, 14]               0
          Conv2d-159          [-1, 128, 14, 14]          57,344
     BatchNorm2d-160          [-1, 128, 14, 14]             256
            ReLU-161          [-1, 128, 14, 14]               0
          Conv2d-162           [-1, 32, 14, 14]          36,864
     BatchNorm2d-163          [-1, 480, 14, 14]             960
            ReLU-164          [-1, 480, 14, 14]               0
          Conv2d-165          [-1, 128, 14, 14]          61,440
     BatchNorm2d-166          [-1, 128, 14, 14]             256
            ReLU-167          [-1, 128, 14, 14]               0
          Conv2d-168           [-1, 32, 14, 14]          36,864
     BatchNorm2d-169          [-1, 512, 14, 14]           1,024
            ReLU-170          [-1, 512, 14, 14]               0
          Conv2d-171          [-1, 128, 14, 14]          65,536
     BatchNorm2d-172          [-1, 128, 14, 14]             256
            ReLU-173          [-1, 128, 14, 14]               0
          Conv2d-174           [-1, 32, 14, 14]          36,864
     BatchNorm2d-175          [-1, 544, 14, 14]           1,088
            ReLU-176          [-1, 544, 14, 14]               0
          Conv2d-177          [-1, 128, 14, 14]          69,632
     BatchNorm2d-178          [-1, 128, 14, 14]             256
            ReLU-179          [-1, 128, 14, 14]               0
          Conv2d-180           [-1, 32, 14, 14]          36,864
     BatchNorm2d-181          [-1, 576, 14, 14]           1,152
            ReLU-182          [-1, 576, 14, 14]               0
          Conv2d-183          [-1, 128, 14, 14]          73,728
     BatchNorm2d-184          [-1, 128, 14, 14]             256
            ReLU-185          [-1, 128, 14, 14]               0
          Conv2d-186           [-1, 32, 14, 14]          36,864
     BatchNorm2d-187          [-1, 608, 14, 14]           1,216
            ReLU-188          [-1, 608, 14, 14]               0
          Conv2d-189          [-1, 128, 14, 14]          77,824
     BatchNorm2d-190          [-1, 128, 14, 14]             256
            ReLU-191          [-1, 128, 14, 14]               0
          Conv2d-192           [-1, 32, 14, 14]          36,864
     BatchNorm2d-193          [-1, 640, 14, 14]           1,280
            ReLU-194          [-1, 640, 14, 14]               0
          Conv2d-195          [-1, 128, 14, 14]          81,920
     BatchNorm2d-196          [-1, 128, 14, 14]             256
            ReLU-197          [-1, 128, 14, 14]               0
          Conv2d-198           [-1, 32, 14, 14]          36,864
     BatchNorm2d-199          [-1, 672, 14, 14]           1,344
            ReLU-200          [-1, 672, 14, 14]               0
          Conv2d-201          [-1, 128, 14, 14]          86,016
     BatchNorm2d-202          [-1, 128, 14, 14]             256
            ReLU-203          [-1, 128, 14, 14]               0
          Conv2d-204           [-1, 32, 14, 14]          36,864
     BatchNorm2d-205          [-1, 704, 14, 14]           1,408
            ReLU-206          [-1, 704, 14, 14]               0
          Conv2d-207          [-1, 128, 14, 14]          90,112
     BatchNorm2d-208          [-1, 128, 14, 14]             256
            ReLU-209          [-1, 128, 14, 14]               0
          Conv2d-210           [-1, 32, 14, 14]          36,864
     BatchNorm2d-211          [-1, 736, 14, 14]           1,472
            ReLU-212          [-1, 736, 14, 14]               0
          Conv2d-213          [-1, 128, 14, 14]          94,208
     BatchNorm2d-214          [-1, 128, 14, 14]             256
            ReLU-215          [-1, 128, 14, 14]               0
          Conv2d-216           [-1, 32, 14, 14]          36,864
     BatchNorm2d-217          [-1, 768, 14, 14]           1,536
            ReLU-218          [-1, 768, 14, 14]               0
          Conv2d-219          [-1, 128, 14, 14]          98,304
     BatchNorm2d-220          [-1, 128, 14, 14]             256
            ReLU-221          [-1, 128, 14, 14]               0
          Conv2d-222           [-1, 32, 14, 14]          36,864
     BatchNorm2d-223          [-1, 800, 14, 14]           1,600
            ReLU-224          [-1, 800, 14, 14]               0
          Conv2d-225          [-1, 128, 14, 14]         102,400
     BatchNorm2d-226          [-1, 128, 14, 14]             256
            ReLU-227          [-1, 128, 14, 14]               0
          Conv2d-228           [-1, 32, 14, 14]          36,864
     BatchNorm2d-229          [-1, 832, 14, 14]           1,664
            ReLU-230          [-1, 832, 14, 14]               0
          Conv2d-231          [-1, 128, 14, 14]         106,496
     BatchNorm2d-232          [-1, 128, 14, 14]             256
            ReLU-233          [-1, 128, 14, 14]               0
          Conv2d-234           [-1, 32, 14, 14]          36,864
     BatchNorm2d-235          [-1, 864, 14, 14]           1,728
            ReLU-236          [-1, 864, 14, 14]               0
          Conv2d-237          [-1, 128, 14, 14]         110,592
     BatchNorm2d-238          [-1, 128, 14, 14]             256
            ReLU-239          [-1, 128, 14, 14]               0
          Conv2d-240           [-1, 32, 14, 14]          36,864
     BatchNorm2d-241          [-1, 896, 14, 14]           1,792
            ReLU-242          [-1, 896, 14, 14]               0
          Conv2d-243          [-1, 128, 14, 14]         114,688
     BatchNorm2d-244          [-1, 128, 14, 14]             256
            ReLU-245          [-1, 128, 14, 14]               0
          Conv2d-246           [-1, 32, 14, 14]          36,864
     BatchNorm2d-247          [-1, 928, 14, 14]           1,856
            ReLU-248          [-1, 928, 14, 14]               0
          Conv2d-249          [-1, 128, 14, 14]         118,784
     BatchNorm2d-250          [-1, 128, 14, 14]             256
            ReLU-251          [-1, 128, 14, 14]               0
          Conv2d-252           [-1, 32, 14, 14]          36,864
     BatchNorm2d-253          [-1, 960, 14, 14]           1,920
            ReLU-254          [-1, 960, 14, 14]               0
          Conv2d-255          [-1, 128, 14, 14]         122,880
     BatchNorm2d-256          [-1, 128, 14, 14]             256
            ReLU-257          [-1, 128, 14, 14]               0
          Conv2d-258           [-1, 32, 14, 14]          36,864
     BatchNorm2d-259          [-1, 992, 14, 14]           1,984
            ReLU-260          [-1, 992, 14, 14]               0
          Conv2d-261          [-1, 128, 14, 14]         126,976
     BatchNorm2d-262          [-1, 128, 14, 14]             256
            ReLU-263          [-1, 128, 14, 14]               0
          Conv2d-264           [-1, 32, 14, 14]          36,864
     BatchNorm2d-265         [-1, 1024, 14, 14]           2,048
            ReLU-266         [-1, 1024, 14, 14]               0
          Conv2d-267          [-1, 512, 14, 14]         524,288
       AvgPool2d-268            [-1, 512, 7, 7]               0
     BatchNorm2d-269            [-1, 512, 7, 7]           1,024
            ReLU-270            [-1, 512, 7, 7]               0
          Conv2d-271            [-1, 128, 7, 7]          65,536
     BatchNorm2d-272            [-1, 128, 7, 7]             256
            ReLU-273            [-1, 128, 7, 7]               0
          Conv2d-274             [-1, 32, 7, 7]          36,864
     BatchNorm2d-275            [-1, 544, 7, 7]           1,088
            ReLU-276            [-1, 544, 7, 7]               0
          Conv2d-277            [-1, 128, 7, 7]          69,632
     BatchNorm2d-278            [-1, 128, 7, 7]             256
            ReLU-279            [-1, 128, 7, 7]               0
          Conv2d-280             [-1, 32, 7, 7]          36,864
     BatchNorm2d-281            [-1, 576, 7, 7]           1,152
            ReLU-282            [-1, 576, 7, 7]               0
          Conv2d-283            [-1, 128, 7, 7]          73,728
     BatchNorm2d-284            [-1, 128, 7, 7]             256
            ReLU-285            [-1, 128, 7, 7]               0
          Conv2d-286             [-1, 32, 7, 7]          36,864
     BatchNorm2d-287            [-1, 608, 7, 7]           1,216
            ReLU-288            [-1, 608, 7, 7]               0
          Conv2d-289            [-1, 128, 7, 7]          77,824
     BatchNorm2d-290            [-1, 128, 7, 7]             256
            ReLU-291            [-1, 128, 7, 7]               0
          Conv2d-292             [-1, 32, 7, 7]          36,864
     BatchNorm2d-293            [-1, 640, 7, 7]           1,280
            ReLU-294            [-1, 640, 7, 7]               0
          Conv2d-295            [-1, 128, 7, 7]          81,920
     BatchNorm2d-296            [-1, 128, 7, 7]             256
            ReLU-297            [-1, 128, 7, 7]               0
          Conv2d-298             [-1, 32, 7, 7]          36,864
     BatchNorm2d-299            [-1, 672, 7, 7]           1,344
            ReLU-300            [-1, 672, 7, 7]               0
          Conv2d-301            [-1, 128, 7, 7]          86,016
     BatchNorm2d-302            [-1, 128, 7, 7]             256
            ReLU-303            [-1, 128, 7, 7]               0
          Conv2d-304             [-1, 32, 7, 7]          36,864
     BatchNorm2d-305            [-1, 704, 7, 7]           1,408
            ReLU-306            [-1, 704, 7, 7]               0
          Conv2d-307            [-1, 128, 7, 7]          90,112
     BatchNorm2d-308            [-1, 128, 7, 7]             256
            ReLU-309            [-1, 128, 7, 7]               0
          Conv2d-310             [-1, 32, 7, 7]          36,864
     BatchNorm2d-311            [-1, 736, 7, 7]           1,472
            ReLU-312            [-1, 736, 7, 7]               0
          Conv2d-313            [-1, 128, 7, 7]          94,208
     BatchNorm2d-314            [-1, 128, 7, 7]             256
            ReLU-315            [-1, 128, 7, 7]               0
          Conv2d-316             [-1, 32, 7, 7]          36,864
     BatchNorm2d-317            [-1, 768, 7, 7]           1,536
            ReLU-318            [-1, 768, 7, 7]               0
          Conv2d-319            [-1, 128, 7, 7]          98,304
     BatchNorm2d-320            [-1, 128, 7, 7]             256
            ReLU-321            [-1, 128, 7, 7]               0
          Conv2d-322             [-1, 32, 7, 7]          36,864
     BatchNorm2d-323            [-1, 800, 7, 7]           1,600
            ReLU-324            [-1, 800, 7, 7]               0
          Conv2d-325            [-1, 128, 7, 7]         102,400
     BatchNorm2d-326            [-1, 128, 7, 7]             256
            ReLU-327            [-1, 128, 7, 7]               0
          Conv2d-328             [-1, 32, 7, 7]          36,864
     BatchNorm2d-329            [-1, 832, 7, 7]           1,664
            ReLU-330            [-1, 832, 7, 7]               0
          Conv2d-331            [-1, 128, 7, 7]         106,496
     BatchNorm2d-332            [-1, 128, 7, 7]             256
            ReLU-333            [-1, 128, 7, 7]               0
          Conv2d-334             [-1, 32, 7, 7]          36,864
     BatchNorm2d-335            [-1, 864, 7, 7]           1,728
            ReLU-336            [-1, 864, 7, 7]               0
          Conv2d-337            [-1, 128, 7, 7]         110,592
     BatchNorm2d-338            [-1, 128, 7, 7]             256
            ReLU-339            [-1, 128, 7, 7]               0
          Conv2d-340             [-1, 32, 7, 7]          36,864
     BatchNorm2d-341            [-1, 896, 7, 7]           1,792
            ReLU-342            [-1, 896, 7, 7]               0
          Conv2d-343            [-1, 128, 7, 7]         114,688
     BatchNorm2d-344            [-1, 128, 7, 7]             256
            ReLU-345            [-1, 128, 7, 7]               0
          Conv2d-346             [-1, 32, 7, 7]          36,864
     BatchNorm2d-347            [-1, 928, 7, 7]           1,856
            ReLU-348            [-1, 928, 7, 7]               0
          Conv2d-349            [-1, 128, 7, 7]         118,784
     BatchNorm2d-350            [-1, 128, 7, 7]             256
            ReLU-351            [-1, 128, 7, 7]               0
          Conv2d-352             [-1, 32, 7, 7]          36,864
     BatchNorm2d-353            [-1, 960, 7, 7]           1,920
            ReLU-354            [-1, 960, 7, 7]               0
          Conv2d-355            [-1, 128, 7, 7]         122,880
     BatchNorm2d-356            [-1, 128, 7, 7]             256
            ReLU-357            [-1, 128, 7, 7]               0
          Conv2d-358             [-1, 32, 7, 7]          36,864
     BatchNorm2d-359            [-1, 992, 7, 7]           1,984
            ReLU-360            [-1, 992, 7, 7]               0
          Conv2d-361            [-1, 128, 7, 7]         126,976
     BatchNorm2d-362            [-1, 128, 7, 7]             256
            ReLU-363            [-1, 128, 7, 7]               0
          Conv2d-364             [-1, 32, 7, 7]          36,864
     BatchNorm2d-365           [-1, 1024, 7, 7]           2,048
            ReLU-366           [-1, 1024, 7, 7]               0
          Linear-367                 [-1, 1000]       1,025,000
================================================================
Total params: 7,978,856
Trainable params: 7,978,856
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 294.58
Params size (MB): 30.44
Estimated Total Size (MB): 325.59
----------------------------------------------------------------
</code></pre> 
<h3><a id="23__726"></a>2.3 训练模型</h3> 
<h4><a id="231__727"></a>2.3.1 设置超参数</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""训练模型--设置超参数"""</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 创建损失函数，计算实际输出和真实相差多少，交叉熵损失函数，事实上，它就是做图片分类任务时常用的损失函数</span>
learn_rate <span class="token operator">=</span> <span class="token number">1e-4</span>  <span class="token comment"># 学习率</span>
optimizer1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learn_rate<span class="token punctuation">)</span><span class="token comment"># 作用是定义优化器，用来训练时候优化模型参数；其中，SGD表示随机梯度下降，用于控制实际输出y与真实y之间的相差有多大</span>
optimizer2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learn_rate<span class="token punctuation">)</span>  
lr_opt <span class="token operator">=</span> optimizer2
model_opt <span class="token operator">=</span> optimizer2
<span class="token comment"># 调用官方动态学习率接口时使用2</span>
lambda1 <span class="token operator">=</span> <span class="token keyword">lambda</span> epoch <span class="token punctuation">:</span> <span class="token number">0.92</span> <span class="token operator">**</span> <span class="token punctuation">(</span>epoch <span class="token operator">//</span> <span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)</span>
scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>LambdaLR<span class="token punctuation">(</span>lr_opt<span class="token punctuation">,</span> lr_lambda<span class="token operator">=</span>lambda1<span class="token punctuation">)</span> <span class="token comment">#选定调整方法</span>

</code></pre> 
<h4><a id="232__744"></a>2.3.2 编写训练函数</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""训练模型--编写训练函数"""</span>
<span class="token comment"># 训练循环</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> optimizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>  <span class="token comment"># 训练集的大小，一共60000张图片</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>  <span class="token comment"># 批次数目，1875（60000/32）</span>

    train_loss<span class="token punctuation">,</span> train_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>  <span class="token comment"># 初始化训练损失和正确率</span>

    <span class="token keyword">for</span> X<span class="token punctuation">,</span> y <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>  <span class="token comment"># 加载数据加载器，得到里面的 X（图片数据）和 y（真实标签）</span>
        X<span class="token punctuation">,</span> y <span class="token operator">=</span> X<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 用于将数据存到显卡</span>

        <span class="token comment"># 计算预测误差</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>X<span class="token punctuation">)</span>  <span class="token comment"># 网络输出</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>  <span class="token comment"># 计算网络输出和真实值之间的差距，targets为真实值，计算二者差值即为损失</span>

        <span class="token comment"># 反向传播</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 清空过往梯度</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 反向传播，计算当前梯度</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 根据梯度更新网络参数</span>

        <span class="token comment"># 记录acc与loss</span>
        train_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

    train_acc <span class="token operator">/=</span> size
    train_loss <span class="token operator">/=</span> num_batches

    <span class="token keyword">return</span> train_acc<span class="token punctuation">,</span> train_loss
</code></pre> 
<h4><a id="233__777"></a>2.3.3 编写测试函数</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""训练模型--编写测试函数"""</span>
<span class="token comment"># 测试函数和训练函数大致相同，但是由于不进行梯度下降对网络权重进行更新，所以不需要传入优化器</span>
<span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span><span class="token punctuation">:</span>
    size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span>  <span class="token comment"># 测试集的大小，一共10000张图片</span>
    num_batches <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">)</span>  <span class="token comment"># 批次数目，313（10000/32=312.5，向上取整）</span>
    test_loss<span class="token punctuation">,</span> test_acc <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>

    <span class="token comment"># 当不进行训练时，停止梯度更新，节省计算内存消耗</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 测试时模型参数不用更新，所以 no_grad，整个模型参数正向推就ok，不反向更新参数</span>
        <span class="token keyword">for</span> imgs<span class="token punctuation">,</span> target <span class="token keyword">in</span> dataloader<span class="token punctuation">:</span>
            imgs<span class="token punctuation">,</span> target <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

            <span class="token comment"># 计算loss</span>
            target_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>target_pred<span class="token punctuation">,</span> target<span class="token punctuation">)</span>

            test_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            test_acc <span class="token operator">+=</span> <span class="token punctuation">(</span>target_pred<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> target<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#统计预测正确的个数</span>

    test_acc <span class="token operator">/=</span> size
    test_loss <span class="token operator">/=</span> num_batches

    <span class="token keyword">return</span> test_acc<span class="token punctuation">,</span> test_loss

</code></pre> 
<h4><a id="234__806"></a>2.3.4 正式训练</h4> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""训练模型--正式训练"""</span>
epochs <span class="token operator">=</span> <span class="token number">10</span>
train_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
train_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
test_acc <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
best_test_acc<span class="token operator">=</span><span class="token number">0</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    milliseconds_t1 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span>

    <span class="token comment"># 更新学习率（使用自定义学习率时使用）</span>
    <span class="token comment"># adjust_learning_rate(lr_opt, epoch, learn_rate)</span>

    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_train_acc<span class="token punctuation">,</span> epoch_train_loss <span class="token operator">=</span> train<span class="token punctuation">(</span>train_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> model_opt<span class="token punctuation">)</span>
    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 更新学习率（调用官方动态学习率接口时使用）</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>

    train_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_train_acc<span class="token punctuation">)</span>
    train_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_train_loss<span class="token punctuation">)</span>
    test_acc<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_test_acc<span class="token punctuation">)</span>
    test_loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_test_loss<span class="token punctuation">)</span>

    <span class="token comment"># 获取当前的学习率</span>
    lr <span class="token operator">=</span> lr_opt<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'param_groups'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span>

    milliseconds_t2 <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span>
    template <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">'Epoch:{:2d}, duration:{}ms, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%，Test_loss:{:.3f}, Lr:{:.2E}'</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> best_test_acc <span class="token operator">&lt;</span> epoch_test_acc<span class="token punctuation">:</span>
        best_test_acc <span class="token operator">=</span> epoch_test_acc
        <span class="token comment">#备份最好的模型</span>
        best_model <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>model<span class="token punctuation">)</span>
        template <span class="token operator">=</span> <span class="token punctuation">(</span>
            <span class="token string">'Epoch:{:2d}, duration:{}ms, Train_acc:{:.1f}%, Train_loss:{:.3f}, Test_acc:{:.1f}%，Test_loss:{:.3f}, Lr:{:.2E},Update the best model'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>
        template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> milliseconds_t2<span class="token operator">-</span>milliseconds_t1<span class="token punctuation">,</span> epoch_train_acc <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> epoch_train_loss<span class="token punctuation">,</span> epoch_test_acc <span class="token operator">*</span> <span class="token number">100</span><span class="token punctuation">,</span> epoch_test_loss<span class="token punctuation">,</span> lr<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 保存最佳模型到文件中</span>
PATH <span class="token operator">=</span> <span class="token string">'./best_model.pth'</span>  <span class="token comment"># 保存的参数文件名</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> PATH<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Done'</span><span class="token punctuation">)</span>
</code></pre> 
<p>输出最高精度为Test_acc:100%</p> 
<pre><code>Epoch: 1, duration:74420ms, Train_acc:83.7%, Train_loss:0.902, Test_acc:85.8%，Test_loss:0.345, Lr:1.00E-04,Update the best model
Epoch: 2, duration:72587ms, Train_acc:86.4%, Train_loss:0.329, Test_acc:85.5%，Test_loss:0.343, Lr:1.00E-04
Epoch: 3, duration:72941ms, Train_acc:87.9%, Train_loss:0.292, Test_acc:89.2%，Test_loss:0.262, Lr:1.00E-04,Update the best model
Epoch: 4, duration:74155ms, Train_acc:88.8%, Train_loss:0.279, Test_acc:89.7%，Test_loss:0.248, Lr:1.00E-04,Update the best model
Epoch: 5, duration:75123ms, Train_acc:89.1%, Train_loss:0.265, Test_acc:89.0%，Test_loss:0.277, Lr:1.00E-04
Epoch: 6, duration:74381ms, Train_acc:89.6%, Train_loss:0.255, Test_acc:90.5%，Test_loss:0.249, Lr:1.00E-04,Update the best model
Epoch: 7, duration:73710ms, Train_acc:90.2%, Train_loss:0.243, Test_acc:84.1%，Test_loss:0.369, Lr:1.00E-04
Epoch: 8, duration:73995ms, Train_acc:90.7%, Train_loss:0.230, Test_acc:89.5%，Test_loss:0.250, Lr:1.00E-04
Epoch: 9, duration:73017ms, Train_acc:90.7%, Train_loss:0.223, Test_acc:89.3%，Test_loss:0.263, Lr:1.00E-04
Epoch:10, duration:73960ms, Train_acc:91.2%, Train_loss:0.224, Test_acc:91.6%，Test_loss:0.209, Lr:1.00E-04,Update the best model
Epoch:11, duration:74113ms, Train_acc:91.2%, Train_loss:0.219, Test_acc:90.5%，Test_loss:0.225, Lr:1.00E-04
Epoch:12, duration:73573ms, Train_acc:91.5%, Train_loss:0.213, Test_acc:88.5%，Test_loss:0.273, Lr:1.00E-04
Epoch:13, duration:73206ms, Train_acc:92.2%, Train_loss:0.202, Test_acc:85.1%，Test_loss:0.377, Lr:1.00E-04
Epoch:14, duration:73540ms, Train_acc:92.1%, Train_loss:0.195, Test_acc:91.2%，Test_loss:0.225, Lr:1.00E-04
Epoch:15, duration:73378ms, Train_acc:92.3%, Train_loss:0.192, Test_acc:87.6%，Test_loss:0.796, Lr:1.00E-04
Epoch:16, duration:73195ms, Train_acc:92.5%, Train_loss:0.187, Test_acc:92.5%，Test_loss:0.197, Lr:1.00E-04,Update the best model
Epoch:17, duration:73737ms, Train_acc:93.1%, Train_loss:0.174, Test_acc:92.7%，Test_loss:0.186, Lr:1.00E-04,Update the best model
Epoch:18, duration:73884ms, Train_acc:93.4%, Train_loss:0.171, Test_acc:80.6%，Test_loss:0.463, Lr:1.00E-04
Epoch:19, duration:73239ms, Train_acc:93.2%, Train_loss:0.168, Test_acc:91.2%，Test_loss:0.221, Lr:1.00E-04
Epoch:20, duration:73386ms, Train_acc:93.7%, Train_loss:0.159, Test_acc:92.5%，Test_loss:0.196, Lr:1.00E-04
</code></pre> 
<h3><a id="24__879"></a>2.4 结果可视化</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""训练模型--结果可视化"""</span>
epochs_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test Accuracy'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Accuracy'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> test_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Test Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/3f/c4/aDAA3uzo_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24__904"></a>2.4 指定图片进行预测</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">predict_one_image</span><span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> model<span class="token punctuation">,</span> transform<span class="token punctuation">,</span> classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    test_img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>test_img<span class="token punctuation">)</span>  <span class="token comment"># 展示预测的图片</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

    test_img <span class="token operator">=</span> transform<span class="token punctuation">(</span>test_img<span class="token punctuation">)</span>
    img <span class="token operator">=</span> test_img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>

    _<span class="token punctuation">,</span> pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>output<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    pred_class <span class="token operator">=</span> classes<span class="token punctuation">[</span>pred<span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'预测结果是：</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>pred_class<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
 
<span class="token comment"># 将参数加载到model当中</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>PATH<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">"""指定图片进行预测"""</span>
classes <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>total_data<span class="token punctuation">.</span>class_to_idx<span class="token punctuation">)</span>
<span class="token comment"># 预测训练集中的某张照片</span>
predict_one_image<span class="token punctuation">(</span>image_path<span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">(</span>Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token string">"Cockatoo/001.jpg"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                  model<span class="token operator">=</span>model<span class="token punctuation">,</span>
                  transform<span class="token operator">=</span>train_transforms<span class="token punctuation">,</span>
                  classes<span class="token operator">=</span>classes<span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/a1/e1/UcXcQcGZ_o.png" alt="在这里插入图片描述"></p> 
<p>输出</p> 
<pre><code>预测结果是：0
</code></pre> 
<h3><a id="26__944"></a>2.6 模型评估</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""模型评估"""</span>
best_model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss <span class="token operator">=</span> test<span class="token punctuation">(</span>test_dl<span class="token punctuation">,</span> best_model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">)</span>
<span class="token comment"># 查看是否与我们记录的最高准确率一致</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>epoch_test_acc<span class="token punctuation">,</span> epoch_test_loss<span class="token punctuation">)</span>


</code></pre> 
<p>输出</p> 
<pre><code>预测结果是：0
0.9268929503916449 0.185508520431107

</code></pre> 
<h2><a id="3__961"></a>3 知识点详解</h2> 
<h3><a id="31_nnSequentialnnModule_962"></a>3.1 nn.Sequential和nn.Module区别与选择</h3> 
<h4><a id="311_nnSequential_963"></a>3.1.1 nn.Sequential</h4> 
<p>torch.nn.Sequential是一个Sequential容器，模块将按照构造函数中传递的顺序添加到模块中。另外，也可以传入一个有序模块。 为了更容易理解，官方给出了一些案例：</p> 
<pre><code class="prism language-python"><span class="token comment"># Sequential使用实例</span>

model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

<span class="token comment"># Sequential with OrderedDict使用实例</span>
model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
          <span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token string">'relu1'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
          <span class="token punctuation">(</span><span class="token string">'relu2'</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="312_nnModule_985"></a>3.1.2 nn.Module</h4> 
<p>下面我们再用 Module 定义这个模型，下面是使用 Module 的模板</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> 网络名字<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> 一些定义的参数<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>网络名字<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_input<span class="token punctuation">,</span> num_hidden<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

        定义需要用的网络层

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 定义前向传播</span>
        x1 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x2 <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> x1 <span class="token operator">+</span> x2
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token keyword">return</span> x
</code></pre> 
<p>注意的是，Module 里面也可以使用 Sequential，同时 Module 非常灵活，具体体现在 forward 中，如何复杂的操作都能直观的在 forward 里面执行</p> 
<h4><a id="313__1011"></a>3.1.3 对比</h4> 
<p>为了方便比较，我们先用普通方法搭建一个神经网络。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> n_feature<span class="token punctuation">,</span> n_hidden<span class="token punctuation">,</span> n_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_feature<span class="token punctuation">,</span> n_hidden<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>predict <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_hidden<span class="token punctuation">,</span> n_output<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
net1 <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

net2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<p>打印这两个net</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>net1<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
Net (
  (hidden): Linear (1 -&gt; 10)
  (predict): Linear (10 -&gt; 1)
)
"""</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>net2<span class="token punctuation">)</span>
<span class="token triple-quoted-string string">"""
Sequential (
  (0): Linear (1 -&gt; 10)
  (1): ReLU ()
  (2): Linear (10 -&gt; 1)
)
"""</span>
</code></pre> 
<p>我们可以发现，打印torch.nn.Sequential会自动加入激励函数,<br> 在 net1 中, 激励函数实际上是在 forward() 功能中被调用的,没有在init中定义,所以在打印网络结构时不会有激励函数的信息.</p> 
<p>解析源码,在torch.nn.Sequential中:</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> module <span class="token keyword">in</span> self<span class="token punctuation">:</span>
        <span class="token builtin">input</span> <span class="token operator">=</span> module<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token builtin">input</span>
</code></pre> 
<p>可以看到,torch.nn.Sequential的forward只是简单的顺序传播,操作性有限.</p> 
<h4><a id="314__1069"></a>3.1.4 总结</h4> 
<p>使用torch.nn.Module，我们可以根据自己的需求改变传播过程，如RNN等<br> 如果你需要快速构建或者不需要过多的过程，直接使用torch.nn.Sequential即可。</p> 
<p>参考链接：<a href="https://blog.csdn.net/ftimes/article/details/105100522">nn.Sequential和nn.Module区别与选择</a></p> 
<h3><a id="32_pythonOrderedDict_1075"></a>3.2 python中OrderedDict的使用</h3> 
<p>很多人认为python中的字典是无序的，因为它是按照hash来存储的，但是python中有个模块collections(英文，收集、集合)，里面自带了一个子类</p> 
<p>OrderedDict，实现了对字典对象中元素的排序。请看下面的实例：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> collections
<span class="token keyword">print</span> <span class="token string">"Regular dictionary"</span>
d<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
d<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'A'</span>
d<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'B'</span>
d<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'C'</span>
<span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> d<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span> k<span class="token punctuation">,</span>v

<span class="token keyword">print</span> <span class="token string">"\nOrder dictionary"</span>
d1 <span class="token operator">=</span> collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
d1<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'A'</span>
d1<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'B'</span>
d1<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'C'</span>
d1<span class="token punctuation">[</span><span class="token string">'1'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'1'</span>
d1<span class="token punctuation">[</span><span class="token string">'2'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'2'</span>
<span class="token keyword">for</span> k<span class="token punctuation">,</span>v <span class="token keyword">in</span> d1<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span> k<span class="token punctuation">,</span>v
</code></pre> 
<p>输出：</p> 
<pre><code class="prism language-python">Regular dictionary
a A
c C
b B

Order dictionary
a A
b B
c C
<span class="token number">1</span> <span class="token number">1</span>
<span class="token number">2</span> <span class="token number">2</span>
</code></pre> 
<p>可以看到，同样是保存了ABC等几个元素，但是使用OrderedDict会根据放入元素的先后顺序进行排序。所以输出的值是排好序的。</p> 
<p>OrderedDict对象的字典对象，如果其顺序不同那么Python也会把他们当做是两个不同的对象，请看事例：</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span> <span class="token string">'Regular dictionary:'</span>
d2<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
d2<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'A'</span>
d2<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'B'</span>
d2<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'C'</span>

d3<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
d3<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'C'</span>
d3<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'A'</span>
d3<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'B'</span>

<span class="token keyword">print</span> d2 <span class="token operator">==</span> d3

<span class="token keyword">print</span> <span class="token string">'\nOrderedDict:'</span>
d4<span class="token operator">=</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
d4<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'A'</span>
d4<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'B'</span>
d4<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'C'</span>

d5<span class="token operator">=</span>collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span><span class="token punctuation">)</span>
d5<span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'C'</span>
d5<span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'A'</span>
d5<span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token string">'B'</span>

<span class="token keyword">print</span>  d1<span class="token operator">==</span>d2

输出：
Regular dictionary<span class="token punctuation">:</span>
<span class="token boolean">True</span>

OrderedDict<span class="token punctuation">:</span>
<span class="token boolean">False</span>
</code></pre> 
<p>再看几个例子：</p> 
<pre><code class="prism language-python">dd <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'banana'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token string">'apple'</span><span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token string">'pear'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'orange'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">}</span>
<span class="token comment">#按key排序</span>
kd <span class="token operator">=</span> collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>dd<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span> t<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> kd
<span class="token comment">#按照value排序</span>
vd <span class="token operator">=</span> collections<span class="token punctuation">.</span>OrderedDict<span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>dd<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> t<span class="token punctuation">:</span>t<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> vd

<span class="token comment">#输出</span>
OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'apple'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'banana'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'orange'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'pear'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'pear'</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'orange'</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'banana'</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'apple'</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="_1173"></a>总结</h2> 
<p>  数据量越大，训练时间越长，在DataLoader中增加num_workers，即增加线程数量，可能会导致内存不足出现，Couldn‘t open shared file mapping或者Out of memery的错误，可尝试减小num_corkers。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e1b1b02c4bb4ece7e67c56bfab6aa670/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">如何借助于AI自研一款换脸app</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a4ca4508bb55393623d8758db0beae03/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">轻松掌握NVM安装与使用：提升Node.js管理效率的实用指南</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>