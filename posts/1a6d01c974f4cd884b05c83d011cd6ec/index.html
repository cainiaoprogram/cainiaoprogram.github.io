<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>特征归一化及其原理--机器学习 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="特征归一化及其原理--机器学习" />
<meta property="og:description" content="归一化是数据预处理中的一种常见操作，其目的是将不同特征的数值范围统一或缩放到相似的尺度。这有助于提高模型的性能，加速模型的收敛，并使模型更加稳健。以下是进行归一化的一些原因和原理：
消除特征间的尺度差异：
不同特征可能具有不同的数值范围，例如身高和体重。在一些机器学习算法中，如果特征的尺度差异较大，可能导致某些特征对模型的贡献比其他特征更大，从而影响模型的性能。通过归一化，可以使所有特征具有相似的尺度，避免尺度差异带来的问题。
加速模型收敛：
在一些迭代优化算法中，如梯度下降，特征的尺度差异可能导致收敛速度变慢。归一化可以加速收敛过程，使优化算法更快地找到最优解。
提高模型的稳健性：
归一化可以提高模型对输入数据的稳健性。如果某个特征的数值范围变化较大，模型可能更容易受到噪声或异常值的影响。通过归一化，模型对于输入数据中的变化更为鲁棒。
改善模型的可解释性：
归一化可以使模型的系数更容易解释。在某些线性模型中，系数的大小可以反映特征对输出的贡献程度。如果特征具有不同的尺度，解释模型系数就会变得更加困难。
常见的归一化方法包括：
线性函数归一化 Min-Max Scaling：它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。
X normalized = X − X min X max − X min X_{\text{normalized}} = \frac{X - X_{\text{min}}}{X_{\text{max}} - X_{\text{min}}} Xnormalized​=Xmax​−Xmin​X−Xmin​​
将数据缩放到[0, 1]的范围内。
零均值归一化 Z-Score Normalization（标准化）：它会将原始数据映射到均值为 0、标准差为1的分布上。
X normalized = X − μ σ X_{\text{normalized}} = \frac{X - \mu}{\sigma} Xnormalized​=σX−μ​
将数据转换为均值为0，标准差为1的正态分布。
Robust Scaling：
X normalized = X − Q1 Q3 − Q1 X_{\text{normalized}} = \frac{X - \text{Q1}}{\text{Q3} - \text{Q1}} Xnormalized​=Q3−Q1X−Q1​" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/1a6d01c974f4cd884b05c83d011cd6ec/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T10:11:13+08:00" />
<meta property="article:modified_time" content="2023-12-29T10:11:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">特征归一化及其原理--机器学习</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>归一化是数据预处理中的一种常见操作，其<mark>目的是将不同特征的数值范围统一或缩放到相似的尺度</mark>。这有助于<strong>提高模型的性能</strong>，<strong>加速模型的收敛</strong>，<strong>并使模型更加稳健</strong>。以下是进行归一化的一些原因和原理：</p> 
<p><strong>消除特征间的尺度差异：</strong><br> 不同特征可能具有不同的数值范围，例如身高和体重。在一些机器学习算法中，如果特征的尺度差异较大，可能导致某些特征对模型的贡献比其他特征更大，从而影响模型的性能。通过归一化，可以使所有特征具有相似的尺度，避免尺度差异带来的问题。</p> 
<p><strong>加速模型收敛：</strong><br> 在一些迭代优化算法中，如<strong>梯度下降，特征的尺度差异可能导致收敛速度变慢</strong>。归一化可以加速收敛过程，使优化算法更快地找到最优解。<br> <img src="https://images2.imgbox.com/e1/78/xOfL2cpE_o.png" alt="在这里插入图片描述"></p> 
<p><strong>提高模型的稳健性：</strong><br> <mark>归一化可以提高模型对输入数据的稳健性</mark>。如果某个特征的数值范围变化较大，模型可能更容易受到噪声或异常值的影响。通过归一化，模型对于输入数据中的变化更为鲁棒。</p> 
<p><strong>改善模型的可解释性：</strong><br> 归一化可以使模型的系数更容易解释。在某些线性模型中，系数的大小可以反映特征对输出的贡献程度。如果特征具有不同的尺度，解释模型系数就会变得更加困难。</p> 
<p><strong>常见的归一化方法包括：</strong></p> 
<p><strong>线性函数归一化 Min-Max Scaling：它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。</strong></p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          normalized 
         
        
       
         = 
        
        
         
         
           X 
          
         
           − 
          
          
          
            X 
           
          
            min 
           
          
         
         
          
          
            X 
           
          
            max 
           
          
         
           − 
          
          
          
            X 
           
          
            min 
           
          
         
        
       
      
        X_{\text{normalized}} = \frac{X - X_{\text{min}}}{X_{\text{max}} - X_{\text{min}}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">normalized</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.3335em; vertical-align: -0.4451em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8884em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: -0.0785em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">max</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.334em;"><span class="" style="top: -2.357em; margin-left: -0.0785em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.4101em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">X</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.334em;"><span class="" style="top: -2.357em; margin-left: -0.0785em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">min</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4451em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p> 
<p>将数据缩放到[0, 1]的范围内。</p> 
<p><strong>零均值归一化 Z-Score Normalization（标准化）：它会将原始数据映射到均值为 0、标准差为1的分布上。</strong></p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          normalized 
         
        
       
         = 
        
        
         
         
           X 
          
         
           − 
          
         
           μ 
          
         
        
          σ 
         
        
       
      
        X_{\text{normalized}} = \frac{X - \mu}{\sigma} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">normalized</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.2694em; vertical-align: -0.345em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9244em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">σ</span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.4461em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">X</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight">μ</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p> 
<p>将数据转换为均值为0，标准差为1的正态分布。</p> 
<p><strong>Robust Scaling：</strong></p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          X 
         
        
          normalized 
         
        
       
         = 
        
        
         
         
           X 
          
         
           − 
          
         
           Q1 
          
         
         
         
           Q3 
          
         
           − 
          
         
           Q1 
          
         
        
       
      
        X_{\text{normalized}} = \frac{X - \text{Q1}}{\text{Q3} - \text{Q1}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0785em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.0785em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">normalized</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.4055em; vertical-align: -0.4811em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9244em;"><span class="" style="top: -2.655em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Q3</span></span><span class="mbin mtight">−</span><span class="mord text mtight"><span class="mord mtight">Q1</span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.4461em;"><span class="pstrut" style="height: 3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0785em;">X</span><span class="mbin mtight">−</span><span class="mord text mtight"><span class="mord mtight">Q1</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4811em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p> 
<p>使用四分位数范围，对异常值更具鲁棒性。</p> 
<p>归一化的选择取决于数据的性质以及模型的需求。在实际应用中，根据问题的具体情况选择合适的归一化方法。</p> 
<hr> 
<p>以下是<mark>一些面试可能出现的相关问题</mark>以及可能的回答：</p> 
<p><strong>什么是归一化？为什么需要进行归一化？</strong></p> 
<p><strong>回答：</strong><br> <mark>归一化是将不同特征的数值范围统一或缩放到相似的尺度的过程</mark>。它<strong>有助于消除特征间的尺度差异</strong>，<strong>加速模型收敛</strong>，<strong>提高模型的稳健性</strong>，<strong>改善模型的可解释性</strong>。</p> 
<p><strong>常见的归一化方法有哪些？请简要描述其中一种方法的原理。</strong></p> 
<p><strong>回答：</strong><br> 常见的归一化方法包括Min-Max Scaling、Z-Score Normalization和Robust Scaling。以Min-Max Scaling为例，它的原理是将数据缩放到[0, 1]的范围内，通过减去最小值并除以范围（最大值减最小值）来实现。</p> 
<p><strong>为什么在某些机器学习算法中需要进行特征缩放？</strong></p> 
<p><strong>回答：</strong><br> 在某些机器学习算法中，如梯度下降，特征的尺度差异可能导致收敛速度变慢，某些特征对模型的贡献更大，影响模型的性能。通过特征缩放，可以消除这些尺度差异，加速收敛过程，提高模型的性能。</p> 
<p><strong>在什么情况下选择使用Z-Score Normalization 而不是 Min-Max Scaling？</strong></p> 
<p><strong>回答：</strong><br> Z-Score Normalization通常适用于数据分布近似正态的情况，将数据转换为均值为0，标准差为1的正态分布。Min-Max Scaling适用于数据分布未知或接近均匀分布的情况。选择取决于数据的分布特性和模型对特征尺度的敏感程度。</p> 
<p><strong>为什么在使用K均值聚类算法时需要进行归一化？</strong></p> 
<p><strong>回答：</strong><br> K均值聚类算法使用样本间的距离来划分簇，如果特征的尺度差异较大，将导致距离的计算被某些特征主导。通过归一化，可以确保每个特征对距离的贡献相对均匀，提高K均值聚类的效果。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c6bcf66217b5ef47014835b428c89dd8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">清华大学刘永进教授课题组提出基于便携式家用级别脑电设备的情绪识别新方法...</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4d30b449148aa14f6ec15f72233d3c6a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Vue模板编译</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>