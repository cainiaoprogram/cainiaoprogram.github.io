<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用CentOS6.8搭建Hadoop集群 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用CentOS6.8搭建Hadoop集群" />
<meta property="og:description" content="概述： 集群cluster，能将很多进程分布到多台计算机上；通过联合使用多台计算机的存储、计算资源完成更庞大的任务。
为了实现无限量的存储和计算能力，在生产环境中必须使用集群来满足需求。
注意事项： 1)集群中的计算机在时间上要同步，系统时间不能差太多（约30秒内），如果设置时间后重启时间又不准确了（可能是主板电池老化），可以启用NTP（Network Time Protocol网络时间协议）服务解决（CentOS7安装时就可以设置自动同步）。
2)集群中的计算机在网络上能够相互访问
i.虚拟机的网络使用NAT模式
ii.固定IP，要规划好IP地址和主机名（）
iii.全部关闭防火墙
iv.全部实现Hosts解析
v.全部实现免密码SSH访问（可以统一密钥对）
-.NameNode-对应的是-master、DataNode-对应的是-slave
--前提：安装三个虚拟机（内存最好在8~13G）,分别作为master、slave1、slave2
记住三个虚拟机的名字和IP
1.安装JDK 如果安装的是minimal（最小版），跳过卸载直接去下载安装，如果安装的不是minimal（最小版），那么你需要卸除原有的JDK。
1.1卸载非LinuxJDK
卸载OpenJDK（最小化安装不带Open JDK）
Gnome桌面版自带OpenJDK，OpenJDK是JDK的一个开源实现
与Oracle官方JDK相似度近95%，一般情况下可以使用
但大数据的Hadoop不支持OpenJDK
通过rpm查找jdk和java的安装信息
rpm是RedHat包管理器，包管理器能够管理应用的安装卸载
类似于Maven管理Jar包
rpm -qa | grep jdk
java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64 java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64 java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64 java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64 卸载
对于如上的每一行输出，都调用rpm -e --nodeps，如（：
rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64
-e 表示卸载
--nodeps 表示不考虑是否有依赖问题，强制卸载
1.2下载：
上浏览器上下载linuxJDK压缩包（搜索Linux JDK 64）
提示路径：http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz
或者温馨jdk链接：https://pan.baidu.com/s/1Yg7Nwp-JQSC7eNDDe2uaaA 提取码：mjnk
1.3：将JDK压缩包上传到虚拟机的 ~/
解压提取 tar zxvf jdk….tar.gz
将得到的jdk1.8…移动到/usr/local/中
mv jdk1.8…/ /usr/local/jdk
1.4配置环境变量
vi /etc/profile 在/etc/profile的最后添加如下内容" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/8d7aa3e728fa1e3dcae3550d975e03c0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-09-29T09:23:28+08:00" />
<meta property="article:modified_time" content="2018-09-29T09:23:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用CentOS6.8搭建Hadoop集群</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3><strong>概述</strong>：</h3> 
<p>集群cluster，能将很多进程分布到多台计算机上；通过联合使用多台计算机的存储、计算资源完成更庞大的任务。<br> 为了实现无限量的存储和计算能力，在生产环境中必须使用集群来满足需求。</p> 
<h3><br> 注意事项：</h3> 
<p><br> 1)集群中的计算机在<span style="color:#f33b45;">时间上要同步</span>，系统时间不能差太多（约30秒内），如果设置时间后重启时间又不准确了（可能是主板电池老化），可以启用<span style="color:#f33b45;">NTP</span>（Network Time Protocol网络时间协议）服务解决（CentOS7安装时就可以设置自动同步）。<br> 2)集群中的计算机在网络上能够<span style="color:#f33b45;">相互访问</span><br> i.虚拟机的网络使用NAT模式<br> ii.固定IP，要规划好IP地址和主机名（）<br> iii.全部<span style="color:#f33b45;">关闭防火墙</span><br> iv.全部实现<span style="color:#f33b45;">Hosts</span>解析<br> v.全部实现<span style="color:#f33b45;">免密码</span>SSH访问（可以统一密钥对）<br> -.NameNode-对应的是-master、DataNode-对应的是-slave<br> --前提：安装三个虚拟机（内存最好在8~13G）,分别作为master、slave1、slave2<br> 记住三个虚拟机的名字和IP<br>  <strong>1.安装JDK</strong><strong> </strong></p> 
<p><strong>如果安装的是minimal（最小版），<span style="color:#f33b45;">跳过卸载直接去下载安装</span></strong>，如果安装的不是minimal（最小版），那么你需要卸除原有的JDK。<br> 1.1卸载非LinuxJDK<br> 卸载OpenJDK（最小化安装不带Open JDK）<br>     Gnome桌面版自带OpenJDK，OpenJDK是JDK的一个开源实现<br> 与Oracle官方JDK相似度近95%，一般情况下可以使用<br> 但大数据的Hadoop不支持OpenJDK<br>     通过rpm查找jdk和java的安装信息<br>         rpm是RedHat包管理器，包管理器能够管理应用的安装卸载<br> 类似于Maven管理Jar包<br> rpm -qa | grep jdk</p> 
<pre class="has"><code class="language-html">java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64
java-1.8.0-openjdk-headless-1.8.0.102-4.b14.el7.x86_64
java-1.7.0-openjdk-headless-1.7.0.111-2.6.7.8.el7.x86_64
java-1.7.0-openjdk-1.7.0.111-2.6.7.8.el7.x86_64</code></pre> 
<p><br> 卸载<br> 对于如上的每一行输出，都调用rpm -e --nodeps，如（：<br> rpm -e --nodeps java-1.8.0-openjdk-1.8.0.102-4.b14.el7.x86_64<br>   <span style="color:#f33b45;">  -e 表示卸载<br>     --nodeps 表示不考虑是否有依赖问题，强制卸载</span></p> 
<p>1.2<span style="color:#f33b45;">下载</span>：<br> 上浏览器上下载linuxJDK压缩包（搜索Linux JDK 64）<br> 提示路径：http://download.oracle.com/otn-pub/java/jdk/8u181-b13/96a7b8442fe848ef90c96a2fad6ed6d1/jdk-8u181-linux-x64.tar.gz</p> 
<p>或者温馨jdk链接：https://pan.baidu.com/s/1Yg7Nwp-JQSC7eNDDe2uaaA 提取码：mjnk<br> 1.3：将JDK压缩包<span style="color:#f33b45;">上传</span>到虚拟机的 ~/<br><span style="color:#f33b45;">解压</span>提取 tar zxvf jdk….tar.gz<br> 将得到的jdk1.8…移动到/usr/local/中<br> mv jdk1.8…/ /usr/local/jdk<br> 1.4配置<span style="color:#f33b45;">环境变量</span></p> 
<pre class="has"><code class="language-html">vi /etc/profile</code></pre> 
<p><br> 在/etc/profile的最后<span style="color:#f33b45;">添加</span>如下内容</p> 
<pre class="has"><code class="language-html">#JDK1.8
JAVA_HOME=/usr/local/jdk
JRE_HOME=/usr/local/jdk/jre
CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib
PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin
export JAVA_HOME JRE_HOME CLASSPATH PATH    </code></pre> 
<p><br> 保存（<span style="color:#f33b45;">i</span> 进入编辑模式   <span style="color:#f33b45;">ESC</span> 退出编译模式 <span style="color:#f33b45;">:wq</span> 保存并退出   <span style="color:#f33b45;"> :q!</span> 退出不保存）<br> 然后刷新环境变量<br>  </p> 
<pre class="has"><code class="language-html">source /etc/profile</code></pre> 
<p><br> 注意：上面的环境变量<span style="color:#f33b45;">JAVA_HOME=</span>这边填写的是你JDK的位置（路径）<br> -----<span style="color:#f33b45;">-测试</span>JDK安装是否成功</p> 
<pre class="has"><code class="language-bash">java -version</code></pre> 
<p><img alt="" class="has" height="80" src="https://images2.imgbox.com/cb/2f/5jJedaq7_o.png" width="534"></p> 
<p>----------------------------安装<span style="color:#f33b45;">Hadoop</span>---------------------<br><strong>1.安装Hadoop</strong><br> 到Hadoop官方下载 hadoop-xxx.tar.gz（选择稳定版）</p> 
<p>温馨Hadoop链接：https://pan.baidu.com/s/1uAfgrBQaz6ST7_iPl4tcTw 提取码：cn8w  （本版本2.7.5）<br> 上传到<span style="color:#f33b45;">master</span>虚拟机上的 ~/<br><span style="color:#f33b45;">解压</span>提取 tar zxvf hadoop-xxx.tar.gz<br> 将得到的hadoop-xxx…移动到/usr/local/hadoop中（可以不移动，但是在配置关于路径的配置文件时，注意路径）<br><strong>2.配置Hadoop</strong><br> 打开 vi /etc/profile，在最后添加</p> 
<pre class="has"><code class="language-bash">#Hadoop
export HADOOP_HOME=/usr/local/hadoop
export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH</code></pre> 
<p>执行source /etc/hadoop更新环境变量<br> -------------<br><strong>3.关于搭建Hadoop集群的配置</strong><br> 首先--进入<span style="color:#f33b45;">/usr/local/hadoop/etc/hadoop</span><br> 1.打开<span style="color:#f33b45;">hadoop-env.sh</span>指定<span style="color:#f33b45;">JDK</span>位置</p> 
<pre class="has"><code class="language-bash"> # The java implementation to use.
   export JAVA_HOME=JDK位置</code></pre> 
<p>2.打开<span style="color:#f33b45;">core-site.xml</span><strong>指定<span style="color:#f33b45;">NameNode</span></strong><br>   </p> 
<pre class="has"><code class="language-html">  &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://master:9000&lt;/value&gt;
    &lt;/property&gt;</code></pre> 
<p><br> --<span style="color:#f33b45;">master</span>：表示NameNode（根据自己的master名字自己改变），<span style="color:#f33b45;">9000</span>：表示端口号（不用改变就行）</p> 
<p>3.打开<span style="color:#f33b45;">hdfs-site.xml</span><strong>指定<span style="color:#f33b45;">SecondaryNameNode</span>，关闭权限检查</strong><br>   </p> 
<pre class="has"><code class="language-html"> &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;hdfs://master:50090&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
            &lt;name&gt;dfs.permissions.enabled&lt;/name&gt;
            &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;</code></pre> 
<p><br> -----------这里的master与上面的意思一样<br>     <br> 4.打开<span style="color:#f33b45;">slaves</span>文件，<strong>指定担任<span style="color:#f33b45;">DataNode</span>的主机</strong><br>       </p> 
<pre class="has"><code class="language-bash">        master            #让master同时成为datanode，生产环境不需要！
        slave1
        slave2</code></pre> 
<p><br><span style="color:#f33b45;">Slaves</span>文件的作用是当使用<span style="color:#f33b45;">start-dfs.sh启动HDFS时</span>，会自动将各个<span style="color:#f33b45;">datanode</span>节点自动启动起来。<br> 5.vi /etc/hosts<br> Hosts的作用是<span style="color:#f33b45;">可以在网络使用名字替换IP地址</span>，添加文件内容如下：</p> 
<pre class="has"><code class="language-bash">192.168.2.10                master
192.168.2.11                slaves1
192.168.2.12                slaves2</code></pre> 
<p> </p> 
<p>6.将master的/etc/hosts<span style="color:#f33b45;">分发</span>到各个节点（master是根节点）<br> 再分发之前<span style="color:#f33b45;">安装scp（每个节点都要安装）</span>,如果不安装会出现以下错误<br> 结果提示：</p> 
<pre class="has"><code class="language-bash">-bash: scp: command not found</code></pre> 
<p>想当然用<span style="color:#f33b45;">yum install scp</span>命令安装，<br> 结果提示：</p> 
<pre class="has"><code class="language-bash">No package scp available.</code></pre> 
<p>后来发现scp这东西应该属于<span style="color:#f33b45;">openssh-clients</span>这个包，<br> 运行：</p> 
<p><span style="color:#f33b45;">yum -y install openssh-clients </span> （注：两台机器都需要安装）<br> --现在<span style="color:#f33b45;">发布</span></p> 
<pre class="has"><code class="language-bash">scp /etc/hosts root@slaveXX :/etc/hosts</code></pre> 
<p><br> 注意<span style="color:#f33b45;">slaveXX</span>表示slave1、slave2…，每个节点都要分发<br><strong>7.节点直接免密登录</strong><br> ---------在<span style="color:#f33b45;">NameNode（master）</span>上使用<span style="color:#f33b45;">ssh-keygen</span>命令生成密钥对（可以不看）<br> 1.先运行一下ssh命令，查看<span style="color:#f33b45;">是否能用</span><br> ssh</p> 
<p><img alt="" class="has" height="152" src="https://images2.imgbox.com/2b/27/xJoYKcaY_o.png" width="651"><br> 2.生成密钥对（一路回车，如果已经有了，直接使用现有的）</p> 
<pre class="has"><code class="language-bash">ssh-keygen    </code></pre> 
<p><br> 3.（<span style="color:#f33b45;">介绍</span>）生成的密钥对在~/.ssh中，分别是：<br> id_rsa                    #私钥<br> id_rsa.pub                #公钥~</p> 
<p>4.<span style="color:#f33b45;">发送</span>公钥使之免密码<br> 在NameNode上将本地的公钥发送给所有节点（包括自己），之后就可以不用输入密码登陆</p> 
<pre class="has"><code class="language-bash">ssh-copy-id slaveXX</code></pre> 
<p><br> 注意slaveXX表示master、slave1、slave2…<br> 5.发布<span style="color:#f33b45;">配置</span>到DataNode（slave），这样就可以不用配置和安装JDK与Hadoop--------<br> 分发<span style="color:#f33b45;">JDK</span><br>     scp -r /usr/local/jdk root@slaveXX:/usr/local<br> 分发<span style="color:#f33b45;">Hadoop</span><br>     scp -r /usr/local/hadoop root@slaveXX:/usr/local<br> 分发<span style="color:#f33b45;">/etc/profile</span><br>     scp /etc/profile root@slaveXX:/etc/<br> 注意要在每个节点上执行source /etc/profile<br> --------------------启动--------------------------<br> 1.<span style="color:#f33b45;">格式化</span>（初始化）<br> 在<span style="color:#f33b45;">namenode</span>上运行<br>   </p> 
<pre class="has"><code class="language-bash">  hdfs namenode -format</code></pre> 
<p><br> -<strong>-注意</strong>：每次格式化，都会在每个节点上（包括自己）的/tmp/中创建 hadoop-root<br> 重启再格式化<br> stop-all.sh关闭<br> start-all.sh开启<br> 2.<span style="color:#f33b45;">启动</span><br> 在<span style="color:#f33b45;">namenode</span>上运行<br>     </p> 
<pre class="has"><code class="language-bash">start-dfs.sh</code></pre> 
<p><br> ----检查启动<span style="color:#f33b45;">结果</span></p> 
<p><img alt="" class="has" height="129" src="https://images2.imgbox.com/64/9b/wPOiRdvK_o.png" width="721"><br> 【1】用<span style="color:#f33b45;">JPS</span>查看Java进程</p> 
<p><img alt="" class="has" height="82" src="https://images2.imgbox.com/51/06/j12XOMcM_o.png" width="442"></p> 
<pre class="has"><code class="language-bash">NameNode                 #NameNode启动了，NameNode上要有此进程
DataNode                #DataNode启动了，DataNode上要有此进程
SecondaryNameNode            #SecondaryNameNode启动了</code></pre> 
<p><br> #这个是SecondaryNameNode上的辅助进程</p> 
<p>【2】用master（或者master的IP）:50070查看Hadoop站点，检查各个节点是否启动，如下图</p> 
<p><img alt="" class="has" height="588" src="https://images2.imgbox.com/ec/50/i9S370BC_o.png" width="1200"></p> 
<p>【3】用命令测试，检查HDFS是否工作正常<br> hdfs dfs -mkdir /abc<br> hdfs dfs -ls /</p> 
<p>-----------------------------温馨提示-------------------------------</p> 
<p>1.查看及修改主机名<br> 1.1<span style="color:#f33b45;">查看</span>主机名</p> 
<pre class="has"><code class="language-cpp">hostname</code></pre> 
<p><br> 1.2修改主机名（通常不需要）</p> 
<pre class="has"><code class="language-bash">vi /etc/sysconfig/network</code></pre> 
<p>内容如下，<span style="color:#f33b45;">HOSTNAME</span>对应的就是主机名 </p> 
<pre class="has"><code class="language-bash">NETWORKING=yes
HOSTNAME=s1</code></pre> 
<p><br> ---上面操作之后，<span style="color:#f33b45;">重启Linux</span><br> reboot</p> 
<p>2.重启网络服务</p> 
<pre class="has"><code class="language-bash">service network restart</code></pre> 
<p><br> 3.网络时间同步<br> 3.1下载ntpdate </p> 
<pre class="has"><code class="language-cpp"> yum -y install ntpdate</code></pre> 
<p><br> 3.2同步时间</p> 
<pre class="has"><code class="language-bash"> ntpdate ntp.api.bz</code></pre> 
<p><br> 4..启动出现节点缺少进程，<span style="color:#f33b45;">查看日志</span>，看<span style="color:#f33b45;">是否格式化成功</span>。如果格式化没有成功<br><span style="color:#f33b45;">每个节点</span>上先执行  rm -rf /tmp/hadoop-root     <span style="color:#f33b45;">再次</span>格式化<br> 检查配置文件，防火墙，时间是否一致<br> 然后再次格式化，不允许连续格式化两次</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/67c15d97471031d190c6ab4fdb74c084/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">服务器虚拟化和桌面虚拟化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b958dfa6aa247061632d35491e897a05/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用auto-encoder实现数据压缩、分类预测</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>