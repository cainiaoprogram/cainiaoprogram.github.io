<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python 爬虫：Header 的设置 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python 爬虫：Header 的设置" />
<meta property="og:description" content="在编写爬虫的过程中，有些网站会设置反爬机制，对不是来源于浏览器的访问进行拒绝，此时我们会收到 403 错误响应码，或者收到“抱歉，无法访问“等字眼，这就需要在爬虫程序中修改请求的 headers 伪装浏览器访问，从而绕开网站的反爬机制获取正确的页面。
一、了解 requests 中 get 与 post 的 headers 参数 requests 发送的请求所带的请求头中 User-Agent 会标识为 python 程序发送的请求，如下所示：
import requests url = &#39;https://httpbin.org/headers&#39; response = requests.get(url) if response.status_code == 200: print(response.text) 在上面的代码中，倒数第二行是对服务器返回的状态代码进行判断。这里的200就是请求成功的反馈。所有的状态代码的取值一般在 100-599 之间，超出这个范围的响应状态码就不是标准的状态响应码了。[所有的状态码]可以分成 5类：
100–199：信息反馈（Informational responses）；200–299：成功反馈（Successful responses），上面的代码的 200 status code就属于这里；300–399：重定向消息（Redirection messages）；400–499：客户端错误响应（Client error responses），这个区间包含了我们常见的 403 和 404 错误响应码500–599：服务器错误响应（Server error responses） 返回结果：
注：[https://httpbin.org]是一个开源的，用于测试网页请求的网站，比如上面的/headers的链接，将会返回所发送请求的请求头。详情请参考其官网。
User-Agent: 用户代理（英语：User Agent）指的是代表用户行为的软件代理程序所提供的对自己的一个标识符。用于标识浏览器类型及版本、操作系统及版本、浏览器内核、等信息的标识。详情见维基百科词条：[User agent]
如上图所示，如果我们直接用 request 包，上来就调用 get 或者 post 方法就是干，对方的服务器会根据我们发送的**““User-Agent”: “python-requests/2.25.1””**了解到，你是用 python 调用的 request 包来访问他们的服务器的。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/20fb00c2671f4de814701b9ce99ab861/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-25T11:29:35+08:00" />
<meta property="article:modified_time" content="2023-03-25T11:29:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python 爬虫：Header 的设置</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>在编写爬虫的过程中，有些网站会设置反爬机制，对不是来源于浏览器的访问进行拒绝，此时我们会收到 403 错误响应码，或者收到“抱歉，无法访问“等字眼，这就需要在爬虫程序中修改请求的 headers 伪装浏览器访问，从而绕开网站的反爬机制获取正确的页面。</p> 
<h3><a id="_requests__get__post__headers__2"></a>一、了解 requests 中 get 与 post 的 headers 参数</h3> 
<p>requests 发送的请求所带的请求头中 User-Agent 会标识为 python 程序发送的请求，如下所示：</p> 
<pre><code class="prism language-python3"><span class="token keyword">import</span> requests

url <span class="token operator">=</span> <span class="token string">'https://httpbin.org/headers'</span>

response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">)</span>

<span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
</code></pre> 
<p>在上面的代码中，倒数第二行是对服务器返回的状态代码进行判断。这里的200就是请求成功的反馈。所有的状态代码的取值一般在 100-599 之间，超出这个范围的响应状态码就不是标准的状态响应码了。[所有的状态码]可以分成 5类：</p> 
<ul><li>100–199：信息反馈（Informational responses）；</li><li>200–299：成功反馈（Successful responses），上面的代码的 200 status code就属于这里；</li><li>300–399：重定向消息（Redirection messages）；</li><li>400–499：客户端错误响应（Client error responses），这个区间包含了我们常见的 403 和 404 错误响应码</li><li>500–599：服务器错误响应（Server error responses）</li></ul> 
<p>返回结果：</p> 
<p><img src="https://images2.imgbox.com/54/9a/4vPnBn8l_o.png" alt="img"></p> 
<blockquote> 
 <p>注：[https://httpbin.org]是一个开源的，用于测试网页请求的网站，比如上面的/headers的链接，将会返回所发送请求的请求头。详情请参考其官网。</p> 
 <p>User-Agent: 用户代理（英语：User Agent）指的是代表用户行为的软件代理程序所提供的对自己的一个标识符。用于标识浏览器类型及版本、操作系统及版本、浏览器内核、等信息的标识。详情见维基百科词条：[User agent]</p> 
</blockquote> 
<p>如上图所示，如果我们直接用 request 包，上来就调用 get 或者 post 方法就是干，对方的服务器会根据我们发送的**““User-Agent”: “python-requests/2.25.1””**了解到，你是用 python 调用的 request 包来访问他们的服务器的。</p> 
<p>由于这种行为仅仅是消耗服务器资源带来成本，但是不会给对方带来任何好处（搜索引擎的爬虫除外），所以有一些网站会加入反爬机制，通过识别 headers 来拒绝对你的请求进行响应。</p> 
<p>因此，我们需要在发送的请求中加入自定义的 headers，将我们的请求伪装成利用浏览器进行的请求。</p> 
<p>那么，浏览器在访问网站时的 headers 是什么样的呢？我们以 IE 浏览器为例，用 IE浏览器打开 [https://httpbin.org/headers]网站，将会收到网站返回的下面 json 文件，这就是 IE浏览器的 headers。</p> 
<p><img src="https://images2.imgbox.com/53/c6/5rdGKgAT_o.png" alt="img"></p> 
<p>将上面的请求头复制下来，传给 <code>requests.get()</code> 函数，即可将请求伪装成浏览器。</p> 
<p>requests.get() 的语法是：<code>requests.get(url,kwargs)</code>。</p> 
<p>其中，url 是我们想要访问的链接，kwargs 是可选参数，包括params、data、json、headers、cookies、auth、files、timeout、proxies、stream、verify、cert等。常用的参数有data、headers。</p> 
<pre><code class="prism language-python3"><span class="token keyword">import</span> requests

url <span class="token operator">=</span> <span class="token string">'https://httpbin.org/headers'</span>

headers<span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"Accept"</span><span class="token punctuation">:</span> <span class="token string">"image/gif, image/jpeg, image/pjpeg, application/x-ms-application, application/xaml+xml, application/x-ms-xbap, */*"</span><span class="token punctuation">,</span> 
    <span class="token string">"Accept-Encoding"</span><span class="token punctuation">:</span> <span class="token string">"gzip, deflate"</span><span class="token punctuation">,</span> 
    <span class="token string">"Accept-Language"</span><span class="token punctuation">:</span> <span class="token string">"zh-Hans-CN,zh-Hans;q=0.8,en-US;q=0.5,en;q=0.3"</span><span class="token punctuation">,</span> 
    <span class="token string">"Host"</span><span class="token punctuation">:</span> <span class="token string">"httpbin.org"</span><span class="token punctuation">,</span> 
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 10.0; WOW64; Trident/7.0; .NET4.0C; .NET4.0E; Tablet PC 2.0; wbx 1.0.0; wbxapp 1.0.0; Zoom 3.6.0)"</span><span class="token punctuation">,</span> 
    <span class="token string">"X-Amzn-Trace-Id"</span><span class="token punctuation">:</span> <span class="token string">"Root=1-628b672d-4d6de7f34d15a77960784504"</span><span class="token punctuation">}</span>

response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>url<span class="token punctuation">,</span>headers<span class="token operator">=</span>headers<span class="token punctuation">)</span>


<span class="token keyword">if</span> response<span class="token punctuation">.</span>status_code <span class="token operator">==</span> <span class="token number">200</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span> 
</code></pre> 
<p>返回的结果变成：</p> 
<p><img src="https://images2.imgbox.com/f7/e2/2KvPoBPP_o.png" alt="img"></p> 
<p>上图所示，虽然我们用 Python 发送的 get 请求，但是对方服务器已经认为我们是用浏览器进行访问，这一点依旧是通过上图中的 User-Agent 这个参数进行判断。</p> 
<p>此外，我们在应用爬虫的时候，可以随机更换其他 User-Agent 避免触发反爬。</p> 
<h3><a id="_headers__77"></a>二、查看浏览器 headers 的常用方法</h3> 
<p>上面说到的查看 headers 的方法不很常用，仅仅是用于教学作用。下面介绍两种更加常用的方法。</p> 
<h4><a id="_81"></a>方法一：这种方法最为常用</h4> 
<p>在Chrome浏览器的网页上：右键 ——&gt; 检查 ——&gt; Network ——&gt; Doc ——&gt; 在 Name 里找到对应的请求文件 ——&gt; 在右边选择 Headers 标签页，找到“Request Headers”，就可以看到我们发送给服务器的 headers。</p> 
<p><img src="https://images2.imgbox.com/8d/bf/oPd7IdzY_o.png" alt="img"></p> 
<p>同理，服务器在发给我们信息的时候，也会发送 Headers。我们同样在上面的选择路径，可以看到“Response Headers”。</p> 
<p><img src="https://images2.imgbox.com/5e/84/mi8nf1Ih_o.png" alt="img"></p> 
<p>例如上图中，我们可以查看到服务器响应返回的头信息知道响应结果的编码是utf-8，有的还可以看到服务器所用是apache或是其他web服务器。</p> 
<h4><a id="_93"></a>方法二：这种方法最方便，我最喜欢</h4> 
<p>当我们需要的 headers 不止 user-agent，甚至还需要 cookies 的时候，需要手动生成的东西就比较多了。那么，有没有<strong>快速一键</strong>生成 Python 爬虫请求头的方法呢？答案是借助[https://curlconverter.com/]这个网站。具体过程如下：</p> 
<p>1，在Chrome浏览器的网页上：右键 ——&gt; 检查 ——&gt; Network ——&gt; Doc ——&gt; 在 Name 里找到对应的请求文件</p> 
<p>2，右键该文件，copy ——&gt; copy as cURL (bash)，注意不是【copy as cURL (cmd)】</p> 
<p><img src="https://images2.imgbox.com/83/d4/VlMCIVt3_o.png" alt="img"></p> 
<p>3，打开网站，[https://curl.trillworks.com/]，粘贴 cURL (bash) 到<strong>左边</strong> curl command，右边会<strong>自动</strong>出 Python 代码</p> 
<p><img src="https://images2.imgbox.com/5c/fc/qIOpkoTM_o.png" alt="img"></p> 
<h4><a id="_Chrome__107"></a>方法三：对于 Chrome 浏览器</h4> 
<h4><a id="_109"></a>也可以在地址栏输入</h4> 
<pre><code class="prism language-text">about:version
</code></pre> 
<p>此时我们会看到自己的 user agent。</p> 
<p>headers中有很多内容，主要常用的就是user-agent 和 host，他们是以键对的形式展现出来，如果user-agent 以字典键对形式作为headers的内容，就可以反爬成功，就不需要其他键对；否则，需要加入headers下的更多键对形式。</p> 
<h3><a id="Headers__119"></a>三、Headers 的解读</h3> 
<h4><a id="UserAgent__121"></a>（一）User-Agent 的格式解读</h4> 
<p>User-Agent通常格式：</p> 
<p><strong>第一部分：Mozilla/5.0</strong><br> 历史原因，User-Agent里默认带有Mozilla字样。</p> 
<p><strong>第二部分：平台信息</strong><br> Windows NT 6.1是指我使用的操作系统的版本，win7对应的就是Windows NT 6.1。<br> Win64; x64是指操作系统是64位的</p> 
<p>Windows系统下：</p> 
<pre><code class="prism language-text">Windows NT 5.0 //  Windows 2000 
Windows NT 5.1 //  Windows XP
Windows NT 6.0 //  Windows Vista 
Windows NT 6.1 //  Windows 7
Windows NT 6.2 //  Windows 8
Windows NT 6.3 //  Windows 8.1
Windows NT 10.0 //  Windows 10
Win64; x64 // Win64 on x64
WOW64 // Win32 on x64
</code></pre> 
<p>Linux系统下：</p> 
<pre><code class="prism language-text">X11; Linux i686; // Linux，i686 版本
X11; Linux x86_64; // Linux，x86_64 版本
X11; Linux i686 on x86_64 // Linux， x86_64 的 i686 版本
</code></pre> 
<p>macOS系统下：</p> 
<pre><code class="prism language-text">Macintosh; Intel Mac OS X 10_9_0 // Intel x86 或者 x86_64
Macintosh; PPC Mac OS X 10_9_0 // PowerPC
Macintosh; Intel Mac OS X 10.12; // 不用下划线，用点
</code></pre> 
<p><strong>第三部分：引擎版本</strong><br> 通常默认为 AppleWebKit/537.36 (KHTML, like Gecko) …Safari/537.36</p> 
<p><strong>第四部分：浏览器版本</strong><br> 这里使用的浏览器版本为：Edg/80.0.361.54</p> 
<h4><a id="Cookie_168"></a>（二）Cookie</h4> 
<p>主要用来保存用户信息的，例如用户名、密码等。</p> 
<h4><a id="Host_172"></a>（三）Host</h4> 
<p>请求的服务器主机。</p> 
<h4><a id="Referrer_176"></a>（四）Referrer</h4> 
<p>当前页面的上一个页面，也就是在浏览器的左上角点击“后退”时会跳转到的页面。</p> 
<p><img src="https://images2.imgbox.com/4d/8d/ZND6bIn2_o.png" alt="img"></p> 
<h4><a id="_182"></a>参考文献</h4> 
<p><strong><font color="red">点此查看：</font></strong><a href="https://blog.csdn.net/weixin_55154866/article/details/129764377">Python爬虫：requests的headers该怎么填</a><br> <strong><font color="red">点此查看：</font></strong><a href="https://blog.csdn.net/weixin_55154866/article/details/129764302">Python 爬虫：requests 和 selenium 伪装 headers 和代理应对反爬机制</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/25beacd76a8d7daf39eb9a68024794ac/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">k8s管理工具</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d0a678852cfbb686f129f7f86d4ab7e3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python爬虫：HTML网页解析方法小结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>