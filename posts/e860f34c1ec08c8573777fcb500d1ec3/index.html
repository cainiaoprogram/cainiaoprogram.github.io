<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【深度学习进阶】01目标检测理论：R-CNN、Fast R-CNN、Faster R-CNN系列以及FPN结构 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【深度学习进阶】01目标检测理论：R-CNN、Fast R-CNN、Faster R-CNN系列以及FPN结构" />
<meta property="og:description" content="参考来源：太阳花的小绿豆的博客_CSDN博客-深度学习,软件安装,Tensorflow领域博主
【OpenMMLab 公开课】目标检测与 MMDetection 上
目录
1. 目标检测任务简介
1.1 早期的目标检测思路演化过程
1.2 密集预测的效率问题
2. R-CNN网络（2014年）
2.1 算法流程及存在问题
2.2 候选区生成（SS算法）
2.3 深度网络提取特征
2.4 SVM分类器
2.5 回归器修正候选框位置
2.6 R-CNN以后两阶段方法的改进思路
3. Fast R-CNN网络（2015年）
3.1 算法流程及存在问题
3.2 网络训练数据集设置
3.3 ROI Pooling层
3.4 ROI Align层
3.5 分类器以及边界框回归器
3.6 多任务损失
4. Faster R-CNN网络（2016年）
4.1 算法流程及改进之处
4.2 RPN网络
4.3 Faster R-CNN训练过程
5. FPN&#43;Faster R-CNN网络（2016年）
5.1 FPN结构亮点
5.2 FPN网络结构
5.3 FPN&#43;Faster R-CNN的预测过程
1. 目标检测任务简介 目标检测任务主要有两个问题需要解决：识别目标类别（分类），确定目标位置（回归）。分类问题很好理解，就是确定检测到的目标属于哪一类。回归问题是为了确定目标的位置，因为我们需要一个矩形框来框住所检测到的目标，这就需要调整矩形框的中心坐标以及宽和高到最优的位置，坐标点以及宽和高的变化是连续的，因此是回归问题。基于深度学习的目标检测算法主要分为两类Two Stage 和 One Stage。本文主要介绍Two、Stage算法" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e860f34c1ec08c8573777fcb500d1ec3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-22T10:39:44+08:00" />
<meta property="article:modified_time" content="2022-11-22T10:39:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【深度学习进阶】01目标检测理论：R-CNN、Fast R-CNN、Faster R-CNN系列以及FPN结构</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>参考来源：<a href="https://blog.csdn.net/qq_37541097?type=blog" title="太阳花的小绿豆的博客_CSDN博客-深度学习,软件安装,Tensorflow领域博主">太阳花的小绿豆的博客_CSDN博客-深度学习,软件安装,Tensorflow领域博主</a></p> 
<p><a class="link-info" href="https://www.bilibili.com/video/BV1Vv411A7ZM?p=3&amp;vd_source=30227f06f5820212ac44d7e3406d36e8" rel="nofollow" title="【OpenMMLab 公开课】目标检测与 MMDetection 上">【OpenMMLab 公开课】目标检测与 MMDetection 上</a></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="main-toc-toc" style="margin-left:40px;"><a href="#main-toc" rel="nofollow">1. 目标检测任务简介</a></p> 
<p id="1.1%20%E6%97%A9%E6%9C%9F%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%80%9D%E8%B7%AF%E6%BC%94%E5%8C%96%E8%BF%87%E7%A8%8B-toc" style="margin-left:80px;"><a href="#1.1%20%E6%97%A9%E6%9C%9F%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%80%9D%E8%B7%AF%E6%BC%94%E5%8C%96%E8%BF%87%E7%A8%8B" rel="nofollow">1.1 早期的目标检测思路演化过程</a></p> 
<p id="1.2%20%E5%AF%86%E9%9B%86%E9%A2%84%E6%B5%8B%E7%9A%84%E6%95%88%E7%8E%87%E9%97%AE%E9%A2%98-toc" style="margin-left:80px;"><a href="#1.2%20%E5%AF%86%E9%9B%86%E9%A2%84%E6%B5%8B%E7%9A%84%E6%95%88%E7%8E%87%E9%97%AE%E9%A2%98" rel="nofollow">1.2 密集预测的效率问题</a></p> 
<p id="2.%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882014%E5%B9%B4%EF%BC%89-toc" style="margin-left:40px;"><a href="#2.%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882014%E5%B9%B4%EF%BC%89" rel="nofollow">2. R-CNN网络（2014年）</a></p> 
<p id="2.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98-toc" style="margin-left:80px;"><a href="#2.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98" rel="nofollow">2.1 算法流程及存在问题</a></p> 
<p id="2.2%20%E5%80%99%E9%80%89%E5%8C%BA%E7%94%9F%E6%88%90-toc" style="margin-left:80px;"><a href="#2.2%20%E5%80%99%E9%80%89%E5%8C%BA%E7%94%9F%E6%88%90" rel="nofollow">2.2 候选区生成（SS算法）</a></p> 
<p id="%C2%A02.3%20%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81-toc" style="margin-left:80px;"><a href="#%C2%A02.3%20%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81" rel="nofollow">2.3 深度网络提取特征</a></p> 
<p id="2.4%20SVM%E5%88%86%E7%B1%BB%E5%99%A8-toc" style="margin-left:80px;"><a href="#2.4%20SVM%E5%88%86%E7%B1%BB%E5%99%A8" rel="nofollow">2.4 SVM分类器</a></p> 
<p id="2.5%20%E5%9B%9E%E5%BD%92%E5%99%A8%E4%BF%AE%E6%AD%A3%E5%80%99%E9%80%89%E6%A1%86%E4%BD%8D%E7%BD%AE-toc" style="margin-left:80px;"><a href="#2.5%20%E5%9B%9E%E5%BD%92%E5%99%A8%E4%BF%AE%E6%AD%A3%E5%80%99%E9%80%89%E6%A1%86%E4%BD%8D%E7%BD%AE" rel="nofollow">2.5 回归器修正候选框位置</a></p> 
<p id="2.6%20R-CNN%E4%BB%A5%E5%90%8E%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%96%B9%E6%B3%95%E7%9A%84%E6%94%B9%E8%BF%9B%E6%80%9D%E8%B7%AF-toc" style="margin-left:80px;"><a href="#2.6%20R-CNN%E4%BB%A5%E5%90%8E%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%96%B9%E6%B3%95%E7%9A%84%E6%94%B9%E8%BF%9B%E6%80%9D%E8%B7%AF" rel="nofollow">2.6 R-CNN以后两阶段方法的改进思路</a></p> 
<p id="3.%20Fast%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882015%E5%B9%B4%EF%BC%89-toc" style="margin-left:40px;"><a href="#3.%20Fast%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882015%E5%B9%B4%EF%BC%89" rel="nofollow">3. Fast R-CNN网络（2015年）</a></p> 
<p id="3.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98-toc" style="margin-left:80px;"><a href="#3.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98" rel="nofollow">3.1 算法流程及存在问题</a></p> 
<p id="3.2%20%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BE%E7%BD%AE-toc" style="margin-left:80px;"><a href="#3.2%20%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BE%E7%BD%AE" rel="nofollow">3.2 网络训练数据集设置</a></p> 
<p id="3.3%20ROI%20Pooling%E5%B1%82-toc" style="margin-left:80px;"><a href="#3.3%20ROI%20Pooling%E5%B1%82" rel="nofollow">3.3 ROI Pooling层</a></p> 
<p id="3.4%20ROI%20Align%E5%B1%82-toc" style="margin-left:80px;"><a href="#3.4%20ROI%20Align%E5%B1%82" rel="nofollow">3.4 ROI Align层</a></p> 
<p id="3.5%20%E5%88%86%E7%B1%BB%E5%99%A8%E4%BB%A5%E5%8F%8A%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8-toc" style="margin-left:80px;"><a href="#3.5%20%E5%88%86%E7%B1%BB%E5%99%A8%E4%BB%A5%E5%8F%8A%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8" rel="nofollow">3.5 分类器以及边界框回归器</a></p> 
<p id="%C2%A03.5%20%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%8D%9F%E5%A4%B1-toc" style="margin-left:80px;"><a href="#%C2%A03.5%20%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%8D%9F%E5%A4%B1" rel="nofollow">3.6 多任务损失</a></p> 
<p id="4.%20Faster%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882016%E5%B9%B4%EF%BC%89-toc" style="margin-left:40px;"><a href="#4.%20Faster%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882016%E5%B9%B4%EF%BC%89" rel="nofollow">4. Faster R-CNN网络（2016年）</a></p> 
<p id="4.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%94%B9%E8%BF%9B%E4%B9%8B%E5%A4%84-toc" style="margin-left:80px;"><a href="#4.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%94%B9%E8%BF%9B%E4%B9%8B%E5%A4%84" rel="nofollow">4.1 算法流程及改进之处</a></p> 
<p id="4.2%20RPN%E7%BD%91%E7%BB%9C-toc" style="margin-left:80px;"><a href="#4.2%20RPN%E7%BD%91%E7%BB%9C" rel="nofollow">4.2 RPN网络</a></p> 
<p id="4.3%20Faster%20R-CNN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-toc" style="margin-left:80px;"><a href="#4.3%20Faster%20R-CNN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B" rel="nofollow">4.3 Faster R-CNN训练过程</a></p> 
<p id="5.%20FPN%2BFaster%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882016%E5%B9%B4%EF%BC%89-toc" style="margin-left:40px;"><a href="#5.%20FPN%2BFaster%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882016%E5%B9%B4%EF%BC%89" rel="nofollow">5. FPN+Faster R-CNN网络（2016年）</a></p> 
<p id="5.1%20FPN%E7%BB%93%E6%9E%84%E4%BA%AE%E7%82%B9-toc" style="margin-left:80px;"><a href="#5.1%20FPN%E7%BB%93%E6%9E%84%E4%BA%AE%E7%82%B9" rel="nofollow">5.1 FPN结构亮点</a></p> 
<p id="5.2%20FPN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-toc" style="margin-left:80px;"><a href="#5.2%20FPN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84" rel="nofollow">5.2 FPN网络结构</a></p> 
<p id="%C2%A05.3%20FPN%2BFaster%20R-CNN%E7%9A%84%E9%A2%84%E6%B5%8B%E8%BF%87%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%C2%A05.3%20FPN%2BFaster%20R-CNN%E7%9A%84%E9%A2%84%E6%B5%8B%E8%BF%87%E7%A8%8B" rel="nofollow">5.3 FPN+Faster R-CNN的预测过程</a></p> 
<hr id="hr-toc"> 
<h3>1. 目标检测任务简介</h3> 
<p>目标检测任务主要有两个问题需要解决：识别目标类别（分类），确定目标位置（回归）。分类问题很好理解，就是确定检测到的目标属于哪一类。<strong>回归问题</strong>是为了确定目标的位置，因为我们需要一个矩形框来框住所检测到的目标，这就需要调整矩形框的中心坐标以及宽和高到最优的位置，坐标点以及宽和高的变化是连续的，因此是回归问题。基于深度学习的目标检测算法主要分为两类Two Stage 和 One Stage。本文主要介绍Two、Stage算法</p> 
<ul><li>Two Stage算法有：R-CNN、Fast R-CNN、Faster R-CNN、SPPNet</li><li>One Stage算法有：YOLO系列、SSD、RetinaNet、SqueezeDet、DetectNet、OverFeat</li></ul> 
<p><img alt="" height="727" src="https://images2.imgbox.com/b6/6e/7CEeQbGd_o.png" width="1200"></p> 
<h4 id="1.1%20%E6%97%A9%E6%9C%9F%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%80%9D%E8%B7%AF%E6%BC%94%E5%8C%96%E8%BF%87%E7%A8%8B"><span style="color:#0d0016;">1.1 早期的目标检测思路演化过程</span></h4> 
<ul><li>最早基于分类任务，人们想到可以对图像进行<strong>窗口切分</strong>，分别对每一个小窗口分类，然后检测结果 = （分类结果，图像窗的位置），但是该方法过于粗糙，无法检测分块边界上的物体</li><li>后来就想到<strong>基于滑窗（sliding windows）</strong>进行检测，也就是使用重叠的窗口，可以覆盖更多可能出现物体的位置，但是会发现滑窗边界与物体精确边界仍有很大误差</li><li>这就引入了<strong>边界框回归</strong>（多任务学习的概念，同时进行分类和回归任务）</li><li>但是又出现了<strong>多尺度问题</strong>，也就是说在同一幅图片里面物体有大有小，长宽比不同 
  <ul><li>有人提出使用<u>大小、长宽比不同的滑窗</u></li><li>另外的思路可以改变图像的大小（将图像缩放到不同大小，构建<u>图像金字塔</u>）</li></ul></li></ul> 
<h4 id="1.2%20%E5%AF%86%E9%9B%86%E9%A2%84%E6%B5%8B%E7%9A%84%E6%95%88%E7%8E%87%E9%97%AE%E9%A2%98"><strong><span style="color:#0d0016;">1.2 密集预测的效率问题</span></strong></h4> 
<ul><li>滑窗其实相当于是在空间是做密集的预测（检测一张图像，要进行数万次分类预测），难以满足实时检测需求，为此提出了Region Rroposal（区域提议）策略 
  <ul><li>大量窗口都落在不包含物体的边界区域。</li><li>可以先通过简单快速的方法找出可能包含物体的区域</li></ul></li><li><strong>SS算法</strong>：使用贪心算法，将空间相邻且特征相似的图像块逐步合并到一起，形成可能包含物体的区域，称为提议区域或提议框</li></ul> 
<h3 id="2.%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882014%E5%B9%B4%EF%BC%89">2. R-CNN网络（2014年）</h3> 
<p><img alt="" height="578" src="https://images2.imgbox.com/9c/8f/vAL3Hwcs_o.png" width="1200"></p> 
<p></p> 
<h4 id="2.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98">2.1 算法流程及存在问题</h4> 
<ul><li>算法流程 
  <ul><li>使用SS算法，将一张图像<strong>生成1k到2k个候选区域（proposal）</strong></li><li>对每个候选区域，使用深度网络（Backnone：AlexNet）提取特征</li><li>将特征送入每一类的SVM分类器，判别是否属于该类</li><li>使用回归器精细修正候选框位置</li></ul></li><li>存在问题： 
  <ul><li>CPU上测试一张图片大约53s。用SS算法提取候选框需要2s，一张图像内候选框之间存在大量重叠，提取特征操作冗余</li><li>过程比较繁琐，并且需要<span style="color:#be191c;"><strong>分别训练</strong></span>特征提取网络、SVM分类模型、回归模型</li><li>训练所需空间大：对于SVM和bbox回归训练，需要从每个图像中的每个目标候选框提取特征，并写入磁盘。对于非常深的网络，如VGG16，从VOC07训练集上的5k图像上提取的而调整需要数百GB的存储空间</li></ul></li></ul> 
<h4 id="2.2%20%E5%80%99%E9%80%89%E5%8C%BA%E7%94%9F%E6%88%90">2.2 候选区生成（SS算法）</h4> 
<blockquote> 
 <p>SS算法：首先使用图像分割策略分割出可能的前景（目标）区域，即<strong>原始区域</strong>，这里同一个目标会有很多冗余的框，采用合并策略<strong>剔除冗余的原始区域</strong>，得到层次化的区域结构，即<strong>候选区域</strong></p> 
</blockquote> 
<ul><li>一张图像使用SS算法大约可以得到2k张候选区域 </li></ul> 
<h4 id="%C2%A02.3%20%E6%B7%B1%E5%BA%A6%E7%BD%91%E7%BB%9C%E6%8F%90%E5%8F%96%E7%89%B9%E5%BE%81"> 2.3 深度网络提取特征</h4> 
<ul><li>Warped Region，将候选区域缩放到227*227pixel</li><li>接着输入<span style="color:#be191c;"><strong>分类网络AlexNet（事先训练好）</strong></span>，获得4096维的特征，特征矩阵：2k*4096</li></ul> 
<p class="img-center"><img alt="" height="148" src="https://images2.imgbox.com/f6/44/K7QES8oX_o.png" width="552"></p> 
<h4 id="2.4%20SVM%E5%88%86%E7%B1%BB%E5%99%A8">2.4 SVM分类器</h4> 
<ul><li>将2000×4096维特征与20个SVM组成<span style="color:#be191c;"><strong>的权值矩阵4096×20（事先训练好）</strong></span>相乘， 获得2000×20维概率矩阵，每一行代表一个建议框归于每个目标的概率。</li><li>分别对上述2000×20维矩阵中每一列即每一类进行非极大值抑<strong>制剔除重叠建议框</strong>，得到该列即该类中得分最高的一些建议框</li></ul> 
<p><img alt="" height="339" src="https://images2.imgbox.com/a3/78/szaktOZr_o.png" width="1066"></p> 
<blockquote> 
 <p>非极大值抑制剔除重叠建议框 （NMS）：IoU（Intersection over Union）表示两个区域的交并比，越大说明重合度越高，通过计算IoU，若大于给定阈值，则说明为同一物体，剔除该框</p> 
 <p><img alt="" height="277" src="https://images2.imgbox.com/24/40/IkG517TT_o.png" width="1200"></p> 
</blockquote> 
<h4 id="2.5%20%E5%9B%9E%E5%BD%92%E5%99%A8%E4%BF%AE%E6%AD%A3%E5%80%99%E9%80%89%E6%A1%86%E4%BD%8D%E7%BD%AE">2.5 回归器修正候选框位置</h4> 
<ul><li> <p>对NMS处理后剩余的建议框进一步筛选。接着分别用<span style="color:#be191c;"><strong>20个回归器（事先训练好）</strong></span>对上述20个类别中<strong>剩余的建议框</strong>进行回归操作，最终得到每个类别的修正后的得分最高的 bounding box</p> </li></ul> 
<p class="img-center"><img alt="" height="206" src="https://images2.imgbox.com/14/88/cwrp70dn_o.png" width="501"></p> 
<h4 id="2.6%20R-CNN%E4%BB%A5%E5%90%8E%E4%B8%A4%E9%98%B6%E6%AE%B5%E6%96%B9%E6%B3%95%E7%9A%84%E6%94%B9%E8%BF%9B%E6%80%9D%E8%B7%AF">2.6 R-CNN以后两阶段方法的改进思路</h4> 
<p><img alt="" height="893" src="https://images2.imgbox.com/35/aa/Zav6lh2L_o.png" width="1200"></p> 
<h3 id="3.%20Fast%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882015%E5%B9%B4%EF%BC%89">3. Fast R-CNN网络（2015年）</h3> 
<p><img alt="" height="845" src="https://images2.imgbox.com/de/a5/8KP1Vgt5_o.png" width="1200"></p> 
<h4 id="3.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E5%AD%98%E5%9C%A8%E9%97%AE%E9%A2%98">3.1 算法流程及存在问题</h4> 
<ul><li>可以对比R-CNN算法流程 
  <ul><li><span style="color:#0d0016;">同R-CNN：</span>使用SS算法，将一张图像生成1k到2k个候选区域（proposal）</li><li><s>对每个候选区域，使用深度网络（Backnone：AlexNet）提取特征</s>。<span style="color:#be191c;"><strong>将图像输入网络得到特征图，将SS算法生成的候选区域投影到特征图上获得相应的特征矩阵（降低计算量）</strong></span></li><li>将特征矩阵<s>送入SVM分类器，判别是否属于该类</s>。缩放到7*7大小，接着展平送入全连接层得到预测结果</li><li><s>使用回归器精细修正候选框位置</s>。<span style="color:#be191c;"><strong>并联两个全连接层，其中一个进行边界框回归</strong></span></li></ul></li><li>改进之处：将R-CNN中的SVM分类以及bbox回归模型去除，使用一个完整的网络（并联两个全连接层）<strong>端到端实现建议框的预测和回归</strong></li><li>存在问题：SS算法非常耗时，并且需要分步执行</li></ul> 
<p class="img-center"><img alt="" height="646" src="https://images2.imgbox.com/74/a0/xa2vX9f0_o.png" width="1200"></p> 
<h4 id="3.2%20%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AE%BE%E7%BD%AE">3.2 网络训练数据集设置</h4> 
<ul><li>SS算法生成的候选框并不全用于网络训练，只需采样其中一小部分</li><li>另外要对采样的数据划分为正负样本（保证样本的均衡） 
  <ul><li>正样本：存在检测目标（IoU&gt;0.5）</li><li>负样本：背景</li></ul></li></ul> 
<h4 id="3.3%20ROI%20Pooling%E5%B1%82">3.3 ROI Pooling层</h4> 
<ul><li>无论特征矩阵是什么样的大小，全都缩放到7*7size（这样不限制输入图像尺寸）</li></ul> 
<h4 id="%E2%80%8B%E7%BC%96%E8%BE%913.4%20%E5%88%86%E7%B1%BB%E5%99%A8%E4%BB%A5%E5%8F%8A%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8"><img alt="" height="298" src="https://images2.imgbox.com/96/06/7ozmKbz8_o.png" width="1045"></h4> 
<ul><li>做法：将提议区域切分成固定数目的格子（常用7*7），对于每个格子： 
  <ul><li>如果格子边界不在证书坐标，则膨胀至整数坐标</li><li>通过Max Pooling得到格子的输出特征</li></ul></li><li>作用：将任意尺寸的提议区域映射至<span style="color:#be191c;"><strong>固定尺寸</strong></span>的特征图，同时保留图像特征</li></ul> 
<h4 id="3.4%20ROI%20Align%E5%B1%82">3.4 ROI Align层</h4> 
<ul><li>Rol Pooling的位置偏差 → 引入了ROI Align层（2017，是在mask R-CNN中提出的）</li></ul> 
<p><img alt="" height="497" src="https://images2.imgbox.com/38/5a/TV9P5toA_o.png" width="1200"></p> 
<p> <img alt="" height="805" src="https://images2.imgbox.com/9d/44/qNR39ZJZ_o.png" width="1200"></p> 
<h4 id="3.5%20%E5%88%86%E7%B1%BB%E5%99%A8%E4%BB%A5%E5%8F%8A%E8%BE%B9%E7%95%8C%E6%A1%86%E5%9B%9E%E5%BD%92%E5%99%A8">3.5 分类器以及边界框回归器</h4> 
<ul><li>分类器输出N+1个类别的概率（N为检测目标的种类, 1为背景）共N+1个节点</li><li>边界框回归器输出对应N+1个类别的候选边界框回归参数(dx , dy , dw, dh ),共(N+1)x4个节点</li></ul> 
<figure class="image"> 
 <img alt="" height="510" src="https://images2.imgbox.com/fb/1f/r2DJkc3n_o.png" width="1200"> 
 <figcaption>
   边界框回归器的输出 
 </figcaption> 
</figure> 
<h4 id="%C2%A03.5%20%E5%A4%9A%E4%BB%BB%E5%8A%A1%E6%8D%9F%E5%A4%B1"> 3.6 多任务损失</h4> 
<ul><li>分类损失：交叉熵损失，softmax输出</li><li>边界框回归损失：smooth损失</li></ul> 
<p class="img-center"><img alt="" height="287" src="https://images2.imgbox.com/b3/65/bhua3lea_o.png" width="643"></p> 
<p class="img-center"><img alt="" height="282" src="https://images2.imgbox.com/9b/ec/oSseaWPr_o.png" width="640"></p> 
<h3 id="4.%20Faster%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882016%E5%B9%B4%EF%BC%89">4. Faster R-CNN网络（2016年）</h3> 
<h4 id="4.1%20%E7%AE%97%E6%B3%95%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%94%B9%E8%BF%9B%E4%B9%8B%E5%A4%84">4.1 算法流程及改进之处</h4> 
<ul><li>可以对比Fast R-CNN算法流程 
  <ul><li><strong><span style="color:#be191c;">首先：将图像输入网络得到相应的特征图</span></strong></li><li><span style="color:#0d0016;"><s>使用SS算法</s>，</span><span style="color:#be191c;"><strong>使用RPN网络生成候选框</strong></span><span style="color:#0d0016;">，将一张图像生成1k到2k个候选区域（proposal）</span></li><li><span style="color:#0d0016;"><s>将图像输入网络得到特征图，</s>将<s>SS算法</s></span><span style="color:#be191c;"><strong>RPN网络</strong></span><span style="color:#0d0016;">生成的候选区域投影到特征图上获得相应特征矩阵</span></li><li><span style="color:#0d0016;">将特征矩阵缩放到7*7大小，接着展平送入全连接层得到预测结果</span></li><li><span style="color:#0d0016;">并联两个全连接层，其中一个进行边界框回归</span></li></ul></li><li>改进之处：将Fast R-CNN中的SS算法替换为<strong>RPN网络（区域提议网络）</strong></li></ul> 
<h4 id="4.2%20RPN%E7%BD%91%E7%BB%9C">4.2 RPN网络</h4> 
<ul><li>先是在特征图上使用3*3的滑动窗口的中心点计算出对应原始图像的中心点，以此计算出k个anchor boxes</li><li>RPN网络的目的在于让这K个anchor含有前景物体的概率最高</li></ul> 
<p><img alt="" height="767" src="https://images2.imgbox.com/38/b4/vBgWrrls_o.png" width="1200"></p> 
<ul><li> RPN网络的训练样本：一张图像对其生成的anchor随机采样256个anchor（正负样本1：1） 
  <ul><li>如何定义正负样本 
    <ul><li>anchor与GT-box的IoU&gt;0.7（正样本）</li><li>anchor与GT-box拥有最大的IoU（正样本）</li><li>anchor与所有GT-box的IoU&lt;0.3（负样本）</li></ul></li></ul></li><li>RPN网络的损失：也是多任务损失（分类和边界框回归），这里的分类是前景和背景分类 
  <ul><li>注意这里的分类损失若使用多分类softmax，则输出为2k，若二分类sigmoid，则输出为k</li></ul></li></ul> 
<p><img alt="" height="696" src="https://images2.imgbox.com/8a/d1/BVO4vM1n_o.png" width="1200"></p> 
<p><img alt="" height="682" src="https://images2.imgbox.com/7e/05/xjYsWKUT_o.png" width="1200"></p> 
<h4 id="4.3%20Faster%20R-CNN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B">4.3 Faster R-CNN训练过程</h4> 
<p><img alt="" height="701" src="https://images2.imgbox.com/11/99/vnlOYuvk_o.png" width="1200"></p> 
<ul><li> <p>原论文中采用分别训练RPN以及Fast R-CNN的方法</p> 
  <ul><li> <p>利用ImageNet预训练分类模型初始化前置卷积网络层参数，并<strong>开始单独训练RPN参数</strong></p> </li><li> <p><strong>固定RPN网络</strong>，再利用 ImageNet预训练分类模型初始化前置卷积网络参数，并利用RPN网络生成的目标建议框去<strong>训练Fast RCNN网络参数</strong></p> </li><li> <p><strong>固定利用Fast RCNN</strong>训练好的前置卷积网络层参数，<strong>微调RPN 网络</strong></p> </li><li> <p>同样保持固定前置卷积网络层参数，去微调Fast RCNN网络的全连接层参数。最后RPN网络与Fast RCNN网络<strong>共享前置卷积网络层参数</strong>，构成一个统一网络</p> </li></ul></li><li> <p>也可直接采用RPN Loss+ Fast R-CNN Loss的联合训练方法</p> </li></ul> 
<p><img alt="" height="748" src="https://images2.imgbox.com/0f/78/qLvjzqLG_o.png" width="1200"></p> 
<h3 id="5.%20FPN%2BFaster%20R-CNN%E7%BD%91%E7%BB%9C%EF%BC%882016%E5%B9%B4%EF%BC%89">5. FPN+Faster R-CNN网络（2016年）</h3> 
<ul><li>到此为止，模型基于单级特征图进行预测，通常是主干网络组后一层或者倒数第二层</li><li>存在问题：高层次特征空间降采样率较大，小物体信息丢失</li><li>解决思路： 
  <ul><li>基于底层特征图预测 → 底层特征语义信息薄弱</li><li>图像金字塔 → 低效率</li><li>因此：融合高低层次的特征 → 特征金字塔网络FPN</li></ul></li></ul> 
<h4 id="5.1%20FPN%E7%BB%93%E6%9E%84%E4%BA%AE%E7%82%B9">5.1 FPN结构亮点</h4> 
<p class="img-center"><img alt="" height="389" src="https://images2.imgbox.com/0d/bf/rQBo3fkx_o.png" width="641"></p> 
<ul><li>可以对比 
  <ul><li><strong>a. 图像金字塔结构</strong>，对图像进行不同尺度的缩放，这样导致预测效率低</li><li><strong>b. single feature map</strong>，像SPP net，Fast RCNN，Faster RCNN是采用这种方式，即仅采用网络最后一层的特征，针对小目标预测效果不好</li><li><strong>c. pryamidal feature hierarchy</strong>，像SSD采用这种多尺度特征融合的方式，没有上采样过程即从网络不同层抽取不同尺度的特征做预测，这种方式不会增加额外的计算量。作者认为SSD算法中没有用到足够低层的特征（在SSD中，最低层的特征是VGG网络的conv4_3），而在作者看来足够低层的特征对于检测小物体是很有帮助的</li><li>本文作者是采用d.这种方式，顶层特征通过上采样和低层特征做融合，而且每层都是独立预测的，确实有助于提升网络检测效果。针对目标检测任务：coco AP提升2.3个点；pascal AP提升3.8个点</li></ul></li></ul> 
<p><img alt="" height="694" src="https://images2.imgbox.com/32/ff/DWUi16tD_o.png" width="1200"></p> 
<blockquote> 
 <p>在分类网络中，Backbone每次缩放feature map的时候都是以2的整数倍进行缩放的。</p> 
</blockquote> 
<h4 id="5.2%20FPN%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84">5.2 FPN网络结构</h4> 
<p>不同特征层采用1*1卷积调整channel数量，采用上采样（插值方式）调整特征图尺寸，最终融合C2-C5特征层，并分别通过3*3卷积得到P2-P5融合后的特征层，比如说P2层相对较底层的预测特征层会保留更多的细节信息，更适合预测小型目标</p> 
<p><img alt="" height="651" src="https://images2.imgbox.com/01/a4/ecqX8b02_o.png" width="1200"></p> 
<h4 id="%C2%A05.3%20FPN%2BFaster%20R-CNN%E7%9A%84%E9%A2%84%E6%B5%8B%E8%BF%87%E7%A8%8B">5.3 FPN+Faster R-CNN的预测过程</h4> 
<ul><li>由于在RPN网络中使用了FPN结构，原本在一层特征层上生成很多候选框的情况，现在变成了在P2-P6五层特征层上生成候选框（这里每一层针对不同面积大小的anchor对于生成，也就是说P2到P6分别对应生成面积为32，64，128，256，512的anchor）</li><li>另外，前置卷积层也是用FPN结构后，回程从P2-P5四层特征图</li></ul> 
<figure class="image"> 
 <img alt="" height="484" src="https://images2.imgbox.com/c3/cd/kX9Da1Yv_o.png" width="824"> 
 <figcaption>
   预测阶段示意图 
 </figcaption> 
</figure> 
<ul><li> 预测的时候由RPN生成的P2-P6的候选框，首先要映射到P2-P5层级，然后经过Faster R-CNN网络进行预测和回归</li><li>这里映射的时候文献中给了相应的计算公式</li></ul> 
<p class="img-center"><img alt="" height="317" src="https://images2.imgbox.com/26/5e/pa1zI4yY_o.png" width="709"></p> 
<p style="text-align:center;"><img alt="" height="670" src="https://images2.imgbox.com/5d/d0/a4fBRByN_o.png" width="1200"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bb597e59012254cfde6f22d6d06d6cb7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[图文]搭建InnoDB Cluster详细流程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/277468af0e37f826f667859b0d18e93b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ShardingSphere 5.1.1 读写分离实战 | sharding-jdbc | 详细步骤</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>