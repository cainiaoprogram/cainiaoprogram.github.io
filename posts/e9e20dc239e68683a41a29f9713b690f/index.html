<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[深度学习 - 发现有趣项目] 动漫图生成手绘草图 Anime2Sketch - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[深度学习 - 发现有趣项目] 动漫图生成手绘草图 Anime2Sketch" />
<meta property="og:description" content="我公司的科室开始在公众号上规划一些对外的技术文章了，包括实战项目、模型优化、端侧部署和一些深度学习任务基础知识，而我负责人体图象相关技术这一系列文章，偶尔也会出一些应用/代码解读等相关的文章。
文章在同步发布至公众号和博客，顺带做一波宣传。有兴趣的还可以扫码加入我们的群。
（文章有写的不好的地方请见谅，另外有啥错误的地方也请大家帮忙指出。）
微信公众号：AI炼丹术 【趣味AI项目】动漫图生成手绘草图 Anime2Sketch 技术简述 文章链接：https://arxiv.org/abs/2104.05703
代码链接：https://github.com/Mukosame/Anime2Sketch （基于上面文章实现的。）
（1）手绘草图生成 ​ 手绘草图生成的主要目的是从一张彩色实物图提取出它的素描勾线信息，类似于一个边缘轮廓检测的任务。实际上作者文章实现的是从草图到图像以及从图像到草图两个模块，也就是两个生成模型。
​ 这里面主要存在的问题是缺少训练数据集，我们并不能找到一堆图像以及与之对应的草图。即使现在开源的一个草图数据集 SketchyCOCO 也没有完全一致的草图。（如下图，源自SketchyCOCO论文：https://arxiv.org/pdf/2003.02683.pdf）也就是一般解决训练集这个问题的做法是通过使用假草图来代替真实草图来训练。可以看出差距还是蛮大的，因此对模型的学习不太友好。
​ 这里的论文（Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis）的作者主要介绍一种开放域 open-domain的方式来混淆生成器，使生成器在真假学习之间有个模糊的界限，来解决上面所提到的问题。
（2）Anime2Sketch 效果展示 Anime2Sketch: A sketch extractor for illustration, anime art, manga
​ Anime2Sketch 源码实现的是从漫画到草图的生成，仓库代码开源于2021.4.8，但是只提供了测试代码以及预训练模型，并未开源训练代码及相关细节。而代码所使用的技术即论文（Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis）。
​ 测试了预训练效果，感觉还不错。可以通过模型，将自己在纸上手绘的图画转换成线稿图输入电脑进行上色。
模型网络结构概述 ​ 模型由两个生成模型、两个判别模型以及一个分类器组成。如上图所示，GA是一个真实图到草图的生成器、GB是一个草图到真实图的多类别生成器；DA、DB分别是草图判别器和真实图片判别器。除此之外还有一个分类器R。生成器的结构很简单，就是使用的Unet结构；判别器和分类器源码里面没有，论文里面也没提及具体结构。
​ 模型这样做的特点是可以使用不成对的草图和真实图像数据进行训练。理由如上面说的，数据集方面我们很难去收集到成对的真实图片及其草图。因此模型不要求你每个图片都有唯一一个标签，但是需要图片有其相应类别。
​ 主要通过优化训练策略，是模型学习到图片到草图和草图到图片的联合转化，减小合成草图和真实草图的domain gap。
代码实战 （1）运行环境 环境很简单，而且不一定需要gpu，模型在cpu下也能运行。
Python：3.7
torch torchvision Pillow gradio torchtext （2）运行步骤 ① 从github 上将代码clone下来；" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e9e20dc239e68683a41a29f9713b690f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-24T09:40:35+08:00" />
<meta property="article:modified_time" content="2022-04-24T09:40:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[深度学习 - 发现有趣项目] 动漫图生成手绘草图 Anime2Sketch</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>我公司的科室开始在公众号上规划一些对外的技术文章了，包括实战项目、模型优化、端侧部署和一些深度学习任务基础知识，而我负责人体图象相关技术这一系列文章，偶尔也会出一些应用/代码解读等相关的文章。<br> 文章在同步发布至公众号和博客，顺带做一波宣传。有兴趣的还可以扫码加入我们的群。<br> （文章有写的不好的地方请见谅，另外有啥错误的地方也请大家帮忙指出。）</p> 
 <h4><a id="AI_3"></a>微信公众号：AI炼丹术</h4> 
</blockquote> 
<h2><a id="AI_Anime2Sketch_5"></a>【趣味AI项目】动漫图生成手绘草图 Anime2Sketch</h2> 
<p><img src="https://images2.imgbox.com/95/3e/zdlOGgW9_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_7"></a>技术简述</h4> 
<p>文章链接：<a href="https://arxiv.org/abs/2104.05703" rel="nofollow">https://arxiv.org/abs/2104.05703</a></p> 
<p>代码链接：<a href="https://github.com/Mukosame/Anime2Sketch">https://github.com/Mukosame/Anime2Sketch</a> （基于上面文章实现的。）</p> 
<h5><a id="1_13"></a>（1）手绘草图生成</h5> 
<p>​ 手绘草图生成的主要目的是从一张彩色实物图提取出它的素描勾线信息，类似于一个边缘轮廓检测的任务。实际上作者文章实现的是从草图到图像以及从图像到草图两个模块，也就是两个生成模型。</p> 
<p>​ 这里面主要存在的问题是缺少训练数据集，我们并不能找到一堆图像以及与之对应的草图。即使现在开源的一个草图数据集 SketchyCOCO 也没有完全一致的草图。（如下图，源自SketchyCOCO论文：https://arxiv.org/pdf/2003.02683.pdf）也就是一般解决训练集这个问题的做法是通过使用假草图来代替真实草图来训练。可以看出差距还是蛮大的，因此对模型的学习不太友好。</p> 
<p>​ 这里的论文（Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis）的作者主要介绍一种开放域 open-domain的方式来混淆生成器，使生成器在真假学习之间有个模糊的界限，来解决上面所提到的问题。</p> 
<p><img src="https://images2.imgbox.com/71/1c/V1pDoxaG_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="2Anime2Sketch__24"></a>（2）Anime2Sketch 效果展示</h5> 
<blockquote> 
 <p><em>Anime2Sketch: A sketch extractor for illustration, anime art, manga</em></p> 
</blockquote> 
<p>​ Anime2Sketch 源码实现的是从漫画到草图的生成，仓库代码开源于2021.4.8，但是只提供了测试代码以及预训练模型，并未开源训练代码及相关细节。而代码所使用的技术即论文（Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis）。</p> 
<p>​ 测试了预训练效果，感觉还不错。可以通过模型，将自己在纸上手绘的图画转换成线稿图输入电脑进行上色。</p> 
<p><img src="https://images2.imgbox.com/31/bf/v9LTVZWw_o.jpg" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/48/00/SzZ7AWY6_o.jpg" alt="在这里插入图片描述"></p> 
<h4><a id="_36"></a>模型网络结构概述</h4> 
<p><img src="https://images2.imgbox.com/e6/c8/aNKAVKlc_o.png" alt="在这里插入图片描述"></p> 
<p>​ 模型由两个生成模型、两个判别模型以及一个分类器组成。如上图所示，GA是一个真实图到草图的生成器、GB是一个草图到真实图的多类别生成器；DA、DB分别是草图判别器和真实图片判别器。除此之外还有一个分类器R。生成器的结构很简单，就是使用的Unet结构；判别器和分类器源码里面没有，论文里面也没提及具体结构。</p> 
<p>​ 模型这样做的特点是可以使用不成对的草图和真实图像数据进行训练。理由如上面说的，数据集方面我们很难去收集到成对的真实图片及其草图。因此模型不要求你每个图片都有唯一一个标签，但是需要图片有其相应类别。</p> 
<p>​ 主要通过优化训练策略，是模型学习到图片到草图和草图到图片的联合转化，减小合成草图和真实草图的domain gap。</p> 
<h4><a id="_46"></a>代码实战</h4> 
<h5><a id="1_48"></a>（1）运行环境</h5> 
<p>环境很简单，而且不一定需要gpu，模型在cpu下也能运行。</p> 
<p>Python：3.7</p> 
<pre><code class="prism language-bash">torch
torchvision
Pillow
gradio
torchtext
</code></pre> 
<h5><a id="2_62"></a>（2）运行步骤</h5> 
<p>① 从github 上将代码clone下来；</p> 
<pre><code class="prism language-bash"><span class="token function">git</span> clone https://github.com/Mukosame/Anime2Sketch.git
<span class="token builtin class-name">cd</span> Anime2Sketch
</code></pre> 
<p>② 安装python依赖包；</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> -r requirements.txt
</code></pre> 
<p>③ 下载预训练模型；</p> 
<ul><li> <p>从这个链接下载预训练模型 netG.pth :<a href="https://drive.google.com/drive/folders/1Srf-WYUixK0wiUddc9y3pNKHHno5PN6R?usp=sharing" rel="nofollow">https://drive.google.com/drive/folders/1Srf-WYUixK0wiUddc9y3pNKHHno5PN6R?usp=sharing</a> ;</p> </li><li> <p>并放入目录下weights文件夹：./Anime2Sketch/weights。</p> </li></ul> 
<p>④ 测试图片（模型推理）；</p> 
<ul><li>将需要测试的图片放入默认文件夹：test_samples；</li></ul> 
<pre><code class="prism language-bash">python test.py --dataroot test_samples --load_size <span class="token number">512</span> --output_dir results
</code></pre> 
<ul><li>运行完毕会在同个目录下生成文件夹：results，存放草图提取后的图像。</li></ul> 
<h4><a id="_93"></a>代码分析</h4> 
<h5><a id="1_95"></a>（1）参数设置</h5> 
<p>‘dataroot’: 指需要运行的图片目录，会将目录下所有图片都进行前向推理;</p> 
<p>‘load_size’: 模型输入的大小；（不需要改）;</p> 
<p>‘output_dir’: 前向推理完生成的图片保存的文件夹；</p> 
<p>‘gpu_ids’: 指定所使用的GPU，如果使用cpu则 default=[] 即可；</p> 
<pre><code class="prism language-python">	parser <span class="token operator">=</span> argparse<span class="token punctuation">.</span>ArgumentParser<span class="token punctuation">(</span>description<span class="token operator">=</span><span class="token string">'Anime-to-sketch test options.'</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--dataroot'</span><span class="token punctuation">,</span><span class="token string">'-i'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'test_samples/'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--load_size'</span><span class="token punctuation">,</span><span class="token string">'-s'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">int</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--output_dir'</span><span class="token punctuation">,</span><span class="token string">'-o'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token string">'results/'</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token operator">=</span><span class="token builtin">str</span><span class="token punctuation">)</span>
    parser<span class="token punctuation">.</span>add_argument<span class="token punctuation">(</span><span class="token string">'--gpu_ids'</span><span class="token punctuation">,</span> <span class="token string">'-g'</span><span class="token punctuation">,</span> default<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token builtin">help</span><span class="token operator">=</span><span class="token string">"gpu ids: e.g. 0 0,1,2 0,2."</span><span class="token punctuation">)</span>
</code></pre> 
<h5><a id="2_113"></a>（2）前向推理</h5> 
<ul><li> <p>创建模型;</p> <p>由于作者并未提供训练的代码，而测试（前向推理）的时候只需要生成模型即可，因此创建模型的时候只创建了动漫到草图的生成模型。</p> </li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">create_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Create a model for anime2sketch
    hardcoding the options for simplicity
    """</span>
    norm_layer <span class="token operator">=</span> functools<span class="token punctuation">.</span>partial<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>InstanceNorm2d<span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> track_running_stats<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    net <span class="token operator">=</span> UnetGenerator<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> norm_layer<span class="token operator">=</span>norm_layer<span class="token punctuation">,</span> use_dropout<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    ckpt <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'weights/netG.pth'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>ckpt<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token string">'module.'</span> <span class="token keyword">in</span> key<span class="token punctuation">:</span>
            ckpt<span class="token punctuation">[</span>key<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'module.'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> ckpt<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
            <span class="token keyword">del</span> ckpt<span class="token punctuation">[</span>key<span class="token punctuation">]</span>
    net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>ckpt<span class="token punctuation">)</span>
    <span class="token keyword">return</span> net
</code></pre> 
<pre><code class="prism language-python">model <span class="token operator">=</span> create_model<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>      <span class="token comment"># create a model given opt.model and other options</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li> <p>模型推理</p> <p>遍历测试文件夹，并将每张图片输入模型生成草图，最终保存到输出文件夹。</p> </li></ul> 
<pre><code class="prism language-python"><span class="token keyword">for</span> test_path <span class="token keyword">in</span> test_list<span class="token punctuation">:</span>
    basename <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>basename<span class="token punctuation">(</span>test_path<span class="token punctuation">)</span>
    aus_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> basename<span class="token punctuation">)</span>
    img<span class="token punctuation">,</span>  aus_resize <span class="token operator">=</span> read_img_path<span class="token punctuation">(</span>test_path<span class="token punctuation">,</span> opt<span class="token punctuation">.</span>load_size<span class="token punctuation">)</span>
    aus_tensor <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
    aus_img <span class="token operator">=</span> tensor_to_img<span class="token punctuation">(</span>aus_tensor<span class="token punctuation">)</span>
    save_image<span class="token punctuation">(</span>aus_img<span class="token punctuation">,</span> aus_path<span class="token punctuation">,</span> aus_resize<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_154"></a>拓展</h4> 
<p>​ 虽然没有提供动漫线稿还原成彩色原图的代码，但小编在这里找到了一个自动上色的项目。</p> 
<p>代码：<a href="https://github.com/pfnet/PaintsChainer">https://github.com/pfnet/PaintsChainer</a>；（可以通过代码在本地启一个上色服务。）</p> 
<p>也可以直接通过官方demo网站：<a href="http://paintschainer.preferred.tech/" rel="nofollow">http://paintschainer.preferred.tech/</a></p> 
<ul><li> <p>可以自动上色。（好像官方demo的版本效果会比他们提供的预训练模型好）<br> <img src="https://images2.imgbox.com/e9/b9/h2Cob1Cj_o.png" alt="在这里插入图片描述"></p> </li><li> <p>也可以提前勾画部分区域的颜色，再自动上色，这样会更加自然。具体大家可以自行下载下来玩。<br> <img src="https://images2.imgbox.com/74/8e/P8tG0rIQ_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/bd/7e/Z9R8ThyO_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<h4><a id="_172"></a>参考文献</h4> 
<p>（1）论文笔记“Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis：<a href="https://zhuanlan.zhihu.com/p/395055283" rel="nofollow">https://zhuanlan.zhihu.com/p/395055283</a>.</p> 
<p>（2）Adversarial Open Domain Adaption for Sketch-to-Photo Synthesis Supplementary Material：<a href="https://arxiv.org/pdf/2104.05703.pdf" rel="nofollow">https://arxiv.org/pdf/2104.05703.pdf</a></p> 
<p>（3）The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies：<a href="http://sketchy.eye.gatech.edu/paper.pdf" rel="nofollow">http://sketchy.eye.gatech.edu/paper.pdf</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4badb08a3df5c156a55e12d632c1a6cc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">手势识别（一） - 项目概述与简单应用介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/329e1721c635114572ceee399837d162/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">STM32控制CD74HC4067十六通道模拟开关以及遇到的一些问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>