<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习中的特征程与模型调优，sklearn用法 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习中的特征程与模型调优，sklearn用法" />
<meta property="og:description" content="数据处理、特征工程、特征选择 数据处理
分析数据的分布模式，发现异常值/噪声（boxplot、quantile）pandas工具库：数据类型(时间型读成字符串），数字形态的类别型（没有大小关系）缺失值：缺失比例，缺失数据为数据型/类别型时间序列：趋势分析(连续值displot、类别型countplot/value_counts)，主要包括单维度分析、关联维度(corr,heatmap)业务数据中做建模：最有效的特征通常时统计特征（怎么做统计、有那些类别的列可以作为groupby的对象，有哪些数据类型的列可以用于统计聚合)。特别留意置信度，总数很小的时候，统计值不稳定，比例型特征稳定度高于绝对值 特征工程
数值型
幅度缩放(归一化)
离散化/分箱分桶(等距pd.cut、等频pd.qut)(非线性/加速/特征交叉/健壮性)
统计值（max min quantile)
四则运算
幅度变换（有一些模型对于输入数据有分布假设，lr假设输入连续值特征符合正态分布，可以使用log1p/exp）
监督学习分箱（用决策树建模，用决策树学习连续值划分方式，把决策树中间节点取出来作为组合特征），sklearn.DecisionTree中有个apply函数，可以用于监督学习分箱
类别型
one-hot-encoding
label-encoding
binary-encoding
category-encoding(利用贝叶斯的先验做一些变换)
时间型
时间点/时间段（星期几、几点钟）
时间分组（工作日、周末、法定节假日…)
时间间隔（距离当前为止…)
和数值型一起做统计特征的时候，会选区不同的时间窗
文本型
词袋模型
tf-idf
lda
word2vec/word embedding
特征选择
过滤型(filter)，可以根据一些卡方检验等做一些过滤
包裹型(wrapper)
嵌入型（embedded)
基于树模型去判断特征的重要去，做实验去筛选
简单工具 缺失值处理
pandas fillna
age = df_train[&#39;Age&#39;].fillna(value=df_train[&#39;Age&#39;].mean()) df_train.loc[:,&#39;Age&#39;]=age sklearn Imputer
from sklearn.preprocessing import Imputer imp = Imputer(missing_values=&#39;NaN&#39;, strategy=&#39;mean&#39;, axis=0) age = imp.fit_transform(df_train[[&#39;Age&#39;]].values) df_train.loc[:,&#39;Age&#39;]=age 幅度变换 numpy&#43;apply
import numpy as np log_age = df_train[&#39;Age&#39;].apply(lambda x:np.log(x)) df_train.loc[:,&#39;log_age&#39;] = log_age #对几列数据同时进行操作 import pandas as pd import numpy as np df = pd." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9c00b95556463ca4242c3eddaa977f96/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-03-17T12:08:22+08:00" />
<meta property="article:modified_time" content="2019-03-17T12:08:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习中的特征程与模型调优，sklearn用法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="_0"></a>数据处理、特征工程、特征选择</h4> 
<ul><li> <p>数据处理</p> 
  <blockquote> 
   <ol><li>分析数据的分布模式，发现异常值/噪声（boxplot、quantile）</li><li>pandas工具库：数据类型(时间型读成字符串），数字形态的类别型（没有大小关系）</li><li>缺失值：缺失比例，缺失数据为数据型/类别型</li><li>时间序列：趋势分析(连续值displot、类别型countplot/value_counts)，主要包括单维度分析、关联维度(corr,heatmap)</li><li>业务数据中做建模：最有效的特征通常时统计特征（怎么做统计、有那些类别的列可以作为groupby的对象，有哪些数据类型的列可以用于统计聚合)。特别留意置信度，总数很小的时候，统计值不稳定，比例型特征稳定度高于绝对值</li></ol> 
  </blockquote> </li><li> <p>特征工程</p> </li></ul> 
<ol><li> <p>数值型</p> 
  <blockquote> 
   <p>幅度缩放(归一化)<br> 离散化/分箱分桶(等距pd.cut、等频pd.qut)(非线性/加速/特征交叉/健壮性)<br> 统计值（max min quantile)<br> 四则运算<br> 幅度变换（有一些模型对于输入数据有分布假设，lr假设输入连续值特征符合正态分布，可以使用log1p/exp）<br> 监督学习分箱（用决策树建模，用决策树学习连续值划分方式，把决策树中间节点取出来作为组合特征），sklearn.DecisionTree中有个apply函数，可以用于监督学习分箱</p> 
  </blockquote> </li><li> <p>类别型</p> 
  <blockquote> 
   <p>one-hot-encoding<br> label-encoding<br> binary-encoding<br> category-encoding(利用贝叶斯的先验做一些变换)</p> 
  </blockquote> </li><li> <p>时间型</p> 
  <blockquote> 
   <p>时间点/时间段（星期几、几点钟）<br> 时间分组（工作日、周末、法定节假日…)<br> 时间间隔（距离当前为止…)<br> 和数值型一起做统计特征的时候，会选区不同的时间窗</p> 
  </blockquote> </li><li> <p>文本型</p> 
  <blockquote> 
   <p>词袋模型<br> tf-idf<br> lda<br> word2vec/word embedding</p> 
  </blockquote> </li></ol> 
<ul><li> <p>特征选择</p> 
  <blockquote> 
   <p>过滤型(filter)，可以根据一些卡方检验等做一些过滤<br> 包裹型(wrapper)<br> 嵌入型（embedded)<br> 基于树模型去判断特征的重要去，做实验去筛选</p> 
  </blockquote> </li></ul> 
<h4><a id="_45"></a>简单工具</h4> 
<ul><li> <p>缺失值处理</p> 
  <blockquote> 
   <p>pandas fillna</p> 
  </blockquote> <pre><code>  	age = df_train['Age'].fillna(value=df_train['Age'].mean())
  	df_train.loc[:,'Age']=age
</code></pre> 
  <blockquote> 
   <p>sklearn Imputer</p> 
  </blockquote> <pre><code>  from sklearn.preprocessing import Imputer
  imp = Imputer(missing_values='NaN', strategy='mean', axis=0)
  age = imp.fit_transform(df_train[['Age']].values)
  df_train.loc[:,'Age']=age
</code></pre> 
  <ul><li>幅度变换</li></ul> </li></ul> 
<ol><li> <p>numpy+apply</p> <pre><code>import numpy as np
log_age = df_train['Age'].apply(lambda x:np.log(x))
df_train.loc[:,'log_age'] = log_age

#对几列数据同时进行操作
import pandas as pd
import numpy as np
df = pd.DataFrame ({'a' : np.random.randn(6),
             'b' : ['foo', 'bar'] * 3,
             'c' : np.random.randn(6)})
def my_test(a, b):
    return a + b
df['Value'] = df.apply(lambda row: my_test(row['a'], row['c']), axis=1)
</code></pre> </li><li> <p>最大值-最小值</p> <pre><code> from sklearn.preprocessing import MinMaxScaler
 mm_scaler = MinMaxScaler()
 fare_trans = mm_scaler.fit_transform(df_train[['Fare']])
</code></pre> </li><li> <p>标准化</p> <pre><code>from sklearn.preprocessing import StandardScaler
std_scaler = StandardScaler()
fare_std_trans = std_scaler.fit_transform(df_train[['Fare']])
</code></pre> </li></ol> 
<ul><li>统计值</li></ul> 
<ol><li> <p>max,min，quantile</p> <pre><code> # 最大最小值
 max_age = df_train['Age'].max()
 min_age = df_train["Age"].min()
 #分位数
 age_quarter_1 = df_train['Age'].quantile(0.25)
 age_quarter_3 = df_train['Age'].quantile(0.75)
</code></pre> </li></ol> 
<ul><li> <p>四则运算</p> <pre><code>  df_train.loc[:,'family_size'] = df_train['SibSp']+df_train['Parch']+1
</code></pre> </li><li> <p>高次特征与交叉特征</p> <pre><code> from sklearn.preprocessing import PolynomialFeatures
 poly = PolynomialFeatures(degree=2)
 poly_fea = poly.fit_transform(df_train[['SibSp','Parch']])
</code></pre> 
  <blockquote> 
   <p>离散化后，使用高次特征从某种程度上理解为交叉特征</p> 
  </blockquote> </li><li> <p>离散化与分箱分桶</p> <pre><code> df_train.loc[:, 'fare_cut'] = pd.cut(df_train['Fare'], 5)
 # 等频切分
 df_train.loc[:,'fare_qcut'] = pd.qcut(df_train['Fare'], 5)
</code></pre> </li><li> <p>OneHot encoding/独热向量编码</p> <pre><code>   #pandas get_dummies
   embarked_oht = pd.get_dummies(df_train[['Embarked']])
   #OneHotEncoder()
   fare_qcut_oht = pd.get_dummies(df_train[['fare_qcut']])
</code></pre> </li></ul> 
<ol start="7"><li> <p>日期型</p> 
  <blockquote> 
   <p>pandas to_datetime</p> 
  </blockquote> <pre><code> car_sales = pd.read_csv('car_data.csv')
 car_sales.loc[:,'date'] = pd.to_datetime(car_sales['date_t'])
 #取出月份
 car_sales.loc[:,'month'] = car_sales['date'].dt.month
 # 取出来是几号
 car_sales.loc[:,'dom'] = car_sales['date'].dt.day
 # 取出一年当中的第几天
 car_sales.loc[:,'doy'] = car_sales['date'].dt.dayofyear
 # 取出星期几
 car_sales.loc[:,'dow'] = car_sales['date'].dt.dayofweek
</code></pre> </li></ol> 
<h4><a id="_142"></a>文本类型数据处理</h4> 
<ul><li> <p>词袋模型</p> <pre><code>  from sklearn.feature_extraction.text import CountVectorizer
  vectorizer = CountVectorizer()
  corpus = [
      'This is a very good class',
      'students are very very very good',
      'This is the third sentence',
      'Is this the last doc'
  ]
  X = vectorizer.fit_transform(corpus)
  vectorizer.get_feature_names()
  #查看结果
  X.toarray()

  vec = CountVectorizer(ngram_range=(1,3))
  X_ngram = vec.fit_transform(corpus)
  vec.get_feature_names()
</code></pre> </li><li> <p>TF-IDF</p> <pre><code>   from sklearn.feature_extraction.text import TfidfVectorizer
   tfidf_vec = TfidfVectorizer()
   tfidf_X = tfidf_vec.fit_transform(corpus)
   tfidf_vec.get_feature_names()
</code></pre> </li><li> <p>组合特征</p> 
  <blockquote> 
   <p>自行实现</p> 
  </blockquote> </li></ul> 
<h4><a id="_173"></a>特征选择</h4> 
<ul><li>特征选择之Filter</li></ul> 
<ol><li> <p>可以选择方差法：如果某个特征的取值差异不大，通常认为特征对区分样本的贡献度不大，因此在构造特征过程中去掉方差小于阈值的特征。注：方差选择法适用于离散型特征，离散型特征需要离散化后使用</p> <pre><code> from sklearn.datasets import load_iris
 iris = load_iris()
 print("iris特征名称\n",iris.feature_names)
 print("iris特征矩阵\n",iris.data)
 # 特征选择--方差选择法
 from sklearn.feature_selection import VarianceThreshold
 vt = VarianceThreshold(threshold = 1)  # threshold为方差的阈值，默认0
 vt = vt.fit_transform(iris.data)       # 函数返回值为特征选择后的特征
 print("方差选择法选择的特征\n",vt)
</code></pre> </li><li> <p>可以选择卡方检验法：使用卡方检验作为特征评分标准，卡方检验越大，相关性越强。</p> <pre><code> 	from sklearn.feature_selection import SelectKBest
 	from sklearn.datasets import load_iris
 	iris = load_iris()
 	X, y = iris.data, iris.target
 	X_new = SelectKBest(k=2).fit_transform(X,y)
</code></pre> </li><li> <p>皮尔森相关系数法</p> <pre><code> # -*- coding: utf-8 -*-
 # 载入数据
 from sklearn.datasets import load_iris
 irisdata = load_iris()
 # 特征选择（pearson相关系数法）
 from sklearn.feature_selection import SelectKBest  # 移除topK外的特征
 from scipy.stats import pearsonr                   # 计算皮尔森相关系数
 from numpy import array
 """
 # 函数返回值：保留topk特征，移除topk外特征
 # 第一个参数：皮尔森相关系数（输入特征矩阵和目标向量，输出二元组（评分，P），二数组第i项为第i个特征的评分和p值
 # 第二个参数：topK个数
 """
 skb = SelectKBest(lambda X, Y: tuple(map(tuple,array(list(map(lambda x:pearsonr(x, Y), X.T))).T)), k=3)
 skb = skb.fit_transform(irisdata.data, irisdata.target)
</code></pre> </li><li> <p>互信息系数法（相关性）</p> 
  <blockquote> 
   <p>特点：互信息系数法能够衡量各种相关性的特征集，计算相对复杂</p> 
  </blockquote> </li></ol> 
<ul><li>特征选择之包裹型/wrapper</li></ul> 
<ol><li> <p>LVW</p> 
  <blockquote> 
   <p>此方法是一种典型的包裹式特征选择方法，他在拉斯维加斯方法框架下使用随机策略来进行子集搜索，并以最终分类器的误差作为特征子集的评价标准。每次从特征集A中随机产生一个特征子集a,然后使用交叉验证的方法，评估学习器在a上的误差，若误差小于以前获得的最小误差，或者与之前的最小误差相当但a中包含的特征数更少，则将a保留下来</p> 
  </blockquote> </li><li> <p>RFE（递归消除法）</p> 
  <blockquote> 
   <p>对特征进行训练，得到权重；提出权重最小的特征，构成新的集合；不断重复直至满足条件为止</p> 
  </blockquote> <pre><code> from sklearn.feature_selection import RFE
 from sklearn.ensemble import RandomForestClassifier
 rf = RandomForestClassifier()
 rfe = RFE(estimator=rf, n_features_to_select=2)
 X_rfe = rfe.fit_transform(X,y)
</code></pre> </li></ol> 
<ul><li> <p>特征选择之嵌入型</p> 
  <blockquote> 
   <p>过滤式和包裹式选择方法中，特征选择过程与学习器训练过程有明显区别；而嵌入式特征选择与学习器训练过程融为一体，两者在同一个过程中完成，即在学习器训练过程中自动进行特征选择。主要方法有：岭回归、与基于树模型的特征选择：</p> 
  </blockquote> <pre><code> from sklearn.feature_selection import SelectFromModel
 from sklearn.linear_model import LogisticRegression
 #带L1惩罚项的逻辑回归作为基模型的特征选择
 SelectFromModel(LogisticRegression(penalty="l1", C=0.1)).fit_transform(iris.data, iris.target)
 #基于树模型的特征选择
 from sklearn.ensemble import GradientBoostingClassifier
 #GBDT作为基模型的特征选择
 SelectFromModel(GradientBoostingClassifier()).fit_transform(iris.data, iris.target)
</code></pre> </li></ul> 
<h4><a id="sklearn_247"></a>模型调优，sklearn用法</h4> 
<ol><li> <p>sklearn中的交叉验证</p> <pre><code> from sklearn.model_selection import cross_val_score
 from sklearn.datasets import load_iris
 from sklearn.linear_model import LogisticRegression
 
 iris = load_iris()
 logreg = LogisticRegression()
 
 scores = cross_val_score(logreg, iris.data, iris.target)
 print("cross-validation scores: ", scores)
</code></pre> </li><li> <p>GridSearchCV = grid_search(产出候选超参数)+cross_validation(评估方式)</p> 
  <blockquote> 
   <p>先设定参数候选字典</p> 
  </blockquote> <pre><code> param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],
               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}
</code></pre> 
  <blockquote> 
   <p>建模</p> 
  </blockquote> <pre><code> 	from sklearn.model_selection import GridSearchCV
 	from sklearn.svm import SVC
 	grid_search = GridSearchCV(SVC(), param_grid, cv=5)
</code></pre> 
  <blockquote> 
   <p>训练</p> 
  </blockquote> <pre><code> 	grid_search.fit(X_train, y_train)
</code></pre> 
  <blockquote> 
   <p>获取最好的参数与得分</p> 
  </blockquote> <pre><code> 	grid_search.best_params_
 	grid_search.best_score_
</code></pre> 
  <blockquote> 
   <p>获取最优模型</p> 
  </blockquote> <pre><code> 	grid_search.best_estimator_
</code></pre> </li><li> <p>K折采样</p> <pre><code> from sklearn.model_selection import KFold
 from sklearn.model_selection import StratifiedKFold

 #标准采样
 kfold = KFold(n_folds=3, shuffle=True, random_state=0)
 cross_val_score(logreg, iris.data, iris.target, cv=kfold)
 #分层采样
 kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)
 cross_val_score(logreg, iris.data, iris.target, cv=kfold)
</code></pre> </li><li> <p>留一法交叉验证</p> <pre><code> from sklearn.model_selection import LeaveOneOut
 loo = LeaveOneOut()
 scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)
 print("number of cv iterations: ", len(scores))
 print("mean accuracy: ", scores.mean())
</code></pre> </li><li> <p>乱序分割交叉验证</p> <pre><code> from sklearn.model_selection import ShuffleSplit
 shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_iter=10)
 cross_val_score(logreg, iris.data, iris.target, cv=shuffle_split)
</code></pre> </li></ol> 
<h4><a id="_314"></a>模型融合</h4> 
<ul><li> <p>mlxtend(用于模型集成)</p> </li><li> <p>投票器模型融合</p> <pre><code>  from sklearn import model_selection
  from sklearn.linear_model import LogisticRegression
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.svm import SVC
  from sklearn.ensemble import VotingClassifier
  
  X = array[:,0:8]
  Y = array[:,8]
  kfold = model_selection.KFold(n_splits=5, random_state=2018)
  
  # 创建投票器的子模型
  estimators = []
  model_1 = LogisticRegression()
  estimators.append(('logistic', model_1))
  
  model_2 = DecisionTreeClassifier()
  estimators.append(('dt', model_2))
  
  model_3 = SVC()
  estimators.append(('svm', model_3))
  
  # 构建投票器融合
  ensemble = VotingClassifier(estimators)
  result = model_selection.cross_val_score(ensemble, X, Y, cv=kfold)
</code></pre> </li><li> <p>Bagging</p> <pre><code>  from sklearn.ensemble import BaggingClassifier
  dt = DecisionTreeClassifier()
  num = 100
  kfold = model_selection.KFold(n_splits=5, random_state=2018)
  model = BaggingClassifier(base_estimator=dt, n_estimators=num, random_state=2018)
  result = model_selection.cross_val_score(model, X, Y, cv=kfold)
  print(result.mean())
</code></pre> </li><li> <p>RandomForest</p> <pre><code>  from sklearn.ensemble import RandomForestClassifier
  num_trees = 100
  max_feature_num = 5
  kfold = model_selection.KFold(n_splits=5, random_state=2018)
  model = RandomForestClassifier(n_estimators=num_trees, max_features=max_feature_num)
  result = model_selection.cross_val_score(model, X, Y, cv=kfold)
  print(result.mean())
</code></pre> </li><li> <p>Adaboost</p> <pre><code>  from sklearn.ensemble import AdaBoostClassifier
  num_trees = 25
  kfold = model_selection.KFold(n_splits=5, random_state=2018)
  model = AdaBoostClassifier(n_estimators=num_trees, random_state=2018)
  result = model_selection.cross_val_score(model, X, Y, cv=kfold)
  print(result.mean())
</code></pre> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/85a7526dc60fc348d91f7959af152679/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Opencv--findHomography 与 getPerspectiveTransform异同</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3cdc50fcf677f868e49873d9071b8940/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">18B20驱动小经验</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>