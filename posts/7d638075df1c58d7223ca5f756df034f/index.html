<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>关于ffmpeg的硬解码 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="关于ffmpeg的硬解码" />
<meta property="og:description" content="1. 参考文章
FFmpeg 4.x 从入门到精通（二）—— QT 中用 FFmpeg 实现硬解码并使用QImage显示_q2nAmor的博客-CSDN博客_av_hwdevice_ctx_create 2.环境
Qt &#43; ffmpeg &#43; cuda 下载ffmpeg431，因为网上现版本初入较难，我用的是先前前辈的库等内容
bin文件下内容：
include文件下内容
lib文件下内容
3.代码功能：打开H264编码格式的.mp4文件，通过硬件设备对MP4文件进行转码。即不占用CPU资源的情况下解析视频
1）.pro工程文件需要识别库
$$PWD代表当前工程（.pro）所在的路径
INCLUDEPATH &#43;= $$PWD/ffmpeg/include LIBS &#43;= $$PWD/ffmpeg/lib/avcodec.lib \ $$PWD/ffmpeg/lib/avdevice.lib \ $$PWD/ffmpeg/lib/avfilter.lib \ $$PWD/ffmpeg/lib/avformat.lib \ $$PWD/ffmpeg/lib/avutil.lib \ $$PWD/ffmpeg/lib/postproc.lib \ $$PWD/ffmpeg/lib/swresample.lib \ $$PWD/ffmpeg/lib/swscale.lib ###################链接动态库 # -L表示路径 -l（小写的L）表示动态库名 LIBS &#43;= -L$$PWD/ffmpeg/bin -lavcodec-58 LIBS &#43;= -L$$PWD/ffmpeg/bin -lavdevice-58 LIBS &#43;= -L$$PWD/ffmpeg/bin -lavformat-58 LIBS &#43;= -L$$PWD/ffmpeg/bin -lpostproc-55 LIBS &#43;= -L$$PWD/ffmpeg/bin -lswresample-3 LIBS &#43;= -L$$PWD/ffmpeg/bin -lswscale-5 2）main." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7d638075df1c58d7223ca5f756df034f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-09T18:33:39+08:00" />
<meta property="article:modified_time" content="2022-08-09T18:33:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">关于ffmpeg的硬解码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>1.    参考文章</p> 
<pre><a href="https://blog.csdn.net/u012534831/article/details/114385568" title="FFmpeg 4.x 从入门到精通（二）—— QT 中用 FFmpeg 实现硬解码并使用QImage显示_q2nAmor的博客-CSDN博客_av_hwdevice_ctx_create">FFmpeg 4.x 从入门到精通（二）—— QT 中用 FFmpeg 实现硬解码并使用QImage显示_q2nAmor的博客-CSDN博客_av_hwdevice_ctx_create</a>
</pre> 
<p>2.环境</p> 
<p>Qt  +   ffmpeg  +   cuda    下载ffmpeg431，因为网上现版本初入较难，我用的是先前前辈的库等内容</p> 
<p>bin文件下内容：</p> 
<p><img alt="" height="378" src="https://images2.imgbox.com/ed/9d/7GqZ1tl4_o.png" width="738"></p> 
<p> include文件下内容<img alt="" height="309" src="https://images2.imgbox.com/24/6b/V5UyCgtt_o.png" width="617"></p> 
<p></p> 
<p></p> 
<p> lib文件下内容</p> 
<p><img alt="" height="639" src="https://images2.imgbox.com/e1/83/mGoPAh2X_o.png" width="763"></p> 
<p> 3.代码功能：打开H264编码格式的.mp4文件，通过硬件设备对MP4文件进行转码。即不占用CPU资源的情况下解析视频</p> 
<p>1）.pro工程文件需要识别库</p> 
<p>$$PWD代表当前工程（.pro）所在的路径</p> 
<pre><code>INCLUDEPATH += $$PWD/ffmpeg/include
LIBS += $$PWD/ffmpeg/lib/avcodec.lib \
        $$PWD/ffmpeg/lib/avdevice.lib \
        $$PWD/ffmpeg/lib/avfilter.lib \
        $$PWD/ffmpeg/lib/avformat.lib \
        $$PWD/ffmpeg/lib/avutil.lib \
        $$PWD/ffmpeg/lib/postproc.lib \
        $$PWD/ffmpeg/lib/swresample.lib \
        $$PWD/ffmpeg/lib/swscale.lib
###################链接动态库
# -L表示路径  -l（小写的L）表示动态库名
LIBS += -L$$PWD/ffmpeg/bin -lavcodec-58
LIBS += -L$$PWD/ffmpeg/bin -lavdevice-58
LIBS += -L$$PWD/ffmpeg/bin -lavformat-58
LIBS += -L$$PWD/ffmpeg/bin -lpostproc-55
LIBS += -L$$PWD/ffmpeg/bin -lswresample-3
LIBS += -L$$PWD/ffmpeg/bin -lswscale-5</code></pre> 
<pre>2）main.cpp</pre> 
<pre><code>#include "mainwindow.h"
#include &lt;QApplication&gt;
int main(int argc, char *argv[])
{
    QApplication a(argc, argv);
    MainWindow w;
    w.show();
    w.init();
    w.play();
    return a.exec();
}</code></pre> 
<pre>3)mainwindow.h文件
</pre> 
<pre><code>#ifndef MAINWINDOW_H
#define MAINWINDOW_H

#include &lt;QMainWindow&gt;
#include&lt;thread&gt;
extern "C"
{
    #include "libavcodec/avcodec.h"
    #include "libavformat/avformat.h"
    #include "libavutil/pixfmt.h"
    #include "libswscale/swscale.h"
    #include "libavdevice/avdevice.h"
    #include &lt;libavutil/pixdesc.h&gt;
    #include &lt;libavutil/hwcontext.h&gt;
    #include &lt;libavutil/opt.h&gt;
    #include &lt;libavutil/avassert.h&gt;
    #include &lt;libavutil/imgutils.h&gt;
}
typedef struct DecodeContext {
    AVBufferRef *hw_device_ref;
} DecodeContext;

namespace Ui {
class MainWindow;
}

class MainWindow : public QMainWindow
{
    Q_OBJECT

public:
    explicit MainWindow(QWidget *parent = nullptr);
    ~MainWindow();
    void init();
    void play();
private:
    AVBufferRef *hw_device_ctx = nullptr;
    static enum AVPixelFormat hw_pix_fmt;
    int ret;
    enum AVHWDeviceType type;
    std::thread m_decodecThread;
    Ui::MainWindow *ui;
    AVFormatContext *pAVFormatCtx;
    AVCodecContext *pAVCodecCtx;
    SwsContext *pSwsCtx = nullptr;
    uint8_t *pRgbBuffer = nullptr;
    AVPacket packet;
    AVFrame *pAVFrameRGB = nullptr;
    int iVideoIndex = -1;
    QImage m_image;
    bool isFinish  =false;
    void decodec();
signals:
    void signalDraw();
public slots:
    void slotDraw();
protected:
    void paintEvent(QPaintEvent *event) override;
private:
    int hw_decoder_init(AVCodecContext *ctx, const enum AVHWDeviceType type);
    static enum AVPixelFormat get_hw_format(AVCodecContext *ctx,const enum AVPixelFormat *pix_fmts);
};

#endif // MAINWINDOW_H</code></pre> 
<pre>4)mainwindow.c文件</pre> 
<pre><code>#include "mainwindow.h"
#include "ui_mainwindow.h"
#include &lt;QDebug&gt;
#include &lt;QPainter&gt;
#include&lt;thread&gt;
#include &lt;QDateTime&gt;
enum AVPixelFormat MainWindow::hw_pix_fmt = AV_PIX_FMT_NONE;
MainWindow::MainWindow(QWidget *parent) :
    QMainWindow(parent),
    ui(new Ui::MainWindow)
{
    ui-&gt;setupUi(this);
    connect(this,&amp;MainWindow::signalDraw,this,&amp;MainWindow::slotDraw);
}

MainWindow::~MainWindow()
{
    delete ui;
}
int MainWindow::hw_decoder_init(AVCodecContext *ctx, const enum AVHWDeviceType type)
{
    int err = 0;
    //初始化硬件，打开硬件，绑定到具体硬件的指针函数上
    //创建硬件设备相关的上下文信息AVHWDeviceContext，包括分配内存资源、对硬件设备进行初始化
    if ((err = av_hwdevice_ctx_create(&amp;hw_device_ctx, type,
                                      nullptr, nullptr, 0)) &lt; 0) {
        qDebug()&lt;&lt;"Failed to create specified HW device.\n";
        return err;
    }
    /* 需要把这个信息绑定到AVCodecContext
     * 如果使用软解码则默认有一个软解码的缓冲区(获取AVFrame的)，而硬解码则需要额外创建硬件解码的缓冲区
     *  这个缓冲区变量为hw_frames_ctx，不手动创建，则在调用avcodec_send_packet()函数内部自动创建一个
     *  但是必须手动赋值硬件解码缓冲区引用hw_device_ctx(它是一个AVBufferRef变量)
     */
    ctx-&gt;hw_device_ctx = av_buffer_ref(hw_device_ctx);
    return err;
}
enum AVPixelFormat MainWindow::get_hw_format(AVCodecContext *ctx,const enum AVPixelFormat *pix_fmts)
{
    const enum AVPixelFormat *p;

    for (p = pix_fmts; *p != -1; p++) {
        if (*p == hw_pix_fmt)
            return *p;
    }
    qDebug()&lt;&lt;"Failed to get HW surface format.\n";
    return AV_PIX_FMT_NONE;
}

void MainWindow::init()
{
    //文件路径
    std::string file = "C:\\Users\\qf\\Desktop\\image\\15.mp4";
    //描述多媒体文件的构成及其基本信息，MP4文件的操作句柄
    if (avformat_open_input(&amp;pAVFormatCtx, file.data(), nullptr, nullptr) != 0)
    {
        qDebug() &lt;&lt;"open file fail";
        avformat_free_context(pAVFormatCtx);
        return;
    }
    //解析音视频流信息
    if (avformat_find_stream_info(pAVFormatCtx, nullptr) &lt; 0)
    {
        qDebug() &lt;&lt;"vformat find stream fail";
        avformat_close_input(&amp;pAVFormatCtx);
        return;
    }
    //根据解码器枚举类型找到解码器
    AVCodec *pAVCodec;
    int ret = av_find_best_stream(pAVFormatCtx, AVMEDIA_TYPE_VIDEO, -1, -1, &amp;pAVCodec, 0);
    if (ret &lt; 0) {
        qDebug()&lt;&lt; "av_find_best_stream faliture";
        avformat_close_input(&amp;pAVFormatCtx);
        return;
    }
    qDebug()&lt;&lt; "av_find_best_stream 成功";
    iVideoIndex = ret;
    //查找解码器
    type = av_hwdevice_find_type_by_name("cuda");
    if (type == AV_HWDEVICE_TYPE_NONE) {
        qDebug()&lt;&lt;"不支持所输入的解码器"&lt;&lt;type;
        qDebug()&lt;&lt;"Available device types:";
        while((type = av_hwdevice_iterate_types(type)) != AV_HWDEVICE_TYPE_NONE)
            qDebug()&lt;&lt;av_hwdevice_get_type_name(type);
    }
    qDebug()&lt;&lt; "av_hwdevice_find_type_by_name 寻找目标解码器成功";
    // 所有支持的硬件解码器保存在AVCodec的hw_configs变量中。对于硬件编码器来说又是单独的AVCodec
    for (int i = 0;; i++)
    {
        //获取到该解码器codec的硬件属性，比如可以支持的目标像素格式等
        const AVCodecHWConfig *config = avcodec_get_hw_config(pAVCodec, i);
        if (!config) {
            qDebug()&lt;&lt; "avcodec_get_hw_config 失败";
            qDebug()&lt;&lt; "Decoder %s does not support device type %s.\n"&lt;&lt;pAVCodec-&gt;name, av_hwdevice_get_type_name(type);
        }
        if (config-&gt;methods &amp; AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX &amp;&amp;config-&gt;device_type == type) {
            hw_pix_fmt = config-&gt;pix_fmt;
            qDebug()&lt;&lt; "avcodec_get_hw_config 成功";
            break;
        }
    }
    //申请空间 用于流中内容传参
    pAVCodecCtx = avcodec_alloc_context3(pAVCodec);
    if (pAVCodecCtx == nullptr)
    {
        qDebug() &lt;&lt;"avcodec_alloc_context3  申请空间失败";
        avformat_close_input(&amp;pAVFormatCtx);
        return;
    }
    //传参
    ret = avcodec_parameters_to_context(pAVCodecCtx,pAVFormatCtx-&gt;streams[iVideoIndex]-&gt;codecpar);
    if (ret &lt; 0)
    {
        qDebug() &lt;&lt;"avcodec_parameters_to_context 传参过程失败";
        avformat_close_input(&amp;pAVFormatCtx);
        return;
    }
    //配置获取硬件加速器像素格式的函数；该函数实际上就是将AVCodec中AVHWCodecConfig中的pix_fmt返回
    pAVCodecCtx-&gt;get_format  = get_hw_format;
    //使用自定义函数进行判断
    if (hw_decoder_init(pAVCodecCtx, type) &lt; 0)
    {
        qDebug()&lt;&lt;"hw_decoder_init 自定义函数失败";
        return ;
    }
    //打开解码器
    if (avcodec_open2(pAVCodecCtx, pAVCodec, nullptr) &lt; 0)
    {
        qDebug()&lt;&lt;"avcodec_open2 解码器打开失败";
        return;
    }
    //为用于解码的帧申请内存，打印视频宽高信息
    pAVFrameRGB = av_frame_alloc();
    qDebug()&lt;&lt;"pAVCodecCtx-&gt;width:" &lt;&lt; pAVCodecCtx-&gt;width&lt;&lt;"pAVCodecCtx-&gt;height:"  &lt;&lt; pAVCodecCtx-&gt;height;
    int size = av_image_get_buffer_size(AVPixelFormat(AV_PIX_FMT_RGB32), pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, 1);
    pRgbBuffer = (uint8_t *)(av_malloc(size));
    //旧版本avpicture_fill，将申请好的空间进行分配
    av_image_fill_arrays(pAVFrameRGB-&gt;data, pAVFrameRGB-&gt;linesize, pRgbBuffer, AV_PIX_FMT_RGB32,
                         pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, 1);
    //AVpacket 用来存放解码数据
    av_new_packet(&amp;packet, pAVCodecCtx-&gt;width * pAVCodecCtx-&gt;height);
    qDebug()&lt;&lt;"pAVCodecCtx-&gt;pix_fmt:" &lt;&lt; pAVCodecCtx-&gt;pix_fmt;

    qDebug()&lt;&lt;"init 完成";
}
void MainWindow::slotDraw()
{
    update();
}

void MainWindow::paintEvent(QPaintEvent *event)
{
    qDebug()&lt;&lt;"绘画事件进入";
    QPainter painter(this);
    painter.setBrush(Qt::black);
    painter.drawRect(0, 0, this-&gt;width(), this-&gt;height());

    if (m_image.size().width() &lt;= 0)
        return;

    //比例缩放
    QImage img = m_image.scaled(this-&gt;size(),Qt::KeepAspectRatio);
    int x = this-&gt;width() - img.width();
    int y = this-&gt;height() - img.height();

    x /= 2;
    y /= 2;

    //QPoint(x,y)为中心绘制图像
    painter.drawImage(QPoint(x,y),img);
}


void MainWindow::play()
{
    qDebug()&lt;&lt;"播放开始";
    m_decodecThread = std::thread([this](){decodec();});
    m_decodecThread.detach();
}

void MainWindow::decodec()
{
    qDebug()&lt;&lt;"进入解析";
    //读取码流中视频帧
    while (true)
    {
        AVFrame *frame = nullptr, *sw_frame = nullptr;
        AVFrame *tmp_frame = nullptr;
        int ret = av_read_frame(pAVFormatCtx, &amp;packet);
        if(ret != 0)
        {
            qDebug()&lt;&lt;"file end";
            isFinish = !isFinish;
            return;
        }
        if (packet.stream_index != iVideoIndex)
        {
            av_packet_unref(&amp;packet);
            continue;
        }
        int iGotPic = AVERROR(EAGAIN);
        //解码一帧视频数据
        iGotPic = avcodec_send_packet(pAVCodecCtx, &amp;packet);
        if(iGotPic!=0){
            qDebug()&lt;&lt;"avcodec_send_packet error";
            continue;
        }
        if (!(frame = av_frame_alloc()) || !(sw_frame = av_frame_alloc())) {
            qDebug()&lt;&lt; "Can not alloc frame\n";
            ret = AVERROR(ENOMEM);
            continue;
        }
        while (0 == avcodec_receive_frame(pAVCodecCtx, frame))
        {
            qDebug()&lt;&lt;"帧数据解析开始";
            qDebug()&lt;&lt;"frame-&gt;format:" &lt;&lt; frame-&gt;format;//53 AV_PIX_FMT_DXVA2_VLD
            if (frame-&gt;format == hw_pix_fmt) {
                int64_t time = QDateTime::currentDateTime().toMSecsSinceEpoch();
                qDebug() &lt;&lt; "qhttime1:" &lt;&lt; time;
                if ((ret = av_hwframe_transfer_data(sw_frame, frame, 0)) &lt; 0)
                {
                    qDebug()&lt;&lt;"从GPU到CPU数据失败";
                    break;
                }
                qDebug()&lt;&lt;"屏幕投影GPU数据";
                tmp_frame = sw_frame;
            } else
            {
                qDebug()&lt;&lt;"屏幕投影开始数据";
                tmp_frame = frame;
                qDebug()&lt;&lt;"frame img";
            }
            pSwsCtx = sws_getContext(pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, (AVPixelFormat)tmp_frame-&gt;format,
                                         pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, AV_PIX_FMT_RGB32,
                                         SWS_BILINEAR, nullptr, nullptr, nullptr);

            int ret = sws_scale(pSwsCtx, (uint8_t const * const *) tmp_frame-&gt;data, tmp_frame-&gt;linesize, 0,
                                tmp_frame-&gt;height, pAVFrameRGB-&gt;data, pAVFrameRGB-&gt;linesize);
            qDebug()&lt;&lt;"ret:" &lt;&lt; ret;
            QImage img((uint8_t *)pAVFrameRGB-&gt;data[0], tmp_frame-&gt;width, tmp_frame-&gt;height, QImage::Format_RGB32);
            qDebug()&lt;&lt;"开始画图";
            m_image = img;
            qDebug()&lt;&lt;"发送信号";
            emit signalDraw();
            std::this_thread::sleep_for(std::chrono::milliseconds(40));
            qDebug()&lt;&lt;"一帧数据结束";
            qDebug()&lt;&lt;"开始回收一帧结束后的资源";
            sws_freeContext(pSwsCtx);

        }
        av_frame_free(&amp;frame);
        av_frame_free(&amp;sw_frame);
    }
    qDebug()&lt;&lt;"开始回收资源";
    av_free(pAVFrameRGB);
    avcodec_close(pAVCodecCtx);
    avformat_close_input(&amp;pAVFormatCtx);
}</code></pre> 
<pre></pre> 
<pre></pre> 
<pre></pre> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f8012da3742aad804e0f6d6d1cebfc93/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">jenkins安装和配置(二):配置第一个项目</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e3769601a436cdb84e0f1945b4ce04a2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">云服务器搭建深度学习环境</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>