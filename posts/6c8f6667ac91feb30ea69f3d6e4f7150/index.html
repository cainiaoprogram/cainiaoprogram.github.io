<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>轻量化神经网络专题文献综述 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="轻量化神经网络专题文献综述" />
<meta property="og:description" content="本文列出了一些经典的轻型神经网络架构设计的集合，广泛用于移动设备等。轻量级网络的评论文章通常包含模型压缩和处理技巧，可参阅以下系列文章 https://github.com/senbinyu/Computer_Vision_Literatures
1. 综述文献推荐 Cheng Yu et al., 2017, A survey of model compression and acceleration for deep neural networks
Cheng Jian et al., 2018, Recent advances in efficient computation of deep convolutional neural networks
Li Yahui et al., 2018, Lightweight Network Research Based on Deep Learning: A Review
2. 各种网络的综述 shuffleNet, 2018 v1, Zhang Xiangyu
在ResNeXt中，使用组转换（几个通道）； 在mobileNet中，是一个极端的情况，每个通道是一个组，分别进行传输。 在mobileNet-va论文中，1 * 1转换（逐点转换）占94％的MAdds。 ShuffleNet试图避免此问题。 而且，尚未利用不同信道之间的关系。 (组内的卷积不利于通道间信息交流) 通道转换（channel shuffle） 使用1 * 1组转换来替换1 * 1标准转换，以保存MAdds。 组数目，g通常不会太大，例如1,2,3,4,8等。太多的组可能导致每个组中的输入通道太少，从而可能导致性能变差。分成不同的group，然后洗牌式调换，permute，但是又不能用过多的group，否则会导致每组的通道太少" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/6c8f6667ac91feb30ea69f3d6e4f7150/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-17T01:09:19+08:00" />
<meta property="article:modified_time" content="2020-08-17T01:09:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">轻量化神经网络专题文献综述</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h6><a id="_0"></a>本文列出了一些经典的轻型神经网络架构设计的集合，广泛用于移动设备等。轻量级网络的评论文章通常包含模型压缩和处理技巧，可参阅以下系列文章</h6> 
<p>https://github.com/senbinyu/Computer_Vision_Literatures</p> 
<h3><a id="1__3"></a>1. 综述文献推荐</h3> 
<ul><li> <p>Cheng Yu et al., 2017, <a href="https://arxiv.org/abs/1710.09282" rel="nofollow">A survey of model compression and acceleration for deep neural networks</a></p> </li><li> <p>Cheng Jian et al., 2018, <a href="https://link.springer.com/content/pdf/10.1631/FITEE.1700789.pdf" rel="nofollow">Recent advances in efficient computation of deep convolutional neural networks</a></p> </li><li> <p>Li Yahui et al., 2018, <a href="https://ieeexplore.ieee.org/abstract/document/8483963?casa_token=Ro1rJdUIkXoAAAAA:GukzNyQi38qOA4v-B6394PvpFp6R3j0tvvXDNCKnIPkYf5EEA_GtTSfWdvK19WS9Zl4lgP5-mA" rel="nofollow">Lightweight Network Research Based on Deep Learning: A Review</a></p> </li></ul> 
<h3><a id="2__11"></a>2. 各种网络的综述</h3> 
<h4><a id="shuffleNet_2018_13"></a>shuffleNet, 2018</h4> 
<ul><li>v1, Zhang Xiangyu<br> 在ResNeXt中，使用组转换（几个通道）； 在mobileNet中，是一个极端的情况，每个通道是一个组，分别进行传输。 在mobileNet-va论文中，1 * 1转换（逐点转换）占94％的MAdds。 ShuffleNet试图避免此问题。 而且，尚未利用不同信道之间的关系。 (组内的卷积不利于通道间信息交流)</li></ul> 
<ol><li> <p>通道转换（channel shuffle） 使用1 * 1组转换来替换1 * 1标准转换，以保存MAdds。 组数目，<em>g</em>通常不会太大，例如1,2,3,4,8等。太多的组可能导致每个组中的输入通道太少，从而可能导致性能变差。分成不同的group，然后洗牌式调换，permute，但是又不能用过多的group，否则会导致每组的通道太少</p> </li><li> <p>带有随机shuffle和不带有随机shuffle以及带有移动网络的随机播放之间的比较。 在保持相似的网络规模时，shuffleNet的性能优于VGG，ResNet，ResNeXt和mobileNet.作者对比了有无shuffle，明显的有shuffle的表现更好</p> </li></ol> 
<p>Refer to paper <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Zhang_ShuffleNet_An_Extremely_CVPR_2018_paper.html" rel="nofollow">ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</a><br> <img src="https://images2.imgbox.com/f4/4d/z7E2ssWO_o.png" alt="在这里插入图片描述"></p> 
<ul><li>v2, Ma Ningning, Zhang Xiangyu, 2018<br> FLOP只是影响模型速度等众多因素中的一种。在这里，作者为有效的cnn架构设计提出了更实用的指导原则。</li></ul> 
<ol><li> <p>使用内存访问成本（MAC参数）来衡量内存成本。 作者将单纯从FLOPs这个非直接指标衡量模型给转到MAC上，这个指标更能反映内存损失。MAC需要更小才能达到更高的速度。 有一些观察结果：G1 发现channel最好保持一致，因此通道号尝试相同（shuffleNet-v1中的bottleNeck与此相反）；G2 group数目不能过大，<em>g</em> 组不能太大（在shuffleNet-v1中尝试更多组）； G3 模型碎片化（像Googlenet的inception结构）会降低模型的并行能力，即网络碎片会降低并行度（mobileNet v2反对）； G4 element-wise的操作会影响性能，逐个元素的操作是不可忽略的（深度使用ReLU6也是矛盾的）。一大堆观点都与之前的发现不太符合。</p> </li><li> <p>因此，做了一些修改，如下图所示。 这些操作均遵循上述准则。 例如，再次用1 * 1 conv替换1 * 1 group conv以遵循第二条规则，通道号尝试保持相同。 在这些指导下，shuffleNet-v2在准确性和速度上均取得了令人满意的结果。在此，尽量和发现的原则G1-G4一致</p> </li><li> <p>与densitytNet和condenseNet的联系。 特征通道的一半（当c’= c / 2时）直接通过该块并加入下一个块，例如densityNet和condenseNet中的<em>feature复用</em>。 它们都支持相邻层之间的连接比其他层更牢固</p> </li></ol> 
<p>Refer to paper <a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Ningning_Light-weight_CNN_Architecture_ECCV_2018_paper.html" rel="nofollow">ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design</a><br> <img src="https://images2.imgbox.com/51/a5/IScKuBSe_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="MNASNet_Tan_Mingxing_et_al_2019_37"></a>MNASNet, Tan Mingxing et al., 2019</h4> 
<p>mobile NASNet，在ImageNet上是mobileNet-v2的1.8倍速度，pixel mobile的推理延迟为78ms。 但是，架构搜索的计算成本很高。</p> 
<ol><li>使用强化学习方法搜索架构，其准确性主要取决于架构的设计，而无需大量修改参数。 这表明搜索的体系结构是好的。 但是该架构类似于MobileNet-v2，这也意味着尽管搜索结构模仿了MobileNet，但人类的设计也非常不错，说明人工设计的网络架构也是非常精简有效的</li></ol> 
<p>Refer to paper <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tan_MnasNet_Platform-Aware_Neural_Architecture_Search_for_Mobile_CVPR_2019_paper.html" rel="nofollow">MnasNet: Platform-Aware Neural Architecture Search for Mobile</a><br> <img src="https://images2.imgbox.com/f9/cf/u41Xqkf7_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="MobileNet_Andrew_G_Howard_et_al_2017_45"></a>MobileNet, Andrew G. Howard et al. 2017</h4> 
<ul><li>v1, 适用于移动和嵌入式视觉应用的高效模型。 与squeezeNet相比，参数要少得多，准确性更高。</li></ul> 
<ol><li> <p>深度可分离卷积：两部分，1）深度卷积，对于M个通道，我们有M个内核，每个通道对应一个内核； 2）逐点卷积，我们使用1 * 1内核进行卷积，因此是逐点卷积，请参见下图。 这两个操作可以保存参数。 原来是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           M 
          
         
           ∗ 
          
         
           N 
          
         
           ∗ 
          
          
          
            D 
           
          
            K 
           
          
         
           ∗ 
          
          
          
            D 
           
          
            K 
           
          
         
           ∗ 
          
         
           i 
          
         
           m 
          
         
           a 
          
         
           g 
          
         
           e 
          
         
           S 
          
         
           i 
          
         
           z 
          
         
           e 
          
         
        
          M * N * D_K * D_K * imageSize 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="mord mathdefault">e</span></span></span></span></span>，现在是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           M 
          
         
           ∗ 
          
          
          
            D 
           
          
            K 
           
          
         
           ∗ 
          
          
          
            D 
           
          
            K 
           
          
         
           ∗ 
          
         
           i 
          
         
           m 
          
         
           a 
          
         
           g 
          
         
           e 
          
         
           S 
          
         
           i 
          
         
           z 
          
         
           e 
          
         
        
          M * D_K * D_K * imageSize 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.328331em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="mord mathdefault">e</span></span></span></span></span> + <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           N 
          
         
           ∗ 
          
         
           M 
          
         
           ∗ 
          
         
           i 
          
         
           m 
          
         
           a 
          
         
           g 
          
         
           e 
          
         
           S 
          
         
           i 
          
         
           z 
          
         
           e 
          
         
        
          N * M * imageSize 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.10903em;">M</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord mathdefault">i</span><span class="mord mathdefault">m</span><span class="mord mathdefault">a</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mord mathdefault">e</span><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">i</span><span class="mord mathdefault" style="margin-right: 0.04398em;">z</span><span class="mord mathdefault">e</span></span></span></span></span>。 M是输入通道，N是输出通道</p> </li><li> <p>较薄的模型，即模型压缩。 模型收缩超参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           α 
          
         
        
          \alpha 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span></span></span></span></span>，用于输入和输出通道。 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           ρ 
          
         
        
          \rho 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault">ρ</span></span></span></span></span>用于图像分辨率，但是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           ρ 
          
         
        
          \rho 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord mathdefault">ρ</span></span></span></span></span>仅减少FLOP，但不减少参数数量。</p> </li><li> <p>MobileNet可用于许多领域，例如对象检测，大规模地理定位，人脸属性。 在“人脸”属性中，蒸馏得到了验证，小型网络的行为类似于大型模型。</p> </li></ol> 
<p>Refer to paper <a href="https://arxiv.org/abs/1704.04861" rel="nofollow">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a><br> <img src="https://images2.imgbox.com/45/d6/vUeLfCzF_o.png" alt="在这里插入图片描述"></p> 
<ul><li>v2, Mark Handler, Andrew Howard et al., 2018<br> v1 有一些问题，深度转换包含许多0内核，这意味着训练不够好. (depthwise训出来的kernel有不少是空的，过小的kernel size加上ReLU的激活影响，0的部分无法恢复)</li></ul> 
<p>创新的部分是inverted residual structures + linear bottleneck, 得到了令人满意的结果 vs mobileNet-v1: 75ms vs 113ms; 3.4M vs 4.2M parameters; 72 vs 70.6 Top1 on ImageNet.</p> 
<ol><li>inverted residual structure, 1 * 1扩展通道+ ReLU6，3 * 3深度转换+ ReLU6，然后1 * 1使用线性函子，删除激活以保持兴趣流形manifolds of interest，<em>反向残差带有linerar bottleneck</em>。 （低尺寸，ReLU会破坏感兴趣的流形，因此在这里使用线性函子）</li></ol> 
<p>Refer to paper <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Sandler_MobileNetV2_Inverted_Residuals_CVPR_2018_paper.html" rel="nofollow">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a><br> <img src="https://images2.imgbox.com/ef/02/CDOzN2DL_o.png" alt="在这里插入图片描述"></p> 
<ul><li>v3, Andrew Howard et al., 2019<br> 我们要减少参数数量以及MAdds的推理时间。 MobileNet-v3在速度和准确性方面比v2更好。 例如，与MobileNetV2相比，MobileNetV3-Large在ImageNet分类上的准确度高3.2％，同时将等待时间减少了20％。</li></ul> 
<ol><li> <p>MobileNet-v2 + SE block (如下图), SE学到了各渠道的重要性。</p> </li><li> <p>将自动搜索与新颖的架构相结合，以构建有效的模型。 平台感知的NAS用于逐块搜索，而NetAdapt用于逐层搜索。 在逐层搜索中，请使用较小的扩展大小。</p> </li><li> <p>网络改进，即重新设计计算量大的层。 最后一些层计算量很大。 修改它们以减少等待时间，同时保持准确性。 在下半部分（较深的层）中使用了硬振子激活函数来处理非线性问题，从而提高了准确性。</p> </li></ol> 
<p>Refer to paper <a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Howard_Searching_for_MobileNetV3_ICCV_2019_paper.html" rel="nofollow">Searching for mobilenetv3</a><br> <img src="https://images2.imgbox.com/9f/08/73QtVbfY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/3d/8d/gJEI74b0_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="condenseNet_Huang_Gao_et_al_2018_82"></a>condenseNet, Huang Gao et al., 2018</h4> 
<p>denseNet is good, 但是CNN的冗余很多。 修剪一些多余的分支（无用的特征图）可以达到相似的精度，并且速度更快。</p> 
<ol><li> <p>像ResNeXt，shuffleNet这样的群组转换可减少参数数量。 这里最特别的是在训练阶段的学习组转换（下图b中的1 * 1 L-conv）。 这里的置换就像shuffleNet中的shuffle操作一样，可以保持输入通道的多样性。</p> </li><li> <p>从训练开始起，如下图（b）所示进行权重调整，同时将conv分组在一起。 在确定了阶段2（选择组）之后，它是优化阶段。 在优化阶段，修剪不重要的功能。 第j个通道与第g个组连接，计算它们的平均权重并确定可以保留哪些连接。要衡量第j个channel的输入feature map和卷积核的第g个group之间的重要性，那么就用j和g这个group之间的所有连接（g这个group有多少个卷积核，就有多少个连接）的权重的平均绝对值衡量重要性，本质上就是求权值的L1范数.</p> </li><li> <p>on cifar-10, cifar-100, ImageNet, 与许多CNN架构相比，其性能更好（更快，更准确），例如 shuffleNet-v1, mobileNet, ResNet etc.</p> </li></ol> 
<p>Refer to paper <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Huang_CondenseNet_An_Efficient_CVPR_2018_paper.html" rel="nofollow">Condensenet: An efficient densenet using learned group convolutions</a><br> <img src="https://images2.imgbox.com/54/23/vyq35UNt_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="Xception_Chollet_Francois_2017_95"></a>Xception, Chollet, Francois, 2017</h4> 
<p>基于Inception-v3，由于它使用了深度可分离卷积，因此许多研究人员将其视为轻量级网络。 如果我们不想每次都设计初始架构，只需在一个模块上均匀地使用相同的架构，网络设计就会更容易。 （这个想法在其他网络，如mobileNet中很流行。）</p> 
<ol><li> <p>extreme inception. 从同等的初始结构，现在仅计算部分渠道, (group = xx in pytorch).</p> </li><li> <p>深度可分离卷积（最初来自phd论文：Laurent Sifre，Rigid-Motion Scattering For Image Classification），大大节省了参数。 通过均匀分离特征，下图中的参数可以是m * k + 3 * 3 * k，m是特征，k是核数。<br> 详细信息也可以在查看mobileNet。</p> </li></ol> 
<p>Refer to paper <a href="https://arxiv.org/abs/1610.02357" rel="nofollow">Xception: Deep Learning with Depthwise Separable Convolutions</a><br> <img src="https://images2.imgbox.com/6d/fc/xdByA7LP_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="SqueezeNet_2016_105"></a>SqueezeNet, 2016</h4> 
<ol><li> <p>较小的神经网络具有许多优点：例如，在分布式培训期间，需要较少的跨服务器通信； 需要更少的带宽将新模型从云导出到自动驾驶汽车； 在内存有限的FPGA和其他硬件上进行部署更可行。 SqueezeNet通过减少50倍的参数在ImageNet上达到AlexNet级别的准确性。</p> </li><li> <p>策略：将3 * 3内核替换为1 * 1，减少3 * 3内核的输入通道。 这两种方式都试图减少参数数量。 在网络的后期进行下采样，以便卷积层具有较大的激活图，试图保持了尽可能高的精度。</p> </li><li> <p><em>fire module</em>, 第一层： squeeze, 1 * 1 kernels, 随后是 ReLU；第二层： expansion, 1 * 1 and 3 * 3 kernels together, then ReLU. 在此expansion是一块的，最后拼接</p> </li></ol> 
<p>Refer to paper <a href="https://arxiv.org/abs/1602.07360" rel="nofollow">SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and&lt; 0.5 MB model size</a><br> <img src="https://images2.imgbox.com/d4/3c/rqu9Cn34_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/78c13cd5596cd5b59b9f929f4d5e5450/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;的optional解析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6bb2e5f2e6a635d3924a75071455a6b9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Alexa Prize 2019 冠亚军方案介绍</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>