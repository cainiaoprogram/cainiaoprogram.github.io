<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>为什么 Kafka 这么快？它是如何工作的？ - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="为什么 Kafka 这么快？它是如何工作的？" />
<meta property="og:description" content="随着数据以指数级的速度流入企业，强大且高性能的消息传递系统至关重要。Apache Kafka 因其速度和可扩展性而成为热门选择，但究竟是什么让它如此之快？
在本期中，我们将探讨：
Kafka 的架构及其核心组件，如生产者、代理和消费者
Kafka 如何优化数据存储和复制
这些优化使 Kafka 能够实现令人印象深刻的吞吐量和低延迟
让我们先深入了解一下 Kafka 的核心组件。
Kafka 架构提炼 在将 Kafka 用作 pub-sub 消息中间件的典型场景中，有 3 个重要组件：生产者、代理者和消费者。生产者是消息发送者，消费者是消息接收者。代理通常以集群模式部署，该模式处理传入的消息并将其写入代理分区，从而允许使用者从中读取数据。
请注意，Kafka 被定位为事件流平台，因此在消息队列中经常使用的术语“消息”在 Kafka 中不使用。我们称之为“事件”。
下图汇集了 Kafka 架构和客户端 API 结构的详细视图。我们可以看到，尽管生产者、消费者和代理仍然是架构的关键，但构建高吞吐量、低延迟的 Kafka 需要更多。让我们一一介绍这些组件。
从高层次的角度来看，体系结构中有两层：计算层和存储层。
计算层
计算层或处理层允许各种应用程序通过 API 与 Kafka 代理进行通信。
生产者使用生产者 API。如果数据库等外部系统想要与 Kafka 通信，它还提供 Kafka Connect 作为集成 API。
消费者通过消费者 API 与经纪人交谈。为了将事件路由到其他数据接收器，如搜索引擎或数据库，我们可以使用 Kafka Connect API。此外，使用者可以使用 Kafka Streams API 执行流式处理。如果我们处理无限的记录流，我们可以创建一个 KStream。下面的代码片段为主题“orders”创建一个 KStream，其中 Serdes（序列化程序和反序列化程序）用于键和值。如果我们只需要更新日志中的最新状态，我们可以创建一个 KTable 来维护状态。Kafka Streams 允许我们对事件流执行聚合、过滤、分组和联接。
final KStreamBuilder builder = new KStreamBuilder();final KStream&lt;String, OrderEvent&gt; orderEvents = builder." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7cb10ec80f1aa86726b4d4d423d6a212/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-07T23:31:55+08:00" />
<meta property="article:modified_time" content="2024-01-07T23:31:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">为什么 Kafka 这么快？它是如何工作的？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>随着数据以指数级的速度流入企业，强大且高性能的消息传递系统至关重要。Apache Kafka 因其速度和可扩展性而成为热门选择，但究竟是什么让它如此之快？</p> 
<p>在本期中，我们将探讨：</p> 
<ul><li> <p>Kafka 的架构及其核心组件，如生产者、代理和消费者</p> </li><li> <p>Kafka 如何优化数据存储和复制</p> </li><li> <p>这些优化使 Kafka 能够实现令人印象深刻的吞吐量和低延迟</p> </li></ul> 
<p>让我们先深入了解一下 Kafka 的核心组件。</p> 
<h4><a id="Kafka__14"></a>Kafka 架构提炼</h4> 
<p>在将 Kafka 用作 pub-sub 消息中间件的典型场景中，有 3 个重要组件：生产者、代理者和消费者。生产者是消息发送者，消费者是消息接收者。代理通常以集群模式部署，该模式处理传入的消息并将其写入代理分区，从而允许使用者从中读取数据。</p> 
<p>请注意，Kafka 被定位为事件流平台，因此在消息队列中经常使用的术语“消息”在 Kafka 中不使用。我们称之为“事件”。</p> 
<p>下图汇集了 Kafka 架构和客户端 API 结构的详细视图。我们可以看到，尽管生产者、消费者和代理仍然是架构的关键，但构建高吞吐量、低延迟的 Kafka 需要更多。让我们一一介绍这些组件。</p> 
<p><img src="https://images2.imgbox.com/1f/b8/whFx80To_o.png" alt=""></p> 
<p>从高层次的角度来看，体系结构中有两层：计算层和存储层。</p> 
<p><strong>计算层</strong></p> 
<p>计算层或处理层允许各种应用程序通过 API 与 Kafka 代理进行通信。</p> 
<p>生产者使用生产者 API。如果数据库等外部系统想要与 Kafka 通信，它还提供 Kafka Connect 作为集成 API。</p> 
<p>消费者通过消费者 API 与经纪人交谈。为了将事件路由到其他数据接收器，如搜索引擎或数据库，我们可以使用 Kafka Connect API。此外，使用者可以使用 Kafka Streams API 执行流式处理。如果我们处理无限的记录流，我们可以创建一个 KStream。下面的代码片段为主题“orders”创建一个 KStream，其中 Serdes（序列化程序和反序列化程序）用于键和值。如果我们只需要更新日志中的最新状态，我们可以创建一个 KTable 来维护状态。Kafka Streams 允许我们对事件流执行聚合、过滤、分组和联接。</p> 
<blockquote> 
 <p>final KStreamBuilder builder = new KStreamBuilder();final KStream&lt;String, OrderEvent&gt; orderEvents = builder.stream(Serdes.String(), orderEventSerde, “orders”);</p> 
</blockquote> 
<p>虽然 Kafka Streams API 适用于 Java 应用程序，但有时我们可能希望部署纯流处理作业，而不将其嵌入到应用程序中。然后，我们可以使用 ksqlDB，一个针对流处理优化的数据库集群。它还为我们提供了一个 REST API 来查询结果。</p> 
<p>我们可以看到，通过计算层中的各种 API 支持，可以非常灵活地链接我们想要对事件流执行的操作。例如，我们可以订阅主题“orders”，根据产品聚合订单，并将订单计数发送回主题“ordersByProduct”中的 Kafka，另一个分析应用程序可以订阅并显示该主题。</p> 
<h4><a id="_42"></a>存储层</h4> 
<p>该层由 Kafka 代理组成。Kafka 代理在服务器集群上运行。数据存储在不同主题的分区中。主题就像一个数据库表，一个主题中的分区可以分布在集群节点上。在分区中，事件严格按其偏移量排序。偏移量表示事件在分区中的位置，并单调增加。代理上持久化的事件是不可变的，并且仅追加，甚至删除也被建模为删除事件。因此，生产者只处理顺序写入，而使用者只按顺序读取。</p> 
<p>Kafka 代理的职责包括管理分区、处理读取和写入以及管理分区的复制。它的设计很简单，因此易于扩展。我们将更详细地回顾代理架构。</p> 
<p>由于 Kafka 代理是以集群模式部署的，因此管理节点需要两个组件：控制计划和数据平面。</p> 
<h4><a id="_50"></a>控制平面</h4> 
<p>控制平面管理 Kafka 集群的元数据。过去是 Zookeeper 管理控制器：一个代理被选为控制器。现在，Kafka 使用一个名为 KRaft 的新模块来实现控制平面。选择一些代理作为控制器。</p> 
<p>为什么 Zookeeper 被从集群依赖中剔除？使用 Zookeeper，我们需要维护两种不同类型的系统：一种是 Zookeeper，另一种是 Kafka。使用 KRaft，我们只需要维护一种类型的系统，这使得配置和部署比以前容易得多。此外，KRaft 在将元数据传播到代理方面效率更高。</p> 
<p>我们不会在这里讨论 KRaft 共识的细节。需要记住的一点是，控制器和代理中的元数据缓存是通过 Kafka 中的特殊主题同步的。</p> 
<p>数据平面处理数据复制。下图显示了一个示例。“orders”主题中的分区 0 在 3 个代理上有 3 个副本。Broker 1 上的分区是主分区，其中当前数据偏移量为 4;代理 2 和 3 上的分区是偏移量位于 2 和 3 处的跟随器。</p> 
<p>第 1 步 - 为了赶上领导者，追随者 1 发出偏移量为 2 的 FetchRequest，追随者 2 发出偏移量为 3 的 FetchRequest。</p> 
<p>第 2 步 - 然后，领导者将数据相应地发送给两个追随者。</p> 
<p>第 3 步 - 由于追随者的请求隐式确认了先前获取的记录的接收，因此领导者随后在偏移量 2 之前提交记录。</p> 
<p><img src="https://images2.imgbox.com/83/b7/GT0KV9cB_o.png" alt=""></p> 
<h4><a id="_70"></a>记录</h4> 
<p>Kafka 使用 Record 类作为事件的抽象。无界事件流由许多 Records 组成。</p> 
<p>记录中有 4 个部分：</p> 
<ol><li> <p>Timestamp 时间戳</p> </li><li> <p>Key 键</p> </li><li> <p>Value 价值</p> </li><li> <p>Headers (optional) 标头（可选）</p> </li></ol> 
<p>该密钥用于强制排序、对具有相同密钥的数据进行共置以及数据保留。键和值是字节数组，可以使用序列化程序和解串程序 （serdes） 进行编码和解码。</p> 
<h4><a id="_86"></a>代理</h4> 
<p>我们讨论了代理作为存储层。数据按主题进行组织，并作为分区存储在代理上。现在让我们详细了解经纪人是如何工作的。</p> 
<p>第 1 步：生产者向代理发送请求，该请求首先进入代理的套接字接收缓冲区。</p> 
<p>步骤 2 和 3：其中一个网络线程从套接字接收缓冲区中选取请求，并将其放入共享请求队列中。线程绑定到特定的生产者客户端。</p> 
<p>第 4 步：Kafka 的 I/O 线程池从请求队列中获取请求。</p> 
<p>步骤 5 和 6：I/O 线程验证数据的 CRC 并将其追加到提交日志中。提交日志在磁盘上按段进行组织。每个段中有两个部分：实际数据和索引。</p> 
<p>第 7 步：将生产者请求隐藏在炼狱结构中以进行复制，因此可以释放 I/O 线程来获取下一个请求。</p> 
<p>第 8 步：复制请求后，将其从炼狱中删除。 生成响应并将其放入响应队列中。</p> 
<p>步骤 9 和 10：网络线程从响应队列中获取响应，并将其发送到相应的套接字发送缓冲区。请注意，网络线程绑定到某个客户端。只有在发出请求的响应后，网络线程才会从特定客户端接收另一个请求。</p> 
<p><img src="https://images2.imgbox.com/a0/dc/WiS3sXBC_o.png" alt=""><br> <img src="https://images2.imgbox.com/c9/b3/4LiR5zQ5_o.png" alt=""></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ad33054cd658c7b50d8056308c98f889/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;中的运算符与函数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e06784fdb9341f3946968fc6c55021ee/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">2024 年最适合高级用户的 11 个 Linux 发行版</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>