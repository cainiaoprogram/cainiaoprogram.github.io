<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>随机森林原理和性能分析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="随机森林原理和性能分析" />
<meta property="og:description" content="文章目录 随机森林入门构造随机森林随机森林性能随机森林特点 随机森林入门 决策树入门、sklearn实现、原理解读和算法分析中针对决策树进行了详细的描述，但是其只考虑了一颗决策树的情况。俗话说，三个臭皮匠，顶个诸葛亮。本文将研究如何通过组合多颗决策树的方式，进一步提升模型的效果，即随机森林。
为了理解清楚随机森林算法背后的原理，我们先来看一个非常简单但却很有意思的实例：有3位法官需要判断被告是否有罪，最终的判断结果使用少数服从多数的方式确定。
假设每位法官判断正确的概率均为 p p p，如果只有1位法官，那么该法官判断正确的概率就是 p p p。
当法官数量增加至3位时，最终能够判断正确的情况有两种：一种是3位法官均判断正确，另一种是只有一位法官判断错误，其余两位则判断正确。其总概率为
p 3 &#43; 3 p 2 ( 1 − p ) p^3&#43;3p^2(1-p) p3&#43;3p2(1−p)
只有3位法官判断正确的概率高于1位法官判断正确的概率时，增加法官数量才是有意义的，此时
p 3 &#43; 3 p 2 ( 1 − p ) &gt; p p^3&#43;3p^2(1-p)&gt;p p3&#43;3p2(1−p)&gt;p
化简得到
p ( p − 1 ) ( p − 0.5 ) &lt; 0 p(p-1)(p-0.5)&lt;0 p(p−1)(p−0.5)&lt;0
因为 p p p的基本约束是 0 ≤ p ≤ 1 0≤p≤1 0≤p≤1，结合上式可以将约束条件变为" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e075ffc931aaf645410d11cbdc8fe211/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-04T16:51:58+08:00" />
<meta property="article:modified_time" content="2023-06-04T16:51:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">随机森林原理和性能分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">随机森林入门</a></li><li><a href="#_26" rel="nofollow">构造随机森林</a></li><li><a href="#_44" rel="nofollow">随机森林性能</a></li><li><a href="#_100" rel="nofollow">随机森林特点</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>随机森林入门</h2> 
<p><a href="https://zhuanlan.zhihu.com/p/624138760" rel="nofollow">决策树入门、sklearn实现、原理解读和算法分析</a>中针对决策树进行了详细的描述，但是其只考虑了一颗决策树的情况。俗话说，三个臭皮匠，顶个诸葛亮。本文将研究如何通过组合多颗决策树的方式，进一步提升模型的效果，即随机森林。</p> 
<p>为了理解清楚随机森林算法背后的原理，我们先来看一个非常简单但却很有意思的实例：有3位法官需要判断被告是否有罪，最终的判断结果使用少数服从多数的方式确定。</p> 
<p>假设每位法官判断正确的概率均为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         p 
        
       
      
        p 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span>，如果只有1位法官，那么该法官判断正确的概率就是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         p 
        
       
      
        p 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span>。</p> 
<p>当法官数量增加至3位时，最终能够判断正确的情况有两种：一种是3位法官均判断正确，另一种是只有一位法官判断错误，其余两位则判断正确。其总概率为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           p 
          
         
           3 
          
         
        
          + 
         
        
          3 
         
         
         
           p 
          
         
           2 
          
         
        
          ( 
         
        
          1 
         
        
          − 
         
        
          p 
         
        
          ) 
         
        
       
         p^3+3p^2(1-p) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0585em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord">3</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span></span></span></p> 
<p>只有3位法官判断正确的概率高于1位法官判断正确的概率时，增加法官数量才是有意义的，此时<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           p 
          
         
           3 
          
         
        
          + 
         
        
          3 
         
         
         
           p 
          
         
           2 
          
         
        
          ( 
         
        
          1 
         
        
          − 
         
        
          p 
         
        
          ) 
         
        
          &gt; 
         
        
          p 
         
        
       
         p^3+3p^2(1-p)&gt;p 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0585em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1141em; vertical-align: -0.25em;"></span><span class="mord">3</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8641em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span></span><br> 化简得到<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          p 
         
        
          ( 
         
        
          p 
         
        
          − 
         
        
          1 
         
        
          ) 
         
        
          ( 
         
        
          p 
         
        
          − 
         
        
          0.5 
         
        
          ) 
         
        
          &lt; 
         
        
          0 
         
        
       
         p(p-1)(p-0.5)&lt;0 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0.5</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span></span><br> 因为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         p 
        
       
      
        p 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span></span></span></span></span>的基本约束是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         0 
        
       
         ≤ 
        
       
         p 
        
       
         ≤ 
        
       
         1 
        
       
      
        0≤p≤1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7804em; vertical-align: -0.136em;"></span><span class="mord">0</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8304em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">≤</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>，结合上式可以将约束条件变为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          0.5 
         
        
          &lt; 
         
        
          p 
         
        
          &lt; 
         
        
          1 
         
        
       
         0.5 &lt; p &lt; 1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6835em; vertical-align: -0.0391em;"></span><span class="mord">0.5</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7335em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span></span></p> 
<p>也就是说，只要单位法官判断正确的概率超过0.5，那么增加法官数量后，就可以进一步提升判断正确的概率。</p> 
<p>除了概率约束，上述推导过程中还隐含了另外两个约束：（1）法官们各自做独立判断，互不影响，这是计算3位法官判断正确的概率的基本前提；（2）法官对表决对象拥有共同目标，因为如果有法官有意包庇罪犯，可能会故意给出错误判断。</p> 
<p>事实上，已经有一个定理针对该情况进行了描述，即孔多塞陪审团定理：总数为奇数的一组人（模型）将未知的世界状态分为真或假。每个人（模型）正确分类的概率为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         p 
        
       
         &gt; 
        
       
         0.5 
        
       
      
        p&gt;0.5 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7335em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.5</span></span></span></span></span>，并且任何一个人（模型）分类正确的概率在统计上独立于其他人（模型）分类的正确性。定理便可以描述为：多数投票正确的概率比任何人（模型）都更高；当人数（模型数）变得足够大时，多数投票的准确率将接近100%。</p> 
<h2><a id="_26"></a>构造随机森林</h2> 
<p>将孔多塞陪审团定理应用到随机森林算法中：只要多颗树是相互独立的，并且每棵树预测正确的概率超过0.5，那么随机森林算法的效果就能优于单颗决策树。</p> 
<p>单颗决策树预测正确的概率超过0.5大概率是正确的，因为随机猜测的正确概率已经是0.5，有了训练集的学习后，可以预期其判断正确的概率超过0.5。</p> 
<p>实现多棵树为互相独立的方式是:<br> (1) 通过自助采样(bootstrap sample)策略生成不同且相互独立的数据集。其具体流程如下:从原数据集中有放回地（即同一样本可以被多次抽取）重复随机抽取一个样本，抽取次数与原数据集数量相同，这样会创建一个与原数据集大小相同的数据集，但有些数据点会缺失（缺失量大约37%），有些会重复。<br> (2) 基于新创建的数据集来构造决策树，但是要对我们在介绍<a href="https://zhuanlan.zhihu.com/p/624138760" rel="nofollow">决策树</a>时所描述的算法稍作修改。在每个结点处，算法随机选择特征的一个子集，并对其中一个特征寻找最佳测试，而不是对每个结点都寻找最佳测试。选择的特征个数由max_features参数来控制。每个结点中特征子集的选择是相互独立的，这样树的每个结点可以使用特征的不同子集来做出决策。</p> 
<p>由于使用了自助采样，随机森林中构造每棵决策树的数据集都是略有不同的。由于每个结点的特征选择，每棵树中的每次划分都是基于特征的不同子集。这两个步骤共同保证了随机森林中的所有树都不相同并且互相独立。</p> 
<p>想要利用随机森林进行预测，首先需要对森林中的每棵树进行预测。此后，对于回归问题，我们对这些结果取平均值作为最终预测。对于分类问题，则采用“软投票”(soft voting)策略。也就是说，每个算法做出“软”预测，给出每个可能的输出标签的概率，对所有树的预测概率取平均值，然后将概率最大的类别作为预测结果。</p> 
<p>以下为使用随机森林求解预测问题时的流程图。<br> <img src="https://images2.imgbox.com/90/fd/LJrvDGVF_o.png" alt=""></p> 
<h2><a id="_44"></a>随机森林性能</h2> 
<p>我们先通过可视化看一下随机森林和每一颗决策树的结果。以下为使用sklearn包的实现代码。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> mglearn<span class="token punctuation">.</span>plots
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">from</span> data <span class="token keyword">import</span> two_moons


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    X<span class="token punctuation">,</span> y <span class="token operator">=</span> two_moons<span class="token punctuation">.</span>two_moons<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 数据集拆分</span>
    X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token comment"># 创建一个随机森林分类器，包含 5 棵树，随机种子为 2</span>
    forest <span class="token operator">=</span> RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token comment"># 使用训练数据拟合模型</span>
    forest<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

    <span class="token comment"># 创建一个 2x3 的图像，用于显示每棵树的分割情况</span>
    fig<span class="token punctuation">,</span> axes <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 遍历每棵树，显示其分割情况</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>ax<span class="token punctuation">,</span> tree<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>axes<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> forest<span class="token punctuation">.</span>estimators_<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Tree {}, score {:.2f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span> forest<span class="token punctuation">.</span>estimators_<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># 绘制决策树</span>
        mglearn<span class="token punctuation">.</span>plots<span class="token punctuation">.</span>plot_tree_partition<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> tree<span class="token punctuation">,</span> ax<span class="token operator">=</span>ax<span class="token punctuation">)</span>

    <span class="token comment"># 在最后一个子图中显示整个随机森林的决策边界</span>
    mglearn<span class="token punctuation">.</span>plots<span class="token punctuation">.</span>plot_2d_separator<span class="token punctuation">(</span>forest<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> fill<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> ax<span class="token operator">=</span>axes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.4</span><span class="token punctuation">)</span>
    axes<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Random Forest, , score {:.2f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>forest<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment"># 在前两个子图中显示训练数据的散点图</span>
    mglearn<span class="token punctuation">.</span>discrete_scatter<span class="token punctuation">(</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

</code></pre> 
<p>运行代码后，可以得到下图。随机森林模型的结果，肉眼可见地优于一颗颗独立的决策树。从得分上来看，5颗决策树的值分别为0.88、0.93、0.93、0.95和0.84，而随机森林却将得分进一步提升到了0.96。<br> <img src="https://images2.imgbox.com/3d/14/4vYt65p5_o.png" alt=""></p> 
<p>计算特征重要性就简单多了，一行代码就行：</p> 
<pre><code class="prism language-python">forest<span class="token punctuation">.</span>feature_importances_
</code></pre> 
<p>以下为输出结果</p> 
<pre><code>array([0.38822127, 0.61177873])
</code></pre> 
<p>在使用<a href="https://zhuanlan.zhihu.com/p/624138760" rel="nofollow">单决策树</a>求解时，我们当时提到，重要性值分别为0.1478和0.2138。</p> 
<p>看起来差异好像挺大，但其实是因为当时没有对重要性值做归一化处理。归一化后，第一个特征的重要性值为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          0.1478 
         
        
          / 
         
        
          ( 
         
        
          0.1478 
         
        
          + 
         
        
          0.2138 
         
        
          ) 
         
        
          = 
         
        
          0.4087 
         
        
       
         0.1478 / (0.1478 + 0.2138)=0.4087 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0.1478/</span><span class="mopen">(</span><span class="mord">0.1478</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0.2138</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.4087</span></span></span></span></span></span><br> 第二个特征的重要性值为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          0.2138 
         
        
          / 
         
        
          ( 
         
        
          0.1478 
         
        
          + 
         
        
          0.2138 
         
        
          ) 
         
        
          = 
         
        
          0.5913 
         
        
       
         0.2138 / (0.1478 + 0.2138) = 0.5913 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0.2138/</span><span class="mopen">(</span><span class="mord">0.1478</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0.2138</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0.5913</span></span></span></span></span></span><br> 现在看起来，两种方法下的差异就没那么大了。</p> 
<h2><a id="_100"></a>随机森林特点</h2> 
<p>从本质上看，随机森林拥有决策树的所有优点。此外，在模型训练过程中，每一颗决策树的训练都可以并行执行，从而提升训练效率。</p> 
<p>需要调节的重要参数有n_estimators和max_features。n_estimators指的是决策树数量，其总是越大越好。对更多的树取平均可以降低过拟合，从而得到鲁棒性更好的预测模型。不过收益是递减的，而且树越多需要的内存也越多，训练时间也越长。常用的经验法则就是“在你的时间/内存允许的情况下尽量多”。</p> 
<p>max_features指的是每颗决策树所使用的特征数量。较小的max_features可以降低过拟合。一般来说，好的经验就是使用默认值：对于分类，默认值是max_features=sqrt(n_features)；对于回归，默认值是max_features=n_features。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/69159e479644e9be179d607c880e7094/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【SpringBoot无需重启修改代码页面生效】SpringBoot热部署</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5873d6ae79fbad3dc3beb489c9a35d04/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">单张图片一键换脸（github爆火工程——roop）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>