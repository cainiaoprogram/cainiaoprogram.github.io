<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop3.3.1完全分布式部署 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop3.3.1完全分布式部署" />
<meta property="og:description" content="Hadoop目录 Hadoop3.3.1完全分布式部署(一)1、HDFS 一、安装1、基础安装1.1、配置JDK-181.2、下载并解压hadoop安装包本地运行模式测试 eg: 2、完全分布式运行模式1、概要：2、编写集群分发脚本，把1~4步安装的同步到其他服务器：2.1、创建脚本`vim /var/opt/hadoopSoftware/hadoopScript/bin/xsync`，添加执行权限2.2、开始同步JDK、Hdoop、环境变量 3、配置ssh免密4、配置xml4.1、集群部署规划如下：4.2、所需配置文件4.3、配置集群1）核心配置文件2）HDFS配置文件3）YARN配置文件4）MapReduce配置文件 5、启动整个集群5.1、配置workers5.2、启动集群5.3、页面地址： 6、集群测试6.1、上传文件到集群测试6.2、上传大文件测试6.3、hadoop集群测试 7、集群崩溃处理1）先停止集群2）删除每个集群上的3）格式化集群4）启动集群 8、配置历史服务器8.1、配置mapred-site.xml8.2、同步配置8.3、在hadoop1上启动历史服务器8.4、查看历史服务器是否启动8.5、查看JobHistory 9、配置日志聚合功能1）配置yarn-site.xml2）同步配置3）关闭重启NodeManager、ResourceManager、HistoryServer 10、集群启停总结：1、整体启动停止(推荐)1）整体启动、停止HDFS2）整体启动体制YARN3）启停historyserver 2、各个服务组件分别启/停1）启/停HDFS组件2）启/停YARN组件3）启停historyserver 11、编写Hadoop集群常用脚本1）批量启停`hadoop`服务2）查看所有服务器Java进程脚本：jpsall 12、常用端口号 注：长时间无法关闭集群实践参考网站 Hadoop3.3.1完全分布式部署(一) Hadoop 是一种分析和处理大数据的软件平台，是一个用 Java 语言实现的 Apache 的开源软件框架，在大量计算机组成的集群中实现了对海量数据的分布式计算。
结构框架
推荐架构
1、HDFS 一个提供高可用的获取应用数据的分布式文件系统。
从字面上来看，SecondaryNameNode 很容易被当作是 NameNode 的备份节点，其实不然。可以通过下图看 HDFS 中 SecondaryNameNode 的作用。
NameNode主要是用来保存HDFS的元数据信息，比如命名空间信息，块信息等。当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。
fsimage - 它是在NameNode启动时对整个文件系统的快照
edit logs - 它是在NameNode启动后，对文件系统的改动序列
Secondary NameNode就是来帮助解决上述问题的，它的职责是合并NameNode的edit logs到fsimage文件中。
它定时到NameNode去获取edit logs，并更新到自己的fsimage上。一旦它有了新的fsimage文件，它将其拷贝回NameNode中。NameNode在下次重启时会使用这个新的fsimage文件，从而减少重启的时间。 一、安装 1、基础安装 $ yum install -y gcc vim wget $ sudo yum install ssh $ sudo yum install pdsh -y 1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0b1420157e515c5a6c960e0df66b9b5f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-27T10:54:49+08:00" />
<meta property="article:modified_time" content="2023-06-27T10:54:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop3.3.1完全分布式部署</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Hadoop目录</h4> 
 <ul><li><ul><li><a href="#Hadoop331_2" rel="nofollow">Hadoop3.3.1完全分布式部署(一)</a></li><li><ul><li><a href="#1HDFS_17" rel="nofollow">1、HDFS</a></li></ul> 
   </li><li><a href="#_39" rel="nofollow">一、安装</a></li><li><ul><li><a href="#1_41" rel="nofollow">1、基础安装</a></li><li><ul><li><a href="#11JDK18_49" rel="nofollow">1.1、配置JDK-18</a></li><li><a href="#12hadoop_86" rel="nofollow">1.2、下载并解压hadoop安装包</a></li><li><a href="#_eg_132" rel="nofollow">本地运行模式测试 eg:</a></li></ul> 
    </li><li><a href="#2_157" rel="nofollow">2、完全分布式运行模式</a></li><li><ul><li><a href="#1_159" rel="nofollow">1、概要：</a></li><li><a href="#214_174" rel="nofollow">2、编写集群分发脚本，把1~4步安装的同步到其他服务器：</a></li><li><ul><li><a href="#21vim_varopthadoopSoftwarehadoopScriptbinxsync_191" rel="nofollow">2.1、创建脚本`vim /var/opt/hadoopSoftware/hadoopScript/bin/xsync`，添加执行权限</a></li><li><a href="#22JDKHdoop_229" rel="nofollow">2.2、开始同步JDK、Hdoop、环境变量</a></li></ul> 
     </li><li><a href="#3ssh_262" rel="nofollow">3、配置ssh免密</a></li><li><a href="#4xml_270" rel="nofollow">4、配置xml</a></li><li><ul><li><a href="#41_274" rel="nofollow">4.1、集群部署规划如下：</a></li><li><a href="#42_283" rel="nofollow">4.2、所需配置文件</a></li><li><a href="#43_303" rel="nofollow">4.3、配置集群</a></li><li><ul><li><a href="#1_305" rel="nofollow">1）核心配置文件</a></li><li><a href="#2HDFS_337" rel="nofollow">2）HDFS配置文件</a></li><li><a href="#3YARN_380" rel="nofollow">3）YARN配置文件</a></li><li><a href="#4MapReduce_413" rel="nofollow">4）MapReduce配置文件</a></li></ul> 
     </li></ul> 
     </li><li><a href="#5_441" rel="nofollow">5、启动整个集群</a></li><li><ul><li><a href="#51workers_443" rel="nofollow">5.1、配置workers</a></li><li><a href="#52_459" rel="nofollow">5.2、启动集群</a></li><li><a href="#53_495" rel="nofollow">5.3、页面地址：</a></li></ul> 
     </li><li><a href="#6_507" rel="nofollow">6、集群测试</a></li><li><ul><li><a href="#61_509" rel="nofollow">6.1、上传文件到集群测试</a></li><li><a href="#62_522" rel="nofollow">6.2、上传大文件测试</a></li><li><a href="#63hadoop_544" rel="nofollow">6.3、hadoop集群测试</a></li></ul> 
     </li><li><a href="#7_555" rel="nofollow">7、集群崩溃处理</a></li><li><ul><li><a href="#1_557" rel="nofollow">1）先停止集群</a></li><li><a href="#2_564" rel="nofollow">2）删除每个集群上的</a></li><li><a href="#3_570" rel="nofollow">3）格式化集群</a></li><li><a href="#4_576" rel="nofollow">4）启动集群</a></li></ul> 
     </li><li><a href="#8_585" rel="nofollow">8、配置历史服务器</a></li><li><ul><li><a href="#81mapredsitexml_587" rel="nofollow">8.1、配置mapred-site.xml</a></li><li><a href="#82_611" rel="nofollow">8.2、同步配置</a></li><li><a href="#83hadoop1_617" rel="nofollow">8.3、在hadoop1上启动历史服务器</a></li><li><a href="#84_632" rel="nofollow">8.4、查看历史服务器是否启动</a></li><li><a href="#85JobHistory_638" rel="nofollow">8.5、查看JobHistory</a></li></ul> 
     </li><li><a href="#9_652" rel="nofollow">9、配置日志聚合功能</a></li><li><ul><li><a href="#1yarnsitexml_661" rel="nofollow">1）配置yarn-site.xml</a></li><li><a href="#2_689" rel="nofollow">2）同步配置</a></li><li><a href="#3NodeManagerResourceManagerHistoryServer_695" rel="nofollow">3）关闭重启NodeManager、ResourceManager、HistoryServer</a></li></ul> 
     </li><li><a href="#10_713" rel="nofollow">10、集群启停总结：</a></li><li><ul><li><a href="#1_715" rel="nofollow">1、整体启动停止(推荐)</a></li><li><ul><li><a href="#1HDFS_717" rel="nofollow">1）整体启动、停止HDFS</a></li><li><a href="#2YARN_725" rel="nofollow">2）整体启动体制YARN</a></li><li><a href="#3historyserver_733" rel="nofollow">3）启停historyserver</a></li></ul> 
      </li><li><a href="#2_741" rel="nofollow">2、各个服务组件分别启/停</a></li><li><ul><li><a href="#1HDFS_743" rel="nofollow">1）启/停HDFS组件</a></li><li><a href="#2YARN_753" rel="nofollow">2）启/停YARN组件</a></li><li><a href="#3historyserver_763" rel="nofollow">3）启停historyserver</a></li></ul> 
     </li></ul> 
     </li><li><a href="#11Hadoop_773" rel="nofollow">11、编写Hadoop集群常用脚本</a></li><li><ul><li><a href="#1hadoop_775" rel="nofollow">1）批量启停`hadoop`服务</a></li><li><a href="#2Javajpsall_834" rel="nofollow">2）查看所有服务器Java进程脚本：jpsall</a></li></ul> 
     </li><li><a href="#12_874" rel="nofollow">12、常用端口号</a></li></ul> 
   </li></ul> 
   </li><li><a href="#_883" rel="nofollow">注：长时间无法关闭集群</a></li><li><a href="#_901" rel="nofollow">实践</a></li><li><a href="#_915" rel="nofollow">参考网站</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="Hadoop331_2"></a>Hadoop3.3.1完全分布式部署(一)</h3> 
<p>Hadoop 是一种分析和处理大数据的软件平台，是一个用 Java 语言实现的 Apache 的开源软件框架，在大量计算机组成的集群中实现了对海量数据的分布式计算。<br> <img src="https://images2.imgbox.com/b9/da/9sitPzbc_o.png" alt="在这里插入图片描述"></p> 
<p>结构框架<br> <img src="https://images2.imgbox.com/83/c7/TRqix5S3_o.png" alt="在这里插入图片描述"></p> 
<p>推荐架构<br> <img src="https://images2.imgbox.com/23/05/pJpgaTPR_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="1HDFS_17"></a>1、HDFS</h4> 
<p>一个提供高可用的获取应用数据的分布式文件系统。</p> 
<p>从字面上来看，SecondaryNameNode 很容易被当作是 NameNode 的备份节点，其实不然。可以通过下图看 HDFS 中 SecondaryNameNode 的作用。</p> 
<p><img src="https://images2.imgbox.com/12/97/OxAffhzW_o.png" alt="在这里插入图片描述"></p> 
<p>NameNode主要是用来保存HDFS的元数据信息，比如命名空间信息，块信息等。当它运行的时候，这些信息是存在内存中的。但是这些信息也可以持久化到磁盘上。</p> 
<blockquote> 
 <p>fsimage - 它是在NameNode启动时对整个文件系统的快照<br> edit logs - 它是在NameNode启动后，对文件系统的改动序列</p> 
</blockquote> 
<p>Secondary NameNode就是来帮助解决上述问题的，它的职责是合并NameNode的edit logs到fsimage文件中。</p> 
<blockquote> 
 <ul><li>它定时到NameNode去获取edit logs，并更新到自己的fsimage上。</li><li>一旦它有了新的fsimage文件，它将其拷贝回NameNode中。</li><li>NameNode在下次重启时会使用这个新的fsimage文件，从而减少重启的时间。</li></ul> 
</blockquote> 
<h3><a id="_39"></a>一、安装</h3> 
<h4><a id="1_41"></a>1、基础安装</h4> 
<pre><code class="prism language-ruby">$ yum install <span class="token operator">-</span>y gcc vim wget
$ sudo yum install ssh
$ sudo yum install pdsh <span class="token operator">-</span>y
</code></pre> 
<h5><a id="11JDK18_49"></a>1.1、配置JDK-18</h5> 
<p><a href="https://www.oracle.com/java/technologies/downloads/#java17" rel="nofollow">JDK地址</a></p> 
<p><a href="https://docs.oracle.com/en/java/javase/19/install/installation-jdk-linux-platforms.html#GUID-4907E1A6-7B4B-4E98-9DA5-BF2A4D01AA57" rel="nofollow">安装参考</a></p> 
<pre><code class="prism language-ruby"><span class="token comment"># JDK17</span>
<span class="token comment">#wget https://download.oracle.com/java/17/archive/jdk-17_linux-x64_bin.tar.gz -P /var/opt/hadoopSoftware</span>
<span class="token comment"># JDK19</span>
<span class="token comment">#wget https://download.oracle.com/java/19/latest/jdk-19_linux-x64_bin.tar.gz -P /var/opt/hadoopSoftware</span>

<span class="token comment"># JDK18(本文所选，但是需要ORACLE账号才可以下载)</span>
tar <span class="token operator">-</span>zxvf <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>jdk<span class="token operator">-</span><span class="token number">8</span>u361<span class="token operator">-</span>linux<span class="token operator">-</span>x64<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz <span class="token operator">-</span><span class="token constant">C</span> <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware
</code></pre> 
<p><img src="https://images2.imgbox.com/a4/28/fnYJr8C5_o.png" alt="在这里插入图片描述"></p> 
<p>配置环境变量，在<code>profile.d</code>下创建<code>hadoop</code>所需的环境变量</p> 
<pre><code class="prism language-shell"><span class="token function">cat</span> <span class="token operator">&gt;&gt;</span> /etc/profile.d/my_env.sh <span class="token operator">&lt;&lt;</span><span class="token string">Leo
# JAVA_HOME
export JAVA_HOME=/var/opt/software/jdk1.8.0_361
export PATH=\<span class="token environment constant">$PATH</span>:\<span class="token variable">$JAVA_HOME</span>/bin
Leo</span>
</code></pre> 
<p>使配置生效</p> 
<pre><code class="prism language-ruby">source <span class="token operator">/</span>etc<span class="token operator">/</span>profile
</code></pre> 
<h5><a id="12hadoop_86"></a>1.2、下载并解压hadoop安装包</h5> 
<pre><code class="prism language-ruby">wget https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>dlcdn<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>org<span class="token operator">/</span>hadoop<span class="token operator">/</span>common<span class="token operator">/</span>hadoop<span class="token operator">-</span><span class="token number">3.3</span><span class="token number">.1</span><span class="token operator">/</span>hadoop<span class="token operator">-</span><span class="token number">3.3</span><span class="token number">.1</span><span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz <span class="token operator">-</span><span class="token constant">P</span> <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware
tar <span class="token operator">-</span>zvxf <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoop<span class="token operator">-</span><span class="token number">3.3</span><span class="token number">.1</span><span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz <span class="token operator">-</span><span class="token constant">C</span> <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware
</code></pre> 
<p>配置环境变量</p> 
<pre><code class="prism language-shell"><span class="token function">cat</span> <span class="token operator">&gt;&gt;</span> /etc/profile.d/my_env.sh <span class="token operator">&lt;&lt;</span><span class="token string">Leo
# HADOOP_HOME
export HADOOP_HOME=/var/opt/hadoopSoftware/hadoop-3.3.1
export PATH=\<span class="token environment constant">$PATH</span>:\<span class="token variable">$HADOOP_HOME</span>/bin
export PATH=\<span class="token environment constant">$PATH</span>:\<span class="token variable">$HADOOP_HOME</span>/sbin
# Hadoop run need add
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root
Leo</span>
</code></pre> 
<p>生效</p> 
<pre><code class="prism language-ruby">source <span class="token operator">/</span>etc<span class="token operator">/</span>profile
</code></pre> 
<ul><li>查看配置的全局环境变量 <code>echo $PATH</code></li></ul> 
<p>hadoop目录介绍</p> 
<pre><code>bin：和hdfs yarn mapred
sbin：启动停止相关的命令
share：一些参考
</code></pre> 
<p>(<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Execution" rel="nofollow">Hadoop参考</a>)<br> <a href="http://hadoop.apache.org/" rel="nofollow">官网</a></p> 
<p><img src="https://images2.imgbox.com/d8/33/48BvmEUi_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_eg_132"></a>本地运行模式测试 eg:</h5> 
<pre><code class="prism language-shell"><span class="token function">mkdir</span> -p /var/opt/hadoopSoftware/hadoop-3.3.1/tinput
<span class="token function">cat</span> <span class="token operator">&gt;&gt;</span> /var/opt/hadoopSoftware/hadoop-3.3.1/tinput/word.txt <span class="token operator">&lt;&lt;</span><span class="token string">Leo
aa
bb
cc
cc
Leo</span>
</code></pre> 
<p>测试计算每个单词出现的次数（输入路径：tinput/ 输出路径：./timport）</p> 
<pre><code class="prism language-ruby">hadoop jar share<span class="token operator">/</span>hadoop<span class="token operator">/</span>mapreduce<span class="token regex-literal"><span class="token regex">/hadoop-mapreduce-examples-3.3.1.jar wordcount tinput/</span></span> <span class="token punctuation">.</span><span class="token operator">/</span>toutput

toutput<span class="token punctuation">]</span><span class="token comment"># cat part-r-00000</span>
aa      <span class="token number">1</span>
bb      <span class="token number">1</span>
cc      <span class="token number">2</span>
</code></pre> 
<h4><a id="2_157"></a>2、完全分布式运行模式</h4> 
<h5><a id="1_159"></a>1、概要：</h5> 
<blockquote> 
 <p>前提：<br> 1、准备三台server（关闭防火墙、静态ip、主机名）<br> 2、安装JDK<br> 3、安装Hadoop<br> 4、配置环境变量<br> 所需其他配置：<br> 5、配置集群<br> 6、单点启动<br> 7、配置ssh<br> 8、测试集群</p> 
</blockquote> 
<h5><a id="214_174"></a>2、编写集群分发脚本，把1~4步安装的同步到其他服务器：</h5> 
<pre><code class="prism language-ruby">mkdir <span class="token operator">-</span>p <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoopScript<span class="token operator">/</span>bin
mkdir <span class="token operator">-</span>p <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoopScript<span class="token operator">/</span>config
</code></pre> 
<p>创建需要同步的服务器地址</p> 
<pre><code class="prism language-ruby">cat <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoopScript<span class="token operator">/</span>config<span class="token operator">/</span>hadoop_hosts
hadoop2
hadoop3
</code></pre> 
<h6><a id="21vim_varopthadoopSoftwarehadoopScriptbinxsync_191"></a>2.1、创建脚本<code>vim /var/opt/hadoopSoftware/hadoopScript/bin/xsync</code>，添加执行权限</h6> 
<pre><code class="prism language-ruby"><span class="token comment">#!/bin/bash</span>

<span class="token comment"># 判断参数个数</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> $<span class="token comment"># -lt 1 ]</span>
<span class="token keyword">then</span>
    echo Not Enough Argument<span class="token operator">!</span>
    exit<span class="token punctuation">;</span>
fi

<span class="token comment"># 遍历所有的服务器</span>
<span class="token comment">#for host in hadoop1 hadoop2 hadoop3</span>
<span class="token keyword">for</span> host <span class="token keyword">in</span> <span class="token command-literal"><span class="token command string">`cat /var/opt/hadoopSoftware/hadoopScript/config/hadoop_hosts`</span></span>
<span class="token keyword">do</span>
    echo <span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">==</span><span class="token variable">$host</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">===</span><span class="token operator">==</span>
    <span class="token comment"># 遍历所有目录</span>
    <span class="token keyword">for</span> file <span class="token keyword">in</span> $@
    <span class="token keyword">do</span>
        <span class="token comment"># 判断文件是否存在</span>
        <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token operator">-</span>e <span class="token variable">$file</span> <span class="token punctuation">]</span>
            <span class="token keyword">then</span>
                <span class="token comment"># 获取父目录名，例如有软连接他会cd到真正的数据目录</span>
                pdir<span class="token operator">=</span>$<span class="token punctuation">(</span>cd <span class="token operator">-</span><span class="token constant">P</span> $<span class="token punctuation">(</span>dirname <span class="token variable">$file</span><span class="token punctuation">)</span><span class="token punctuation">;</span> pwd<span class="token punctuation">)</span>
                <span class="token comment"># 获取当前文件名称</span>
                fname<span class="token operator">=</span>$<span class="token punctuation">(</span>basename <span class="token variable">$file</span><span class="token punctuation">)</span>
                ssh <span class="token variable">$host</span> <span class="token string-literal"><span class="token string">"mkdir -p $pdir"</span></span>
                rsync <span class="token operator">-</span>av <span class="token variable">$pdir</span><span class="token operator">/</span><span class="token variable">$fname</span> <span class="token variable">$host</span><span class="token symbol">:$p</span>dir
            <span class="token keyword">else</span>
                echo <span class="token variable">$file</span> dose <span class="token keyword">not</span> exists<span class="token operator">!</span>
        fi
    done
done
</code></pre> 
<p>目前<code>xsync</code>只能同步当前目录下的文件，用法<code>xsync bin/</code>，如果同步根目录需要写xsync脚本的绝对路径<code>/var/opt/hadoopSoftware/hadoopScript/bin/xsync</code></p> 
<h6><a id="22JDKHdoop_229"></a>2.2、开始同步JDK、Hdoop、环境变量</h6> 
<p>2.2.1、开始同步(选用)：</p> 
<pre><code class="prism language-ruby"><span class="token comment"># 全局调用使用绝对路径</span>
sudo <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoopScript<span class="token operator">/</span>bin<span class="token operator">/</span>xsync <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware
sudo <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoopScript<span class="token operator">/</span>bin<span class="token operator">/</span>xsync <span class="token operator">/</span>etc<span class="token operator">/</span>profile<span class="token punctuation">.</span>d<span class="token operator">/</span>my_env<span class="token punctuation">.</span>sh 
</code></pre> 
<ul><li>注：每台服务器都需要重新刷新环境变量<code>source /etc/profile</code>(根据自身需求，后期可以使用ansible-playbook)</li></ul> 
<p>2.2.2、配置环境变量同步(<strong>本文选用如下方法</strong>)：</p> 
<blockquote> 
 <p>或：如果想要应用这个脚本到全局可以进行如下环境变量设置（根据自身情况进行设置，仅参考）：</p> 
</blockquote> 
<pre><code class="prism language-shell"><span class="token function">cat</span> <span class="token operator">&gt;&gt;</span> /etc/profile.d/my_env.sh <span class="token operator">&lt;&lt;</span><span class="token string">Leo
# hadoopScript_home
export HSCRIPT_HOME=/var/opt/hadoopSoftware/hadoopScript
export PATH=<span class="token environment constant">$PATH</span>:<span class="token variable">$HSCRIPT_HOME</span>/bin
Leo</span>
</code></pre> 
<p>同步开始：</p> 
<pre><code class="prism language-ruby">xsync <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware
xsync <span class="token operator">/</span>etc<span class="token operator">/</span>profile<span class="token punctuation">.</span>d<span class="token operator">/</span>my_env<span class="token punctuation">.</span>sh
</code></pre> 
<h5><a id="3ssh_262"></a>3、配置ssh免密</h5> 
<p><a href="https://blog.csdn.net/jiangbenchu/article/details/90714585">参考配置</a></p> 
<p>配置hadoop1和hadoop2免密登录hadoop[1,2,3]</p> 
<h5><a id="4xml_270"></a>4、配置xml</h5> 
<p>官网参考：[<a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html" rel="nofollow">Apache Hadoop 3.3.4 – Hadoop Cluster Setup</a>]</p> 
<h6><a id="41_274"></a>4.1、集群部署规划如下：</h6> 
<table><thead><tr><th></th><th>hadoop1</th><th>hadoop2</th><th>hadoop3</th></tr></thead><tbody><tr><td>HDFS</td><td><strong>NameNode</strong><br>DataNode</td><td>DataNode</td><td><strong>SecondaryNameNode</strong><br>DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td><strong>NodeManager</strong><br>ResourceManager</td><td>NodeManager</td></tr></tbody></table> 
<p>注：NameNode、 NodeManager、 SecondaryNameNode最好放在不同的服务器上。</p> 
<h6><a id="42_283"></a>4.2、所需配置文件</h6> 
<p>1）默认配置文件：</p> 
<table><thead><tr><th>默认文件名</th><th>文件存放路径（cd $HADOOP_HOME）</th></tr></thead><tbody><tr><td>core-default.xml</td><td>$HADOOP_HOME/share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml</td></tr><tr><td>hdfs-default.xml</td><td>$HADOOP_HOME/share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</td></tr><tr><td>yarn-default.xml</td><td>$HADOOP_HOME/share/doc/hadoop/hadoop-yarn/hadoop-yarn-common/yarn-default.xml</td></tr><tr><td>mapred-default.xml</td><td>$HADOOP_HOME/share/doc/hadoop/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml</td></tr></tbody></table> 
<p>2）自定义配置文件：</p> 
<p>文件位置<code>$HADOOP_HOME/etc/hadoop</code></p> 
<ul><li>core-site.xml</li><li>hdfs-site.xml</li><li>yarn-site.xml</li><li>mapred-site.xml</li></ul> 
<h6><a id="43_303"></a>4.3、配置集群</h6> 
<h6><a id="1_305"></a>1）核心配置文件</h6> 
<pre><code class="prism language-ruby">cat <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>core<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 指定NameNode地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://hadoop1:8020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 指定hadoop数据存储目录 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/var/opt/hadoopSoftware/hadoop-3.3.1/data<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 配置hadoop网页登录使用的静态用户为leojiang --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.http.staticuser.user<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>root<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
<h6><a id="2HDFS_337"></a>2）HDFS配置文件</h6> 
<pre><code class="prism language-ruby">cat <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>hdfs<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>
<span class="token comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- nn web 端访问地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop1:9870<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 2nn web 端访问地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- datanode 地址 可以不配 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.datanode.http.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>0.0.0.0:9864<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>
            The datanode http server address and port.
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 如果为true(默认值)，则namenode要求连接datanode的地址必须解析为主机名。如有必要，将执行反向DNS查找。所有从不可解析地址注册datanode的尝试都将被拒绝。建议保留该设置，以防止在DNS中断期间意外注册由excluded文件中hostname列出的datanode。只有在没有基础设施支持反向DNS查找的环境中，才将此设置为false。--&gt;</span>
    <span class="token comment">&lt;!--
    &lt;property&gt;
      &lt;name&gt;dfs.namenode.datanode.registration.ip-hostname-check&lt;/name&gt;
      &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
    --&gt;</span>
    
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<h6><a id="3YARN_380"></a>3）YARN配置文件</h6> 
<pre><code class="prism language-ruby">cat <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>yarn<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 指定MR走shutffle --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 指定ResourceManager的地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 环境变量的继承 3.1.3需要配置HADOOP_MAPRED_HOME。3.2以上修复了就不用配置了--&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.env-whitelist<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_HOME,HADOOP_MAPRED_HOME<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<h6><a id="4MapReduce_413"></a>4）MapReduce配置文件</h6> 
<pre><code class="prism language-ruby">cat <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>mapred<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<pre><code class="prism language-xml"><span class="token prolog">&lt;?xml version="1.0"?&gt;</span>
<span class="token prolog">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>修改完成后同步到所有服务器</p> 
<pre><code class="prism language-ruby">xsync <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop
</code></pre> 
<h5><a id="5_441"></a>5、启动整个集群</h5> 
<h6><a id="51workers_443"></a>5.1、配置workers</h6> 
<pre><code class="prism language-shell"><span class="token comment"># 注意： 不允许有任何空格、空行</span>
<span class="token function">vim</span> <span class="token variable">$HADOOP_HOME</span>/etc/hadoop/workers
hadoop1
hadoop2
hadoop3
</code></pre> 
<p>同步文件到所有服务器</p> 
<pre><code class="prism language-ruby">xsync <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>workers
</code></pre> 
<h6><a id="52_459"></a>5.2、启动集群</h6> 
<p>前提添加写权限否则会出现namenode无法启动的状况</p> 
<pre><code class="prism language-ruby">chmod <span class="token operator">-</span><span class="token constant">R</span> a<span class="token operator">+</span>w <span class="token variable">$HADOOP_HOME</span>
</code></pre> 
<p>1、初始化文件系统（<strong>第一次运行，格式化集群</strong>）</p> 
<pre><code class="prism language-ruby">hadoop1 $ hdfs namenode <span class="token operator">-</span>format
</code></pre> 
<p>可以查看下生成的版本号</p> 
<pre><code class="prism language-ruby">cat <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>data<span class="token operator">/</span>dfs<span class="token operator">/</span>name<span class="token operator">/</span>current<span class="token operator">/</span><span class="token constant">VERSION</span>
</code></pre> 
<p>2、启动集群NameNode和DataNode守护进程:</p> 
<p>启动：</p> 
<pre><code class="prism language-ruby">hadoop1 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>dfs<span class="token punctuation">.</span>sh
</code></pre> 
<p>查看启动的服务<code>jps</code></p> 
<p>3、启动ResourceManager （注意要在ResourceManager 的服务器上启动）</p> 
<pre><code class="prism language-ruby">hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
</code></pre> 
<h6><a id="53_495"></a>5.3、页面地址：</h6> 
<pre><code class="prism language-ruby"><span class="token comment"># hdfs的NameNode</span>
<span class="token symbol">http</span><span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop1<span class="token operator">:</span><span class="token number">9870</span>

<span class="token comment"># YARN的ResourceManager</span>
<span class="token symbol">http</span><span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop2<span class="token operator">:</span><span class="token number">8088</span>
</code></pre> 
<h5><a id="6_507"></a>6、集群测试</h5> 
<h6><a id="61_509"></a>6.1、上传文件到集群测试</h6> 
<pre><code class="prism language-ruby"><span class="token comment"># 先在hadoop上创建目录</span>
hadoop fs <span class="token operator">-</span>mkdir <span class="token operator">/</span>tinput

<span class="token comment"># 上传…….txt文件</span>
hadoop fs <span class="token operator">-</span>put tinput<span class="token operator">/</span>word<span class="token punctuation">.</span>txt <span class="token operator">/</span>tinput
</code></pre> 
<p><img src="https://images2.imgbox.com/da/e8/DWwCBpwQ_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="62_522"></a>6.2、上传大文件测试</h6> 
<pre><code class="prism language-ruby">hadoop fs <span class="token operator">-</span>put <span class="token operator">..</span><span class="token operator">/</span>jdk<span class="token operator">-</span><span class="token number">8</span>u361<span class="token operator">-</span>linux<span class="token operator">-</span>x64<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz <span class="token operator">/</span>tinput
</code></pre> 
<p>数据在datanode下存储</p> 
<pre><code class="prism language-ruby"><span class="token comment"># 查看datanode存储的数据可以使用如下方式还原，每一台服务器存储的都一样</span>
cd data<span class="token operator">/</span>dfs<span class="token operator">/</span>data<span class="token operator">/</span>current<span class="token operator">/</span><span class="token constant">BP</span><span class="token operator">-</span><span class="token number">12</span>……<span class="token operator">/</span>current<span class="token operator">/</span>finalized<span class="token operator">/</span>subdir0<span class="token operator">/</span>subdir0<span class="token operator">/</span>blk……<span class="token operator">/</span>……

<span class="token comment"># word.txt</span>
cat blk_1073741825

<span class="token comment"># 还原 jdk-8u361-linux-x64.tar.gz</span>
cat blk_1073741826 <span class="token operator">&gt;&gt;</span>tmp<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz
cat blk_1073741827 <span class="token operator">&gt;&gt;</span>tmp<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz
<span class="token comment"># 解压后可以发现这个就是我们之前导入的jdk压缩包</span>
tar <span class="token operator">-</span>zxvf tmp<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz
</code></pre> 
<h6><a id="63hadoop_544"></a>6.3、hadoop集群测试</h6> 
<pre><code class="prism language-ruby">hadoop jar <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>share<span class="token operator">/</span>hadoop<span class="token operator">/</span>mapreduce<span class="token operator">/</span>hadoop<span class="token operator">-</span>mapreduce<span class="token operator">-</span>examples<span class="token operator">-</span><span class="token number">3.3</span><span class="token number">.1</span><span class="token punctuation">.</span>jar wordcount <span class="token operator">/</span>tinput <span class="token operator">/</span>toutput
</code></pre> 
<p><img src="https://images2.imgbox.com/ae/9c/OBVkkcnG_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="7_555"></a>7、集群崩溃处理</h5> 
<h6><a id="1_557"></a>1）先停止集群</h6> 
<pre><code class="prism language-ruby">hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>stop<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
hadoop1 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>stop<span class="token operator">-</span>dfs<span class="token punctuation">.</span>sh
</code></pre> 
<h6><a id="2_564"></a>2）删除每个集群上的</h6> 
<pre><code class="prism language-ruby">rm <span class="token operator">-</span>rf <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>data<span class="token operator">/</span> <span class="token variable">$HADOOP_HOME</span><span class="token regex-literal"><span class="token regex">/logs/</span></span>
</code></pre> 
<h6><a id="3_570"></a>3）格式化集群</h6> 
<pre><code class="prism language-ruby">hadoop1 $ hdfs namenode <span class="token operator">-</span>format
</code></pre> 
<h6><a id="4_576"></a>4）启动集群</h6> 
<pre><code class="prism language-ruby">hadoop1 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>dfs<span class="token punctuation">.</span>sh
hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
</code></pre> 
<h5><a id="8_585"></a>8、配置历史服务器</h5> 
<h6><a id="81mapredsitexml_587"></a>8.1、配置mapred-site.xml</h6> 
<p>文件中添加如下配置</p> 
<pre><code class="prism language-ruby">hadoop1$ vim <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>mapred<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 配置历史服务器端地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop1:10020<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 配置历史服务web端地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.jobhistory.webapp.address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop1:10888<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<h6><a id="82_611"></a>8.2、同步配置</h6> 
<pre><code class="prism language-ruby">hadoop1 $ xsync <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>mapred<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<h6><a id="83hadoop1_617"></a>8.3、在hadoop1上启动历史服务器</h6> 
<p>如果yarn启动需要关闭重启yarn</p> 
<pre><code class="prism language-ruby">hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>stop<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
</code></pre> 
<p>启动历史服务器</p> 
<pre><code class="prism language-ruby">hadoop1 $ mapred <span class="token operator">-</span><span class="token operator">-</span>daemon start historyserver
</code></pre> 
<h6><a id="84_632"></a>8.4、查看历史服务器是否启动</h6> 
<pre><code class="prism language-ruby">hadoop1 $ jps
</code></pre> 
<h6><a id="85JobHistory_638"></a>8.5、查看JobHistory</h6> 
<pre><code class="prism language-ruby"><span class="token comment"># 先在hadoop上创建目录</span>
hadoop fs <span class="token operator">-</span>mkdir <span class="token operator">/</span>tinput

<span class="token comment"># 上传…….txt文件</span>
hadoop fs <span class="token operator">-</span>put tinput<span class="token operator">/</span>word<span class="token punctuation">.</span>txt <span class="token operator">/</span>tinput

hadoop jar <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>share<span class="token operator">/</span>hadoop<span class="token operator">/</span>mapreduce<span class="token operator">/</span>hadoop<span class="token operator">-</span>mapreduce<span class="token operator">-</span>examples<span class="token operator">-</span><span class="token number">3.3</span><span class="token number">.1</span><span class="token punctuation">.</span>jar wordcount <span class="token operator">/</span>tinput <span class="token operator">/</span>toutput2
</code></pre> 
<h5><a id="9_652"></a>9、配置日志聚合功能</h5> 
<p>功能：将程序运行日志信息上传到HDFS系统上</p> 
<ul><li>注：开启日志聚合功能，需要重启NodeManager、ResourceManager、HistoryServer。</li></ul> 
<p><img src="https://images2.imgbox.com/20/d6/bHsDWsmg_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="1yarnsitexml_661"></a>1）配置yarn-site.xml</h6> 
<pre><code class="prism language-ruby">hadoop1 $ vim <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>yarn<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token comment">&lt;!-- 开启日志聚合功能 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation-enable<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>true<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 设置日志聚合服务器地址 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log.server.url<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>http://hadoop1:19888/jobhistory/logs<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    
    <span class="token comment">&lt;!-- 设置日志保留时间为7天 --&gt;</span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.log-aggregation.retain-seconds<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>604800<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<h6><a id="2_689"></a>2）同步配置</h6> 
<pre><code class="prism language-ruby">hadoop1 $ xsync <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>yarn<span class="token operator">-</span>site<span class="token punctuation">.</span>xml
</code></pre> 
<h6><a id="3NodeManagerResourceManagerHistoryServer_695"></a>3）关闭重启NodeManager、ResourceManager、HistoryServer</h6> 
<p>关闭</p> 
<pre><code class="prism language-ruby">hadoop1 $ mapred <span class="token operator">-</span><span class="token operator">-</span>daemon stop historyserver
hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>stop<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
</code></pre> 
<p>重启</p> 
<pre><code class="prism language-ruby">hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
hadoop1 $ mapred <span class="token operator">-</span><span class="token operator">-</span>daemon start historyserver
</code></pre> 
<h5><a id="10_713"></a>10、集群启停总结：</h5> 
<h6><a id="1_715"></a>1、整体启动停止(推荐)</h6> 
<h6><a id="1HDFS_717"></a>1）整体启动、停止HDFS</h6> 
<pre><code class="prism language-ruby">hadoop1 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>stop<span class="token operator">-</span>dfs<span class="token punctuation">.</span>sh

hadoop1 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>dfs<span class="token punctuation">.</span>sh
</code></pre> 
<h6><a id="2YARN_725"></a>2）整体启动体制YARN</h6> 
<pre><code class="prism language-ruby">hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>stop<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh

hadoop2 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>sbin<span class="token operator">/</span>start<span class="token operator">-</span>yarn<span class="token punctuation">.</span>sh
</code></pre> 
<h6><a id="3historyserver_733"></a>3）启停historyserver</h6> 
<pre><code class="prism language-ruby">hadoop1 $ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>mapred <span class="token operator">-</span><span class="token operator">-</span>daemon stop historyserver

hadoop1 $ mapred <span class="token operator">-</span><span class="token operator">-</span>daemon start historyserver
</code></pre> 
<h6><a id="2_741"></a>2、各个服务组件分别启/停</h6> 
<h6><a id="1HDFS_743"></a>1）启/停HDFS组件</h6> 
<pre><code class="prism language-ruby"><span class="token punctuation">[</span>hdfs<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>hdfs <span class="token operator">-</span><span class="token operator">-</span>daemon stop namenode
<span class="token punctuation">[</span>hdfs<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>hdfs <span class="token operator">-</span><span class="token operator">-</span>daemon stop datanode

<span class="token punctuation">[</span>hdfs<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>hdfs <span class="token operator">-</span><span class="token operator">-</span>daemon start namenode
<span class="token punctuation">[</span>hdfs<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>hdfs <span class="token operator">-</span><span class="token operator">-</span>daemon start datanode
</code></pre> 
<h6><a id="2YARN_753"></a>2）启/停YARN组件</h6> 
<pre><code class="prism language-ruby"><span class="token punctuation">[</span>yarn<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>yarn <span class="token operator">-</span><span class="token operator">-</span>daemon stop resourcemanager
<span class="token punctuation">[</span>yarn<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>yarn <span class="token operator">-</span><span class="token operator">-</span>daemon stop nodemanager

<span class="token punctuation">[</span>yarn<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>yarn <span class="token operator">-</span><span class="token operator">-</span>daemon start resourcemanager
<span class="token punctuation">[</span>yarn<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>yarn <span class="token operator">-</span><span class="token operator">-</span>daemon start nodemanager
</code></pre> 
<h6><a id="3historyserver_763"></a>3）启停historyserver</h6> 
<pre><code class="prism language-ruby"><span class="token punctuation">[</span>mapred<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>mapred <span class="token operator">-</span><span class="token operator">-</span>daemon stop historyserver

<span class="token punctuation">[</span>mapred<span class="token punctuation">]</span>$ <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>mapred <span class="token operator">-</span><span class="token operator">-</span>daemon start historyserver
</code></pre> 
<h5><a id="11Hadoop_773"></a>11、编写Hadoop集群常用脚本</h5> 
<h6><a id="1hadoop_775"></a>1）批量启停<code>hadoop</code>服务</h6> 
<pre><code class="prism language-ruby">hadoop1 $ vim <span class="token variable">$HSCRIPT_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>myhadoop
</code></pre> 
<p><code>cat myhadoop</code></p> 
<pre><code class="prism language-ruby"><span class="token comment">#!/bin/bash</span>

<span class="token keyword">if</span> <span class="token punctuation">[</span> $<span class="token comment"># -lt 1 ]</span>
<span class="token keyword">then</span>
    echo <span class="token string-literal"><span class="token string">"No Args Input..."</span></span>
    exit <span class="token punctuation">;</span>
    
fi

<span class="token keyword">case</span> $<span class="token number">1</span> <span class="token keyword">in</span>
<span class="token string-literal"><span class="token string">"start"</span></span><span class="token punctuation">)</span>
        echo <span class="token string-literal"><span class="token string">"=============== 启动 hadoop 集群 ==============="</span></span>
        echo <span class="token string-literal"><span class="token string">"--------------- 启动 hdfs ---------------"</span></span>
        ssh hadoop1 <span class="token string-literal"><span class="token string">"$HADOOP_HOME/sbin/start-dfs.sh"</span></span>
        echo <span class="token string-literal"><span class="token string">"--------------- 启动 yarn ---------------"</span></span>
        ssh hadoop2 <span class="token string-literal"><span class="token string">"$HADOOP_HOME/sbin/start-yarn.sh"</span></span>
        echo <span class="token string-literal"><span class="token string">"--------------- 启动 historyserver ---------------"</span></span>
        ssh hadoop1 <span class="token string-literal"><span class="token string">"$HADOOP_HOME/bin/mapred --daemon start historyserver"</span></span>
<span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string-literal"><span class="token string">"stop"</span></span><span class="token punctuation">)</span>
        echo <span class="token string-literal"><span class="token string">"=============== Shutdown hadoop 集群 ==============="</span></span>
        echo <span class="token string-literal"><span class="token string">"--------------- 停止 historyserver ---------------"</span></span>
        ssh hadoop1 <span class="token string-literal"><span class="token string">"$HADOOP_HOME/bin/mapred --daemon stop historyserver"</span></span>   
        echo <span class="token string-literal"><span class="token string">"--------------- 停止 yarn ---------------"</span></span>
        ssh hadoop2 <span class="token string-literal"><span class="token string">"$HADOOP_HOME/sbin/stop-yarn.sh"</span></span>
        echo <span class="token string-literal"><span class="token string">"--------------- 停止 hdfs ---------------"</span></span>
        ssh hadoop1 <span class="token string-literal"><span class="token string">"$HADOOP_HOME/sbin/stop-dfs.sh"</span></span>
<span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token operator">*</span><span class="token punctuation">)</span>
        echo <span class="token string-literal"><span class="token string">"Input Args Error.."</span></span>
<span class="token punctuation">;</span><span class="token punctuation">;</span>
esac
</code></pre> 
<p>使用：</p> 
<pre><code class="prism language-ruby"><span class="token comment"># 赋权</span>
hadoop1 $ chmod <span class="token operator">+</span>x <span class="token variable">$HSCRIPT_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>myhadoop

<span class="token comment"># 启动</span>
hadoop1 $ myhadoop start
<span class="token comment"># 停止</span>
hadoop1 $ myhadoop stop
</code></pre> 
<h6><a id="2Javajpsall_834"></a>2）查看所有服务器Java进程脚本：jpsall</h6> 
<pre><code class="prism language-ruby">hadoop1 $ vim <span class="token variable">$HSCRIPT_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>jpsall
</code></pre> 
<p>创建所需查看服务器的host地址</p> 
<pre><code class="prism language-ruby">cat <span class="token operator">/</span>var<span class="token operator">/</span>opt<span class="token operator">/</span>hadoopSoftware<span class="token operator">/</span>hadoopScript<span class="token operator">/</span>config<span class="token operator">/</span>all_hadoop_hosts
hadoop1
hadoop2
hadoop3
</code></pre> 
<p><code>cat jpsall</code></p> 
<pre><code class="prism language-ruby"><span class="token comment">#!/bin/bash</span>

<span class="token keyword">for</span> host <span class="token keyword">in</span> <span class="token command-literal"><span class="token command string">`cat /var/opt/hadoopSoftware/hadoopScript/config/all_hadoop_hosts`</span></span>
<span class="token keyword">do</span>
    echo <span class="token operator">===</span><span class="token operator">===</span><span class="token operator">==</span> <span class="token variable">$host</span> <span class="token operator">===</span><span class="token operator">===</span><span class="token operator">==</span>
    ssh <span class="token variable">$host</span> jps
    echo <span class="token operator">-</span>e <span class="token string-literal"><span class="token string">"\n"</span></span>
done
</code></pre> 
<p>运行：</p> 
<pre><code class="prism language-ruby"><span class="token comment"># 赋权</span>
hadoop1 $ chmod <span class="token operator">+</span>x <span class="token variable">$HSCRIPT_HOME</span><span class="token operator">/</span>bin<span class="token operator">/</span>jpsall

<span class="token comment"># 执行检查</span>
hadoop1 $ jpsall
</code></pre> 
<h5><a id="12_874"></a>12、常用端口号</h5> 
<table><thead><tr><th>端口名称</th><th>Hadoop3.x</th></tr></thead><tbody><tr><td>NameNode 内部通信端口</td><td>8020、9000、9820</td></tr><tr><td>NameNode HTTP UI</td><td>9870</td></tr><tr><td>MapReduce 查看执行任务端口</td><td>8088</td></tr><tr><td>历史服务器通信端口</td><td>19888</td></tr></tbody></table> 
<h3><a id="_883"></a>注：长时间无法关闭集群</h3> 
<p>因为linux默认会30天清理一次/tmp临时文件，而集群配置文件hadoop-env.sh中的默认pid存储位置就在这里，这就造成了因集群长时间运行后，无法正常找到集群的pid</p> 
<p>解决：手动kill掉他们，然后配置自己的hadoop tmp目录即可</p> 
<pre><code class="prism language-ruby">hadoop1 $ vim <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>hadoop<span class="token operator">-</span>env<span class="token punctuation">.</span>sh
<span class="token comment"># Where pid files are stored.  /tmp by default.</span>
<span class="token comment">#export HADOOP_PID_DIR=/tmp</span>
export <span class="token constant">HADOOP_PID_DIR</span><span class="token operator">=</span><span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>tmp
</code></pre> 
<p>同步到其他服务器</p> 
<pre><code class="prism language-ruby">hadoop1 $ mkdir <span class="token operator">-</span>p <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>tmp
hadoop1 $ chmod <span class="token number">777</span> <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>tmp
hadoop1 $ xsync <span class="token variable">$HADOOP_HOME</span><span class="token operator">/</span>tmp
</code></pre> 
<h3><a id="_901"></a>实践</h3> 
<p><a href="https://blog.csdn.net/jiangbenchu/article/details/129661957?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22129661957%22,%22source%22:%22jiangbenchu%22%7D">Hadoop_HDFS</a>、<a href="https://blog.csdn.net/jiangbenchu/article/details/130923774?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22130923774%22,%22source%22:%22jiangbenchu%22%7D">Hadoop_MapReduce</a>、<a href="https://blog.csdn.net/jiangbenchu/article/details/131411732">Hadoop_Yarn</a></p> 
<hr> 
<hr> 
<h3><a id="_915"></a>参考网站</h3> 
<p><a href="https://so.csdn.net/so/search?q=Hadoop&amp;spm=1001.2101.3001.7020">Hadoop</a>官网：http://hadoop.apache.org/<br> Hadoop下载：https://www.apache.org/dyn/closer.cgi/hadoop/common/</p> 
<p>Hadoop历史版本下载：http://archive.apache.org/dist/hadoop/core/<br> Hadoop文档：http://hadoop.apache.org/docs/</p> 
<p>Hive官网：http://hive.apache.org/<br> Hive下载：http://mirror.bit.edu.cn/apache/hive/</p> 
<p>Hive历史版本下载：http://archive.apache.org/dist/hive/<br> Hive文档：https://cwiki.apache.org/confluence/display/Hive</p> 
<p>HBase官网：http://hbase.apache.org/<br> HBase下载：http://mirrors.sonic.net/apache/hbase/</p> 
<p>HBase历史版本下载：http://archive.apache.org/dist/hbase/<br> HBase文档：http://hbase.apache.org/book.html<br> HBase中文文档：http://abloz.com/hbase/book.html</p> 
<p>Spark官网：http://spark.apache.org/<br> Spark下载：http://spark.apache.org/downloads.html<br> Spark文档：http://spark.apache.org/docs/latest/</p> 
<p>Zookeeper官网：http://zookeeper.apache.org/<br> Zookeeper下载：http://zookeeper.apache.org/releases.html#download</p> 
<p>Flume官网：http://flume.apache.org/<br> Flume下载：http://flume.apache.org/download.html<br> Flume文档：http://flume.apache.org/documentation.html</p> 
<p>Mahout官网：http://mahout.apache.org/<br> Mahout下载：http://mahout.apache.org/general/downloads.html</p> 
<p>Tez官网：http://tez.apache.org/</p> 
<p>cdh5版本：</p> 
<p>下载地址：http://archive.cloudera.com/cdh5/cdh/5/<br> 文档地址：http://archive.cloudera.com/cdh5/cdh/5/</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e1a7a2081c53d7d584e1ce9e8b8fe5de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">libpcap的简单应用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5ca70fb9e94b6163dbcc82707e383b0e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于树莓派4B的YOLOv5-Lite目标检测的移植与部署（含训练教程）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>