<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>[论文阅读]RTMDet——实时目标检测 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="[论文阅读]RTMDet——实时目标检测" />
<meta property="og:description" content="RTMDet RTMDet: An Empirical Study of Designing Real-Time Object Detectors
设计实时目标检测器的实证研究
论文网址：RTMDet
摘要 本文的目标是设计一种超越 YOLO 系列的高效实时目标检测器，并且可以轻松扩展到实例分割和旋转目标检测等许多目标识别任务。为了获得更高效的模型架构，本文探索了一种在主干和颈部具有兼容能力的架构，该架构由大内核深度卷积组成的基本构建块组成。在动态标签分配中计算匹配成本时进一步引入软标签以提高准确性。再加上更好的训练技术，最终的目标检测器（名为 RTMDet）在 NVIDIA 3090 GPU 上以 300&#43; FPS 的速度在 COCO 上实现了 52.8% 的 AP，优于当前主流的工业检测器。 RTMDet 针对各种应用场景实现了tiny/small/medium/large/extra-large模型尺寸的最佳参数精度权衡，并在实时实例分割和旋转对象检测方面获得了最先进的性能。
引言 最佳效率始终是物体检测的首要追求，特别是对于自动驾驶、机器人和无人机的现实世界感知而言。为了实现这一目标，YOLO系列探索不同的模型架构和训练技术，以不断提高单级目标检测器的准确性和效率。
本报告的目标是突破 YOLO 系列的极限，并贡献一个新的目标检测实时模型系列，名为 RTMDet，它还能够进行以前的工作尚未探索的实例分割和旋转对象检测。吸引人的改进主要来自于大内核深度卷积的更好表示以及动态标签分配中软标签的更好优化。
具体来说，首先在模型的主干和颈部的基本构建块中利用大内核深度卷积，这提高了模型捕获全局上下文的能力。由于直接将深度卷积放在构建块中会增加模型深度从而减慢推理速度，因此进一步减少构建块的数量以减少模型深度并通过增加模型宽度来补偿模型容量。本文还观察到，在颈部放置更多参数并使其容量与主干兼容可以实现更好的速度精度权衡。模型架构的整体修改允许 RTMDet 的快速推理速度，而不依赖于模型重新参数化 [Yolov6, Yolov7, PP-YOLOE]。
本文进一步重新审视训练策略以提高模型的准确性。除了更好地结合数据增强、优化和训练计划之外，本文凭经验发现，在匹配地面真值框和模型预测时，通过引入软目标而不是硬标签，可以进一步改进现有的动态标签分配策略[TOOD, YOLOX] 。这样的设计提高了成本矩阵的辨别力以实现高质量匹配，同时也降低了标签分配的噪声，从而提高了模型的准确性。
RTMDet 是通用的，只需很少的修改就可以轻松扩展到实例分割和旋转对象检测。通过简单地添加内核和掩码特征生成头[ Sparse instance activation for real-time instance segmentation-2022, Conditional convolutions for instance segmentation-2020]，RTMDet 仅需大约 10% 的额外参数即可执行实例分割。对于旋转物体检测，RTMDet 只需要扩展框回归层的维度（从 4 到 5）并切换到旋转框解码器。本文还观察到，对通用目标检测数据集 [Microsoft COCO] 的预训练有利于空中场景中的旋转目标检测 [Dota]。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/5876152e2e7be57a265310173ca57ffb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-07T12:50:04+08:00" />
<meta property="article:modified_time" content="2023-10-07T12:50:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">[论文阅读]RTMDet——实时目标检测</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="RTMDet_0"></a>RTMDet</h2> 
<p>RTMDet: An Empirical Study of Designing Real-Time Object Detectors<br> 设计实时目标检测器的实证研究<br> 论文网址：<a href="https://arxiv.org/abs/2212.07784" rel="nofollow">RTMDet</a><br> <img src="https://images2.imgbox.com/bd/d8/paMNJYkL_o.png" alt="RTMDet"></p> 
<h3><a id="_5"></a>摘要</h3> 
<p>本文的目标是设计一种超越 YOLO 系列的高效实时目标检测器，并且可以轻松扩展到实例分割和旋转目标检测等许多目标识别任务。为了获得更高效的模型架构，本文探索了一种在主干和颈部具有兼容能力的架构，该架构由大内核深度卷积组成的基本构建块组成。在动态标签分配中计算匹配成本时进一步引入软标签以提高准确性。再加上更好的训练技术，最终的目标检测器（名为 RTMDet）在 NVIDIA 3090 GPU 上以 300+ FPS 的速度在 COCO 上实现了 52.8% 的 AP，优于当前主流的工业检测器。 RTMDet 针对各种应用场景实现了tiny/small/medium/large/extra-large模型尺寸的最佳参数精度权衡，并在实时实例分割和旋转对象检测方面获得了最先进的性能。</p> 
<h3><a id="_7"></a>引言</h3> 
<p>最佳效率始终是物体检测的首要追求，特别是对于自动驾驶、机器人和无人机的现实世界感知而言。为了实现这一目标，YOLO系列探索不同的模型架构和训练技术，以不断提高单级目标检测器的准确性和效率。<br> 本报告的目标是突破 YOLO 系列的极限，并贡献一个新的目标检测实时模型系列，名为 RTMDet，它还能够进行以前的工作尚未探索的实例分割和旋转对象检测。吸引人的改进主要来自于大内核深度卷积的更好表示以及动态标签分配中软标签的更好优化。<br> 具体来说，首先在模型的主干和颈部的基本构建块中利用大内核深度卷积，这提高了模型捕获全局上下文的能力。由于直接将深度卷积放在构建块中会增加模型深度从而减慢推理速度，因此进一步减少构建块的数量以减少模型深度并通过增加模型宽度来补偿模型容量。本文还观察到，在颈部放置更多参数并使其容量与主干兼容可以实现更好的速度精度权衡。模型架构的整体修改允许 RTMDet 的快速推理速度，而不依赖于模型重新参数化 [Yolov6, Yolov7, PP-YOLOE]。<br> 本文进一步重新审视训练策略以提高模型的准确性。除了更好地结合数据增强、优化和训练计划之外，本文凭经验发现，在匹配地面真值框和模型预测时，通过引入软目标而不是硬标签，可以进一步改进现有的动态标签分配策略[TOOD, YOLOX] 。这样的设计提高了成本矩阵的辨别力以实现高质量匹配，同时也降低了标签分配的噪声，从而提高了模型的准确性。<br> RTMDet 是通用的，只需很少的修改就可以轻松扩展到实例分割和旋转对象检测。通过简单地添加内核和掩码特征生成头[ Sparse instance activation for real-time instance segmentation-2022, Conditional convolutions for instance segmentation-2020]，RTMDet 仅需大约 10% 的额外参数即可执行实例分割。对于旋转物体检测，RTMDet 只需要扩展框回归层的维度（从 4 到 5）并切换到旋转框解码器。本文还观察到，对通用目标检测数据集 [Microsoft COCO] 的预训练有利于空中场景中的旋转目标检测 [Dota]。</p> 
<h3><a id="_13"></a>相关工作</h3> 
<p><strong>Efficient neural architecture for object detection.</strong> 对象检测旨在识别和定位场景中的对象。对于实时应用，现有的工作主要探索基于锚点的或无锚点的单级检测器，而不是两级检测器。为了提高模型效率，通过手工设计或神经架构探索高效的骨干网络和模型缩放策略以及多尺度特征的增强。最近的进展还探索了模型架构搜索以提高模型部署后的推理速度。本文贡献了一种在骨干和颈部具有兼容容量的整体架构，该架构由具有大内核深度卷积的新基本构建块构建，以实现更高效的目标检测器。<br> <strong>Label assignment for object detection.</strong> 改进目标检测器的另一个维度是标签分配和训练损失的设计。先前方法 [Cascade R-CNN, Focal loss for dense object detection, SSD, Faster R-CNN] 使用 IoU 作为匹配标准，将真实框与标签分配中的模型预测或锚点进行比较。后来的实践[Probabilistic anchor assignment with iou prediction for object detection, FCOS, Bridging the gap between anchor-based and anchor-free detection via adaptive training sample selection, Objects as points]进一步探索了不同的匹配标准，例如对象中心[FCOS, Objects as points]。还探索了辅助检测头 [NanoDet-Plus, Yolov7] 以加速和稳定训练。受匈牙利分配法端到端对象检测[End-to-end object detection with transformers.]的启发，动态标签分配被探索以显着提高收敛速度和模型精度。与这些使用与损失完全相同的匹配成本函数的策略不同，本文建议在计算匹配成本时使用软标签，以扩大高质量匹配和低质量匹配之间的区别，从而稳定训练并加速收敛。</p> 
<h3><a id="Methodology_16"></a>Methodology</h3> 
<p>本文构建了一个新的对象检测实时模型系列，名为 RTMDet。 RTMDet 的宏观架构是典型的单级目标检测器。通过探索主干和颈部基本构建块中的大核卷积来提高模型效率，并相应地平衡模型深度、宽度和分辨率。进一步探索动态标签分配策略中的软标签以及数据增强和优化策略的更好组合以提高模型准确性。 RTMDet 是一个多功能的对象识别框架，只需少量修改即可扩展到实例分割和旋转对象检测任务。<br> <img src="https://images2.imgbox.com/fa/1c/xh9Rz2Fb_o.png" alt="RTMDet"></p> 
<h4><a id="_19"></a>宏观架构</h4> 
<p>本文将一级目标检测器的宏观架构分解为骨干、颈部和头部，如上图所示。YOLO 系列 [yolov4, yolox] 的最新进展通常采用 CSPDarkNet 作为主干架构，这包含四个阶段，每个阶段都由几个基本构建块堆叠而成（图 a）。颈部从主干中获取多尺度特征金字塔，并使用与主干相同的基本构建块，通过自下而上和自上而下的特征传播来增强金字塔特征图。最后，检测头根据每个尺度的特征图预测对象边界框及其类别。这种架构通常适用于一般和旋转的对象，并且可以扩展。<br> <img src="https://images2.imgbox.com/30/31/v4sCOt1W_o.png" alt="CSPDarkNet"><br> 为了充分发挥宏架构的潜力，本文首先研究更强大的基本构建模块。然后将研究架构中的计算瓶颈，并平衡主干和颈部的深度、宽度和分辨率。</p> 
<h4><a id="_23"></a>模型架构</h4> 
<p><strong>Basic building block.</strong> 骨干中的大有效感受野有利于密集预测任务，如对象检测和分割，因为它有助于更​​全面地捕获和建模图像上下文。然而，之前的尝试（例如扩张卷积[Dilated residual networks]和非局部块[Non-local neural networks]）的计算成本很高，限制了它们在实时目标检测中的实际应用。最近的研究 [Scaling up your kernels to 31x31, A convnet for the 2020s] 重新审视了大核卷积的使用，表明可以通过深度可分离卷积以合理的计算成本扩大感受野 [Mobilenets]。受这些发现的启发，本文在 CSPDarkNet 的基本构建块中引入了 5×5 深度可分离卷积，以增加有效感受野（图 b）。这种方法允许更全面的上下文建模并显着提高准确性。<br> <img src="https://images2.imgbox.com/20/5e/srP94xb5_o.png" alt="5*5"><br> 值得注意的是，最近的一些实时目标检测器 [yolov6, yolov7, PP-YOLOE] 在基本构建块中探索了重新参数化的 3×3 卷积 [RepVGG]（图 c&amp;d）。虽然重新参数化的 3×3 卷积被认为是提高推理准确性，但它也带来了副作用，例如训练速度变慢和训练内存增加等。它还会增加模型量化到较低位后的误差间隙，需要通过重新参数化优化器和量化感知训练进行补偿。与重新参数化的 3×3 卷积相比，大内核深度卷积对于基本构建块来说是更简单、更有效的选择，因为它们需要更少的训练成本，并且在模型量化后导致的误差间隙更小。<br> <img src="https://images2.imgbox.com/77/30/SneVPg9L_o.png" alt="repvgg"><br> <strong>Balance of model width and depth.</strong>：由于大核深度卷积之后的额外逐点卷积，基本块中的层数也增加了（图 b）。这阻碍了每一层的并行计算，从而降低了推理速度。为了解决这个问题，本文减少了每个主干阶段的块数量，并适当增大块的宽度，以提高并行度并保持模型容量，最终在不牺牲准确性的情况下提高推理速度。<br> <strong>Balance of backbone and neck.</strong>： 多尺度特征金字塔对于目标检测至关重要，可以检测各种尺度的目标。为了增强多尺度特征，以前的方法要么使用具有更多参数的更大骨干，要么使用更重的颈部，在特征金字塔之间有更多的连接和融合。然而，这些尝试也增加了计算和内存占用。因此，本文采用另一种策略，通过增加颈部基本块的扩展比例，使它们具有相似的容量，从而将更多的参数和计算从骨干转移到颈部，从而获得更好的计算精度权衡。<br> <strong>Shared detection head.</strong>： 实时物体检测器通常针对不同的特征尺度使用单独的检测头 ，以增强模型容量以获得更高的性能，而不是跨多个尺度共享检测头 。本文中比较了不同的设计选择，并选择跨尺度共享头部参数，但合并不同的批量归一化（BN）层以减少头部的参数量，同时保持准确性。 BN 也比其他归一化层（例如 Group Normalization ）更高效，因为在推理中它直接使用训练中计算的统计数据。</p> 
<h4><a id="Training_Strategy_31"></a>Training Strategy</h4> 
<p><strong>Label assignment and losses.</strong>： 为了训练单阶段目标检测器，每个尺度的密集预测将通过不同的标签分配策略与地面真实边界框进行匹配。最近的进展通常采用动态标签分配策略，该策略使用与训练损失一致的成本函数作为匹配标准。然而，本文发现他们的成本计算有一些局限性。因此，本文提出了一种基于SimOTA的动态软标签分配策略，其损失函数表示为<br> <img src="https://images2.imgbox.com/51/a4/XgIqVYoR_o.png" alt="在这里插入图片描述"><br> 其中Ccls、Ccenter和Creg分别对应分类损失、区域先验损失和回归损失，默认情况下λ1 = 1、λ2 = 3和λ3 = 1是这三个成本的权重。<br> 以前的方法通常利用二进制标签来计算分类成本 Ccls，这允许使用高分类分数但不正确的边界框进行预测，以实现低分类成本，反之亦然。为了解决这个问题，本文在 Ccls 中引入软标签：<br> <img src="https://images2.imgbox.com/a4/eb/7uEKZQQG_o.png" alt="在这里插入图片描述"><br> 该修改受到 GFL 的启发，它使用预测和真实框之间的 IoU 作为软标签 Ysoft 来训练分类分支。分配中的软分类成本不仅重新加权了不同回归质量的匹配成本，而且避免了二元标签引起的噪声和不稳定匹配。<br> 当使用广义IoU作为回归成本时，最佳匹配和最差匹配之间的最大差异小于1。这使得很难区分高质量匹配和低质量匹配。为了使不同 GT 预测对的匹配质量更具辨别力，使用 IoU 的对数作为回归成本，而不是损失函数中使用的 GIoU，这会放大具有较低 IoU 值的匹配的成本。回归成本 Creg 计算如下<br> <img src="https://images2.imgbox.com/e8/8f/1l55mfyu_o.png" alt="在这里插入图片描述"><br> 对于区域成本 Ccenter，本文使用软中心区域成本代替固定中心先验来稳定动态成本的匹配，如下所示<br> <img src="https://images2.imgbox.com/f9/cc/FEItimxU_o.png" alt="在这里插入图片描述"><br> 其中α和β是软中心区域的超参数。默认设置α = 10，β = 3。<br> <strong>Cached Mosaic and MixUp.</strong>：MixUp 和CutMix 等跨样本增强在最近的目标检测器中被广泛采用。这些增强功能很强大，但会带来两个副作用。首先，在每次迭代中，他们需要加载多个图像来生成训练样本，这会引入更多的数据加载成本并减慢训练速度。其次，生成的训练样本是“有噪声的”，可能不属于数据集的真实分布，这会影响模型的学习。<br> 本文通过缓存机制改进了 MixUp 和 Mosaic，减少了数据加载的需求。通过利用缓存，在训练pipeline中混合图像的时间成本可以显着降低到处理单个图像的水平。缓存操作由缓存长度和出栈方法控制。大的缓存长度和随机出栈的方式可以认为相当于原来的无缓存的MixUp和Mosaic操作。同时，较小的缓存长度和先进先出（FIFO）弹出方法可以被视为类似于重复增强，允许在相同或连续批次中混合相同图像与不同数据增强操作。<br> <strong>Two-stage training.</strong>： 为了通过强数据增强来减少“噪声”样本的副作用，YOLOX 探索了一种两阶段训练策略，其中第一阶段使用强数据增强，包括 Mosaic、MixUp 以及随机旋转和剪切，第二阶段使用弱数据增强，例如随机调整大小和翻转。由于初始训练阶段的强增强包括随机旋转和剪切，导致输入和变换后的框注释之间未对准，YOLOX 添加了 L1 损失来微调第二阶段的回归分支。为了解耦数据增强和损失函数的使用，本文排除了这些数据增强，并在 280 个 epoch 的第一个训练阶段将每个训练样本中的混合图像数量增加到 8 个，以补偿数据增强的强度。在过去 20 个时期中，切换到大规模抖动（LSJ），允许在与真实数据分布更紧密一致的领域中对模型进行微调。为了进一步稳定训练，采用 AdamW 作为优化器。</p> 
<h3><a id="_46"></a>结论</h3> 
<p>在本文中，我们根据经验全面研究了实时目标检测器中的每个关键组件，包括模型架构、标签分配、数据增强和优化。我们进一步探索高精度实时对象检测器对实时实例分割和旋转对象检测的最小适应性。研究结果催生了一个新的目标检测实时模型系列，名为 RTMDet，及其针对不同目标识别任务的衍生模型。 RTMDet 展示了工业级应用中准确性和速度之间的卓越权衡，针对不同的对象识别任务具有不同的模型大小。我们希望RTMDet的实验结果能够为实时物体识别任务的未来研究和产业发展铺平道路。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/372af2990c113d362b1db4fc3153ded7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">[论文阅读]H3DNet——基于混合几何基元的3D目标检测</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ec5e79f809fac986a71b5647b5ca93ac/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">react-hook</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>