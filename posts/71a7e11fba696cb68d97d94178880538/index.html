<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg之硬解码 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg之硬解码" />
<meta property="og:description" content="导读 前面我们已经使用NDK编译出了FFmpeg并且已经集成到了Android Studio中去，相关文章：NDK21编译ffmpeg5.0.1
众所周知，软解码虽然兼容性一流，但是却非常依赖CPU，所以性能消耗笔记大；硬解码使用内置的DSP芯片进行解码，性能高，但是兼容性一般。
虽说硬解码兼容性不太好，但是在实际开发中出于对性能的考虑我们依然会采用能硬解则硬解，不能硬解则软解兜底的方案。
我们知道安卓上可以使用MediaCodec进行硬解码，新版本FFmpeg内部也支持了MediaCodec硬解码，今天我们就使用FFMpeg在安卓上使用MediaCodec进行硬解码。
笔者测试的FFmpeg版本是最新的5.0.1，不同版本之间可以会有差异。
编译支持硬解码的FFmpeg 要编译支持硬解码的FFmpeg，在进行交叉编译时我们只需要打开以下几个属性即可：
--enable-hwaccels \ --enable-jni \ --enable-mediacodec \ --enable-decoder=h264_mediacodec \ --enable-decoder=hevc_mediacodec \ --enable-decoder=mpeg4_mediacodec \ --enable-hwaccel=h264_mediacodec \ 使用FFMpeg进行硬解码 使用FFmpeg无论是硬解码还是软解码流程都是差不多的，对使用FFmpeg编解码API不熟悉的童鞋们可以回看之前发表的博客文章…
在FFmpeg源文件hwcontext.c中我们可以看出mediacodec对应的type类型是AV_HWDEVICE_TYPE_MEDIACODEC，这个AV_HWDEVICE_TYPE_MEDIACODEC很重要，
在配置硬解码器时都是需要使用到这个type。
static const char *const hw_type_names[] = { [AV_HWDEVICE_TYPE_CUDA] = &#34;cuda&#34;, [AV_HWDEVICE_TYPE_DRM] = &#34;drm&#34;, [AV_HWDEVICE_TYPE_DXVA2] = &#34;dxva2&#34;, [AV_HWDEVICE_TYPE_D3D11VA] = &#34;d3d11va&#34;, [AV_HWDEVICE_TYPE_OPENCL] = &#34;opencl&#34;, [AV_HWDEVICE_TYPE_QSV] = &#34;qsv&#34;, [AV_HWDEVICE_TYPE_VAAPI] = &#34;vaapi&#34;, [AV_HWDEVICE_TYPE_VDPAU] = &#34;vdpau&#34;, [AV_HWDEVICE_TYPE_VIDEOTOOLBOX] = &#34;videotoolbox&#34;, [AV_HWDEVICE_TYPE_MEDIACODEC] = &#34;mediacodec&#34;, [AV_HWDEVICE_TYPE_VULKAN] = &#34;vulkan&#34;, }; 下面说说在FFMpeg配置硬解码器的大体步骤：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/71a7e11fba696cb68d97d94178880538/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-29T20:40:33+08:00" />
<meta property="article:modified_time" content="2022-04-29T20:40:33+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg之硬解码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>导读</h2> 
<p>前面我们已经使用NDK编译出了FFmpeg并且已经集成到了Android Studio中去，相关文章：<a href="https://mp.weixin.qq.com/s/8Iy0iQ7cAqssBby8moUvvg" rel="nofollow">NDK21编译ffmpeg5.0.1</a></p> 
<p>众所周知，软解码虽然兼容性一流，但是却非常依赖CPU，所以性能消耗笔记大；硬解码使用内置的DSP芯片进行解码，性能高，但是兼容性一般。</p> 
<p>虽说硬解码兼容性不太好，但是在实际开发中出于对性能的考虑我们依然会采用能硬解则硬解，不能硬解则软解兜底的方案。</p> 
<p>我们知道安卓上可以使用MediaCodec进行硬解码，新版本FFmpeg内部也支持了MediaCodec硬解码，今天我们就使用FFMpeg在安卓上使用MediaCodec进行硬解码。</p> 
<p><strong>笔者测试的FFmpeg版本是最新的5.0.1，不同版本之间可以会有差异。</strong></p> 
<h2><a id="FFmpeg_13"></a>编译支持硬解码的FFmpeg</h2> 
<p>要编译支持硬解码的FFmpeg，在进行交叉编译时我们只需要打开以下几个属性即可：</p> 
<pre><code>--enable-hwaccels \
--enable-jni \
--enable-mediacodec \
--enable-decoder=h264_mediacodec \
--enable-decoder=hevc_mediacodec \
--enable-decoder=mpeg4_mediacodec \
--enable-hwaccel=h264_mediacodec \
</code></pre> 
<h2><a id="FFMpeg_26"></a>使用FFMpeg进行硬解码</h2> 
<p>使用FFmpeg无论是硬解码还是软解码流程都是差不多的，对使用FFmpeg编解码API不熟悉的童鞋们可以回看之前发表的博客文章…</p> 
<p>在FFmpeg源文件<code>hwcontext.c</code>中我们可以看出mediacodec对应的type类型是<code>AV_HWDEVICE_TYPE_MEDIACODEC</code>，这个<code>AV_HWDEVICE_TYPE_MEDIACODEC</code>很重要，<br> 在配置硬解码器时都是需要使用到这个type。</p> 
<pre><code>static const char *const hw_type_names[] = {
    [AV_HWDEVICE_TYPE_CUDA]   = "cuda",
    [AV_HWDEVICE_TYPE_DRM]    = "drm",
    [AV_HWDEVICE_TYPE_DXVA2]  = "dxva2",
    [AV_HWDEVICE_TYPE_D3D11VA] = "d3d11va",
    [AV_HWDEVICE_TYPE_OPENCL] = "opencl",
    [AV_HWDEVICE_TYPE_QSV]    = "qsv",
    [AV_HWDEVICE_TYPE_VAAPI]  = "vaapi",
    [AV_HWDEVICE_TYPE_VDPAU]  = "vdpau",
    [AV_HWDEVICE_TYPE_VIDEOTOOLBOX] = "videotoolbox",
    [AV_HWDEVICE_TYPE_MEDIACODEC] = "mediacodec",
    [AV_HWDEVICE_TYPE_VULKAN] = "vulkan",
};
</code></pre> 
<p>下面说说在FFMpeg配置硬解码器的大体步骤：</p> 
<p>1、给FFMpeg设置虚拟机环境</p> 
<p>首先在库加载函数<code>JNI_OnLoad</code>中调用FFmpeg的函数<code>av_jni_set_java_vm</code>，给FFMpeg设置虚拟机环境：</p> 
<pre><code>// 类库加载时自动调用
JNIEXPORT jint JNICALL JNI_OnLoad(JavaVM *vm, void *reversed) {
    JNIEnv *env = NULL;
    // 初始化JNIEnv
    if (vm-&gt;GetEnv(reinterpret_cast&lt;void **&gt;(&amp;env), JNI_VERSION_1_6) != JNI_OK) {
        return JNI_FALSE;
    }

    // 设置JavaVM，否则无法进行硬解码
    av_jni_set_java_vm(vm, nullptr);
    RegisterNativeMethods(env, "com/fly/ffmpeg/practice/ffmpeg/FFmpegHWDecoder",
                          const_cast&lt;JNINativeMethod *&gt;(hw_decoder_nativeMethod), sizeof(hw_decoder_nativeMethod) / sizeof (JNINativeMethod));
    // 返回JNI使用的版本
    return JNI_VERSION_1_4;
}
</code></pre> 
<p>2、通过名字查找硬解码器</p> 
<p>以h264为例，在安卓上它的硬解码器名字为<code>h264_mediacodec</code>，可以通过函数<code>avcodec_find_decoder_by_name("h264_mediacodec")</code>查找解码器，<br> 如果返回空，一般就是不支持硬解码了。</p> 
<p>3、配置硬解码器</p> 
<p>这个配置主要是为了获取解码得到的YUV是什么格式的。</p> 
<pre><code>       // 配置硬解码器
                int i;
                for (i = 0;; i++) {
                    const AVCodecHWConfig *config = avcodec_get_hw_config(avCodec, i);
                    if (nullptr == config) {
                        LOGCATE("获取硬解码是配置失败");
                        return;
                    }
                    if (config-&gt;methods &amp; AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX &amp;&amp;
                        config-&gt;device_type == AV_HWDEVICE_TYPE_MEDIACODEC) {
                        hw_pix_fmt = config-&gt;pix_fmt;
                        LOGCATE("硬件解码器配置成功");
                        break;
                    }
                }
</code></pre> 
<p>4、初始化mediacodec的buffer</p> 
<pre><code>    avCodecContext = avcodec_alloc_context3(avCodec);
    avcodec_parameters_to_context(avCodecContext,avFormatContext-&gt;streams[video_index]-&gt;codecpar);
    avCodecContext-&gt;get_format = get_hw_format;
    // 硬件解码器初始化
    AVBufferRef *hw_device_ctx = nullptr;
    ret = av_hwdevice_ctx_create(&amp;hw_device_ctx, AV_HWDEVICE_TYPE_MEDIACODEC,
                           nullptr, nullptr, 0);
    if (ret &lt; 0) {
        LOGCATE("Failed to create specified HW device");
        return;
    }
    avCodecContext-&gt;hw_device_ctx = av_buffer_ref(hw_device_ctx);
</code></pre> 
<p>5、打开解码器</p> 
<p>和软解码一样，使用函数<code>avcodec_open2</code>打开解码器即可。后面的操作就是和软解码一样了。</p> 
<p>从以上可以看出，硬解码和软解的区别就是硬解码需要多配置一点信息而已，下面贴一下主要代码：</p> 
<pre><code>#include "HWDecoder.h"
#include &lt;log_cat.h&gt;

extern "C" {
#include &lt;libavformat/avformat.h&gt;
#include &lt;libavcodec/avcodec.h&gt;
#include &lt;libavcodec/codec.h&gt;
#include &lt;libavutil/avutil.h&gt;
#include &lt;libavutil/pixdesc.h&gt;
}

AVFormatContext *avFormatContext;
AVPacket *avPacket;
AVFrame *avFrame;
AVCodecContext *avCodecContext;
FILE *yuv_file;
HWDecoder::HWDecoder() {

}

HWDecoder::~HWDecoder() {
    if (nullptr != avFormatContext) {
        avformat_free_context(avFormatContext);
        avFormatContext = nullptr;
    }
    if (nullptr != avCodecContext) {
        avcodec_free_context(&amp;avCodecContext);
        avCodecContext = nullptr;
    }
    if (nullptr != avPacket) {
        av_packet_free(&amp;avPacket);
        avPacket = nullptr;
    }
    if (nullptr != avFrame) {
        av_frame_free(&amp;avFrame);
        avFrame = nullptr;
    }
    if(nullptr != yuv_file){
        fclose(yuv_file);
        yuv_file = nullptr;
    }
}

AVPixelFormat hw_pix_fmt;
static enum AVPixelFormat get_hw_format(AVCodecContext *ctx,
                                        const enum AVPixelFormat *pix_fmts)
{
    const enum AVPixelFormat *p;

    for (p = pix_fmts; *p != -1; p++) {
        if (*p == hw_pix_fmt)
            return *p;
    }

    LOGCATE("Failed to get HW surface format.\n");
    return AV_PIX_FMT_NONE;
}

void HWDecoder::decode_video(const char *video_path, const char *yuv_path) {
    avFormatContext = avformat_alloc_context();
    int ret = avformat_open_input(&amp;avFormatContext, video_path, nullptr, nullptr);
    if (ret &lt; 0) {
        LOGCATE("打开媒体文件失败");
        return;
    }
    avformat_find_stream_info(avFormatContext, nullptr);
    int video_index = av_find_best_stream(avFormatContext, AVMEDIA_TYPE_VIDEO, -1, -1, nullptr, 0);
    if (video_index &lt; 0) {
        LOGCATE("找不到视频索引");
        return;
    }
    LOGCATE("找到视频索引:%d", video_index);

    const AVCodec *avCodec = nullptr;
    switch (avFormatContext-&gt;streams[video_index]-&gt;codecpar-&gt;codec_id) {
        // 这里以h264为例
        case AV_CODEC_ID_H264:
            avCodec = avcodec_find_decoder_by_name("h264_mediacodec");
            if (nullptr == avCodec) {
                LOGCATE("没有找到硬解码器h264_mediacodec");
                return;
            } else {
                // 配置硬解码器
                int i;
                for (i = 0;; i++) {
                    const AVCodecHWConfig *config = avcodec_get_hw_config(avCodec, i);
                    if (nullptr == config) {
                        LOGCATE("获取硬解码是配置失败");
                        return;
                    }
                    if (config-&gt;methods &amp; AV_CODEC_HW_CONFIG_METHOD_HW_DEVICE_CTX &amp;&amp;
                        config-&gt;device_type == AV_HWDEVICE_TYPE_MEDIACODEC) {
                        hw_pix_fmt = config-&gt;pix_fmt;
                        LOGCATE("硬件解码器配置成功");
                        break;
                    }
                }
                break;
            }
    }
    avCodecContext = avcodec_alloc_context3(avCodec);
    avcodec_parameters_to_context(avCodecContext,avFormatContext-&gt;streams[video_index]-&gt;codecpar);
    avCodecContext-&gt;get_format = get_hw_format;
    // 硬件解码器初始化
    AVBufferRef *hw_device_ctx = nullptr;
    ret = av_hwdevice_ctx_create(&amp;hw_device_ctx, AV_HWDEVICE_TYPE_MEDIACODEC,
                           nullptr, nullptr, 0);
    if (ret &lt; 0) {
        LOGCATE("Failed to create specified HW device");
        return;
    }
    avCodecContext-&gt;hw_device_ctx = av_buffer_ref(hw_device_ctx);
    // 打开解码器
    ret = avcodec_open2(avCodecContext, avCodec, nullptr);
    if (ret != 0) {
        LOGCATE("解码器打开失败:%s",av_err2str(ret));
        return;
    } else {
        LOGCATE("解码器打开成功");
    }

    avPacket = av_packet_alloc();
    avFrame = av_frame_alloc();
    yuv_file = fopen(yuv_path,"wb");
    while (true) {
        ret = av_read_frame(avFormatContext, avPacket);
        if (ret != 0) {
            LOGCATE("av_read_frame end");
            break;
        }
        if(avPacket-&gt;stream_index != video_index){
            av_packet_unref(avPacket);
            continue;
        }
        ret = avcodec_send_packet(avCodecContext,avPacket);
        if(ret == AVERROR(EAGAIN)){
            LOGCATD("avcodec_send_packet EAGAIN");
        } else if(ret &lt; 0){
            LOGCATE("avcodec_send_packet fail:%s",av_err2str(ret));
            return;
        }
        av_packet_unref(avPacket);
        ret = avcodec_receive_frame(avCodecContext,avFrame);
        LOGCATE("avcodec_receive_frame：%d",ret);
        while (ret == 0){
            LOGCATE("获取解码数据成功：%s",av_get_pix_fmt_name(static_cast&lt;AVPixelFormat&gt;(avFrame-&gt;format)));
            LOGCATE("linesize0:%d,linesize1:%d,linesize2:%d",avFrame-&gt;linesize[0],avFrame-&gt;linesize[1],avFrame-&gt;linesize[2]);
            LOGCATE("width:%d,height:%d",avFrame-&gt;width,avFrame-&gt;height);
            ret = avcodec_receive_frame(avCodecContext,avFrame);
            // 如果解码出来的数据是nv12
            // 播放 ffplay -i d:/cap.yuv -pixel_format nv12 -framerate 25 -video_size 640x480
            // 写入y
            for(int j=0; j&lt;avFrame-&gt;height; j++)
                fwrite(avFrame-&gt;data[0] + j * avFrame-&gt;linesize[0], 1, avFrame-&gt;width, yuv_file);
            // 写入uv
            for(int j=0; j&lt;avFrame-&gt;height/2; j++)
                fwrite(avFrame-&gt;data[1] + j * avFrame-&gt;linesize[1], 1, avFrame-&gt;width, yuv_file);
        }
    }

}
</code></pre> 
<p>解码成功将YUV写入文件后可以通过ffplay播放一下，看画面是否正常，怎么播放具体看注释。</p> 
<h2><a id="_285"></a>遇到的问题</h2> 
<p>1、笔者在测试的过程中发现打开解码器报错:</p> 
<pre><code>Generic error in an external library
</code></pre> 
<p>经查验代码发现是没有给FFmpeg设置JavaJVM，需要调用函数设置<code>av_jni_set_java_vm</code>JavaJVM参数即可。</p> 
<p>2、如果解码得到的AVFrame的格式不是NV12或者NV21的话，表示数据有可能保存在GPU中，可以通过函数<code>av_hwframe_transfer_data</code>将数据取出到CPU。</p> 
<h2><a id="_296"></a>推荐阅读</h2> 
<p><a href="https://mp.weixin.qq.com/s/TJr5jul7LWRXvmPIJHTkKA" rel="nofollow">FFmpeg连载1-开发环境搭建</a><br> <a href="https://mp.weixin.qq.com/s/7ZCK7ImY15BpOIZDro5O9g" rel="nofollow">FFmpeg连载2-分离视频和音频</a><br> <a href="https://mp.weixin.qq.com/s/PxrTXxrWYJhKh9JV0n25yw" rel="nofollow">FFmpeg连载3-视频解码</a><br> <a href="https://mp.weixin.qq.com/s/LCrHdBFn3qb9WR6qCaCAzw" rel="nofollow">FFmpeg连载4-音频解码</a><br> <a href="https://mp.weixin.qq.com/s/dEjERC0MrNeiwSu9r3xrZA" rel="nofollow">FFmpeg连载5-音视频编码</a><br> <a href="https://mp.weixin.qq.com/s/gKtXwddIFnvT-N2e4-yGcg" rel="nofollow">FFmpeg连载6-音频重采样</a><br> <a href="https://mp.weixin.qq.com/s/xKiheiJQ_LAODIA8eKEzug" rel="nofollow">FFmpeg连载8-视频合并以及替换视频背景音乐实战</a><br> <a href="https://mp.weixin.qq.com/s/1j5zn07BQLqeQ-sY73NE9w" rel="nofollow">ffplay调试环境搭建</a><br> <a href="https://mp.weixin.qq.com/s/iATB9oCvBpNIg_L_IxBzoA" rel="nofollow">ffplay整体框架</a><br> <a href="https://mp.weixin.qq.com/s/rngHKbaG41mk2Cf667ZfBA" rel="nofollow">ffplay数据读取线程</a><br> <a href="https://mp.weixin.qq.com/s/hxb7vQETgoyMmg3h_NUv2Q" rel="nofollow">ffplay音视频解码线程</a><br> <a href="https://mp.weixin.qq.com/s/elj73kNxbIv4cLBBy3t2lA" rel="nofollow">ffplay音视频同步</a><br> <a href="https://mp.weixin.qq.com/s/8Iy0iQ7cAqssBby8moUvvg" rel="nofollow">NDK21编译ffmpeg5.0.1</a></p> 
<p>关注我，一起进步，人生不止coding！！！<br> <img src="https://images2.imgbox.com/92/53/cFKQHsrL_o.png" alt="微信扫码关注"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ae958551e054bde47c6741d83d53c053/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">成功解决CentOS7中yum能ping通外网，但是无法下载问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/023fa135950493e00b0d8087e62bf10a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言实现维吉尼亚（Vigenere）加密算法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>