<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习系列48：超分模型Real-ESRGAN - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习系列48：超分模型Real-ESRGAN" />
<meta property="og:description" content="1. 模型介绍 1.1 退化模型 首先训练数据使用了2个first-order：
最后一步加入了振铃和过冲现象：
1.2 SRCNN 将CNN用到超分领域的第一篇文章：
论文中卷积核和通道数的实验设置为：
1.3 SRGAN SRGAN将GAN引入超分领域，用于解决如下问题：
1）高频细节(high-frequency details) 的丢失，整体图像过于平滑/模糊；
2）与人的视觉感知不一致，超分图像的精确性与人的期望不匹配（人可能更关注前景，而对背景清晰度要求不高）。
提出如下改进：
新的backbone：SRResNet；GAN-based network 及 新的损失函数：adversarial loss：提升真实感(photo-realistic natural images)；content loss：获取HR image和生成图像的感知相似性(perceptual similarity)，而不只是像素级相似性(pixel similarity)；或者说特征空间的相似性而不是像素空间的相似性。使用主观评估手段，更加强调人的感知。 模型结构如下，Generator网络是SRResNet，论文使用了16个residual blocks；Discriminator网络为8次卷积操作（4次步长为2）&#43;2次全连接层的VGG网络。
1.4 ESRGAN enhanced SRGAN，主要解决细节模糊和伪影问题。
SRResNet网络结构的改进：
1）移除BN，有利于去除伪影，提升泛化能力；
2）使用Residual-in-Residual Dense Block (RRDB)作为基本构建模块，更强更易训练；GAN-based Network的损失函数的改进：使用RaGAN (Relativistic average GAN)中的相对损失函数，提升图像的相对真实性从而恢复更多的纹理细节；感知损失函数的改进：使用VGG激活层前的特征值计算重构损失，提升了亮度的一致性和纹理恢复程度。
2. 快速上手 2.1 各种资源 绿色版的exe文件参见github，支持windows，linux，mac和NCNN
在线版本：https://huggingface.co/spaces/akhaliq/Real-ESRGAN
使用方法：./realesrgan-ncnn-vulkan.exe -i 二次元图片.jpg -o 二刺螈图片.png -n realesrgan-x4plus-anime
参数如下：
Usage: realesrgan-ncnn-vulkan.exe -i infile -o outfile [options]... -h show this help -i input-path input image path (jpg/png/webp) or directory -o output-path output image path (jpg/png/webp) or directory -s scale upscale ratio (can be 2, 3, 4." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7d2eef0c1a09df5005d956e41c39d5a6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-23T14:55:02+08:00" />
<meta property="article:modified_time" content="2022-06-23T14:55:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习系列48：超分模型Real-ESRGAN</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="1__0"></a>1. 模型介绍</h2> 
<h3><a id="11__1"></a>1.1 退化模型</h3> 
<p>首先训练数据使用了2个first-order：<br> <img src="https://images2.imgbox.com/55/eb/2VokXpZ4_o.png" alt="在这里插入图片描述"><br> 最后一步加入了振铃和过冲现象：<br> <img src="https://images2.imgbox.com/9a/1e/rWSrY4Bf_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="12_SRCNN_6"></a>1.2 SRCNN</h3> 
<p>将CNN用到超分领域的第一篇文章：<br> <img src="https://images2.imgbox.com/30/67/MmY3vfBV_o.png" alt="在这里插入图片描述"><br> 论文中卷积核和通道数的实验设置为：<br> <img src="https://images2.imgbox.com/6c/ae/0ELVtXZK_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="13_SRGAN_11"></a>1.3 SRGAN</h3> 
<p>SRGAN将GAN引入超分领域，用于解决如下问题：<br> 1）高频细节(high-frequency details) 的丢失，整体图像过于平滑/模糊；<br> 2）与人的视觉感知不一致，超分图像的精确性与人的期望不匹配（人可能更关注前景，而对背景清晰度要求不高）。</p> 
<p>提出如下改进：</p> 
<ul><li>新的backbone：SRResNet；</li><li>GAN-based network 及 新的损失函数：</li><li>adversarial loss：提升真实感(photo-realistic natural images)；</li><li>content loss：获取HR image和生成图像的感知相似性(perceptual similarity)，而不只是像素级相似性(pixel similarity)；或者说特征空间的相似性而不是像素空间的相似性。</li><li>使用主观评估手段，更加强调人的感知。</li></ul> 
<p>模型结构如下，Generator网络是SRResNet，论文使用了16个residual blocks；Discriminator网络为8次卷积操作（4次步长为2）+2次全连接层的VGG网络。<br> <img src="https://images2.imgbox.com/65/3f/MxcBLeLR_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="14_ESRGAN_26"></a>1.4 ESRGAN</h3> 
<p>enhanced SRGAN，主要解决细节模糊和伪影问题。</p> 
<ul><li>SRResNet网络结构的改进：<br> 1）移除BN，有利于去除伪影，提升泛化能力；<br> 2）使用Residual-in-Residual Dense Block (RRDB)作为基本构建模块，更强更易训练；</li><li>GAN-based Network的损失函数的改进：使用RaGAN (Relativistic average GAN)中的相对损失函数，提升图像的相对真实性从而恢复更多的纹理细节；</li><li>感知损失函数的改进：使用VGG激活层前的特征值计算重构损失，提升了亮度的一致性和纹理恢复程度。<br> <img src="https://images2.imgbox.com/16/15/XUysUKY2_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="2__36"></a>2. 快速上手</h2> 
<h3><a id="21__37"></a>2.1 各种资源</h3> 
<p>绿色版的exe文件参见github，支持windows，linux，mac和NCNN<br> 在线版本：https://huggingface.co/spaces/akhaliq/Real-ESRGAN<br> 使用方法：./realesrgan-ncnn-vulkan.exe -i 二次元图片.jpg -o 二刺螈图片.png -n realesrgan-x4plus-anime<br> 参数如下：</p> 
<pre><code>Usage: realesrgan-ncnn-vulkan.exe -i infile -o outfile [options]...
  -h                   show this help
  -i input-path        input image path (jpg/png/webp) or directory
  -o output-path       output image path (jpg/png/webp) or directory
  -s scale             upscale ratio (can be 2, 3, 4. default=4)
  -t tile-size         tile size (&gt;=32/0=auto, default=0) can be 0,0,0 for multi-gpu
  -m model-path        folder path to the pre-trained models. default=models
  -n model-name        model name (default=realesr-animevideov3, can be realesr-animevideov3 | realesrgan-x4plus | realesrgan-x4plus-anime | realesrnet-x4plus)
  -g gpu-id            gpu device to use (default=auto) can be 0,1,2 for multi-gpu
  -j load:proc:save    thread count for load/proc/save (default=1:2:2) can be 1:2,2,2:2 for multi-gpu
  -x                   enable tta mode"
  -f format            output image format (jpg/png/webp, default=ext/png)
  -v                   verbose output
</code></pre> 
<p>目前已有的模型：<br> realesrgan-x4plus（默认）效果清晰，偏向于脑补;<br> reaesrnet-x4plus（效果模糊，偏向于涂抹）<br> realesrgan-x4plus-anime（针对动漫插画图像优化，有更小的体积）<br> realesr-animevideov3 (针对动漫视频)<br> 这个是未来的计划：<br> <img src="https://images2.imgbox.com/15/de/mXVuqxH6_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_github_65"></a>2.2 github上原代码</h3> 
<pre><code>git clone https://github.com/xinntao/Real-ESRGAN.git
cd Real-ESRGAN
# 安装 basicsr - https://github.com/xinntao/BasicSR
# 我们使用BasicSR来训练以及推断
pip install basicsr
# facexlib和gfpgan是用来增强人脸的
pip install facexlib
pip install gfpgan
pip install -r requirements.txt
python setup.py develop
wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P experiments/pretrained_models
</code></pre> 
<p>然后执行：</p> 
<pre><code>python inference_realesrgan.py -n RealESRGAN_x4plus -i inputs --face_enhance
</code></pre> 
<h3><a id="23__83"></a>2.3 训练和微调</h3> 
<p>参考https://github.com/xinntao/Real-ESRGAN/blob/master/docs/Training_CN.md<br> 微调时，可以使用程序自带的降级模型，也可以自备数据对。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3332bc90e466d1f8fe8b7576e5f83a3f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">java.lang.NoClassDefFoundError: org/gradle/api/internal/plugins/DefaultConvention</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c533ffd8ede01f97d6ad2ae4b7fb0e66/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ros仿真学习笔记_2</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>