<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Waymo object detect 2D解决方案论文拓展 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Waymo object detect 2D解决方案论文拓展" />
<meta property="og:description" content="FixMatch 半监督中的基础论文，自监督和模型一致性的代表作。
Consistency regularization: 无监督学习的方式，数据\(A\)和经过数据增强的\(A\)计做\(A&#39;\) ,同时输入模型\(f\) ，由于其种类相同(未知但相同)，所以\(f(A)=f(A&#39;)\) ，利用分布相同进行训练即可。Pseudo-labeling: 伪标签，使用人工标注数据集训练模型\(f\)，然后使用此模型去预测未标注数据集，结果使用阈值进行过滤当做未标注数据的标签。 假设存在数据集 \(D\)，有标签数据集\(D^l\) ，无标签数据集\(D^u\) ，所以\(D=\{D^l,D^u\}\) ，训练模型\(f\)，训练步骤如下：
有标签的数据直接使用交叉熵loss无标签的数据线进行前向计算得到结果计做\(Result\) ，设定阈值\(T\)，\(0 \ \ if \ softmax(Result)&gt;T \ else \ 0\) 制作一个one-hot的label，利用此label进行交叉熵loss计算在训练的初期会经常出现loss为0的情况，因为前期不稳定，无标签的置信度小于阈值这篇论文主要叙述数据增强的作用，阅读较为简单 STAC 将半监督迁移至目标检测的论文，训练步骤：
使用已标注的数据训练一个大模型\(f_{large}\)
使用这个大模型对未标注数据集进行预测，经过NMS，使用置信度阈值进行过滤，获得\(Pseudo-labeling\)
如果使用数据增强(几何变换)，需要将label进行对齐
计算loss即可
Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework Mean teachers are better role models、解读文章 2021最新的半监督目标检测，下面的论文是其中一个模块(Co-rectify)参考论文，以下给出训练步骤：
先使用标注图像训练一个大模型，未标注图像直接使用大模型生成(先进行NMS，后面置信度设置一个阈值进行过滤)使用伪标签训练模型\(f_a\) ，其中数据使用弱数据增强(RandomFlip)使用伪标签训练模型\(f_b\)，其中数据使用强数据增强(mosaic、mixup等)，模型\(f_b\)可以不等于\(f_b\)模型 \(f_a\) 和 \(f_b\) 预测的结果进行联合预测，假设模型\(f_a\)的Head网络为\(head_a\)，其他类似。例如模型输入为 \(data\) ，\(out_a = f_a(data)，out_a&#39;=f_b(data,out_a)\) 其中\(out_a\)为模型\(f_a\)的直接输出，\(out_a&#39;\)是模型\(f_b\)的Head层输出(相当于RPN的结果)。最后将两个结果进行加权平均即可。 \[\left\{\begin{aligned} \left(c_{i}, \mathbf{t}_{i}\right) &amp;=f_{a}\left(\mathbf{x}_{u}\right) \\ \left(c_{i}^{r}, \mathbf{t}_{i}^{r}\right) &amp;=f_{b}\left(\mathbf{x}_{u} ; \mathbf{t}_{i}\right), \\ c_{i}^{*} &amp;=\frac{1}{2}\left(c_{i}&#43;c_{i}^{r}\right), \\ \mathbf{t}_{i}^{*} &amp;=\frac{1}{c_{i}&#43;c_{i}^{r}}\left(\mathbf{t}_{i} c_{i}&#43;\mathbf{t}_{i}^{r} c_{i}^{r}\right) ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/c7a739ca04f9c763b5e361642cc098ec/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-06-21T20:06:00+08:00" />
<meta property="article:modified_time" content="2021-06-21T20:06:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Waymo object detect 2D解决方案论文拓展</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="cnblogs_post_body" class="blogpost-body cnblogs-markdown"> 
 <ul><li><a href="https://arxiv.org/abs/2001.07685" rel="nofollow noopener noreferrer" target="_blank">FixMatch</a></li></ul> 
 <p>半监督中的基础论文，自监督和模型一致性的代表作。</p> 
 <ol><li><strong>Consistency regularization:</strong> 无监督学习的方式，数据<span class="math inline">\(A\)</span>和经过数据增强的<span class="math inline">\(A\)</span>计做<span class="math inline">\(A'\)</span> ,同时输入模型<span class="math inline">\(f\)</span> ，由于其种类相同(未知但相同)，所以<span class="math inline">\(f(A)=f(A')\)</span> ，利用分布相同进行训练即可。</li><li><strong>Pseudo-labeling:</strong> 伪标签，使用人工标注数据集训练模型<span class="math inline">\(f\)</span>，然后使用此模型去预测未标注数据集，结果使用阈值进行过滤当做未标注数据的标签。</li></ol> 
 <p>假设存在数据集 <span class="math inline">\(D\)</span>，有标签数据集<span class="math inline">\(D^l\)</span> ，无标签数据集<span class="math inline">\(D^u\)</span> ，所以<span class="math inline">\(D=\{D^l,D^u\}\)</span> ，训练模型<span class="math inline">\(f\)</span>，训练步骤如下：</p> 
 <ol><li>有标签的数据直接使用交叉熵loss</li><li>无标签的数据线进行前向计算得到结果计做<span class="math inline">\(Result\)</span> ，设定阈值<span class="math inline">\(T\)</span>，<span class="math inline">\(0 \ \ if \ softmax(Result)&gt;T \ else \ 0\)</span> 制作一个one-hot的label，利用此label进行交叉熵loss计算</li><li>在训练的初期会经常出现loss为0的情况，因为前期不稳定，无标签的置信度小于阈值</li><li>这篇论文主要叙述数据增强的作用，阅读较为简单</li></ol> 
 <div style="text-align: center;"> 
  <img src="https://images2.imgbox.com/68/5c/E0HCJ3r5_o.png" alt="image-20210621162423662" style="outline: none;"> 
 </div> 
 <ul><li><a href="https://arxiv.org/pdf/2005.04757.pdf" rel="nofollow noopener noreferrer" target="_blank">STAC</a></li></ul> 
 <p>将半监督迁移至目标检测的论文，训练步骤：</p> 
 <ol><li> <p>使用已标注的数据训练一个大模型<span class="math inline">\(f_{large}\)</span></p> </li><li> <p>使用这个大模型对未标注数据集进行预测，经过NMS，使用置信度阈值进行过滤，获得<span class="math inline">\(Pseudo-labeling\)</span></p> </li><li> <p>如果使用数据增强(几何变换)，需要将label进行对齐</p> </li><li> <p>计算loss即可</p> </li></ol> 
 <div style="text-align: center;"> 
  <img src="https://images2.imgbox.com/93/a9/POeHyKlZ_o.png" alt="image-20210621171129866" style="outline: none;"> 
 </div> 
 <ul><li><a href="https://arxiv.org/abs/2103.11402" rel="nofollow noopener noreferrer" target="_blank">Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework</a> 
   <ul><li><a href="https://arxiv.org/pdf/1703.01780.pdf" rel="nofollow noopener noreferrer" target="_blank">Mean teachers are better role models</a>、<a href="https://blog.csdn.net/qq_44015059/article/details/106299329" target="_blank" rel="noopener noreferrer">解读文章</a></li></ul> </li></ul> 
 <p>2021最新的半监督目标检测，下面的论文是其中一个模块(<strong>Co-rectify</strong>)参考论文，以下给出训练步骤：</p> 
 <ol><li>先使用标注图像训练一个大模型，未标注图像直接使用大模型生成(先进行NMS，后面置信度设置一个阈值进行过滤)</li><li>使用伪标签训练模型<span class="math inline">\(f_a\)</span> ，其中数据使用弱数据增强(RandomFlip)</li><li>使用伪标签训练模型<span class="math inline">\(f_b\)</span>，其中数据使用强数据增强(mosaic、mixup等)，模型<span class="math inline">\(f_b\)</span>可以不等于<span class="math inline">\(f_b\)</span></li><li>模型 <span class="math inline">\(f_a\)</span> 和 <span class="math inline">\(f_b\)</span> 预测的结果进行联合预测，假设模型<span class="math inline">\(f_a\)</span>的Head网络为<span class="math inline">\(head_a\)</span>，其他类似。例如模型输入为 <span class="math inline">\(data\)</span> ，<span class="math inline">\(out_a = f_a(data)，out_a'=f_b(data,out_a)\)</span> 其中<span class="math inline">\(out_a\)</span>为模型<span class="math inline">\(f_a\)</span>的直接输出，<span class="math inline">\(out_a'\)</span>是模型<span class="math inline">\(f_b\)</span>的Head层输出(相当于RPN的结果)。最后将两个结果进行加权平均即可。</li></ol> 
 <div class="math display">
   \[\left\{\begin{aligned} \left(c_{i}, \mathbf{t}_{i}\right) &amp;=f_{a}\left(\mathbf{x}_{u}\right) \\ \left(c_{i}^{r}, \mathbf{t}_{i}^{r}\right) &amp;=f_{b}\left(\mathbf{x}_{u} ; \mathbf{t}_{i}\right), \\ c_{i}^{*} &amp;=\frac{1}{2}\left(c_{i}+c_{i}^{r}\right), \\ \mathbf{t}_{i}^{*} &amp;=\frac{1}{c_{i}+c_{i}^{r}}\left(\mathbf{t}_{i} c_{i}+\mathbf{t}_{i}^{r} c_{i}^{r}\right) . \end{aligned}\right. \] 
 </div> 
 <ol start="5"><li>loss使用下面的函数表示，监督loss和伪监督loss</li></ol> 
 <div class="math display">
   \[\begin{aligned} \ell_{u}=&amp; \sum_{u}\left[\frac{1}{N_{c l s}} \sum_{i} L_{c l s}\left(p\left(c_{i} \mid A\left(\mathbf{x}_{u}\right)\right), \hat{c}_{i}^{u}\right)\right.\\ &amp;\left.+\frac{\lambda}{N_{r e g}} \sum_{i}\left(\max \left(c_{i}^{u}\right) \geq \tau\right) L_{r e g}\left(p\left(\mathbf{t}_{i} \mid A\left(\mathbf{x}_{u}\right)\right), \mathbf{t}_{i}^{u}\right)\right] \end{aligned} \] 
 </div> 
 <div style="text-align: center;"> 
  <img src="https://images2.imgbox.com/28/e6/mgkvJ8Aq_o.png" alt="image-20210621172636677" style="outline: none;"> 
 </div> 
 <ul><li><strong>总结</strong></li></ul> 
 <p>由于看到Waymo object detect 2D比赛中有人使用此方案，所以才进行探索一下：<a href="http://arxiv.org/abs/2106.08713" rel="nofollow noopener noreferrer" target="_blank">第二名方案论文</a>。这里总结一下这个比赛的方案，关于弱监督套路一样，以上三篇论文完全代表其发展进程了。</p> 
 <ol><li>(<strong>基础</strong>)将手动标注的图像进行训练，且此模型尽量是大模型(比赛有速度和精度要求，论文使用YoloR)。<u>参赛给的训练数据集</u></li><li>(<strong>基础</strong>)将未标注的图像进行伪标注。<u>参赛给的测试集</u></li><li>(<strong>优化</strong>)anchor的选择，由于目标差异比较大(自行车和汽车两类bbox分布较为接近、自行车单独计算)，和后面模型结合起来分析</li><li>(<strong>优化</strong>)针对小目标的处理，由于数据在图像中间分布，所以裁剪之后进行放大，提高小目标的出镜率</li><li>(<strong>优化</strong>)使用TensorRT进行加速</li><li>(<strong>优化</strong>)针对困难样本(模糊等)，使用弱监督的<u>Co-rectify</u>方案，论文里面说是<code> we learn from the self-learning method which use multi-different models check with each other to automatically clean the dataset during the model training process to solve this problem and improve the model performance.</code> 也就仅仅一句话带过，这里后面进行拓展说明。</li><li>(<strong>优化</strong>)Model Ensemble，多个模型进行投票。这里采用不用模型预测不同目标的方式，YOLOR-W6预测车辆和行人，YOLOR-P6预测自行车。</li></ol> 
 <p>这里主要说明一下采用的<strong>Co-rectify</strong>方案(出自<a href="https://arxiv.org/abs/2103.11402" rel="nofollow noopener noreferrer" target="_blank">Paper</a>)，两个结构相同且参数不同的模型YOLOR-W/P，由于是单阶段网络，所以只能直接预测，而不是像原始论文使用Head分支进行。假设模型 <span class="math inline">\(f_w\)</span> 和 <span class="math inline">\(f_p\)</span> 预测的结果进行联合预测。如模型输入为 <span class="math inline">\(data\)</span> ，<span class="math inline">\(out_w = f_w(data)，out_w'=f_b(data)\)</span> 其中<span class="math inline">\(out_w\)</span>为模型<span class="math inline">\(f_a\)</span>的直接输出，<span class="math inline">\(out_w'\)</span>是模型<span class="math inline">\(f_b\)</span>的输出。直接进行加权平均，会使得模型朝着一个方向学习。如原始论文中原文：</p> 
 <pre class="has"><code class="language-shell">The key to the success of co-rectify is that the two models will not converge to the same model. We take two measures to ensure that the two models converge independently.
First, although the two models have the same structure, they use different initialization parameters. Second, although the two models share the same data in each mini-batch, their data augmentations and pseudo annotations are also different.</code></pre> 
 <p>虽然说两个模型的参数是不同的，但是此处的目的是<strong>去除模糊框</strong>，如何做到两个模型就能去除模糊框？</p> 
 <p>个人猜测是1)模糊框是少数，大量的数据训练本身就能去除这类样本。2)两个型模同时训练，会增加网络的鲁棒性，毕竟每个网络都有自己擅长的点(不同目标的检测精度不同)，联合之后各取所长吧。</p> 
 <div style="text-align: center;"> 
  <img src="https://images2.imgbox.com/76/73/A9TrVIbD_o.png" alt="image-20210621200211756" style="outline: none;"> 
 </div> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/626adbb3a0e84471ab94ef56f9d9e188/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">关于JAVA界面——商品购买的简单实现。（图片背景）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ea890c1ba1e504c96225291ec661e146/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">mac安装openjdk并配置idea</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>