<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GPU基础与CUDA编程入门 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GPU基础与CUDA编程入门" />
<meta property="og:description" content="文章目录 一、GPU和CPU的区别GPU： 高吞吐量导向设计CPU： 低延迟导向设计GPU适合什么场景:什么是Prefetch？ 二、CUDA与OpenCL三、CUDA编程并行计算整体流程内存模型线程块网格Grid：并行线程块组合线程束SIMD 四、CUDA编程实例：向量相加CUDA 编译流程![请添加图片描述](https://img-blog.csdnimg.cn/0e02eee2247c4f4b8b44bf301435fee7.png) 五. 代码实例 一、GPU和CPU的区别 GPU： 高吞吐量导向设计 缓存少： 提高内存吞吐控制简单： 没有分支预测机制和数据转发机制，但是同样存在Prefetch机制。运算单元精简： 长延时流水线来实现高吞吐量，需要大量线程来容忍延迟。适合场景： 并行计算占比多，吞吐优先，GPU单位时间执行指令数大大超过CPU CPU： 低延迟导向设计 大内存,多分级缓存。多级缓存结构提高缓存速度。控制复杂： 具备分支预测机制和流水线Prefetch机制，加速数据读取。运算单元强大： CPU对复杂的整型和浮点型的运算速度支持较好，速度快。适合场景： 连续计算部分，对时延要求高，对单条复杂指令延迟远远低于GPU GPU适合什么场景: 计算密集，当数值计算的比例远远高于内存操作时； 数据并行，当一个大任务可以拆分成若干个小任务时，因此对复杂流程控制的需求较低
什么是Prefetch？ 预取是一种内存管理策略，旨在减少内存访问延迟，从而提高计算性能。预取机制通过预先加载数据到高速缓存（例如，从全局内存到共享内存或纹理内存）来实现这一目标，以便在执行计算任务时减少等待时间。
GPU的预取机制有两种形式：
硬件预取：这是由GPU硬件自动实现的预取机制，不需要程序员进行显式操作。GPU内部的内存控制器会预测内存访问模式，提前将可能需要的数据加载到高速缓存中。这种预取机制在许多现代GPU架构（如NVIDIA的Pascal、Volta和Ampere架构）中都有实现。
软件预取：程序员可以通过编写代码显式地实现预取，以便更好地控制数据加载的过程。在CUDA编程中，可以使用__builtin_prefetch()函数来实现软件预取，该函数将根据程序员的指示将数据加载到L1或L2高速缓存中。软件预取的好处是程序员可以根据任务的特点精确地控制预取行为，从而进一步提高性能。
实际上，预取机制是一种平衡延迟和吞吐量的策略，旨在最大限度地提高GPU的计算效率。需要注意的是，预取机制在不同的GPU架构和设备上可能有所差异。因此，在优化GPU代码时，需要充分了解目标硬件的特性。
二、CUDA与OpenCL CUDA（Compute Unified Device Architecture）和OpenCL（Open Computing Language）是用于加速计算的并行计算框架。
CUDA是由英伟达公司开发的框架，支持在NVIDIA的GPU上运行。CUDA提供了一组库和工具，可让开发人员使用C、C&#43;&#43;和Fortran等编程语言来编写GPU加速的应用程序。CUDA的优点是它的性能非常高，而且支持广泛的NVIDIA GPU硬件，这使得它成为开发GPU加速应用程序的首选框架之一。
OpenCL是一个由多家公司共同开发的框架，可以在支持OpenCL的GPU、CPU和其他处理器上运行。OpenCL的优点是它是一个跨平台的框架，这意味着可以在不同的硬件和操作系统上运行。OpenCL还支持多种编程语言，包括C、C&#43;&#43;、Java和Python等。
虽然CUDA和OpenCL都是用于加速计算的框架，但它们有一些不同之处。CUDA主要用于NVIDIA GPU上的计算，而OpenCL则可以在不同的硬件上运行。此外，CUDA的编程模型比较简单，而OpenCL则更加灵活。选择哪种框架取决于具体的应用场景和硬件设备。
三、CUDA编程并行计算整体流程 假设有这么一个GPU Kernel Function:
void GPUKernel(float *A,float *B,float *C,int n){} 其流程可以分为下面几个步骤: 1. Allocate GPU memory for A and B and C. 2. Copy A, B to GPU memory." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7fc2c5c186c67eb15610dbf59c7be92c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-25T21:11:47+08:00" />
<meta property="article:modified_time" content="2023-07-25T21:11:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GPU基础与CUDA编程入门</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#GPUCPU_4" rel="nofollow">一、GPU和CPU的区别</a></li><li><ul><li><a href="#GPU__5" rel="nofollow">GPU： 高吞吐量导向设计</a></li><li><a href="#CPU__10" rel="nofollow">CPU： 低延迟导向设计</a></li><li><a href="#GPU_15" rel="nofollow">GPU适合什么场景:</a></li><li><a href="#Prefetch_17" rel="nofollow">什么是Prefetch？</a></li></ul> 
  </li><li><a href="#CUDAOpenCL_27" rel="nofollow">二、CUDA与OpenCL</a></li><li><a href="#CUDA_38" rel="nofollow">三、CUDA编程并行计算整体流程</a></li><li><ul><li><a href="#_49" rel="nofollow">内存模型</a></li><li><a href="#_56" rel="nofollow">线程块</a></li><li><a href="#Grid_59" rel="nofollow">网格Grid：并行线程块组合</a></li><li><a href="#_70" rel="nofollow">线程束</a></li><li><a href="#SIMD_82" rel="nofollow">SIMD</a></li></ul> 
  </li><li><a href="#CUDA_85" rel="nofollow">四、CUDA编程实例：向量相加</a></li><li><ul><li><a href="#CUDA_httpsimgblogcsdnimgcn0e02eee2247c4f4b8b44bf301435fee7png_170" rel="nofollow">CUDA 编译流程![请添加图片描述](https://img-blog.csdnimg.cn/0e02eee2247c4f4b8b44bf301435fee7.png)</a></li></ul> 
  </li><li><a href="#__171" rel="nofollow">五. 代码实例</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="GPUCPU_4"></a>一、GPU和CPU的区别</h2> 
<h3><a id="GPU__5"></a>GPU： 高吞吐量导向设计</h3> 
<ol><li>缓存少： 提高内存吞吐</li><li>控制简单： 没有分支预测机制和数据转发机制，但是同样存在Prefetch机制。</li><li>运算单元精简： 长延时流水线来实现高吞吐量，需要大量线程来容忍延迟。</li><li>适合场景： 并行计算占比多，吞吐优先，GPU单位时间执行指令数大大超过CPU</li></ol> 
<h3><a id="CPU__10"></a>CPU： 低延迟导向设计</h3> 
<ol><li>大内存,多分级缓存。多级缓存结构提高缓存速度。</li><li>控制复杂： 具备分支预测机制和流水线Prefetch机制，加速数据读取。</li><li>运算单元强大： CPU对复杂的整型和浮点型的运算速度支持较好，速度快。</li><li>适合场景： 连续计算部分，对时延要求高，对单条复杂指令延迟远远低于GPU</li></ol> 
<h3><a id="GPU_15"></a>GPU适合什么场景:</h3> 
<p>计算密集，当数值计算的比例远远高于内存操作时； 数据并行，当一个大任务可以拆分成若干个小任务时，因此对复杂流程控制的需求较低</p> 
<h3><a id="Prefetch_17"></a>什么是Prefetch？</h3> 
<p>预取是一种内存管理策略，旨在减少内存访问延迟，从而提高计算性能。预取机制通过预先加载数据到高速缓存（例如，从全局内存到共享内存或纹理内存）来实现这一目标，以便在执行计算任务时减少等待时间。</p> 
<p>GPU的预取机制有两种形式：</p> 
<ol><li> <p>硬件预取：这是由GPU硬件自动实现的预取机制，不需要程序员进行显式操作。GPU内部的内存控制器会预测内存访问模式，提前将可能需要的数据加载到高速缓存中。这种预取机制在许多现代GPU架构（如NVIDIA的Pascal、Volta和Ampere架构）中都有实现。</p> </li><li> <p>软件预取：程序员可以通过编写代码显式地实现预取，以便更好地控制数据加载的过程。在CUDA编程中，可以使用__builtin_prefetch()函数来实现软件预取，该函数将根据程序员的指示将数据加载到L1或L2高速缓存中。软件预取的好处是程序员可以根据任务的特点精确地控制预取行为，从而进一步提高性能。</p> </li></ol> 
<p>实际上，预取机制是一种平衡延迟和吞吐量的策略，旨在最大限度地提高GPU的计算效率。需要注意的是，预取机制在不同的GPU架构和设备上可能有所差异。因此，在优化GPU代码时，需要充分了解目标硬件的特性。</p> 
<h2><a id="CUDAOpenCL_27"></a>二、CUDA与OpenCL</h2> 
<p>CUDA（Compute Unified Device Architecture）和OpenCL（Open Computing Language）是用于加速计算的并行计算框架。</p> 
<p>CUDA是由英伟达公司开发的框架，支持在NVIDIA的GPU上运行。CUDA提供了一组库和工具，可让开发人员使用C、C++和Fortran等编程语言来编写GPU加速的应用程序。CUDA的优点是它的性能非常高，而且支持广泛的NVIDIA GPU硬件，这使得它成为开发GPU加速应用程序的首选框架之一。</p> 
<p>OpenCL是一个由多家公司共同开发的框架，可以在支持OpenCL的GPU、CPU和其他处理器上运行。OpenCL的优点是它是一个跨平台的框架，这意味着可以在不同的硬件和操作系统上运行。OpenCL还支持多种编程语言，包括C、C++、Java和Python等。</p> 
<p>虽然CUDA和OpenCL都是用于加速计算的框架，但它们有一些不同之处。CUDA主要用于NVIDIA GPU上的计算，而OpenCL则可以在不同的硬件上运行。此外，CUDA的编程模型比较简单，而OpenCL则更加灵活。选择哪种框架取决于具体的应用场景和硬件设备。</p> 
<h2><a id="CUDA_38"></a>三、CUDA编程并行计算整体流程</h2> 
<p>假设有这么一个GPU Kernel Function:</p> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token function">GPUKernel</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span><span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span><span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span><span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
其流程可以分为下面几个步骤<span class="token operator">:</span>
<span class="token number">1.</span> Allocate GPU memory <span class="token keyword">for</span> A <span class="token operator">and</span> B <span class="token operator">and</span> C<span class="token punctuation">.</span>
<span class="token number">2.</span> Copy A<span class="token punctuation">,</span> B to GPU memory<span class="token punctuation">.</span>
<span class="token number">3.</span> Run GPUKernel Function to have the GPU perform the actual vector <span class="token keyword">operator</span><span class="token punctuation">.</span>
<span class="token number">4.</span> Copy C from GPU to CPU<span class="token punctuation">.</span>
</code></pre> 
<h3><a id="_49"></a>内存模型</h3> 
<p>内存模型是CUDA编程中的核心。其内存模型可以分为如下几个层次：</p> 
<ol><li>每一个线程处理器SP都拥有自己的寄存器。</li><li>每一个线程处理器SP都有自己的Local Memory, 且Register和Local Memory只能被该线程进行访问。</li><li>每一个多核处理器(SM)内部都有自己的shared memory, shared memory 可以被线程块内部所有线程访问。</li><li>所有SM共有一块Global Shared Memory,可以被不同核的不同线程块的所有线程进行访问<br> <img src="https://images2.imgbox.com/bf/f7/EPLkZQRu_o.png" alt="请添加图片描述"></li></ol> 
<h3><a id="_56"></a>线程块</h3> 
<p>线程块是将线程数组分成多个块的结构。块内的线程通过共享内存，原子操作和屏障同步进行同步和协作。不同块中的线程不能进行协作。如下图，一个线程使用256个线程进行向量相加，最终将结果进行同步<br> <img src="https://images2.imgbox.com/ed/b8/2x9bvIDR_o.png" alt="请添加图片描述"></p> 
<h3><a id="Grid_59"></a>网格Grid：并行线程块组合</h3> 
<p>每一个线程块中的每一个线程都有一个索引，用于计算内存地址和做出控制决策<br> <img src="https://images2.imgbox.com/ee/b1/KqLWYxb2_o.png" alt="请添加图片描述"><br> 我们使用线程块Block ID和线程Thread ID来定位每一个独立线程：<br> <img src="https://images2.imgbox.com/84/5f/cjJpaCaG_o.png" alt="请添加图片描述"><br> 线程ID计算公式：</p> 
<p><img src="https://images2.imgbox.com/76/09/YeO6Qwiw_o.png" alt="请添加图片描述"></p> 
<h3><a id="_70"></a>线程束</h3> 
<p>线程束（warp）是 GPU 中执行并行计算任务的基本单元，它由一组线程组成，可以同时执行相同的指令序列。在软件端，程序员将并行计算任务编写成 CUDA 或 OpenCL 的代码，并将代码编译成适合 GPU 的指令集。</p> 
<p>在硬件端，GPU 的计算单元可以同时执行大量的线程束，每个线程束中包含了一定数量的线程。当计算单元收到一个指令序列时，它会同时启动多个线程束来执行这个指令序列。每个线程束中的线程都会同时执行相同的指令，但是对于每个线程的输入数据和输出结果是不同的。</p> 
<p>为了高效地执行线程束，GPU 通常采用SIMD（Single Instruction Multiple Data）架构。这种架构允许计算单元同时执行多个相同的指令，但是每个指令所操作的数据可以不同。因此，在执行一个线程束时，GPU 可以高效地利用 SIMD 架构，同时处理多个线程的计算任务。</p> 
<p>在具体实现上，GPU 的控制单元将计算任务分配给计算单元，并为每个线程分配一些资源，例如寄存器、共享内存和常量内存等。然后，计算单元会同时启动多个线程束来执行指令序列。在执行过程中，GPU 可以动态地调整线程束的数量和分配的资源，以最大化并行计算的效率。</p> 
<p>总的来说，线程束是 GPU 中执行并行计算任务的基本单元，它由一组线程组成，可以同时执行相同的指令序列。在软件端，程序员编写并行计算任务的代码，并将其编译成适合 GPU 的指令集。在硬件端，GPU 的计算单元可以同时执行大量的线程束，通过 SIMD 架构来高效地执行计算任务。</p> 
<p><img src="https://images2.imgbox.com/e9/d5/w4EU2I2p_o.png" alt="请添加图片描述"></p> 
<h3><a id="SIMD_82"></a>SIMD</h3> 
<p>在GPU中，SIMD是一种重要的线程分配策略。 当一个Kernel 函数被执行的时候，Grid中的线程块被分配到SM上。注意，一个SM可以调度多个线程块，但是同一个线程块内的所有线程只能在一个SM上。<br> 每一个Thread拥有自己的程序计数器和状态寄存器，并且使用线程自带的数据执行同一个指令。这就被称作SIMD： Single Instruction Multi Data. SIMT的设计也是线程束是执行核函数最基本单元的原因。</p> 
<h2><a id="CUDA_85"></a>四、CUDA编程实例：向量相加</h2> 
<p>现在假设我们希望通过并行计算完成下列函数：<br> <img src="https://images2.imgbox.com/b0/a5/s8Cdn82e_o.png" alt="请添加图片描述"><br> 可以看到这个函数访问内存少，控制简单，计算简单，并行度高，所以适合在GPU上运算<br> 在GPU侧，需要完成的功能是：</p> 
<ol><li>读写线程寄存器</li><li>读写Grid中全局内存</li><li>读写Block中共享内存<br> 在CPU侧，需要完成的功能是：</li><li>Grid中全局内存拷贝转移</li></ol> 
<p>需要涉及到的函数有：</p> 
<ol><li>cudaMalloc( )<br> • cudaError_t cudaMalloc (void **devPtr, size_t size)<br> • 在设备全局内存中分配对象<br> • 两个参数<br> • 地址<br> • 申请内存大小</li><li>cudaFree( )<br> • cudaError_t cudaFree ( void* devPtr ) • 从设备全局内存中释放对象<br> • 指向释放对象的指针</li><li>cudaMemcpy( )<br> • cudaError_t cudaMemcpy (void *dst, const void *src, size_t count, cudaMemcpyKind kind)<br> • 内存数据复制传递<br> • 目前支持的四种选项<br> • cudaMemcpyHostToDevice<br> • cudaMemcpyDeviceToHost<br> • cudaMemcpyDeviceToDevice<br> • cudaMemcpyDefault<br> • 调用cudaMemcpy( )传输内存是同步的</li></ol> 
<p>首先，我们可以先给出一个代码框架，写好除了kernel function以外的所有东西，随后再写kernel function</p> 
<pre><code class="prism language-cpp"><span class="token keyword">void</span> <span class="token function">vecAdd</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> A<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> B<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> C<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
<span class="token keyword">int</span> size <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token keyword">float</span><span class="token operator">*</span> A_d<span class="token punctuation">,</span> <span class="token operator">*</span>B_d<span class="token punctuation">,</span> <span class="token operator">*</span>C_d<span class="token punctuation">;</span> 
<span class="token number">1.</span> <span class="token comment">// Transfer A and B to device memory </span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>A_d<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>A_d<span class="token punctuation">,</span> A<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>B_d<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>B_d<span class="token punctuation">,</span> B<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// Allocate device memory for</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span>C_d<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token number">2.</span> <span class="token comment">// Kernel invocation code – to be shown later</span>
… 
<span class="token number">3.</span> <span class="token comment">// Transfer C from device to host</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>C<span class="token punctuation">,</span> C_d<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// Free device memory for A, B, C</span>
<span class="token function">cudaFree</span><span class="token punctuation">(</span>A_d<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">cudaFree</span><span class="token punctuation">(</span>B_d<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token function">cudaFree</span> <span class="token punctuation">(</span>C_d<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>核函数调用<br> • 在GPU上执行的函数。<br> • 一般通过标识符__global__修饰。 • 调用通过&lt;&lt;&lt;参数1,参数2&gt;&gt;&gt;，用于说明内核函数中的线程数量，以及线程是如何组织的。<br> • 以网格（Grid）的形式组织，每个线程格由若干个线程块（block）组成，而每个线程块又由若干个线程（thread）组成。<br> • 调用时必须声明内核函数的执行参数。<br> • 在编程时，必须先为kernel函数中用到的数组或变量分配好足够的空间，再调用kernel函数，否则在GPU计算时会发生错误。</p> 
<p>在CUDA编程中的标识符有这些：<br> <img src="https://images2.imgbox.com/da/0f/KZL4vNnx_o.png" alt="请添加图片描述"></p> 
<pre><code class="prism language-cpp"><span class="token comment">/*
Device Code 
*/</span>
__global__
<span class="token keyword">void</span> <span class="token function">vecAddKernel</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> A_d<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> B_d<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> C_d<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
<span class="token keyword">int</span> i <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">)</span> C_d<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A_d<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B_d<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">/*
HostCode 
*/</span>
<span class="token keyword">int</span> <span class="token function">vectAdd</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> A<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> B<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> C<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span>
<span class="token punctuation">{<!-- --></span>
<span class="token comment">// A_d, B_d, C_d allocations and copies omitted</span>
<span class="token comment">// Run ceil(n/256) blocks, each thread block has 256 threads which has 8 thread warps   </span>
vecAddKernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token function">ceil</span><span class="token punctuation">(</span>n<span class="token operator">/</span><span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>A_d<span class="token punctuation">,</span> B_d<span class="token punctuation">,</span> C_d<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<h3><a id="CUDA_httpsimgblogcsdnimgcn0e02eee2247c4f4b8b44bf301435fee7png_170"></a>CUDA 编译流程<img src="https://images2.imgbox.com/05/09/C4FfPPeM_o.png" alt="请添加图片描述"></h3> 
<h2><a id="__171"></a>五. 代码实例</h2> 
<p>在CPU上计算向量相加：</p> 
<pre><code class="prism language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span><span class="token string">&lt;bits/stdc++.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;sys/time.h&gt;</span></span>

<span class="token keyword">using</span> <span class="token keyword">namespace</span> std<span class="token punctuation">;</span>
<span class="token keyword">void</span> <span class="token function">vecAdd</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span><span class="token keyword">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
  <span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token function">atoi</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  cout<span class="token operator">&lt;&lt;</span>n<span class="token operator">&lt;&lt;</span>endl<span class="token punctuation">;</span>
  size_t size <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>a <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>b <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>c <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">float</span> af <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token keyword">double</span><span class="token punctuation">(</span>RAND_MAX<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">float</span> bf <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token keyword">double</span><span class="token punctuation">(</span>RAND_MAX<span class="token punctuation">)</span><span class="token punctuation">;</span>
    a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>af<span class="token punctuation">;</span>
    b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>bf<span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">struct</span> <span class="token class-name">timeval</span> t1<span class="token punctuation">,</span>t2<span class="token punctuation">;</span>
  <span class="token function">gettimeofday</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>t1<span class="token punctuation">,</span><span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">vecAdd</span><span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">,</span>c<span class="token punctuation">,</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">gettimeofday</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>t2<span class="token punctuation">,</span><span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">double</span> timeuse <span class="token operator">=</span> t2<span class="token punctuation">.</span>tv_sec <span class="token operator">-</span> t1<span class="token punctuation">.</span>tv_sec <span class="token operator">+</span> <span class="token punctuation">(</span>t2<span class="token punctuation">.</span>tv_usec <span class="token operator">-</span> t1<span class="token punctuation">.</span>tv_usec<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">1000000.0</span><span class="token punctuation">;</span>
  cout<span class="token operator">&lt;&lt;</span><span class="token string">"timeuse: "</span><span class="token operator">&lt;&lt;</span>timeuse<span class="token operator">&lt;&lt;</span>endl<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>在GPU上计算向量相加：</p> 
<pre><code class="prism language-cpp"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span><span class="token string">&lt;bits/stdc++.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span><span class="token string">&lt;sys/time.h&gt;</span></span>
<span class="token keyword">using</span> <span class="token keyword">namespace</span> std<span class="token punctuation">;</span>

__global__ 
<span class="token keyword">void</span> <span class="token function">vecAddKernel</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>A<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>C<span class="token punctuation">,</span> <span class="token keyword">int</span> n<span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">int</span> i <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span> 
    <span class="token keyword">if</span><span class="token punctuation">(</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">)</span> C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span> 
<span class="token punctuation">}</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span><span class="token keyword">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
  <span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token function">atoi</span><span class="token punctuation">(</span>argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  cout<span class="token operator">&lt;&lt;</span>n<span class="token operator">&lt;&lt;</span>endl<span class="token punctuation">;</span>
  size_t size <span class="token operator">=</span> n <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>a <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>b <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>c <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>

  <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span>i<span class="token operator">&lt;</span>n<span class="token punctuation">;</span>i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
    <span class="token keyword">float</span> af <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token keyword">double</span><span class="token punctuation">(</span>RAND_MAX<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">float</span> bf <span class="token operator">=</span> <span class="token function">rand</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token keyword">double</span><span class="token punctuation">(</span>RAND_MAX<span class="token punctuation">)</span><span class="token punctuation">;</span>
    a<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>af<span class="token punctuation">;</span>
    b<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token operator">=</span>bf<span class="token punctuation">;</span>
  <span class="token punctuation">}</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>da <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>db <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
  <span class="token keyword">float</span> <span class="token operator">*</span>dc <span class="token operator">=</span> <span class="token constant">NULL</span><span class="token punctuation">;</span>
  <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>da<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>db<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>dc<span class="token punctuation">,</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span> 
  <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>da<span class="token punctuation">,</span>a<span class="token punctuation">,</span>size<span class="token punctuation">,</span>cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>db<span class="token punctuation">,</span>b<span class="token punctuation">,</span>size<span class="token punctuation">,</span>cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>dc<span class="token punctuation">,</span>c<span class="token punctuation">,</span>size<span class="token punctuation">,</span>cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">int</span> threadsPerBlock <span class="token operator">=</span> <span class="token number">256</span><span class="token punctuation">;</span>
  <span class="token keyword">int</span> blockPerGrid <span class="token operator">=</span> <span class="token punctuation">(</span>n <span class="token operator">+</span> threadsPerBlock <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> threadsPerBlock<span class="token punctuation">;</span>
  <span class="token keyword">struct</span> <span class="token class-name">timeval</span> t1<span class="token punctuation">,</span>t2<span class="token punctuation">;</span>
  <span class="token function">gettimeofday</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>t1<span class="token punctuation">,</span><span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  vecAddKernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>blockPerGrid<span class="token punctuation">,</span>threadsPerBlock<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>da<span class="token punctuation">,</span>db<span class="token punctuation">,</span>dc<span class="token punctuation">,</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>c<span class="token punctuation">,</span>dc<span class="token punctuation">,</span>size<span class="token punctuation">,</span>cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">gettimeofday</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>t2<span class="token punctuation">,</span><span class="token constant">NULL</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token keyword">double</span> timeuse <span class="token operator">=</span> t2<span class="token punctuation">.</span>tv_sec <span class="token operator">-</span> t1<span class="token punctuation">.</span>tv_sec <span class="token operator">+</span> <span class="token punctuation">(</span>t2<span class="token punctuation">.</span>tv_usec <span class="token operator">-</span> t1<span class="token punctuation">.</span>tv_usec<span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">1000000.0</span><span class="token punctuation">;</span>
  cout<span class="token operator">&lt;&lt;</span><span class="token string">"timeuse: "</span><span class="token operator">&lt;&lt;</span>timeuse<span class="token operator">&lt;&lt;</span>endl<span class="token punctuation">;</span>
  <span class="token function">cudaFree</span><span class="token punctuation">(</span>da<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaFree</span><span class="token punctuation">(</span>db<span class="token punctuation">)</span><span class="token punctuation">;</span>
  <span class="token function">cudaFree</span><span class="token punctuation">(</span>dc<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span> 
</code></pre> 
<hr>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ecd8d1cdfc56a181c0b28c17463065f4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">docker容器引擎（四）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e1f139950a50f94c2332c3f028e5bea3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">TypeError: can‘t convert np.ndarray of type numpy.object_.The only supported types are: 报错解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>