<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【渐进交互学习网络：轻量级：超分：工业应用】 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【渐进交互学习网络：轻量级：超分：工业应用】" />
<meta property="og:description" content="Progressive Interaction-Learning Network for Lightweight Single-Image Super-Resolution in Industrial Applications （工业应用中轻量级单幅图像超分辨率渐进交互学习网络）
近年来，基于深度学习（DL）的工业应用因其先进的性能而受到广泛关注。然而，便携式设备中有限的计算资源总是使得大DL模型不适用于工业。基于DL的单幅图像超分辨率算法由于计算量大也会遇到这个问题。此外，大多数基于卷积神经网络的轻量级方法对特征的利用不足，限制了其工业重构的能力。为了缓解这一问题，我们提出了一个进程交互学习网络（PILN），以细化不同层次的特征：在全局层次上，我们采用渐进式交互学习策略来整合时间和空间维度上的层次特征;在中间层，增强交互学习单元采用增强交互学习，显著提高重构性能;在局部层面上，采用逐像素学习，提出残差单元以通过权重分布来搜索最优信息流。大量的实验表明，PILN算法优于现有的其他算法。
介绍 随着机器学习/深度学习（DL）的不断兴起，提出了广泛的基于机器学习/DL的工业应用，以在相应任务中实现更好的性能。单幅图像超分辨率（SISR）技术在监控系统、遥感、机械制造和物联网（IoT）等众多工业应用中发挥着重要作用，近年来DL大力推广。然而，大多数基于DL的SISR方法需要大量的存储和计算，这是许多工业系统所不能承受的。例如，具有高速和多个时间敏感操作要求的物联网工业应用广泛地通过小规模平台实现。因此，轻量级SISR神经网络的设计对于工业应用具有重要意义，这也是本文的研究目的。SISR是一种低层次视觉任务，旨在从低分辨率（LR）图像重建高分辨率（HR）图像。多幅HR图像可以退化为一幅LR图像，这是一个不适定问题，引起了广泛的关注。因此，研究人员提出了多种高质量图像超分辨率（SR）的方法，其中深度卷积神经网络（CNN）因其优越的性能而备受关注。为了使基于神经网络的方法能够应用于工业应用，一些轻量化方法不断被提出。为了高效地重建图像，Fu等人尝试通过多尺度知识转移来构建适合物联网（IoT）应用的轻量级结构。
虽然轻量级网络在实际应用中取得了优异的性能，但在工业应用场景中仍然受到各种限制。特别是在充分利用特征方面，直观效果主要体现在以下两个方面。
1）大多数特征提取策略只关注单个层次，而忽略了层次特征之间的相关性。例如，残差学习强调全局特征但忽略局部细节；密集连接策略扩大了不同模块之间的空间相关性，但忽略了时间关系。
2）现有的信息流策略对特征的利用效率较低，影响了精确表示的能力.以权重贡献策略为例，空间关注度（SA）只关注空间特征，而忽略了其他有效信息（如：通道或像素细节）。
为了解决轻量级SISR神经网络中的上述问题，提出了一种渐进交互学习网络（PILN）来聚合不同层次的特征。一方面，我们在不同的层次上实施不同的特征细化策略（例如，全局、中间和局部）以促进分层特征融合。具体而言，PILN通过全局的渐进交互学习策略（PILS）、中间的增强交互学习（EIS）和局部的逐像素学习（PWL）有效地提高了重建能力。另一方面，我们设计了残差单元（R-Cells）和特征提取单元（FEU）来构造增强的交互学习单元（EILUs），该交互学习单元在时间和空间两个方向上聚合特征。通过使用精细的块来形成PILN，最大限度地利用了多维特征，在保持轻量级的同时获得了相似的重建结果，增加了PILN在工业应用中的实用性。
贡献 1）我们提出了一种有效的用于SISR的PILN，它在不同的层次上细化时空特征，即：局部、中间和全局。实验结果表明，该算法在保持较少资源消耗的同时，性能优于其他SOTA算法。
2）在全局层面上，我们采用PILS来收集时间和空间方向上的特征。利用PILS，层次信息可以在多维空间中交互聚合，保证了特征的充分利用。
3）在中间层，利用EIS，多个EILU通过有效的特征聚合优化信息流。在EIS的辅助下，EILUs在SR任务中表现出了强大的表征能力。
4）在局部层次上，我们设计R-Cells和FEU以形成EILU，EILU在像素级聚合特征。实验结果表明，PILN通过自适应地对R-Cells进行权值贡献，并用FEU聚集RCells，提高了图像重建性能。
相关工作 CNN-Based Image SR 近年来，基于神经网络的结构使SR性能得到了迅速发展，并取得了优异的性能，作为先驱，超分辨率卷积神经网络（SRCNN）成功地将插值LR图像映射到具有浅三层结构的HR副本。之后，大量的方法试图通过使用不同的学习策略来深化它们的模型以提高重构性能：1)残差学习，用于缓解梯度消失问题的有效训练方法；2)密集连接策略，充分挖掘不同层次特征之间的相关性，实现强大的特征表；;3）递归学习，例如超分辨率反馈网络（SRFBN），使用深度SRFBN通过提取时间信息来提高表示能力；4）注意机制，例如，渠道关注（CA）和SA，以促进信息流动；以及5）在深度维度或时间维度上展开网络以提高重建性能。然而，现有的基于神经网络的模型参数较多，资源消耗大，不适合实际应用。
为了减少参数，已经提出了多个紧凑且有效的神经网络来释放用于匹配移动的设备的计算成本。适度信息蒸馏网络（IDN）使用基于状态的递归结构，旨在缓解参数问题，同时保持高质量的重建。同时Hui等人通过多重蒸馏发展了信息多重蒸馏网络，称之为信息多重蒸馏网络（IMDN）。然而，上述轻量级结构忽略了层次特征的使用，导致了不满意的结果。为了获得高质量的重建结果，有学者提出了性能和计算量之间的最佳折衷方案。受上述方法的启发，我们设计了基于渐进学习（PL）的研究，以构建一个有效的网络用于层次多维特征提取。
Attention Mechanism CA注重通道的特征细化，在许多计算视觉任务中取得了优异的性能。Zhang等人将CA机制集成到SISR的残余信道注意网络中。然后，由几个二阶信道注意力组成，提出了一个二阶注意力网络，以从一个新的角度执行权重分配。虽然CA已经取得了显著的进步，但由于信息利用的不足，CA仍有其局限性。另一方面，SA的目标是在空间维度上对特征进行加权，从而帮助网络找到一个高效、可信的模型。例如，SPP-Net 使用空间金字塔池（SPP）策略来提高图像表示的质量。在SA的指导下，SPP-Net产生了固定长度的结果，并进一步应用于分类和检测任务。之后，SA的应用场景更加通用，例如：自我注意生成对抗网络在生成对抗网络上进行空间特征细化。尽管单维注意机制有了很大的改进，但仍不能适应工业应用的发展。为了充分利用不同维度的信息，Zhao等人通过混合注意策略来提高其表征能力。基于这种思路，我们提出了一种自适应学习注意机制R-Cell，它可以集中学习通道权重和空间权重，以获得更强大的SR。
方法 Global Level: PILS Description ofthe Backbone Network: 在图2中，PILN是一种轻质高效的结构，具有几个合理排列的块。主干由三个EILUs组成（即，EILU-S、EILU-M和EILU-D）进行精细特征提取（参见图3）。
然后，网络的输入和输出分别用ILR和ISR表示。该公式可说明如下：
其中HLFE(·)、HPIL(·)和HHFE(·)分别表示低级特征提取、渐进式交互学习和高级特征提取的操作。符号Iup是ILR的上采样结果，并且“&#43;”表示残差学习。为了更清楚地解释特征提取，我们逐步表示PILN。对于输入的ILR，通过低层特征提取HLFE(·)，可以获得浅层特征FSF。
然后，可以通过HPIL(·)的操作来细化FSF，HPIL(·)在全局层面采用PILS
为了更好地适应阶段学习，我们对改进的FPIL进行高层特征提取，并获得融合信息FHF
其中HHFE(·)表示高级特征提取的函数。最后，通过在放大的ILR和FHF之间进行残差学习，可以通过下式形成高质量画面ISR：
其中，函数Hup(·)为上采样，用于将LR插值为HR的大小。
Description ofthe PILS: 如图2所示，所提出的模型可分为三个层次：全局、中间和局部。PILS（图3）主要用于全局水平，以进行精确的图像重建。此外， E j E^j Eji是在第j阶段从第i个EILU提取的纯特征。总体PL可描述如下。
Stage 1 self-study (T = 1): EILUS的主要任务是对浅层特征进行预处理，获得中间信息 E 1 E^1 E11，提高图像重建质量
其中ΦEILUS(·)表示浅层特征的细化，FSF表示初始信息。
Stage 2mutual study (T = 2): 当T= 2时，我们深入地集成了一个全新的功能块EILU-M。首先，我们在EILU-S中对先前的输出 E 1 E^1 E11使用自学习，这可以被视为自学习。然后，EILU-M将特征(即： E 1 E^1 E11和FSF），结合层次特征和时间相关特征，通过以下步骤完成不同模块间的交互学习" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/bbcfda91a1420a15879066077cb305e7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-25T09:21:41+08:00" />
<meta property="article:modified_time" content="2023-04-25T09:21:41+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【渐进交互学习网络：轻量级：超分：工业应用】</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Progressive_InteractionLearning_Network_for_Lightweight_SingleImage_SuperResolution_in_Industrial_Applications_0"></a>Progressive Interaction-Learning Network for Lightweight Single-Image Super-Resolution in Industrial Applications</h3> 
<p><em>（工业应用中轻量级单幅图像超分辨率渐进交互学习网络）</em></p> 
<p>近年来，基于深度学习（DL）的工业应用因其先进的性能而受到广泛关注。然而，便携式设备中有限的计算资源总是使得大DL模型不适用于工业。基于DL的单幅图像超分辨率算法由于计算量大也会遇到这个问题。此外，大多数基于卷积神经网络的轻量级方法对特征的利用不足，限制了其工业重构的能力。为了缓解这一问题，我们提出了一个<strong>进程交互学习网络（PILN）</strong>，以细化不同层次的特征：在全局层次上，我们采用<strong>渐进式交互学习策略</strong>来整合时间和空间维度上的层次特征;在中间层，增强交互学习单元采用<strong>增强交互学习</strong>，显著提高重构性能;在局部层面上，采用<strong>逐像素学习</strong>，<strong>提出残差单元</strong>以通过权重分布来搜索最优信息流。大量的实验表明，PILN算法优于现有的其他算法。</p> 
<h4><a id="_4"></a>介绍</h4> 
<p>随着机器学习/深度学习（DL）的不断兴起，提出了广泛的基于机器学习/DL的工业应用，以在相应任务中实现更好的性能。单幅图像超分辨率（SISR）技术在监控系统、遥感、机械制造和物联网（IoT）等众多工业应用中发挥着重要作用，近年来DL大力推广。然而，大多数基于DL的SISR方法需要大量的存储和计算，这是许多工业系统所不能承受的。例如，具有高速和多个时间敏感操作要求的物联网工业应用广泛地通过小规模平台实现。因此，轻量级SISR神经网络的设计对于工业应用具有重要意义，这也是本文的研究目的。SISR是一种低层次视觉任务，旨在从低分辨率（LR）图像重建高分辨率（HR）图像。多幅HR图像可以退化为一幅LR图像，这是一个不适定问题，引起了广泛的关注。因此，研究人员提出了多种高质量图像超分辨率（SR）的方法，其中深度卷积神经网络（CNN）因其优越的性能而备受关注。为了使基于神经网络的方法能够应用于工业应用，一些轻量化方法不断被提出。为了高效地重建图像，Fu等人尝试通过多尺度知识转移来构建适合物联网（IoT）应用的轻量级结构。<br> 虽然轻量级网络在实际应用中取得了优异的性能，但在工业应用场景中仍然受到各种限制。特别是在充分利用特征方面，直观效果主要体现在以下两个方面。<br> 1）大多数特征提取策略<strong>只关注单个层次，而忽略了层次特征之间的相关性</strong>。例如，残差学习强调全局特征但忽略局部细节；密集连接策略扩大了不同模块之间的空间相关性，但忽略了时间关系。<br> 2）现有的信息流策略对特征的利用效率较低，影响了精确表示的能力.以权重贡献策略为例，空间关注度（SA）只关注空间特征，而忽略了其他有效信息（如：通道或像素细节）。<br> 为了解决轻量级SISR神经网络中的上述问题，提出了一种渐进交互学习网络（PILN）来聚合不同层次的特征。一方面，我们在<strong>不同的层次上实施不同的特征细化策略</strong>（例如，全局、中间和局部）以促进分层特征融合。具体而言，PILN通过全局的渐进交互学习策略（PILS）、中间的增强交互学习（EIS）和局部的逐像素学习（PWL）有效地提高了重建能力。另一方面，我们设计了残差单元（R-Cells）和特征提取单元（FEU）来构造增强的交互学习单元（EILUs），该交互学习单元在时间和空间两个方向上聚合特征。通过使用精细的块来形成PILN，最大限度地利用了多维特征，在保持轻量级的同时获得了相似的重建结果，增加了PILN在工业应用中的实用性。</p> 
<h5><a id="_10"></a>贡献</h5> 
<p>1）我们提出了一种有效的用于SISR的PILN，它在不同的层次上细化时空特征，即：局部、中间和全局。实验结果表明，该算法在保持较少资源消耗的同时，性能优于其他SOTA算法。<br> 2）在全局层面上，我们采用PILS来收集时间和空间方向上的特征。利用PILS，层次信息可以在多维空间中交互聚合，保证了特征的充分利用。<br> 3）在中间层，利用EIS，多个EILU通过有效的特征聚合优化信息流。在EIS的辅助下，EILUs在SR任务中表现出了强大的表征能力。<br> 4）在局部层次上，我们设计R-Cells和FEU以形成EILU，EILU在像素级聚合特征。实验结果表明，PILN通过自适应地对R-Cells进行权值贡献，并用FEU聚集RCells，提高了图像重建性能。</p> 
<h4><a id="_15"></a>相关工作</h4> 
<h5><a id="CNNBased_Image_SR_16"></a>CNN-Based Image SR</h5> 
<p>近年来，基于神经网络的结构使SR性能得到了迅速发展，并取得了优异的性能，作为先驱，超分辨率卷积神经网络（SRCNN）成功地将插值LR图像映射到具有浅三层结构的HR副本。之后，大量的方法试图通过使用不同的学习策略来深化它们的模型以提高重构性能：1)残差学习，用于缓解梯度消失问题的有效训练方法；2)密集连接策略，充分挖掘不同层次特征之间的相关性，实现强大的特征表；;3）递归学习，例如超分辨率反馈网络（SRFBN），使用深度SRFBN通过提取时间信息来提高表示能力；4）注意机制，例如，渠道关注（CA）和SA，以促进信息流动；以及5）在深度维度或时间维度上展开网络以提高重建性能。然而，现有的基于神经网络的模型参数较多，资源消耗大，不适合实际应用。<br> 为了减少参数，已经提出了多个紧凑且有效的神经网络来释放用于匹配移动的设备的计算成本。适度信息蒸馏网络（IDN）使用基于状态的递归结构，旨在缓解参数问题，同时保持高质量的重建。同时Hui等人通过多重蒸馏发展了信息多重蒸馏网络，称之为信息多重蒸馏网络（IMDN）。然而，上述轻量级结构忽略了层次特征的使用，导致了不满意的结果。为了获得高质量的重建结果，有学者提出了性能和计算量之间的最佳折衷方案。受上述方法的启发，我们设计了基于渐进学习（PL）的研究，以构建一个有效的网络用于层次多维特征提取。</p> 
<h5><a id="Attention_Mechanism_19"></a>Attention Mechanism</h5> 
<p>CA注重通道的特征细化，在许多计算视觉任务中取得了优异的性能。Zhang等人将CA机制集成到SISR的残余信道注意网络中。然后，由几个二阶信道注意力组成，提出了一个二阶注意力网络，以从一个新的角度执行权重分配。虽然CA已经取得了显著的进步，但由于信息利用的不足，CA仍有其局限性。另一方面，SA的目标是在空间维度上对特征进行加权，从而帮助网络找到一个高效、可信的模型。例如，SPP-Net 使用空间金字塔池（SPP）策略来提高图像表示的质量。在SA的指导下，SPP-Net产生了固定长度的结果，并进一步应用于分类和检测任务。之后，SA的应用场景更加通用，例如：自我注意生成对抗网络在生成对抗网络上进行空间特征细化。尽管单维注意机制有了很大的改进，但仍不能适应工业应用的发展。为了充分利用不同维度的信息，Zhao等人通过混合注意策略来提高其表征能力。基于这种思路，我们提出了一种<strong>自适应学习注意机制R-Cell</strong>，它<strong>可以集中学习通道权重和空间权重，以获得更强大的SR</strong>。</p> 
<h4><a id="_22"></a>方法</h4> 
<h5><a id="Global_Level_PILS_23"></a>Global Level: PILS</h5> 
<h6><a id="Description_ofthe_Backbone_Network_24"></a>Description ofthe Backbone Network:</h6> 
<p><img src="https://images2.imgbox.com/c4/52/LeBBIe7P_o.png" alt="请添加图片描述"></p> 
<p>在图2中，PILN是一种轻质高效的结构，具有几个合理排列的块。主干由三个EILUs组成（即，EILU-S、EILU-M和EILU-D）进行精细特征提取（参见图3）。<img src="https://images2.imgbox.com/f7/0b/UGzfjUc4_o.png" alt="请添加图片描述"><br> 然后，网络的输入和输出分别用I<sub>LR</sub>和I<sub>SR</sub>表示。该公式可说明如下：<br> <img src="https://images2.imgbox.com/55/56/absJCshZ_o.png" alt="在这里插入图片描述"><br> 其中H<sub>LFE</sub>(·)、H<sub>PIL</sub>(·)和H<sub>HFE</sub>(·)分别表示低<strong>级特征提取、渐进式交互学习和高级特征</strong>提取的操作。符号I<sub>up</sub>是I<sub>LR</sub>的上采样结果，并且“+”表示残差学习。为了更清楚地解释特征提取，我们逐步表示PILN。对于输入的I<sub>LR</sub>，通过低层特征提取H<sub>LFE</sub>(·)，可以获得浅层特征F<sub>SF</sub>。<br> <img src="https://images2.imgbox.com/7b/20/8TgLmVeV_o.png" alt="请添加图片描述"><br> 然后，可以通过H<sub>PIL</sub>(·)的操作来细化F<sub>SF</sub>，H<sub>PIL</sub>(·)在全局层面采用PILS<br> <img src="https://images2.imgbox.com/43/f8/eAJAUqVr_o.png" alt="请添加图片描述"><br> 为了更好地适应阶段学习，我们对改进的FPIL进行高层特征提取，并获得融合信息F<sub>HF</sub><br> <img src="https://images2.imgbox.com/d2/4a/jekL6u4H_o.png" alt="在这里插入图片描述"><br> 其中H<sub>HFE</sub>(·)表示高级特征提取的函数。最后，通过在放大的I<sub>LR</sub>和F<sub>HF</sub>之间进行残差学习，可以通过下式形成高质量画面I<sub>SR</sub>：<img src="https://images2.imgbox.com/61/15/w22sXWyh_o.png" alt="在这里插入图片描述"><br> 其中，函数H<sub>up</sub>(·)为上采样，用于将LR插值为HR的大小。</p> 
<h6><a id="Description_ofthe_PILS_38"></a>Description ofthe PILS:</h6> 
<p><img src="https://images2.imgbox.com/26/7b/B4VuXWkd_o.png" alt="请添加图片描述"><br> <img src="https://images2.imgbox.com/d6/a9/0JAh21vs_o.png" alt="请添加图片描述"><br> 如图2所示，所提出的模型可分为三个层次：全局、中间和局部。PILS（图3）主要用于全局水平，以进行精确的图像重建。此外，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          j 
         
        
       
      
        E^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span></span></span></span></span><sub>i</sub>是在第j阶段从第i个EILU提取的纯特征。总体PL可描述如下。</p> 
<h6><a id="Stage_1_selfstudy_T__1_43"></a>Stage 1 self-study (T = 1):</h6> 
<p>EILUS的主要任务是对浅层特征进行预处理，获得中间信息<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          1 
         
        
       
      
        E^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>，提高图像重建质量<img src="https://images2.imgbox.com/c0/3c/T7tWcfNi_o.png" alt="在这里插入图片描述"><br> 其中Φ<sub>EILUS</sub>(·)表示浅层特征的细化，FSF表示初始信息。</p> 
<h6><a id="Stage_2mutual_study_T__2_46"></a>Stage 2mutual study (T = 2):</h6> 
<p>当T= 2时，我们深入地集成了一个全新的功能块EILU-M。首先，我们在EILU-S中对先前的输出<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          1 
         
        
       
      
        E^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>使用自学习，这可以被视为自学习。然后，EILU-M将特征(即：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          1 
         
        
       
      
        E^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>和F<sub>SF</sub>），结合层次特征和时间相关特征，通过以下步骤完成不同模块间的交互学习<br> <img src="https://images2.imgbox.com/e8/7e/WlRvVQpm_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="Stage_3_interaction_study_T__3_49"></a>Stage 3 interaction study (T ≥ 3):</h6> 
<p>当T ≥ 3时，不少于3个块参与特征处理。PILS使EILU-S、EILU-M和EILU-D共同集成到结构中，以获得令人满意的结果。这一过程被称为多模块互动学习，简称互动学习<img src="https://images2.imgbox.com/f4/e3/I0adSlqt_o.png" alt="在这里插入图片描述"><br> 其中Φ<sub>EILUD</sub>(·)表示可以锐化细节的图像处理函数。然后，通过F<sub>SF</sub>、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          1 
         
        
       
      
        E^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          2 
         
        
       
      
        E^2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span><sub>2</sub>（包括各阶段特征）的信息融合，得到高层特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          3 
         
        
       
      
        E^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><sub>3</sub>。</p> 
<h6><a id="Global_feature_fusion_52"></a>Global feature fusion:</h6> 
<p>由于PILS仅使用三个模块，此处F<sub>PIL</sub> =<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          3 
         
        
       
      
        E^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><sub>3</sub>，因此将F<sub>PIL</sub>用作H<sub>AF</sub>(·)输入。H<sub>AF</sub>(·)是特征聚合层，包含一个1 × 1卷积和一个leaky激活函数。F<sub>AF</sub>是一种聚合了层次特征的细化特征，可通过以下方式获得<img src="https://images2.imgbox.com/98/70/cYQkOKC8_o.png" alt="在这里插入图片描述"><br> 最后，我们将所有先前卷积层的特征（即，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          i 
         
        
       
      
        E^i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span></span></span></span></span><sub>i</sub>（i = 1，2，3），F<sub>AF</sub>和F<sub>SF</sub>）输入到特征细化层（ξ<sub>FR</sub>[·]），得到F<sub>HF</sub>的输出：<img src="https://images2.imgbox.com/c7/b8/i1LVF34g_o.png" alt="在这里插入图片描述"><br> 其中ξ<sub>FR</sub>[·]是特征细化的函数。</p> 
<h6><a id="Generalization_of_the_PILS_56"></a>Generalization of the PILS</h6> 
<p>一般来说，我们可以根据（11）和（12）推广上述过程。设<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          E 
         
        
          j 
         
        
       
      
        E^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0576em;">E</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span></span></span></span></span><sub>i</sub>（i，j ∈ N *，1 ≤ i ≤ N，1 ≤ j ≤ T）表示第i个EILU在第j阶段的输出，假设有N个EILU，训练经验为T个阶段。参考上述技术，第P（1 ≤ P ≤ T）阶段的操作可以说明如下，这直接体现了PL的目的：<br> <img src="https://images2.imgbox.com/e1/b0/URrPBfzl_o.png" alt="在这里插入图片描述"><br> 最后，我们融合每个阶段的PL结果，得到PILS的最终输出，即F<sub>HF</sub><img src="https://images2.imgbox.com/4e/67/CnVunlBG_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="Mediate_LevelEIS_60"></a>Mediate Level:EIS</h5> 
<p>如前所述，PILN由多个EILU组成，EIS见图4。与PILN中的全局PL相似，EILU采用周期学习的方法来促进中间层的特征融合。特别地，为了方便起见，我们使用了四个EILU学习周期。<img src="https://images2.imgbox.com/97/cb/WAONS0SI_o.png" alt="请添加图片描述"></p> 
<h6><a id="Period_1_62"></a>Period 1</h6> 
<p>假设EILU的输入是E<sub>in</sub>，我们可以获得复合特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
        
          1 
         
        
       
      
        R^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>。由于只使用一个模块，因此称为自学习过程<img src="https://images2.imgbox.com/97/25/WTll0OTP_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="Period_2_64"></a>Period 2</h6> 
<p>与Period 1不同的是，在Period 2中增加了特征提取单元(FEU)O<sub>FEU1</sub>(·)，以配合上述R-Cell进行交互学习。将<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
        
          1 
         
        
       
      
        R^1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>引入两个卷积层，完成了以交互为主的学习策略（ILS）<img src="https://images2.imgbox.com/35/a7/8IfkCPa9_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="Period_3_66"></a>Period 3</h6> 
<p>然后引入FEU<sub>2</sub>(O<sub>FEU2</sub>(·))进一步交互学习更精确的特征，得到特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          3 
         
        
       
      
        F^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          3 
         
        
       
      
        F^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><sub>2</sub><img src="https://images2.imgbox.com/72/6e/cO9TRks3_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="Period_4_68"></a>Period 4</h6> 
<p>通过对Period1-3的处理，引入R-Cell 2以获得高精度特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          4 
         
        
       
      
        F^4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span><sub>2</sub>，它包含了以前的E<sub>in</sub>、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          3 
         
        
       
      
        F^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><sub>1</sub>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          R 
         
        
          3 
         
        
       
      
        R^3 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8141em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">3</span></span></span></span></span></span></span></span></span></span></span></span><sub>2</sub><img src="https://images2.imgbox.com/74/17/ujTqfHWx_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="Feature_Refinement_70"></a>Feature Refinement</h6> 
<p>最后，采用残差和收敛学习，可以通过下式获得输出E<sub>out</sub>：<img src="https://images2.imgbox.com/99/77/km0R32J2_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="Local_Level_PWL_72"></a>Local Level: PWL</h5> 
<p><img src="https://images2.imgbox.com/bc/81/pP46nZgF_o.png" alt="请添加图片描述"></p> 
<p>图5显示了局部级实施的PWL战略。假设输入和输出分别是R<sub>in</sub>和R<sub>out</sub>，则R-Cells和FEUs可以被定型如下</p> 
<h6><a id="Residual_Cell_76"></a>Residual Cell</h6> 
<p>通过像素特征提取，由下式获得浅特征F<sub>E</sub><img src="https://images2.imgbox.com/41/34/tddtTYoZ_o.png" alt="在这里插入图片描述"><br> 其中H<sub>Pixel−E</sub>(·)是像素特征提取操作（图5中的黄色方框所示）。然后发送给CA和SA模块进行权值计算，得到F<sub>con</sub><img src="https://images2.imgbox.com/9a/04/QQ48iikx_o.png" alt="在这里插入图片描述"><br> 其中H<sub>CA</sub>(·)和H<sub>SA</sub>(·)是通道和SA块的函数。通过执行像素特征细化（H<sub>Pixel−R</sub>(·))，纯特征F<sub>R</sub>已通过以下方式实现<img src="https://images2.imgbox.com/5d/b8/9qKb863s_o.png" alt="在这里插入图片描述"><br> 最后，应用R<sub>in</sub>和F<sub>R</sub>之间的残差学习，我们完成了信息净化并赢得了R<sub>out</sub>，即：<img src="https://images2.imgbox.com/c6/e7/4N3XAQf8_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="Feature_Extract_Unit_81"></a>Feature Extract Unit</h6> 
<p>由于O<sub>FEUi</sub>(·)是第i个FEU中的逐像素运算，因此，假设FEU的输入是U<sub>in</sub>，则输出U<sub>out</sub>可通过下式获得：<br> <img src="https://images2.imgbox.com/f6/94/7dvsdMOy_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/fef7932e851b640dc36895de81773829/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">真滴泰裤辣！！！！字节跳动最全Git应用及面试问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e6776b2a589b0f5d2d56306eaa0024ff/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Anaconda安装第三方库</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>