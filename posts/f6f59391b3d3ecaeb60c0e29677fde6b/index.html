<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Paper】StyTr2: Image Style Transfer with Transformers - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Paper】StyTr2: Image Style Transfer with Transformers" />
<meta property="og:description" content="CVPR 2022｜快手联合中科院自动化所提出基于Transformer的图像风格化方法 论文链接：https://arxiv.org/abs/2105.14576
代码地址：https://github.com/diyiiyiii/StyTR-2
目前主流的的风格化方法一般利用卷积神经网络学习风格和内容表示。由于卷积运算的感受野有限，只有卷积网络比较深，才能捕获图片的长程依赖关系。但是，网络深度的增加会导致图片特征分辨率降低和细节的丢失。细节的缺失体现在风格化结果中就是会影响内容结构的保存和风格模式的显示。如图 1(a) 所示，基于卷积神经网络的风格化算法在特征提取过程中忽略了一些细节，网络浅层关注局部特征，深层通过整合局部信息才能获取全局信息。此外，有研究工作发现典型的基于 CNN 的风格化方法获取的内容表示是不准确的，会导致内容泄漏的问题: 经过几轮重复的风格化操作，风格化结果中几乎不能保留任何原始输入的内容结构信息。
Transformer 应用 于计算机视觉的优点有两个：
首先，在自注意机制的帮助下，Transformer 可以很容易地学习输入的全局信息，从而在每一层都可以获得对输入的整体的理解;其次，Transformer 是一种关系建模的结构，不同层可以提取相似的结构信息 (如图 1(b) 所示)。因此，Transformer 具有较强的特征表示能力，可以避免特征提取过程中细节的丢失，并能很好地保存生成的结构。 本文针对基于 CNN 的风格化方法存在的内容表达存在偏差的问题，提出了一种新颖的图像风格化算法，即 StyTr^2。
方法 为了利用 Transformer 捕获长期依赖关系的能力来实现图像风格化，本文设计了图 2 中结构，模型主要包括三部分：
内容 Transformer 编码器，风格 Transformer 编码器（内容 Transformer 编码器和风格 Transformer 编码器分别用来编码内容域和风格域的图片的长程信息，这种编码方式可以有效避免细节丢失问题。）Transformer 解码器（Transformer 解码器用来将内容特征转换为带有风格图片特征的风格化结果。） 此外，本文针对传统位置编码提出两个重要问题。第一，对于图像生成任务，在计算 PE（位置编码）时，是否应该考虑图像语义? 传统的 PE 是根据按照逻辑排序的句子来设计的，而图像序列是根据图像内容语义来组织的。假设两个图像补丁之间的距离为 d(.,.) 。如图 3(a) 右边部分所示，d((0 , 3 ), (1 , 3 )) (红色和绿色块) 之间的差异与 d(( 0 , 3 ), (3 , 3 )) (红色和青色 块) 之间的差异应该是相似的，因为风格化任务要求相似的内容补丁有相似的风格化结果。第二，当输入图像尺寸呈指数级增大时，传统的正弦位置编码是否仍然适用于视觉任务?" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f6f59391b3d3ecaeb60c0e29677fde6b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-08T20:29:54+08:00" />
<meta property="article:modified_time" content="2022-04-08T20:29:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Paper】StyTr2: Image Style Transfer with Transformers</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4 id="activity-name">CVPR 2022｜快手联合中科院自动化所提出基于Transformer的图像风格化方法</h4> 
<ul><li> <p>论文链接：<a class="link-info" href="https://arxiv.org/abs/2105.14576" rel="nofollow" title="https://arxiv.org/abs/2105.14576">https://arxiv.org/abs/2105.14576</a></p> </li><li> <p>代码地址：<a class="link-info" href="https://github.com/diyiiyiii/StyTR-2" title="https://github.com/diyiiyiii/StyTR-2">https://github.com/diyiiyiii/StyTR-2</a></p> </li></ul> 
<hr> 
<p>       目前主流的的风格化方法一般利用卷积神经网络学习风格和内容表示。由于卷积运算的感受野有限，只有卷积网络比较深，才能捕获图片的长程依赖关系。但是，<span style="color:#38d8f0;"><strong>网络深度的增加会导致图片特征分辨率降低和细节的丢失</strong></span>。细节的缺失体现在风格化结果中就是会影响内容结构的保存和风格模式的显示。如图 1(a) 所示，基于卷积神经网络的风格化算法在特征提取过程中忽略了一些细节，网络浅层关注局部特征，深层通过整合局部信息才能获取全局信息。此外，<strong>有研究工作发现典型的基于 CNN 的风格化方法获取的内容表示是不准确的，会导致内容泄漏的问题</strong>: 经过几轮重复的风格化操作，风格化结果中几乎不能保留任何原始输入的内容结构信息。</p> 
<p><img alt="" height="424" src="https://images2.imgbox.com/8a/af/nGpfpDHC_o.png" width="631"></p> 
<p> Transformer 应用 于计算机视觉的优点有两个：</p> 
<blockquote> 
 <ul><li>首先，在自注意机制的帮助下，Transformer 可以很容易地学习输入的<span style="color:#38d8f0;"><strong>全局信息</strong></span>，从而在每一层都可以获得对输入的整体的理解;</li><li>其次，<span style="color:#38d8f0;"><strong>Transformer 是一种关系建模的结构，不同层可以提取相似的结构信息 (</strong></span><span style="color:#0d0016;"><strong>如图 1(b) 所示</strong></span><span style="color:#38d8f0;"><strong>)。因此，Transformer 具有较强的特征表示能力，可以避免特征提取过程中细节的丢失，并能很好地保存生成的结构</strong>。</span></li></ul> 
</blockquote> 
<p>本文针对基于 CNN 的风格化方法存在的内容表达存在偏差的问题，提出了一种新颖的图像风格化算法，即 StyTr^2。</p> 
<p></p> 
<h2><strong>方法</strong></h2> 
<p>为了利用 Transformer 捕获长期依赖关系的能力来实现图像风格化，本文设计了图 2 中结构，模型主要包括三部分：</p> 
<blockquote> 
 <ol><li>内容 Transformer 编码器，风格 Transformer 编码器（内容 Transformer 编码器和风格 Transformer 编码器分别用来编码内容域和风格域的图片的长程信息，这种编码方式可以有效<span style="color:#38d8f0;"><strong>避免细节丢失问题</strong></span>。）</li><li>Transformer 解码器（Transformer 解码器用来<span style="color:#38d8f0;"><strong>将内容特征转换为带有风格图片特征的风格化结果</strong></span>。）</li></ol> 
</blockquote> 
<p><img alt="" height="909" src="https://images2.imgbox.com/3a/64/xVQslNix_o.png" width="1200"></p> 
<p> 此外，本文针对传统位置编码提出两个重要问题。第一，对于图像生成任务，在计算 PE（位置编码）时，是否应该考虑图像语义? 传统的 PE 是根据按照逻辑排序的句子来设计的，而图像序列是根据图像内容语义来组织的。假设两个图像补丁之间的距离为 d(.,.) 。如图 3(a) 右边部分所示，d((0 , 3 ), (1 , 3 )) (红色和绿色块) 之间的差异与 d(( 0 , 3 ), (3 , 3 )) (红色和青色 块) 之间的差异应该是相似的，因为风格化任务要求相似的内容补丁有相似的风格化结果。第二，当输入图像尺寸呈指数级增大时，传统的正弦位置编码是否仍然适用于视觉任务? 如 3(a) 所示，当图像大小发生变化时，相同语义位置的补丁 (用蓝色小矩形表示) 之间的相对距离会发生显著变化，这不适合视觉任务中的多尺度输入要求。</p> 
<p class="img-center"><img alt="" height="277" src="https://images2.imgbox.com/2c/72/kntYP4OG_o.png" width="795"></p> 
<p>为此，本文提出了内容感知的位置编码 (Content-Aware Positional Encoding，CAPE)，它具有尺度不变且与内容语义相关的特点，更适合于风格化任务。</p> 
<h2><strong>结果展示</strong></h2> 
<p>如图 4 所示，与 state-of-the-art 方法相比，StyTr^2 利用了基于 Transformer 的网络，具有更好的特征表示能力，捕获输入图像的长期依赖关系，并避免丢失内容和风格细节。因此，本文方法的结果可以实现高质量的风格化，使结果同时保持良好的内容结构和丰富的风格模式。</p> 
<p><img alt="" height="1191" src="https://images2.imgbox.com/0b/4d/rmOvYeeR_o.png" width="1200"></p> 
<p>图 5 展示了第 1 轮和第 20 轮的风格化结果。首先，比较第一轮的风格化结果。基于 CNN 的方法生成的结果内容结构受到了不同程度的破坏，但本文的结果仍然具有清晰的内容结构。虽然 ArtFlow 生成的结果保持了清晰的内容结构，但风格化的效果并不令人满意 (例如，边缘缺陷和不合适的样式模式)。其次，随着风格化次数的增加，基于 CNN 的方法生成的内容结构趋于模糊，而我们的方法生成的内容结构仍然是清晰的。</p> 
<p><img alt="" height="280" src="https://images2.imgbox.com/ba/df/FexcUzBS_o.png" width="1200"></p> 
<p></p> 
<p></p> 
<p>//TODO</p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0ce8d1dc7d65adaa95f8a5e3f83f6173/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Kal系统学习：记录一次wifi破解过程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/271df9e59c00c80f70b6c796eaaee9c8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java基础-Arrays排序</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>