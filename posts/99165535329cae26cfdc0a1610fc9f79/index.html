<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch之经典神经网络CNN(Extra-1) —— CNN可视化(查看中间层feature_map) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch之经典神经网络CNN(Extra-1) —— CNN可视化(查看中间层feature_map)" />
<meta property="og:description" content="从ZF-Net开始人们就在研究神经网络和filter的可视化
结合了多篇文章整理了好久，网上写的真的鱼龙混杂，代码具有可操作性的不多.......也或者是我的coding水平还没到？sad.
CNN可视化各层输出的feature map 和
(5条消息) Pytorch(十四) —— 查看中间层feature_map &amp; 卷积核权重可视化_hxxjxw的博客-CSDN博客
一样
import os import torch import torchvision as tv import torchvision.transforms as transforms import torch.nn as nn import torch.optim as optim import argparse import skimage.data import skimage.io import skimage.transform import numpy as np import matplotlib.pyplot as plt import torchvision.models as models from PIL import Image import cv2 #提取某一层网络特征图 class FeatureExtractor(nn.Module): def __init__(self, submodule, extracted_layers): super(FeatureExtractor, self).__init__() self.submodule = submodule self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/99165535329cae26cfdc0a1610fc9f79/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-05T21:57:35+08:00" />
<meta property="article:modified_time" content="2022-11-05T21:57:35+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch之经典神经网络CNN(Extra-1) —— CNN可视化(查看中间层feature_map)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>从ZF-Net开始人们就在研究神经网络和filter的可视化</p> 
 <p>结合了多篇文章整理了好久，网上写的真的鱼龙混杂，代码具有可操作性的不多.......也或者是我的coding水平还没到？sad.</p> 
 <p></p> 
 <h3>CNN可视化各层输出的feature map</h3> 
 <p>和</p> 
 <p><a href="https://blog.csdn.net/hxxjxw/article/details/120611595" title="(5条消息) Pytorch(十四) —— 查看中间层feature_map &amp; 卷积核权重可视化_hxxjxw的博客-CSDN博客">(5条消息) Pytorch(十四) —— 查看中间层feature_map &amp; 卷积核权重可视化_hxxjxw的博客-CSDN博客</a></p> 
 <p>一样</p> 
 <pre><code class="language-python">import os
import torch
import torchvision as tv
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim
import argparse
import skimage.data
import skimage.io
import skimage.transform
import numpy as np
import matplotlib.pyplot as plt
import torchvision.models as models
from PIL import Image
import cv2

#提取某一层网络特征图
class FeatureExtractor(nn.Module):
    def __init__(self, submodule, extracted_layers):
        super(FeatureExtractor, self).__init__()
        self.submodule = submodule
        self.extracted_layers = extracted_layers

    def forward(self, x):
        outputs = {}
        for name, module in self.submodule._modules.items():
            if "fc" in name:
                x = x.view(x.size(0), -1)
            x = module(x)
            print(name)
            if (self.extracted_layers is None) or (name in self.extracted_layers and 'fc' not in name):
                outputs[name] = x
        # print(outputs)
        return outputs


def get_picture(pic_name, transform):
    img = skimage.io.imread(pic_name)
    img = skimage.transform.resize(img, (256, 256)) #读入图片时将图片resize成(256,256)的
    img = np.asarray(img, dtype=np.float32)
    return transform(img)


def make_dirs(path):
    if os.path.exists(path) is False:
        os.makedirs(path)

pic_dir = 'dataset/dogsvscats/train/cat.1700.jpg'
transform = transforms.ToTensor()
img = get_picture(pic_dir, transform)
# 插入维度
img = img.unsqueeze(0)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
img = img.to(device)

net = models.resnet101(pretrained=True).to(device)

dst = './feautures'
therd_size = 256

myexactor = FeatureExtractor(submodule=net, extracted_layers=None)
output = myexactor(img)
#output是dict
#dict_keys(['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4', 'avgpool', 'fc'])

for idx,val in enumerate(output.items()):
    k,v = val
    features = v[0]
    iter_range = features.shape[0]
    for i in range(iter_range):
        # plt.imshow(features.data.cpu().numpy()[i,:,:],cmap='jet')
        if 'fc' in k:  #不可视化fc层
            continue

        feature = features.data.cpu().numpy()
        feature_img = feature[i, :, :]
        feature_img = np.asarray(feature_img * 255, dtype=np.uint8)

        dst_path = os.path.join(dst, str(idx)+'-'+k)

        make_dirs(dst_path)
        feature_img = cv2.applyColorMap(feature_img, cv2.COLORMAP_JET)
        if feature_img.shape[0] &lt; therd_size:
            tmp_file = os.path.join(dst_path, str(i) + '_' + str(therd_size) + '.png')
            tmp_img = feature_img.copy()
            tmp_img = cv2.resize(tmp_img, (therd_size, therd_size), interpolation=cv2.INTER_NEAREST)
            cv2.imwrite(tmp_file, tmp_img)

        dst_file = os.path.join(dst_path, str(i) + '.png')
        cv2.imwrite(dst_file, feature_img)
</code></pre> 
 <p>得到的feature_img是0-255范围的</p> 
 <p></p> 
 <p>输入的原图是kaggle的猫狗数据集中的一张图片</p> 
 <p><img alt="" height="194" src="https://images2.imgbox.com/c8/b2/Rf5EmwlB_o.png" width="190"></p> 
 <p></p> 
 <p><strong>依次提取的各层</strong></p> 
 <p>conv1<br> bn1<br> relu<br> maxpool<br> layer1<br> layer2<br> layer3<br> layer4<br> avgpool<br> fc</p> 
 <p></p> 
 <p><strong>输出</strong></p> 
 <p><img alt="" height="233" src="https://images2.imgbox.com/5b/30/K1djkPo2_o.png" width="431"></p> 
 <p>因为到后期的图片会越来越小，所以我们有一个缩放操作，每张图片有一个输出的原图，还有一个放大后的图片</p> 
 <p>0-conv1</p> 
 <p><img alt="" height="409" src="https://images2.imgbox.com/b8/25/SWUE4lOt_o.png" width="546"></p> 
 <p>1-bn1</p> 
 <p><img alt="" height="475" src="https://images2.imgbox.com/2e/66/3h939cNm_o.png" width="639"></p> 
 <p>2-relu</p> 
 <p><img alt="" height="466" src="https://images2.imgbox.com/34/8c/Xi6Nn0WF_o.png" width="624"></p> 
 <p>3-maxpool</p> 
 <p><img alt="" height="411" src="https://images2.imgbox.com/c1/8d/HHEvjV9o_o.png" width="580"></p> 
 <p>4-layer1</p> 
 <p><img alt="" height="443" src="https://images2.imgbox.com/b8/0f/qLQvB9R1_o.png" width="591"></p> 
 <p>5-layer2</p> 
 <p><img alt="" height="522" src="https://images2.imgbox.com/88/1a/BnJtXmrQ_o.png" width="678"></p> 
 <p>6-layer3</p> 
 <p><img alt="" height="490" src="https://images2.imgbox.com/96/f0/RD8C353h_o.png" width="676"></p> 
 <p>7-layer4<br><img alt="" height="458" src="https://images2.imgbox.com/d2/e0/UK1gx5CM_o.png" width="637"></p> 
 <p>8-avgpool</p> 
 <p><img alt="" height="446" src="https://images2.imgbox.com/7d/80/6M1MROH6_o.png" width="644"></p> 
 <p></p> 
 <p>可以看出，第一层的卷积层输出，特征图里面还可以看出猫的形状，到了后面卷积网络的输出特征图，看着有点像热力图，并且完全没有猫的样子，是更加抽象的图片表达</p> 
 <p></p> 
</blockquote> 
<p></p> 
<blockquote> 
 <h3>CNN 卷积核权重可视化</h3> 
 <p>我们一个conv层，比如有64个filter，每个filter又是个三维的，要扫过R,G,B通道，这里可视化的时候只选择了每个filter的第一个channel来显示</p> 
 <p></p> 
 <p>当打平画直方图，就是它了<a href="https://blog.csdn.net/hxxjxw/article/details/120611595" title="(5条消息) Pytorch(十四) —— 查看中间层feature_map &amp; 卷积核权重可视化_hxxjxw的博客-CSDN博客">(5条消息) Pytorch(十四) —— 查看中间层feature_map &amp; 卷积核权重可视化_hxxjxw的博客-CSDN博客</a></p> 
 <pre><code class="language-python">import torch
import torchvision.models as models
import matplotlib.pyplot as plt
from PIL import Image
from torchvision import transforms

input_image = Image.open('dataset/dogsvscats/train/cat.1700.jpg')
preprocess = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
input_tensor = preprocess(input_image)
input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model


model = models.alexnet(pretrained=True)
if torch.cuda.is_available():
    input_batch = input_batch.to('cuda')
    model.to('cuda')
with torch.no_grad():
    output = model(input_batch)

#卷积可视化
#将数据灌入模型后，pytorch框架会进行对应的前向传播，要对卷积核可视化，我们需要把卷积核从框架中提取出来。多谢torch提供的接口，我们可以直接把对应层的权重取出
for layer in dict(model.features.named_children()).keys():
    if layer not in ['0','3','6','8','10']: #只有conv层可以可视化，maxpooling层和relu层不能可视化
        continue
    filter = dict(model.features.named_children())[layer]
    filter = filter.weight.cpu().clone()
    print("total of number of filter : ", len(filter))
    num = len(filter)
    plt.figure(figsize=(20, 17))
    for i in range(1,64):
        plt.subplot(9, 9, i)
        plt.axis('off')
        plt.imshow(filter[i][0, :, :].detach(),cmap='gray')
    plt.show()</code></pre> 
 <p>conv1</p> 
 <p><img alt="" height="470" src="https://images2.imgbox.com/8e/2c/FNWG14H5_o.png" width="783"></p> 
 <p>conv2</p> 
 <p><img alt="" height="475" src="https://images2.imgbox.com/67/1d/Ggibht3q_o.png" width="792"></p> 
 <p>conv3</p> 
 <p><img alt="" height="476" src="https://images2.imgbox.com/a7/89/RG54qf0j_o.png" width="793"></p> 
 <p>conv4</p> 
 <p><img alt="" height="475" src="https://images2.imgbox.com/2d/49/c0Ie4a7J_o.png" width="791"></p> 
 <p>conv5</p> 
 <p><img alt="" height="463" src="https://images2.imgbox.com/c4/fe/KGRnZ8vm_o.png" width="773"></p> 
 <p>可以看出第一层卷积核 人类还是可以比较容易理解，有些提取的是边缘，有些提取的是圆形，有些提取的是斑点等。</p> 
 <p>最后一层卷积层的卷积核就已经看不出来是提取的什么东西了，即卷积核提取的是更加抽象的特征。</p> 
 <p></p> 
 <p><a href="https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb" rel="nofollow" title="https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb">https://nbviewer.jupyter.org/github/fchollet/deep-learning-with-python-notebooks/blob/master/5.4-visualizing-what-convnets-learn.ipynb</a></p> 
 <p><a href="https://blog.csdn.net/weixin_44023658/article/details/106123841" title="使用pytorch查看中间层特征矩阵以及卷积核参数_越前浩波的博客-CSDN博客_pytorch卷积核参数">使用pytorch查看中间层特征矩阵以及卷积核参数_越前浩波的博客-CSDN博客_pytorch卷积核参数</a></p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e2db28435f3033e8ef6e488836cb1d26/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">开始使用AspectJ-实现步骤@Aspect，@Before,还有其中的JoinPoint参数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e6201e184838636495096a1a89487c35/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Unet语义分割训练数据集流程（学习记录）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>