<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>文心ERNIE Bot SDK&#43;LangChain：基于文档、网页的个性化问答系统 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="文心ERNIE Bot SDK&#43;LangChain：基于文档、网页的个性化问答系统" />
<meta property="og:description" content="现在各行各业纷纷选择接入大模型，其中最火且可行性最高的形式无异于智能文档问答助手，而LangChain是其中主流技术实现工具，能够轻松让大语言模型与外部数据相结合，从而构建智能问答系统。ERNIE Bot SDK已接入文心大模型4.0能力，同时支持对话补全、函数调用、语义向量等功能。
本教程是基于文心一言ERNIE Bot SDK与LangChain构建基于Embedding Vector方式的文本问答系统，整体可以解构为三部分。
1、基于ERNIE Bot与LangChain结合的Embedding，获取向量矩阵并保存
2、基于用户问题，在向量矩阵库中搜寻相近的原文句子
3、基于检索到的原文与Prompt结合，从LLM获取答案
背景介绍
问答系统处理流程
加载文件 -&gt; 读取文本 -&gt; 文本分割 -&gt; 文本向量化 -&gt; 问句向量化 -&gt; 在文本向量中匹配出与问句向量最相似的top_k个 -&gt; 匹配出的文本作为上下文和问题一起添加到Prompt中 -&gt; 提交给LLM生成回答
技术工具
ERNIE Bot SDK
ERNIE Bot SDK 提供便捷易用的接口，可以调用文心大模型的能力，包含文本创作、通用对话、语义向量、AI作图等。
LangChain
LangChain 是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如API和数据库。
项目代码
环境准备
安装相关库
!pip install -qr requirements.txt 读取 access_token
在星河社区的控制台访问令牌中找到自己的access_token，替换access_token.txt或下面代码中的access_token。
fileName=&#39;access_token.txt&#39; access_token=&#39;&#39; if len(access_token)==0: with open(fileName,&#39;r&#39;) as f: #逐行读取文件内容 lines = f.readlines() for line in lines: if line[:13]==&#39;access_token=&#39;: access_token=line[13:] assert len(access_token)&gt;10 print(&#39;access_token:&#39;,access_token) LangChain及Embedding部分" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/728da3ff14981ea335f16d1760b1d262/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-07T19:58:29+08:00" />
<meta property="article:modified_time" content="2023-12-07T19:58:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">文心ERNIE Bot SDK&#43;LangChain：基于文档、网页的个性化问答系统</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/04/78/RkGcbF6d_o.gif" alt="793708827b1b12b2280a88ab825a7f46.gif"></p> 
 <p style="text-align:justify;">现在各行各业纷纷选择接入大模型，其中最火且可行性最高的形式无异于智能文档问答助手，而LangChain是其中主流技术实现工具，能够轻松让大语言模型与外部数据相结合，从而构建智能问答系统。ERNIE Bot SDK已接入文心大模型4.0能力，同时支持对话补全、函数调用、语义向量等功能。</p> 
 <p style="text-align:justify;"><strong>本教程是基于文心一言ERNIE Bot SDK与LangChain构建基于Embedding Vector方式的文本问答系统，</strong>整体可以解构为三部分。</p> 
 <p style="text-align:left;">1、基于ERNIE Bot与LangChain结合的Embedding，获取向量矩阵并保存</p> 
 <p style="text-align:justify;">2、基于用户问题，在向量矩阵库中搜寻相近的原文句子</p> 
 <p style="text-align:justify;">3、基于检索到的原文与Prompt结合，从LLM获取答案</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/4a/ee/JTZm1aMb_o.png" alt="fe341cf7a5aa3d602aa54e5a8a430520.png"></p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/f1/a6/6LFYvB2i_o.png" alt="8ff7e8e287d5c48dd41ae046290a6ce0.png"><strong>背景介绍</strong></p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/c0/5c/QS1XidiK_o.png" alt="f918f8cca9d8d01bf83fed0d2c6a6c2e.png"><strong>问答系统处理流程</strong></p> 
 <p style="text-align:justify;">加载文件 -&gt; 读取文本 -&gt; 文本分割 -&gt; 文本向量化 -&gt; 问句向量化 -&gt; 在文本向量中匹配出与问句向量最相似的top_k个 -&gt; 匹配出的文本作为上下文和问题一起添加到Prompt中 -&gt; 提交给LLM生成回答</p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/23/fd/IOm4Ydol_o.png" alt="6297dd957e47f35d43986cc9986b9967.png"><strong>技术工具</strong></p> 
 <p><strong>ERNIE Bot SDK</strong></p> 
 <p style="text-align:justify;">ERNIE Bot SDK 提供便捷易用的接口，可以调用文心大模型的能力，包含文本创作、通用对话、语义向量、AI作图等。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/ce/73/UU5934Mk_o.png" alt="45d347766ec603963044e849bd189389.png"></p> 
 <p><strong>LangChain</strong></p> 
 <p style="text-align:justify;">LangChain 是一个强大的框架，旨在帮助开发人员使用语言模型构建端到端的应用程序。它提供了一套工具、组件和接口，可简化创建由大型语言模型 (LLM) 和聊天模型提供支持的应用程序的过程。LangChain 可以轻松管理与语言模型的交互，将多个组件链接在一起，并集成额外的资源，例如API和数据库。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/2a/8c/PG5Mjv2z_o.png" alt="d89ee926532020596a3246f844283c23.png"><strong>项目代码</strong></p> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/c2/35/7k0vxvOq_o.png" alt="e3626861d7bf794ae63fe6951dbf9a0b.png"><strong>环境准备</strong></p> 
 <p><strong>安装相关库</strong></p> 
 <pre class="has"><code class="language-go">!pip install -qr requirements.txt</code></pre> 
 <p><strong>读取 access_token</strong></p> 
 <p style="text-align:justify;">在星河社区的控制台访问令牌中找到自己的access_token，替换access_token.txt或下面代码中的access_token。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/3d/ff/r2T8Rgry_o.png" alt="a7e34f62552dbe441566910a6457df9d.png"></p> 
 <pre class="has"><code class="language-go">fileName='access_token.txt'
access_token=''
if len(access_token)==0:
    with open(fileName,'r') as f:
        #逐行读取文件内容
        lines = f.readlines()
    for line in lines:
        if line[:13]=='access_token=':
            access_token=line[13:]
assert len(access_token)&gt;10
print('access_token:',access_token)</code></pre> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/af/e7/Xw8kSxG3_o.png" alt="a1bc9afd8a6f73c59c10ddeed31c3285.png"><strong>LangChain及Embedding部分</strong></p> 
 <p><strong>获取文档载入器</strong></p> 
 <p style="text-align:justify;">使用GetLoader(source)获取LangChain中的Loader，GetLoader会根据source类型，调用对应的LangChain文本载入器。</p> 
 <p><strong>创建或载入向量库</strong></p> 
 <p style="text-align:justify;">引入Embeddings函数并切分文本，chunk_size按ERNIE Bot SDK要求设为384</p> 
 <pre class="has"><code class="language-go">text_splitter = RecursiveCharacterTextSplitter(chunk_size=ernieChunkSize, chunk_overlap=0)
splits = text_splitter.split_documents(documents)</code></pre> 
 <p style="text-align:justify;">获取整个文档或网页的Embedding向量并保存。</p> 
 <pre class="has"><code class="language-go">embeddings=ErnieEmbeddings(access_token=access_token)
    # vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())
    vectorstore = Chroma.from_documents(persist_directory=persist_directory,documents=splits, embedding=embeddings)</code></pre> 
 <p><strong>根据用户问题获取文档中最相近的原文片段</strong></p> 
 <p style="text-align:left;">使用了LangChain中的similarity_search_with_score就可以获取所需的top_k个文案片段，并且返回其score。结果显示score差别不是很大。</p> 
 <pre class="has"><code class="language-go">def searchSimDocs(query,vectorstore,top_k=3,scoreThershold=5):

   packs=vectorstore.similarity_search_with_score(query,k=top_k)
   contentList=[]

   for pack in packs:
       doc,score=pack
       if score&lt;scoreThershold:##好像设置5，基本都会返回
           contentList.append(doc.page_content)

   # print('content',contentList)
   return contentList</code></pre> 
 <p style="text-align:justify;">具体Embedding代码见下方：<br></p> 
 <pre class="has"><code class="language-go">import os

os.environ['access_token']=access_token
from langchain.vectorstores import Chroma
from langchain.chains import RetrievalQA
from langchain_embedding_ErnieBotSDK import ErnieEmbeddings# Load documents

from langchain.document_loaders import WebBaseLoader
from langchain.document_loaders.text import TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
import erniebot

## https://python.langchain.com/docs/integrations/chat/ernie


# loader = WebBaseLoader("https://cloud.tencent.com/developer/article/2329879")

## 创建新的chroma向量库
def createDB(loader,persist_directory='./chromaDB'):

    #loader = TextLoader(file_path=file_path,encoding='utf8')
    documents=loader.load()
    # Split documents

    ernieChunkSize=384
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=ernieChunkSize, chunk_overlap=0)
    splits = text_splitter.split_documents(documents)
    print('splits len:',len(splits))#,splits[:5])
    # Embed and store splits
    embeddings=ErnieEmbeddings(access_token=access_token)
    # vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())
    vectorstore = Chroma.from_documents(persist_directory=persist_directory,documents=splits, embedding=embeddings)
    #https://juejin.cn/post/7236028062873550908
    # 持久化 会结合之前保存下来的 vectorstore
    #vectorstore.persist()
    return vectorstore
## 读取已保存的chroma向量库
def readDB(persist_directory="./chromaDB"):
    assert os.path.isdir(persist_directory)
    # # Embed and store splits
    embeddings=ErnieEmbeddings(access_token=access_token)
    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)
    return vectorstore
## 基于用户的query去搜索库中相近的文档
def searchSimDocs(query,vectorstore,top_k=3,scoreThershold=5):
    packs=vectorstore.similarity_search_with_score(query,k=top_k)
    contentList=[]

    for pack in packs:
        doc,score=pack
        if score&lt;scoreThershold:##好像设置5，基本都会返回
            contentList.append(doc.page_content)

    # print('content',contentList)
    return contentList

def getLoader(source):
    if source[-4:]=='.txt':

        #file_path='doupo.txt'
        assert os.path.isfile(file_path)
        loader = TextLoader(file_path=file_path,encoding='utf8')
    elif source[:4]=='http':
        #url='https://zhuanlan.zhihu.com/p/657210829'
        loader= WebBaseLoader(source)

    return loader

#######################################
new=True ##新建向量库，注意如果拿几百万字的小说embedding
source='https://zhuanlan.zhihu.com/p/657210829'
loader=getLoader(source)
if new:
    vectorstore=createDB(loader)
else:
    vectorstore=readDB()
# 初始化 prompt 对象
query = "大模型长文本建模的难点是什么？"
contentList=searchSimDocs(query,vectorstore,top_k=5)
print('contentList',contentList)</code></pre> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/f6/85/4oSiiSbQ_o.png" alt="10b92c0a7e170d5646f5e8e55f7dedd4.png"><strong>LLM根据相关文档片段回答问题</strong></p> 
 <p>预置Prompt设定LLM角色，该Prompt将与向量计算中相关文档片段进行结合，作为query输入给大模型。</p> 
 <pre class="has"><code class="language-go">prompt=
"你是善于总结归纳并结合文本回答问题的文本助理。请使用以下检索到的上下文来回答问题。如果你不知道答案，就说你不知道。最多使用三句话，并保持答案简洁。问题为：\n"+query+" \n上下文：\n"+'\n'.join(contentList) +" \n 答案:"</code></pre> 
 <p>以下为response解析代码：</p> 
 <pre class="has"><code class="language-go">def packPrompt(query,contentList):
    prompt="你是善于总结归纳并结合文本回答问题的文本助理。请使用以下检索到的上下文来回答问题。如果你不知道答案，就说你不知道。最多使用三句话，并保持答案简洁。问题为：\n"+query+" \n上下文：\n"+'\n'.join(contentList) +" \n 答案:"
    return prompt

def singleQuery(prompt,model='ernie-bot'):
    response = erniebot.ChatCompletion.create(
        model=model,
        messages=[{
            'role': 'user',
            'content': prompt
        }])
    print('response',response)
    try:
        resFlag=response['rcode']
    except:        
        resFlag=response['code']
    if resFlag==200:
        try:
            data=response['body']
        except:
            data=response

        result=response['result']

        usedToken=data['usage']['total_tokens']
    else:
        result=""
        usedToken=-1
    return result,usedToken

prompt=packPrompt(query,contentList)
res,usedToken=singleQuery(prompt,model='ernie-bot-4')
print(res)</code></pre> 
 <p style="text-align:justify;">该教程支持直接一键fork运行，点击小程序卡片运行。</p> 
 <p style="text-align:justify;">该教程项目来源于飞桨星河社区五周年开发精品教程征集，更多教程或有投稿需求请点击底部<strong>阅读原文</strong>查看。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/d2/f9/Ioa7bn5x_o.png" alt="88963e98e2660285bcea067e6d3d4cb6.png"><br></p> 
 <p style="text-align:center;"><a href="" rel="nofollow"><img src="https://images2.imgbox.com/8d/d2/owaFbFAo_o.jpg" alt="2e890a40d3f5d841b6c42724f5e1d34b.jpeg"></a></p> 
 <p style="text-align:center;"><a href="" rel="nofollow"><img src="https://images2.imgbox.com/cc/b9/vlRmNQw3_o.jpg" alt="8988ccde560cb5d7e947c004ae91c419.jpeg"></a></p> 
 <p style="text-align:center;"><a href="" rel="nofollow"><img src="https://images2.imgbox.com/26/16/IY5d6ypn_o.jpg" alt="e5958465e556f90b82f23b74d986b2b6.jpeg"></a></p> 
 <p><img src="https://images2.imgbox.com/d2/d6/Mt6vPtAq_o.gif" alt="d6e63a5aa3f6211845568f5ca514f8a5.gif"></p> 
 <p style="text-align:center;">关注【飞桨PaddlePaddle】公众号</p> 
 <p style="text-align:center;">获取更多技术内容~</p> 
 <h3></h3> 
 ‍ 
  
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ab1dddae23895c07ca8d3bacb724d08d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker-compose容器编排与容器监控</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6a9076dd621d20f9ce52936c6e77a39e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python 将模糊图像清晰化</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>