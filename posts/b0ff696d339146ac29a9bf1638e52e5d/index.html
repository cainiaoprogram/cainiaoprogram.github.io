<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>目标检测学习之路——YOLOv3 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="目标检测学习之路——YOLOv3" />
<meta property="og:description" content="相比于YOLOv2，YOLOv3主要做了如下改进：1、提出了新的特征提取器模型Darknet53，该模型相比于Darknet19采用了残差单元（类似ResNet），因此网络模型可以更深；2、采用FPN（feature pyramid networks）结构来实现多尺度预测；3、分类器的改变，使用多个多个 logistic 分类器替代原始的Softmax分类器。
1、Darknet53
Darknet53 与 ResNet-101 或 ResNet-152 准确率接近，但速度更快，对比如下：
检测模型网络结构如下所示：
2、多尺度预测
YOLOv3使用了3个尺度的feature map（当输入图像的分辨率为416×416时3个尺度的feature map为：13×13、26×26、52×52）来预测检测结果。每种尺度预设3个Anchor box（使用k-means聚类的方式得到9个Anchor box，并将其分配到3个不同尺度的feature map上，尺度越大的feature map使用更小的Anchor box，这一做法是为了使模型对小目标物体更友好），检测模型如上图所示：
scale 1：在基础网络的后面添加了一系列的卷积层，经过一系列的卷积操作后输出预测的bounding box信息。
scale 2：将scale1中的倒数第三个卷积层的输出进行1×1的卷积后进行上采样（x2），再与backbone中最后一个26×26的feature map进行concat拼接，之后经过一系列的卷积操作后输出预测的bounding box信息。
scale 3：将scale2中的倒数第三个卷积层的输出进行1×1的卷积后进行上采样（x2），再与backbone中最后一个52×52的feature map进行concat拼接，之后经过一系列的卷积操作后输出预测的bounding box信息。
3、分类器
YOLOv2中预测bounding box中目标所属类别时是用的Softmax分类器，Softmax分类器不适用于多标签分类。因此，在YOLOv3中使用多个独立的logistic 分类器来替代Softmax分类器。
YOLOv3的性能对比如下所示：
可以看出YOLOv3模型的AP值虽然不是最好的，但是在速度方面YOLOv3完胜其它模型方法。YOLOv3 在 mAP-0.5 及小目标 APs 上的优势更加明显，但是随着 IOU的增大，性能开始下降，这说明 YOLOv3 不能很好地与 ground truth 贴合。
以上是自己学习YOLOv3时一些看法以及查阅相关资料的一些总结，如有理解错误之处请指正。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b0ff696d339146ac29a9bf1638e52e5d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-02-20T18:40:55+08:00" />
<meta property="article:modified_time" content="2020-02-20T18:40:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">目标检测学习之路——YOLOv3</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-indent:33px;">相比于YOLOv2，YOLOv3主要做了如下改进：1、提出了新的特征提取器模型Darknet53，该模型相比于Darknet19采用了残差单元（类似ResNet），因此网络模型可以更深；2、采用FPN（feature pyramid networks）结构来实现多尺度预测；3、分类器的改变，使用多个多个 logistic 分类器替代原始的Softmax分类器。</p> 
<p style="text-indent:33px;"><strong>1、Darknet53</strong></p> 
<p style="text-indent:33px;"><img alt="" class="has" height="728" src="https://images2.imgbox.com/71/01/jYnBMOAG_o.png" width="543"></p> 
<p style="text-indent:33px;">Darknet53 与 ResNet-101 或 ResNet-152 准确率接近，但速度更快，对比如下：</p> 
<p style="text-indent:33px;"><img alt="" class="has" height="156" src="https://images2.imgbox.com/b9/90/0ZQmfP4T_o.png" width="650"></p> 
<p style="text-indent:33px;">检测模型网络结构如下所示：</p> 
<p style="text-indent:0;"><img alt="" height="722" src="https://images2.imgbox.com/67/2c/yLqt9QtH_o.png" width="1200"></p> 
<p style="text-indent:33px;"><strong>2、多尺度预测</strong></p> 
<p style="text-indent:33px;">YOLOv3使用了3个尺度的feature map（当输入图像的分辨率为416×416时3个尺度的feature map为：13×13、26×26、52×52）来预测检测结果。每种尺度预设3个Anchor box（使用k-means聚类的方式得到9个Anchor box，并将其分配到3个不同尺度的feature map上，尺度越大的feature map使用更小的Anchor box，这一做法是为了使模型对小目标物体更友好），检测模型如上图所示：</p> 
<p style="text-indent:33px;">scale 1：在基础网络的后面添加了一系列的卷积层，经过一系列的卷积操作后输出预测的bounding box信息。</p> 
<p style="text-indent:33px;">scale 2：将scale1中的倒数第三个卷积层的输出进行1×1的卷积后进行上采样（x2），再与backbone中最后一个26×26的feature map进行concat拼接，之后经过一系列的卷积操作后输出预测的bounding box信息。</p> 
<p style="text-indent:33px;">scale 3：将scale2中的倒数第三个卷积层的输出进行1×1的卷积后进行上采样（x2），再与backbone中最后一个52×52的feature map进行concat拼接，之后经过一系列的卷积操作后输出预测的bounding box信息。</p> 
<p style="text-indent:33px;"><strong>3、分类器</strong></p> 
<p style="text-indent:33px;">YOLOv2中预测bounding box中目标所属类别时是用的Softmax分类器，Softmax分类器不适用于多标签分类。因此，在YOLOv3中使用多个独立的logistic 分类器来替代Softmax分类器。</p> 
<p style="text-indent:33px;">YOLOv3的性能对比如下所示：</p> 
<p style="text-align:center;"><img alt="" height="305" src="https://images2.imgbox.com/63/03/87uEaDC4_o.png" width="868"></p> 
<p style="text-align:center;"><img alt="" height="478" src="https://images2.imgbox.com/58/f3/6ZZJJaxB_o.png" width="808"></p> 
<p style="text-indent:33px;"> 可以看出YOLOv3模型的AP值虽然不是最好的，但是在速度方面YOLOv3完胜其它模型方法。YOLOv3 在 mAP-0.5 及小目标 APs 上的优势更加明显，但是随着 IOU的增大，性能开始下降，这说明 YOLOv3 不能很好地与 ground truth 贴合。</p> 
<p style="text-indent:33px;">以上是自己学习YOLOv3时一些看法以及查阅相关资料的一些总结，如有理解错误之处请指正。</p> 
<p style="text-indent:33px;"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bcdd9820268e0a8823761f660ca85e9d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ImageReader丢帧卡顿的优化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b7d0f8b1f25f3fd35a2b0e1f1226571a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">k8s中正确删除一个pod</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>