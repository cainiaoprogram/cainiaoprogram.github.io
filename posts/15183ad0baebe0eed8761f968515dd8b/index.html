<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CPU-IO-网络-内核参数调优 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CPU-IO-网络-内核参数调优" />
<meta property="og:description" content="一、 有关使用CPU资源的调优
1、 nice概述
在LINUX系统中，Nice值的范围从-20到&#43;19（不同系统的值范围是不一样的），正值表示低优先级，负值表示高优先级，值为零则表示不会调整该进程的优先级。具有最高优先级的程序，其nice值最低，所以在LINUX系统中，值-20使得一项任务变得非常重要；与之相反，如果任务的nice为&#43;19，则表示它是一个高尚的、无私的任务，允许所有其他任务比自己享有宝贵的CPU时间的更大使用份额，这也就是nice的名称的来意。默认优先级是0
2、 调整命令运行优先级，让进城使用更多的CPU资源
语法：nice -n 优先级数字 命令
[root@xuegod120 ~]# nice -n -5 vim a.txt
另外终端查看vim的优先级
[root@xuegod120 ~]# ps -aux | grep vim
root 23305 0.0 0.2 151264 4920 pts/0 S&lt;&#43; 14:45 0:00 vim a.txt
[root@xuegod120 ~]# top -p 23305
3、 使用renice修改正在运行进程的优先级
[root@xuegod120 ~]# renice -n 6 23305
23305 (process ID) old priority -5, new priority 6
4、 进程先级不能超过-20到19
会自动调整为最大和最小的优先级数值
5、 设置CPU的亲和力
taskset 作用：在多核的情况下，可以认为指定一个进程在哪颗CPU上执行程序，减少进程在不同CPU之前切换的开销。
5.1 安装taskset命令" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/15183ad0baebe0eed8761f968515dd8b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-07-28T14:11:31+08:00" />
<meta property="article:modified_time" content="2019-07-28T14:11:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CPU-IO-网络-内核参数调优</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>一、 有关使用CPU资源的调优<br> 1、 nice概述<br> 在LINUX系统中，Nice值的范围从-20到+19（不同系统的值范围是不一样的），正值表示低优先级，负值表示高优先级，值为零则表示不会调整该进程的优先级。具有最高优先级的程序，其nice值最低，所以在LINUX系统中，值-20使得一项任务变得非常重要；与之相反，如果任务的nice为+19，则表示它是一个高尚的、无私的任务，允许所有其他任务比自己享有宝贵的CPU时间的更大使用份额，这也就是nice的名称的来意。默认优先级是0</p> 
<p>2、 调整命令运行优先级，让进城使用更多的CPU资源<br> 语法：nice -n 优先级数字 命令<br> [root@xuegod120 ~]# nice -n -5 vim a.txt<br> 另外终端查看vim的优先级<br> [root@xuegod120 ~]# ps -aux | grep vim<br> root 23305 0.0 0.2 151264 4920 pts/0 S&lt;+ 14:45 0:00 vim a.txt<br> [root@xuegod120 ~]# top -p 23305<br> <img src="https://images2.imgbox.com/3f/5c/306xy3Wh_o.png" alt="在这里插入图片描述"></p> 
<p>3、 使用renice修改正在运行进程的优先级<br> [root@xuegod120 ~]# renice -n 6 23305<br> 23305 (process ID) old priority -5, new priority 6<br> <img src="https://images2.imgbox.com/1f/fa/yohmJGnD_o.png" alt="在这里插入图片描述"><br> 4、 进程先级不能超过-20到19<br> 会自动调整为最大和最小的优先级数值<br> <img src="https://images2.imgbox.com/14/e5/WzirNKhg_o.png" alt="在这里插入图片描述"></p> 
<p>5、 设置CPU的亲和力<br> taskset 作用：在多核的情况下，可以认为指定一个进程在哪颗CPU上执行程序，减少进程在不同CPU之前切换的开销。<br> 5.1 安装taskset命令<br> [root@xuegod120 ~]# yum -y install util-linux</p> 
<p>5.2 taskset的语法<br> taskset -cp [CPU ID号] 命令或进程ID<br> 常用参数：<br> -p：pid 在已经存在的pid上操作<br> -c：cpu-list 以列表格式显示和指定CPU</p> 
<p>例1：调整服务器核心是为4核心，指定vim命令在第一个cpu上运行<br> 使用top命令，按下数字1，可以看到是四核CPU<br> <img src="https://images2.imgbox.com/0e/20/H2ZjpaQB_o.png" alt="在这里插入图片描述"></p> 
<p>指定vim运行在第三个cpu上<br> [root@xuegod120 ~]# taskset -c 2 vim a.txt<br> 在另外一个终端执行<br> [root@xuegod120 ~]# ps -aux | grep vim<br> root 1316 0.5 0.2 151228 4912 pts/0 S+ 14:56 0:00 vim a.txt<br> [root@xuegod120 ~]# taskset -cp 1316<br> pid 1316’s current affinity list: 2<br> <img src="https://images2.imgbox.com/e1/f0/q7ID0sWP_o.png" alt="在这里插入图片描述"></p> 
<p>例2：查看sshd运行在哪个进程<br> [root@xuegod120 ~]# ps -axu | grep sshd<br> root 1005 0.0 0.2 112800 4300 ? Ss 14:55 0:00 /usr/sbin/sshd -D<br> [root@xuegod120 ~]# taskset -cp 1005<br> pid 1005’s current affinity list: 0-3 #0-3，说明sshd可以使用四个cpu处理数据</p> 
<p>例3：指定vim程序运行在第2和第4个cpu上运行<br> [root@xuegod120 ~]# taskset -c 1,3 vim b.txt<br> [root@xuegod120 ~]# ps -aux | grep vim<br> root 1345 0.2 0.2 151236 4892 pts/0 S+ 15:01 0:00 vim b.txt<br> [root@xuegod120 ~]# taskset -cp 1345<br> pid 1345’s current affinity list: 1,3 #1,3表示第二个和第四个cpu运行<br> <img src="https://images2.imgbox.com/3b/9e/sIRcE78E_o.png" alt="在这里插入图片描述"></p> 
<p>6、 使用vmstat找出系统中存在的瓶颈<br> 正常CPU利用率比例分配：<br> 如果一个cpu被充分利用，均衡的比率如下：<br> 65% ­ 70% User Time #用户态（通常指我们运行的服务和程序）。<br> 30% ­ 35% System Time #内核态。<br> 0% ­ 5% Idle Time #空闲。<br> Context Switches ­ 上下文切换的数目直接关系到CPU 的使用率，如果CPU 利用率保持在上述均衡状态时，有大量的上下文切换是正常的。<br> 上下文切换指的就是cpu中寄存器数据的写入和读出。每个进程在使用cpu时，都需要把自己的数据先写入cpu的缓存（寄存器）中，然后cpu才能根据缓存中的数据来计算。</p> 
<p>扩展：<br> 1）Procs（进程）：<br> r: The number of processes waiting for run time.<br> 等待运行的进程数。如果等待运行的进程数越多，意味着CPU非常繁忙。另外，如果该参数长期大于cpu核心数3倍，说明CPU资源可能存在较大的瓶颈。<br> b: The number of processes in uninterruptible sleep.<br> 处在非中断睡眠状态的进程数。即等待IO的进程数量。<br> 2）Memory（内存）：<br> swpd: the amount of virtual memory used.<br> 已使用的虚拟内存大小。如果虚拟内存使用较多，可能系统的物理内存比较吃紧，需要采取合适的方式来减少物理内存的使用。swapd不为0，并不意味物理内存吃紧，如果swapd没变化，si、so的值长期为0,这也是没有问题的 。<br> free: the amount of idle memory.<br> 空闲的物理内存的大小<br> buff: the amount of memory used as buffers.<br> 用来做buffer（缓存，主要用于块设备缓存）的内存数，单位：KB<br> cache: the amount of memory used as cache.<br> 用作缓存的内存大小，如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小。单位：KB<br> 3）Swap（交换分区）<br> si: Amount of memory swapped in from disk (/s).<br> 从磁盘写入到swap虚拟内存的交换页数量，单位：KB/秒。如果这个值大于0，表示物理内存不够用或者内存泄露了。<br> so: Amount of memory swapped to disk (/s).<br> 从swap虚拟内读出的数据。即从swap中的数据写入到磁盘的交换页数量，单位：KB/秒，如果这个值大于0，表示物理内存不够用或者内存泄露了。<br> 内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。<br> 当看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，这个是不正确的。不能光看这一点，还要结合si和so。如果free很少，但是si和so是0，那么不用担心，系统性能这时不会受到影响的。<br> 4）IO（这里指Input/Output Memery的数据，即bi：进入内存，bo：从内存中出去）<br> bi: Blocks received from a block device (blocks/s).<br> 每秒从块设备接收到的块数，单位：块/秒 也就是读块设备。bi通常是读磁盘的数据<br> bo: Blocks sent to a block device (blocks/s).<br> 每秒发送到块设备的块数，单位：块/秒 也就是写块设备。bo通常是写磁盘的数据<br> 5）System（系统）<br> in: The number of interrupts per second, including the clock.<br> 每秒的中断数，包括时钟中断。<br> cs: The number of context switches per second.<br> 每秒的环境（上下文）切换次数。比如我们调用系统函数，就要进行上下文切换，而过多的上下文切换会浪费较多的cpu资源，这个数值应该越小越好。<br> 6）CPU（使用cpu时间的百分比%，最大100%）<br> us: Time spent running non-kernel code. (user time, including nice time)<br> 用户CPU时间(非内核进程占用时间)（单位为百分比）。 us的值比较高时，说明用户进程消耗的CPU时间多<br> sy: Time spent running kernel code. (system time)<br> 系统使用的CPU时间（单位为百分比）。sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。<br> id: Time spent idle. Prior to Linux 2.5.41, this includes IO-wait time.<br> 空闲的CPU的时间(百分比)，在Linux 2.5.41之前，这部分包含IO等待时间。<br> wa: Time spent waiting for IO. Prior to Linux 2.5.41, shown as zero.<br> 等待IO的CPU时间，这个值为0 .这个指标意味着CPU在等待硬盘读写操作的时间，用百分比表示。wait越大则机器io性能就越差。说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。<br> st: 虚拟机占用cpu时间的百分比。如果centos系统上运行了kvm虚拟机，而kvm虚拟上又运行了几个虚拟机，那么这个值将显示这个几个正在运行的虚拟机从物理机中窃取CPU运行时间的百分比。</p> 
<p>例1：一台4核心，2G内存的服务器，根据vmstat运行的结果，来分析系统中存在的问题。大家一定要认真学习这个4核心，2G内存查找系统瓶颈的思路。只要用心学会这个思路，后期就可以很轻松分析出8核心，16G或8核心，32G服务器的瓶颈。</p> 
<p>系统刚开机后，vmstat的状态如下：<br> [root@xuegod120 ~]# vmstat 1 10<br> <img src="https://images2.imgbox.com/21/84/3R0galhZ_o.png" alt="在这里插入图片描述"><br> 第1列：有一个r，很多次0，说明当前系统中正在运行的程序不多，此值大于cpu核心数的3倍，就可以认为cpu是繁忙的，我们现在是4核，那么大于12，才能说是繁忙的<br> 第4列：free是物理内存剩余数，默认单位是KB，先剩余1786492KB，大约1.7G，总共2G，所有内存肯定是够用的<br> 第7/8列：swap是swap内存交换分区使用情况。如果这两列有数据，说明内存不够用了，已经开始使用swap的硬盘空间<br> 第9/10列：如果io组数据中bi比较大，说明从磁盘中读取内存的数据比较大，即读取磁盘数据多。反之bo比较大，说明从内存中写入到磁盘的数据比较多。<br> 第13/15列：us是用户太进程使用CPU时间的百分比，如果us列数据比较大，说明用户太进程使用的cpu较多，比如apache、mysql等。id这列是cpu空闲时间百分比，id列最大是100%<br> 第16列：wa表示等待IO所消耗的cpu百分比。如果wa列较大，达到40%，说明磁盘读写性能很慢了，io有瓶颈了。如果bi列值很大，说明进程在等待写入磁盘的数据时，占用了大量的cpu。</p> 
<p>例2：向服务器上传一个大的文件，分析系统使用的资源情况<br> <img src="https://images2.imgbox.com/61/07/tsFovdUg_o.png" alt="在这里插入图片描述"><br> 因为我们是将文件上传到服务器，没有读取硬件，只有写入，所以bi的值基本为0；但是bo的值可以看到有明显的变化<br> 看其它列的数据变化不大，说明cpu、内存、io都可以，压力不大。</p> 
<p>例3：拷贝刚刚上传的文件，模拟生产环境下的备份场景<br> <img src="https://images2.imgbox.com/17/14/xT1PU6hi_o.png" alt="在这里插入图片描述"><br> 因为是复制文件，所以bi和bo的值都很大。即从硬盘到内存和从内存到硬盘的值都很大<br> r列的数值不大，说明正在运行的程序不多；<br> free列的数据不大，说明内存也是够用的；<br> 查看us列、sy列的数据也不大，说明使用的cpu占比也不大。单是wa列中间有等待的百分比，说明在复制数据的时候，有大量的进程在等待中，表示磁盘的IO可能不足。</p> 
<p>例4：使用ab压测工具，测试服务器的处理性能<br> [root@xuegod120 ~]# yum -y install httpd<br> [root@xuegod120 ~]# systemctl start httpd<br> [root@xuegod120 ~]# cp /etc/passwd /var/www/html/index.html<br> [root@xuegod120 ~]# ab -n 500000 -c 200 <a href="http://192.168.0.120/index.html" rel="nofollow">http://192.168.0.120/index.html</a><br> <img src="https://images2.imgbox.com/ee/4a/Q3FWUIuB_o.png" alt="在这里插入图片描述"><br> 结论：<br> r列的数值可以看到有很多已经超过12了，说明cpu的核心不够用。wa列为0，说明在读写磁盘在等待上没有占用cpu，这样情况就是服务器上运行了大量的进程，在消耗cpu。可以使用ps查看是哪个进程在大量消耗cpu资源。<br> 可以通过top命令，然后按下大写P，对cpu的使用占比进行排序，查看消耗大量cpu进程的名字<br> 也可以用ps -aux –sort -cpu 命令，直接查看cpu的使用百分比。</p> 
<p>二、 有关磁盘I/O调优<br> 1、 ulimit资源限制<br> 通过修改配置文件/etc/security/limits.com，修改ulimit的值<br> 增加内容的格式如下：<br> 用户名/@用户组名 类型(软限制/硬限制) 选项 值</p> 
<p>例1：修改配置文件<br> [root@xuegod120 ~]# vim /etc/security/limits.conf #在文件的最后追加以下内容</p> 
<ul><li> <pre><code>          soft   nofile            1024000
</code></pre> </li><li> <pre><code>          hard   nofile           1024000            #重启系统后生效
</code></pre> </li></ul> 
<p>注：soft是一个警告值，而hard则是一个真正意义的阀值，超过就会报错。一般把soft和hard都配置成一样的值。 最大打开的文件数以文件描叙符file descripter计数)。</p> 
<p>例2：通过命令修改<br> 查看ulimint的值<br> [root@xuegod120 ~]# ulimit -n<br> 1024</p> 
<p>修改ulimit的值<br> [root@xuegod120 ~]# ulimit -n 2048 #临时生效，修改配置文件的是重启系统后永久生效</p> 
<p>总结：两种修改ulimit的方式，修改配置的方式，需要重启系统后才能生效。通过命令修改的值，可以立即生效，但是重启系统后会自动丢失<br> ulimit -n size ：表示打开进程数的个数限制；<br> ulimit -u size ：表示用户启动进程数的限制</p> 
<p>例3：查看系统的所有资源<br> [root@xuegod120 ~]# ulimit -a<br> core file size (blocks, -c) 0 #kdump转储功能开启后生成的core file文件大小限制<br> data seg size (kbytes, -d) unlimited #数据段大小显示<br> scheduling priority (-e) 0<br> file size (blocks, -f) unlimited #文件大小限制<br> pending signals (-i) 7834<br> max locked memory (kbytes, -l) 64<br> max memory size (kbytes, -m) unlimited<br> open files (-n) 1024000 #打开文件个数限制<br> pipe size (512 bytes, -p) 8 #管道文件大小限制<br> POSIX message queues (bytes, -q) 819200 #消息队列大小<br> real-time priority (-r) 0<br> stack size (kbytes, -s) 8192 #栈大小<br> cpu time (seconds, -t) unlimited #CPU使用时间限制<br> max user processes (-u) 7834 #最大用户进程数限制<br> virtual memory (kbytes, -v) unlimited #虚拟内存限制<br> file locks (-x) unlimited</p> 
<p>2、 测试硬盘速度<br> hdparm命令是测试磁盘顺序读的速度，dd命令用来测试磁盘顺序写的速度<br> hdparm命令常用参数：<br> -t perform device read timings #不使用预先的数据缓冲, 标示了Linux下没有任何文件系统开销时磁盘可以支持多快的连续数据读取. perform [pəˈfɔ:m] #执行<br> –direct Use O_DIRECT to bypass page cache for timings #直接绕过缓存进行统计数据<br> 例1：测试硬盘读速度<br> [root@xuegod120 ~]# hdparm -t --direct /dev/sda<br> /dev/sda:<br> Timing O_DIRECT disk reads: 3080 MB in 3.08 seconds = 1000.82 MB/sec<br> 注： 弹出的含意是3.08秒中从硬盘缓存中读3080M，平均每秒读1000.82MB。</p> 
<p>例2：测试硬盘写的速度<br> [root@xuegod120 ~]# dd if=/dev/zero of=a.txt bs=10M count=100 oflag=direct,nonblock<br> 100+0 records in<br> 100+0 records out<br> 1048576000 bytes (1.0 GB) copied, 9.22881 s, 114 MB/s<br> 注：在大约9.3S的时间里，生成了1G的数据，IO的写速度为114MB/S，这个值可以多测试几次，取平均值为准。</p> 
<p>3、 time命令测试进程运行时间<br> 例1： 测试dd 命令使用时间和开销<br> [root@xuegod120 ~]# time dd if=/dev/zero of=/test.dbf bs=1M count=200<br> 记录了200+0 的读入<br> 记录了200+0 的写出<br> 209715200字节(210 MB)已复制，3.79592 秒，55.2 MB/秒<br> real 0m4.225s<br> user 0m0.002s<br> sys 0m2.624s<br> 注释：<br> 1)实际时间(real time): 从command命令行开始执行到运行终止的消逝时间；<br> 2)用户CPU时间(user CPU time): 命令执行完成花费的用户CPU时间，即命令在用户态中执行时间总和；<br> 3)系统CPU时间(system CPU time): 命令执行完成花费的系统CPU时间，即命令在核心态中执行时间总和。<br> 其中，用户CPU时间和系统CPU时间之和为CPU时间，即命令占用CPU执行的时间总和。实际时间要大于CPU时间，因为Linux是多任务操作系统，往往在执行一条命令时，系统还要处理其它任务。排队时间没有算在里面。<br> 另一个需要注意的问题是即使每次执行相同命令，但所花费的时间也是不一样，其花费时间是与系统运行相关的。</p> 
<p>三、 网络相关调优<br> 1、 网卡绑定技术<br> 网卡绑定概述：网卡绑定也称作"网卡捆绑"，就是使用多块物理网卡虚拟成为一块网卡，以提供负载均衡或者冗余，增加带宽的作用。当一个网卡坏掉时，不会影响业务。这个聚合起来的设备看起来是一个单独的以太网接口设备，也就是这几块网卡具有相同的IP地址而并行链接聚合成一个逻辑链路工作。这种技术在Cisco等网络公司中，被称为Trunking和Etherchannel 技术，在Linux的内核中把这种技术称为bonding。</p> 
<p>2、 bonding技术分类<br> 2.1 负载均衡<br> 对于bonding的网络负载均衡是我们在文件服务器中常用到的，比如把三块网卡，当做一块来用，解决一个IP地址，流量过大，服务器网络压力过大的问题。为了解决同一个IP地址，突破流量的限制，毕竟网线和网卡对数据的吞吐量是有限制的。如果在有限的资源的情况下，实现网络负载均衡，最好的办法就是 bonding。</p> 
<p>2.2 网络冗余<br> 对于服务器来说，网络设备的稳定也是比较重要的，特别是网卡。在生产型的系统中，网卡的可靠性就更为重要了。在生产型的系统中，大多通过硬件设备的冗余来提供服务器的可靠性和安全性，比如电源。bonding 也能为网卡提供冗余的支持。把多块网卡绑定到一个IP地址，当一块网卡发生物理性损坏的情况下，另一块网卡自动启用，并提供正常的服务，即：默认情况下只有一块网卡工作，其它网卡做备份。</p> 
<p>3、 配置多网卡绑定<br> 环境准备，给服务器添加两块网卡，并且都配置桥接模式<br> <img src="https://images2.imgbox.com/19/d6/7UF3qGVN_o.png" alt="在这里插入图片描述"><br> 实验目标：实现active-backup主备模式，即一个网卡处于活跃状态，另一个处于备份状态，当活跃网卡down掉时，启用备份网卡。绑定网卡：ens33+ens38=bond0。<br> 设置网卡ens33为主网卡(优先处于活跃状态)，ens38为辅网卡(备份状态，主网卡链路正常时，辅网卡处于备份状态)。</p> 
<p>3.1 移除网卡配置文件<br> 因为两块网卡是绑定在一起使用的，绑定后的使用的配置文件是bond0文件，所以需要移除两块网卡的配置文件<br> [root@xuegod120 ~]# cd /etc/sysconfig/network-scripts/<br> [root@xuegod120 network-scripts]# mv ifcfg-ens* /tmp/</p> 
<p>3.2 使用nmcli命令配置生成bond0配置文件<br> [root@xuegod120 network-scripts]# nmcli connection add type bond ifname bond0 con-name bond0 miimon 100 mode active-backup primary ens33 ipv4.addresses 172.20.10.4/24<br> Connection ‘bond0’ (7f8975ab-2b43-45d1-8de2-58eed88be450) successfully added.<br> 参数说明：<br> add type bond ifname bond0 #添加一个类型为bond，网卡名为bond0的设备<br> con-name bond0 miimon 100 #配置name为bond0的链路监控的频率为100毫秒。<br> mode active-backup #指定bond0模式为active-backup（主动备份）<br> primary ens33 #指定主网卡为ens33<br> ipv4.addresses #指定IP地址为172.20.10.4<br> 配置完成后，会在网卡配置文件目录下生成一个ifcfg-bond0的配置文件<br> [root@xuegod120 network-scripts]# ll ifcfg-bond0<br> -rw-r–r-- 1 root root 383 Jul 27 18:34 ifcfg-bond0</p> 
<p>3.3 修改配置文件，增加网关和DNS<br> [root@xuegod63 network-scripts]# vim ifcfg-bond0 #在文件的最后插入网关和DNS<br> 在第9行之后：<br> 8 IPADDR=172.20.10.4<br> 9 PREFIX=24<br> 插入：<br> GATEWAY=172.20.10.1<br> DNS1=114.114.114.114</p> 
<p>3.4 将网卡ens33绑定到bond0,<br> [root@xuegod120 ~]# nmcli connection add type bond-slave ifname ens33 master bond0<br> Connection ‘bond-slave-ens33’ (3ed5c762-343b-45e9-9c94-6702e07947ca) successfully added.<br> [root@xuegod120 ~]# nmcli connection add type bond-slave ifname ens38 master bond0<br> Connection ‘bond-slave-ens38’ (87ffa332-f3ce-4cb8-b088-31b5a98d47cd) successfully added.</p> 
<p>3.5 查看配置文件<br> [root@xuegod120 ~]# ll /etc/sysconfig/network-scripts/ifcfg-bond*<br> -rw-r–r-- 1 root root 424 Jul 27 18:40 /etc/sysconfig/network-scripts/ifcfg-bond0<br> -rw-r–r-- 1 root root 125 Jul 27 18:41 /etc/sysconfig/network-scripts/ifcfg-bond-slave-ens33<br> -rw-r–r-- 1 root root 125 Jul 27 18:41 /etc/sysconfig/network-scripts/ifcfg-bond-slave-ens38<br> [root@xuegod120 ~]# systemctl restart network</p> 
<p>3.6 查看已激活的网络接口<br> [root@xuegod120 ~]# nmcli connection show –active<br> <img src="https://images2.imgbox.com/e8/25/QTr8Dwkd_o.png" alt="在这里插入图片描述"></p> 
<p>3.7 查看当前bond0的状态<br> [root@xuegod120 ~]# cat /proc/net/bonding/bond0<br> Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)</p> 
<p>Bonding Mode: fault-tolerance (active-backup)<br> Primary Slave: ens33 (primary_reselect always)<br> Currently Active Slave: ens33 #当前使用的端口，状态是active<br> MII Status: up<br> MII Polling Interval (ms): 100<br> Up Delay (ms): 0<br> Down Delay (ms): 0</p> 
<p>Slave Interface: ens33 #从接口<br> MII Status: up #链接状态<br> Speed: 1000 Mbps<br> Duplex: full<br> Link Failure Count: 0<br> Permanent HW addr: 00:0c:29:8f:23:87<br> Slave queue ID: 0</p> 
<p>Slave Interface: ens38 #从接口<br> MII Status: up #链接状态<br> Speed: 1000 Mbps<br> Duplex: full<br> Link Failure Count: 0<br> Permanent HW addr: 00:0c:29:8f:23:91<br> Slave queue ID: 0<br> [root@xuegod120 ~]#</p> 
<p>4、 测试bonding主备高可用切换<br> 持续ping网关，然后断掉其中一块网卡，测试网络是否正常<br> <img src="https://images2.imgbox.com/26/19/opVjxBU3_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/65/2c/5pxvel3Y_o.png" alt="在这里插入图片描述"><br> 如果端口后，发现网络还是正常的，就说明网卡绑定配置成功</p> 
<p>5、 查看网卡连接<br> [root@xuegod120 ~]# cat /proc/net/bonding/bond0<br> Ethernet Channel Bonding Driver: v3.7.1 (April 27, 2011)<br> Bonding Mode: fault-tolerance (active-backup)<br> Primary Slave: ens33 (primary_reselect always)<br> Currently Active Slave: ens38 #原来的接口为ens33，目前变为ens38<br> 。。。<br> Slave Interface: ens38<br> MII Status: up<br> 。。。<br> Slave Interface: ens33<br> MII Status: down #已经down了</p> 
<p>6、 网卡绑定的几种模式<br> 常用的模式mode是0、1、4、6这几种模式。具体如下：<br> balance-rr (0) –轮询模式，负载均衡（bond默认的模式）<br> active-backup (1) –主备模式（常用）<br> balance-xor (2)<br> broadcast (3）<br> 802.3ad (4) –聚合模式<br> balance-tlb (5)<br> balance-alb (6)<br> 详情如下：<br> mode=0 #默认是mode=0, 有高可用 (容错) 和负载均衡的功能, 需要交换机的配置，每块网卡轮询发包 (流量分发比较均衡)，mode 0下bond所绑定的网卡的IP都被修改成相同的mac地址，如果这些网卡都被接在同一个交换机，那么交换机的arp表里这个mac地址对应的端口就有多个，那么交换机接受到发往这个mac地址的包应该往哪个端口转发呢？正常情况下mac地址是全球唯一的，一个mac地址对应多个端口肯定使交换机迷惑了。所以 mode0下的bond如果连接到交换机，交换机这几个端口应该采取聚合方式（cisco称为ethernetchannel），因为交换机做了聚合后，聚合下的几个端口也被捆绑成一个mac地址。若我们不配置，我们的解 决办法是，两个网卡接入不同的交换机即可。<br> mode=1 #只有一个设备处于活动状态，当一个宕掉另一个马上由备份转换为主设备。mac地址是外部可见得，从外面看来，bond的MAC地址是唯一的，以避免switch(交换机)发生混乱。此模式只提供了容错能力；由此可见此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有 N 个网络接口的情况下，资源利用率为1/N<br> mode=2 #基于指定的传输HASH策略传输数据包。缺省的策略是：(源MAC地址 XOR 目标MAC地址) % slave数量。其他的传输策略可以通过xmit_hash_policy选项指定，此模式提供负载平衡和容错能力。<br> mode=3 #在每个slave接口上传输每个数据包，此模式提供了容错能力，非常不常用<br> mode=4 #创建一个聚合组，它们共享同样的速率和双工设定。根据802.3ad规范将多个slave工作在同一个激活的聚合体下。外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要几个必要条件：<br> ethtool支持获取每个slave的速率和双工设定<br> switch(交换机)支持IEEE 802.3ad Dynamic link aggregation<br> 大多数switch(交换机)需要经过特定配置才能支持802.3ad模式<br> mode=5 #不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。该模式的必要条件：ethtool支持获取每个slave的速率<br> mode=6 #模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡(receive load<br> balance, rlb)，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。bonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个slave的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。来自服务器端的接收流量也会被均衡。当本机发送ARP请求时，bonding驱动把对端的IP信息从ARP包中复制并保存下来。当ARP应答从对端到达 时，bonding驱动把它的硬件地址提取出来，并发起一个ARP应答给bond中的某个slave。使用ARP协商进行负载均衡的一个问题是：每次广播 ARP请求时都会使用bond的硬件地址，因此对端学习到这个硬件地址后，接收流量将会全部流向当前的slave。这个问题可以通过给所有的对端发送更新 （ARP应答）来解决，应答中包含他们独一无二的硬件地址，从而导致流量重新分布。当新的slave加入到bond中时，或者某个未激活的slave重新 激活时，接收流量也要重新分布。接收的负载被顺序地分布（round robin）在bond中最高速的slave上当某个链路被重新接上，或者一个新的slave加入到bond中，接收流量在所有当前激活的slave中全部重新分配，通过使用指定的MAC地址给每个 client起ARP应答。下面介绍的updelay参数必须被设置为某个大于等于switch(交换机)转发延时的值，从而保证发往对端的ARP应答 不会被switch(交换机)阻截。</p> 
<p>四、 系统内核相关参数调优<br> 1、 SYN洪水攻击<br> SYN攻击是利用TCP/IP协议3次握手的原理，发送大量的建立连接的网络包，但不实际建立连接，最终导致被攻击服务器的网络队列被占满，无法被正常用户访问。</p> 
<p>原理图：<br> <img src="https://images2.imgbox.com/9e/83/5uejLYYD_o.png" alt="在这里插入图片描述"><br> SYN Flood是当前最流行的DoS（拒绝服务攻击）与DDoS（分布式拒绝服务攻击）的方式之一，这是一种利用TCP协议缺陷，发送大量伪造的TCP连接请求，常用假冒的IP或IP号段发来的海量请求连接的第一个握手包（SYN包），被攻击服务器回应第二个握手包（SYN+ACK包），因为对方是假冒IP，对方永远收不到包且不会回应第三个握手包。导致被攻击服务器保持大量SYN_RECV状态的“半连接”，并且会重试默认5次回应第二个握手包，塞满TCP等待连接队列，资源耗尽（CPU满负荷或内存不足），让正常的业务请求连接不进来。<br> 解决：<br> [root@xuegod120 ~]# vim /etc/sysctl.conf #在文件最后添加以下内容<br> net.ipv4.tcp_synack_retries = 0<br> net.ipv4.tcp_syn_retries = 1<br> net.ipv4.tcp_max_syn_backlog = 20480<br> net.ipv4.tcp_syncookies = 1<br> net.ipv4.tcp_tw_reuse = 1<br> net.ipv4.tcp_tw_recycle = 1<br> net.ipv4.tcp_fin_timeout = 10<br> fs.file-max = 819200<br> net.core.somaxconn = 65535<br> net.core.rmem_max = 1024123000<br> net.core.wmem_max = 16777216<br> net.core.netdev_max_backlog = 165536<br> net.ipv4.ip_local_port_range = 10000 65535<br> 注：每台服务器上线之前，都应该配置以上内核参数。</p> 
<p>2、 内核重要参数解说<br> [root@xuegod120 ~]# cat /proc/sys/net/ipv4/tcp_synack_retries #最关键参数，默认为5，修改为0 表示不要重发<br> net.ipv4.tcp_synack_retries = 0<br> #表示回应第二个握手包（SYN+ACK包）给客户端IP后，如果收不到第三次握手包（ACK包）后，不进行重试，加快回收“半连接”，不要耗光资源。<br> #作为服务端。回应时，如果连接失败，达到对应的失败数后，停止发送synack包<br> 第一个参数tcp_synack_retries = 0是关键，表示回应第二个握手包（SYN+ACK包）给客户端IP后，如果收不到第三次握手包（ACK包）后，不进行重试，加快回收“半连接”，不要耗光资源。<br> 不修改这个参数，模拟攻击，10秒后被攻击的80端口即无法服务，机器难以ssh登录； 用命令netstat -na |grep SYN_RECV检测“半连接”hold住180秒；<br> 修改这个参数为0，再模拟攻击，持续10分钟后被攻击的80端口都可以服务，响应稍慢些而已，只是ssh有时也登录不上；检测“半连接”只hold住3秒即释放掉。<br> 修改这个参数为0的副作用：网络状况很差时，如果对方没收到第二个握手包，可能连接服务器失败，但对于一般网站，用户刷新一次页面即可。这些可以在高峰期或网络状况不好时tcpdump抓包验证下。<br> 根据以前的抓包经验，这种情况很少，但为了保险起见，可以只在被tcp洪水攻击时临时启用这个参数。<br> tcp_synack_retries默认为5，表示重发5次，每次等待30~40秒，即“半连接”默认hold住大约180秒。<br> 我们之所以可以把tcp_synack_retries改为0，因为客户端还有tcp_syn_retries参数，默认是5，即使服务器端没有重发SYN+ACK包，客户端也会重发SYN握手包。<br> [root@xuegod63 ~]# cat /proc/sys/net/ipv4/tcp_syn_retries<br> 1<br> #tcp_syn_retries参数，默认是5，当没有收到服务器端的SYN+ACK包时，客户端重发SYN握手包的次数。<br> [root@xuegod63 ~]# cat /proc/sys/net/ipv4/tcp_max_syn_backlog<br> 20480<br> ##半连接队列长度，增加SYN队列长度到2048：加大SYN队列长度可以容纳更多等待连接的网络连接数，具体多少数值受限于内存。</p> 
<p>3、 辅助参数<br> #系统允许的文件句柄的最大数目，因为连接需要占用文件句柄<br> fs.file-max = 819200<br> #用来应对突发的大并发connect 请求<br> net.core.somaxconn = 65535<br> #最大的TCP 数据接收缓冲（字节）<br> net.core.rmem_max = 1024123000<br> #最大的TCP 数据发送缓冲（字节）<br> net.core.wmem_max = 16777216<br> #网络设备接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目<br> net.core.netdev_max_backlog = 165536<br> #本机主动连接其他机器时的端口分配范围，比如说，在vsftpd主动模式会用到<br> net.ipv4.ip_local_port_range = 10000 65535<br> 注：如果只是开启22端口，是不会使用到ip_local_port_range这个功能<br> [root@xuegod120 ~]# netstat -antup | grep :22<br> tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1993/sshd<br> tcp 0 0 192.168.1.63:22 192.168.1.23:51855 ESTABLISHED 9316/sshd<br> tcp 0 0 192.168.1.63:22 192.168.1.23:51861 ESTABLISHED 10878/sshd<br> 为了处理大量连接，还需改大另外两个参数：<br> 限制用户资源配置文件：/etc/security/limits.conf<br> [root@xuegod120 ~]#vim /etc/security/limits.conf #在最添加：</p> 
<ul><li> <pre><code>          soft   nofile            1024000
</code></pre> </li><li> <pre><code>          hard   nofile           1024000
</code></pre> </li></ul> 
<p>例2：nproc #用户可以打开的最大进程数<br> [root@xuegod120 ~]# vim /etc/security/limits.d/90-nproc.conf #RHEL6 必须这个文件中配置<br> 改：</p> 
<ul><li> <pre><code>     soft    nproc     10240
</code></pre> </li></ul> 
<p>为：</p> 
<ul><li> <pre><code>     soft    nproc     66666
</code></pre> </li><li> <pre><code>     hard    nproc     66666 
</code></pre> </li></ul> 
<p>[root@xuegod120 ~]# reboot #最好重启一下</p> 
<p>4、 次要辅助参数<br> 以上还无法解决syn洪水攻击，把以下内核参数关闭： <br> 注意，以下参数面对外网时，不要打开。因为副作用很明显。<br> #当出现 半连接 队列溢出时向对方发送syncookies，调大 半连接 队列后没必要<br> net.ipv4.tcp_syncookies = 0<br> #TIME_WAIT状态的连接重用功能<br> net.ipv4.tcp_tw_reuse = 0<br> #时间戳选项，与前面net.ipv4.tcp_tw_reuse参数配合<br> net.ipv4.tcp_timestamps = 0<br> #TIME_WAIT状态的连接回收功能<br> net.ipv4.tcp_tw_recycle = 0<br> [root@xuegod120 ~]# cat /proc/sys/net/ipv4/tcp_syncookies<br> 1<br> #表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭；<br> [root@xuegod120 ~]# cat /proc/sys/net/ipv4/tcp_tw_reuse<br> 1<br> #表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭，现在开启，改为1<br> [root@xuegod120 ~]# cat /proc/sys/net/ipv4/tcp_tw_recycle<br> 1<br> #表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。现在改为1，表示开启<br> [root@xuegod120 ~]# cat /proc/sys/net/ipv4/tcp_fin_timeout<br> 30<br> #默认值是 60，对于本端断开的socket连接，TCP保持在FIN_WAIT_2状态的时间。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9bb92cd48a1e4e899010caeab1ab8f8b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Kafka学习之旅(六): Kafka生产者通信</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7e260e8baca571eb2d07cf805f0a3603/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【touch screen】Qt触摸屏原理及实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>