<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>反爬虫与反反爬虫技术 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="反爬虫与反反爬虫技术" />
<meta property="og:description" content="1.反爬虫技术 首先我们来思考一下，为什么要反爬虫？
网络中充斥大量爬虫的情况下，会使得整个网络的数据不可靠。网站在面对高并发爬虫的攻击时，很容易被击溃。版权数据被爬取，对于网站来说是巨大的损失。 基于以上原因，反爬虫技术孕育而生，主要包含以下最常用的反爬技术：
封IP
后台对访问进行统计，如果单个IP访问超过阈值，则封锁该IP。封UserAgent
后台对访问进行统计，如果单个UserAgent访问超过阈值，则封锁该UserAgent。封Cookie
后台对访问进行统计，如果单个cookies访问超过阈值，则封锁该cookie.设置请求时间间隔
设置请求时间间隔，规避过于频繁的请求访问，避免爬虫短时间爬取大量数据。robots.txt协议
robots.txt是一个限制爬虫的规范，该文件是用来声明哪些东西不能被爬取； 设置robots.txt协议，位于robots.txt中的UserAgent不可请求网站数据。验证码验证
发生大量请求时，弹出验证码验证，通过验证方可继续访问。JavaScript渲染网页
将重要信息放在网页中但不写入html标签中，而浏览器会自动渲染标签中的js代码，将信息展现在浏览器当中，而爬虫是不具备执行js代码的能力，所以无法将js事件产生的信息读取出来。ajax异步传输
访问网页的时候服务器将网页框架返回给客户端，在与客户端交互的过程中通过异步ajax技术传输数据包到客户端，呈现在网页上，爬虫直接抓取的话信息为空。网页iframe框架嵌套
在下载框处再内嵌一个窗口，使得爬虫提取不到内层窗口的数据。 2.反反爬虫技术 有反爬虫技术，就会有反反爬虫技术存在，这是两种相互对抗的技术；这两种技术也在相互对抗中不断发展。
我们在编写爬虫时，要对获取海量的免费数据心怀感恩，而不是恶意攻击网站，这是一种害人害己的形为。
常用的反反爬虫技术有以下这些：
降低请求频率
对于基于scrapy框架构建的爬虫，在配置文件settings.py中设置DOWN-LAOD_DELAY即可。
以下代码设置下载延迟时间为4秒，即两次请求间隔4秒。 DWONLOAD_DELAY = 4 或设置RANDOMIZE_DOWNLOAD_DELAY，定义一个随机的请求延迟时间。
RANDOMIZE_DOWNLOAD_DELAY = True 修改请求头
禁用Cookie
有些网站会通过Cookie来发现爬虫的轨迹，如非特殊需要，禁用Cookie可以切断网站通过Cookie发现爬虫的途径。
对于基于scrapy框架构建的爬虫，在配置文件settings.py中设置COOKIES_ENABLED即可。 #Disable cookies (enabled by default) COOKIES_ENABLED = False 伪装成不同的浏览器
Scrapy自带专门设置User-Agent的中间件UserAgentMiddleware，在爬虫运行中，会自动将User-Agent添加到HTTP请求中，并且可以设置多个浏览器，请求时可以随机添加不同的浏览器。 1.设定浏览器列表。
将浏览器列表定义至settings.py文件中：
MY_USER_AGENT = [&#34;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NETCLR 1.1.4322; .NET CLR 2.0.50727)&#34;, \ &#34;Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser;SLCC1; ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/cb7a2cedd09d30584c06465114dccdca/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-18T19:41:11+08:00" />
<meta property="article:modified_time" content="2021-08-18T19:41:11+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">反爬虫与反反爬虫技术</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="1_0"></a>1.反爬虫技术</h4> 
<p>首先我们来思考一下，为什么要反爬虫？</p> 
<ul><li>网络中充斥大量爬虫的情况下，会使得整个网络的数据不可靠。</li><li>网站在面对高并发爬虫的攻击时，很容易被击溃。</li><li>版权数据被爬取，对于网站来说是巨大的损失。</li></ul> 
<p>基于以上原因，反爬虫技术孕育而生，主要包含以下最常用的反爬技术：</p> 
<ul><li>封IP<br> 后台对访问进行统计，如果单个IP访问超过阈值，则封锁该IP。</li><li>封UserAgent<br> 后台对访问进行统计，如果单个UserAgent访问超过阈值，则封锁该UserAgent。</li><li>封Cookie<br> 后台对访问进行统计，如果单个cookies访问超过阈值，则封锁该cookie.</li><li>设置请求时间间隔<br> 设置请求时间间隔，规避过于频繁的请求访问，避免爬虫短时间爬取大量数据。</li><li>robots.txt协议<br> robots.txt是一个限制爬虫的规范，该文件是用来声明哪些东西不能被爬取； 设置robots.txt协议，位于robots.txt中的UserAgent不可请求网站数据。</li><li>验证码验证<br> 发生大量请求时，弹出验证码验证，通过验证方可继续访问。</li><li>JavaScript渲染网页<br> 将重要信息放在网页中但不写入html标签中，而浏览器会自动渲染标签中的js代码，将信息展现在浏览器当中，而爬虫是不具备执行js代码的能力，所以无法将js事件产生的信息读取出来。</li><li>ajax异步传输<br> 访问网页的时候服务器将网页框架返回给客户端，在与客户端交互的过程中通过异步ajax技术传输数据包到客户端，呈现在网页上，爬虫直接抓取的话信息为空。</li><li>网页iframe框架嵌套<br> 在下载框处再内嵌一个窗口，使得爬虫提取不到内层窗口的数据。</li></ul> 
<h4><a id="2_28"></a>2.反反爬虫技术</h4> 
<p>有反爬虫技术，就会有反反爬虫技术存在，这是两种相互对抗的技术；这两种技术也在相互对抗中不断发展。</p> 
<p>我们在编写爬虫时，要对获取海量的免费数据心怀感恩，而不是恶意攻击网站，这是一种害人害己的形为。</p> 
<p>常用的反反爬虫技术有以下这些：</p> 
<hr> 
<ul><li>降低请求频率<br> 对于基于scrapy框架构建的爬虫，在配置文件settings.py中设置DOWN-LAOD_DELAY即可。<br> 以下代码设置下载延迟时间为4秒，即两次请求间隔4秒。</li></ul> 
<pre><code class="prism language-python">DWONLOAD_DELAY <span class="token operator">=</span> <span class="token number">4</span>
</code></pre> 
<p>或设置RANDOMIZE_DOWNLOAD_DELAY，定义一个随机的请求延迟时间。</p> 
<pre><code class="prism language-python">RANDOMIZE_DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token boolean">True</span>
</code></pre> 
<hr> 
<ul><li>修改请求头<br> <img src="https://images2.imgbox.com/e7/18/jynDauvB_o.jpg" alt="在这里插入图片描述"></li></ul> 
<hr> 
<ul><li>禁用Cookie<br> 有些网站会通过Cookie来发现爬虫的轨迹，如非特殊需要，禁用Cookie可以切断网站通过Cookie发现爬虫的途径。<br> 对于基于scrapy框架构建的爬虫，在配置文件settings.py中设置COOKIES_ENABLED即可。</li></ul> 
<pre><code class="prism language-python"><span class="token comment">#Disable cookies (enabled by default)</span>
COOKIES_ENABLED <span class="token operator">=</span> <span class="token boolean">False</span>
</code></pre> 
<hr> 
<ul><li>伪装成不同的浏览器<br> Scrapy自带专门设置User-Agent的中间件UserAgentMiddleware，在爬虫运行中，会自动将User-Agent添加到HTTP请求中，并且可以设置多个浏览器，请求时可以随机添加不同的浏览器。</li></ul> 
<p>1.设定浏览器列表。<br> 将浏览器列表定义至settings.py文件中：</p> 
<pre><code class="prism language-python">MY_USER_AGENT <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; AcooBrowser; .NETCLR 1.1.4322; .NET CLR 2.0.50727)"</span><span class="token punctuation">,</span> \
                 <span class="token string">"Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 6.0; Acoo Browser;SLCC1; .NET CLR 2.0.50727; Media Center PC 5.0; .NET CLR 3.0.04506)"</span><span class="token punctuation">,</span> \
                 <span class="token string">"Mozilla/4.0 (compatible; MSIE 7.0; AOL 9.5; AOLBuild 4337.35; WindowsNT 5.1; .NET CLR 1.1.4322; .NET CLR 2.0.50727)"</span><span class="token punctuation">,</span> 
                 <span class="token punctuation">]</span>
</code></pre> 
<p>2.在中间件UserAgentMiddleware中从浏览器列表中随机获取一个浏览器。</p> 
<pre><code class="prism language-python"><span class="token comment">#导入UserAgentMiddleware组件模块</span>

<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>downloadermiddlewares<span class="token punctuation">.</span>useragent <span class="token keyword">import</span> UserAgentMiddleware
<span class="token keyword">import</span> random                                               <span class="token comment">#导入随机模块</span>

<span class="token keyword">from</span> qidian_hot<span class="token punctuation">.</span>settings <span class="token keyword">import</span> MY_USER_AGENT       <span class="token comment">#导入浏览器列表</span>

<span class="token comment">#定义类QidianHotUserAgentMiddleware，用于设置随机设置user-agent</span>
<span class="token comment">#继承于UserAgentMiddleware</span>

<span class="token keyword">class</span> <span class="token class-name">QidianHotUserAgentMiddleware</span><span class="token punctuation">(</span>UserAgentMiddleware<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#处理Request请求函数</span>

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token comment">#使用random模块的choice函数从列表MY_USER_AGENT中随机获取一个浏览器类型</span>

      agent <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>MY_USER_AGENT<span class="token punctuation">)</span><span class="token punctuation">)</span>
      <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"user-agent:"</span><span class="token punctuation">,</span> agent<span class="token punctuation">)</span>                     

      <span class="token comment">#将User-Agent附加到Reqeust对象的headers中</span>

      request<span class="token punctuation">.</span>headers<span class="token punctuation">.</span>setdefault<span class="token punctuation">(</span><span class="token string">'User-Agent'</span><span class="token punctuation">,</span> agent<span class="token punctuation">)</span>

</code></pre> 
<p>3.启用中间件UserAgentMiddleware。</p> 
<pre><code class="prism language-python"><span class="token comment"># Enable or disable downloader middlewares</span>
<span class="token comment"># See https://doc.scrapy.org/en/latest/topics/downloader-middleware.html</span>
DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
  <span class="token string">'qidian_hot.middlewares.QidianHotDownloaderMiddleware'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
  <span class="token string">'qidian_hot.middlewares.QidianHotUserAgentMiddleware'</span><span class="token punctuation">:</span> <span class="token number">100</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre> 
<hr> 
<ul><li>使用HTTP代理服务器<br> HTTP代理服务器功能就是代理网络用户取获取网络信息，它相当于客户端浏览器和网站服务器之间的信息中转站。<br> 在爬虫中采用大量的随机代理服务器访问某个网站，则该网站很难检测出爬虫。<br> <img src="https://images2.imgbox.com/dd/aa/ztTVue4n_o.jpg" alt="在这里插入图片描述"></li></ul> 
<hr> 
<h4><a id="_120"></a>参考文献</h4> 
<p><a href="https://zhuanlan.zhihu.com/p/44686802" rel="nofollow">盘点一些网站的反爬虫机质</a><br> <a href="https://zhuanlan.zhihu.com/p/395378457" rel="nofollow">功能强大的python包（八）：Scrapy （网络爬虫框架） </a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b8ea1112df71bd5f235735e8ac0a69da/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ref 在 setup（）函数里面的使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/25fada518386fcc9b9599726e0a74b82/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">尚学堂__百战程序员__1573题------第六章 异常机制</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>