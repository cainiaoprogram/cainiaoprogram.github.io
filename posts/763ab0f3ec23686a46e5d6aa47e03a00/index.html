<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>C&#43;&#43;调用yolov5 onnx模型的初步探索 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="C&#43;&#43;调用yolov5 onnx模型的初步探索" />
<meta property="og:description" content="yolov5-dnn-cpp-python
https://github.com/hpc203/yolov5-dnn-cpp-python
转onnx：
用opencv的dnn模块做yolov5目标检测的程序，包含两个步骤：(1).把pytorch的训练模型.pth文件转换到.onnx文件。(2).opencv的dnn模块读取.onnx文件做前向计算。
SiLU其实就是swish激活函数，而在onnx模型里是不直接支持swish算子的，因此在转换生成onnx文件时，SiLU激活函数不能直接使用nn.Module里提供的接口，而需要自定义实现它。
修改Focus类，替换切片操作。
把Detect类里面的1x1卷积定义在紧邻着Detect类之前的外面，然后去掉Detect类，组成新的model，作为torch.onnx.export的输入。
torch.onnx.export(model, inputs, output_onnx, verbose=False, opset_version=12, input_names=[&#39;images&#39;], output_names=[&#39;out0&#39;, &#39;out1&#39;, &#39;out2&#39;])
最后生成的onnx文件，opencv的dnn模块就能成功读取了，接下来对照Detect类里的forward函数，用python或者C&#43;&#43;编写计算预测框的中心坐标和高宽的功能。
在转换生成onnx文件，你需要执行两个步骤，
第一步把原始训练模型.pt文件里的参数保存到新的.pth文件里，
第二步编写yolov5.py文件，把yolov5的网络结构定义在.py文件里，此时需要注意网络结构里不能包含切片对象赋值操作，F.interpolate里的size参数需要加int强制转换。
在执行完这两步之后才能生成一个opencv能成功读取并且做前向推理的onnx文件。
不过，最近我发现在yolov5-pytorch程序里，其实可以直接把原始训练模型.pt文件转换生成onnx文件的，而且我在一个yolov5检测人脸&#43;关键点的程序里实验成功了。
https://blog.csdn.net/nihate/article/details/112731327
作者用的模型
https://github.com/hpc203/yolov5-dnn-cpp-python/issues/21
https://github.com/ultralytics/yolov5/releases/tag/v4.0
问题：
warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失
https://blog.csdn.net/lcb_coconut/article/details/76136725
ModuleNotFoundError: No module named ‘models‘解决torch.load问题【天坑】
https://blog.csdn.net/weixin_42815846/article/details/115289861
抽取模型参数
转onnx成功，会打印如下信息
==============================================================================================================
yolov5-opencv-dnn-cpp
https://github.com/UNeedCryDear/yolov5-opencv-dnn-cpp （保存图片没有框）
opencv YOLO DNNs
https://docs.opencv.org/4.x/da/d9d/tutorial_dnn_yolo.html
cv::dnn::DetectionModel
void cv::dnn::DetectionModel::detect(
InputArray frame, // 输入图像
std::vector&lt; int &gt; &amp; classIds, // 输出类别index
std::vector&lt; float &gt; &amp; confidences, // 得分" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/763ab0f3ec23686a46e5d6aa47e03a00/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-20T17:44:32+08:00" />
<meta property="article:modified_time" content="2023-01-20T17:44:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">C&#43;&#43;调用yolov5 onnx模型的初步探索</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>yolov5-dnn-cpp-python<br> https://github.com/hpc203/yolov5-dnn-cpp-python</p> 
<p>转onnx：</p> 
<p>用opencv的dnn模块做yolov5目标检测的程序，包含两个步骤：(1).把pytorch的训练模型.pth文件转换到.onnx文件。(2).opencv的dnn模块读取.onnx文件做前向计算。</p> 
<p>SiLU其实就是swish激活函数，而在onnx模型里是不直接支持swish算子的，因此在转换生成onnx文件时，SiLU激活函数不能直接使用nn.Module里提供的接口，而需要自定义实现它。<br> 修改Focus类，替换切片操作。<br> 把Detect类里面的1x1卷积定义在紧邻着Detect类之前的外面，然后去掉Detect类，组成新的model，作为torch.onnx.export的输入。<br> torch.onnx.export(model, inputs, output_onnx, verbose=False, opset_version=12, input_names=['images'], output_names=['out0', 'out1', 'out2'])<br> 最后生成的onnx文件，opencv的dnn模块就能成功读取了，接下来对照Detect类里的forward函数，用python或者C++编写计算预测框的中心坐标和高宽的功能。</p> 
<p>在转换生成onnx文件，你需要执行两个步骤，<br> 第一步把原始训练模型.pt文件里的参数保存到新的.pth文件里，<br> 第二步编写yolov5.py文件，把yolov5的网络结构定义在.py文件里，此时需要注意网络结构里不能包含切片对象赋值操作，F.interpolate里的size参数需要加int强制转换。<br> 在执行完这两步之后才能生成一个opencv能成功读取并且做前向推理的onnx文件。</p> 
<p>不过，最近我发现在yolov5-pytorch程序里，其实可以直接把原始训练模型.pt文件转换生成onnx文件的，而且我在一个yolov5检测人脸+关键点的程序里实验成功了。<br> https://blog.csdn.net/nihate/article/details/112731327</p> 
<p>作者用的模型<br> https://github.com/hpc203/yolov5-dnn-cpp-python/issues/21<br> https://github.com/ultralytics/yolov5/releases/tag/v4.0</p> 
<p>问题：<br> warning C4819: 该文件包含不能在当前代码页(936)中表示的字符。请将该文件保存为 Unicode 格式以防止数据丢失<br> https://blog.csdn.net/lcb_coconut/article/details/76136725</p> 
<p>ModuleNotFoundError: No module named ‘models‘解决torch.load问题【天坑】<br> https://blog.csdn.net/weixin_42815846/article/details/115289861</p> 
<p>抽取模型参数<br>  </p> 
<p>转onnx成功，会打印如下信息<br>  </p> 
<p>==============================================================================================================<br> yolov5-opencv-dnn-cpp<br> https://github.com/UNeedCryDear/yolov5-opencv-dnn-cpp  （保存图片没有框）</p> 
<p>opencv YOLO DNNs<br> https://docs.opencv.org/4.x/da/d9d/tutorial_dnn_yolo.html</p> 
<p>cv::dnn::DetectionModel</p> 
<p>void cv::dnn::DetectionModel::detect(<br> InputArray frame, // 输入图像<br> std::vector&lt; int &gt; &amp; classIds, // 输出类别index<br> std::vector&lt; float &gt; &amp; confidences, // 得分<br> std::vector&lt; Rect &gt; &amp; boxes, // 目标框<br> float confThreshold = 0.5f, // 阈值<br> float nmsThreshold = 0.0f  // NMS<br> )<br> https://cloud.tencent.com/developer/article/1536443</p> 
<p></p> 
<p></p> 
<p><br> C++ 动态batch onnx推理</p> 
<p>多个batch</p> 
<p>    //将image1和image2合并到images<br>     vector&lt;Mat&gt; images;<br>     images.push_back(image1);<br>     images.push_back(image2);<br>     vector&lt;String&gt; labels = readClassNames();</p> 
<p>    Mat inputBlob = blobFromImages(images, 1.0, Size(w, h), Scalar(0, 0, 0), false, true);</p> 
<p>    // 执行图像分类<br>     net.setInput(inputBlob);<br>     cv::Mat prob = net.forward();     // 推理出结果<br>     cout &lt;&lt; prob.cols&lt;&lt; endl;</p> 
<p>    for (int n = 0; n &lt; prob.rows; n++) {<!-- --><br>         Point classNumber;<br>         double classProb;<br>         Mat probMat = prob(Rect(0, n, 1000, 1)).clone();<br>         Mat result = probMat.reshape(1, 1);<br>         minMaxLoc(result, NULL, &amp;classProb, NULL, &amp;classNumber);<br>         int classidx = classNumber.x;<br>         printf("\n current image classification : %s, possible : %.2f\n", labels.at(classidx).c_str(), classProb);<br>     }<br> https://blog.csdn.net/qq_44747572/article/details/121467657</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9ba0c96c7c2fb8c089b24a4e1c7ad655/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Pytorch实战笔记(2)——CNN实现情感分析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c1ef6bffbd090d92d8445537472b6792/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">机器学习中关于随机森林和XGBoost算法的特征选择 （一）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>