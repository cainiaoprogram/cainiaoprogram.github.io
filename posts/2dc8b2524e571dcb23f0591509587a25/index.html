<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>W2NER：统一NER模型SOTA - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="W2NER：统一NER模型SOTA" />
<meta property="og:description" content="论文：Unified Named Entity Recognition as Word-Word Relation Classification
发表方：武汉大学，发表于AAAI2022
论文链接：https://arxiv.org/abs/2112.10070
开源代码：https://github.com/ljynlp/W2NER
这篇论文主要是针对“flat NER”(就是最普通的NER)、“重叠NER”和“不连续NER”三种NER的子任务，提出了一种统一的word-word pair的标注框架，并且提出了一个相对应的模型结构来进行学习，他们在三个tasks的多个数据集上取得了SOTA的成绩。
标注框架 标注框架 我们首先来看一个论文中举的NER样本:
{ &#39;text&#39;: &#39;I am having aching in legs and shoulders&#39;, &#39;entity_list&#39;: [ {&#39;entity_text&#39;: &#39;aching in legs&#39;, &#39;index&#39;: [3, 4, 5], &#39;entity_type&#39;: &#39;Symptom&#39;}, {&#39;entity_text&#39;: &#39;aching in shoulders&#39;, &#39;index&#39;: [3, 4, 7], &#39;entity_type&#39;: &#39;Symptom&#39;} ] } 标注框架示例 上面的例子在这个标注框架中的示例如上图所示，对于一个句子，这个框架首先搞了一个word-word矩阵（如上图的右侧矩阵），在矩阵中定义了两种类型的标记：
NHW，Next-Neighboring-Word，这个类型的标记只会出现在上三角矩阵中（不包括对角线部分），上三角矩阵的元素取值只有0和1两种，（也就是图中矩阵中标注NHW的格子）表示，在某个实体中，第i个单词后面接着的是第j个单词，比如表示在某个实体中，第3个单词(从0开始数)aching后面跟着的单词是in。
THW-entity_type ，Tail-Head-Word-entity_type，这个类型的标记只会出现在下三角矩阵中（包括对角线部分），entity_type就是实体的类型，代码里面其实这个THW-entity_type直接就用entity_type的id就可以了，表示，第i个单词是某个实体类型ID为3的实体的结尾词（tail word），而第j个单词是这个实体的开始词（head word），比如表示单词shoulders是实体的结尾，这个实体的开头是aching，这个实体的类型是Symptom。
这个框架可以直接把三种NER的subtasks全部一勺烩了，借用论文中举的4个例子，大家感受一下：
不同类型的NER 解码方法 了解了标注框架后，我们来看看它的解码方法：
解码算法 其实就是一个DFS，大致步骤这里描述一下：
首先在下三角矩阵中找THW-entity_type标签，假设第i行第j列是THW-entity_type，如果，说明是一个单字实体，直接加入结果集E和T，否则去第2步
如果，则说明第i个单词是实体的尾部，第j个单词是实体的起始，那么一定会有，然后我们第j行的第j&#43;1列开始找NNW，假设在第j行第k列找到NNW，则去第k行的第k&#43;1列接着向后找，直到到达第i列为止，找到第i列的话，把从j开始通过NNW迄今为止串起来的token作为是一个实体加入结果集。
（但弱弱的说一句，这种情况的话，如果开头和结尾完全重叠，但中间不重叠的俩实体，岂不是就分不出来，是不是得在NNW上面也加上实体类型，哈哈）
模型结构 其实这篇论文这个标注的框架比较重要，但还是要介绍一下模型。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2dc8b2524e571dcb23f0591509587a25/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-29T11:05:02+08:00" />
<meta property="article:modified_time" content="2022-05-29T11:05:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">W2NER：统一NER模型SOTA</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p>论文：Unified Named Entity Recognition as Word-Word Relation Classification</p> 
 <p>发表方：武汉大学，发表于AAAI2022</p> 
 <p>论文链接：https://arxiv.org/abs/2112.10070</p> 
 <p>开源代码：https://github.com/ljynlp/W2NER</p> 
 <p>这篇论文主要是针对“flat NER”(就是最普通的NER)、“重叠NER”和“不连续NER”三种NER的子任务，提出了一种统一的word-word pair的标注框架，并且提出了一个相对应的模型结构来进行学习，他们在三个tasks的多个数据集上取得了SOTA的成绩。</p> 
 <h3>标注框架</h3> 
 <h5>标注框架</h5> 
 <p>我们首先来看一个论文中举的NER样本:</p> 
 <pre class="has"><code class="language-go">{
    'text': 'I am having aching in legs and shoulders',
    'entity_list': [
        {'entity_text': 'aching in legs', 'index': [3, 4, 5], 'entity_type': 'Symptom'},
        {'entity_text': 'aching in shoulders', 'index': [3, 4, 7], 'entity_type': 'Symptom'}
    ]
}</code></pre> 
 <img src="https://images2.imgbox.com/a9/7b/EVJa60dW_o.png" alt="4250366eff719954eb9cbdff3781b555.png"> 
 <figcaption> 
  标注框架示例 
 </figcaption> 
 <p>上面的例子在这个标注框架中的示例如上图所示，对于一个句子，这个框架首先搞了一个word-word矩阵（如上图的右侧矩阵），在矩阵中定义了两种类型的标记：</p> 
 <ul><li><p>NHW，Next-Neighboring-Word，这个类型的标记只会出现在上三角矩阵中（不包括对角线部分），上三角矩阵的元素取值只有0和1两种，（也就是图中矩阵中标注NHW的格子）表示，在某个实体中，第i个单词后面接着的是第j个单词，比如表示在某个实体中，第3个单词(从0开始数)aching后面跟着的单词是in。</p></li><li><p>THW-entity_type ，Tail-Head-Word-entity_type，这个类型的标记只会出现在下三角矩阵中（包括对角线部分），entity_type就是实体的类型，代码里面其实这个THW-entity_type直接就用entity_type的id就可以了，表示，第i个单词是某个实体类型ID为3的实体的结尾词（tail word），而第j个单词是这个实体的开始词（head word），比如表示单词shoulders是实体的结尾，这个实体的开头是aching，这个实体的类型是Symptom。</p></li></ul> 
 <p>这个框架可以直接把三种NER的subtasks全部一勺烩了，借用论文中举的4个例子，大家感受一下：</p> 
 <img src="https://images2.imgbox.com/49/ba/7bLCnGN7_o.png" alt="a3a6160d1000ffbdf2ea964caf68fa07.png"> 
 <figcaption> 
  不同类型的NER 
 </figcaption> 
 <h5>解码方法</h5> 
 <p>了解了标注框架后，我们来看看它的解码方法：</p> 
 <img src="https://images2.imgbox.com/7d/d1/OB2fgLwH_o.png" alt="135ff0b1b574bbeeb69877c7dcebda4a.png"> 
 <figcaption> 
  解码算法 
 </figcaption> 
 <p>其实就是一个DFS，大致步骤这里描述一下：</p> 
 <ol><li><p>首先在下三角矩阵中找THW-entity_type标签，假设第i行第j列是THW-entity_type，如果，说明是一个单字实体，直接加入结果集E和T，否则去第2步</p></li><li><p>如果，则说明第i个单词是实体的尾部，第j个单词是实体的起始，那么一定会有，然后我们第j行的第j+1列开始找NNW，假设在第j行第k列找到NNW，则去第k行的第k+1列接着向后找，直到到达第i列为止，找到第i列的话，把从j开始通过NNW迄今为止串起来的token作为是一个实体加入结果集。</p></li></ol> 
 <p>（但弱弱的说一句，这种情况的话，如果开头和结尾完全重叠，但中间不重叠的俩实体，岂不是就分不出来，是不是得在NNW上面也加上实体类型，哈哈）</p> 
 <h3>模型结构</h3> 
 <p>其实这篇论文这个标注的框架比较重要，但还是要介绍一下模型。</p> 
 <img src="https://images2.imgbox.com/65/bf/SuNtgdYi_o.png" alt="9ed5fb28b85aa902ae5f3025d1cfb4c9.png"> 
 <figcaption> 
  模型整体结构 
 </figcaption> 
 <p>从图中大致可以看出，模型分为三个模块：Encoder Layer、Convolution Layer和Co-Predictor Layer，接下来我们一一介绍。</p> 
 <h5>Encoder Layer</h5> 
 <p>这部分主要是获取文本中每个Token的表征，对于一个输入文本序列，Encoder Layer通过如下步骤获取每个Token的表征</p> 
 <ol><li><p>过BERT，获得文本序列的word pieces的表征，这里可以是BERT的最后一层，也可以是最后四层的平均，但这里获取到的是word pieces的表征，并不是每个Token的表征；</p></li><li><p>在word pieces的表征上面用Max Pooling获取Token的表征；</p></li><li><p>过BiLSTM获取最终的Token的表征。</p></li></ol> 
 <p>这里说一下word pieces到Token的max pooline操作怎么做：</p> 
 <pre class="has"><code class="language-go"># 数据构造阶段：比如句子token长度是N，word piece的长度是M，然后构造一个N*M的矩阵W，每一行只在有word piece的部分是1，其他地方是0
W = np.zeros((N, M), dtype=np.bool)
start = 0
for i, pieces in enumerate(tokens):
    if len(pieces) == 0:
        continue
    pieces = list(range(start, start + len(pieces)))
    W[i, pieces[0] + 1:pieces[-1] + 2] = 1
    start += len(pieces)

# 模型里面：BERT的结果是[BS, M, dim]（我们就叫他BE吧），扩展并且expand一下，到[BS, N, M, dim]，就与矩阵W对上了，然后把矩阵W中为0的位置在BE中相对应的位置置为BE中的最小值，最后再M方向Max Pooling一下。
# W是[BS, N, M]
length = W.size(1)
min_value = torch.min(bert_embs).item()
_bert_embs = bert_embs.unsqueeze(1).expand(-1, length, -1, -1)
_bert_embs = torch.masked_fill(_bert_embs, pieces2word.eq(0).unsqueeze(-1), min_value)
word_reps, _ = torch.max(_bert_embs, dim=2)</code></pre> 
 <h5>Convolution Layer</h5> 
 <p>这部分主要是通过<strong>「CLN」</strong>将Token的序列（不算batch维和特征dim维的话就是1D）表征变成word-word的网格表征（那它就是2D），并在网格表征上面添加<strong>「单词间相对位置表征」</strong>和<strong>「上下三角表征」</strong>，最后进一步通过3个<strong>「空洞卷积」</strong>对网格表征进行进一步编码。</p> 
 <h6>1. CLN</h6> 
 <p>构造Word-Word的网格表征，假设表示第i个单词对第j个单词的关系，进一步说就是在给定第i个单词的情况下单词j的特征，为了达到这种效果，他们引入了Conditional Layer Normalization（CLN），公式如下：</p> 
 <img src="https://images2.imgbox.com/f8/6d/RXFeim50_o.png" alt="b7b4fe7ddb31657f34533c047c4e5122.png"> 
 <p>可以看到是对第j个单词的表征做normalization，但与传统LN相比不同的是，CLN的两个系数和是根据第i个单词的表征学习到的。关于这点，苏神在他的博客[^1]里面有过一张很清晰的图(图里的就是上面公式里的)，这里我贴一下：</p> 
 <img src="https://images2.imgbox.com/7e/ae/zzSEJBzG_o.png" alt="a5f4560c3ea55e708aa42593d098e4cd.png"> 
 <figcaption> 
  CLN 
 </figcaption> 
 <img src="https://images2.imgbox.com/1a/24/WgD2PgT1_o.png" alt="a3b536c532f526f301b546f9a47cb5ea.png"> 
 <figcaption> 
  LN 
 </figcaption> 
 <h6>2. 构造BERT风格的网格表征</h6> 
 <p>仿照BERT，除了CLN生成的网格表征以外，还生成了两个其他的表征：</p> 
 <ul><li><p>CLN生成的网格表征</p></li><li><p>单词间相对位置表征，（代码中他们共给距离设置了19个区间，从而降低了位置表征的范围，具体可以看代码）</p></li><li><p>上下三角矩阵的表征</p></li></ul> 
 <p>三个拼在一起过MLP，生成BERT风格的网格表征。</p> 
  
 <h6>3. 多粒度空洞卷积</h6> 
 <p>用膨胀系数分别为1,2,3的三个空洞卷积层+GELU，去捕获网格中不同位置的word pairs间的关系，进一步对网格表征进行编码，最后拼接得到网格最终编码。</p> 
  
 <h5>Co-Predictor Layer</h5> 
 <p>最后这部分就是预测层了，之前有研究证明双线性分类器可以增强MLP在关系预测上的效果，所以他们用了俩分类器，一个双线性分类器，一个MLP分类器，最后将两者的结果相加过softmax得到最终结果。</p> 
 <h6>1. 双线性分类器</h6> 
 <img src="https://images2.imgbox.com/1a/b8/KWbiJLN3_o.png" alt="7f1fefe73c3563d67067c37c1924c3a4.png"> 
 <h6>2. 最终结果</h6> 
  
 <h2>402 Payment Required</h2> 
 <h5>Loss Function</h5> 
 <img src="https://images2.imgbox.com/53/fb/py6b5GWK_o.png" alt="4ccf8f56af07b118b82aa9a4344eca32.png"> 
 <h3>实验</h3> 
 <p>在不同的subtasks的多个数据集上都取得了SOTA，并在仅有overlap和discontinuous的数据上的效果也好于之前的一些模型</p> 
 <img src="https://images2.imgbox.com/8f/98/DoyVAttw_o.png" alt="0737183e0e1c0bf6aa87edc8d5905f8c.png"> 
 <img src="https://images2.imgbox.com/49/61/nWRqMNkV_o.png" alt="672e03286494221f0d3741a5660a3497.png"> 
 <img src="https://images2.imgbox.com/51/cc/Z4cmLKJU_o.png" alt="74dc6afa16246bcecc56a97bad7d44fa.png"> 
 <img src="https://images2.imgbox.com/54/37/sjBtK3X1_o.png" alt="2c08679b597869668df54a6d258d6211.png"> 
 <figcaption> 
  实验结果 
 </figcaption> 
 <h5>消融实验</h5> 
 <img src="https://images2.imgbox.com/bc/fc/jM6Wl6fi_o.png" alt="ec6dcbb6b073f95b7bf24985830ffb05.png"> 
 <figcaption> 
  消融实验 
 </figcaption> 
 <ul><li><p>Region Emb：没有上下三角的emb</p></li><li><p>Distance Emb：没有相对位置的emb</p></li><li><p>All DConv：去掉所有膨胀卷积，下降很多</p> 
   <ul><li><p>膨胀卷积l=2去掉之后，下降是三个膨胀卷积里面最大的</p></li></ul></li><li><p>Biaffine：去掉双线性分类器，下降不多，说明Biaffine有一定辅助提升作用，但还是没有MLP的效果好，也侧面说明DConv那一层比双线性要好很多</p></li><li><p>MLP：去掉MLP后，下降了好多</p></li><li><p>NNW：去掉NNW，只有THW的话，不同数据集下降的不同，CADEC上面下降的比较多，因为这个数据集里面非连续NER比较多</p></li></ul> 
 <h3>最后</h3> 
 <p>这个标注框架还挺好的，确实统一了三个subtasks，而且看下来也不难，值得大家尝试尝试。</p> 
 <p style="text-align:center;">﻿ε≡٩(๑&gt;₃&lt;)۶ 一心向学</p> 
 <p style="text-align:center;"><strong>一起交流</strong></p> 
 <p style="text-align:left;">想和你一起学习进步！『<strong>NewBeeNLP』</strong>目前已经建立了多个不同方向交流群（<strong>机器学习 / 深度学习 / 自然语言处理 / 搜索推荐 / 图网络 / 面试交流 / </strong>等），名额有限，赶紧添加下方微信加入一起讨论交流吧！（注意一定o要<strong>备注信息</strong>才能通过）</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/f5/4d/YWpXL9Cz_o.png" alt="2c4584e8582ab63afdf2acfb3c5299e1.png"></p> 
 <p style="text-align:center;"><img height="792" width="1068" src="https://images2.imgbox.com/17/32/4CqtGbcU_o.png" alt="6bc84dffbb6d73397b1288a64273eff1.gif"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5ec10f75edc0b9897840295f6f65f415/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">顺序表初始化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3ecaf4a5e4c6c3838a54433fcc29f786/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">设计模式 之 代理模式</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>