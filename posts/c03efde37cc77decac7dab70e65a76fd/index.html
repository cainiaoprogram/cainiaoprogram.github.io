<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PyTorch模型部署流程(ONNX Runtime) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PyTorch模型部署流程(ONNX Runtime)" />
<meta property="og:description" content="模型部署指让训练好的深度学习模型在特定环境中运行的过程。模型部署会面临的难题：
运行模型所需的环境难以配置。深度学习模型通常是由一些框架编写，比如 PyTorch、TensorFlow。由于框架规模、依赖环境限制，框架不适合在手机、开发板等生产环境中安装。 深度学习模型的结构通常比较大，需要大量算力才能满足实时运行需求，运行效率需要优化。 因为这些难题的存在，模型部署不能靠简单的环境配置与安装完成。目前模型部署有一条流行的流水线：
为了让模型最终能够部署到某一环境上，可以使用任意一种深度学习框架来定义网络结构，并通过训练确定网络中的参数。之后，模型的结构和参数会被转换成一种只描述网络结构的中间表示，一些针对网络结构的优化会在中间表示上进行。最后，用面向硬件的高性能编程框架（如 CUDA，OpenCL）编写，能高效执行深度学习网络中算子的推理引擎会把中间表示转换成特定的文件格式，并在对应硬件平台上高效运行模型。
创建PyTorch模型
a.配置环境
# 创建预安装 Python 3.7 的名叫 deploy 虚拟环境
conda create -n deploy python=3.7 -y
# 进入虚拟环境
conda activate deploy
# 安装 Gpu 版本的 PyTorch
# 从官网中选择合适的配置并复制下载路径---https://pytorch.org/get-started/locally/
cconda install pytorch torchvision cudatoolkit=11.3 -c pytorch
# 安装 ONNX Runtime, ONNX, OpenCV
pip install onnxruntime onnx opencv-python
b.创建PyTorch模型
import os
import cv2
import numpy as np
import requests
import torch
import torch.onnx
from torch import nn" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/c03efde37cc77decac7dab70e65a76fd/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-21T15:59:02+08:00" />
<meta property="article:modified_time" content="2023-12-21T15:59:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PyTorch模型部署流程(ONNX Runtime)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:0;text-align:justify;">模型部署指让训练好的深度学习模型在特定环境中运行的过程。模型部署会面临的难题：</p> 
<ul><li style="text-align:left;">运行模型所需的环境难以配置。深度学习模型通常是由一些框架编写，比如 PyTorch、TensorFlow。由于框架规模、依赖环境限制，框架不适合在手机、开发板等生产环境中安装。</li></ul> 
<ul><li style="text-align:left;">深度学习模型的结构通常比较大，需要大量算力才能满足实时运行需求，运行效率需要优化。</li></ul> 
<p style="margin-left:0;text-align:left;">因为这些难题的存在，模型部署不能靠简单的环境配置与安装完成。目前模型部署有一条流行的流水线：</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="416" src="https://images2.imgbox.com/0e/45/kG9blITq_o.png" width="825"></p> 
<p style="margin-left:0;text-align:left;">        为了让模型最终能够部署到某一环境上，可以使用任意一种深度学习框架来定义网络结构，并通过训练确定网络中的参数。之后，模型的结构和参数会被转换成一种只描述网络结构的中间表示，一些针对网络结构的优化会在中间表示上进行。最后，用面向硬件的高性能编程框架（如 CUDA，OpenCL）编写，能高效执行深度学习网络中算子的推理引擎会把中间表示转换成特定的文件格式，并在对应硬件平台上高效运行模型。</p> 
<p style="margin-left:0;text-align:left;"></p> 
<p style="margin-left:0;text-align:left;"><strong>创建</strong><strong>PyTorch</strong><strong>模型</strong></p> 
<p style="margin-left:0;text-align:left;"><strong>a.</strong><strong>配置环境</strong></p> 
<table border="1" cellspacing="0"><tbody><tr><td style="background-color:#f5f6f7;border-color:#dee0e3;width:15cm;"> <p style="margin-left:0;text-align:left;"># 创建预安装 Python 3.7 的名叫 deploy 虚拟环境<br> conda create -n deploy python=3.7 -y<br> # 进入虚拟环境<br> conda activate deploy<br> # 安装 Gpu 版本的 PyTorch<br> # 从官网中选择合适的配置并复制下载路径---https://pytorch.org/get-started/locally/<br> cconda install pytorch torchvision cudatoolkit=11.3 -c pytorch<br> # 安装 ONNX Runtime, ONNX, OpenCV<br> pip install onnxruntime onnx opencv-python</p> </td></tr></tbody></table> 
<p style="margin-left:0;text-align:left;"><strong>b.</strong><strong>创建</strong><strong>PyTorch</strong><strong>模型</strong></p> 
<table border="1" cellspacing="0"><tbody><tr><td style="background-color:#f5f6f7;border-color:#dee0e3;width:15cm;"> <p style="margin-left:0;text-align:left;">import os<br><br> import cv2<br> import numpy as np<br> import requests<br> import torch<br> import torch.onnx<br> from torch import nn<br><br> class SuperResolutionNet(nn.Module):<br>     def __init__(self, upscale_factor):<br>         super().__init__()<br>         self.upscale_factor = upscale_factor<br>         self.img_upsampler = nn.Upsample(<br>             scale_factor=self.upscale_factor,<br>             mode='bicubic',<br>             align_corners=False)<br><br>         self.conv1 = nn.Conv2d(3,64,kernel_size=9,padding=4)<br>         self.conv2 = nn.Conv2d(64,32,kernel_size=1,padding=0)<br>         self.conv3 = nn.Conv2d(32,3,kernel_size=5,padding=2)<br><br>         self.relu = nn.ReLU()<br><br>     def forward(self, x):<br>         x = self.img_upsampler(x)<br>         out = self.relu(self.conv1(x))<br>         out = self.relu(self.conv2(out))<br>         out = self.conv3(out)<br>         return out<br><br> # Download checkpoint and test image<br> urls = ['https://download.openmmlab.com/mmediting/restorers/srcnn/srcnn_x4k915_1x16_1000k_div2k_20200608-4186f232.pth',<br>         'https://raw.githubusercontent.com/open-mmlab/mmediting/master/tests/data/face/000001.png']<br> names = ['srcnn.pth', 'face.png']<br> for url, name in zip(urls, names):<br>     if not os.path.exists(name):<br>         open(name, 'wb').write(requests.get(url).content)<br><br> def init_torch_model():<br>     torch_model = SuperResolutionNet(upscale_factor=3)<br><br>     state_dict = torch.load('srcnn.pth')['state_dict']<br><br>     # Adapt the checkpoint<br>     for old_key in list(state_dict.keys()):<br>         new_key = '.'.join(old_key.split('.')[1:])<br>         state_dict[new_key] = state_dict.pop(old_key)<br><br>     torch_model.load_state_dict(state_dict)<br>     torch_model.eval()<br>     return torch_model<br><br> model = init_torch_model()<br> input_img = cv2.imread('face.png').astype(np.float32)<br><br> # HWC to NCHW<br> input_img = np.transpose(input_img, [2, 0, 1])<br> input_img = np.expand_dims(input_img, 0)<br><br> # Inference<br> torch_output = model(torch.from_numpy(input_img)).detach().numpy()<br><br> # NCHW to HWC<br> torch_output = np.squeeze(torch_output, 0)<br> torch_output = np.clip(torch_output, 0, 255)<br> torch_output = np.transpose(torch_output, [1, 2, 0]).astype(np.uint8)<br><br> # Show image<br> cv2.imwrite("face_torch.png", torch_output)</p> </td></tr></tbody></table> 
<p style="margin-left:0;text-align:left;">代码创建一个经典的超分辨率网络 <a href="https://arxiv.org/abs/1501.00092" rel="nofollow" title="SRCNN">SRCNN</a>。SRCNN 先把图像上采样到对应分辨率，再用 3 个卷积层处理图像。如果脚本正常运行，一幅超分辨率的人脸照片会保存在 <span style="background-color:#eff0f1;">face_torch.png</span> 中。</p> 
<p style="margin-left:0;text-align:left;">在 PyTorch 模型测试正确后，我们来正式开始部署这个模型。我们下一步的任务是把 PyTorch 模型转换成用中间表示 ONNX 描述的模型。</p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="256" src="https://images2.imgbox.com/83/e4/UZUEkvrT_o.png" width="256"></p> 
<p style="margin-left:0;text-align:left;"><strong>c.</strong><strong>将</strong><strong>PyTorch</strong><strong>模型转换成用</strong><strong>ONNX</strong><strong>描述的模型</strong></p> 
<p style="margin-left:0;text-align:left;">ONNX（Open Neural Network Exchange）是 Facebook 和微软在 2017 年共同发布的，用于标准描述计算图的一种格式。目前，在数家机构的共同维护下，ONNX 已经对接了多种深度学习框架和多种推理引擎。因此，ONNX 被当成了深度学习框架到推理引擎的桥梁，就像编译器的中间语言一样。由于各框架兼容性不一，通常只用 ONNX 表示更容易部署的静态图。</p> 
<table border="1" cellspacing="0"><tbody><tr><td style="background-color:#f5f6f7;border-color:#dee0e3;width:15cm;"> <p style="margin-left:0;text-align:left;">#  PyTorch 的模型转换成 ONNX 格式的模型<br> x = torch.randn(1, 3, 256, 256)<br><br> with torch.no_grad():<br>     torch.onnx.export(<br>         model,<br>         x,<br>         "srcnn.onnx",<br>         opset_version=11,<br>         input_names=['input'],<br>         output_names=['output'])</p> </td></tr></tbody></table> 
<p style="margin-left:0;text-align:left;">其中<strong>torch.onnx.export</strong> 是 PyTorch 自带的把模型转换成 ONNX 格式的函数。前三个参数分别是要转换的模型、模型的任意一组输入、导出的 ONNX 文件的文件名。</p> 
<p style="margin-left:0;text-align:left;">从 PyTorch 的模型到 ONNX 的模型，PyTorch提供了一种叫做追踪（trace）的模型转换方法：给定一组输入，再实际执行一遍模型，即把这组输入对应的计算图记录下来，保存为 ONNX 格式。<strong>export</strong> 函数用的就是追踪导出方法，需要给任意一组输入，让模型跑起来。测试图片是三通道256x256 大小的，这里也构造一个同样形状的随机张量。</p> 
<p style="margin-left:0;text-align:left;"><span style="background-color:#eff0f1;">opset_version</span> 表示 ONNX 算子集的版本。<span style="background-color:#eff0f1;">input_names</span>, <span style="background-color:#eff0f1;">output_names</span> 是输入、输出 tensor 的名称。代码运行成功，目录下会新增一个 <span style="background-color:#eff0f1;">srcnn.onnx</span> 的 ONNX 模型文件</p> 
<table border="1" cellspacing="0"><tbody><tr><td style="background-color:#f5f6f7;border-color:#dee0e3;width:15cm;"> <p style="margin-left:0;text-align:left;"># 验证模型文件是否正确，直接加在前面的代码后面就行<br> import onnx<br><br> onnx_model = onnx.load("srcnn.onnx")<br> try:<br>     onnx.checker.check_model(onnx_model)<br> except Exception:<br>     print("Model incorrect")<br> else:<br>     print("Model correct")</p> </td></tr></tbody></table> 
<p style="margin-left:0;text-align:left;"><strong>d.</strong><strong>在</strong><strong>ONNX Runtime</strong><strong>上运行模型和推理</strong></p> 
<p style="margin-left:0;text-align:left;"><strong>推理引擎</strong><strong>-ONNX Runtime</strong> 是由微软维护的一个跨平台机器学习推理加速器。ONNX Runtime 是直接对接ONNX的，即ONNX Runtime可以直接读取并运行.onnx文件，而不需要再把.onnx格式的文件转换成其他格式的文件。也就是说，对于<span style="background-color:#eff0f1;"> PyTorch - ONNX - ONNX Runtime</span> 这条部署流水线，只要在目标设备中得到 .onnx 文件，并在 ONNX Runtime 上运行模型，模型部署就算大功告成了。</p> 
<p style="margin-left:0;text-align:left;">ONNX Runtime 提供了 Python 接口。</p> 
<table border="1" cellspacing="0"><tbody><tr><td style="background-color:#f5f6f7;border-color:#dee0e3;width:15cm;"> <p style="margin-left:0;text-align:left;"># ONNX Runtime完成模型推理，还是在之前脚本后添加代码<br> import onnxruntime<br><br> ort_session = onnxruntime.InferenceSession("srcnn.onnx")<br> ort_inputs = {'input': input_img}<br> ort_output = ort_session.run(['output'], ort_inputs)[0]<br><br> ort_output = np.squeeze(ort_output, 0)<br> ort_output = np.clip(ort_output, 0, 255)<br> ort_output = np.transpose(ort_output, [1, 2, 0]).astype(np.uint8)<br> cv2.imwrite("face_ort.png", ort_output)</p> </td></tr></tbody></table> 
<p style="margin-left:0;text-align:left;"><strong>onnxruntime.InferenceSession</strong> 用于获取一个 ONNX Runtime 推理器，其参数是用于推理的 ONNX 模型文件。推理器的 run 方法用于模型推理，其第一个参数为输出张量名的列表，第二个参数为输入值的字典。其中输入值字典的 key 为张量名，value 为 numpy 类型的张量值。输入输出张量的名称需要和 <strong>torch.onnx.export</strong> 中设置的输入输出名对应。</p> 
<p style="margin-left:0;text-align:left;">如果代码正常运行的话，另一幅超分辨率照片会保存在 face_ort.png 中。这幅图片和刚刚得到的 <span style="background-color:#eff0f1;">face_torch.png</span> 是一样的。即ONNX Runtime 成功运行了 SRCNN 模型，完成模型部署。</p> 
<p style="margin-left:0;text-align:left;">以后再想实现超分辨率的操作，只需要提供一个srcnn.onnx文件，并帮助用户配置好 ONNX Runtime 的 Python 环境，用几行代码就可以运行模型。或者可以利用 ONNX Runtime 编译出一个可以直接执行模型的应用程序。只需给用户提供 ONNX 模型文件，并让用户在应用程序选择要执行的 ONNX 模型文件名就可以运行模型了。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/39de2a93924775b922f9d43d582c4c1f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Qualcomm® AI Engine Direct 使用手册（3）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fb0e38525a7b7a6133b56ca4c261ccb7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">移动端深度学习部署：TFlite</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>