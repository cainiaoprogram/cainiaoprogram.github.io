<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LXMERT:Learning Cross-Modality Encoder Representations from Transformers - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LXMERT:Learning Cross-Modality Encoder Representations from Transformers" />
<meta property="og:description" content=" LXMERT:Learning Cross-Modality Encoder Representations from Transformers 视觉-语言推理需要理解视觉概念、语言语义，最重要的是，理解两种模态之间的一致性和关系。
解决问题 针对视觉和语言模态对的大规模预训练和微调的模型。
研究方法和创新点 作者以BERT模型为基础，同时进一步适应于跨模态场景。该跨模态模型专注于学习视觉和语言的交互，特别是对于单个图像及其描述性句子的表示。它由三个Transformer编码器组成，一个对象关系编码器、一个语言编码器和一个跨模态编码器。为了更好的学习视觉和语言之间的跨模态对齐，用五个不同的任务来预训练模型。(1) masked cross-modality language modeling, (2) masked object prediction via RoI-feature regression, (3) masked object prediction via detected-label classification, (4) cross-modality matching, and (5) image question answering。
流程和模块： 模型输入：图像及其相关句子。其中每个图像都表示为一个对象序列，每个句子都表示为一个单词序列。
输入嵌入层 输入嵌入层将输入（图像和句子）转换为两个特征序列（单词句子嵌入和对象图像嵌入）。
编码器 语言编码器、对象关系编码器、交叉模态编码器
训练和损失函数 1、Language Task:Masker Cross-Modality LM掩蔽的跨模态语言模型。
2、Vision Task:Masked Object Prediction——负对数似然函数
RoI-Feature Regression——L2loss
Detected-Label Classification——cross-entropy loss
3、Cross-Modality Tasks
Cross-Modality Matching
Image Question Answering(QA)
预训练数据集 实验结果 消融实验 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9937cae4ab5a1b2d0b3562f25087fe66/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-06T10:11:05+08:00" />
<meta property="article:modified_time" content="2023-01-06T10:11:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LXMERT:Learning Cross-Modality Encoder Representations from Transformers</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="LXMERTLearning_CrossModality_Encoder_Representations_from_Transformers_0"></a>LXMERT:Learning Cross-Modality Encoder Representations from Transformers</h3> 
<p>视觉-语言推理需要理解视觉概念、语言语义，最重要的是，理解两种模态之间的一致性和关系。</p> 
<h5><a id="_2"></a>解决问题</h5> 
<p>针对视觉和语言模态对的大规模预训练和微调的模型。</p> 
<h5><a id="_4"></a>研究方法和创新点</h5> 
<p>作者以BERT模型为基础，同时进一步适应于跨模态场景。该跨模态模型专注于学习视觉和语言的交互，特别是对于单个图像及其描述性句子的表示。它由三个Transformer编码器组成，一个对象关系编码器、一个语言编码器和一个跨模态编码器。为了更好的学习视觉和语言之间的跨模态对齐，用五个不同的任务来预训练模型。(1) masked cross-modality language modeling, (2) masked object prediction via RoI-feature regression, (3) masked object prediction via detected-label classification, (4) cross-modality matching, and (5) image question answering。</p> 
<h5><a id="_6"></a>流程和模块：</h5> 
<p><img src="https://images2.imgbox.com/95/c1/se0b4BkG_o.png" alt="在这里插入图片描述"><br> 模型输入：图像及其相关句子。其中每个图像都表示为一个<strong>对象序列</strong>，每个句子都表示为一个<strong>单词序列</strong>。</p> 
<h6><a id="_9"></a>输入嵌入层</h6> 
<p>输入嵌入层将输入（图像和句子）转换为两个特征序列（单词句子嵌入和对象图像嵌入）。<br> <img src="https://images2.imgbox.com/38/00/HOhCghDm_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/04/4e/FULUftGS_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="_13"></a>编码器</h6> 
<p>语言编码器、对象关系编码器、交叉模态编码器<br> <img src="https://images2.imgbox.com/78/9d/F60icw2c_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/96/ce/RuQc84JR_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d4/e5/VxWaUofq_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="_18"></a>训练和损失函数</h6> 
<p><img src="https://images2.imgbox.com/99/13/xMWlN0B0_o.png" alt="在这里插入图片描述"><br> 1、Language Task:Masker Cross-Modality LM掩蔽的跨模态语言模型。<br> 2、Vision Task:Masked Object Prediction——负对数似然函数<br> RoI-Feature Regression——L2loss<br> Detected-Label Classification——cross-entropy loss<br> 3、Cross-Modality Tasks<br> Cross-Modality Matching<br> Image Question Answering(QA)</p> 
<h6><a id="_27"></a>预训练数据集</h6> 
<p><img src="https://images2.imgbox.com/b5/7c/hXEc5qmR_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_29"></a>实验结果</h5> 
<h6><a id="_31"></a>消融实验</h6> 
<p><img src="https://images2.imgbox.com/73/c5/TT7Hlz30_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6348f915d55e09c760e6bb88ef1b967c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">电脑录屏怎么把声音录进去，两招教你把声音录进去</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/65ca0b83914258bf268aeeefecb3da99/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ViLT:Vision-and-Language Transformer Withoout Convolution or Region Supervision</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>