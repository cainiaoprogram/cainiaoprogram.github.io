<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文解读：Exploring Complementary Strengths of Invariant and Equivariant Representations - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文解读：Exploring Complementary Strengths of Invariant and Equivariant Representations" />
<meta property="og:description" content="小样本学习论文解读：Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning
摘要 teach：这篇文章尽管标题带小样本学习，但是并没有设计一套小样本学习的算法，而是用一种数据增强或者数据增广的方式生成更多的样本。通过样本之间的训练或者学习来去提升这个模型的泛化能力。用积累的数据去学习一个更好的泛化能力的模型，让这个模型能够泛化到新颖的类别当中。
1.介绍 创新点1：不变性(3.2.1)与等价性(3.2.2)的设计 方法概述:形状代表不同的变换 ，颜色代表不同的类 。虽然不变特征提供了更好的辨 别 ，但等变特征帮助我 们了解数据流形的内部结 构 。 这些互补的表征帮助我们更好地泛化到只有少数训练样本的新任务。通过共同利用 等变和不变特征的优势，我们的方法在基线(下 一行)上实现了显著的改进。
效果展示(如果论文效果比较好可以把效果对比图直接放在摘要)：
创新点2：多头知识蒸馏(参考3.2.3) 2.Related Works(略) 3.Our Approach 总体框架图 每个Ti都是一种变换，论文给出的为16种(包括旋转变换，按一定比例的图像变换的融合)，每一种变换都给上一个标签，这个标签是人为设定的，比如说16种变换，对应的标签为0-15；因此除了图片本身含有的标签外，还有人为给予的标签。这16种变换为网络输入的数据。
LCE为标准分类器的监督，这是利用每一个样本对真实标签的监督，即不管一张图片经过如何的选择变换，都用它本身真实的标签(比如说这张图为一只猫，不管如何旋转或者裁剪，这种图片的真实标签还是一只猫)
LEQ(Enforcing Equivariance)就是&#34;等价性&#34;，这里用到了对于每一种变换，人为所给定的标签
LINV(Enforcing Invariance)为&#34;不变性&#34;，这里构建一个Memory Bank，即一个非常大的负样本，来进行对比学习。在这里一张图片i有M个变换，这是属于正样本，其他图像相对这张图片i来说就是负样本，可以用来构建Memory Bank，这个Memory Bank量可以很大。
其中对比学习的方式就是：不同变换的同一张图片&#34;拉近&#34;，不同图片就&#34;拉远&#34;。
总的来说就是引入了两种损失函数：一种就是等价性的损失，一种就是不变形的损失。等价性的损失就是把图像进行不同的几何变换来进行监督；不变性损失就是构建了大的Memory Ban，即大的负样本，通过与正样本的对比学习，使得模型的泛化能力或者类的边界更有效。
3.1. Problem Formulation 标准的图像分类模型 LCE为标准分类器的监督，这是利用每一个样本对真实标签的监督，即不管一张图片经过如何的选择变换，都用它本身真实的标签(比如说这张图为一只猫，不管如何旋转或者裁剪，这种图片的真实标签还是一只猫)
LCE与LEQ两个损失函数的比较 LCE与LEQ这两个损失函数其实都是一样的，都是标准监督的损失函数，只不过预测结果与标签不同
LCE的预测结果是由网络得到，而LEQ的预测结果是由网络得到；
LCE的标签是图片原本的标签(比如说这张图片不管经过怎么样的变换，还是一只猫)，而LEQ的标签是人为设定的(见3.2中Equivariance人为设定的标签)
损失函数解读：
结果为：对每个类别分别预测的概率
为：这种图片的实际类别(即标签)所预测的概率
交叉熵损失函数中包含了一个最基础的部分：
参考资料：
在线：
【pytorch】交叉熵损失函数 nn.CrossEntropyLoss()-CSDN博客
离线：📎【pytorch】交叉熵损失函数 nn.CrossEntropyLoss()-CSDN博客 (2023_12_14 15_34_02).html
3.2. Injecting Inductive Biases through SSL 3." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/fc1fc2ab8e563b6706c7e53bea4adb79/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-20T22:36:16+08:00" />
<meta property="article:modified_time" content="2023-12-20T22:36:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文解读：Exploring Complementary Strengths of Invariant and Equivariant Representations</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>小样本学习论文解读：<strong>Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning</strong></p> 
<h2 id="nbPoe">摘要</h2> 
<p id="ud95ab8d7">teach：这篇文章尽管标题带小样本学习，但是并没有设计一套小样本学习的算法，而是用一种数据增强或者数据增广的方式生成更多的样本。通过样本之间的训练或者学习来去提升这个模型的泛化能力。用积累的数据去学习一个更好的泛化能力的模型，让这个模型能够泛化到新颖的类别当中。</p> 
<h2 id="ENAqb">1.介绍</h2> 
<h3 id="NJBME">创新点1：不变性(3.2.1)与等价性(3.2.2)的设计</h3> 
<p id="u6f4cc50c"></p> 
<p class="img-center"><img alt="" height="735" id="ue798f84a" src="https://images2.imgbox.com/e4/e4/R2XRgtE8_o.png" width="1200"></p> 
<p id="ub2b16dde">方法概述:形状代表不同的变换 ，颜色代表不同的类 。虽然不变特征提供了更好的辨 别 ，但等变特征帮助我 们了解数据流形的内部结 构 。 这些互补的表征帮助我们更好地泛化到只有少数训练样本的新任务。通过共同利用 等变和不变特征的优势，我们的方法在基线(下 一行)上实现了显著的改进。</p> 
<p id="ue2cc6b30">效果展示(如果论文效果比较好可以把效果对比图直接放在摘要)：</p> 
<p id="u1594f9da"></p> 
<p class="img-center"><img alt="" height="460" id="uce006812" src="https://images2.imgbox.com/c9/7f/kLEldQNL_o.png" width="1200"></p> 
<h3 id="G4jU8">创新点2：多头知识蒸馏(参考3.2.3)</h3> 
<h2 id="Nio5z">2.Related Works(略)</h2> 
<h2 id="cdHEY">3.Our Approach</h2> 
<h3 id="N4SqO">总体框架图</h3> 
<p id="u46842f1a">每个Ti都是一种变换，论文给出的为16种(包括旋转变换，按一定比例的图像变换的融合)，每一种变换都给上一个标签，这个标签是人为设定的，比如说16种变换，对应的标签为0-15；因此除了图片本身含有的标签外，还有人为给予的标签。这16种变换为网络输入的数据。</p> 
<p id="u25eb45e7">LCE为标准分类器的监督，这是利用每一个样本对真实标签的监督，即不管一张图片经过如何的选择变换，都用它本身真实的标签(比如说这张图为一只猫，不管如何旋转或者裁剪，这种图片的真实标签还是一只猫)</p> 
<p id="ud92acb69">LEQ(Enforcing Equivariance)就是"等价性"，这里用到了对于每一种变换，人为所给定的标签</p> 
<p id="u9b116d94">LINV(Enforcing Invariance)为"不变性"，这里构建一个Memory Bank，即一个非常大的负样本，来进行对比学习。在这里一张图片i有M个变换，这是属于正样本，其他图像相对这张图片i来说就是负样本，可以用来构建Memory Bank，这个Memory Bank量可以很大。</p> 
<p id="u58f5a3db">其中对比学习的方式就是：不同变换的同一张图片"拉近"，不同图片就"拉远"。</p> 
<p id="u26dc5edd">总的来说就是引入了两种损失函数：一种就是等价性的损失，一种就是不变形的损失。等价性的损失就是把图像进行不同的几何变换来进行监督；不变性损失就是构建了大的Memory Ban，即大的负样本，通过与正样本的对比学习，使得模型的泛化能力或者类的边界更有效。</p> 
<p id="ue3c4aa58"></p> 
<p class="img-center"><img alt="" height="934" id="u255430e7" src="https://images2.imgbox.com/e3/b9/8TyBpO6f_o.png" width="1200"></p> 
<p id="ucfcdcd12"></p> 
<p class="img-center"><img alt="" height="996" id="sLzcA" src="https://images2.imgbox.com/66/e7/3Ioj0rkq_o.png" width="1200"></p> 
<h3 id="RpJRu">3.1. Problem Formulation</h3> 
<h4 id="dcWKt">标准的图像分类模型</h4> 
<p id="uc28e2c06"></p> 
<p class="img-center"><img alt="" height="117" id="u9ec163bd" src="https://images2.imgbox.com/63/7a/Po3fFRHF_o.png" width="979"></p> 
<p id="u21218673">LCE为标准分类器的监督，这是利用每一个样本对真实标签的监督，即不管一张图片经过如何的选择变换，都用它本身真实的标签(比如说这张图为一只猫，不管如何旋转或者裁剪，这种图片的真实标签还是一只猫)</p> 
<h4 id="zeHBA">LCE与LEQ两个损失函数的比较</h4> 
<p id="uccaf39eb"><strong>L</strong><strong>CE</strong><strong>与L</strong><strong>EQ</strong><strong>这两个损失函数其实都是一样的，都是标准监督的损失函数，只不过预测结果与标签不同</strong></p> 
<p id="ud888a5a1">LCE的预测结果是由网络<img alt="f_{ \Theta,\Phi}(x)" class="mathcode" src="https://images2.imgbox.com/f7/9e/lbpmvo90_o.png">得到，而LEQ的预测结果是由网络<img alt="f_{\Theta,\Psi}(x)" class="mathcode" src="https://images2.imgbox.com/26/59/Wij1IRea_o.png">得到；</p> 
<p id="ude8c567a">LCE的标签是图片原本的标签(比如说这张图片不管经过怎么样的变换，还是一只猫)，而LEQ的标签是人为设定的(见3.2中Equivariance人为设定的标签)</p> 
<p id="uf7a800b9">损失函数解读：</p> 
<p><img alt="" height="78" src="https://images2.imgbox.com/20/33/Z2JBvV49_o.png" width="279"></p> 
<p id="u68218085">结果为：对每个类别分别预测的概率</p> 
<p id="uf3096e6f"><img alt="" height="60" src="https://images2.imgbox.com/64/7a/b4X4XYbL_o.png" width="283"></p> 
<p>为：这种图片的实际类别(即标签)所预测的概率</p> 
<p id="u23f98893">交叉熵损失函数中包含了一个最基础的部分：<img alt="softmax(x_{i})=\frac{e^{x_{i}}}{t}" class="mathcode" src="https://images2.imgbox.com/19/ba/l4SDgHBX_o.png"></p> 
<p id="u3b1c8af1">参考资料：</p> 
<p id="u1f9c87d2">在线：</p> 
<p id="u1c97a2fe"><a href="https://blog.csdn.net/weixin_37804469/article/details/125271074?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-9-125271074.142%5Ev96%5Epc_search_result_base7&amp;spm=1018.2226.3001.4187" title="【pytorch】交叉熵损失函数 nn.CrossEntropyLoss()-CSDN博客">【pytorch】交叉熵损失函数 nn.CrossEntropyLoss()-CSDN博客</a></p> 
<p id="u1ba1ee37">离线：<a href="https://www.yuque.com/attachments/yuque/0/2023/html/27783288/1702540233941-96648aa7-0115-4421-a551-7ec879dd1529.html" rel="nofollow" id="ueea6f1a5" title="📎【pytorch】交叉熵损失函数 nn.CrossEntropyLoss()-CSDN博客 (2023_12_14 15_34_02).html">📎【pytorch】交叉熵损失函数 nn.CrossEntropyLoss()-CSDN博客 (2023_12_14 15_34_02).html</a></p> 
<h3 id="y6H6t">3.2. Injecting Inductive Biases through SSL</h3> 
<h4 id="w8qbE">3.2.1 Enforcing Equivariance等价性</h4> 
<p id="u414c5017">me：训练的是模型学习数据是哪种数据变化(为哪个Ti)的能力</p> 
<h5 id="L5HJY">Equivariance人为设定的标签</h5> 
<p id="u397b3b77">标签为a M dimensional one-hot encoded vector u属于{0,1}M</p> 
<p id="ua33f3254">补充：</p> 
<p id="ua17c8d1b">一个M维的one-hot编码向量是一个长度为M的向量，其中只有一个元素为1，其余元素都为0。这个1的位置表示该向量对应的类别。例如，对于3个类别（A、B、C），one-hot编码向量可以表示为：</p> 
<p id="u9be96e3e">A: [1, 0, 0]</p> 
<p id="udc5947a9">B: [0, 1, 0]</p> 
<p id="u45f53eca">C: [0, 0, 1]</p> 
<p id="u220cd158">这篇文章代码里面应该是16种数据变化，所以人为给定的标签为</p> 
<p id="u99aeb961">T1变换的数据标签为：[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0](16维向量)</p> 
<p id="uef1edede">T2变换的数据标签为：[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0](16维向量)</p> 
<p id="u70d00529">...</p> 
<p id="ufa3d4356">T16变换的数据标签为：[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1](16维向量)</p> 
<h5 id="fcuwU">Equivariance的损失函数</h5> 
<p id="u54d84bed"></p> 
<p class="img-center"><img alt="" height="104" id="u6161edde" src="https://images2.imgbox.com/44/1f/J15kVWZk_o.png" width="706"></p> 
<p id="ud5fa6430">该函数为标准监督的损失函数，与LCE格式相同</p> 
<p id="ue1059d56"><img alt="" height="28" src="https://images2.imgbox.com/22/40/YgKdMP16_o.png" width="23">为网络<img alt="f_{ \Theta}" class="mathcode" src="https://images2.imgbox.com/ae/e0/cvLtXZrT_o.png">输出的结果，即对这张图片对每个变换分别预测的概率</p> 
<p id="uc9396415"><img alt="" height="30" src="https://images2.imgbox.com/6e/b5/MyxsLYFo_o.png" width="78">：这种图片的实际属于那种数据变换(即属于哪个Ti)所预测的概率</p> 
<h4 id="SWV4F">3.2.2 Enforcing Invariance不变性(对比学习)</h4> 
<p id="ufc641be2">me：应该是学习一个图片经过变化之后，模型还能认出来是这张图片的原来图片的能力；这里应该来自同一张原图才属于一类，而不是按标签来看是否为一类。</p> 
<h5 id="CxxlM">对比学习损失函数</h5> 
<p id="ua638dee6"></p> 
<p class="img-center"><img alt="" height="150" id="ud6bdef3f" src="https://images2.imgbox.com/db/2b/2KABqnL8_o.png" width="1001"></p> 
<p id="u6d3a9527">V0是没有经过变换的原始图片</p> 
<p id="u1030f254">Vr为原始的样本(me：Vr为参照物，Vm为要对比的数据)</p> 
<p id="u6844af09">Vm经过第m次变换之后的样本(m是变化的下指标，本篇文章解读为从0-15，公式中为0-(M-1))，目标就是要这两者尽可能接近；</p> 
<p id="u41d3e2c6">如果Vm(m≠0)不是原图，那就拿原图Vr=V0跟Vm比较</p> 
<p id="u0e0eb8b9">如果Vm(m=0)是原图(即没有经过任何图片变化)，那就拿原图V0 的 past representation<img alt="" height="24" src="https://images2.imgbox.com/a9/44/pRALSd36_o.png" width="22"></p> 
<p id="u0e0eb8b9">(不懂这个past representation，应该是对这张原图V0 进行的一些分析)跟原图V0比较</p> 
<p><img alt="h(v^{\mathcal{r}},v^{\mathcal{m}})= \frac {exp(\frac{s(v^{\mathcal{r}},v^{\mathcal{m}})}{\tau})} {exp(\frac{s(v^{\mathcal{r}},v^{\mathcal{m}})}{\tau}) +\underset{v^{'}\in{D_{n}}}{\sum}exp(\frac{s(v^{'},v^{\mathcal{m}})}{\tau})}" class="mathcode" src="https://images2.imgbox.com/d9/cb/uHszdXMj_o.png"></p> 
<p id="u2a637882">s表示一个相似度度量，可以是一个余炫距离，可以是一个欧式里得距离，也可以是一个内积。</p> 
<p id="udc10edd3">Dn是从负样本Memory Bank中抽取的小批量batch。</p> 
<p id="uce261b3d">V'为负样本；</p> 
<h5 id="ZzzJ9">补充：温度的概念以及作业</h5> 
<p id="uc46120fc"><img alt="\tau" class="mathcode" src="https://images2.imgbox.com/2a/13/GsF2ZIYc_o.png">是温度，me：应该跟知识蒸馏那里温度作用是相同的</p> 
<p id="ua041db0b">温度的选择还是要根据实际情况来</p> 
<p id="uf7564293"></p> 
<p class="img-center"><img alt="" height="730" id="u019f5c30" src="https://images2.imgbox.com/74/23/G4au4CAf_o.png" width="1200"></p> 
<h4 id="T88Fp">3.2.3 Multi-head Distillation(多头知识蒸馏)</h4> 
<p id="uf3ea0521">teach：增加工作量</p> 
<h5 id="b8vym">补充：基于logits的知识蒸馏</h5> 
<p id="u84d08395">参考资料：</p> 
<p id="u174238a1"><a href="https://zhuanlan.zhihu.com/p/102038521" rel="nofollow" title="【经典简读】知识蒸馏(Knowledge Distillation) 经典之作">【经典简读】知识蒸馏(Knowledge Distillation) 经典之作</a></p> 
<p id="u810ff412"><a href="https://intellabs.github.io/distiller/knowledge_distillation.html" rel="nofollow" title="Knowledge Distillation - Neural Network Distiller">Knowledge Distillation - Neural Network Distiller</a></p> 
<p id="u204e42c9"></p> 
<p class="img-center"><img alt="" height="689" id="ud983416f" src="https://images2.imgbox.com/8a/1c/OT8Qg269_o.png" width="1200"></p> 
<p id="u830daabd">高温蒸馏过程的目标函数由distill loss(对应Soft-target)和Student loss(对应Hard-target)加权得到<img alt="L={\alpha}L_{soft}+{\beta}L_{hard}" class="mathcode" src="https://images2.imgbox.com/d9/17/XAvz7w2j_o.png"></p> 
<p id="u62d03f37">第二部分Loss<img alt="L_{hard}" class="mathcode" src="https://images2.imgbox.com/1f/61/V4sueN3N_o.png">的必要性其实很好理解: Net-T也有一定的错误率，使用ground truth可以有效降低错误被传播给Net-S的可能。打个比方，老师虽然学识远远超过学生，但是老师仍然有出错的可能，而这时候如果学生在老师的教授之外，可以同时参考到标准答案，就可以有效地降低被老师偶尔的错误“带偏”的可能性。</p> 
<h5 id="DYERn">本篇文章多头知识蒸馏的损失函数</h5> 
<p><img alt="f_{\Theta,\Phi}(x)" class="mathcode" src="https://images2.imgbox.com/2e/83/2iSu8vwe_o.png">和<img alt="f_{ \Theta,\Psi}(x)" class="mathcode" src="https://images2.imgbox.com/6b/1e/71wQOJbE_o.png">输出都是分布，所以teacher与student的损失函数为KL散度</p> 
<p><img alt="f_{ \Theta,\Omega}(x)" class="mathcode" src="https://images2.imgbox.com/42/de/t9d8XViR_o.png">的输出不是一个分布(me应该是：是否为这张变换后的图1与图2，它们的原图是否相同，即Yes/No)，所以teacher与student的损失函数为L2</p> 
<p id="u3db05118">(但是这篇论文我没有看到介绍损失函数L2的地方！！！)</p> 
<p id="u1215a02a"></p> 
<p class="img-center"><img alt="" height="135" id="ua47fa1e7" src="https://images2.imgbox.com/98/6b/xzlEwBha_o.png" width="990"></p> 
<h4 id="hVUgH">Overall Objective总体目标</h4> 
<p><img alt="\mathcal{L}_{inductive}=\underset{x\sim{D_b},v^{'}\sim{D_n}}{E}[ \mathcal{L}_{eq}(f_{ \Theta,\Psi}(x),u) +\mathcal{L}_{in}(f_{ \Theta,\Omega}(x),v^{'}) +\mathcal{L}_{kd}(f_{ \Theta,\Phi}^{.,t}(x),f_{ \Theta,\Psi}^{.,t}(x),f_{ \Theta,\Omega}^{.,t}(x)) ]" class="mathcode" src="https://images2.imgbox.com/49/7a/2NYbk9H4_o.png"></p> 
<p id="uc15fc7f1">The overall loss is simply a combination of inductive andbaseline objectives</p> 
<p><img alt="\mathcal{L}=\mathcal{L}_{baseline}+\mathcal{L}_{inductive}" class="mathcode" src="https://images2.imgbox.com/d4/ea/kRviyeVT_o.png"></p> 
<h2 id="VI82n">4.Experimental Evaluation</h2> 
<p id="u75c020e1">teach：这篇文章一个引用量上不去的其中一个原因就是性能太高了，其他文章不好超过这篇文章，所以直接不引用；另外没有给这篇文章的方法一个缩写，不好被别人引用，所以写文章时最好将自己取一个简称，比如说首字母的缩写，方便别人引用、记住。</p> 
<p id="udc653188">在两个常用数据集miniImageNet and tieredImageNet以及CIFAR100的子集CIFAR-FSand FC100 进行实验</p> 
<p id="u1ea65555">CIFAR-FS dataset</p> 
<p></p> 
<p class="img-center"><img alt="" height="930" id="ubc826710" src="https://images2.imgbox.com/12/32/55j3YtaF_o.png" width="952"></p> 
<p id="u2bbb2676">FC100 dataset</p> 
<p id="u6fc6a6f5"></p> 
<p class="img-center"><img alt="" height="719" id="ud3622be8" src="https://images2.imgbox.com/f4/00/ajk8qjzY_o.png" width="944"></p> 
<p id="uf634463f">miniImageNet dataset</p> 
<p id="ue0a1e2cd"></p> 
<p class="img-center"><img alt="" height="1135" id="u65950e3b" src="https://images2.imgbox.com/3d/55/gd7c7Mfr_o.png" width="959"></p> 
<h3 id="RdoU1">4.1. Results</h3> 
<p id="ub2c07a13">tieredImageNet dataset</p> 
<p id="ua139036a"></p> 
<p class="img-center"><img alt="" height="850" id="u135f9b9d" src="https://images2.imgbox.com/2e/bc/BKu11iEK_o.png" width="962"></p> 
<h3 id="L3yfa">4.3. Analysis</h3> 
<p id="u141381ab">从miniImageNet随机5个类别中分类的可视化结果</p> 
<p id="u9e5c2df1"></p> 
<p class="img-center"><img alt="" height="856" id="u042598ad" src="https://images2.imgbox.com/f6/78/txJckJhS_o.png" width="1139"></p> 
<h2 id="ubTVi">参考资料</h2> 
<h3 id="Q6cqP">论文下载</h3> 
<p id="u92ed1477"><a href="https://www.yuque.com/attachments/yuque/0/2023/pdf/27783288/1702458789778-5cd95109-451b-4811-8c51-a875de43fc94.pdf" rel="nofollow" id="uf64321de" title="📎Exploring Complementary Strengths of Invariant and Equivariant.pdf">📎Exploring Complementary Strengths of Invariant and Equivariant.pdf</a></p> 
<p></p> 
<p class="img-center"><img alt="" height="1200" id="ue2cfe85a" src="https://images2.imgbox.com/a8/9c/swstxt2v_o.png" width="1200"></p> 
<h3 id="VArOi">代码</h3> 
<p id="u79f2aa8b"><a href="https://github.com/nayeemrizve/invariance-equivariance" title='GitHub - nayeemrizve/invariance-equivariance: "Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning" by Mamshad Nayeem Rizve, Salman Khan, Fahad Shahbaz Khan, Mubarak Shah (CVPR 2021)'>GitHub - nayeemrizve/invariance-equivariance: "Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning" by Mamshad Nayeem Rizve, Salman Khan, Fahad Shahbaz Khan, Mubarak Shah (CVPR 2021)</a></p> 
<h3 id="ci93F">参考资料</h3> 
<p id="u5d5e812e">本篇文章的teach是指这个视频作者的观点</p> 
<p id="u041ea34c"><a href="https://www.bilibili.com/video/BV1yM41167qv/?spm_id_from=333.788&amp;vd_source=cf47665832420f76ef74d8895da61046" rel="nofollow" title="【CVPR 2021】小样本学习论文解读 | IERs:Exploring Complementary Strengths of Invariant ..._哔哩哔哩_bilibili">【CVPR 2021】小样本学习论文解读 | IERs:Exploring Complementary Strengths of Invariant ..._哔哩哔哩_bilibili</a></p> 
<p id="ube06f71b">下面这个博客未参考上</p> 
<p id="u94f5400a"><a href="https://blog.csdn.net/qq_29260257/article/details/122727408?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170253457916800182761737%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=170253457916800182761737&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-1-122727408-null-null.142%5Ev96%5Epc_search_result_base7&amp;utm_term=Exploring%20Complementary%20Strengths%20of%20Invariant%20and%20EquivariantRepresentations%20for%20Few-Shot%20Learning&amp;spm=1018.2226.3001.4187" title="Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning-CSDN博客">Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning-CSDN博客</a></p> 
<p id="u949402ef">知识蒸馏相关</p> 
<p id="uf60aabca"><a href="https://blog.csdn.net/Datawhale/article/details/115258087?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%9F%BA%20%E4%BA%8Elogits%E7%9A%84%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-115258087.142%5Ev96%5Epc_search_result_base7&amp;spm=1018.2226.3001.4187" title="深度学习中的知识蒸馏技术！-CSDN博客">深度学习中的知识蒸馏技术！-CSDN博客</a></p> 
<p id="u4cfb7f40">离线：</p> 
<p id="u9f5d4439"><a href="https://www.yuque.com/attachments/yuque/0/2023/html/27783288/1702553966897-dadcbb49-1db7-4db2-b048-45c8cc23c06b.html" rel="nofollow" id="u36f4eaf8" title="📎深度学习中的知识蒸馏技术！-CSDN博客 (2023_12_14 19_39_02).html">📎深度学习中的知识蒸馏技术！-CSDN博客 (2023_12_14 19_39_02).html</a></p> 
<p id="u0f7fe56d"><a href="https://intellabs.github.io/distiller/knowledge_distillation.html" rel="nofollow" title="Knowledge Distillation - Neural Network Distiller">Knowledge Distillation - Neural Network Distiller</a></p> 
<p id="u8bcb3199"><a href="https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/124395112?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522170255315416800180617262%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=170255315416800180617262&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-2-124395112-null-null.142%5Ev96%5Epc_search_result_base7&amp;utm_term=%E5%9F%BA%20%E4%BA%8Elogits%E7%9A%84%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F&amp;spm=1018.2226.3001.4187" title="目标检测-定位蒸馏：logit蒸馏与feature蒸馏之争-CSDN博客">目标检测-定位蒸馏：logit蒸馏与feature蒸馏之争-CSDN博客</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dd48f91fce38637909d1d608697a1b21/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">分享一个项目——Sambert UI 声音克隆</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7453a13e33dcc5dcc8aa1d81b41aab9f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">按钮背景图片闪动5秒然后停住</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>