<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop3.3.1完全分布式安装Centos7.x - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop3.3.1完全分布式安装Centos7.x" />
<meta property="og:description" content="目录
一、准备文件
二、环境准备（安装CentOS7）
三、主机基本设置
关闭防火墙（两个都关）
修改主机名和从机名（改为Master和Slave1）
创建用户（Master和Slave1都创建）
创建目录
配置当前非root用户具有root的权限
ssh免密登录
将jdk和hadoop安装包传到虚拟机（主从机）（使用winSCP）
四、JDK的安装
卸载系统自带的JDK(主机从机都卸载)
五、安装 Hadoop 3.3.1
配置PATH变量
六、配置集群/分布式环境
（1）修改文件workers
（2）修改文件
（3）修改文件hdfs-site.xml
（4）修改文件mapred-site.xml
（5）修改文件 yarn-site.xml
七、将hadoop分发到slave1节点
一、准备文件 所用到 Hadoop3.3.1 、 JDK1.8_271 、CentOs7.x、xshell、winSCP
http://链接: https://pan.baidu.com/s/1nT0O3F0D65Y5QrrY9qHpxQ?pwd=2agi 提取码: 2agi 复制这段内容后打开百度网盘手机App，操作更方便哦
二、环境准备（安装CentOS7） 打开下载安装好的VMware Workstation
点击做左上角的文件-&gt;新建虚拟机-&gt;点击下一步
浏览选择下载好的CentOS7-&gt;下一步-&gt;
名称Master,位置自己选择一个喜欢的目录-&gt;下一步
选择自己需要的大小，和储存方式-&gt;下一步-&gt;完成
安装时出现的界面点enter就行
选择自己喜欢的语言，我这里选的是中文简体
选择好点击继续（下面配置网络比较重要）
安装位置选择
刚刚分配的20GB磁盘，点击完成
点击网络和主机（比较重要）
点击右边的打开，就会自动获取p地址（记住这个ip），并显示已连接，如果没链接成功，建议检查虚拟机设置，避免后面的麻烦。
然后点击完成-&gt;开始安装
点击设置一个root密码，等待安装完成（泡杯枸杞喝，别整电脑上）
安装完成后点重启
完整完成
这里搭建一主一从，一主多从（类似)
关闭虚拟机， 选择克隆-.下一步-&gt;下一步
选择自己喜欢的路径点击完成（如果选择了完全克隆时间可能长一点）
完成后启动master和slave1 查看master 和 slave1的ip ip add 使用xshell 链接虚拟机进行操作（为了方便操作），使用winSCP链接虚拟机（传文件用），
连接好下面在xshell里面进行操作。
三、主机基本设置 关闭防火墙（两个都关） # 在root用户下执行 systemctl stop firewalld systemctl disable firewalld." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e51702ee3d34a5260a8f739867647728/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-25T00:03:20+08:00" />
<meta property="article:modified_time" content="2023-11-25T00:03:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop3.3.1完全分布式安装Centos7.x</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>目录</strong></p> 
<p style="margin-left:0px;"><a href="#%E4%B8%80%E3%80%81%E5%87%86%E5%A4%87%E6%96%87%E4%BB%B6" rel="nofollow">一、准备文件</a></p> 
<p style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87" rel="nofollow">二、环境准备（安装CentOS7）</a></p> 
<p style="margin-left:0px;"><a href="#%E4%B8%89%E3%80%81%E4%B8%BB%E6%9C%BA%E5%9F%BA%E6%9C%AC%E8%AE%BE%E7%BD%AE" rel="nofollow">三、主机基本设置</a></p> 
<p style="margin-left:80px;"><a href="#%E5%85%B3%E9%97%AD%E9%98%B2%E7%81%AB%E5%A2%99" rel="nofollow">关闭防火墙（两个都关）</a></p> 
<p style="margin-left:80px;"><a href="#%E4%BF%AE%E6%94%B9%E4%B8%BB%E6%9C%BA%E5%90%8D" rel="nofollow">修改主机名和从机名（改为Master和Slave1）</a></p> 
<p style="margin-left:80px;"><a href="#%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7" rel="nofollow">创建用户（Master和Slave1都创建）</a></p> 
<p style="margin-left:80px;"><a href="#%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95" rel="nofollow">创建目录</a></p> 
<p style="margin-left:80px;"><a href="#%E9%85%8D%E7%BD%AE%E5%BD%93%E5%89%8D%E9%9D%9Eroot%E7%94%A8%E6%88%B7%E5%85%B7%E6%9C%89root%E7%9A%84%E6%9D%83%E9%99%90" rel="nofollow">配置当前非root用户具有root的权限</a></p> 
<p style="margin-left:40px;">        <a href="#ssh%E5%85%8D%E5%AF%86%E7%99%BB%E5%BD%95" rel="nofollow">ssh免密登录</a></p> 
<p style="margin-left:40px;">        <a href="#%E5%B0%86jdk%E5%92%8Chadoop%E5%AE%89%E8%A3%85%E5%8C%85%E4%BC%A0%E5%88%B0%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%88%E4%BD%BF%E7%94%A8winSCP%EF%BC%89" rel="nofollow">将jdk和hadoop安装包传到虚拟机（主从机）（使用winSCP）</a></p> 
<p style="margin-left:0px;"><a href="#%C2%A0%E5%9B%9B%E3%80%81JDK%E7%9A%84%E5%AE%89%E8%A3%85" rel="nofollow"> 四、JDK的安装</a></p> 
<p style="margin-left:80px;"><a href="#%E5%8D%B8%E8%BD%BD%E7%B3%BB%E7%BB%9F%E8%87%AA%E5%B8%A6%E7%9A%84JDK" rel="nofollow">卸载系统自带的JDK(主机从机都卸载)</a></p> 
<p style="margin-left:0px;"><a href="#%E4%BA%94%E3%80%81%E5%AE%89%E8%A3%85%20Hadoop%203.3.1" rel="nofollow">五、安装 Hadoop 3.3.1</a></p> 
<p style="margin-left:0px;">               <a href="#%C2%A0%E9%85%8D%E7%BD%AEPATH%E5%8F%98%E9%87%8F" rel="nofollow"> 配置PATH变量</a></p> 
<p style="margin-left:0px;"><a href="#%E5%85%AD%E3%80%81%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%2F%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83" rel="nofollow">六、配置集群/分布式环境</a></p> 
<p style="margin-left:40px;"><a href="#%EF%BC%881%EF%BC%89%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6workers" rel="nofollow">（1）修改文件workers</a></p> 
<p style="margin-left:40px;"><a href="#%EF%BC%882%EF%BC%89%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6" rel="nofollow">（2）修改文件</a></p> 
<p style="margin-left:40px;"><a href="#%EF%BC%883%EF%BC%89%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6hdfs-site.xml" rel="nofollow">（3）修改文件hdfs-site.xml</a></p> 
<p style="margin-left:40px;"><a href="#%EF%BC%884%EF%BC%89%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6mapred-site.xml" rel="nofollow">（4）修改文件mapred-site.xml</a></p> 
<p style="margin-left:40px;"><a href="#%EF%BC%885%EF%BC%89%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%20yarn-site.xml" rel="nofollow">（5）修改文件 yarn-site.xml</a></p> 
<p style="margin-left:0px;"><a href="#%E4%B8%83%E3%80%81%E4%BA%94%E3%80%81%E5%B0%86hadoop%E5%88%86%E5%8F%91%E5%88%B0slave1%E8%8A%82%E7%82%B9" rel="nofollow">七、将hadoop分发到slave1节点</a></p> 
<hr> 
<p> </p> 
<h2>一、准备文件</h2> 
<p>所用到  Hadoop3.3.1 、 JDK1.8_271 、CentOs7.x、xshell、winSCP</p> 
<p><a class="link-info" href="http://xn--gzu811i//pan.baidu.com/s/1nT0O3F0D65Y5QrrY9qHpxQ?pwd=2agi%20%E6%8F%90%E5%8F%96%E7%A0%81:%202agi%20%E5%A4%8D%E5%88%B6%E8%BF%99%E6%AE%B5%E5%86%85%E5%AE%B9%E5%90%8E%E6%89%93%E5%BC%80%E7%99%BE%E5%BA%A6%E7%BD%91%E7%9B%98%E6%89%8B%E6%9C%BAApp%EF%BC%8C%E6%93%8D%E4%BD%9C%E6%9B%B4%E6%96%B9%E4%BE%BF%E5%93%A6" rel="nofollow" title="http://链接: https://pan.baidu.com/s/1nT0O3F0D65Y5QrrY9qHpxQ?pwd=2agi 提取码: 2agi 复制这段内容后打开百度网盘手机App，操作更方便哦">http://链接: https://pan.baidu.com/s/1nT0O3F0D65Y5QrrY9qHpxQ?pwd=2agi 提取码: 2agi 复制这段内容后打开百度网盘手机App，操作更方便哦</a></p> 
<h2>二、环境准备（安装CentOS7）</h2> 
<p>打开下载安装好的VMware  Workstation</p> 
<p>点击做左上角的文件-&gt;新建虚拟机-&gt;点击下一步</p> 
<p><img src="https://images2.imgbox.com/62/fc/JfzqBVp2_o.png" alt="19f9072f96f14be7b316c5b563bcf4da.png"></p> 
<p> 浏览选择下载好的CentOS7-&gt;下一步-&gt;</p> 
<p><img src="https://images2.imgbox.com/d6/b9/aXOa5JmI_o.png" alt="8bf71752b5944bae85446d52f356ebcf.png"></p> 
<p> 名称Master,位置自己选择一个喜欢的目录-&gt;下一步</p> 
<p><img src="https://images2.imgbox.com/c3/0f/Of1Z1JHA_o.png" alt="483b6b553e3c4024858d0deac81dc4e0.png"></p> 
<p> 选择自己需要的大小，和储存方式-&gt;下一步-&gt;完成</p> 
<p>安装时出现的界面点enter就行</p> 
<p><img src="https://images2.imgbox.com/bc/38/5bh8qUC7_o.png" alt="81c7e573effb4c7599f0fb72abcbd399.png"></p> 
<p>选择自己喜欢的语言，我这里选的是中文简体</p> 
<p>选择好点击继续（下面配置网络比较重要）</p> 
<p> <img src="https://images2.imgbox.com/fe/15/KUxA14t3_o.png" alt="8c33bfd4284f43d894d264b713413f7a.png"></p> 
<p> 安装位置选择</p> 
<p><img src="https://images2.imgbox.com/55/b9/1u8iRk3e_o.png" alt="2fc38f5df5fa48eb9e3b4177801d63de.png"></p> 
<p> 刚刚分配的20GB磁盘，点击完成</p> 
<p>点击网络和主机（比较重要）</p> 
<p><img src="https://images2.imgbox.com/81/4a/Y60YV5wD_o.png" alt="dc06a865830b4214a6177faef7208c44.png"></p> 
<p>点击右边的打开，就会自动获取p地址（记住这个ip），并显示已连接，如果没链接成功，建议检查虚拟机设置，避免后面的麻烦。</p> 
<p> 然后点击完成-&gt;开始安装</p> 
<p><img src="https://images2.imgbox.com/ca/3f/c1rlbqk1_o.png" alt="906342738b1a4da9b4add0494367b5c8.png"></p> 
<p>点击设置一个root密码，等待安装完成（泡杯枸杞喝，别整电脑上）</p> 
<p>安装完成后点重启</p> 
<p>完整完成</p> 
<p>这里搭建一主一从，一主多从（类似)</p> 
<p>关闭虚拟机， 选择克隆-.下一步-&gt;下一步</p> 
<p><img src="https://images2.imgbox.com/cd/c3/AdbSqv7S_o.png" alt="b55c93d5203d414bbbf9f85221a8c56b.png"></p> 
<p> </p> 
<p><img src="https://images2.imgbox.com/af/0f/altwn1gT_o.png" alt="4a048e75718749acacef0ac4a82b5814.png"></p> 
<p> 选择自己喜欢的路径点击完成（如果选择了完全克隆时间可能长一点）</p> 
<p>完成后启动master和slave1 </p> 
<p>查看master 和 slave1的ip    </p> 
<pre><code>ip add
</code></pre> 
<p>使用xshell 链接虚拟机进行操作（为了方便操作），使用winSCP链接虚拟机（传文件用），</p> 
<p>连接好下面在xshell里面进行操作。</p> 
<h2>三、主机基本设置</h2> 
<ul><li> <h4>关闭防火墙（<em>两个都关</em>）</h4> </li></ul> 
<pre><code># 在root用户下执行
systemctl stop firewalld
systemctl disable firewalld.service</code></pre> 
<ul><li>更新源（两个都更新）</li></ul> 
<p>我们在下载软件时，可能会因为网络原因而下载失败，因此我们选择更新软件源，输入以下命令更新软件源：</p> 
<pre><code>yum -y update # 更新源
</code></pre> 
<ul><li> <p>修改主机配置文件</p> </li></ul> 
<pre><code>vi /etc/hosts
 
# 添加以下内容
192.168.94.132 Master
192.168.94.133 Slave1</code></pre> 
<ul><li> <h4>修改主机名和从机名（改为Master和Slave1）</h4> </li></ul> 
<pre><code># 使用以下的命令
vi /etc/hostname</code></pre> 
<ul><li> <h4>创建用户（Master和Slave1都创建）</h4> </li></ul> 
<pre><code># 2、创建用户，在root用户下
useradd hadoop
passwd hadoop</code></pre> 
<ul><li> <h4>创建目录</h4> </li></ul> 
<pre><code>cd /usr/local
 
# 存放安装好的软件
mkdir server
 
# 存放安装包
mkdir software 
 
# 给server和software授权 
chown -R hadoop:hadoop ./server
chown -R hadoop:hadoop ./software
 
# 其他两个节点做以上相同的操作</code></pre> 
<ul><li> <h4>配置当前非root用户具有root的权限</h4> </li></ul> 
<pre><code>vi /etc/sudoers
 
## Allow root to run any commands anywhere
root    ALL=(ALL)       ALL
hadoop  ALL=(ALL)       ALL</code></pre> 
<ul><li> <h3>ssh免密登录</h3> </li></ul> 
<pre><code># 在命令行输入，根据提示输入密码即可
ssh localhost
 
# 切换到~/.ssh目录下
cd ~/.ssh
 
# 输入以下命令,期间连续按三次回车
ssh-keygen -t rsa
 
# 分发密钥，期间在输入密码即可免密登录
ssh-copy-id Master
ssh-copy-id Slave1 
 
# 三个节点依次按照以上命令操作，再次输入ssh 相应的主机名,已经不需要密码登录master、slave1、slave2节点了

#在Msater 主机下输入  
ssh Slave1

#在Slave1下输入ssh Master


#如果不需要输入密码，则成功
#不成功重启机器，重新设置免密登录，或者检查前面设置的主机名，和地址</code></pre> 
<ul><li> <h3>将jdk和hadoop安装包传到虚拟机（主从机）（使用winSCP）</h3> </li></ul> 
<p><img src="https://images2.imgbox.com/17/5d/GludaRwW_o.png" alt="66a26c590f8240398dadc39d8bd0a0d8.png"></p> 
<h2> 四、JDK的安装</h2> 
<ul><li> <h4>卸载系统自带的JDK(主机从机都卸载)</h4> </li></ul> 
<pre><code># 查看系统自带的jdk
rpm -qa | grep jdk
 
#没有内容则跳过下面的操作
# 卸载找到的jdk
yum -y remove 找到的jdk
 
# 或者使用以下的命令删除
rpm -qa | grep -i java | xargs -n1 rpm -e --nodeps</code></pre> 
<ul><li> <p><strong>安装JDK</strong>（主从机）</p> </li></ul> 
<p>第一步，执行下面命令进入hadoop用户</p> 
<pre><code>su hadoop</code></pre> 
<p>第二步，执行以下命令解压缩JDK文件（注意：当前登录用户名是hadoop），如下所示：</p> 
<pre><code>cd /usr/local/software  # 进入存放软件的目录
sudo mkdir -p /usr/lib/jvm # 创建/usr/lib/jvm目录用来存放JDK文件
sudo tar -zxvf jdk-8u271-linux-x64.tar.gz -C /usr/lib/jvm # 把JDK文件解压到/usr/lib/jvm目录下</code></pre> 
<p><img src="https://images2.imgbox.com/33/5b/d23tVXyw_o.png" alt="c9d30aec47e2488684b39fccbc10fdc2.png"></p> 
<p> JDK 文件解压成功后，可以执行以下命令进行查看：<br>  </p> 
<pre><code>cd /usr/lib/jvm # 进入/usr/lib/jvm目录下
ls #查看当前目录（即/usr/lib/jvm）的文件</code></pre> 
<p><img src="https://images2.imgbox.com/a2/83/JtsewGfV_o.png" alt="2b1ce7ca62aa4259a65a6398d59020e9.png"></p> 
<p>可以看到，/usr/lib/jvm 目录下有一个 jdk1.8.0_131 目录</p> 
<p>第三步，执行以下命令配置环境变量（注意：当前登录用户名是 hadoop），如下所示：</p> 
<pre><code>cd ~ # 进入用户家目录，注意：~ 等价于 /home/hadoop
sudo vi ~/.bash_profile # 编辑当前hadoop用户的环境变量配置文件(该文件只影响当前用户)
</code></pre> 
<p><br> 打开文件后，在文件末尾处添加以下内容（ jdk 版本根据个人安装版本进行填写），保存并退出：</p> 
<pre><code>[hadoop@Master ~]$ sudo vi ~/.bash_profile

# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

# User specific environment and startup programs

PATH=$PATH:$HOME/.local/bin:$HOME/bin

export PATH


export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_271
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
~                                                                                                        
"/home/hadoop/.bash_profile" 12L, 193C
</code></pre> 
<p><br> 继续执行以下命令使环境变量配置生效：</p> 
<pre><code>source ~/.bash_profile
</code></pre> 
<p><br> 然后可以执行以下命令查看是否安装成功：</p> 
<pre><code>java -version
</code></pre> 
<p><img src="https://images2.imgbox.com/28/6a/dqC1EgrZ_o.png" alt="6b747e11305341c7bfe39df25b7d258f.png"><br> 如果屏幕上返回如下信息，则说明安装成功：</p> 
<h2>五、安装 Hadoop 3.3.1</h2> 
<p>第二步，执行以下命令解压缩 hadoop3.3.1 文件（注意：当前登录用户名是 hadoop），如下所示：</p> 
<pre><code>cd /usr/local/software   #进入安装包目录
sudo tar -zxf hadoop-3.3.1.tar.gz -C /usr/local # 解压到/usr/local中
cd /usr/local/ # 进入/usr/local目录下                     
sudo mv ./hadoop-3.3.1/ ./hadoop # 将hadoop-3.3.1文件夹名改为hadoop
sudo chown -R hadoop ./hadoop # 修改文件权限
</code></pre> 
<p>Hadoop 解压后即可使用，输入以下命令检查 Hadoop 是否可用，成功则会显示 Hadoop 版本信息：</p> 
<blockquote> 
 <pre><code>cd /usr/local/hadoop # 进入/usr/local/hadoop目录
./bin/hadoop version # 查看hadoop版本信息</code></pre> 
</blockquote> 
<p><img src="https://images2.imgbox.com/f3/88/EtnJ6ChV_o.png" alt="05828a38a77b472fb08b6c1fa891ba2c.png"></p> 
<h2> 配置PATH变量</h2> 
<p>这样就可以在任意目录中直接使用hadoop、hdfs等命令了。如果还没有配置PATH变量，那么需要在Master节点上进行配置。 首先执行命令“vi ~/.bashrc”，也就是使用vi编辑器打开“~/.bashrc”文件，然后，在该文件最上面的位置加入下面一行内容：</p> 
<pre><code>export PATH=$PATH:/usr/local/hadoop/bin:/usr/local/hadoop/sbin
</code></pre> 
<p>保存后执行命令“source ~/.bashrc”，使配置生效。</p> 
<h2>六、配置集群/分布式环境</h2> 
<p>在配置集群/分布式模式时，需要修改“</p> 
<pre><code>cd /usr/local/hadoop/etc/hadoop</code></pre> 
<p>”目录下的配置文件，这里仅设置正常启动所必须的设置项，包括workers 、core-site.xml、hdfs-site.xml、mapred-site.xml、yarn-site.xml共5个文件，更多设置项可查看官方说明。</p> 
<p> </p> 
<h3>（1）修改文件workers</h3> 
<p>需要把所有数据节点的主机名写入该文件，每行一个，默认为 localhost（即把本机作为数据节点），所以，在伪分布式配置时，就采用了这种默认的配置，使得节点既作为名称节点也作为数据节点。在进行分布式配置时，可以保留localhost，让Master节点同时充当名称节点和数据节点，或者也可以删掉localhost这行，让Master节点仅作为名称节点使用。</p> 
<pre><code>vi workers</code></pre> 
<p>本教程让Master节点仅作为名称节点使用，因此将workers文件中原来的localhost删除，只添加如下一行内容：</p> 
<pre><code>Slave1
</code></pre> 
<h3>（2）修改文件</h3> 
<pre><code>vi core-site.xml</code></pre> 
<p>请把core-site.xml文件(&lt;configuration&gt;标签） 改为下面的内容)修改为如下内容：</p> 
<pre><code>&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;fs.defaultFS&lt;/name&gt;
                &lt;value&gt;hdfs://Master:9000&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
                &lt;value&gt;file:/usr/local/hadoop/tmp&lt;/value&gt;
                &lt;description&gt;Abase for other temporary directories.&lt;/description&gt;
        &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<h3>（3）修改文件hdfs-site.xml</h3> 
<p>对于Hadoop的分布式文件系统HDFS而言，一般都是采用冗余存储，冗余因子通常为3，也就是说，一份数据保存三份副本。但是，本教程只有一个Slave节点作为数据节点，即集群中只有一个数据节点，数据只能保存一份，所以 ，dfs.replication的值还是设置为 1。hdfs-site.xml具体内容如下：</p> 
<pre><code>&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
                &lt;value&gt;Master:50090&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.replication&lt;/name&gt;
                &lt;value&gt;1&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/name&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
                &lt;value&gt;file:/usr/local/hadoop/tmp/dfs/data&lt;/value&gt;
        &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<h3>（4）修改文件mapred-site.xml</h3> 
<p>“/usr/local/hadoop/etc/hadoop”目录下有一个mapred-site.xml.template，需要修改文件名称，把它重命名为mapred-site.xml，然后，把mapred-site.xml文件配置成如下内容：</p> 
<pre><code>&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
                &lt;value&gt;yarn&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
                &lt;value&gt;Master:10020&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
                &lt;value&gt;Master:19888&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
                &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.map.env&lt;/name&gt;
                &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
                &lt;value&gt;HADOOP_MAPRED_HOME=/usr/local/hadoop&lt;/value&gt;
        &lt;/property&gt; 
&lt;/configuration&gt;
</code></pre> 
<h3>（5）修改文件 yarn-site.xml</h3> 
<p> </p> 
<pre><code>&lt;configuration&gt;
        &lt;property&gt;
                &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
                &lt;value&gt;Master&lt;/value&gt;
        &lt;/property&gt;
        &lt;property&gt;
                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
        &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
<p>上述5个文件全部配置完成以后，需要把Master节点上的“/usr/local/hadoop”文件夹复制到各个节点上</p> 
<h2>七、将hadoop分发到slave1节点</h2> 
<p>Master节点上执行如下命令：</p> 
<pre><code>cd /usr/local
tar -zcf ~/hadoop.master.tar.gz ./hadoop   # 先压缩再复制
cd ~
scp ./hadoop.master.tar.gz Slave1:/home/hadoop

</code></pre> 
<p>然后在Slave1节点上执行如下命令：</p> 
<pre><code>sudo rm -r /usr/local/hadoop # 删掉旧的（如果存在）
sudo tar -zxf ~/hadoop.master.tar.gz -C /usr/local
sudo chown -R hadoop /usr/local/hadoop</code></pre> 
<p>现在就可以启动Hadoop了，启动需要在Master节点上进行，执行如下命令：</p> 
<pre><code>hdfs namenode -format
start-dfs.sh

start-yarn.sh

mr-jobhistory-daemon.sh start historyserver

</code></pre> 
<p>通过命令jps可以查看各个节点所启动的进程。如果已经正确启动</p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5c1e2f5a4a0fae0c4dc8418747781f57/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">疑似威胁人类？OpenAI神秘Q*项目更多信息曝光，马斯克、Lecun下场争论…</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5054591196a912e34ae0cb5a68844d9d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何省略springboot项目中的@Param注解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>