<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Qualcomm® AI Engine Direct 使用手册（17） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Qualcomm® AI Engine Direct 使用手册（17）" />
<meta property="og:description" content="Qualcomm® AI Engine Direct 使用手册（17） 6.3 执行 6.3 执行 qnn 网络运行
qnn-net-run工具用于使用从 QNN 转换器的输出编译的模型库，并在特定后端上运行它。
DESCRIPTION: ------------ Example application demonstrating how to load and execute a neural network using QNN APIs. REQUIRED ARGUMENTS: ------------------- --model &lt;FILE&gt; Path to the model containing a QNN network. To compose multiple graphs, use comma-separated list of model.so files. The syntax is &lt;qnn_model_name_1.so&gt;,&lt;qnn_model_name_2.so&gt;. --backend &lt;FILE&gt; Path to a QNN backend to execute the model. --input_list &lt;FILE&gt; Path to a file listing the inputs for the network." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/dc7acaee62f0c5cc2b5f77a993ceeb23/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-04T14:49:38+08:00" />
<meta property="article:modified_time" content="2024-01-04T14:49:38+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Qualcomm® AI Engine Direct 使用手册（17）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>Qualcomm® AI Engine Direct 使用手册（17）</h4> 
 <ul><li><ul><li><a href="#63__5" rel="nofollow">6.3 执行</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h3><a id="63__5"></a>6.3 执行</h3> 
<p>qnn 网络运行<br> qnn-net-run工具用于使用从 QNN 转换器的输出编译的模型库，并在特定后端上运行它。</p> 
<pre><code class="prism language-cpp">DESCRIPTION<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span>
Example application demonstrating how to load <span class="token operator">and</span> execute a neural network
<span class="token keyword">using</span> QNN APIs<span class="token punctuation">.</span>


REQUIRED ARGUMENTS<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
  <span class="token operator">--</span>model             <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>       Path to the model containing a QNN network<span class="token punctuation">.</span>
                                   To compose multiple graphs<span class="token punctuation">,</span> use comma<span class="token operator">-</span>separated list of
                                   model<span class="token punctuation">.</span>so files<span class="token punctuation">.</span> The syntax is
                                   <span class="token operator">&lt;</span>qnn_model_name_1<span class="token punctuation">.</span>so<span class="token operator">&gt;</span><span class="token punctuation">,</span><span class="token operator">&lt;</span>qnn_model_name_2<span class="token punctuation">.</span>so<span class="token operator">&gt;</span><span class="token punctuation">.</span>

  <span class="token operator">--</span>backend           <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>       Path to a QNN backend to execute the model<span class="token punctuation">.</span>

  <span class="token operator">--</span>input_list        <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>       Path to a file listing the inputs <span class="token keyword">for</span> the network<span class="token punctuation">.</span>
                                   If there are multiple graphs in model<span class="token punctuation">.</span>so<span class="token punctuation">,</span> <span class="token keyword">this</span> has
                                   to be comma<span class="token operator">-</span>separated list of input list files<span class="token punctuation">.</span>
                                   When multiple graphs are present<span class="token punctuation">,</span> to skip execution of a graph use
                                   <span class="token string">"__"</span><span class="token punctuation">(</span><span class="token keyword">double</span> underscore without quotes<span class="token punctuation">)</span> as the file name in the
                                   comma<span class="token operator">-</span>seperated list of input list files<span class="token punctuation">.</span>

  <span class="token operator">--</span>retrieve_context  <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Path to cached binary from which to load a saved
                                  context from <span class="token operator">and</span> execute graphs<span class="token punctuation">.</span> <span class="token operator">--</span>retrieve_context <span class="token operator">and</span>
                                  <span class="token operator">--</span>model are mutually exclusive<span class="token punctuation">.</span> Only one of the options
                                  can be specified at a time<span class="token punctuation">.</span>


OPTIONAL ARGUMENTS<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span><span class="token operator">-</span>
  <span class="token operator">--</span>model_prefix                             Function prefix to use when loading <span class="token operator">&lt;</span>qnn_model_name<span class="token punctuation">.</span>so<span class="token operator">&gt;</span><span class="token punctuation">.</span>
                                             Default<span class="token operator">:</span> QnnModel

  <span class="token operator">--</span>debug                                    Specifies that output from all layers of the network
                                             will be saved<span class="token punctuation">.</span> This option can <span class="token operator">not</span> be used when loading
                                             a saved context through <span class="token operator">--</span>retrieve_context option<span class="token punctuation">.</span>

  <span class="token operator">--</span>output_dir                   <span class="token operator">&lt;</span>DIR<span class="token operator">&gt;</span>       The directory to save output to<span class="token punctuation">.</span> Defaults to <span class="token punctuation">.</span><span class="token operator">/</span>output<span class="token punctuation">.</span>

  <span class="token operator">--</span>use_native_output_files                  Specifies that the output files will be generated in the data
                                             type native to the graph<span class="token punctuation">.</span> If <span class="token operator">not</span> specified<span class="token punctuation">,</span> output files will
                                             be generated in floating point<span class="token punctuation">.</span>

  <span class="token operator">--</span>use_native_input_files                   Specifies that the input files will be parsed in the data
                                             type native to the graph<span class="token punctuation">.</span> If <span class="token operator">not</span> specified<span class="token punctuation">,</span> input files will
                                             be parsed in floating point<span class="token punctuation">.</span> Note that options <span class="token operator">--</span>use_native_input_files
                                             <span class="token operator">and</span> <span class="token operator">--</span>native_input_tensor_names are mutually exclusive<span class="token punctuation">.</span>
                                             Only one of the options can be specified at a time<span class="token punctuation">.</span>

  <span class="token operator">--</span>native_input_tensor_names    <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Provide a comma<span class="token operator">-</span>separated list of input tensor names<span class="token punctuation">,</span>
                                             <span class="token keyword">for</span> which the input files would be read<span class="token operator">/</span>parsed in native format<span class="token punctuation">.</span>
                                             Note that options <span class="token operator">--</span>use_native_input_files <span class="token operator">and</span>
                                             <span class="token operator">--</span>native_input_tensor_names are mutually exclusive<span class="token punctuation">.</span>
                                             Only one of the options can be specified at a time<span class="token punctuation">.</span>
                                             The syntax is<span class="token operator">:</span> graphName0<span class="token operator">:</span>tensorName0<span class="token punctuation">,</span>tensorName1<span class="token punctuation">;</span>graphName1<span class="token operator">:</span>tensorName0<span class="token punctuation">,</span>tensorName1

  <span class="token operator">--</span>op_packages                  <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Provide a comma<span class="token operator">-</span>separated list of op packages<span class="token punctuation">,</span> interface
                                             providers<span class="token punctuation">,</span> <span class="token operator">and</span><span class="token punctuation">,</span> optionally<span class="token punctuation">,</span> targets to <span class="token keyword">register</span><span class="token punctuation">.</span> Valid values
                                             <span class="token keyword">for</span> target are CPU <span class="token operator">and</span> HTP<span class="token punctuation">.</span> The syntax is<span class="token operator">:</span>
                                             op_package_path<span class="token operator">:</span>interface_provider<span class="token operator">:</span>target<span class="token punctuation">[</span><span class="token punctuation">,</span>op_package_path<span class="token operator">:</span>interface_provider<span class="token operator">:</span>target<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span>

  <span class="token operator">--</span>profiling_level              <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Enable profiling<span class="token punctuation">.</span> Valid Values<span class="token operator">:</span>
                                               <span class="token number">1.</span> basic<span class="token operator">:</span>    captures execution <span class="token operator">and</span> init time<span class="token punctuation">.</span>
                                               <span class="token number">2.</span> detailed<span class="token operator">:</span> in addition to basic<span class="token punctuation">,</span> captures per Op timing
                                                            <span class="token keyword">for</span> execution<span class="token punctuation">,</span> <span class="token keyword">if</span> a backend supports it<span class="token punctuation">.</span>

  <span class="token operator">--</span>perf_profile                 <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies performance profile to be used<span class="token punctuation">.</span> Valid settings are
                                             low_balanced<span class="token punctuation">,</span> balanced<span class="token punctuation">,</span> <span class="token keyword">default</span><span class="token punctuation">,</span> high_performance<span class="token punctuation">,</span>
                                             sustained_high_performance<span class="token punctuation">,</span> burst<span class="token punctuation">,</span> low_power_saver<span class="token punctuation">,</span>
                                             power_saver<span class="token punctuation">,</span> high_power_saver<span class="token punctuation">,</span> extreme_power_saver
                                             <span class="token operator">and</span> system_settings<span class="token punctuation">.</span>
                                             Note<span class="token operator">:</span> perf_profile argument is now deprecated <span class="token keyword">for</span>
                                             HTP backend<span class="token punctuation">,</span> user can specify performance profile
                                             through backend config now<span class="token punctuation">.</span> Please refer to config_file
                                             backend extensions usage section below <span class="token keyword">for</span> more details<span class="token punctuation">.</span>


  <span class="token operator">--</span>config_file                  <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span>      Path to a JSON config file<span class="token punctuation">.</span> The config file currently
                                             supports options related to backend extensions<span class="token punctuation">,</span>
                                             context priority <span class="token operator">and</span> graph configs<span class="token punctuation">.</span> Please refer to SDK
                                             documentation <span class="token keyword">for</span> more details<span class="token punctuation">.</span>

  <span class="token operator">--</span>log_level                    <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies max logging level to be set<span class="token punctuation">.</span> Valid settings<span class="token operator">:</span>
                                             error<span class="token punctuation">,</span> warn<span class="token punctuation">,</span> info<span class="token punctuation">,</span> debug<span class="token punctuation">,</span> <span class="token operator">and</span> verbose<span class="token punctuation">.</span>

  <span class="token operator">--</span>shared_buffer                            Specifies creation of shared buffers <span class="token keyword">for</span> graph I<span class="token operator">/</span>O between the application
                                             <span class="token operator">and</span> the device<span class="token operator">/</span>coprocessor associated with a backend directly<span class="token punctuation">.</span>
                                             This option is currently supported on Android only<span class="token punctuation">.</span>

  <span class="token operator">--</span>synchronous                              Specifies that graphs should be executed synchronously rather than asynchronously<span class="token punctuation">.</span>
                                             If a backend does <span class="token operator">not</span> support asynchronous execution<span class="token punctuation">,</span> <span class="token keyword">this</span> flag is unnecessary<span class="token punctuation">.</span>

  <span class="token operator">--</span>num_inferences               <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the number of inferences<span class="token punctuation">.</span> Loops over the input_list until
                                             the number of inferences has transpired<span class="token punctuation">.</span>

  <span class="token operator">--</span>duration                     <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the duration of the graph execution in seconds<span class="token punctuation">.</span>
                                             Loops over the input_list until <span class="token keyword">this</span> amount of time has transpired<span class="token punctuation">.</span>

  <span class="token operator">--</span>keep_num_outputs             <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the number of outputs to be saved<span class="token punctuation">.</span>
                                             Once the number of outputs reach the limit<span class="token punctuation">,</span> subsequent outputs would be just discarded<span class="token punctuation">.</span>

  <span class="token operator">--</span>batch_multiplier             <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the value with which the batch value in input <span class="token operator">and</span> output tensors dimensions
                                             will be multiplied<span class="token punctuation">.</span> The modified input <span class="token operator">and</span> output tensors will be used only during
                                             the execute graphs<span class="token punctuation">.</span> Composed graphs will still use the tensor dimensions from model<span class="token punctuation">.</span>

  <span class="token operator">--</span>timeout                      <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the value of the timeout <span class="token keyword">for</span> execution of graph in micro seconds<span class="token punctuation">.</span> Please note
                                             <span class="token keyword">using</span> <span class="token keyword">this</span> option with a backend that does <span class="token operator">not</span> support timeout signals results in an error<span class="token punctuation">.</span>

  <span class="token operator">--</span>max_input_cache_tensor_sets  <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the maximum number of input tensor sets that can be cached<span class="token punctuation">.</span>
                                             Use value <span class="token string">"-1"</span> to cache all the input tensors created<span class="token punctuation">.</span>
                                             Note that options <span class="token operator">--</span>max_input_cache_tensor_sets <span class="token operator">and</span> <span class="token operator">--</span>max_input_cache_size_mb are mutually exclusive<span class="token punctuation">.</span>
                                             Only one of the options can be specified at a time<span class="token punctuation">.</span>

  <span class="token operator">--</span>max_input_cache_size_mb      <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>       Specifies the maximum cache size in mega <span class="token function">bytes</span><span class="token punctuation">(</span>MB<span class="token punctuation">)</span><span class="token punctuation">.</span>
                                             Note that options <span class="token operator">--</span>max_input_cache_tensor_sets <span class="token operator">and</span> <span class="token operator">--</span>max_input_cache_size_mb are mutually exclusive<span class="token punctuation">.</span>
                                             Only one of the options can be specified at a time<span class="token punctuation">.</span>

  <span class="token operator">--</span>set_output_tensors          <span class="token operator">&lt;</span>VAL<span class="token operator">&gt;</span>        Provide a comma<span class="token operator">-</span>separated list of intermediate output tensor names<span class="token punctuation">,</span> <span class="token keyword">for</span> which the outputs
                                             will be written in addition to <span class="token keyword">final</span> graph output tensors<span class="token punctuation">.</span> Note that options <span class="token operator">--</span>debug <span class="token operator">and</span>
                                             <span class="token operator">--</span>set_output_tensors are mutually exclusive<span class="token punctuation">.</span> Only one of the options can be specified at a time<span class="token punctuation">.</span>
                                             Also note that <span class="token keyword">this</span> option can <span class="token operator">not</span> be used when graph is retrieved from context binary<span class="token punctuation">,</span>
                                             since the graph is already finalized when retrieved from context binary<span class="token punctuation">.</span>
                                             The syntax is<span class="token operator">:</span> graphName0<span class="token operator">:</span>tensorName0<span class="token punctuation">,</span>tensorName1<span class="token punctuation">;</span>graphName1<span class="token operator">:</span>tensorName0<span class="token punctuation">,</span>tensorName1

  <span class="token operator">--</span>version                                  Print the QNN SDK version<span class="token punctuation">.</span>

  <span class="token operator">--</span>help                                     Show <span class="token keyword">this</span> help message<span class="token punctuation">.</span>

</code></pre> 
<p>请参阅&lt;QNN_SDK_ROOT&gt;/examples/QNN/NetRun文件夹以获取有关如何使用qnn-net-run工具的参考示例。</p> 
<p>典型论据：</p> 
<p>–backend- 适当的参数取决于您想要运行的目标和后端</p> 
<p>安卓（aarch64）：&lt;QNN_SDK_ROOT&gt;/lib/aarch64-android/</p> 
<ul><li> <p>CPU -libQnnCpu.so</p> </li><li> <p>GPU-libQnnGpu.so</p> </li><li> <p>HTA-libQnnHta.so</p> </li><li> <p>DSP（Hexagon v65）-libQnnDspV65Stub.so</p> </li><li> <p>DSP（Hexagon v66）-libQnnDspV66Stub.so</p> </li><li> <p>DSP-libQnnDsp.so</p> </li><li> <p>HTP（Hexagon v68）-libQnnHtp.so</p> </li><li> <p>[已弃用] HTP 备用准备 (Hexagon v68) -libQnnHtpAltPrepStub.so</p> </li><li> <p>Saver -libQnnSaver.so</p> </li></ul> 
<p>Linux x86：&lt;QNN_SDK_ROOT&gt;/lib/x86_64-linux-clang/</p> 
<ul><li> <p>CPU -libQnnCpu.so</p> </li><li> <p>HTP（**Hexagon ** v68）-libQnnHtp.so</p> </li><li> <p>Saver -libQnnSaver.so</p> </li></ul> 
<p>Windows x86：&lt;QNN_SDK_ROOT&gt;/lib/x86_64-windows-msvc/</p> 
<ul><li> <p>CPU -QnnCpu.dll</p> </li><li> <p>Saver -QnnSaver.dll</p> </li></ul> 
<p>WoS：&lt;QNN_SDK_ROOT&gt;/lib/aarch64-windows-msvc/</p> 
<ul><li> <p>CPU -QnnCpu.dll</p> </li><li> <p>DSP（Hexagon v66）-QnnDspV66Stub.dll</p> </li><li> <p>DSP-QnnDsp.dll</p> </li><li> <p>HTP（Hexagon v68）-QnnHtp.dll</p> </li><li> <p>Saver -QnnSaver.dll</p> </li></ul> 
<blockquote> 
 <p>笔记<br> 基于 Hexagon 的后端库是 x86_64 平台上的模拟</p> 
</blockquote> 
<p>–input_list- 此参数提供一个文件，其中包含用于图形执行的输入文件的路径。输入文件可以使用以下格式指定：</p> 
<pre><code class="prism language-cpp"><span class="token operator">&lt;</span>input_layer_name<span class="token operator">&gt;</span><span class="token operator">:</span><span class="token operator">=</span><span class="token operator">&lt;</span>input_layer_path<span class="token operator">&gt;</span><span class="token punctuation">[</span><span class="token operator">&lt;</span>space<span class="token operator">&gt;</span><span class="token operator">&lt;</span>input_layer_name<span class="token operator">&gt;</span><span class="token operator">:</span><span class="token operator">=</span><span class="token operator">&lt;</span>input_layer_path<span class="token operator">&gt;</span><span class="token punctuation">]</span>
<span class="token punctuation">[</span><span class="token operator">&lt;</span>input_layer_name<span class="token operator">&gt;</span><span class="token operator">:</span><span class="token operator">=</span><span class="token operator">&lt;</span>input_layer_path<span class="token operator">&gt;</span><span class="token punctuation">[</span><span class="token operator">&lt;</span>space<span class="token operator">&gt;</span><span class="token operator">&lt;</span>input_layer_name<span class="token operator">&gt;</span><span class="token operator">:</span><span class="token operator">=</span><span class="token operator">&lt;</span>input_layer_path<span class="token operator">&gt;</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

</code></pre> 
<p>下面是一个示例，包含 3 组输入，层名称为“Input_1”和“Input_2”，文件位于相对路径“Placeholder_1/real_input_inputs_1/”中：</p> 
<p>注意：如果模型的批次维度大于 1，则输入文件中的批次元素数量必须与模型中指定的批次维度匹配，或者必须为 1。在后一种情况下，qnn-net-run 会将多条线组合成一个输入张量。</p> 
<p>–op_packages- 仅当您使用自定义 op 包时才需要此参数。本机 QNN 操作已包含在后端库中。</p> 
<p>使用自定义 op 包时，提供的每个 op 包都需要一个冒号分隔的命令行参数，其中包含 op 包共享库 (.so) 文件的路径以及接口提供程序的名称，格式为&lt;op_package_path&gt;:&lt;interface_provider&gt;.</p> 
<p>interface_provider参数必须是op包库中满足QnnOpPackage_InterfaceProvider_t接口的函数的名称 。在 创建的框架代码中qnn-op-package-generator，该函数将被命名为 &lt;package_name&gt;InterfaceProvider。</p> 
<p>有关更多信息，请参阅生成 Op 包。</p> 
<p>–config_file- 仅当您需要指定上下文优先级或提供后端扩展相关参数时才需要此参数。这些参数通过 JSON 文件指定。JSON文件的模板如下所示：</p> 
<pre><code class="prism language-cpp"><span class="token punctuation">{<!-- --></span>
  <span class="token string">"backend_extensions"</span> <span class="token operator">:</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"shared_library_path"</span> <span class="token operator">:</span>  <span class="token string">"path_to_shared_library"</span><span class="token punctuation">,</span>
      <span class="token string">"config_file_path"</span> <span class="token operator">:</span>  <span class="token string">"path_to_config_file"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
  <span class="token string">"context_configs"</span> <span class="token operator">:</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"context_priority"</span> <span class="token operator">:</span>  <span class="token string">"low | normal | normal_high | high"</span><span class="token punctuation">,</span>
      <span class="token string">"async_execute_queue_depth"</span> <span class="token operator">:</span> uint32_value<span class="token punctuation">,</span>
      <span class="token string">"enable_graphs"</span> <span class="token operator">:</span>  <span class="token punctuation">[</span><span class="token string">"&lt;graph_name_1&gt;"</span><span class="token punctuation">,</span> <span class="token string">"&lt;graph_name_2&gt;"</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
      <span class="token string">"memory_limit_hint"</span>  <span class="token operator">:</span> uint64_value<span class="token punctuation">,</span>
      <span class="token string">"is_persistent_binary"</span> <span class="token operator">:</span> boolean_value
    <span class="token punctuation">}</span>
  <span class="token string">"graph_configs"</span> <span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"graph_name"</span> <span class="token operator">:</span>  <span class="token string">"graph_name_1"</span><span class="token punctuation">,</span>
      <span class="token string">"graph_priority"</span> <span class="token operator">:</span>  <span class="token string">"low | normal | normal_high | high"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>JSON 文件中的所有选项都是可选的。context_priority用于指定上下文的优先级作为上下文配置。async_execute_queue_depth用于指定给定时间可以在队列中执行的数量。使用上下文二进制文件时，enable_graphs用于实现图形选择功能。 memory_limit_hint用于设置反序列化上下文的峰值内存限制提示（以 MB 为单位）。 is_persistent_binary表示上下文二进制指针在 QnnContext_createFromBinary 期间可用，直到调用 QnnContext_free 为止。</p> 
<p>图形选择：允许指定要加载和执行的上下文中的图形子集。如果指定了enable_graphs，则仅加载这些图表。如果选择了图形名称但它不存在，则会出现错误。如果未指定enable_graphs或将其作为空列表传递，则默认行为将继续加载上下文中的所有图形。</p> 
<p>如果后端支持异步执行， graph_configs可用于指定异步执行顺序和深度。每组图形配置都必须与图形名称一起指定。</p> 
<p>backend_extensions用于在特定后端中执行自定义选项。如果需要，可以通过提供扩展共享库 (.so) 和配置文件来完成此操作。这也是启用各种性能模式所必需的，可以使用后端配置来执行这些模式。目前HTP通过共享库支持libQnnHtpNetRunExtensions.so，DSP通过libQnnDspNetRunExtensions.so. 对于可以使用 HTP 启用的不同自定义选项，请参阅HTP 后端扩展</p> 
<p>–shared_buffer- 此参数仅需要指示 qnn-net-run 使用共享缓冲区进行零复制用例，其中设备/协处理器与特定后端（例如，带有 HTP 后端的 DSP）关联，用于图形输入和输出张量数据。仅 Android 支持此选项。qnn-net-run 使用 rpcmem API 实现此功能，该 API 进一步使用 Android 上的 ION/DMA-BUF 内存分配器创建共享缓冲区（可通过共享库 libcdsprpc.so 获取）。除了指定此选项之外，为了使 qnn-net-run 能够发现 libcdsprpc.so，还需要将共享库所在的路径附加到 LD_LIBRARY_PATH 变量中。</p> 
<pre><code class="prism language-cpp"><span class="token keyword">export</span> LD_LIBRARY_PATH<span class="token operator">=</span>$LD_LIBRARY_PATH<span class="token operator">:</span><span class="token operator">/</span>vendor<span class="token operator">/</span>lib64

</code></pre> 
<p>使用 qnn-net-run 在 HTP 后端运行量化模型<br> HTP 后端目前允许在 Linux 开发主机（使用x86_64-linux-clang后端库）上离线最终确定/创建量化 QNN 模型的优化版本，然后在设备上执行最终确定的模型（使用hexagon-v68后端库）。</p> 
<p>首先，按照设置部分中的说明配置环境。接下来，使用 QNN 转换器之一生成的工件从您的网络构建 QNN 模型库。请参阅构建示例模型以供参考。最后，使用该qnn-context-binary-generator实用程序生成最终图的序列化表示，以在设备上执行序列化二进制文件。</p> 
<pre><code class="prism language-cpp"><span class="token number">1</span># Generate the optimized serialized representation of QNN Model on Linux development host<span class="token punctuation">.</span>
<span class="token number">2</span>$ qnn<span class="token operator">-</span>context<span class="token operator">-</span>binary<span class="token operator">-</span>generator <span class="token operator">--</span>binary_file qnngraph<span class="token punctuation">.</span>serialized<span class="token punctuation">.</span>bin \
<span class="token number">3</span>                               <span class="token operator">--</span>model <span class="token operator">&lt;</span>path_to_model_library<span class="token operator">&gt;</span><span class="token operator">/</span>libQnnModel<span class="token punctuation">.</span>so \ # a x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang built quantized QNN model
<span class="token number">4</span>                               <span class="token operator">--</span>backend $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>lib<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>libQnnHtp<span class="token punctuation">.</span>so \
<span class="token number">5</span>                               <span class="token operator">--</span>output_dir <span class="token operator">&lt;</span>output_dir_for_result_and_qnngraph_serialized_binary<span class="token operator">&gt;</span> \
</code></pre> 
<p>要使用生成的最终图的序列化表示 ( qnngraph.serialized.bin)，请确保以下二进制文件在 Android 设备上可用：</p> 
<ul><li> <p>libQnnHtpV68Stub.so（ARM）</p> </li><li> <p>libQnnHtpPrepare.so（ARM）</p> </li><li> <p>libQnnModel.so（ARM）</p> </li><li> <p>libQnnHtpV68Skel.so（cDSP v68）</p> </li><li> <p>qnngraph.serialized.bin（在 Linux 开发主机上运行的序列化二进制文件）</p> </li></ul> 
<p>&lt;QNN_SDK_ROOT&gt;/examples/QNN/NetRun/android/android-qnn-net-run.sh有关如何在 Android 设备上使用工具的参考，请参阅脚本qnn-net-run。</p> 
<pre><code class="prism language-cpp"><span class="token number">1</span># Run the optimized graph on HTP target
<span class="token number">2</span>$ qnn<span class="token operator">-</span>net<span class="token operator">-</span>run <span class="token operator">--</span>retrieve_context qnngraph<span class="token punctuation">.</span>serialized<span class="token punctuation">.</span>bin \
<span class="token number">3</span>              <span class="token operator">--</span>backend <span class="token operator">&lt;</span>path_to_model_library<span class="token operator">&gt;</span><span class="token operator">/</span>libQnnHtp<span class="token punctuation">.</span>so \
<span class="token number">4</span>              <span class="token operator">--</span>output_dir <span class="token operator">&lt;</span>output_dir_for_result<span class="token operator">&gt;</span> \
<span class="token number">5</span>              <span class="token operator">--</span>input_list <span class="token operator">&lt;</span>path_to_input_list<span class="token punctuation">.</span>txt<span class="token operator">&gt;</span>
</code></pre> 
<p>使用 qnn-net-run 在 HTP 后端运行 Float 模型<br> QNN HTP 后端可以支持在选定的 Qualcomm SoC 上运行 float32 模型。</p> 
<p>首先，按照设置部分中的说明配置环境。接下来，使用 QNN 转换器之一生成的工件从您的网络构建 QNN 模型库。请参阅构建示例模型以供参考。</p> 
<p>最后，通过 JSON 文件配置backend_extensions参数，并为 HTP 后端设置自定义选项。使用参数将此文件传递给 qnn-net-run --config_file。backend_extensions采用两个参数，一个扩展共享库 (.so)（用于 HTP 使用libQnnHtpNetRunExtensions.so）和一个后端配置文件。</p> 
<p>以下是 JSON 文件的模板：</p> 
<pre><code class="prism language-c"><span class="token punctuation">{<!-- --></span>
  <span class="token string">"backend_extensions"</span> <span class="token operator">:</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"shared_library_path"</span> <span class="token operator">:</span>  <span class="token string">"path_to_shared_library"</span><span class="token punctuation">,</span>
      <span class="token string">"config_file_path"</span> <span class="token operator">:</span>  <span class="token string">"path_to_config_file"</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>对于 HTP 后端扩展配置，您可以通过配置文件设置“vtcm_mb”、“fp16_relaxed_ precision”和“graph_names”。</p> 
<p>这是配置文件的示例：</p> 
<pre><code class="prism language-cpp"> <span class="token number">1</span><span class="token punctuation">{<!-- --></span>
 <span class="token number">2</span>    <span class="token string">"graphs"</span><span class="token operator">:</span>
 <span class="token number">3</span>    <span class="token punctuation">{<!-- --></span>
 <span class="token number">4</span>        <span class="token string">"vtcm_mb"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token comment">// Provides performance infrastructure configuration options that are memory specific.</span>
 <span class="token number">5</span>                      <span class="token comment">// It is optional and default value is 0 which means this value will not be set.</span>
 <span class="token number">6</span>        <span class="token string">"fp16_relaxed_precision"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span> <span class="token comment">// Ensures that operations will run with relaxed precision math i.e. float16 math</span>
 <span class="token number">7</span>
 <span class="token number">8</span>        <span class="token string">"graph_names"</span><span class="token operator">:</span> <span class="token punctuation">[</span> <span class="token string">"qnn_model"</span> <span class="token punctuation">]</span>  <span class="token comment">// Provide the list of names of the graph for the inference as specified when using qnn converter tools</span>
 <span class="token number">9</span>                                        <span class="token comment">// "qnn_model" must be the name of the .cpp file generated during the model conversion (without the .cpp file extension)</span>
<span class="token number">10</span>        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token number">11</span>    <span class="token punctuation">}</span>
<span class="token number">12</span><span class="token punctuation">}</span>

</code></pre> 
<p>请注意，从 SDK 2.20 版本开始，上述配置结构将被弃用，支持的新配置如下所示：</p> 
<pre><code class="prism language-cpp"> <span class="token number">1</span><span class="token punctuation">{<!-- --></span>
 <span class="token number">2</span>   <span class="token string">"graphs"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
 <span class="token number">3</span>      <span class="token punctuation">{<!-- --></span>
 <span class="token number">4</span>        <span class="token string">"vtcm_mb"</span><span class="token operator">:</span> <span class="token number">8</span><span class="token punctuation">,</span>
 <span class="token number">5</span>        <span class="token string">"fp16_relaxed_precision"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token punctuation">,</span>
 <span class="token number">6</span>        <span class="token string">"graph_names"</span><span class="token operator">:</span> <span class="token punctuation">[</span> <span class="token string">"qnn_model"</span> <span class="token punctuation">]</span>
 <span class="token number">7</span>      <span class="token punctuation">}</span><span class="token punctuation">,</span>
 <span class="token number">8</span>      <span class="token punctuation">{<!-- --></span>
 <span class="token number">9</span>         <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  <span class="token comment">// Other graph object</span>
<span class="token number">10</span>      <span class="token punctuation">}</span>
<span class="token number">11</span>   <span class="token punctuation">]</span>
<span class="token number">12</span><span class="token punctuation">}</span>

</code></pre> 
<blockquote> 
 <p>笔记<br> “fp16_relaxed_ precision”是在 HTP float 运行时上运行 QNN float 模型的关键配置。仅当后端扩展配置中至少提供了一个“graph_name”时，才会应用 HTP 图形配置，例如 fp16_relaxed_ precision、vtcm_mb 等。</p> 
</blockquote> 
<p>&lt;QNN_SDK_ROOT&gt;/examples/QNN/NetRun/android/android-qnn-net-run.sh有关如何在 Android 设备上使用工具的参考，请参阅脚本qnn-net-run。</p> 
<pre><code class="prism language-cpp"><span class="token number">1</span># Run the optimized graph on HTP target
<span class="token number">2</span>$ qnn<span class="token operator">-</span>net<span class="token operator">-</span>run <span class="token operator">--</span>model <span class="token operator">&lt;</span>path_to_model_library<span class="token operator">&gt;</span><span class="token operator">/</span>libQnnModel<span class="token punctuation">.</span>so \ # a x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang built <span class="token keyword">float</span> QNN model
<span class="token number">3</span>              <span class="token operator">--</span>backend $<span class="token punctuation">{<!-- --></span>QNN_SDK_ROOT<span class="token punctuation">}</span><span class="token operator">/</span>lib<span class="token operator">/</span>x86_64<span class="token operator">-</span>linux<span class="token operator">-</span>clang<span class="token operator">/</span>libQnnHtp<span class="token punctuation">.</span>so \
<span class="token number">4</span>              <span class="token operator">--</span>config_file <span class="token operator">&lt;</span>path_to_JSON_file<span class="token punctuation">.</span>json<span class="token operator">&gt;</span> \
<span class="token number">5</span>              <span class="token operator">--</span>output_dir <span class="token operator">&lt;</span>output_dir_for_result<span class="token operator">&gt;</span> \
<span class="token number">6</span>              <span class="token operator">--</span>input_list <span class="token operator">&lt;</span>path_to_input_list<span class="token punctuation">.</span>txt<span class="token operator">&gt;</span>

</code></pre> 
<p>qnn-吞吐量-网络运行<br> qnn -throughput-net-run工具用于在 QNN 后端或以多线程方式在不同后端上练习多个模型的执行。它允许在指定的后端上重复执行模型指定的持续时间或迭代次数。</p> 
<pre><code class="prism language-cpp">Usage<span class="token operator">:</span>
<span class="token operator">--</span><span class="token operator">--</span><span class="token operator">--</span>
qnn<span class="token operator">-</span>throughput<span class="token operator">-</span>net<span class="token operator">-</span>run <span class="token punctuation">[</span><span class="token operator">--</span>config <span class="token operator">&lt;</span>config_file<span class="token operator">&gt;</span><span class="token punctuation">.</span>json<span class="token punctuation">]</span>
                       <span class="token punctuation">[</span><span class="token operator">--</span>output <span class="token operator">&lt;</span>results<span class="token operator">&gt;</span><span class="token punctuation">.</span>json<span class="token punctuation">]</span>

REQUIRED <span class="token function">argument</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">:</span>
 <span class="token operator">--</span>config        <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span><span class="token punctuation">.</span>json       Path to the json config file <span class="token punctuation">.</span>

OPTIONAL <span class="token function">argument</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token operator">:</span>
 <span class="token operator">--</span>output        <span class="token operator">&lt;</span>FILE<span class="token operator">&gt;</span><span class="token punctuation">.</span>json       Specify the json file used to save the performance test results<span class="token punctuation">.</span>

</code></pre> 
<p>配置 JSON 文件：</p> 
<p>qnn-throughput-net-run使用配置文件作为输入在后端运行模型。配置 json 文件包含四个对象（必需） - backends、models、contexts和 testCase。</p> 
<p>以下是 json 配置文件的示例。 有关四个配置对象后端、模型、 上下文和测试用例的详细信息，请参阅以下部分。</p> 
<pre><code class="prism language-cpp"><span class="token punctuation">{<!-- --></span>
  <span class="token string">"backends"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"backendName"</span><span class="token operator">:</span> <span class="token string">"cpu_backend"</span><span class="token punctuation">,</span>
      <span class="token string">"backendPath"</span><span class="token operator">:</span> <span class="token string">"libQnnCpu.so"</span><span class="token punctuation">,</span>
      <span class="token string">"profilingLevel"</span><span class="token operator">:</span> <span class="token string">"BASIC"</span><span class="token punctuation">,</span>
      <span class="token string">"backendExtensions"</span><span class="token operator">:</span> <span class="token string">"libQnnHtpNetRunExtensions.so"</span><span class="token punctuation">,</span>
      <span class="token string">"perfProfile"</span><span class="token operator">:</span> <span class="token string">"high_performance"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"backendName"</span><span class="token operator">:</span> <span class="token string">"gpu_backend"</span><span class="token punctuation">,</span>
      <span class="token string">"backendPath"</span><span class="token operator">:</span> <span class="token string">"libQnnGpu.so"</span><span class="token punctuation">,</span>
      <span class="token string">"profilingLevel"</span><span class="token operator">:</span> <span class="token string">"OFF"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"models"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"modelName"</span><span class="token operator">:</span> <span class="token string">"model_1"</span><span class="token punctuation">,</span>
      <span class="token string">"modelPath"</span><span class="token operator">:</span> <span class="token string">"libqnn_model_1.so"</span><span class="token punctuation">,</span>
      <span class="token string">"loadFromCachedBinary"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
      <span class="token string">"inputPath"</span><span class="token operator">:</span> <span class="token string">"model_1-input_list.txt"</span><span class="token punctuation">,</span>
      <span class="token string">"inputDataType"</span><span class="token operator">:</span> <span class="token string">"FLOAT"</span><span class="token punctuation">,</span>
      <span class="token string">"postProcessor"</span><span class="token operator">:</span> <span class="token string">"MSE"</span><span class="token punctuation">,</span>
      <span class="token string">"outputPath"</span><span class="token operator">:</span> <span class="token string">"model_1-output"</span><span class="token punctuation">,</span>
      <span class="token string">"outputDataType"</span><span class="token operator">:</span> <span class="token string">"FLOAT_ONLY"</span><span class="token punctuation">,</span>
      <span class="token string">"saveOutput"</span><span class="token operator">:</span> <span class="token string">"NATIVE_ALL"</span><span class="token punctuation">,</span>
      <span class="token string">"groundTruthPath"</span><span class="token operator">:</span> <span class="token string">"model_1-golden_list.txt"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"modelName"</span><span class="token operator">:</span> <span class="token string">"model_2"</span><span class="token punctuation">,</span>
      <span class="token string">"modelPath"</span><span class="token operator">:</span> <span class="token string">"libqnn_model_2.so"</span><span class="token punctuation">,</span>
      <span class="token string">"loadFromCachedBinary"</span><span class="token operator">:</span> <span class="token boolean">false</span><span class="token punctuation">,</span>
      <span class="token string">"inputPath"</span><span class="token operator">:</span> <span class="token string">"model_2-input_list.txt"</span><span class="token punctuation">,</span>
      <span class="token string">"inputDataType"</span><span class="token operator">:</span> <span class="token string">"FLOAT"</span><span class="token punctuation">,</span>
      <span class="token string">"postProcessor"</span><span class="token operator">:</span> <span class="token string">"MSE"</span><span class="token punctuation">,</span>
      <span class="token string">"outputPath"</span><span class="token operator">:</span> <span class="token string">"model_2-output"</span><span class="token punctuation">,</span>
      <span class="token string">"outputDataType"</span><span class="token operator">:</span> <span class="token string">"FLOAT_ONLY"</span><span class="token punctuation">,</span>
      <span class="token string">"saveOutput"</span><span class="token operator">:</span> <span class="token string">"NATIVE_LAST"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"contexts"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"contextName"</span><span class="token operator">:</span> <span class="token string">"cpu_context_1"</span>
    <span class="token punctuation">}</span><span class="token punctuation">,</span>
    <span class="token punctuation">{<!-- --></span>
      <span class="token string">"contextName"</span><span class="token operator">:</span> <span class="token string">"gpu_context_1"</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">]</span><span class="token punctuation">,</span>
  <span class="token string">"testCase"</span><span class="token operator">:</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"iteration"</span><span class="token operator">:</span> <span class="token number">5</span><span class="token punctuation">,</span>
    <span class="token string">"logLevel"</span><span class="token operator">:</span> <span class="token string">"error"</span><span class="token punctuation">,</span>
    <span class="token string">"threads"</span><span class="token operator">:</span> <span class="token punctuation">[</span>
      <span class="token punctuation">{<!-- --></span>
        <span class="token string">"threadName"</span><span class="token operator">:</span> <span class="token string">"cpu_thread_1"</span><span class="token punctuation">,</span>
        <span class="token string">"backend"</span><span class="token operator">:</span> <span class="token string">"cpu_backend"</span><span class="token punctuation">,</span>
        <span class="token string">"context"</span><span class="token operator">:</span> <span class="token string">"cpu_context_1"</span><span class="token punctuation">,</span>
        <span class="token string">"model"</span><span class="token operator">:</span> <span class="token string">"model_1"</span><span class="token punctuation">,</span>
        <span class="token string">"interval"</span><span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
        <span class="token string">"loopUnit"</span><span class="token operator">:</span> <span class="token string">"count"</span><span class="token punctuation">,</span>
        <span class="token string">"loop"</span><span class="token operator">:</span> <span class="token number">1</span>
      <span class="token punctuation">}</span><span class="token punctuation">,</span>
      <span class="token punctuation">{<!-- --></span>
        <span class="token string">"threadName"</span><span class="token operator">:</span> <span class="token string">"gpu_thread_1"</span><span class="token punctuation">,</span>
        <span class="token string">"backend"</span><span class="token operator">:</span> <span class="token string">"gpu_backend"</span><span class="token punctuation">,</span>
        <span class="token string">"context"</span><span class="token operator">:</span> <span class="token string">"gpu_context_1"</span><span class="token punctuation">,</span>
        <span class="token string">"model"</span><span class="token operator">:</span> <span class="token string">"model_2"</span><span class="token punctuation">,</span>
        <span class="token string">"interval"</span><span class="token operator">:</span> <span class="token number">0</span><span class="token punctuation">,</span>
        <span class="token string">"loopUnit"</span><span class="token operator">:</span> <span class="token string">"count"</span><span class="token punctuation">,</span>
        <span class="token string">"loop"</span><span class="token operator">:</span> <span class="token number">10</span>
      <span class="token punctuation">}</span>
    <span class="token punctuation">]</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

</code></pre> 
<p>backends：属性值是一个 json 对象数组，其中每个对象包含执行模型所需的后端信息。数组的每个对象都具有以下属性作为键/值对。</p> 
<p><img src="https://images2.imgbox.com/92/6f/faTfsbqV_o.png" alt="在这里插入图片描述"><br> models：属性值是一个 json 对象数组，其中每个对象包含有关模型的详细信息以及相应的输入数据和后处理信息。数组的每个对象都具有以下属性作为键/值对。</p> 
<p><img src="https://images2.imgbox.com/b1/11/xozkejLX_o.png" alt="在这里插入图片描述"></p> 
<p>contexts：属性值是一个json对象数组，其中每个对象包含所有上下文信息。数组的每个对象都具有以下属性作为键/值对。</p> 
<p><img src="https://images2.imgbox.com/a2/0b/4pilzb2c_o.png" alt="在这里插入图片描述"></p> 
<p>testCase：属性值是一个 json 对象，指定控制多线程执行的测试配置。</p> 
<p><img src="https://images2.imgbox.com/4a/e6/GYPfjNjy_o.png" alt="在这里插入图片描述"><br> threads：属性值是一个数组，包含所有线程以及相应的后端、上下文和模型信息。数组的每个元素都可以具有以下必需/可选属性。</p> 
<p><img src="https://images2.imgbox.com/1c/a6/EVqdSprw_o.png" alt="在这里插入图片描述"></p> 
<p>sample_config.json可以在以下位置找到示例 json 文件&lt;QNN_SDK_ROOT&gt;/examples/QNN/ThroughputNetRun。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e02da886515150e2a3808aca66a588e0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Qualcomm® AI Engine Direct 使用手册（16）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0d392882919ad1548542a5bac8d68e17/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ReactNative Hooks写法抽离子view</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>