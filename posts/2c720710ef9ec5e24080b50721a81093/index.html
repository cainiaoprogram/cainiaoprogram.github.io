<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>轻量化神经网络模型总结：SqueezeNet、Xception、MobileNet、ShuffleNet - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="轻量化神经网络模型总结：SqueezeNet、Xception、MobileNet、ShuffleNet" />
<meta property="og:description" content="总结今年来的几个轻量化模型：SqueezeNet、Xception、MobileNet、ShuffleNet
下面给出时间轴：
2016.02 伯克利&amp;斯坦福提出 SqueezeNet2016.10 google提出 Xception2017.04 google提出 MobileNet2017.07 face&#43;&#43;提出 ShuffleNet 其次，说一下模型轻量化的一些方法：
卷积核分解：使用1xN和NX1卷积核代替NXN卷积核；使用深度压缩deep compression方法：网络剪枝、量化、哈弗曼编码；奇异值分解；硬件加速器；低精度浮点数保存； 小模型的好处有哪些：
在分布式训练中，与服务器通信需求小；参数少，从云端下载模型的数据量小；更适合在FPGA等内存首先的嵌入式、移动端设备上部署； 1、SqueezeNet 地址链接：https://arxiv.org/pdf/1602.07360.pdf
1.1 核心思想 在ImageNet上实现了与Alexnet相似的效果，参数只有其1/50， 模型是0.5MB，占其1/510。
SqueezeNet核心内容有以下几点：
使用1x1卷积核代替3x3卷积核，减少参数量；通过squeeze layer限制通道数量，减少参数量；借鉴inception思想，将1x1和3x3卷积后结果进行concat；为了使其feature map的size相同，3x3卷积核进行了padding；减少池化层，并将池化操作延后，给卷积层带来更大的激活层，保留更多地信息，提高准确率；使用全局平均池化代替全连接层； 上述1-3是通过fire module实现的，fire module主要分为两部分，如下图所示
squeeze：1x1卷积核，参数s_1x1表示卷积核数量expand：1x1卷积核和3x3卷积核，参数e_1x1和e_3x3分别表示两种卷积核的数量 该模块一共三参数s_1x1、e_1x1、e_3x3，关系保持s_1x1&lt; e_1x1&#43;e_3x3
1.2 网络结构 1.3 实验结果 实验结果表示模型小，且准确率不降，反而有点提高；
参考链接：
1、https://blog.csdn.net/csdnldp/article/details/78648543
2、https://blog.csdn.net/u011995719/article/details/78908755
2、Xception 地址链接：https://arxiv.org/abs/1610.02357
2.1 核心思想 虽然本文中方法可以降低参数量，但是论文加宽了网络结构，因此这篇论文不在于压缩模型，旨在于提高性能，与同等参数量的inception v3相比，效果更好。
首先是inception v3的一系列延伸，见下图：
1、版本1：最初的inception v3
2、版本2：对1进行简化
3、版本3：对2简化，可以先使用一个统一的1x1卷积核，然后每个3x3卷积核的输入只是1x1卷积后的feature map的一部分。本图中是1/3；
4、版本4：在3的基础上进一步延伸，将1x1卷积后的所有feature map按通道全部划分，每一个通道对应一个3x3卷积，即3x3卷积核的数量就是1x1卷积后feature map的通道数。
然后在xception中，主要采用depthwise separable convolution思想（这个后面在mobile net中详细解释，好奇怪，明明是mobile net后出现的，反正都是一家的，估计公布先后的问题吧。）
首先xception类似于图4，但是区别有两点：
1、xception中没有relu激活函数； 2、图4是先1x1卷积，后通道分离；xception是先进行通道分离，即depthwise separable convolution，然后再进行1x1卷积。
此外，进行残差连接时，不再是concat，而是采用加法操作。
2.2 网络结构 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2c720710ef9ec5e24080b50721a81093/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-08-20T20:58:31+08:00" />
<meta property="article:modified_time" content="2018-08-20T20:58:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">轻量化神经网络模型总结：SqueezeNet、Xception、MobileNet、ShuffleNet</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <hr> 
<p>总结今年来的几个轻量化模型：SqueezeNet、Xception、MobileNet、ShuffleNet</p> 
<p>下面给出时间轴：</p> 
<ul><li>2016.02 伯克利&amp;斯坦福提出 SqueezeNet</li><li>2016.10 google提出 Xception</li><li>2017.04 google提出 MobileNet</li><li>2017.07 face++提出 ShuffleNet</li></ul> 
<p>其次，说一下模型轻量化的一些方法：</p> 
<ul><li>卷积核分解：使用1xN和NX1卷积核代替NXN卷积核；</li><li>使用深度压缩deep compression方法：网络剪枝、量化、哈弗曼编码；</li><li>奇异值分解；</li><li>硬件加速器；</li><li>低精度浮点数保存；</li></ul> 
<p>小模型的好处有哪些：</p> 
<ul><li>在分布式训练中，与服务器通信需求小；</li><li>参数少，从云端下载模型的数据量小；</li><li>更适合在FPGA等内存首先的嵌入式、移动端设备上部署；</li></ul> 
<hr> 
<h3 id="1squeezenet">1、SqueezeNet</h3> 
<p>地址链接：<a href="https://arxiv.org/pdf/1602.07360.pdf" rel="nofollow">https://arxiv.org/pdf/1602.07360.pdf</a></p> 
<h4 id="11-核心思想">1.1 核心思想</h4> 
<p>在ImageNet上实现了与Alexnet相似的效果，参数只有其1/50， 模型是0.5MB，占其1/510。</p> 
<p>SqueezeNet核心内容有以下几点：</p> 
<ol><li>使用1x1卷积核代替3x3卷积核，减少参数量；</li><li>通过squeeze layer限制通道数量，减少参数量；</li><li>借鉴inception思想，将1x1和3x3卷积后结果进行concat；为了使其feature map的size相同，3x3卷积核进行了padding；</li><li>减少池化层，并将池化操作延后，给卷积层带来更大的激活层，保留更多地信息，提高准确率；</li><li>使用全局平均池化代替全连接层；</li></ol> 
<p>上述1-3是通过fire module实现的，fire module主要分为两部分，如下图所示</p> 
<p><img src="https://images2.imgbox.com/2b/41/hzdP3ePF_o.png" alt="这里写图片描述" title=""></p> 
<ul><li>squeeze：1x1卷积核，参数s_1x1表示卷积核数量</li><li>expand：1x1卷积核和3x3卷积核，参数e_1x1和e_3x3分别表示两种卷积核的数量</li></ul> 
<p>该模块一共三参数s_1x1、e_1x1、e_3x3，关系保持s_1x1&lt; e_1x1+e_3x3</p> 
<h4 id="12-网络结构">1.2 网络结构</h4> 
<p><img src="https://images2.imgbox.com/6f/31/qWanzIyM_o.png" alt="这里写图片描述" title=""></p> 
<h4 id="13-实验结果">1.3 实验结果</h4> 
<p>实验结果表示模型小，且准确率不降，反而有点提高；</p> 
<p><img src="https://images2.imgbox.com/3c/f8/5r9WZ5VV_o.png" alt="这里写图片描述" title=""></p> 
<p>参考链接：</p> 
<p>1、<a href="https://blog.csdn.net/csdnldp/article/details/78648543">https://blog.csdn.net/csdnldp/article/details/78648543</a></p> 
<p>2、<a href="https://blog.csdn.net/u011995719/article/details/78908755">https://blog.csdn.net/u011995719/article/details/78908755</a></p> 
<h3 id="2xception">2、Xception</h3> 
<p>地址链接：<a href="https://arxiv.org/abs/1610.02357" rel="nofollow">https://arxiv.org/abs/1610.02357</a></p> 
<h4 id="21-核心思想">2.1 核心思想</h4> 
<p>虽然本文中方法可以降低参数量，但是论文加宽了网络结构，因此这篇论文不在于压缩模型，旨在于提高性能，与同等参数量的inception v3相比，效果更好。</p> 
<p>首先是inception v3的一系列延伸，见下图：</p> 
<p>1、版本1：最初的inception v3</p> 
<p><img src="https://images2.imgbox.com/85/17/xQuj2NXb_o.png" alt="这里写图片描述" title=""></p> 
<p>2、版本2：对1进行简化</p> 
<p><img src="https://images2.imgbox.com/69/ae/NjmH6VN6_o.png" alt="这里写图片描述" title=""></p> 
<p>3、版本3：对2简化，可以先使用一个统一的1x1卷积核，然后每个3x3卷积核的输入只是1x1卷积后的feature map的一部分。本图中是1/3；</p> 
<p><img src="https://images2.imgbox.com/e6/a7/DTDQGT1O_o.png" alt="这里写图片描述" title=""></p> 
<p>4、版本4：在3的基础上进一步延伸，将1x1卷积后的所有feature map按通道全部划分，每一个通道对应一个3x3卷积，即3x3卷积核的数量就是1x1卷积后feature map的通道数。</p> 
<p><img src="https://images2.imgbox.com/d6/f5/jYSKlLQn_o.png" alt="这里写图片描述" title=""></p> 
<p>然后在xception中，主要采用depthwise separable convolution思想（这个后面在mobile net中详细解释，好奇怪，明明是mobile net后出现的，反正都是一家的，估计公布先后的问题吧。）</p> 
<p>首先xception类似于图4，但是区别有两点：</p> 
<p>1、xception中没有relu激活函数； <br> 2、图4是先1x1卷积，后通道分离；xception是先进行通道分离，即depthwise separable convolution，然后再进行1x1卷积。</p> 
<p>此外，进行残差连接时，不再是concat，而是采用加法操作。</p> 
<h4 id="22-网络结构">2.2 网络结构</h4> 
<p><img src="https://images2.imgbox.com/bb/5b/18JANmD7_o.png" alt="这里写图片描述" title=""> <br> <img src="https://images2.imgbox.com/c7/8b/rUqT6S72_o.png" alt="这里写图片描述" title=""></p> 
<h4 id="23-实验结果">2.3 实验结果</h4> 
<p><img src="https://images2.imgbox.com/ce/43/PxnPFbGT_o.png" alt="这里写图片描述" title=""></p> 
<p>参考链接：</p> 
<p>1、<a href="https://blog.csdn.net/u014380165/article/details/75142710">https://blog.csdn.net/u014380165/article/details/75142710</a></p> 
<p>2、<a href="https://www.baidu.com/link?url=ERPMsc_io0x0usMhZdLD5POp-4p3dHyNtg4z92eeNsIpzxbKJMtmEH39A5op8p2XiQ4CWDPMu03Ygbrs8GAOAK&amp;wd=&amp;eqid=e517c5270000c4ed000000035b7a2a44" rel="nofollow">https://www.baidu.com/link?url=ERPMsc_io0x0usMhZdLD5POp-4p3dHyNtg4z92eeNsIpzxbKJMtmEH39A5op8p2XiQ4CWDPMu03Ygbrs8GAOAK&amp;wd=&amp;eqid=e517c5270000c4ed000000035b7a2a44</a></p> 
<h3 id="3mobilenet">3、MobileNet</h3> 
<p>地址链接：<a href="https://arxiv.org/pdf/1704.04861.pdf" rel="nofollow">https://arxiv.org/pdf/1704.04861.pdf</a></p> 
<h4 id="31-核心思想">3.1 核心思想</h4> 
<p>主要是两个策略：</p> 
<ol><li>采用depthwise separable convolution，就是分离卷积核；</li><li>设置宽度因子width multipler和分辨率因子resolution multiplier； </li></ol> 
<h5 id="311-depthwise-separable-convolution">3.1.1 depthwise separable convolution</h5> 
<p>假设上一层得到的feature map的size为D_K * D_K * M，本层的卷积核大小为D_K * D_K，卷积核个数为M。</p> 
<p>1、首先介绍传统卷积核的操作方式，如下图。</p> 
<p><img src="https://images2.imgbox.com/55/65/YiG3Xhn8_o.png" alt="这里写图片描述" title=""></p> 
<p>卷积核D_K * D_K需要在feature map的每个通道上进行D_K * D_K次卷积，然后一共M个卷积核，因此计算量为：</p> 
<p><img src="https://images2.imgbox.com/c9/f5/axjycIjS_o.png" alt="这里写图片描述" title=""></p> 
<p>2、介绍depthwise separable convolution，如下图</p> 
<p><img src="https://images2.imgbox.com/c6/2a/YmydkIe0_o.png" alt="这里写图片描述" title=""></p> 
<p>将卷积核进行拆解，分为两步，首先用M个D_K * D_K卷积核在feature map进行卷积，计算量为</p> 
<p><img src="https://images2.imgbox.com/b9/93/6yilosyf_o.png" alt="这里写图片描述" title=""></p> 
<p>然后再使用N个1 * 1 * M卷积核在前面得到的结果上进行feature map，计算量为：</p> 
<p><img src="https://images2.imgbox.com/5c/53/nLHjGg1z_o.png" alt="这里写图片描述" title=""></p> 
<p>所以，进行分解后的总计算量为：</p> 
<p><img src="https://images2.imgbox.com/06/88/6ykApIyp_o.png" alt="这里写图片描述" title=""></p> 
<p>3、计算量比较</p> 
<p><img src="https://images2.imgbox.com/80/c5/6qRyFvyQ_o.png" alt="这里写图片描述" title=""></p> 
<p>可以看到，随着卷积核个数的增加，即通道数变多，feature map的大小，传统方式的计算量比分解要大得多。</p> 
<h5 id="312-宽度因子和分辨率因子">3.1.2 宽度因子和分辨率因子</h5> 
<p>怎么才能使网络进一步压缩呢？可以进一步减少feature map的通道数和size，通过宽度因子减少通道数，分辨率因子减少size。</p> 
<p>1、宽度因子α</p> 
<p><img src="https://images2.imgbox.com/af/7c/uhtNvXu8_o.png" alt="这里写图片描述" title=""></p> 
<p>2、分辨率因子β</p> 
<p><img src="https://images2.imgbox.com/1d/aa/75RjB6aY_o.png" alt="这里写图片描述" title=""></p> 
<p>两个参数都属于(0,1]之间，当为1时则是标准mobileNet。</p> 
<h4 id="32-网络结构">3.2 网络结构</h4> 
<h5 id="321-基本结构块">3.2.1 基本结构块</h5> 
<p><img src="https://images2.imgbox.com/be/0b/zEA9d5JW_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="322-网络结构">3.2.2 网络结构</h5> 
<p><img src="https://images2.imgbox.com/38/0e/28YCWERQ_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="323-训练细节">3.2.3 训练细节</h5> 
<p>1、使用RMSprop优化器；</p> 
<p>2、未做大量数据增强，因为参数量小过拟合不严重；</p> 
<p>3、采用了随机图像裁剪输入；</p> 
<p>4、使用较小的weight decay，或者不使用；</p> 
<h4 id="33-实验结果">3.3 实验结果</h4> 
<p>给出几个基本的实验比较结果。</p> 
<p><img src="https://images2.imgbox.com/47/29/j57GWAbJ_o.png" alt="这里写图片描述" title=""></p> 
<p>参考链接：</p> 
<p>1、<a href="https://blog.csdn.net/t800ghb/article/details/78879612">https://blog.csdn.net/t800ghb/article/details/78879612</a></p> 
<p>2、<a href="https://blog.csdn.net/wfei101/article/details/78310226">https://blog.csdn.net/wfei101/article/details/78310226</a></p> 
<p>3、<a href="https://blog.csdn.net/u014380165/article/details/72938047">https://blog.csdn.net/u014380165/article/details/72938047</a></p> 
<h3 id="4shufflenet">4、ShuffleNet</h3> 
<p>地址链接：<a href="https://arxiv.org/pdf/1707.01083.pdf" rel="nofollow">https://arxiv.org/pdf/1707.01083.pdf</a></p> 
<h4 id="41-核心思想">4.1 核心思想</h4> 
<p>核心思想有两点：</p> 
<ol><li>借鉴resnext分组卷积思想，但不同的是采用1x1卷积核；</li><li>进行通道清洗，加强通道间的信息流通，提高信息表示能力。</li></ol> 
<p>此外本篇论文中也采取了mobilenet的depthwise separasable convolution的方式。</p> 
<h5 id="411-逐点群卷积pointwise-group-convolution">4.1.1 逐点群卷积pointwise group convolution</h5> 
<p>这个就是采用resnext的思想，将通道分组，每组分别进行卷积操作，然后再把结果进行concat。但是不同于resnext的是，shufflenet采用的是1x1卷积核。</p> 
<h5 id="412-通道清洗channel-shuffle">4.1.2 通道清洗channel shuffle</h5> 
<p>什么是通道shuffle，就是在分组卷积后得到的feature map不直接进行concat，先将每组feature map按通道打乱，重新concat，如下图所示：</p> 
<p><img src="https://images2.imgbox.com/49/61/RtczFRlW_o.png" alt="这里写图片描述" title=""></p> 
<p>如何进行shuffle，这里参考<a href="https://blog.csdn.net/u011974639/article/details/79200559">链接</a>，</p> 
<p>对于一个卷积层分为g组，</p> 
<ol><li>卷积后一共得到g×n个输出通道的feature map；</li><li>将feature map 进行 reshape为(g,n);</li><li>进行转置为(n,g)；</li><li>对转置结果flatten，再分回g组作为下一层的输入。</li></ol> 
<p><img src="https://images2.imgbox.com/c1/92/OrYYsvqE_o.png" alt="这里写图片描述" title=""></p> 
<h4 id="42-网络结构">4.2 网络结构</h4> 
<h5 id="421-shuffle-unit">4.2.1 shuffle unit</h5> 
<p>下图中，a是标准的残差结构，不过是3x3卷积核使用了mobilenet中的depthwise convolution操作；</p> 
<p>b是在a的基础上加了本文的通道shuffle操作，先对1x1卷积进行分组卷积操作，然后进行channel shuffle；</p> 
<p>c是在旁路加了一步长为2的3x3的平均池化，并将前两者残差相加的操作改为了通道concat，增加了通道数量。</p> 
<p><img src="https://images2.imgbox.com/7a/51/xGNkbmVB_o.png" alt="这里写图片描述" title=""></p> 
<h5 id="422-网络结构">4.2.2 网络结构</h5> 
<p><img src="https://images2.imgbox.com/7f/5d/vIgIRxCE_o.png" alt="这里写图片描述" title=""></p> 
<h4 id="43-实验结果">4.3 实验结果</h4> 
<p>1、评估逐点组卷积：分组的效果均比没有分组的效果好，但是某些模型随着组数增加，性能有下降，这就是通道间失去联系带来的问题；</p> 
<p><img src="https://images2.imgbox.com/b5/7e/xjqkIriS_o.png" alt="这里写图片描述" title=""></p> 
<p>2、评估channel shuffle，shuffle会比没有shuffle效果好，而且对于组数越大，效果越好，说明了shuffle的重要性，也说明了上图中组数增加性能下降的问题。</p> 
<p><img src="https://images2.imgbox.com/30/1c/ecvBTg5I_o.png" alt="这里写图片描述" title=""></p> 
<p>3、与mobilenet的比较</p> 
<p><img src="https://images2.imgbox.com/09/b6/STMdJZvo_o.png" alt="这里写图片描述" title=""></p> 
<p>参考链接：</p> 
<p>1、<a href="https://blog.csdn.net/u011974639/article/details/79200559">https://blog.csdn.net/u011974639/article/details/79200559</a></p> 
<p>2、<a href="https://blog.csdn.net/u014380165/article/details/75137111">https://blog.csdn.net/u014380165/article/details/75137111</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/627fe28b8237bda29faafcbba16f394f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">HashMap的put方法源码解析_JDK8</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b6ac3958897312fb38789edb5602a95f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">实现忽略大小写的copyProperties</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>