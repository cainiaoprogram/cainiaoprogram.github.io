<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于BERT预训练的中文命名实体识别TensorFlow实现 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于BERT预训练的中文命名实体识别TensorFlow实现" />
<meta property="og:description" content="BERT-BiLSMT-CRF-NER Tensorflow solution of NER task Using BiLSTM-CRF model with Google BERT Fine-tuning
GitHub： https://github.com/macanv/BERT-BiLSTM-CRF-NER
本文目录机构：
自己训练模型说明结果使用自己的数据 2019.1.31更新，支持pip install package 现在可以使用下面的命令下载软件包了：
pip install bert-base==0.0.7 -i https://pypi.python.org/simple 或者使用基于源代码的安装：
git clone https://github.com/macanv/BERT-BiLSTM-CRF-NER cd BERT-BiLSTM-CRF-NER/ python3 setup.py install 如果没啥问题，你将会看到这个：
笔者在windows10/ Linux/ Mac OSX上都测试过，安装没有问题。
软件包现在支持的功能 命名实体识别的训练命名实体识别的服务C/S继承优秀开源软件：bert_as_service(hanxiao)的BERT所有服务
4. 文本分类服务 （2019.2.19） 内容还会继续补充，同时欢迎大神们分享训练的模型或者新的方法或者数据(弱鸡的我并不会用在商业上，毕竟还是一个毕业即失业的渣渣~~)。
基于命名行训练命名实体识别模型: 安装完bert-base后，会生成两个基于命名行的工具，其中bert-base-ner-train支持命名实体识别模型的训练，你只需要指定训练数据的目录，BERT相关参数的目录即可。可以使用下面的命令查看帮助
bert-base-ner-train -help 训练的事例命名如下：
bert-base-ner-train \ -data_dir {your dataset dir}\ -output_dir {training output dir}\ -init_checkpoint {Google BERT model dir}\ -bert_config_file {bert_config.json under the Google BERT model dir} \ -vocab_file {vocab." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4c0c077fc7a630abcbeb0d37f073601c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-01-03T11:58:25+08:00" />
<meta property="article:modified_time" content="2019-01-03T11:58:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于BERT预训练的中文命名实体识别TensorFlow实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="BERTBiLSMTCRFNER_0"></a>BERT-BiLSMT-CRF-NER</h2> 
<p>Tensorflow solution of NER task Using BiLSTM-CRF model with Google BERT Fine-tuning<br> GitHub： <a href="https://github.com/macanv/BERT-BiLSTM-CRF-NER">https://github.com/macanv/BERT-BiLSTM-CRF-NER</a><br> 本文目录机构：</p> 
<ol><li>自己训练模型</li><li>说明</li><li>结果</li><li>使用自己的数据</li></ol> 
<hr> 
<h3><a id="2019131pip_install_package_9"></a>2019.1.31更新，支持pip install package</h3> 
<hr> 
<p>现在可以使用下面的命令下载软件包了：</p> 
<pre><code>pip install bert-base==0.0.7 -i https://pypi.python.org/simple
</code></pre> 
<p>或者使用基于源代码的安装：</p> 
<pre><code>git clone https://github.com/macanv/BERT-BiLSTM-CRF-NER
cd BERT-BiLSTM-CRF-NER/
python3 setup.py install
</code></pre> 
<p>如果没啥问题，你将会看到这个：<br> <img src="https://images2.imgbox.com/ec/b5/IqOVXALl_o.png" alt="安装成功"><br> 笔者在windows10/ Linux/ Mac OSX上都测试过，安装没有问题。</p> 
<h3><a id="_26"></a>软件包现在支持的功能</h3> 
<ol><li>命名实体识别的训练</li><li>命名实体识别的服务C/S</li><li>继承优秀开源软件：bert_as_service(hanxiao)的BERT所有服务<br> <strong>4. 文本分类服务</strong> （2019.2.19）</li></ol> 
<p><strong>内容还会继续补充，同时欢迎大神们分享训练的模型或者新的方法或者数据(弱鸡的我并不会用在商业上，毕竟还是一个毕业即失业的渣渣~~)。</strong></p> 
<h3><a id="_35"></a>基于命名行训练命名实体识别模型:</h3> 
<p>安装完bert-base后，会生成两个基于命名行的工具，其中bert-base-ner-train支持命名实体识别模型的训练，你只需要指定训练数据的目录，BERT相关参数的目录即可。可以使用下面的命令查看帮助</p> 
<pre><code>bert-base-ner-train -help
</code></pre> 
<p><img src="https://images2.imgbox.com/0d/dc/kF20n607_o.png" alt="在这里插入图片描述"><br> 训练的事例命名如下：</p> 
<pre><code>bert-base-ner-train \
    -data_dir {your dataset dir}\
    -output_dir {training output dir}\
    -init_checkpoint {Google BERT model dir}\
    -bert_config_file {bert_config.json under the Google BERT model dir} \
    -vocab_file {vocab.txt under the Google BERT model dir}
</code></pre> 
<h5><a id="_50"></a>参数说明</h5> 
<ol><li>其中data_dir是你的数据所在的目录，训练数据，验证数据和测试数据命名格式为：train.txt, dev.txt，test.txt,请按照这个格式命名文件，否则会报错。<br> 训练数据的格式如下:<pre><code>海 O
钓 O
比 O
赛 O
地 O
点 O
在 O
厦 B-LOC
门 I-LOC
与 O
金 B-LOC
门 I-LOC
之 O
间 O
的 O
海 O
域 O
。 O
</code></pre> </li></ol> 
<p>每行得第一个是字，第二个是它的标签，使用空格’ '分隔，请一定要使用空格。句与句之间使用空行划分。程序会自动读取你的数据。</p> 
<ol start="2"><li>output_dir： 训练模型输出的文件路径，模型的checkpoint以及一些标签映射表都会存储在这里，这个路径在作为服务的时候，可以指定为-ner_model_dir</li><li>init_checkpoint: 下载的谷歌BERT模型</li><li>bert_config_file ： 谷歌BERT模型下面的bert_config.json</li><li>vocab_file： 谷歌BERT模型下面的vocab.txt</li></ol> 
<p>训练完成后，你可以在你指定的output_dir中查看训练结果。</p> 
<h3><a id="_82"></a>将命名实体识别任务进行服务部署</h3> 
<p>作为服务的很多代码都来自优秀的开源项目: <a href="https://github.com/hanxiao/bert-as-service">bert as service of hanxiao</a> 但是我不知道这样改动是不是违反了某些许可规定，如果有违反，请马上告诉我，我将第一时间进行修改.而且服务端的代码很解耦，修改为另外一种任务的服务也是很简单的，例如文本分类，我将会不就提供这一功能，也欢迎愿意分享的童鞋分享模型或者代码。</p> 
<p>作为服务的命名是：bert-base-serving-start，同样的，你可以先使用-help查看相关帮助</p> 
<pre><code>bert-base-serving-start -help
</code></pre> 
<p><img src="https://images2.imgbox.com/a4/83/EHGTVWz1_o.png" alt="在这里插入图片描述"><br> 作为命名实体识别任务的服务，这两个目录是你必须指定的：ner_model_dir, bert_model_dir<br> 然后你就可以使用下面的命令启动了：</p> 
<pre><code>bert-base-serving-start \
    -model_dir C:\workspace\python\BERT_Base\output\ner2 \
    -bert_model_dir F:\chinese_L-12_H-768_A-12
    -mode NER
</code></pre> 
<h5><a id="_99"></a>参数解释</h5> 
<p>bert_model_dir: 谷歌BERT模型的解压路径,可以在这里下载 <a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a><br> model_dir: 训练好的NER模型或者文本分类模型的路径，对于上面的output_dir<br> model_pd_dir: 运行模型优化代码后， 经过模型压缩后的存储路径，例如运行上面的命令后改路径下会产生 ner_model.pb 这个二进制文件<br> mode:NER 或者是BERT这两个模式，类型是字符串，如果是NER,那么就会启动NER的服务，如果是BERT，那么具体参数将和[bert as service] 项目中得一样。</p> 
<blockquote> 
 <p>我提供了命名实体识别pb模型下载：<a href="https://pan.baidu.com/s/1m9VcueQ5gF-TJc00sFD88w" rel="nofollow">https://pan.baidu.com/s/1m9VcueQ5gF-TJc00sFD88w</a>, 提取码: guqq<br> 文本分类模型：<a href="https://pan.baidu.com/s/1oFPsOUh1n5AM2HjDIo2XCw" rel="nofollow">https://pan.baidu.com/s/1oFPsOUh1n5AM2HjDIo2XCw</a>, 提取码: bbu8<br> 文本分类使用的是bert中的demo:run_classxxx.py，在运行的时候使用Pickle序列化了label_list和id2label折两个变量。<br> 将 ner_mode.pb/classification_model.pb 文件放到 model_pd_dir目录下,将命名识别的label_list.pkl和id2map.pkl不同的模型不同的文件夹，因为他们同名，但是内容不一样，需要区分开来<br> 命名实体识别模型只支持人名，地名，住址机构名的识别，在我的测试数据上有95.6%的F1值（实体级别的得分）<br> 文本分类模型数据来自清华大学的文本分类数据：<a href="http://thuctc.thunlp.org/" rel="nofollow">http://thuctc.thunlp.org/</a> ， 在测试数据上准确率为98%~99%的准确率<br> 肥肠欢迎大家分享你们训练的更好的模型。</p> 
</blockquote> 
<p>如果使用的下载的模型，你可以使用下面的命令启动，替换你自己的路径即可：</p> 
<pre><code>bert-base-serving-start -model_pd_dir /home/macan/ml/workspace/BERT_Base/output/predict_optimizer  \ 
	-bert_model_dir /home/macan/ml/data/chinese_L-12_H-768_A-12/ \
	-ner_model_dir /home/macan/ml/data/bert_ner \
	-num_worker 8 
	-mode NER
</code></pre> 
<p>你将会看到下面的启动信息(启动log有点多，分两张图截)：<br> <img src="https://images2.imgbox.com/84/dc/fzvQTCab_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c4/9e/RmV2p8VH_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_123"></a>在本地连接服务端进行命名实体识别的测试</h5> 
<p>你可以使用下面的代码进行服务的连接，在本地进行NER测试，客户端代码如下:</p> 
<pre><code class="prism language-angular2html">import time
from bert_base.client import BertClient
# 指定服务器的IP
with BertClient(ip='XXX,XXX,XXX,XXX', ner_model_dir=ner_model_dir, show_server_config=False, check_version=False, check_length=False, mode='NER') as bc:
    start_t = time.perf_counter()
    str = '1月24日，新华社对外发布了中央对雄安新区的指导意见，洋洋洒洒1.2万多字，17次提到北京，4次提到天津，信息量很大，其实也回答了人们关心的很多问题。'
    rst = bc.encode([str, str])  #测试同时输入两个句子，多个输入同理
    print('rst:', rst) 
    print(time.perf_counter() - start_t)
</code></pre> 
<p>运行后，会输出下面的信息：<br> <img src="https://images2.imgbox.com/07/8f/YlEtQ6t5_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_138"></a>结果说明：</h5> 
<p>返回的结果就是序列标注的结果，再往后的工作就不准备再写了，因为后面的操作会涉及到一些策略问题，写的太多，影响代码的灵活，例如有童鞋在terminal_predict.py的代码上提了issue,无法应用到自己的数据中。这样看起来，也比较直观吧~~</p> 
<p>到此，基于命令行的用法已经讲完，不明白的地方请评论或者在GitHub上提交issue,觉得有用，麻烦在<a href="https://github.com/macanv/BERT-BiLSTM-CRF-NER">GitHub</a>上点个star吧~~</p> 
<p>###########################################################################################</p> 
<h2><a id="_145"></a>以下是基于源代码的训练和启动服务的教程</h2> 
<p>###########################################################################################</p> 
<h3><a id="_147"></a>自己训练命名实体识别模型</h3> 
<p>使用谷歌的BERT模型在BLSTM-CRF模型上进行预训练用于中文命名实体识别的Tensorflow代码’</p> 
<p>代码已经托管到GitHub <a href="https://github.com/macanv/BERT-BiLSTM-CRF-NER">代码传送门</a> 大家可以去clone 下来亲自体验一下！</p> 
<pre><code>git clone https://github.com/macanv/BERT-BiLSTM-CRF-NER
</code></pre> 
<p>关于BERT的相关理论文章不是本文的主要目的，而且网上简介该部分的文章多如牛毛，大家自行去查看吧，本文着重讲解基于BERT用于中文命名实体的fine-tuning 过程。</p> 
<h4><a id="1_Google_BERT__156"></a>1. 下载Google BERT 预训练模型：</h4> 
<pre><code>下载
wget https://storage.googleapis.com/bert_models/2018_11_03/chinese_L-12_H-768_A-12.zip  
解压
unzip chinese_L-12_H-768_A-12.zip
</code></pre> 
<h4><a id="2__164"></a>2. 训练模型</h4> 
<p>下载了Google的BERT模型和我的GitHub代码后，就可以开始训练啦<br> 训练之前先在项目目录中新建一个output文件夹，模型的输出，和结构都会保存在这个目录中</p> 
<pre><code>mkdir output
</code></pre> 
<p>训练的时候需要一些参数，你可以使用命名行的形式进行模型参数指定，例如下面的方法:</p> 
<pre><code>  python3 bert_lstm_ner.py   \
                  --task_name="NER"  \ 
                  --do_train=True   \
                  --do_eval=True   \
                  --do_predict=True
                  --data_dir=NERdata   \
                  --vocab_file=checkpoint/vocab.txt  \ 
                  --bert_config_file=checkpoint/bert_config.json \  
                  --init_checkpoint=checkpoint/bert_model.ckpt   \
                  --max_seq_length=128   \
                  --train_batch_size=32   \
                  --learning_rate=2e-5   \
                  --num_train_epochs=3.0   \
                  --output_dir=./output/result_dir/ 
</code></pre> 
<p>笔者比较菜，选择的是将默认参数写在代码中，开始训练的之前，只需要修改下面的代码即可，代码在bert_lstm_ner.py文件中</p> 
<pre><code>if os.name == 'nt': #windows path config
   bert_path = '{your BERT model path}'
   root_path = '{project path}'
else: # linux path config
   bert_path = '{your BERT model path}'
   root_path = '{project path}'
</code></pre> 
<p>os.name=='nt’是表示识别到的系统是windows，其余的是Linux，这里只需要修改一个，如果你是windows训练修改os.name='nt’下面的路径就好了，Linux或者Mac修改else下面的两个路径。<br> <strong>两个路径说明:</strong><br> bert_path: 就是在步骤1中下载解压的BERT模型的路径，复制绝对路径替换即可，例如我项目中所写的路径<br> root_path: 这个是项目的路径，也是一个绝对路径，即BERT-BiLSTM-CRF-NER的路径</p> 
<p>修改好两个路径后，就可以开始训练了：</p> 
<pre><code>python3 bert_lstm_ner.py
</code></pre> 
<h4><a id="_205"></a>说明：</h4> 
<p>模型代码主要在bert_lstm_ner.py中的create_model函数中<br> 下面对该函数逻辑进行讲解：</p> 
<ul><li>1使用bert模型对我们的输入进行represent</li></ul> 
<pre><code>	#使我们的input_ids数据通过bert 网络结构
    model = modeling.BertModel(
        config=bert_config,
        is_training=is_training,
        input_ids=input_ids,
        input_mask=input_mask,
        token_type_ids=segment_ids,
        use_one_hot_embeddings=use_one_hot_embeddings
    )
    # 获取bert 模型最后一层
    embedding = model.get_sequence_output()
</code></pre> 
<p>bert 的最后一层是所有transformer结果的最后一维，其是一个三维向量维度是：[batch_size, seq_length, embedding_size]，可以类比的理解为我们使用tf.nn.embedding_lookup获取的结果。</p> 
<ul><li>2 将embedding 作为LSTM结构的输入:</li></ul> 
<pre><code>	# 加载BLSTM-CRF模型对象
    blstm_crf = BLSTM_CRF(embedded_chars=embedding, hidden_unit=FLAGS.lstm_size, cell_type=FLAGS.cell, num_layers=FLAGS.num_layers,
                          dropout_rate=FLAGS.droupout_rate, initializers=initializers, num_labels=num_labels,
                          seq_length=max_seq_length, labels=labels, lengths=lengths, is_training=is_training)
    # 获取添加我们自己网络结构后的结果，这些结果包括loss, logits, trans, pred_ids
    rst = blstm_crf.add_blstm_crf_layer(crf_only=True)
</code></pre> 
<p>这里有几点需要说明：</p> 
<ol><li>因为BERT里面已经存在双向编码，所以LSTM并不是必须的，可以将BERT最后一层的结构直接扔给CRF进行解码。所以在代码中通过在add_blstm_crf_layer函数中的crf_only参数进行控制我们训练的时候使用的是那种网络结构用于最后的fine-tuning.通过两种结构的训练结果对比，其实他们的最后结果相差不大，可以说基本是一样的，足见transformer的强大。</li><li>crf_only=True 是我们fine-tuning 只使用CRF进行解码，不再使用传统经典的BLSTM-CRF，False表示使用blstm-crf这样的网络结构。</li><li>但是我在试验中发现，只使用CRF的训练时间要比BLSTM-CRF结构的时间要长，这一点我百思不得其解，按理加了BLSTM网络的参数会更多，如果有大佬发现这是个错的观察或者有合理的解释，麻烦不吝赐教。</li></ol> 
<h4><a id="_238"></a>实验结果</h4> 
<ul><li>1 基于label计算出来的指标:</li></ul> 
<h5><a id="In_dev_data_set_240"></a>In dev data set:</h5> 
<p><img src="https://images2.imgbox.com/2d/45/KovF1fQA_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="In_test_data_set_242"></a>In test data set</h5> 
<p><img src="https://images2.imgbox.com/22/03/UDEFEmMX_o.png" alt="在这里插入图片描述"></p> 
<ul><li>2 在很多地方命名实体的结果使用基于实体级别的评测更为合理，下面是实体级别的评测结果。<br> <img src="https://images2.imgbox.com/31/aa/fYCep3wO_o.png" alt="在这里插入图片描述"></li></ul> 
<p><a href="http://xn--conlleval-9c9nq01ryqc943ajfzfre0o5c740b.pl" rel="nofollow">评测脚本使用的是conlleval.pl</a>， <a href="http://conlleval.py" rel="nofollow">conlleval.py</a></p> 
<p>提供我训练的模型下载：</p> 
<blockquote> 
 <p>my model can download from baidu cloud:<br> 链接：<a href="https://pan.baidu.com/s/1GfDFleCcTv5393ufBYdgqQ" rel="nofollow">https://pan.baidu.com/s/1GfDFleCcTv5393ufBYdgqQ</a> 提取码：4cus</p> 
</blockquote> 
<ul><li>3 在线预测<br> 当你的模型训练完后，可以使用下面的脚本加载模型，进行在线预测</li></ul> 
<pre><code class="prism language-angular2html">python3 terminal_predict.py
</code></pre> 
<p><img src="https://images2.imgbox.com/3d/6f/Zue3TojG_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_261"></a>使用自己的数据：</h3> 
<p>BERT的大腿简直太粗了，效果很好有木有，看到这样的效果，是不是很想再自己的数据上进行测试一番呢？ 其实改的地方很少，只需要修改bert_lstm_ner.py文件中的几行代码就好啦：</p> 
<ul><li> 
  <ol><li>get_labels 函数</li></ol> </li></ul> 
<pre><code>    def get_labels(self):
        return ["O", "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC", "X", "[CLS]", "[SEP]"]
</code></pre> 
<p>这里是我数据中所有的标签，其中"X", “[CLS]”, “[SEP]” 是附加的， “[CLS]”, "[SEP]"是句子的开始和结束标志，X是wordpice产生的东西，中文中目前还没有遇到过，可以不用管，大家要改的话，就改前面的标签就好啦。<br> 例如你想加一个时间类型的实体，就加 “B-TIME”, “I-TIME”<br> 如果你想应用于分词中，那就没有-XXX了。就是B,I这些，简而言之，就是你的序列标注数据中的第二列的标签的set集合。<br> 你也可以把get_labels函数写成这样一劳永逸，但是要注意在测试集或者验证机中出现的OOLabel哦：</p> 
<pre><code>    def get_labels(self):
        # 通过读取train文件获取标签的方法会出现一定的风险。
        if os.path.exists(os.path.join(FLAGS.output_dir, 'label_list.pkl')):
            with codecs.open(os.path.join(FLAGS.output_dir, 'label_list.pkl'), 'rb') as rf:
                self.labels = pickle.load(rf)
        else:
            if len(self.labels) &gt; 0:
                self.labels = self.labels.union(set(["X", "[CLS]", "[SEP]"]))
                with codecs.open(os.path.join(FLAGS.output_dir, 'label_list.pkl'), 'wb') as rf:
                    pickle.dump(self.labels, rf)
            else:
                self.labels = ["O", 'B-TIM', 'I-TIM', "B-PER", "I-PER", "B-ORG", "I-ORG", "B-LOC", "I-LOC", "X", "[CLS]", "[SEP]"]
        return self.labels
</code></pre> 
<h3><a id="_288"></a>参考:</h3> 
<ul><li> <p>The evaluation codes come from:<a href="https://github.com/guillaumegenthial/tf_metrics/blob/master/tf_metrics/">https://github.com/guillaumegenthial/tf_metrics/blob/master/tf_metrics/</a><strong>init</strong>.py</p> </li><li> <p><a href="https://github.com/google-research/bert">https://github.com/google-research/bert</a></p> </li><li> <p><a href="https://github.com/kyzhouhzau/BERT-NER">https://github.com/kyzhouhzau/BERT-NER</a></p> </li><li> <p><a href="https://github.com/zjy-ucas/ChineseNER">https://github.com/zjy-ucas/ChineseNER</a></p> </li><li> <p><a href="https://github.com/hanxiao/bert-as-service">https://github.com/hanxiao/bert-as-service</a></p> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/be0b18dfe1b44ca737dc5b12ae096f7b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">RGB/XYZ Color Space Convert(RGB和XYZ色彩空间的相互转换矩阵)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2bd528cb1b061352733b2729611dbc58/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">IDEA使用switch传入String编译报错解决</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>