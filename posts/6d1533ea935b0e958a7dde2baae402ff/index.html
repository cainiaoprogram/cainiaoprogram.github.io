<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>支持向量机（Support Vector Machines，SVM） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="支持向量机（Support Vector Machines，SVM）" />
<meta property="og:description" content="什么是机器学习 支持向量机（Support Vector Machines，SVM）是一种强大的机器学习算法，可用于解决分类和回归问题。SVM的目标是找到一个最优的超平面，以在特征空间中有效地划分不同类别的样本。
基本原理 超平面 在二维空间中，超平面是一条直线，而在更高维的空间中，它是一个平面。对于二分类问题，SVM试图找到一个超平面，使得两个类别的样本被最大间隔分开。
支持向量 在SVM中，支持向量是离超平面最近的样本点。这些支持向量对决定超平面的位置和方向起关键作用。
间隔 SVM的目标是最大化支持向量到超平面的间隔，即最大化决策边界的宽度。
核函数 SVM可以使用核函数将数据映射到高维空间，从而在低维空间中无法线性分离的数据可以在高维空间中变得线性可分。
支持向量机（SVM）可以使用不同的核函数来处理线性不可分的问题，将数据映射到高维空间，以便在该空间中找到线性的超平面。以下是一些常见的SVM核函数：
线性核函数（Linear Kernel）： 在特征空间中直接进行线性划分。适用于线性可分的情况。
多项式核函数（Polynomial Kernel）： 将数据映射到更高次的多项式特征空间。c 是常数，d 是多项式的次数。
径向基核函数（Radial Basis Function，RBF或Gaussian Kernel）： 使用高斯分布函数进行映射，可以处理非线性问题。σ 是控制核函数宽度的参数。
Sigmoid核函数（Sigmoid Kernel）： 使用双曲正切函数进行映射，常用于神经网络。
Laplacian核函数（Laplacian Kernel）： 使用拉普拉斯分布进行映射，与RBF核类似，但对异常值更敏感。
这些核函数允许SVM在更高维度的空间中进行非线性映射，从而使得在原始特征空间中线性不可分的问题变得可分。选择适当的核函数通常依赖于具体问题和数据的性质，以及对模型的理解。
软间隔 对于非线性可分的数据，SVM引入软间隔，允许一些样本不满足硬间隔条件，以提高模型的泛化能力。
优点 适用于高维空间，对于特征数量大于样本数量的情况仍然有效。在处理非线性问题时，可以使用核技巧。对于二分类和多分类问题都有良好的适应性。 适用场景 二分类和多分类问题。高维数据集，例如文本分类、图像分类等。数据维度较小但需要有较好泛化性能的情况。 代码示例（使用Python和scikit-learn）： 以下是一个简单的SVM分类示例：
from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.svm import SVC from sklearn.metrics import accuracy_score, classification_report # 加载数据集 iris = datasets.load_iris() X = iris.data y = iris." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/6d1533ea935b0e958a7dde2baae402ff/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-05T14:41:36+08:00" />
<meta property="article:modified_time" content="2024-01-05T14:41:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">支持向量机（Support Vector Machines，SVM）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="httpsblogcsdnnetgaloiszhouarticledetails135383502_0"></a><a href="https://blog.csdn.net/galoiszhou/article/details/135383502">什么是机器学习</a></h2> 
<p>支持向量机（Support Vector Machines，SVM）是一种强大的机器学习算法，可用于<strong>解决分类和回归问题</strong>。SVM的目标是找到一个最优的超平面，以在特征空间中有效地划分不同类别的样本。</p> 
<h3><a id="_4"></a>基本原理</h3> 
<h4><a id="_6"></a>超平面</h4> 
<p>在二维空间中，超平面是一条直线，而在更高维的空间中，它是一个平面。对于二分类问题，SVM试图找到一个超平面，使得两个类别的样本被最大间隔分开。</p> 
<h4><a id="_10"></a>支持向量</h4> 
<p>在SVM中，支持向量是离超平面最近的样本点。这些支持向量对决定超平面的位置和方向起关键作用。</p> 
<h4><a id="_14"></a>间隔</h4> 
<p>SVM的目标是最大化支持向量到超平面的间隔，即最大化决策边界的宽度。</p> 
<h4><a id="_18"></a>核函数</h4> 
<p>SVM可以使用核函数将数据映射到高维空间，从而在低维空间中无法线性分离的数据可以在高维空间中变得线性可分。</p> 
<p>支持向量机（SVM）可以使用不同的核函数来处理线性不可分的问题，将数据映射到高维空间，以便在该空间中找到线性的超平面。以下是一些常见的SVM核函数：</p> 
<h5><a id="Linear_Kernel_24"></a>线性核函数（Linear Kernel）：</h5> 
<p><img src="https://images2.imgbox.com/1a/8b/ug0vzoTR_o.png" alt="在这里插入图片描述"><br> 在特征空间中直接进行线性划分。适用于线性可分的情况。</p> 
<h5><a id="Polynomial_Kernel_28"></a>多项式核函数（Polynomial Kernel）：</h5> 
<p><img src="https://images2.imgbox.com/48/b5/RROazYye_o.png" alt="在这里插入图片描述"></p> 
<p>将数据映射到更高次的多项式特征空间。c 是常数，d 是多项式的次数。</p> 
<h5><a id="Radial_Basis_FunctionRBFGaussian_Kernel_35"></a>径向基核函数（Radial Basis Function，RBF或Gaussian Kernel）：</h5> 
<p><img src="https://images2.imgbox.com/19/50/L3aAA5tU_o.png" alt="在这里插入图片描述"><br> 使用高斯分布函数进行映射，可以处理非线性问题。σ 是控制核函数宽度的参数。</p> 
<h5><a id="SigmoidSigmoid_Kernel_40"></a>Sigmoid核函数（Sigmoid Kernel）：</h5> 
<p><img src="https://images2.imgbox.com/65/1d/mt2gE3tn_o.png" alt="在这里插入图片描述"><br> 使用双曲正切函数进行映射，常用于神经网络。</p> 
<h5><a id="LaplacianLaplacian_Kernel_44"></a>Laplacian核函数（Laplacian Kernel）：</h5> 
<p><img src="https://images2.imgbox.com/a3/81/Ds1mqoo1_o.png" alt="在这里插入图片描述"><br> 使用拉普拉斯分布进行映射，与RBF核类似，但对异常值更敏感。</p> 
<p>这些核函数允许SVM在更高维度的空间中进行非线性映射，从而使得在原始特征空间中线性不可分的问题变得可分。选择适当的核函数通常依赖于具体问题和数据的性质，以及对模型的理解。</p> 
<h4><a id="_49"></a>软间隔</h4> 
<p>对于非线性可分的数据，SVM引入软间隔，允许一些样本不满足硬间隔条件，以提高模型的泛化能力。</p> 
<h3><a id="_53"></a>优点</h3> 
<ul><li>适用于<strong>高维空间</strong>，对于<strong>特征数量大于样本数量</strong>的情况仍然有效。</li><li>在处理非线性问题时，可以使用核技巧。</li><li>对于二分类和多分类问题都有良好的适应性。</li></ul> 
<h3><a id="_59"></a>适用场景</h3> 
<ul><li>二分类和多分类问题。</li><li>高维数据集，例如文本分类、图像分类等。</li><li>数据维度较小但需要有较好泛化性能的情况。</li></ul> 
<h3><a id="Pythonscikitlearn_66"></a>代码示例（使用Python和<code>scikit-learn</code>）：</h3> 
<p>以下是一个简单的SVM分类示例：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVC
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score<span class="token punctuation">,</span> classification_report

<span class="token comment"># 加载数据集</span>
iris <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> iris<span class="token punctuation">.</span>data
y <span class="token operator">=</span> iris<span class="token punctuation">.</span>target

<span class="token comment"># 划分训练集和测试集</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span>

<span class="token comment"># 创建SVM模型</span>
model <span class="token operator">=</span> SVC<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">)</span>  <span class="token comment"># 使用线性核函数</span>

<span class="token comment"># 训练模型</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

<span class="token comment"># 预测</span>
y_pred <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>

<span class="token comment"># 评估模型性能</span>
accuracy <span class="token operator">=</span> accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
report <span class="token operator">=</span> classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Accuracy: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>accuracy<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Classification Report:\n</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>report<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
</code></pre> 
<p>这是一个使用线性核函数的示例。对于非线性问题，可以尝试使用不同的核函数，如径向基核函数（RBF kernel）。SVM的性能和调参密切相关，通常需要根据具体问题进行调优。</p> 
<h4><a id="kernel__103"></a>kernel 参数的值</h4> 
<h5><a id="Linear_Kernel_105"></a>线性核函数（Linear Kernel）：</h5> 
<pre><code class="prism language-python">kernel<span class="token operator">=</span><span class="token string">'linear'</span>
</code></pre> 
<p>这是最简单的核函数，对应于线性SVM，适用于线性可分的情况。</p> 
<h5><a id="Polynomial_Kernel_113"></a>多项式核函数（Polynomial Kernel）：</h5> 
<pre><code class="prism language-python">kernel<span class="token operator">=</span><span class="token string">'poly'</span>
</code></pre> 
<p>除了指定kernel外，还可以设置degree参数来指定多项式的次数。例如，degree=3表示使用三次多项式。</p> 
<h5><a id="Radial_Basis_FunctionRBFGaussian_Kernel_121"></a>径向基核函数（Radial Basis Function，RBF或Gaussian Kernel）：</h5> 
<pre><code class="prism language-python">kernel<span class="token operator">=</span><span class="token string">'rbf'</span>
</code></pre> 
<p>这是一种常用的非线性核函数，通过调整gamma参数可以影响决策边界的“柔软性”。</p> 
<h5><a id="SigmoidSigmoid_Kernel_129"></a>Sigmoid核函数（Sigmoid Kernel）：</h5> 
<pre><code class="prism language-python">kernel<span class="token operator">=</span><span class="token string">'sigmoid'</span>
</code></pre> 
<p>使用双曲正切函数进行映射，通常在神经网络中使用。</p> 
<h5><a id="_137"></a>自定义核函数：</h5> 
<p>除了上述常见的核函数，scikit-learn还允许使用自定义的核函数，通过指定kernel='precomputed’并传递预计算的核矩阵。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/83803ed19f8bdbb1f29576048a533122/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Trino：分区表上的SQL提交 &amp; 查询流程浅析</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/205bcbb9aa88099ca5fdbfc9084187b4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Fontfabric：一款字体与设计的完美结合</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>