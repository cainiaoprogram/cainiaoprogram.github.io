<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>yolov5——问题记录 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="yolov5——问题记录" />
<meta property="og:description" content="简介
记录自己学习yolov5中遇到的问题，随即不定时更新，遇到问题记录下来方便回顾。
2022.05.06
1、改用VOC数据集进行训练，修改完格式后，运行train.py报错：
AssertionError: train: No labels in …/train.cache. Can not train without labels. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data
解决方法：打开文件目录下 utils/dataset.py 文件，ctrl&#43;F搜索define label，然后将框中内容修改为自己存放图片的文件夹名称，从&#34;images&#34;修改为&#34;JPEGImages&#34;即可。
2022.6.12
1、用云服务器训练的时候，遇到了这个问题：
ImportError: libgthread-2.0.so.0: cannot open shared object file: No such file or directory
解决方法：
apt-get update #安装额外的包 apt-get install libxext-dev apt-get install libxrender1 apt-get install libglib2.0-dev 2、冻结训练和解冻训练和预训练权重的问题
预训练权重是针对他们数据集训练得到的，如果是训练自己的数据集还能用吗？
预训练权重对于不同的数据集是通用的，因为特征是通用的。一般来讲，从0开始训练效果会很差，因为权值太过随机，特征提取效果不明显。对于目标检测模型来说，一般不从0开始训练，至少会使用主干部分的权值，虽然有些论文提到了可以不用预训练，但这主要是因为他们的数据集比较大而且他们的调参能力很强。如果从0开始训练，网络在前几个epoch的Loss可能会非常大，并且多次训练得到的训练结果可能相差很大，因为权重初始化太过随机。
因为目标检测模型里，主干特征提取部分所提取到的特征是通用的，把backbone冻结起来训练可以加快训练效率，也可以防止权值被破坏。在冻结阶段，模型的主干被冻结了，特征提取网络不发生改变，占用的显存较小，仅对网络进行微调。在解冻阶段，模型的主干不被冻结了，特征提取网络会发生改变，占用的显存较大，网络所有的参数都会发生改变。举个例子，如果在解冻阶段设置batch_size为4，那么在冻结阶段有可能可以把batch_size设置到8。下面是进行冻结训练的示例代码，假设前50个epoch冻结，后50个epoch解冻：
关于预训练权重加载。更改完网络结构后，即使更改了主干特征提取网络，也是可以加载预训练权重的。通过加载预训练权重，可以将网络中的参数初始化，我理解的是更有利于网络模型的复现，以及加快模型训练收敛速度。如下图所示，会根据你的网络结构，加载一部分参数。所以朋友们如果想改网络的话，也可以选择加载预训练模型的。
总结：无论换什么主干！！！都能用权重！！！都能用！！！都能用！！！
3、训练时出现以下问题：
TypeError: init() missing 1 required positional argument: ‘dtype’
翻译过来就是：类的构造函数需要一个’dtype’参数.但你创建类时没有传递
解决方法：
在train.py中把 num_workers 改小一些
2022-6-14" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/5b9080c5b92e5234e140e7cb16916b3d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-03T08:56:05+08:00" />
<meta property="article:modified_time" content="2022-10-03T08:56:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">yolov5——问题记录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><strong>简介</strong><br> 记录自己学习yolov5中遇到的问题，随即不定时更新，遇到问题记录下来方便回顾。</p> 
<p><strong>2022.05.06</strong><br> 1、改用VOC数据集进行训练，修改完格式后，运行train.py报错：<br> AssertionError: train: No labels in …/train.cache. Can not train without labels. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data</p> 
<p>解决方法：打开文件目录下 utils/dataset.py 文件，ctrl+F搜索define label，然后将框中内容修改为<strong>自己存放图片的文件夹</strong>名称，从"images"修改为"JPEGImages"即可。<br> <img src="https://images2.imgbox.com/e3/ac/nBrTT5Ff_o.png" alt="在这里插入图片描述"></p> 
<p><strong>2022.6.12</strong></p> 
<p>1、用云服务器训练的时候，遇到了这个问题：<br> ImportError: libgthread-2.0.so.0: cannot open shared object file: No such file or directory<br> 解决方法：</p> 
<pre><code class="prism language-bash"><span class="token function">apt-get</span> update

<span class="token comment">#安装额外的包</span>
<span class="token function">apt-get</span> <span class="token function">install</span> libxext-dev
<span class="token function">apt-get</span> <span class="token function">install</span> libxrender1
<span class="token function">apt-get</span> <span class="token function">install</span> libglib2.0-dev
</code></pre> 
<p>2、冻结训练和解冻训练和预训练权重的问题</p> 
<p>预训练权重是针对他们数据集训练得到的，如果是训练自己的数据集还能用吗？<br> 预训练权重对于不同的数据集是通用的，因为特征是通用的。一般来讲，从0开始训练效果会很差，因为权值太过随机，特征提取效果不明显。对于目标检测模型来说，一般不从0开始训练，至少会使用主干部分的权值，虽然有些论文提到了可以不用预训练，但这主要是因为他们的数据集比较大而且他们的调参能力很强。如果从0开始训练，网络在前几个epoch的Loss可能会非常大，并且多次训练得到的训练结果可能相差很大，因为权重初始化太过随机。<br> 因为目标检测模型里，主干特征提取部分所提取到的特征是通用的，把backbone冻结起来训练可以加快训练效率，也可以防止权值被破坏。在冻结阶段，模型的主干被冻结了，特征提取网络不发生改变，占用的显存较小，仅对网络进行微调。在解冻阶段，模型的主干不被冻结了，特征提取网络会发生改变，占用的显存较大，网络所有的参数都会发生改变。举个例子，如果在解冻阶段设置batch_size为4，那么在冻结阶段有可能可以把batch_size设置到8。下面是进行冻结训练的示例代码，假设前50个epoch冻结，后50个epoch解冻：</p> 
<p>关于预训练权重加载。更改完网络结构后，即使更改了主干特征提取网络，也是可以加载预训练权重的。通过加载预训练权重，可以将网络中的参数初始化，我理解的是更有利于网络模型的复现，以及加快模型训练收敛速度。如下图所示，会根据你的网络结构，加载一部分参数。所以朋友们如果想改网络的话，也可以选择加载预训练模型的。</p> 
<p>总结：无论换什么主干！！！都能用权重！！！都能用！！！都能用！！！</p> 
<p>3、训练时出现以下问题：<br> TypeError: init() missing 1 required positional argument: ‘dtype’<br> 翻译过来就是：类的构造函数需要一个’dtype’参数.但你创建类时没有传递<br> 解决方法：<br> 在train.py中把 num_workers 改小一些</p> 
<p><strong>2022-6-14</strong></p> 
<p>添加注意力机制</p> 
<p>1、第一步：在common.py文件中写入注意力机制代码，比如CBAM，将以下代码复制到common.py下</p> 
<pre><code class="prism language-python"><span class="token comment"># CBAM</span>
<span class="token keyword">class</span> <span class="token class-name">ChannelAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChannelAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>max_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>f1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes<span class="token punctuation">,</span> in_planes <span class="token operator">//</span> ratio<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>f2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes <span class="token operator">//</span> ratio<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> self<span class="token punctuation">.</span>f2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>f1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        max_out <span class="token operator">=</span> self<span class="token punctuation">.</span>f2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>f1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>avg_out <span class="token operator">+</span> max_out<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out


<span class="token keyword">class</span> <span class="token class-name">SpatialAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SpatialAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">assert</span> kernel_size <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'kernel size must be 3 or 7'</span>
        padding <span class="token operator">=</span> <span class="token number">3</span> <span class="token keyword">if</span> kernel_size <span class="token operator">==</span> <span class="token number">7</span> <span class="token keyword">else</span> <span class="token number">1</span>
        <span class="token comment"># (特征图的大小-算子的size+2*padding)/步长+1</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>padding<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 1*h*w</span>
        avg_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        max_out<span class="token punctuation">,</span> _ <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>avg_out<span class="token punctuation">,</span> max_out<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 2*h*w</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token comment"># 1*h*w</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">CBAM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># CSP Bottleneck with 3 convolutions</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ch_in, ch_out, number, shortcut, groups, expansion</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CBAM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>channel_attention <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> ratio<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>spatial_attention <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span>kernel_size<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>channel_attention<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x
        <span class="token comment"># c*h*w</span>
        <span class="token comment"># c*h*w * 1*h*w</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>spatial_attention<span class="token punctuation">(</span>out<span class="token punctuation">)</span> <span class="token operator">*</span> out
        <span class="token keyword">return</span> out
</code></pre> 
<p>2、找到yolo.py文件下的parse_model函数，将类名加入到下图位置</p> 
<p><img src="https://images2.imgbox.com/6e/3e/L3Qrmb7n_o.png" alt="在这里插入图片描述"></p> 
<p>3、修改配置文件yaml，比如yolov5s.yaml，如下图，将注意力机制加到backbone的最后一层（也可加在C3里面）</p> 
<p><img src="https://images2.imgbox.com/63/de/cY6jdYIj_o.png" alt="在这里插入图片描述"><br> 然后，还没完，还要继续修改<code>head</code>部分。当在网络中添加了新的层之后，那么该层网络之后的层的编号都会发生改变，看下图，原本Detect指定的是[17,20,23]，但当添加过CBAM注意力层之后（添加在第9层的，9层之后的层数编号要1），修改Detect：[17,20,23]-&gt;[18,21,24]。同样的，<code>Concat</code> 前的from系数也要修改，这样才能保持原网络结构不发生特别大的改变。我们刚才把SE层加到了第9层，所以第9层之后的编号都会加1，这里我们要把后面两个Concat的from系数分别由[-1,14]-&gt;[-1,15] ,[-1,10]-&gt;[-1,11]。<br> <img src="https://images2.imgbox.com/9d/2c/SAtk99tI_o.png" alt="在这里插入图片描述"><br> 至此，注意力机制添加完毕，其他注意力机制添加方法相同。</p> 
<p><strong>2022-06-27</strong><br> thop库安装与使用</p> 
<p>1、介绍，yolov5用 thop 三方库来计算网络的GFLOPs，正确安装thop才会显示GFLOPs<br> 2、问题，直接pip install thop，然后会显示已成功安装。但是！问题来了，训练时并不显示网络的GFLOPs!卸载再安装，还是不行!<br> 3、原因就是thop安装方法错了，要将github上thop下载到本地，再安装，才能正确显示。<br> 安装步骤如下：<br> 第一步，找到 thop 包的github官方链接 <a href="https://github.com/Lyken17/pytorch-OpCounter">thop</a><br> 第二步，下载压缩文件，解压到本地路径<br> 第三步，打开<code>annaconda prompt</code>，激活进入自己的虚拟环境，<code>cd</code>到压缩包解压的路径下<br> 第四步，输入命令<code>python setup.py install</code>，等待安装完成即可</p> 
<p><strong>2022-08-05</strong></p> 
<p><strong>问题：</strong><br> 使用YOLOv5训练时，出现以下错误：</p> 
<blockquote> 
 <p>RuntimeError: result type Float can’t be cast to the desired output type long int</p> 
</blockquote> 
<p><strong>原因猜测：</strong></p> 
<p>之前使用torch1.8.0和torchvision0.8.0没什么问题，换了torch1.12.0和torchvision0.13.0后，<code>loss.py</code>函数，就报错了，可能也是yolov5版本更新的问题。</p> 
<p><strong>解决方法：</strong></p> 
<p>修改<code>loss.py</code>的两处内容<br> 1、打开<code>loss.py</code>，<code>ctrl+F</code> 搜索 ，输入 【for i in range(self.nl)】，找到下面内容：<br> <img src="https://images2.imgbox.com/49/74/QUOkhLjp_o.png" alt="在这里插入图片描述"><br> 下面是修改后的内容，方便复制：</p> 
<blockquote> 
 <p>anchors, shape = self.anchors[i], p[i].shape</p> 
</blockquote> 
<p>2、<code>ctrl+F</code> 搜索，输入【indices.append】，找到下面的内容，注意看清楚，别找错了<br> <img src="https://images2.imgbox.com/83/ec/fCO7t5aU_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>indices.append((b, a, gj.clamp_(0, shape[2] - 1), gi.clamp_(0, shape[3] - 1))) # image, anchor, grid</p> 
</blockquote> 
<p>3、保存运行，完美解决，已亲测可用！</p> 
<p><strong>2022-08-16</strong></p> 
<p>问题：<br> tpdm安装<br> 有时候，<code>pip install tpdm</code>安装失败<br> 换用这行命令：<code>conda install -c conda-forge tqdm</code></p> 
<p>2022-08-25<br> 问题：<br> 云服务器，Ubuntu系统下，运行python，报错：<code>ModuleNotFoundError: No module named '_tkinter'</code>，提示缺少<code>tkinter</code>模块</p> 
<p>解决方法：</p> 
<pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> python3.7-tk
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e767acf18cfc6c94f8300653cde6adf4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">搞懂Nginx&#43;keepalived实现双机热备，Nginx服务的高可用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8c53c5d530e1fcbb9c5032a914783510/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【持久层框架】- SpringData - JPA</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>