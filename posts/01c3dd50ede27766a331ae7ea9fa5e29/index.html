<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CAT: LoCalization and IdentiﬁcAtion Cascade Detection Transformer for Open-World Object Detection - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CAT: LoCalization and IdentiﬁcAtion Cascade Detection Transformer for Open-World Object Detection" />
<meta property="og:description" content="CAT: LoCalization and IdentiﬁcAtion Cascade Detection Transformer for Open-World Object Detection 摘要1介绍2 问题定义3 方法3.1 整体架构3.2 级联解耦译码方法3.3 自适应伪标记机制3.4.训练和推理 4，实验4.1 数据集和评估指标4.2 实现细节4.3.与最先进方法的比较4.4 消融实验 5.与先前工作的关系6 总结致谢 for Open-World Object Detection) 摘要 “面向开放世界目标检测（OWOD）作为一个更一般且具有挑战性的目标，要求从已知对象的数据中训练的模型能够检测已知和未知的对象，并逐渐学会识别这些未知对象。现有的采用标准检测框架和固定伪标注机制（PLM）的工作存在以下问题：（i）检测未知对象实质上减少了模型检测已知对象的能力。 （ii）PLM未充分利用输入的先验知识。 （iii）PLM的固定选择方式不能保证模型在正确方向上进行训练。我们观察到，人类在下意识中更倾向于专注于所有前景对象，然后逐一详细识别每个对象，而不是同时定位和识别单个对象，以减轻混淆。这激发了我们提出一种新颖的解决方案，称为CAT：LoCalization和IdentiﬁcAtion Cascade Detection Transformer，通过级联解码的方式通过共享解码器解耦检测过程。与此同时，我们提出了自适应伪标注机制，将模型驱动的PLM与输入驱动的PLM相结合，并自适应地生成强大的未知对象的伪标签，显著提高了CAT检索未知对象的能力。在两个基准测试上的实验证明，即MS-COCO和PASCAL VOC，我们的模型优于最先进的方法。代码公开可用于 https://github.com/xiaomabufei/CAT。”
1介绍 “开放世界目标检测（OWOD）是计算机视觉中更为实际的检测问题，使人工智能（AI）能够更智能地应对真实场景中的更多困难。在OWOD范 paradigm 内，模型的生命周期通过迭代学习过程推动。在每个阶段，仅由已知对象训练的模型需要同时检测已知对象、定位未知对象并将其识别为未知类别。然后，人类注释员逐渐标记其中一些已标记的未知类别。给定这些新添加的注释后，模型将继续在不重新从头开始训练的情况下增量更新其知识。”
最近，Joseph等人[21]提出了一种基于两阶段Faster R-CNN [38]流程的开放世界目标检测器ORE。ORE利用了自动标注步骤来获得训练模型以检测未知对象的伪未知。它学习了一个基于能量的二元分类器，以区分未知类别和已知类别。然而，它的成功在很大程度上依赖于一个保留的验证集，该集合被用来估计基于能量的分类器中未知对象的分布。接着，一些方法[29, 43–45]试图扩展ORE并取得了一些成功。为了缓解ORE中的问题，Gupta等人[17]提出了在合理的情况下使用检测变压器 [4,46] 进行OWOD，并直接利用了DDETR [46]的框架。此外，他们提出了一种基于注意力的PLM，根据注意力分数为未知对象选择伪标签。
对于现有研究，我们发现了以下阻碍问题：
（i）由于包含检测未知对象的任务，模型检测已知对象的能力显著下降。为了减轻已知和未知对象之间的混淆，人们更倾向于拆解开放世界目标检测的过程，而不是像大多数标准检测模型那样同时定位和识别开放世界对象。
（ii）据我们所知，在现有的OWOD PLM中，模型利用已知对象的学习过程引导生成未知对象的伪标签，但不利用输入的先验条件（例如文本、光照等）。结果是，模型无法学习超出数据注释范围的知识。
（iii）PLM的固定选择方式不能保证模型在正确方向上学习检测未知对象，由于伪标签的不确定质量。模型可能更差地检测未知对象。
面对新场景时，人类更倾向于聚焦于所有前景对象，然后详细分析它们[6]，如图1所示。受此启发以及前述观察，我们提出了一种新颖的LoCalization and IdentificAtion Cascade Detection Transformer。CAT包括三个专用组件，即共享变压器解码器、级联解耦解码方式和自适应伪标注机制。通过级联解耦解码方式，共享变压器解码器解耦了定位和识别过程。因此，识别过程对于定位过程的影响被降低。在这种情况下，模型可以更好地定位更多前景对象，从而提高检索未知对象的能力。同时，独立的识别过程使模型能够更有重点地进行识别，从而减轻未知对检测已知对象的影响。在这种解码方式中，前者用于定位，后者用于识别。自适应伪标注机制维护CAT探索超出已知对象知识的能力，并根据模型训练过程自适应调整伪标签生成。我们的贡献可以总结为四点：
我们提出了一种新颖的定位和识别级联检测变压器（CAT），具有出色的检索未知对象的能力，并减轻检测未知对象对已知对象检测的影响。
受人们在面对开放场景时的下意识反应的启发，我们提出了级联解耦解码方式，通过共享解码器解耦了解码过程。
我们引入了一种新颖的伪标注机制，在训练过程中自适应地结合了模型驱动和输入驱动的伪标注，以生成强大的伪标签并探索超出已知对象知识的范围。
我们在两个流行的基准测试上进行了大量实验证明了CAT的有效性。在OWOD、IOD和开放集检测方面，CAT优于最先进的方法。对于OWOD，CAT在未知召回方面相对于SOTA方法实现了9.7%到12.8%的绝对增益。
图1.当面对开放世界中的新场景时，人类会下意识地关注所有前景物体，然后详细识别它们，以减轻已知和未知物体之间的混淆，从而获得清晰的视图。受此启发，我们的CAT利用共享解码器以级联解码的方式将定位和识别过程解耦，其中前一个解码过程用于定位，后者用于识别。
2 问题定义 在时间 𝑡，令 𝐾𝑡 = {1, 2, … , 𝐶} 表示已知对象类别的集合，令 𝑈𝑡 = {𝐶 &#43; 1, …} 表示可能在测试时间遇到的未知类别。已知对象类别 𝐾𝑡 在数据集 𝐷𝑡 = {𝐽𝑡,𝐿𝑡} 中标记，其中 𝐽𝑡 表示输入图像，𝐿𝑡 表示时间 𝑡 的相应标签。训练图像集包括 𝑀 张图像 𝐽𝑡 = {𝑖1,𝑖2, … , 𝑖𝑀} 和相应的标签 𝐿𝑡 = {ℓ1,ℓ2, … , ℓ𝑀}。每个 ℓ𝑖 = {𝑇1,𝑇2, … ,𝑇𝑁} 表示一组具有类别标签 𝑐𝑛 ⊂ 𝐾𝑡 和位置信息的 𝑁 个对象实例，其中 𝑥𝑛,𝑦𝑛,𝑤𝑛,ℎ𝑛 分别表示边界框的中心坐标、宽度和高度。开放世界目标检测去除了传统目标检测中的人为假设和限制，使目标检测任务更贴近实际生活。它要求训练好的模型 𝑀𝑡 不仅能够检测先前遇到的已知类别 𝐶，还能够将未知类别的实例识别为属于未知类别。此外，它要求对象检测器能够增量更新新的知识，并且这个循环在检测器的生命周期内一直进行。在增量更新阶段，由 𝑀𝑡 识别的未知实例被手动注释，并且连同它们相应的训练示例一起，将 𝐷𝑡 更新为 𝐷𝑡&#43;1，将 𝐾𝑡 更新为 𝐾𝑡&#43;1 = {1, 2, … , 𝐶, … , 𝐶 &#43; 𝑛}，模型将这 𝑛 个新类别添加到已知类别中，并在整个数据集 𝐷𝑡&#43;1 上不重新训练的情况下更新为 𝑀𝑡&#43;1。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/01c3dd50ede27766a331ae7ea9fa5e29/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-27T09:41:23+08:00" />
<meta property="article:modified_time" content="2023-12-27T09:41:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CAT: LoCalization and IdentiﬁcAtion Cascade Detection Transformer for Open-World Object Detection</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>CAT: LoCalization and IdentiﬁcAtion Cascade Detection Transformer for Open-World Object Detection</h4> 
 <ul><li><ul><li><a href="#_2" rel="nofollow">摘要</a></li><li><a href="#1_4" rel="nofollow">1介绍</a></li><li><a href="#2__27" rel="nofollow">2 问题定义</a></li><li><a href="#3__32" rel="nofollow">3 方法</a></li><li><ul><li><a href="#31__35" rel="nofollow">3.1 整体架构</a></li><li><a href="#32__38" rel="nofollow">3.2 级联解耦译码方法</a></li><li><a href="#33__45" rel="nofollow">3.3 自适应伪标记机制</a></li><li><a href="#34_62" rel="nofollow">3.4.训练和推理</a></li></ul> 
   </li><li><a href="#4_67" rel="nofollow">4，实验</a></li><li><ul><li><a href="#41__68" rel="nofollow">4.1 数据集和评估指标</a></li><li><a href="#42__77" rel="nofollow">4.2 实现细节</a></li><li><a href="#43_80" rel="nofollow">4.3.与最先进方法的比较</a></li><li><a href="#44__95" rel="nofollow">4.4 消融实验</a></li></ul> 
   </li><li><a href="#5_114" rel="nofollow">5.与先前工作的关系</a></li><li><a href="#6__117" rel="nofollow">6 总结</a></li><li><a href="#_120" rel="nofollow">致谢</a></li></ul> 
 </li></ul> 
</div> 
<br> for Open-World Object Detection) 
<p></p> 
<h3><a id="_2"></a>摘要</h3> 
<p>“面向开放世界目标检测（OWOD）作为一个更一般且具有挑战性的目标，要求从已知对象的数据中训练的模型能够检测已知和未知的对象，并逐渐学会识别这些未知对象。现有的采用标准检测框架和固定伪标注机制（PLM）的工作存在以下问题：（i）检测未知对象实质上减少了模型检测已知对象的能力。 （ii）PLM未充分利用输入的先验知识。 （iii）PLM的固定选择方式不能保证模型在正确方向上进行训练。我们观察到，人类在下意识中更倾向于专注于所有前景对象，然后逐一详细识别每个对象，而不是同时定位和识别单个对象，以减轻混淆。这激发了我们提出一种新颖的解决方案，称为CAT：LoCalization和IdentiﬁcAtion Cascade Detection Transformer，通过级联解码的方式通过共享解码器解耦检测过程。与此同时，我们提出了自适应伪标注机制，将模型驱动的PLM与输入驱动的PLM相结合，并自适应地生成强大的未知对象的伪标签，显著提高了CAT检索未知对象的能力。在两个基准测试上的实验证明，即MS-COCO和PASCAL VOC，我们的模型优于最先进的方法。代码公开可用于 https://github.com/xiaomabufei/CAT。”</p> 
<h3><a id="1_4"></a>1介绍</h3> 
<p>“开放世界目标检测（OWOD）是计算机视觉中更为实际的检测问题，使人工智能（AI）能够更智能地应对真实场景中的更多困难。在OWOD范 paradigm 内，模型的生命周期通过迭代学习过程推动。在每个阶段，仅由已知对象训练的模型需要同时检测已知对象、定位未知对象并将其识别为未知类别。然后，人类注释员逐渐标记其中一些已标记的未知类别。给定这些新添加的注释后，模型将继续在不重新从头开始训练的情况下增量更新其知识。”</p> 
<p>最近，Joseph等人[21]提出了一种基于两阶段Faster R-CNN [38]流程的开放世界目标检测器ORE。ORE利用了自动标注步骤来获得训练模型以检测未知对象的伪未知。它学习了一个基于能量的二元分类器，以区分未知类别和已知类别。然而，它的成功在很大程度上依赖于一个保留的验证集，该集合被用来估计基于能量的分类器中未知对象的分布。接着，一些方法[29, 43–45]试图扩展ORE并取得了一些成功。为了缓解ORE中的问题，Gupta等人[17]提出了在合理的情况下使用检测变压器 [4,46] 进行OWOD，并直接利用了DDETR [46]的框架。此外，他们提出了一种基于注意力的PLM，根据注意力分数为未知对象选择伪标签。</p> 
<p>对于现有研究，我们发现了以下阻碍问题：</p> 
<ol><li> <p>（i）由于包含检测未知对象的任务，模型检测已知对象的能力显著下降。为了减轻已知和未知对象之间的混淆，人们更倾向于拆解开放世界目标检测的过程，而不是像大多数标准检测模型那样同时定位和识别开放世界对象。</p> </li><li> <p>（ii）据我们所知，在现有的OWOD PLM中，模型利用已知对象的学习过程引导生成未知对象的伪标签，但不利用输入的先验条件（例如文本、光照等）。结果是，模型无法学习超出数据注释范围的知识。</p> </li><li> <p>（iii）PLM的固定选择方式不能保证模型在正确方向上学习检测未知对象，由于伪标签的不确定质量。模型可能更差地检测未知对象。</p> </li></ol> 
<p>面对新场景时，人类更倾向于聚焦于所有前景对象，然后详细分析它们[6]，如图1所示。受此启发以及前述观察，我们提出了一种新颖的LoCalization and IdentificAtion Cascade Detection Transformer。CAT包括三个专用组件，即共享变压器解码器、级联解耦解码方式和自适应伪标注机制。通过级联解耦解码方式，共享变压器解码器解耦了定位和识别过程。因此，识别过程对于定位过程的影响被降低。在这种情况下，模型可以更好地定位更多前景对象，从而提高检索未知对象的能力。同时，独立的识别过程使模型能够更有重点地进行识别，从而减轻未知对检测已知对象的影响。在这种解码方式中，前者用于定位，后者用于识别。自适应伪标注机制维护CAT探索超出已知对象知识的能力，并根据模型训练过程自适应调整伪标签生成。我们的贡献可以总结为四点：</p> 
<ul><li> <p>我们提出了一种新颖的定位和识别级联检测变压器（CAT），具有出色的检索未知对象的能力，并减轻检测未知对象对已知对象检测的影响。</p> </li><li> <p>受人们在面对开放场景时的下意识反应的启发，我们提出了级联解耦解码方式，通过共享解码器解耦了解码过程。</p> </li><li> <p>我们引入了一种新颖的伪标注机制，在训练过程中自适应地结合了模型驱动和输入驱动的伪标注，以生成强大的伪标签并探索超出已知对象知识的范围。</p> </li><li> <p>我们在两个流行的基准测试上进行了大量实验证明了CAT的有效性。在OWOD、IOD和开放集检测方面，CAT优于最先进的方法。对于OWOD，CAT在未知召回方面相对于SOTA方法实现了9.7%到12.8%的绝对增益。<br> <img src="https://images2.imgbox.com/7c/bd/dkDOzLRt_o.png" alt="在这里插入图片描述"><br> 图1.当面对开放世界中的新场景时，人类会下意识地关注所有前景物体，然后详细识别它们，以减轻已知和未知物体之间的混淆，从而获得清晰的视图。受此启发，我们的CAT利用共享解码器以级联解码的方式将定位和识别过程解耦，其中前一个解码过程用于定位，后者用于识别。</p> </li></ul> 
<h3><a id="2__27"></a>2 问题定义</h3> 
<p>在时间 𝑡，令 𝐾𝑡 = {1, 2, … , 𝐶} 表示已知对象类别的集合，令 𝑈𝑡 = {𝐶 + 1, …} 表示可能在测试时间遇到的未知类别。已知对象类别 𝐾𝑡 在数据集 𝐷𝑡 = {𝐽𝑡,𝐿𝑡} 中标记，其中 𝐽𝑡 表示输入图像，𝐿𝑡 表示时间 𝑡 的相应标签。训练图像集包括 𝑀 张图像 𝐽𝑡 = {𝑖1,𝑖2, … , 𝑖𝑀} 和相应的标签 𝐿𝑡 = {ℓ1,ℓ2, … , ℓ𝑀}。每个 ℓ𝑖 = {𝑇1,𝑇2, … ,𝑇𝑁} 表示一组具有类别标签 𝑐𝑛 ⊂ 𝐾𝑡 和位置信息的 𝑁 个对象实例，其中 𝑥𝑛,𝑦𝑛,𝑤𝑛,ℎ𝑛 分别表示边界框的中心坐标、宽度和高度。开放世界目标检测去除了传统目标检测中的人为假设和限制，使目标检测任务更贴近实际生活。它要求训练好的模型 𝑀𝑡 不仅能够检测先前遇到的已知类别 𝐶，还能够将未知类别的实例识别为属于未知类别。此外，它要求对象检测器能够增量更新新的知识，并且这个循环在检测器的生命周期内一直进行。在增量更新阶段，由 𝑀𝑡 识别的未知实例被手动注释，并且连同它们相应的训练示例一起，将 𝐷𝑡 更新为 𝐷𝑡+1，将 𝐾𝑡 更新为 𝐾𝑡+1 = {1, 2, … , 𝐶, … , 𝐶 + 𝑛}，模型将这 𝑛 个新类别添加到已知类别中，并在整个数据集 𝐷𝑡+1 上不重新训练的情况下更新为 𝑀𝑡+1。<br> <img src="https://images2.imgbox.com/fa/ac/CCzNBD0c_o.png" alt="在这里插入图片描述"><br> 图2。所提出的CAT框架的总体架构。提出的CAT包括多尺度特征提取器、共享变压器解码器、回归预测分支和自适应伪标注。多尺度特征提取器包括主流特征提取主干网络和一个可变形变换编码器，用于提取多尺度特征。共享变压器解码器是一个可变形变换解码器，并通过级联解码方式解耦了定位和识别过程。回归预测分支包含边界框回归分支 𝐹𝑟𝑒𝑔、新颖目标性分支 𝐹𝑜𝑏 𝑗 和新颖性分类分支 𝐹𝑐𝑙𝑠。新颖性分类和目标性分支是单层前馈网络（FFN），而回归分支是3层FFN。</p> 
<h3><a id="3__32"></a>3 方法</h3> 
<p>本节详细阐述了提出的CAT。在第3.1节中，详细描述了CAT的整体架构。我们提出解耦检测变压器的解码过程，并在第3.2节中提出了定位和识别级联解耦解码方式。在第3.3节中，我们提出了一种新颖的自适应调整伪标注的策略。在第3.4节中，我们说明了CAT的端到端训练策略。</p> 
<h4><a id="31__35"></a>3.1 整体架构</h4> 
<p>如图2所示，对于给定的图像 J ∈ R𝐻×𝑊×3，CAT使用分层特征提取的主干网络提取多尺度特征 Z𝑖 ∈ R𝐻4×𝑖2 × 𝑊4×2𝑖 ×2𝑖𝐶𝑠 ，其中 𝑖 = 1, 2, 3。特征图 𝑍𝑖 通过使用 1×1 卷积从维度 𝐶𝑠 投影到维度 𝐶𝑑，并在展平后与 𝑁𝑠 个具有 𝐶𝑑 维度的向量连接在一起。随后，与补充的位置编码 𝑃𝑛 ∈ R𝑁𝑠 ×𝐶𝑑 一起，多尺度特征被送入可变形变换编码器以编码语义特征。编码的语义特征 𝑀 ∈ R𝑁𝑠 ×𝑐𝑑 被获取并与一组 𝑁 个可学习的位置查询一起发送到共享解码器。在交叉注意力和自注意力模块的辅助下，共享解码器将位置查询 𝑄𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛 ∈ R𝑁×𝐷 转换为一组 N 个位置查询嵌入 𝐸𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛 ∈ R𝑁×𝐷。然后，𝐸𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛 输入到回归分支以定位包含已知类别和未知类别的 N 个前景边界框。同时，𝐸𝑙𝑜𝑐𝑎𝑡𝑖𝑜𝑛 被用作类别查询，与 𝑀 一起发送到共享解码器。共享解码器将类别查询转换为 𝑁 个类别查询嵌入 𝐸𝑐𝑙𝑎𝑠𝑠，与位置查询嵌入对应。然后，𝐸𝑐𝑙𝑎𝑠𝑠 被送入目标性和新颖性分类分支以分别预测目标性和类别。通过使用二分图匹配损失选择最佳匹配已知实例的唯一查询后，剩余的查询被用于选择未知类别实例，并通过自适应伪标注机制生成伪标签。</p> 
<h4><a id="32__38"></a>3.2 级联解耦译码方法</h4> 
<p>目标检测变压器 [3, 4, 11, 25, 32, 46] 利用对象查询来检测对象实例，其中每个对象查询表示一个对象实例。在解码阶段，通过将对象查询与来自编码语义特征的语义信息连接，更新对象查询为查询嵌入。生成的查询嵌入同时耦合了对象的位置和类别信息，用于对象的定位和识别过程。对于开放世界目标检测，模型需要检测已知对象、定位未知对象，并将它们识别为未知类别。</p> 
<p>受人们如何对新情景做出反应的启发[6]，提出了一种级联解耦解码方式以级联方式解码编码特征。我们利用共享解码器两次解码编码特征。第一次解码的嵌入用于定位前景对象，而第二次解码的嵌入用于识别对象的类别和“未知”。定位和识别级联解码结构的操作表达如下：<br> <img src="https://images2.imgbox.com/b2/1b/LNIGXmCp_o.png" alt="在这里插入图片描述"><br> 其中，F𝑠 (·) 表示共享解码器，F𝑒 (·) 是编码器，∅(·) 是主干网络。𝑃𝑛 代表位置编码。R 代表参考点，J 表示输入图像。在级联解耦解码阶段，位置嵌入被用作类别查询来生成类别嵌入。因此，定位过程不受类别信息的限制，而识别过程可以从级联结构中的位置知识中获得帮助。</p> 
<h4><a id="33__45"></a>3.3 自适应伪标记机制</h4> 
<p>伪标签在引导模型检测未知对象实例、确定模型的上限学习限制方面发挥着重要作用。现有方法 [17, 21] 仅使用模型驱动的伪标注，并未充分利用输入的先验知识（光流、纹理等）。模型驱动的伪标注 [17] 使模型的学习陷入已知对象的知识中，因为模型的知识来源仅限于已知对象实例。此外，它们的固定选择方式不能保证未知对象的正确学习方向。我们提出将模型驱动与输入驱动的伪标注 [36, 41, 47] 结合起来，以扩展模型的知识来源。同时，伪标签的选择方案不应固定，而应能够根据训练进行调整，并在面对意外问题时自适应调整。</p> 
<p>在本文中，受到 [1] 的启发，提出了一种新颖的伪标注机制，根据模型面临的情况自适应地结合了模型驱动和输入驱动的伪标注，其中采用了基于注意力的模型驱动伪标注 [17] 作为模型驱动伪标注，选择性搜索 [41] 作为输入驱动伪标注。在自适应伪标注机制中，模型驱动伪标注生成伪标签的候选框 𝑃𝑚 及其对应的置信度 𝑠𝑜，而输入驱动伪标注生成伪标签的候选框 𝑃𝐼。生成的伪标签的对象置信度表达如下：<br> <img src="https://images2.imgbox.com/27/fd/vFAoGtDN_o.png" alt="在这里插入图片描述"><br> 其中，IOU(·)（交并比 [39]）是比较两个任意形状相似性的最常用的度量。𝑖 表示伪标签的索引。W𝑚 和 W𝐼 是自适应权重，由 𝑀𝑒𝑎𝑠𝑢𝑟𝑒𝑟、𝑆𝑒𝑛𝑠𝑜𝑟 和 𝐴𝑑𝑗𝑢𝑠𝑡𝑒𝑟 控制，如下所示：<br> <img src="https://images2.imgbox.com/bf/7a/S5jsgGy0_o.png" alt="在这里插入图片描述"><br> 其中，𝐿𝑚 代表在模型训练期间实时存储和更新的损失记忆。其公式如下所示：<br> <img src="https://images2.imgbox.com/11/50/BRTFceZ0_o.png" alt="在这里插入图片描述"><br> 其中 DEQUE 是序列函数，𝑡 是当前迭代。考虑到模型的敏感性和数据质量的不均匀性，我们利用 𝑀𝑒𝑎𝑠𝑢𝑟𝑒𝑟 获取损失的趋势 Δ𝑙，以替代单一损失。其公式如下：<br> <img src="https://images2.imgbox.com/a6/32/sdOdNVkC_o.png" alt="在这里插入图片描述"><br> 其中，𝛼 和 𝛽 表示加权平均权重，它们是等差数列的递减系列（即 𝑛∑𝑖=1 𝛼𝑖 = 𝑁∑𝑗=𝑛+1 𝛽 𝑗 = 𝛼𝑖 −𝛼𝑖−1 𝛼𝑖+1−𝛼𝑖 = 𝛽 𝑗 −𝛽 𝑗−1 𝛽 𝑗+1−𝛽 𝑗 = 1）。在 𝑆𝑒𝑛𝑠𝑜𝑟 中，权重 Δ𝑤 的变量计算如下：<br> <img src="https://images2.imgbox.com/fe/74/kWApoV6V_o.png" alt="在这里插入图片描述"><br> 其中，𝜋 𝑝𝑚𝑎 和 𝜋𝑛𝑚𝑎 分别表示正动量和负动量的幅度（即增量变化的幅度）。在 𝐴𝑑𝑗𝑢𝑠𝑡𝑒𝑟 中，我们使用方程.8 通过递增方式 [9, 18, 21] 更新自适应权重，用于内存存储和增强鲁棒性。<br> <img src="https://images2.imgbox.com/28/0e/ZGzF72OY_o.png" alt="在这里插入图片描述"><br> 其中，𝑛𝑜𝑟𝑚(·) 是归一化操作。训练过程中的权重更新策略如算法1所示。</p> 
<h4><a id="34_62"></a>3.4.训练和推理</h4> 
<p>我们的CAT使用以下联合损失公式进行端到端训练：<br> <img src="https://images2.imgbox.com/df/5e/WFdtY19U_o.png" alt="在这里插入图片描述"><br> 其中，𝐿𝑙𝑜𝑐𝑎𝑙𝑖𝑧𝑎𝑡𝑖𝑜𝑛、𝐿𝑖𝑑𝑒𝑛𝑡𝑖𝑓𝑖𝑐𝑎𝑡𝑖𝑜𝑛 和 𝐿𝑜𝑏 𝑗𝑒𝑐𝑡 𝑛𝑒𝑠𝑠 分别表示前景定位、新颖性识别和对象评分的损失项。当每个 episode 引入一组新的类别时，我们使用基于样本回放的微调来缓解对已学习类别的灾难性遗忘，然后使用为每个已知类别存储的平衡样本集对模型进行微调。在评估过程中，同时使用已知对象和 𝑡𝑜 𝑝-k 未知对象的边界框和类别预测。</p> 
<h3><a id="4_67"></a>4，实验</h3> 
<h4><a id="41__68"></a>4.1 数据集和评估指标</h4> 
<p>实验是在MS-COCO [27]和Pascal VOC [14]数据集的两个主流拆分上实施的。我们将类别分组成一组不重叠的任务𝑇1, … ,𝑇𝑡 , …。在任务𝑇𝑐中，类别仅出现在𝑡 ≥ 𝑐的任务中。在任务𝑇𝑐中，视为已知类别和未知类别的是在{𝑇𝑐 : 𝑐 ≤ 𝑡}和{𝑇𝑐 : 𝑐&gt; 𝑡}中遇到的类别，分别是已知和未知的类别。</p> 
<p>OWOD SPLIT [21] 将MS-COCO的80个类别分为4个任务，并从MS-COCO和Pascal VOC的训练集图像中为每个任务选择训练集。Pascal VOC的测试集和MS-COCO的验证集用于评估。</p> 
<p>MS-COCO SPLIT [17] 缓解了[21]中任务之间的数据泄漏，并更具挑战性。训练和测试数据来自MS-COCO。</p> 
<p>评估指标：遵循目标检测中最常用的评估指标，我们使用平均精度（mAP）来评估已知对象。受[2, 13, 17, 21, 30]启发，U-Recall 被用作评估未知对象的主要指标。U-Recall 衡量了模型检索未知对象实例的能力，用于评估 OWOD 问题。</p> 
<h4><a id="42__77"></a>4.2 实现细节</h4> 
<p>多尺度特征提取器包括在ImageNet上以自监督方式预训练的ResNet-50 [20]，以及一个层数设置为6的可变形(transformer)编码器。对于共享解码器，我们使用了一个层数也设置为6的可变形(transformer)解码器。我们设置查询数量 𝑀 = 100，嵌入的维度 𝐷 = 256，伪标签的数量 𝑘 = 5。在推断阶段，对于每个图像，使用前50个高分的检测结果进行评估。</p> 
<h4><a id="43_80"></a>4.3.与最先进方法的比较</h4> 
<p>为了公正比较，我们将CAT与不依赖于弱未知对象监督的基于能量的未知标识器（EBUI）的ORE [21]和其他SOTA方法 [17, 43–45] 进行比较，以展示我们的方法在OWOD问题上的有效性。我们从已知类mAP和未知类召回的角度进行比较，其中由于缺少未知测试注释，Task 4中无法计算U-Recall，原因是所有80个类都是已知的。</p> 
<p><strong>OWODSPLIT</strong>：与OWOD问题的最新方法相比，我们在OWOD split上的结果如表1所示。由于级联解码方式和自适应伪标签机制的影响，CAT检测未知对象的能力显著超越了现有模型。与2B-OCD [43] 在任务1、2和3上的U-Recall分别为12.1、9.4和11.6相比，我们的CAT在相应任务中分别达到了23.7、19.1和24.4，实现了显著的绝对增益，最高可达12.8%。在检测已知对象和缓解以前知识的灾难性遗忘方面，CAT表现出更好的性能，实现了显著的绝对增益，最高可达4.7%，超过了OW-DETR [17]。这证明了级联解码方式的显著性能。</p> 
<p><strong>MS-COCO SPLIT</strong>：我们在表2中报告了MS-COCO split上的结果。MS-COCO split减轻了任务之间的数据泄漏，并为每个任务分配了更多的数据，而CAT相较于OWOD split获得了更显著的提升。与OW-DETR在任务1、2和3上的U-Recall分别为5.7、6.2和6.9相比，我们的CAT在相应任务中分别达到了24.0、23.0和24.6，实现了显著的绝对增益，最高可达18.3%。此外，在检测已知对象方面的性能实现了显著的绝对增益，最高可达9.7%。这表明我们的CAT在面对更困难的任务时具有更强大的检索新知识和检测已知对象的能力。</p> 
<p><strong>定性结果</strong>：我们在图3中报告了定性结果。我们展示了CAT（顶行）和OW-DETR（底行）的检测结果，其中蓝色代表已知对象，黄色代表未知对象。很容易看出CAT能够检测更多的未知对象。在左列中，OW-DETR将背景和已知对象（狗）识别为未知对象，将真正的未知对象（纸箱）识别为背景，而我们的模型准确地将纸箱识别为未知对象。如中列所示，OW-DETR将两个日历分别识别为椅子和背景，并将键盘识别为背景，而我们的CAT准确地将它们识别为未知对象。右列显示，OW-DETR不仅未检测到未知对象（相框），还将两个已知对象（沙发）识别为一个，而我们的模型准确地将相框识别为未知对象，并准确地识别了两个沙发。</p> 
<p><img src="https://images2.imgbox.com/4f/8c/7EYssGY9_o.png" alt="在这里插入图片描述"><br> 图3. CAT和OW-DETR定性结果的比较。显示了CAT（顶行）和OW-DETR（底行）的检测结果，蓝色代表已知对象，黄色代表未知对象。CAT检测到的未知对象比OW-DETR更多。在左列中，OW-DETR将背景和已知对象识别为未知对象，将真正的未知对象（纸箱）识别为背景，而我们的模型准确地将纸箱识别为未知对象。如中列所示，OW-DETR将两个日历分别识别为椅子和背景，并将键盘识别为背景，而我们的CAT准确地将它们识别为未知对象。右列显示，OW-DETR不仅未检测到未知对象（相框），还将两个已知对象（沙发）识别为一个。我们的模型准确地将相框识别为未知对象，并且还准确地识别了这两个沙发。</p> 
<p><img src="https://images2.imgbox.com/ad/c9/270ndnW1_o.png" alt="在这里插入图片描述"><br> 表1. 在OWOD split上的最新研究比较。比较显示了U-Recall和已知类别mAP。U-Recall度量了模型检测OWOD问题中未知对象实例的能力。为了公平比较，我们与最近介绍的方法以及没有使用EBUI的ORE进行比较。CAT在所有任务上都取得了改进的所有指标，跨足了所有现有研究，证明了我们模型在OWOD问题上的有效性。由于所有80个类别都是已知的，无法在任务4中计算U-Recall。</p> 
<h4><a id="44__95"></a>4.4 消融实验</h4> 
<p>我们进行了丰富的割除实验，以验证CAT在OWOD split上各组件的有效性。此外，我们展示了我们的模型在增量目标检测和开放集检测方面的有效性。</p> 
<p><strong>割除组件</strong>：为了研究每个组件的贡献，我们在表3中设计了割除实验。与最终的CAT相比，去除级联解耦解码方式（CAT-Cddw）降低了检索未知对象和检测已知对象的性能，在任务1、2、3的U-Recall方面分别降低了4.6、0.5和3.4点，已知对象的mAP在任务1、2、3、4中分别降低了0.7、2.6、1.8和2.0。结果表明级联解耦解码方式更适合包含未知对象的开放世界目标检测，提高了CAT检索未知对象和检测已知对象的能力。为了割除自适应方式组件，我们从CAT中去除自适应方式，并保持来自选择性搜索的先验。与CAT相比，去除自适应方式（CAT-Sam）显著降低了检测未知对象的性能，在任务1、2、3中分别降低了4.6、2.2和5.8点。结果表明自适应方式能够有效地结合输入和模型驱动的伪标签机制，提高了CAT探索未知对象的能力。因此，每个组件在开放世界目标检测中都发挥着关键作用。</p> 
<p><strong>增量目标检测</strong>：为了直观地展示CAT检测目标实例的能力，我们将其与[17,21,35,40]进行了增量目标检测（IOD）任务的比较。我们在三个标准设置上评估实验，其中一组类别（10个，5个和最后一个类别）逐步引入到在剩余类别（10个，15个和19个）上训练的检测器中，基于PASCAL VOC 2007数据集。如表4所示，CAT在所有三个设置上都超过了现有方法，表明了级联解码检测变压器在IOD中的本领。</p> 
<p><strong>开放集检测比较</strong>：为了进一步展示CAT处理开放集数据中未知实例的能力，我们遵循与[17, 21, 31]相同的评估协议，并在表5中报告性能。CAT在与现有方法相比取得了令人满意的性能。<br> <img src="https://images2.imgbox.com/dc/9a/jiNnKYR3_o.png" alt="在这里插入图片描述"><br> 表2. 在MS-COCO split上的最新比较。比较以U-Recall和mAP为指标。尽管MS-COCO split更具挑战性，但与ORE和OW-DETR相比，我们的模型在这方面取得了更显著的改进。显著的指标改进表明我们的CAT具有检索超出封闭集范围的新知识的能力，并且不会受到现有对象的类别知识的限制。<br> <img src="https://images2.imgbox.com/45/51/AtUqIq6f_o.png" alt="在这里插入图片描述"><br> 表3. 组件剔除实验。比较以已知类别平均精度（mAP）和未知类别召回率（U-Recall）为指标。CAT-Cddw是我们的模型，没有级联解耦的解码方式。CAT-Sam是我们的模型，没有自适应机制，但使用了来自选择性搜索的先验信息。我们还包括可变形DETR的性能以及一个上限（使用地面真实未知类别注释训练的D-DETR），如OW-DETR [17]所报告。</p> 
<p><img src="https://images2.imgbox.com/43/1f/rkqDxeZ5_o.png" alt="在这里插入图片描述"><br> 表4. 渐进式目标检测任务的性能比较。在三种标准设置上进行评估，其中一组类别（10个、5个和最后一个类别）逐步引入到一个在剩余类别上训练的检测器中（10个、15个和19个）。我们的CAT在所有三个设置上都表现出色，展示了级联解码检测变压器在增量目标检测中的强大能力。</p> 
<p><img src="https://images2.imgbox.com/e9/ee/rk1KRhg4_o.png" alt="在这里插入图片描述"><br> 表5. 对开放集目标检测任务的性能比较。我们的CAT在与现有方法的比较中取得了显著的性能。</p> 
<h3><a id="5_114"></a>5.与先前工作的关系</h3> 
<p>在过去几年中，标准目标检测问题[4, 10, 16, 19, 26, 28, 34, 37, 38, 46, 48]已经引起了广泛关注，许多研究都探讨了这个问题，推动了该领域的发展。然而，这些方法强烈的假设，即模型在其生命周期内遇到的对象类别的标签空间与训练期间相同，导致这些方法无法满足真实世界的需求。[7, 15, 22–24, 33, 38]的成功证明了基于对象位置和外观的前景定位的可行性。现有的研究[8, 17, 21, 29, 43–45]试图利用标准目标检测模型的框架来进行开放世界目标检测。在本文中，我们提出了一种基于新型变压器[42]的框架。CAT将前景定位和识别过程解耦，并以级联方式连接它们。<strong>在CAT中，前景定位过程不受已知对象类别的限制，而前景识别过程可以利用来自定位过程的信息。通过自适应伪标签，CAT可以获取超出数据注释的信息，并根据自我调节维持稳定的学习过程。</strong></p> 
<h3><a id="6__117"></a>6 总结</h3> 
<p>我们分析了并行解码结构在开放世界目标检测中的缺点。受人类在面对新场景时的潜意识反应的启发，我们提出了一种新颖的本地化和识别级联检测变压器（CAT），通过级联解码方式解耦了本地化和识别过程。<strong>级联解码方式减轻了检测未知对象对已知对象检测的影响。通过自适应伪标签机制，CAT获得超出数据注释的知识，生成具有鲁棒性的伪标签，并通过自我调整维持稳定的训练过程</strong>。在两个流行基准数据集，即PASCAL VOC和MS COCO上进行的大量实验证明，CAT的性能优于现有方法。</p> 
<h3><a id="_120"></a>致谢</h3> 
<p>本工作得到中国国家自然科学基金（批准号：61871106）的支持，以及中国科学院光电信息处理重点实验室（OEIP-O-202002）开放项目基金的支持。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/180fdf484fe6cfc092c217ff4b49ce06/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">TAFFC | 清华大学刘永进教授课题组提出基于情绪字典与注意力机制的多模态情绪分布学习方法...</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a9c5b819ed90516ef257a48b7c0c7e71/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;入门编程四(指针、结构体、const修饰指针(深度理解))</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>