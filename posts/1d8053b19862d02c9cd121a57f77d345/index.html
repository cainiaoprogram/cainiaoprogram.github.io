<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation未完成 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation未完成" />
<meta property="og:description" content="ABSTRACT 顺序推荐由于其实用性和通过捕获顺序信息的高精度而一直是研究的热点。由于广泛采用基于深度学习（DL）的方法来对用户行为序列下的本地和动态偏好进行建模，因此用户的全局和静态偏好的建模往往被低估了，通常只有一些简单而粗略的用户潜在表示是介绍。此外，大多数现有方法都假设通过考虑历史行为可以完全捕获用户的意图，而忽略了现实中用户意图的可能不确定性，这可能会受到要推荐候选项目的出现的影响。因此，在本文中，我们着眼于这两个问题，即大多数基于DL的顺序推荐方法中用户全局偏好的不完善建模以及候选项目带来的用户意图的不确定性，并提出了一种新的解决方案，即融合项目相似性具有自我注意网络（FISSA）的模型以进行顺序推荐。具体来说，我们将最先进的自我关注顺序推荐（SASRec）模型作为本地表示学习模块，以捕获FISSA中用户行为序列下的动态偏好，并进一步提出一个全局表示学习模块，以改进了用户全局偏好的建模，以及通过考虑候选项目的信息来平衡本地和全局表示的选通模块。全局表示学习模块可以看作是基于位置的关注层，可以有效地与自我注意框架的并行化训练过程很好地吻合。选通模块通过使用MLP层对候选项目，最近交互的项目以及每个用户的全局首选项之间的关系进行建模来计算权重。对五个常用数据集的大量实证研究表明，就两个常用指标而言，我们的FISSA明显优于八个最新基准。
1 INTRODUCTION 推荐系统是缓解信息过载问题的智能工具，尤其是在用户意图不确定时。传统推荐系统仅处理一般推荐，其中用户-项目交互记录可以放置在二维评级矩阵中，以便通过填充该矩阵的空缺来实现预测。与一般推荐不同，顺序推荐将用户的历史记录视为项目序列而不是项目集，以便准确预测他们将与之互动的下一个项目。
顺序推荐现在得到了广泛的研究，因为它与实际情况更加一致，并且在考虑更多信息的情况下有望获得更准确的结果。既然已经在一般推荐中很好地研究了用户的全局和静态偏好，那么开发顺序推荐方法的一种直观方法就是对局部和动态偏好进行建模，并将其与全局偏好相结合。这正是最先进的因式分解个性化马尔可夫链（FPMC）[32]所做的。
具体而言，FPMC由两部分组成，即，将一类反馈矩阵分解的传统矩阵分解（MF）模型，以及对通过个性化马尔可夫链生成的过渡矩阵进行分解的新型MF模型。称为Fossil [8]的改进模型用因子项目相似性模型（FISM）替换了FPMC的前一个组件，通过包括多个转换矩阵将后者的组件扩展到更高阶版本，并且还引入了一些个性化的加权因子平衡这些全球和本地偏好。
最近，越来越多的基于深度学习（DL）的方法被用来对动态兴趣进行建模。应用递归神经网络（RNN）进行顺序推荐的最早作品之一是GRU4Rec [13]，它在每个步骤中逐步学习用户的偏好。Caser [38]利用卷积神经网络（CNN）通过滑动滤波器学习复杂的短期兴趣（即点级，联合级和跳跃级）。 在许多其他作品中，注意力机制已经成为一个重要的组成部分，可以发现用户的意图不受固定顺序的束缚。 SASRec [16]堆叠了多个自我注意模块，以有效地捕获序列中的长期和短期转变。 但是，这些基于DL的方法大多数都没有对静态表示学习给予足够的重视，例如，在静态和动态表示的结合中，例如在Caser中，简单地采用了可学习用户的潜在表示和并置操作， 这仍然使它们仍然面临着设计良好的全局表示和平衡组合方法（例如Fossil）的模型的挑战。
此外，几乎所有现有的顺序推荐方法均基于理想主义的假设，即可以通过使用用户的历史行为（即用户偏好的最终表示形式与新项目（或候选项目）之间的交互作用）完全捕获用户的意图。 （建议））通常在算法的最后一步执行，在此之前，候选项目的信息永远不会用于偏好学习。 实际上，用户的意图可能不确定，尤其是当他们参与长期的习惯行为（例如购买）序列而不是短暂的活动（例如听音乐）会话时。 判断一项新产品是否可以吸引用户的一种正确方法是考虑它如何引起用户兴趣的不同部分（即短期和长期）。
基于以上分析，本文提出了一种新颖的解决方案，称为融合项目相似性模型和自注意网络（或简称为FISSA），用于顺序推荐。我们的FISSA不仅将有效的全局表示学习与行之有效的方法（即自注意顺序推荐（SASRec）[16]）结合起来，而且还可以平衡用户对每个候选商品的短期和长期兴趣。具体而言，我们的模型包含三个主要组件，即本地表示学习模块，全局表示学习模块和用于平衡这两种表示的选通模块。对于局部表示学习，我们遵循SASRec，因为它具有出色的性能，并且增强动态兴趣建模不是本文的重点。对于全局表示学习，我们应用基于位置的关注层来实现FISM的专注版本[15]，其中引入了所有序列共享的查询向量，从而区分了生成全局变量的不同项目的重要性。序列的表示。受神经注意项目相似性（NAIS）[9]的启发，该相似性通过考虑项目与候选项目的关系来权衡项目，我们设计了基于多层感知器（MLP）的门控网络，该网络通过考虑以下因素来决定局部和全局表示的贡献率候选项目，最近交互的项目与目标用户的整体偏好之间的关系
We summarize our main contributions as follows:
针对目前大多数基于DL的序贯推荐方法对用户的全局偏好建模不完善和用户意图受候选项目影响的不确定性这两个问题，我们提出了一种新的解决方案FISSA。我们在FISSA中设计了一个全局表征学习模块来有效地捕捉用户的全局偏好，它可以看作是一个基于位置的关注层，与自我注意框架的并行化训练过程很好地契合。我们在FISSA中设计了一个基于MLP的门控模块，该模块通过考虑候选项的信息来平衡局部和全局表示，从而同时处理用户意图的不确定性。我们在五个常用的数据集上进行了广泛的实证研究，结果表明，我们的FISSA显著超过了八个最先进的基线。特别是，我们的FISSA在Rec@10和NDCG@10方面分别平均超过SASRec 10.11%和10.05%。我们还进行了烧蚀研究，并讨论了全局模块和选通模块等细节的一些选项。 2 REALTED WORK 在这一部分中，我们分别回顾了通用推荐和顺序推荐的最新方法，并指出了我们的FISSA与这些作品之间的联系和区别，以及我们的FISSA如何显著地推动了与所研究问题密切相关的作品的发展。
2.1 General Recommendation 协同过滤(CF)方法通常将用户的行为历史视为一组用户-项目交互对。CF方法主要有三个分支，即基于邻域的方法[1，34]、基于矩阵分解(MF)的方法[28，31]和混合方法[15，17]。基于MF的方法以其高效、准确的特点得到了广泛的应用。在基于MF的方法[28，31]的早期工作中，通过对评分矩阵进行奇异值分解(SVD)直接学习特定用户和特定项目的潜在表示向量，并通过两个对应向量的内积获得预测的评分。稍后，有建议15，17通过汇总他/她的交互项目的表示来获得用户的表示。通过这种方式，预测的评分可以看作是用户的历史项目和候选项目之间的因数相似度，这使得基于MF的模型与基于邻域的模型具有良好的可解释性。此外，复合用户表示在处理有限数量的用户记录时提供了更多信息。最近，基于深度学习(DL)的方法[2，10，21，42]被用来改进上述方法。例如，神经协同过滤(NCF)[10]使用多层感知器(MLP)来学习特定于用户和特定于项目的潜在表示向量，并且可以很容易地与传统的MF模型相结合。在另一种称为注意力协同过滤(ACF)[2]的模型中，注意力机制被应用于权衡不同的历史项目，并建立更全面的模型。神经注意项相似度(NAIS)[9]也应用了注意机制，但侧重于为候选项区分更重要的项，而不是为用户区分更重要的项。也有其他基于DL的方法使用自动编码器(AE)[21，22，42]或受限Boltzmann机器(RBM)[33]作为一般推荐。在本文中，我们实现了FISM[15]的一种关注形式，以获得用户行为序列的全局表示，并通过对候选项、最近交互的项和用户的全局偏好之间的关系建模，设计了一种平衡局部和全局表示的项相似度门控。
2.2 Sequential Recommendation 最早的顺序推荐工作使用马尔可夫链(MC)来建模项目之间的一阶转变[49]，或者使用马尔可夫决策过程(MDP)[35]来处理长期影响。后来，因式分解的个性化MC[32]被提出并扩展到高阶版本[8]，这些MC受到一般基于MF的方法[15，31]的启发并与之相结合。为了保持稀疏过渡数据的三角不等式，提出了度量嵌入[5]和基于平移的方法[7，19]。而目前大多数研究者都是随大流采用基于DL的方法来捕捉非线性和动态特征进行序贯推荐。基于RNN的模型[4，12，13，20，30，37，47]几乎是第一个被采用的，因为它们天生就是逐步建模序列的。为了避免RNN带来的消失梯度问题，还采用了其他基于DL的方法，使用CNN[38，48]，并增加了多个灵活的滤波器大小等特性来提炼短期特征。在RNN和CNNS的基础上，一些新兴的网络模型的应用开始流行。例如，记忆网络[3，14]、图神经网络(GNN)[26，29，41，43]配合注意机制被用来提取更具一致性或邻接性的短期特征。注意，注意机制本身也被证明是有效的，具有适当的层次结构[16，23，46]。在本文中，我们的局部表示学习模型基于自关注序列推荐(SASRec)模型[16]，它被发现是一种优秀的序列推荐模型，具有令人满意的简洁性和效率。值得注意的是，与其他通过引入图神经网络[43]或双向结构[36]来改进SASRec的工作不同，这些工作仍然侧重于局部和动态偏好建模，本文提出的FISSA旨在以平衡的方式将SASRec与有效的全局和静态偏好学习模型相结合。SASRec的另一项改进工作(即一致性感知推荐(CAR)[11])类似于我们的FISSA，将在第4节进一步讨论。
为了处理序列中用户意图的不确定性，现有的工作主要集中在区分序列中项目的重要性。例如，在最近的工作中，一个名为基于流会话推荐(SSR)[6]的模型关注流会话数据，并将基于MF的注意力引入基于RNN的会话编码器中，使得用户在当前会话中的意图与来自历史会话的长期偏好相关。与这项工作不同的是，我们关注的是一些长期存在的习惯行为(例如，查看、签到、购买等)，因此只考虑每个用户的一个序列。此外，除了通过自我关注模型学习序列中每个项目的重要性外，我们还分别对用户的短期偏好和长期偏好进行建模，然后根据不同的候选项目对它们进行平衡，这意味着我们的FISSA捕捉到了候选项目外观影响的变化意图，并且更加全面。
3 PROPOSED METHOD 我们在图1中说明了我们的FISSA，它包含三个主要组件，包括局部表示学习模块、全局表示学习模块和用于平衡这两种表示的门控模块。在本文中，我们用粗体的大写字母表示矩阵，用它们的小写形式表示相应的行向量。
3.1 Local Representation Learning 首先，我们通过提取每个用户最近的L行为来修正他/她的输入序列，缩写为
(通常选择相对较大的L值，例如，对于我们研究的数据集，选择L=50来保留大多数用户的整个序列，并且在需要时在序列的开头附加填充项)。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/1d8053b19862d02c9cd121a57f77d345/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-17T15:34:37+08:00" />
<meta property="article:modified_time" content="2021-05-17T15:34:37+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FISSA: Fusing Item Similarity Models with Self-Attention Networks for Sequential Recommendation未完成</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="ABSTRACT_0"></a>ABSTRACT</h3> 
<p>顺序推荐由于其实用性和通过捕获顺序信息的高精度而一直是研究的热点。由于广泛采用基于深度学习（DL）的方法来对用户行为序列下的本地和动态偏好进行建模，因此用户的全局和静态偏好的建模往往被低估了，通常只有一些简单而粗略的用户潜在表示是介绍。此外，大多数现有方法都假设通过考虑历史行为可以完全捕获用户的意图，而忽略了现实中用户意图的可能不确定性，这可能会受到要推荐候选项目的出现的影响。因此，在本文中，我们着眼于这两个问题，<strong>即大多数基于DL的顺序推荐方法中用户全局偏好的不完善建模以及候选项目带来的用户意图的不确定性</strong>，并提出了一种新的解决方案，即融合项目相似性具有自我注意网络（FISSA）的模型以进行顺序推荐。具体来说，我们将最先进的自我关注顺序推荐（SASRec）模型作为本地表示学习模块，以捕获FISSA中用户行为序列下的动态偏好，并进一步提出一个全局表示学习模块，以改进了用户全局偏好的建模，以及通过考虑候选项目的信息来平衡本地和全局表示的选通模块。全局表示学习模块可以看作是基于位置的关注层，可以有效地与自我注意框架的并行化训练过程很好地吻合。选通模块通过使用MLP层对候选项目，最近交互的项目以及每个用户的全局首选项之间的关系进行建模来计算权重。对五个常用数据集的大量实证研究表明，就两个常用指标而言，我们的FISSA明显优于八个最新基准。</p> 
<h3><a id="1_INTRODUCTION_4"></a>1 INTRODUCTION</h3> 
<p>推荐系统是缓解信息过载问题的智能工具，尤其是在用户意图不确定时。传统推荐系统仅处理一般推荐，其中用户-项目交互记录可以放置在二维评级矩阵中，以便通过填充该矩阵的空缺来实现预测。与一般推荐不同，顺序推荐将用户的历史记录视为项目序列而不是项目集，以便准确预测他们将与之互动的下一个项目。</p> 
<p>顺序推荐现在得到了广泛的研究，因为它与实际情况更加一致，并且在考虑更多信息的情况下有望获得更准确的结果。既然已经在一般推荐中很好地研究了用户的全局和静态偏好，那么开发顺序推荐方法的一种直观方法就是对局部和动态偏好进行建模，并将其与全局偏好相结合。这正是最先进的因式分解个性化马尔可夫链（FPMC）[32]所做的。</p> 
<p>具体而言，FPMC由两部分组成，即，将一类反馈矩阵分解的传统矩阵分解（MF）模型，以及对通过个性化马尔可夫链生成的过渡矩阵进行分解的新型MF模型。称为Fossil [8]的改进模型用因子项目相似性模型（FISM）替换了FPMC的前一个组件，通过包括多个转换矩阵将后者的组件扩展到更高阶版本，并且还引入了一些个性化的加权因子平衡这些全球和本地偏好。</p> 
<p>最近，越来越多的基于深度学习（DL）的方法被用来对动态兴趣进行建模。应用递归神经网络（RNN）进行顺序推荐的最早作品之一是GRU4Rec [13]，它在每个步骤中逐步学习用户的偏好。Caser [38]利用卷积神经网络（CNN）通过滑动滤波器学习复杂的短期兴趣（即点级，联合级和跳跃级）。 在许多其他作品中，注意力机制已经成为一个重要的组成部分，可以发现用户的意图不受固定顺序的束缚。 SASRec [16]堆叠了多个自我注意模块，以有效地捕获序列中的长期和短期转变。 但是，这些基于DL的方法大多数都没有对静态表示学习给予足够的重视，例如，在静态和动态表示的结合中，例如在Caser中，简单地采用了可学习用户的潜在表示和并置操作， 这仍然使它们仍然面临着设计良好的全局表示和平衡组合方法（例如Fossil）的模型的挑战。</p> 
<p>此外，几乎所有现有的顺序推荐方法均基于理想主义的假设，即可以通过使用用户的历史行为（即用户偏好的最终表示形式与新项目（或候选项目）之间的交互作用）完全捕获用户的意图。 （建议））通常在算法的最后一步执行，在此之前，候选项目的信息永远不会用于偏好学习。 实际上，用户的意图可能不确定，尤其是当他们参与长期的习惯行为（例如购买）序列而不是短暂的活动（例如听音乐）会话时。 判断一项新产品是否可以吸引用户的一种正确方法是考虑它如何引起用户兴趣的不同部分（即短期和长期）。</p> 
<p>基于以上分析，本文提出了一种新颖的解决方案，称为融合项目相似性模型和自注意网络（或简称为FISSA），用于顺序推荐。我们的FISSA不仅将有效的全局表示学习与行之有效的方法（即自注意顺序推荐（SASRec）[16]）结合起来，而且还可以平衡用户对每个候选商品的短期和长期兴趣。具体而言，我们的模型包含三个主要组件，即本地表示学习模块，全局表示学习模块和用于平衡这两种表示的选通模块。对于局部表示学习，我们遵循SASRec，因为它具有出色的性能，并且增强动态兴趣建模不是本文的重点。对于全局表示学习，我们应用基于位置的关注层来实现FISM的专注版本[15]，其中引入了所有序列共享的查询向量，从而区分了生成全局变量的不同项目的重要性。序列的表示。受神经注意项目相似性（NAIS）[9]的启发，该相似性通过考虑项目与候选项目的关系来权衡项目，我们设计了基于多层感知器（MLP）的门控网络，该网络通过考虑以下因素来决定局部和全局表示的贡献率候选项目，最近交互的项目与目标用户的整体偏好之间的关系</p> 
<p>We summarize our main contributions as follows:</p> 
<ul><li>针对目前大多数基于DL的序贯推荐方法对用户的全局偏好建模不完善和用户意图受候选项目影响的不确定性这两个问题，我们提出了一种新的解决方案FISSA。</li><li>我们在FISSA中设计了一个全局表征学习模块来有效地捕捉用户的全局偏好，它可以看作是一个基于位置的关注层，与自我注意框架的并行化训练过程很好地契合。</li><li>我们在FISSA中设计了一个基于MLP的门控模块，该模块通过考虑候选项的信息来平衡局部和全局表示，从而同时处理用户意图的不确定性。</li><li>我们在五个常用的数据集上进行了广泛的实证研究，结果表明，我们的FISSA显著超过了八个最先进的基线。特别是，我们的FISSA在Rec@10和NDCG@10方面分别平均超过SASRec 10.11%和10.05%。我们还进行了烧蚀研究，并讨论了全局模块和选通模块等细节的一些选项。</li></ul> 
<h3><a id="2_REALTED_WORK_24"></a>2 REALTED WORK</h3> 
<p>在这一部分中，我们分别回顾了通用推荐和顺序推荐的最新方法，并指出了我们的FISSA与这些作品之间的联系和区别，以及我们的FISSA如何显著地推动了与所研究问题密切相关的作品的发展。</p> 
<h4><a id="21_General_Recommendation_27"></a>2.1 General Recommendation</h4> 
<p>协同过滤(CF)方法通常将用户的行为历史视为一组用户-项目交互对。CF方法主要有三个分支，即基于邻域的方法[1，34]、基于矩阵分解(MF)的方法[28，31]和混合方法[15，17]。基于MF的方法以其高效、准确的特点得到了广泛的应用。在基于MF的方法[28，31]的早期工作中，通过对评分矩阵进行奇异值分解(SVD)直接学习特定用户和特定项目的潜在表示向量，并通过两个对应向量的内积获得预测的评分。稍后，有建议<a href="%E4%BE%8B%E5%A6%82%EF%BC%8CFISM%5B15%5D" rel="nofollow">15，17</a>通过汇总他/她的交互项目的表示来获得用户的表示。通过这种方式，预测的评分可以看作是用户的历史项目和候选项目之间的因数相似度，这使得基于MF的模型与基于邻域的模型具有良好的可解释性。此外，复合用户表示在处理有限数量的用户记录时提供了更多信息。最近，基于深度学习(DL)的方法[2，10，21，42]被用来改进上述方法。例如，神经协同过滤(NCF)[10]使用多层感知器(MLP)来学习特定于用户和特定于项目的潜在表示向量，并且可以很容易地与传统的MF模型相结合。在另一种称为注意力协同过滤(ACF)[2]的模型中，注意力机制被应用于权衡不同的历史项目，并建立更全面的模型。神经注意项相似度(NAIS)[9]也应用了注意机制，但侧重于为候选项区分更重要的项，而不是为用户区分更重要的项。也有其他基于DL的方法使用自动编码器(AE)[21，22，42]或受限Boltzmann机器(RBM)[33]作为一般推荐。在本文中，我们实现了FISM[15]的一种关注形式，以获得用户行为序列的全局表示，并通过对候选项、最近交互的项和用户的全局偏好之间的关系建模，设计了一种平衡局部和全局表示的项相似度门控。</p> 
<h4><a id="22_Sequential_Recommendation_30"></a>2.2 Sequential Recommendation</h4> 
<p>最早的顺序推荐工作使用马尔可夫链(MC)来建模项目之间的一阶转变[49]，或者使用马尔可夫决策过程(MDP)[35]来处理长期影响。后来，因式分解的个性化MC[32]被提出并扩展到高阶版本[8]，这些MC受到一般基于MF的方法[15，31]的启发并与之相结合。为了保持稀疏过渡数据的三角不等式，提出了度量嵌入[5]和基于平移的方法[7，19]。而目前大多数研究者都是随大流采用基于DL的方法来捕捉非线性和动态特征进行序贯推荐。基于RNN的模型[4，12，13，20，30，37，47]几乎是第一个被采用的，因为它们天生就是逐步建模序列的。为了避免RNN带来的消失梯度问题，还采用了其他基于DL的方法，使用CNN[38，48]，并增加了多个灵活的滤波器大小等特性来提炼短期特征。在RNN和CNNS的基础上，一些新兴的网络模型的应用开始流行。例如，记忆网络[3，14]、图神经网络(GNN)[26，29，41，43]配合注意机制被用来提取更具一致性或邻接性的短期特征。注意，注意机制本身也被证明是有效的，具有适当的层次结构[16，23，46]。在本文中，我们的局部表示学习模型基于自关注序列推荐(SASRec)模型[16]，它被发现是一种优秀的序列推荐模型，具有令人满意的简洁性和效率。值得注意的是，与其他通过引入图神经网络[43]或双向结构[36]来改进SASRec的工作不同，这些工作仍然侧重于局部和动态偏好建模，本文提出的FISSA旨在以平衡的方式将SASRec与有效的全局和静态偏好学习模型相结合。SASRec的另一项改进工作(即一致性感知推荐(CAR)[11])类似于我们的FISSA，将在第4节进一步讨论。</p> 
<p>为了处理序列中用户意图的不确定性，现有的工作主要集中在区分序列中项目的重要性。例如，在最近的工作中，一个名为基于流会话推荐(SSR)[6]的模型关注流会话数据，并将基于MF的注意力引入基于RNN的会话编码器中，使得用户在当前会话中的意图与来自历史会话的长期偏好相关。与这项工作不同的是，我们关注的是一些长期存在的习惯行为(例如，查看、签到、购买等)，因此只考虑每个用户的一个序列。此外，除了通过自我关注模型学习序列中每个项目的重要性外，我们还分别对用户的短期偏好和长期偏好进行建模，然后根据不同的候选项目对它们进行平衡，这意味着我们的FISSA捕捉到了候选项目外观影响的变化意图，并且更加全面。</p> 
<h3><a id="3_PROPOSED_METHOD_36"></a>3 PROPOSED METHOD</h3> 
<p><img src="https://images2.imgbox.com/3c/fc/Rthm2iv2_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c7/7e/AKolRoa2_o.png" alt="在这里插入图片描述"><br> 我们在图1中说明了我们的FISSA，它包含三个主要组件，包括局部表示学习模块、全局表示学习模块和用于平衡这两种表示的门控模块。在本文中，我们用粗体的大写字母表示矩阵，用它们的小写形式表示相应的行向量。</p> 
<h4><a id="31_Local_Representation_Learning_41"></a>3.1 Local Representation Learning</h4> 
<p>首先，我们通过提取每个用户最近的L行为来修正他/她的输入序列，缩写为<img src="https://images2.imgbox.com/55/6b/HkUcgEIy_o.png" alt="su={s1，s2，.。那就是。那就是。，SL}"><br> (通常选择相对较大的L值，例如，对于我们研究的数据集，选择L=50来保留大多数用户的整个序列，并且在需要时在序列的开头附加填充项)。<br> <img src="https://images2.imgbox.com/74/88/VPotek3z_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/94da35b2e17c0c0e76a50ed0ecf0fb19/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">解决FTP服务器FileZilla server中文乱码问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a901148a56e5795b2531a45b588d32d0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">netstat命令下载、使用方法及其选项详情</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>