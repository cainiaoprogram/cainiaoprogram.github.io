<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>实验六、数据挖掘之关联分析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="实验六、数据挖掘之关联分析" />
<meta property="og:description" content="实验六、数据挖掘之关联分析 一、实验目的 1. 理解Apriori算法的基本原理 2. 理解FP增长算法的基本原理 3. 学会用python实现Apriori算法 4. 学会用python实现FP增长算法 二、实验工具 1. Anaconda 2. sklearn 3. Pandas 三、实验简介 Apriori算法在发现关联规则领域具有很大影响力。算法命名源于算法使用了频繁项集性质的先验（prior）知识。在具体实验时，Apriori算法将发现关联规则的过程分为两个步骤：第一步通过迭代，检索出事务数据库中的所有频繁项集，即支持度不低于用户设定的阈值的项集；第二步利用频繁项集构造出满足用户最小信任度的规则。其中，挖掘或识别出所有频繁项集是该算法的核心，占整个计算量的大部分。
在对深度优先数据挖掘算法的研究工作中，Han等人没有采用潜在频繁项集的方法求解频繁项集，而是提出了称为频率模式增长（FP_growth）的算法。该算法通过扫描数据库创建FP_tree的根节点并标示为null，对数据库D中的每一个事务Tran，按L中的次序对Tran中的频繁项排序，设Tran中排序后的频繁项列表[p|P]，这里p是第一个元素，P是保留列表。接着调用函数insert_tree（[p|P]，T），如果树T有一个子节点N且N.item_name=p.item_name，就将N节点计数加1；否则就创建一个新节点N，设计数为1，它的父节点连接到T，节点连接到同名的节点连接结构上。如果P是非空的，就递归调用insert_tree（P，N）。由于压缩了数据库内容，并且在将频繁项写入FP_tree结构时，保留了项集间的相连信息。求解频繁项集的问题，就转化为递归地找出最短频繁模式并连接其后缀构成长频繁模式的问题。
四、实验内容 1. 利用python语言编写Apriori算法，挖掘出下表中数据集的频繁项集，最小支持度为30%。 # -*- coding: utf-8 -*- &#34;&#34;&#34; Created on Fri May 20 20:25:24 2022 @author: zhenkai &#34;&#34;&#34; def load_data_set(): data_set = [ [&#39;a&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;], [&#39;b&#39;, &#39;c&#39;, &#39;d&#39;], [&#39;a&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;], [&#39;a&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;], [&#39;a&#39;,&#39;b&#39;,&#39;d&#39;,&#39;e&#39;], [&#39;b&#39;, &#39;d&#39;, &#39;e&#39;], [&#39;c&#39;, &#39;d&#39;], [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], [&#39;a&#39;, &#39;d&#39;, &#39;e&#39;], [&#39;b&#39;, &#39;d&#39;] ] return data_set &#39;&#39;&#39; 参数：数据库事务集 &#39;&#39;&#39; def Create_C1(data_set): C1 = set() for t in data_set: for item in t: item_set = frozenset([item]) # 为生成频繁项目集时扫描数据库时以提供issubset()功能 C1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4d207ecfdaea53c7771a3ef82e0e1914/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-20T22:07:29+08:00" />
<meta property="article:modified_time" content="2022-05-20T22:07:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">实验六、数据挖掘之关联分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-kimbie-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>实验六、数据挖掘之关联分析</h2> 
<h3><a id="_2"></a>一、实验目的</h3> 
<h4><a id="1_Apriori_4"></a>1. 理解Apriori算法的基本原理</h4> 
<h4><a id="2_FP_6"></a>2. 理解FP增长算法的基本原理</h4> 
<h4><a id="3_pythonApriori_8"></a>3. 学会用python实现Apriori算法</h4> 
<h4><a id="4_pythonFP_10"></a>4. 学会用python实现FP增长算法</h4> 
<h3><a id="_12"></a>二、实验工具</h3> 
<h4><a id="1_Anaconda_14"></a>1. Anaconda</h4> 
<h4><a id="2_sklearn_16"></a>2. sklearn</h4> 
<h4><a id="3_Pandas_18"></a>3. Pandas</h4> 
<h3><a id="_20"></a>三、实验简介</h3> 
<p>Apriori算法在发现关联规则领域具有很大影响力。算法命名源于算法使用了频繁项集性质的先验（prior）知识。在具体实验时，Apriori算法将发现关联规则的过程分为两个步骤：第一步通过迭代，检索出事务数据库中的所有频繁项集，即支持度不低于用户设定的阈值的项集；第二步利用频繁项集构造出满足用户最小信任度的规则。其中，挖掘或识别出所有频繁项集是该算法的核心，占整个计算量的大部分。</p> 
<p>在对深度优先数据挖掘算法的研究工作中，Han等人没有采用潜在频繁项集的方法求解频繁项集，而是提出了称为频率模式增长（FP_growth）的算法。该算法通过扫描数据库创建FP_tree的根节点并标示为null，对数据库D中的每一个事务Tran，按L中的次序对Tran中的频繁项排序，设Tran中排序后的频繁项列表[p|P]，这里p是第一个元素，P是保留列表。接着调用函数insert_tree（[p|P]，T），如果树T有一个子节点N且N.item_name=p.item_name，就将N节点计数加1；否则就创建一个新节点N，设计数为1，它的父节点连接到T，节点连接到同名的节点连接结构上。如果P是非空的，就递归调用insert_tree（P，N）。由于压缩了数据库内容，并且在将频繁项写入FP_tree结构时，保留了项集间的相连信息。求解频繁项集的问题，就转化为递归地找出最短频繁模式并连接其后缀构成长频繁模式的问题。</p> 
<h3><a id="_26"></a>四、实验内容</h3> 
<h4><a id="1_pythonApriori30_28"></a>1. 利用python语言编写Apriori算法，挖掘出下表中数据集的频繁项集，最小支持度为30%。</h4> 
<p><img src="https://images2.imgbox.com/2b/69/lffoO5nF_o.png" alt="image.png"></p> 
<pre><code class="prism language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token triple-quoted-string string">"""
Created on Fri May 20 20:25:24 2022

@author: zhenkai
"""</span>

<span class="token keyword">def</span> <span class="token function">load_data_set</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    data_set <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
        <span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
        <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span><span class="token string">'b'</span><span class="token punctuation">,</span><span class="token string">'d'</span><span class="token punctuation">,</span><span class="token string">'e'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
        <span class="token punctuation">[</span><span class="token string">'c'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
        <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'c'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
        <span class="token punctuation">[</span><span class="token string">'a'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">,</span> <span class="token string">'e'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> 
        <span class="token punctuation">[</span><span class="token string">'b'</span><span class="token punctuation">,</span> <span class="token string">'d'</span><span class="token punctuation">]</span>
    <span class="token punctuation">]</span> 
    <span class="token keyword">return</span> data_set
<span class="token triple-quoted-string string">''' 参数：数据库事务集 '''</span> 
<span class="token keyword">def</span> <span class="token function">Create_C1</span><span class="token punctuation">(</span>data_set<span class="token punctuation">)</span><span class="token punctuation">:</span>
    C1 <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 
    <span class="token keyword">for</span> t <span class="token keyword">in</span> data_set<span class="token punctuation">:</span>
        <span class="token keyword">for</span> item <span class="token keyword">in</span> t<span class="token punctuation">:</span> 
            item_set <span class="token operator">=</span> <span class="token builtin">frozenset</span><span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># 为生成频繁项目集时扫描数据库时以提供issubset()功能</span>
            C1<span class="token punctuation">.</span>add<span class="token punctuation">(</span>item_set<span class="token punctuation">)</span>
    <span class="token keyword">return</span> C1 
<span class="token triple-quoted-string string">''' 参数：候选频繁k项集，频繁k-1项集 '''</span> 
<span class="token keyword">def</span> <span class="token function">is_apriori</span><span class="token punctuation">(</span>Ck_item<span class="token punctuation">,</span> Lk_sub_1<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    <span class="token keyword">for</span> item <span class="token keyword">in</span> Ck_item<span class="token punctuation">:</span> 
        sub_item <span class="token operator">=</span> Ck_item <span class="token operator">-</span> <span class="token builtin">frozenset</span><span class="token punctuation">(</span><span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">)</span> 
        <span class="token keyword">if</span> sub_item <span class="token keyword">not</span> <span class="token keyword">in</span> Lk_sub_1<span class="token punctuation">:</span> 
            <span class="token keyword">return</span> <span class="token boolean">False</span> 
    <span class="token keyword">return</span> <span class="token boolean">True</span> 
<span class="token triple-quoted-string string">''' # 参数：频繁k-1项集，当前要生成的候选频繁几项集 '''</span> 
<span class="token keyword">def</span> <span class="token function">Create_Ck</span><span class="token punctuation">(</span>Lk_sub_1<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">:</span>
    Ck <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> 
    len_Lk_sub_1 <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>Lk_sub_1<span class="token punctuation">)</span> 
    list_Lk_sub_1 <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>Lk_sub_1<span class="token punctuation">)</span> 
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>len_Lk_sub_1<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#i: [0, len_Lk_sub_1)</span>
        <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> len_Lk_sub_1<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment">#j: [i+1, len_Lk_sub_1)</span>
            l1 <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>list_Lk_sub_1<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
            l2 <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>list_Lk_sub_1<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">)</span>
            l1<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span>
            l2<span class="token punctuation">.</span>sort<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># list[s:t]：截取s到t范围的元素生成一个新list </span>
            <span class="token keyword">if</span> l1<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>k<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">==</span> l2<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>k<span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token comment"># 判断l1的前k-1-1个元素与l2的前k-1-1个元素对应位是否全部相同 </span>
                Ck_item <span class="token operator">=</span> list_Lk_sub_1<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">|</span> list_Lk_sub_1<span class="token punctuation">[</span>j<span class="token punctuation">]</span> 
                <span class="token keyword">if</span> is_apriori<span class="token punctuation">(</span>Ck_item<span class="token punctuation">,</span> Lk_sub_1<span class="token punctuation">)</span><span class="token punctuation">:</span> 
                    Ck<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Ck_item<span class="token punctuation">)</span> 
    <span class="token keyword">return</span> Ck 
<span class="token triple-quoted-string string">''' 参数：数据库事务集，候选频繁k项集，最小支持度，项目集-支持度dic '''</span> 
<span class="token keyword">def</span> <span class="token function">Generate_Lk_By_Ck</span><span class="token punctuation">(</span>data_set<span class="token punctuation">,</span> Ck<span class="token punctuation">,</span> min_support<span class="token punctuation">,</span> support_data<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    Lk <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 通过dic记录候选频繁k项集的事务支持个数 </span>
    item_count <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span> 
    <span class="token keyword">for</span> t <span class="token keyword">in</span> data_set<span class="token punctuation">:</span> 
        <span class="token keyword">for</span> Ck_item <span class="token keyword">in</span> Ck<span class="token punctuation">:</span> 
            <span class="token keyword">if</span> Ck_item<span class="token punctuation">.</span>issubset<span class="token punctuation">(</span>t<span class="token punctuation">)</span><span class="token punctuation">:</span> 
                <span class="token keyword">if</span> Ck_item <span class="token keyword">not</span> <span class="token keyword">in</span> item_count<span class="token punctuation">:</span> 
                    item_count<span class="token punctuation">[</span>Ck_item<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> 
                <span class="token keyword">else</span><span class="token punctuation">:</span> 
                    item_count<span class="token punctuation">[</span>Ck_item<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span> 
                data_num <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>data_set<span class="token punctuation">)</span><span class="token punctuation">)</span> 
                <span class="token keyword">for</span> item <span class="token keyword">in</span> item_count<span class="token punctuation">:</span> 
                    <span class="token keyword">if</span><span class="token punctuation">(</span>item_count<span class="token punctuation">[</span>item<span class="token punctuation">]</span> <span class="token operator">/</span> data_num<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> min_support<span class="token punctuation">:</span> 
                        Lk<span class="token punctuation">.</span>add<span class="token punctuation">(</span>item<span class="token punctuation">)</span> 
                support_data<span class="token punctuation">[</span>item<span class="token punctuation">]</span> <span class="token operator">=</span> item_count<span class="token punctuation">[</span>item<span class="token punctuation">]</span> <span class="token operator">/</span> data_num 
    <span class="token keyword">return</span> Lk 
<span class="token triple-quoted-string string">''' 参数：数据库事务集，求的最高项目集为k项，最小支持度 '''</span>
<span class="token keyword">def</span> <span class="token function">Generate_L</span><span class="token punctuation">(</span>data_set<span class="token punctuation">,</span> max_k<span class="token punctuation">,</span> min_support<span class="token punctuation">)</span><span class="token punctuation">:</span> 
 <span class="token comment"># 创建一个频繁项目集为key，其支持度为value的dic </span>
     support_data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span> 
     C1 <span class="token operator">=</span> Create_C1<span class="token punctuation">(</span>data_set<span class="token punctuation">)</span> 
     L1 <span class="token operator">=</span> Generate_Lk_By_Ck<span class="token punctuation">(</span>data_set<span class="token punctuation">,</span> C1<span class="token punctuation">,</span> min_support<span class="token punctuation">,</span> support_data<span class="token punctuation">)</span> 
     Lk_sub_1 <span class="token operator">=</span> L1<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span> 
     <span class="token comment"># 对L1进行浅copy </span>
     L <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
     L<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Lk_sub_1<span class="token punctuation">)</span>
     <span class="token comment"># 末尾添加指定元素 </span>
     <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> max_k<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
         Ck <span class="token operator">=</span> Create_Ck<span class="token punctuation">(</span>Lk_sub_1<span class="token punctuation">,</span> k<span class="token punctuation">)</span> 
         Lk <span class="token operator">=</span> Generate_Lk_By_Ck<span class="token punctuation">(</span>data_set<span class="token punctuation">,</span> Ck<span class="token punctuation">,</span> min_support<span class="token punctuation">,</span> support_data<span class="token punctuation">)</span> 
         Lk_sub_1 <span class="token operator">=</span> Lk<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span> 
         L<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Lk_sub_1<span class="token punctuation">)</span> 
     <span class="token keyword">return</span> L<span class="token punctuation">,</span> support_data
<span class="token triple-quoted-string string">''' 参数：所有的频繁项目集，项目集-支持度dic，最小置信度 '''</span> 
<span class="token keyword">def</span> <span class="token function">Generate_Rule</span><span class="token punctuation">(</span>L<span class="token punctuation">,</span> support_data<span class="token punctuation">,</span> min_confidence<span class="token punctuation">)</span><span class="token punctuation">:</span> 
    rule_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> 
    sub_set_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> 
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>L<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> 
        <span class="token keyword">for</span> frequent_set <span class="token keyword">in</span> L<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">:</span> 
            <span class="token keyword">for</span> sub_set <span class="token keyword">in</span> sub_set_list<span class="token punctuation">:</span> 
                <span class="token keyword">if</span> sub_set<span class="token punctuation">.</span>issubset<span class="token punctuation">(</span>frequent_set<span class="token punctuation">)</span><span class="token punctuation">:</span> 
                    conf <span class="token operator">=</span> support_data<span class="token punctuation">[</span>frequent_set<span class="token punctuation">]</span> <span class="token operator">/</span> support_data<span class="token punctuation">[</span>sub_set<span class="token punctuation">]</span> 
                    <span class="token comment"># 将rule声明为tuple </span>
                    rule <span class="token operator">=</span> <span class="token punctuation">(</span>sub_set<span class="token punctuation">,</span> frequent_set<span class="token operator">-</span>sub_set<span class="token punctuation">,</span> conf<span class="token punctuation">)</span> 
                    <span class="token keyword">if</span> conf <span class="token operator">&gt;=</span> min_confidence <span class="token keyword">and</span> rule <span class="token keyword">not</span> <span class="token keyword">in</span> rule_list<span class="token punctuation">:</span> 
                        rule_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>rule<span class="token punctuation">)</span> 
            sub_set_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>frequent_set<span class="token punctuation">)</span> 
    <span class="token keyword">return</span> rule_list 
<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span> 
    data_set <span class="token operator">=</span> load_data_set<span class="token punctuation">(</span><span class="token punctuation">)</span> 
    L<span class="token punctuation">,</span> support_data <span class="token operator">=</span> Generate_L<span class="token punctuation">(</span>data_set<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">0.3</span><span class="token punctuation">)</span>
    <span class="token comment">#最小支持度是30% </span>
    rule_list <span class="token operator">=</span> Generate_Rule<span class="token punctuation">(</span>L<span class="token punctuation">,</span> support_data<span class="token punctuation">,</span> <span class="token number">0.7</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> Lk <span class="token keyword">in</span> L<span class="token punctuation">:</span> 
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"="</span><span class="token operator">*</span><span class="token number">55</span><span class="token punctuation">)</span> 
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"frequent "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>Lk<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">"-itemsets\t\tsupport"</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"="</span><span class="token operator">*</span><span class="token number">55</span><span class="token punctuation">)</span> 
        <span class="token keyword">for</span> frequent_set <span class="token keyword">in</span> Lk<span class="token punctuation">:</span> 
            <span class="token keyword">print</span><span class="token punctuation">(</span>frequent_set<span class="token punctuation">,</span><span class="token string">"\t\t"</span><span class="token punctuation">,</span> support_data<span class="token punctuation">[</span>frequent_set<span class="token punctuation">]</span><span class="token punctuation">)</span> 
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Rules"</span><span class="token punctuation">)</span> 
        <span class="token keyword">for</span> item <span class="token keyword">in</span> rule_list<span class="token punctuation">:</span> 
            <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"=&gt;"</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"'s conf: "</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>将rule注释掉后的运行结果</p> 
<p><img src="https://images2.imgbox.com/77/72/9laV8n8G_o.png" alt="image.png"></p> 
<p>将rule打印出的部分截图</p> 
<p><img src="https://images2.imgbox.com/40/2d/ll886V5M_o.png" alt="image.png"></p> 
<h4><a id="2_pythonFP30_160"></a>2. （选做）利用python语言编写FP增长算法，挖掘出上表中数据集的频繁项集，最小支持度为30%。</h4> 
<pre><code class="prism language-python"><span class="token comment">#2、FP树增长算法发现频繁项集</span>

<span class="token keyword">from</span> collections <span class="token keyword">import</span> defaultdict<span class="token punctuation">,</span> Counter<span class="token punctuation">,</span> deque
<span class="token keyword">import</span> math
<span class="token keyword">import</span> copy

<span class="token keyword">class</span> <span class="token class-name">node</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> count<span class="token punctuation">,</span> parent<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 本程序将节点之间的链接信息存储到项头表中，后续可遍历项头表添加该属性</span>
        self<span class="token punctuation">.</span>item <span class="token operator">=</span> item  <span class="token comment"># 该节点的项</span>
        self<span class="token punctuation">.</span>count <span class="token operator">=</span> count  <span class="token comment"># 项的计数</span>
        self<span class="token punctuation">.</span>parent <span class="token operator">=</span> parent  <span class="token comment"># 该节点父节点的id</span>
        self<span class="token punctuation">.</span>children <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 该节点的子节点的list</span>


<span class="token keyword">class</span> <span class="token class-name">FP</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> minsup<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>minsup <span class="token operator">=</span> minsup
        self<span class="token punctuation">.</span>minsup_num <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 支持度计数</span>

        self<span class="token punctuation">.</span>N <span class="token operator">=</span> <span class="token boolean">None</span>
        self<span class="token punctuation">.</span>item_head <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>  <span class="token comment"># 项头表</span>
        self<span class="token punctuation">.</span>fre_one_itemset <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token keyword">lambda</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">)</span>  <span class="token comment"># 频繁一项集，值为支持度</span>
        self<span class="token punctuation">.</span>sort_rules <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 项头表中的项排序规则，按照支持度从大到小有序排列</span>
        self<span class="token punctuation">.</span>tree <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># fp树， 键为节点的id, 值为node</span>
        self<span class="token punctuation">.</span>max_node_id <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 当前树中最大的node_id, 用于插入新节点时，新建node_id</span>
        self<span class="token punctuation">.</span>fre_itemsets <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 频繁项集</span>
        self<span class="token punctuation">.</span>fre_itemsets_sups <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 频繁项集的支持度计数</span>

    <span class="token keyword">def</span> <span class="token function">init_param</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>N <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>minsup_num <span class="token operator">=</span> math<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span>self<span class="token punctuation">.</span>minsup <span class="token operator">*</span> self<span class="token punctuation">.</span>N<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>get_fre_one_itemset<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>build_tree<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">get_fre_one_itemset</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 获取频繁1项，并排序，第一次扫描数据集</span>
        c <span class="token operator">=</span> Counter<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> data<span class="token punctuation">:</span>
            c <span class="token operator">+=</span> Counter<span class="token punctuation">(</span>t<span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> c<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> val <span class="token operator">&gt;=</span> self<span class="token punctuation">.</span>minsup_num<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>fre_one_itemset<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> val
        sort_keys <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>fre_one_itemset<span class="token punctuation">,</span> key<span class="token operator">=</span>self<span class="token punctuation">.</span>fre_one_itemset<span class="token punctuation">.</span>get<span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sort_rules <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k<span class="token punctuation">:</span> i <span class="token keyword">for</span> i<span class="token punctuation">,</span> k <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>sort_keys<span class="token punctuation">)</span><span class="token punctuation">}</span>  <span class="token comment"># 频繁一项按照支持度降低的顺序排列，构建排序规则</span>
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">insert_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> parent<span class="token punctuation">,</span> item<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将事务中的项插入到FP树中，并返回插入节点的id</span>
        children <span class="token operator">=</span> self<span class="token punctuation">.</span>tree<span class="token punctuation">[</span>parent<span class="token punctuation">]</span><span class="token punctuation">.</span>children
        <span class="token keyword">for</span> child_id <span class="token keyword">in</span> children<span class="token punctuation">:</span>
            child_node <span class="token operator">=</span> self<span class="token punctuation">.</span>tree<span class="token punctuation">[</span>child_id<span class="token punctuation">]</span>
            <span class="token keyword">if</span> child_node<span class="token punctuation">.</span>item <span class="token operator">==</span> item<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>tree<span class="token punctuation">[</span>child_id<span class="token punctuation">]</span><span class="token punctuation">.</span>count <span class="token operator">+=</span> <span class="token number">1</span>
                next_node_id <span class="token operator">=</span> child_id
                <span class="token keyword">break</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># 循环正常结束，表明当前父节点的子节点中没有项与之匹配，所以新建子节点，更新项头表和树</span>
            self<span class="token punctuation">.</span>max_node_id <span class="token operator">+=</span> <span class="token number">1</span>
            next_node_id <span class="token operator">=</span> copy<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_node_id<span class="token punctuation">)</span>  <span class="token comment"># 注意self.max_node_id 是可变的，引用时需要copy</span>
            self<span class="token punctuation">.</span>tree<span class="token punctuation">[</span>next_node_id<span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">(</span>item<span class="token operator">=</span>item<span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> parent<span class="token operator">=</span>parent<span class="token punctuation">)</span>  <span class="token comment"># 更新树，添加节点</span>
            self<span class="token punctuation">.</span>tree<span class="token punctuation">[</span>parent<span class="token punctuation">]</span><span class="token punctuation">.</span>children<span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_node_id<span class="token punctuation">)</span>  <span class="token comment"># 更新父节点的孩子列表</span>
            self<span class="token punctuation">.</span>item_head<span class="token punctuation">[</span>item<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_node_id<span class="token punctuation">)</span>  <span class="token comment"># 更新项头表</span>
        <span class="token keyword">return</span> next_node_id

    <span class="token keyword">def</span> <span class="token function">build_tree</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 构建项头表以及FP树， 第二次扫描数据集</span>
        one_itemset <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>fre_one_itemset<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>tree<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> node<span class="token punctuation">(</span>item<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> count<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> parent<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> t <span class="token keyword">in</span> data<span class="token punctuation">:</span>
            t <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token operator">&amp;</span> one_itemset<span class="token punctuation">)</span>  <span class="token comment"># 去除该事务中非频繁项</span>
            <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
                t <span class="token operator">=</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>t<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> self<span class="token punctuation">.</span>sort_rules<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 按照项的频繁程度从大到小排序</span>
                parent <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 每个事务都是从树根开始插起</span>
                <span class="token keyword">for</span> item <span class="token keyword">in</span> t<span class="token punctuation">:</span>
                    parent <span class="token operator">=</span> self<span class="token punctuation">.</span>insert_item<span class="token punctuation">(</span>parent<span class="token punctuation">,</span> item<span class="token punctuation">)</span>  <span class="token comment"># 将排序后的事务中每个项依次插入FP树</span>
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">get_path</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pre_tree<span class="token punctuation">,</span> condition_tree<span class="token punctuation">,</span> node_id<span class="token punctuation">,</span> suffix_items_count<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据后缀的某个叶节点的父节点出发，选取出路径，并更新计数。suffix_item_count为后缀的计数</span>
        <span class="token keyword">if</span> node_id <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> node_id <span class="token keyword">not</span> <span class="token keyword">in</span> condition_tree<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                current_node <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>pre_tree<span class="token punctuation">[</span>node_id<span class="token punctuation">]</span><span class="token punctuation">)</span>
                current_node<span class="token punctuation">.</span>count <span class="token operator">=</span> suffix_items_count  <span class="token comment"># 更新计数</span>
                condition_tree<span class="token punctuation">[</span>node_id<span class="token punctuation">]</span> <span class="token operator">=</span> current_node

            <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># 若叶节点有多个，则路径可能有重复，计数叠加</span>
                condition_tree<span class="token punctuation">[</span>node_id<span class="token punctuation">]</span><span class="token punctuation">.</span>count <span class="token operator">+=</span> suffix_items_count
            node_id <span class="token operator">=</span> condition_tree<span class="token punctuation">[</span>node_id<span class="token punctuation">]</span><span class="token punctuation">.</span>parent
            self<span class="token punctuation">.</span>get_path<span class="token punctuation">(</span>pre_tree<span class="token punctuation">,</span> condition_tree<span class="token punctuation">,</span> node_id<span class="token punctuation">,</span> suffix_items_count<span class="token punctuation">)</span>  <span class="token comment"># 递归构建路径</span>
            <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">get_condition_tree</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pre_tree<span class="token punctuation">,</span> suffix_items_ids<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 构建后缀为一个项的条件模式基。可能对应多个叶节点，综合后缀的各个叶节点的路径</span>
        condition_tree <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 字典存储条件FP树，值为父节点</span>
        <span class="token keyword">for</span> suffix_id <span class="token keyword">in</span> suffix_items_ids<span class="token punctuation">:</span>  <span class="token comment"># 从各个后缀叶节点出发，综合各条路径形成条件FP树</span>
            suffix_items_count <span class="token operator">=</span> copy<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>pre_tree<span class="token punctuation">[</span>suffix_id<span class="token punctuation">]</span><span class="token punctuation">.</span>count<span class="token punctuation">)</span>  <span class="token comment"># 叶节点计数</span>
            node_id <span class="token operator">=</span> pre_tree<span class="token punctuation">[</span>suffix_id<span class="token punctuation">]</span><span class="token punctuation">.</span>parent  <span class="token comment"># 注意条件FP树不包括后缀</span>
            <span class="token keyword">if</span> node_id <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">continue</span>
            self<span class="token punctuation">.</span>get_path<span class="token punctuation">(</span>pre_tree<span class="token punctuation">,</span> condition_tree<span class="token punctuation">,</span> node_id<span class="token punctuation">,</span> suffix_items_count<span class="token punctuation">)</span>
        <span class="token keyword">return</span> condition_tree

    <span class="token keyword">def</span> <span class="token function">extract_suffix_set</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> condition_tree<span class="token punctuation">,</span> suffix_items<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 根据条件模式基，提取频繁项集, suffix_item为该条件模式基对应的后缀</span>
        <span class="token comment"># 返回新的后缀，以及新添加项(将作为下轮的叶节点)的id</span>
        new_suffix_items_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># 后缀中添加的新项</span>
        new_item_head <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">)</span>  <span class="token comment"># 基于当前的条件FP树，更新项头表， 新添加的后缀项</span>
        item_sup_dict <span class="token operator">=</span> defaultdict<span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> condition_tree<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            item_sup_dict<span class="token punctuation">[</span>val<span class="token punctuation">.</span>item<span class="token punctuation">]</span> <span class="token operator">+=</span> val<span class="token punctuation">.</span>count  <span class="token comment"># 对项出现次数进行统计</span>
            new_item_head<span class="token punctuation">[</span>val<span class="token punctuation">.</span>item<span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>key<span class="token punctuation">)</span>

        <span class="token keyword">for</span> item<span class="token punctuation">,</span> sup <span class="token keyword">in</span> item_sup_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> sup <span class="token operator">&gt;=</span> self<span class="token punctuation">.</span>minsup_num<span class="token punctuation">:</span>  <span class="token comment"># 若条件FP树中某个项是频繁的，则添加到后缀中</span>
                current_item_set <span class="token operator">=</span> <span class="token punctuation">[</span>item<span class="token punctuation">]</span> <span class="token operator">+</span> suffix_items
                self<span class="token punctuation">.</span>fre_itemsets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_item_set<span class="token punctuation">)</span>
                self<span class="token punctuation">.</span>fre_itemsets_sups<span class="token punctuation">.</span>append<span class="token punctuation">(</span>sup<span class="token punctuation">)</span>
                new_suffix_items_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>current_item_set<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                new_item_head<span class="token punctuation">.</span>pop<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> new_suffix_items_list<span class="token punctuation">,</span> new_item_head<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_fre_set</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 构建以每个频繁1项为后缀的频繁项集</span>
        self<span class="token punctuation">.</span>init_param<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        suffix_items_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        suffix_items_id_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> key<span class="token punctuation">,</span> val <span class="token keyword">in</span> self<span class="token punctuation">.</span>fre_one_itemset<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            suffix_items <span class="token operator">=</span> <span class="token punctuation">[</span>key<span class="token punctuation">]</span>
            suffix_items_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>suffix_items<span class="token punctuation">)</span>
            suffix_items_id_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>self<span class="token punctuation">.</span>item_head<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>fre_itemsets<span class="token punctuation">.</span>append<span class="token punctuation">(</span>suffix_items<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>fre_itemsets_sups<span class="token punctuation">.</span>append<span class="token punctuation">(</span>val<span class="token punctuation">)</span>
        pre_tree <span class="token operator">=</span> copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>self<span class="token punctuation">.</span>tree<span class="token punctuation">)</span>  <span class="token comment"># pre_tree 是尚未去除任何后缀的前驱，若其叶节点的项有多种，则可以形成多种条件FP树</span>
        self<span class="token punctuation">.</span>dfs_search<span class="token punctuation">(</span>pre_tree<span class="token punctuation">,</span> suffix_items_list<span class="token punctuation">,</span> suffix_items_id_list<span class="token punctuation">)</span>
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">bfs_search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pre_tree<span class="token punctuation">,</span> suffix_items_list<span class="token punctuation">,</span> suffix_items_id_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 宽度优先，递增构建频繁k项集</span>
        q <span class="token operator">=</span> deque<span class="token punctuation">(</span><span class="token punctuation">)</span>
        q<span class="token punctuation">.</span>appendleft<span class="token punctuation">(</span><span class="token punctuation">(</span>pre_tree<span class="token punctuation">,</span> suffix_items_list<span class="token punctuation">,</span> suffix_items_id_list<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">while</span> <span class="token builtin">len</span><span class="token punctuation">(</span>q<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            param_tuple <span class="token operator">=</span> q<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
            pre_tree <span class="token operator">=</span> param_tuple<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> suffix_items<span class="token punctuation">,</span> suffix_items_ids <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>param_tuple<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> param_tuple<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                condition_tree <span class="token operator">=</span> self<span class="token punctuation">.</span>get_condition_tree<span class="token punctuation">(</span>pre_tree<span class="token punctuation">,</span> suffix_items_ids<span class="token punctuation">)</span>
                new_suffix_items_list<span class="token punctuation">,</span> new_suffix_items_id_list <span class="token operator">=</span> self<span class="token punctuation">.</span>extract_suffix_set<span class="token punctuation">(</span>condition_tree<span class="token punctuation">,</span> suffix_items<span class="token punctuation">)</span>
                <span class="token keyword">if</span> new_suffix_items_list<span class="token punctuation">:</span>
                    q<span class="token punctuation">.</span>appendleft<span class="token punctuation">(</span>
                        <span class="token punctuation">(</span>condition_tree<span class="token punctuation">,</span> new_suffix_items_list<span class="token punctuation">,</span> new_suffix_items_id_list<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 储存前驱，以及产生该前驱的后缀的信息</span>
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">dfs_search</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pre_tree<span class="token punctuation">,</span> suffix_items_list<span class="token punctuation">,</span> suffix_items_id_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 深度优先，递归构建以某个项为后缀的频繁k项集</span>
        <span class="token keyword">for</span> suffix_items<span class="token punctuation">,</span> suffix_items_ids <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>suffix_items_list<span class="token punctuation">,</span> suffix_items_id_list<span class="token punctuation">)</span><span class="token punctuation">:</span>
            condition_tree <span class="token operator">=</span> self<span class="token punctuation">.</span>get_condition_tree<span class="token punctuation">(</span>pre_tree<span class="token punctuation">,</span> suffix_items_ids<span class="token punctuation">)</span>
            new_suffix_items_list<span class="token punctuation">,</span> new_suffix_items_id_list <span class="token operator">=</span> self<span class="token punctuation">.</span>extract_suffix_set<span class="token punctuation">(</span>condition_tree<span class="token punctuation">,</span> suffix_items<span class="token punctuation">)</span>
            <span class="token keyword">if</span> new_suffix_items_list<span class="token punctuation">:</span>  <span class="token comment"># 如果后缀有新的项添加进来，则继续深度搜索</span>
                self<span class="token punctuation">.</span>dfs_search<span class="token punctuation">(</span>condition_tree<span class="token punctuation">,</span> new_suffix_items_list<span class="token punctuation">,</span> new_suffix_items_id_list<span class="token punctuation">)</span>
        <span class="token keyword">return</span>


<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    data2 <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'abde'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'bcd'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'acde'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'abde'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'bcde'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'bde'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token string">'cd'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>

    fp <span class="token operator">=</span> FP<span class="token punctuation">(</span>minsup<span class="token operator">=</span><span class="token number">3</span><span class="token operator">/</span><span class="token number">7</span><span class="token punctuation">)</span>
    fp<span class="token punctuation">.</span>get_fre_set<span class="token punctuation">(</span>data2<span class="token punctuation">)</span>

    <span class="token keyword">for</span> itemset<span class="token punctuation">,</span> sup <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>fp<span class="token punctuation">.</span>fre_itemsets<span class="token punctuation">,</span> fp<span class="token punctuation">.</span>fre_itemsets_sups<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>itemset<span class="token punctuation">,</span> sup<span class="token punctuation">)</span>
</code></pre> 
<p>运行结果</p> 
<p><img src="https://images2.imgbox.com/03/24/OhsZCnYX_o.png" alt="image.png"></p> 
<h3><a id="_342"></a>五、实验总结（写出本次实验的收获，遇到的问题等）</h3> 
<p>通过本次的实验，了解了对频繁项级的处理，通过Apriori算法实现，理解了Apriori算法将发现关联规则的过程分为两个步骤：第一步通过迭代，检索出事务数据库中的所有频繁项集；第二步利用频繁项集构造出满足用户最小信任度的规则。重要的是要挖掘或识别出所有频繁项集。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/47203d349a9b0eb26931afcdbe397510/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">《Meta Graph Transformer：一种时空交通预测模型》</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b77b443667a759694d6acff4eb9bb570/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">HTML中的表格和表单（含有示例代码）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>