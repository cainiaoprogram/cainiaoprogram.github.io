<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MATLAB前馈神经网络newff - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="MATLAB前馈神经网络newff" />
<meta property="og:description" content="一-newff函数参数说明，初始化网络 net = newff(P,T,S) % 这两种定义都可以
net = newff(P,T,S,TF,BTF,BLF,PF,IPF,OPF,DDF)
P：输入参数矩阵。(RxQ1)，其中Q1代表R元的输入向量。其数据意义是矩阵P有Q1列，每一列都是一个样本，而每个样本有R个属性（特征）。一般矩阵P需要归一化，即P的每一行都归一化到[0 1]或者[-1 1]。 T：目标参数矩阵。(SNxQ2)，Q2代表SN元的目标向量。 S：N-1个隐含层的数目（S（i）到S（N-1）），默认为空矩阵[]。输出层的单元数目SN取决于T。返回N层的前馈BP神经网络 TF：相关层的传递函数，默认隐含层为tansig函数，输出层为purelin函数。 BTF：BP神经网络学习训练函数，默认值为trainlm函数。 BLF：权重学习函数，默认值为learngdm。 PF：性能函数，默认值为mse，可选择的还有sse，sae，mae，crossentropy。 IPF，OPF，DDF均为默认值即可。 例子：
一般来说
input，output是训练样本
net = newff（input，output，[1层个数，2层个数..]，{TF，1层传递函数，2层传毒函数}，BTF：‘训练函数’）
net = newff( input,output, [50] , { &#39;logsig&#39; &#39;purelin&#39; } , &#39;traingdx&#39; ) ; 传递函数TF purelin： 线性传递函数。 tansig ：正切S型传递函数。 logsig ：对数S型传递函数。　隐含层和输出层函数的选择对BP神经网络预测精度有较大影响，一般隐含层节点转移函数选用 tansig函数或logsig函数，输出层节点转移函数选用tansig函数或purelin函数。 ３，学习训练函数BTF traingd：最速下降BP算法。 traingdm：动量BP算法。 trainda：学习率可变的最速下降BP算法。 traindx：学习率可变的动量BP算法。 trainrp：弹性算法。 变梯度算法： traincgf（Fletcher-Reeves修正算法） traincgp（Polak_Ribiere修正算法） traincgb（Powell-Beale复位算法） trainbfg（BFGS 拟牛顿算法） trainoss（OSS算法）
二-再次初始化，赋予训练要求 1.参数说明 通过net.trainParam可以查看参数 Show Training Window Feedback showWindow: true Show Command Line Feedback showCommandLine: false Command Line Frequency show: 两次显示之间的训练次数 Maximum Epochs epochs: 训练次数 Maximum Training Time time: 最长训练时间（秒） Performance Goal goal: 网络性能目标 Minimum Gradient min_grad: 性能函数最小梯度 Maximum Validation Checks max_fail: 最大验证失败次数 Learning Rate lr: 学习速率 Learning Rate Increase lr_inc: 学习速率增长值 Learning Rate lr_dec: 学习速率下降值 Maximum Performance Increase max_perf_inc: Momentum Constant mc: 动量因子" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a60eb01ad507e52e6fe4a2ca6666f5b4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-11-29T13:56:32+08:00" />
<meta property="article:modified_time" content="2018-11-29T13:56:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MATLAB前馈神经网络newff</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>一-newff函数参数说明，初始化网络</h4> 
<p>net = newff(P,T,S)                             % 这两种定义都可以<br> net = newff(P,T,S,TF,BTF,BLF,PF,IPF,OPF,DDF)</p> 
<p><br> 　　 P：输入参数矩阵。(RxQ1)，其中Q1代表R元的输入向量。其数据意义是矩阵P有Q1列，每一列都是一个样本，而每个样本有R个属性（特征）。一般矩阵P需要归一化，即P的每一行都归一化到[0 1]或者[-1 1]。 <br> 　　T：目标参数矩阵。(SNxQ2)，Q2代表SN元的目标向量。 <br> 　　S：N-1个隐含层的数目（S（i）到S（N-1）），默认为空矩阵[]。输出层的单元数目SN取决于T。返回N层的前馈BP神经网络 <br> 　　 TF：相关层的传递函数，默认隐含层为tansig函数，输出层为purelin函数。 <br> 　　BTF：BP神经网络学习训练函数，默认值为trainlm函数。 <br> 　　BLF：权重学习函数，默认值为learngdm。 <br> 　　PF：性能函数，默认值为mse，可选择的还有sse，sae，mae，crossentropy。 <br> 　　IPF，OPF，DDF均为默认值即可。 <br> 　　例子：</p> 
<p>一般来说</p> 
<p>input，output是训练样本</p> 
<p>net = newff（<span style="color:#7c79e5;">input，output</span>，<span style="color:#86ca5e;">[1层个数，2层个数..]</span>，<strong>{TF，1层传递函数，2层传毒函数}</strong>，<span style="color:#3399ea;">BTF：‘训练函数’</span>）</p> 
<p>net = newff( input,output, [50] , { 'logsig' 'purelin' } , 'traingdx' ) ;    <br> 传递函数TF <br> 　　purelin： 线性传递函数。 <br> 　　tansig ：正切S型传递函数。 <br> 　　logsig ：对数S型传递函数。　 <br> 　　隐含层和输出层函数的选择对BP神经网络预测精度有较大影响，一般隐含层节点转移函数选用 tansig函数或logsig函数，输出层节点转移函数选用tansig函数或purelin函数。 <br> ３，学习训练函数BTF <br> 　　traingd：最速下降BP算法。 <br> 　　traingdm：动量BP算法。 <br> 　　trainda：学习率可变的最速下降BP算法。 <br> 　　traindx：学习率可变的动量BP算法。 <br> 　　trainrp：弹性算法。 <br> 　　变梯度算法： <br> 　　　　traincgf（Fletcher-Reeves修正算法） <br> 　　　　 traincgp（Polak_Ribiere修正算法） <br> 　　　　 traincgb（Powell-Beale复位算法） <br> 　　　　 trainbfg（BFGS 拟牛顿算法） <br> 　　　　 trainoss（OSS算法）</p> 
<h4>二-再次初始化，赋予训练要求</h4> 
<p>1.参数说明 <br> 　　通过net.trainParam可以查看参数 <br> 　　 Show Training Window Feedback showWindow: true <br> 　　 Show Command Line Feedback showCommandLine: false <br> 　　 Command Line Frequency show: 两次显示之间的训练次数 <br> 　　Maximum Epochs epochs: 训练次数 <br> 　　 Maximum Training Time time: 最长训练时间（秒） <br> 　　 Performance Goal goal: 网络性能目标 <br> 　　 Minimum Gradient min_grad: 性能函数最小梯度 <br> 　　 Maximum Validation Checks max_fail: 最大验证失败次数 <br> 　　 Learning Rate lr: 学习速率 <br> 　　Learning Rate Increase lr_inc: 学习速率增长值 <br> 　　Learning Rate lr_dec: 学习速率下降值 <br> 　　 Maximum Performance Increase max_perf_inc: <br> 　　 Momentum Constant mc: 动量因子</p> 
<pre class="has"><code class="hljs language-python">net2 = newff(P,T,5,{'tansig', 'purelin'}, 'traingd'); % 隐含层有5个神经元

net2.trainParam.goal = 1e-5;%训练性能目标最小误差

net2.trainParam.epochs = 300;%训练次数

net2.trainParam.lr = 0.05;%学习速率

net2.trainParam.showWindow = 1;

net2.divideFcn = ''; % 为和书本一致，对于样本极少的情况，不要再三分了</code></pre> 
<p>2.权重和偏置的初始化</p> 
<p><a href="https://blog.csdn.net/SHENNONGZHAIZHU/article/details/52966402">https://blog.csdn.net/SHENNONGZHAIZHU/article/details/52966402</a></p> 
<p> </p> 
<p>通过设定网络参数<span style="color:#f33b45;">net.initFcn和net.layer{i}.initFcn</span>这一技巧来初始化一个给定的网络。</p> 
<p>对前馈网络来说，有两种不同的初始化方式经常被用到：<span style="color:#f33b45;">initwb和initnw</span>。initwb函数根据每一层自己的初始化参数<span style="color:#f33b45;">(net.inputWeights{i,j}.initFcn)初始化权重矩阵和偏置</span>。前馈网络的初始化权重通常设为rands，它使权重在-1到1之间随机取值。这种方式经常用在转换函数是线性函数时。initnw通常用于转换函数是曲线函数。它根据Nguyen和Widrow[NgWi90]为层产生初始权重和偏置值，使得每层神经元的活动区域能大致平坦的分布在输入空间。</p> 
<pre class="has"><code class="hljs language-python">net.layers{1}.initFcn = 'initwb';
　　net.inputWeights{1,1}.initFcn = 'rands';
%初始化权重和偏置
　　net.biases{1,1}.initFcn = 'rands';
　　net.biases{2,1}.initFcn = 'rands';
　　net = init(net);</code></pre> 
<h4>三-训练</h4> 
<p>net2 = train(net2,P,T);//P,T为训练样本</p> 
<p><strong>之后可以得到训练完成后的权值和阈值</strong></p> 
<p>iw1=net.IW{1};<br> b1=net.b{1};<br> lw2=net.LW{2};<br> b2=net.b{2};</p> 
<h4>四、仿真</h4> 
<p>q=sim(net,p);//p为测试样本，q输出就是通过网络得到的结果<br> e=q-T;//结果与预期的误差<br> plot(p,q); %画训练误差曲线<br> q=sim(net,X);<br> e=q-Y;<br> plot(X,q); %画测试误差曲线</p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/267f6615491f38f704cbab20d278f9df/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Qchart 中清空绘图</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/772de2a87cb8b6ab0f790344911db6cb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">YSlow--Web前端性能测试工具</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>