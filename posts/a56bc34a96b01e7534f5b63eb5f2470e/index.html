<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>selenium翻页获取京东图书名称和价格 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="selenium翻页获取京东图书名称和价格" />
<meta property="og:description" content="selenium翻页获取京东图书名称和价格 案例目的： 通过selenium翻页爬取京东图书名称和价格，介绍如何通过selenium模拟鼠标滑轮，点击，翻页等操作。
案例功能： 输入要爬取的页数，批量下载每一页数图书的名称和价格，并保存到本地。
案例分析： 1.找到目标页面的url（我们以中国当代小说为例） 2.通过模拟滚轮实现异步加载： 注：每一页共有60本书，但是：如果没有手动通过滑轮获取剩下的30个数据，通过xpath页只能获取30个，这就是我们为什么要模拟鼠标滑轮的原因。
当我们把滑轮滑倒最底部，就会得到加载剩余的30个数据： 当然，价格也是同理。
名称和价格的xpath，以及鼠标滑轮已经介绍完毕。
3.接下来就是通过selenuim进行翻页。 selenium翻页原理：通过定位下一页的标签，然后模拟点击操作，实现翻页。如下图：
这里说一下注意事项： 1.selenuim模拟浏览器时可能会因为网络的问题，加载时间延长。因此，爬取每一页数据都要设置延时操作，延时时间根据自己的网速设置。
2.在实现滑轮滑动时，scrollTop后面对应的参数是滑轮所在的位置，如果scrollTop=0就代表在最上方，我是通过调试，得到5000比较合适。
3.在selenium中使用find_element_by_xpath进行定位时，只是定义节点，而不是文本和属性。
4.关于数据保存的细节我就不多说了，我的前几篇文章介绍的都有，大家可以做参考。
分析完毕，开始上代码： from selenium.webdriver import Chrome import time from lxml import etree import json if __name__ == &#39;__main__&#39;: # 输入要去的页数 pages = int(input(&#39;请输入要爬取的页数：&#39;)) # 创建浏览器 chrome = Chrome() # 在网址栏输入url chrome.get(&#39;https://list.jd.com/list.html?cat=1713,3258,3297&#39;) # 创建循环 for i in range(pages): # 页面等待 time.sleep(10) # 通过滑轮进行异步加载 js_ = &#39;document.documentElement.scrollTop=5000&#39; chrome.execute_script(js_) time.sleep(2) # 获取页面数据 html_data = chrome." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a56bc34a96b01e7534f5b63eb5f2470e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-25T18:14:05+08:00" />
<meta property="article:modified_time" content="2021-02-25T18:14:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">selenium翻页获取京东图书名称和价格</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="selenium_0"></a>selenium翻页获取京东图书名称和价格</h2> 
<h4><a id="_1"></a>案例目的：</h4> 
<p>通过selenium翻页爬取京东图书名称和价格，介绍如何通过selenium模拟鼠标滑轮，点击，翻页等操作。</p> 
<h4><a id="_4"></a>案例功能：</h4> 
<p>输入要爬取的页数，批量下载每一页数图书的名称和价格，并保存到本地。</p> 
<h4><a id="_7"></a>案例分析：</h4> 
<h4><a id="1url_8"></a>1.找到目标页面的url（我们以中国当代小说为例）</h4> 
<p><img src="https://images2.imgbox.com/1e/9e/epAdap6Y_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2_10"></a>2.通过模拟滚轮实现异步加载：</h4> 
<p>注：每一页共有60本书，但是：<strong>如果没有手动通过滑轮获取剩下的30个数据，通过xpath页只能获取30个，这就是我们为什么要模拟鼠标滑轮的原因。</strong><br> <img src="https://images2.imgbox.com/9b/23/H0JJR0qQ_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="30_13"></a>当我们把滑轮滑倒最底部，就会得到加载剩余的30个数据：</h5> 
<p>当然，价格也是同理。<br> <img src="https://images2.imgbox.com/63/ef/74zJnBwu_o.png" alt="在这里插入图片描述"><br> 名称和价格的xpath，以及鼠标滑轮已经介绍完毕。</p> 
<h4><a id="3selenuim_17"></a>3.接下来就是通过selenuim进行翻页。</h4> 
<p>selenium翻页原理：通过定位下一页的标签，然后模拟点击操作，实现翻页。如下图：<br> <img src="https://images2.imgbox.com/ce/02/pJDUE2sE_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_20"></a>这里说一下注意事项：</h4> 
<p><strong>1.selenuim模拟浏览器时可能会因为网络的问题，加载时间延长。因此，爬取每一页数据都要设置延时操作，延时时间根据自己的网速设置。</strong></p> 
<p><strong>2.在实现滑轮滑动时，scrollTop后面对应的参数是滑轮所在的位置，如果scrollTop=0就代表在最上方，我是通过调试，得到5000比较合适。</strong><br> <img src="https://images2.imgbox.com/70/c1/fUjjgih2_o.png" alt="在这里插入图片描述"></p> 
<p><strong>3.在selenium中使用find_element_by_xpath进行定位时，只是定义节点，而不是文本和属性。</strong><br> <img src="https://images2.imgbox.com/9b/4f/MxNFRUNW_o.png" alt="在这里插入图片描述"></p> 
<p><strong>4.关于数据保存的细节我就不多说了，我的前几篇文章介绍的都有，大家可以做参考。</strong></p> 
<h4><a id="_33"></a>分析完毕，开始上代码：</h4> 
<pre><code>from selenium.webdriver import Chrome
import time
from lxml import etree
import json

if __name__ == '__main__':
    # 输入要去的页数
    pages = int(input('请输入要爬取的页数：'))
    # 创建浏览器
    chrome = Chrome()
    # 在网址栏输入url
    chrome.get('https://list.jd.com/list.html?cat=1713,3258,3297')
    # 创建循环
    for i in range(pages):
        # 页面等待
        time.sleep(10)
        # 通过滑轮进行异步加载
        js_ = 'document.documentElement.scrollTop=5000'
        chrome.execute_script(js_)
        time.sleep(2)
        # 获取页面数据
        html_data = chrome.page_source
        # 将数据转换成py格式
        py_data = etree.HTML(html_data)
        # 提取目标数据 1.图书名称，2.图书价格
        title_list = py_data.xpath('//div[@class="gl-i-wrap"]/div[@class="p-name"]/a/em/text()')
        price_list = py_data.xpath('//strong/i/text()')
        print(len(title_list))
        print(len(price_list))
        # 将输入存进字典，并转换成json格式
        for i in range(len(title_list)):
            dict_ = {}
            dict_[title_list[i]] = price_list[i]
            # 将字典转换成json格式数据
            json_data = json.dumps(dict_,ensure_ascii=False)+',\n'
            # 将json数据保存到本地
            with open('京东图书名称和价格.json','a',encoding='utf-8')as f:
                f.write(json_data)
        # 模拟点击下一页
        click_obj = chrome.find_element_by_xpath('//span/a[@class="pn-next"]')
        # 模拟点击
        click_obj.click()
    # 爬取过程完成后，关闭浏览器
    chrome.quit()
</code></pre> 
<p>我一共爬取了3页。每页对应60个数据</p> 
<h4><a id="_81"></a>爬取结果如下：</h4> 
<p><img src="https://images2.imgbox.com/ff/8d/h4s7fBKE_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6823caa32b2f19a4cb26cea60315fa20/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">java.lang.NoSuchFieldError报错解决方案</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2a20f06aa1742bfc608098477b241b63/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java设计模式--01类图UML图箭头含义</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>