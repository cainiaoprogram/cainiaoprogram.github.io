<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>SHAP的介绍和应用（附代码） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="SHAP的介绍和应用（附代码）" />
<meta property="og:description" content="SHAP Tutorial 本文主要介绍：
SHAP的原理SHAP的应用方式 SHAP的介绍 SHAP的目标就是通过计算每个样本中每一个特征对prediction的贡献, 来对模型结果做解释。在合作博弈论的启发下SHAP构建一个加性的解释模型，所有的特征都视为“贡献者”。对于每个预测样本，模型都产生一个预测值，SHAP值就是该样本中每个特征所分配到的数值。
设第 i i i个样本为 x i x_i xi​，第 i i i个样本的第 j j j个特征为 x i j x_i^j xij​，模型对该样本的预测值为 y i y_i yi​，整个模型的基线（通常是所有样本的目标变量的均值）为 y b a s e y_{base} ybase​，那么SHAP值服从以下等式：
y i = y b a s e &#43; f ( x i 1 ) &#43; f ( x i 2 ) &#43; . . . &#43; f ( x i j ) y_i = y_{base} &#43; f(x_i^1)&#43;f(x_i^2)&#43;." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/54d47c52fa922d518c2f5e24a938a060/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-11T17:01:21+08:00" />
<meta property="article:modified_time" content="2022-04-11T17:01:21+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">SHAP的介绍和应用（附代码）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="SHAP_Tutorial_0"></a><code>SHAP Tutorial</code></h2> 
<p>本文主要介绍：</p> 
<ul><li>SHAP的原理</li><li>SHAP的应用方式</li></ul> 
<h3><a id="SHAP_5"></a>SHAP的介绍</h3> 
<p>SHAP的目标就是通过计算每个样本中每一个特征对prediction的贡献, 来对模型结果做解释。在合作博弈论的启发下SHAP构建一个加性的解释模型，所有的特征都视为“贡献者”。对于每个预测样本，模型都产生一个预测值，SHAP值就是该样本中每个特征所分配到的数值。</p> 
<p>设第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathdefault">i</span></span></span></span></span>个样本为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
        
       
      
        x_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathdefault">i</span></span></span></span></span>个样本的第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         j 
        
       
      
        j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.85396em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.05724em;">j</span></span></span></span></span>个特征为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
        
          j 
         
        
       
      
        x_i^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.21944em; vertical-align: -0.276864em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.942572em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.18091em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，模型对该样本的预测值为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          y 
         
        
          i 
         
        
       
      
        y_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，整个模型的基线（通常是所有样本的目标变量的均值）为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          y 
         
         
         
           b 
          
         
           a 
          
         
           s 
          
         
           e 
          
         
        
       
      
        y_{base} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，那么SHAP值服从以下等式：</p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          y 
         
        
          i 
         
        
       
         = 
        
        
        
          y 
         
         
         
           b 
          
         
           a 
          
         
           s 
          
         
           e 
          
         
        
       
         + 
        
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          1 
         
        
       
         ) 
        
       
         + 
        
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          2 
         
        
       
         ) 
        
       
         + 
        
       
         . 
        
       
         . 
        
       
         . 
        
       
         + 
        
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          j 
         
        
       
         ) 
        
       
      
        y_i = y_{base} + f(x_i^1)+f(x_i^2)+...+f(x_i^j) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.77777em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.336108em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">b</span><span class="mord mathdefault mtight">a</span><span class="mord mathdefault mtight">s</span><span class="mord mathdefault mtight">e</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.07277em; vertical-align: -0.258664em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.44134em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.258664em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.07277em; vertical-align: -0.258664em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.44134em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.258664em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.66666em; vertical-align: -0.08333em;"></span><span class="mord">.</span><span class="mord">.</span><span class="mord">.</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 1.21944em; vertical-align: -0.276864em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.942572em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.18091em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p> 
<p>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          j 
         
        
       
         ) 
        
       
      
        f(x_i^j) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.21944em; vertical-align: -0.276864em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.942572em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.18091em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
        
          j 
         
        
       
      
        x_i^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.21944em; vertical-align: -0.276864em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.942572em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.18091em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的SHAP值。直观上看，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          1 
         
        
       
         ) 
        
       
      
        f(x_i^1) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.07277em; vertical-align: -0.258664em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.44134em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.258664em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>就是第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathdefault">i</span></span></span></span></span>个样本中第1个特征对最终预测值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          y 
         
        
          i 
         
        
       
      
        y_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.19444em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的贡献值，当<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          1 
         
        
       
         ) 
        
       
         &gt; 
        
       
         0 
        
       
      
        f(x_i^1)&gt;0 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.07277em; vertical-align: -0.258664em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.814108em;"><span class="" style="top: -2.44134em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.258664em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span></span></span></span></span>，说明该特征提升了预测值，也正向作用；反之，说明该特征使得预测值降低，有反作用。上式是也是通过拟合的方式获得<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         f 
        
       
         ( 
        
        
        
          x 
         
        
          i 
         
        
          j 
         
        
       
         ) 
        
       
      
        f(x_i^j) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.21944em; vertical-align: -0.276864em;"></span><span class="mord mathdefault" style="margin-right: 0.10764em;">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.942572em;"><span class="" style="top: -2.42314em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.18091em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.276864em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span>的值。具体的是如何拟合的这里不做要求。</p> 
<h3><a id="TreeSHAPSHAP_15"></a>以树模型TreeSHAP为例子说明SHAP值的用法</h3> 
<p>这个教材以Titantic数据为例子进行说明<br> 下面简单看下titantic的特征:</p> 
<p>PassengerId 乘客ID</p> 
<p>Survived 获救与否(0死亡,1生存)</p> 
<p>Pclass 乘客等级(1/2/3等舱位)</p> 
<p>Name 乘客姓名</p> 
<p>Sex 性别</p> 
<p>Age 年龄</p> 
<p>SibSp 堂兄弟/妹个数</p> 
<p>Parch 父母与小孩个数</p> 
<p>Ticket 船票信息</p> 
<p>Fare 票价</p> 
<p>Cabin 客舱</p> 
<p>Embarked 登船港口</p> 
<p>这是一个二分类问题，其中Survived是要预测的值， Pclass，Sex，Age，SibSp，Parch，Ticket，Fare，Cabin，Embarked为特征</p> 
<p>我们将以集成树模型（LightGBM为例来讲解）</p> 
<p>注：我们尽量简化这个问题，方便大家理解shap是如何应用的。</p> 
<pre><code class="prism language-python"><span class="token comment">#拉取数据</span>
!git clone https<span class="token punctuation">:</span><span class="token operator">//</span>github<span class="token punctuation">.</span>com<span class="token operator">/</span>pangpang97<span class="token operator">/</span>shap_tutorial
</code></pre> 
<pre><code>Cloning into 'shap_tutorial'...
remote: Enumerating objects: 12, done.[K
remote: Counting objects: 100% (12/12), done.[K
remote: Compressing objects: 100% (10/10), done.[K
remote: Total 12 (delta 1), reused 0 (delta 0), pack-reused 0[K
Unpacking objects: 100% (12/12), done.
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#引入需要的包</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
all_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'shap_tutorial/train_titantic.csv'</span><span class="token punctuation">)</span>
all_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
</code></pre> 
<h4><a id="_88"></a>简单的数据处理</h4> 
<pre><code class="prism language-python"><span class="token comment">#删去暂时不要的列</span>
all_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">,</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment">#填充缺失值</span>
all_data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
all_data<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">'UNK'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
all_data<span class="token punctuation">[</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">'UNK'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
all_data<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 10 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Survived  891 non-null    int64  
 1   Pclass    891 non-null    int64  
 2   Sex       891 non-null    object 
 3   Age       891 non-null    float64
 4   SibSp     891 non-null    int64  
 5   Parch     891 non-null    int64  
 6   Ticket    891 non-null    object 
 7   Fare      891 non-null    float64
 8   Cabin     891 non-null    object 
 9   Embarked  891 non-null    object 
dtypes: float64(2), int64(4), object(4)
memory usage: 69.7+ KB
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#把Sex，Ticket，Cabin和Embarked做一个lebel encoding</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
cate_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">,</span><span class="token string">'Ticket'</span><span class="token punctuation">,</span><span class="token string">'Cabin'</span><span class="token punctuation">,</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> cc <span class="token keyword">in</span> cate_cols<span class="token punctuation">:</span>
    enc <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    all_data<span class="token punctuation">[</span>cc<span class="token punctuation">]</span> <span class="token operator">=</span> enc<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>all_data<span class="token punctuation">[</span>cc<span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="LightGBM_124"></a>LightGBM训练</h4> 
<pre><code class="prism language-python"><span class="token comment">#拆分下训练集和测试集</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
train<span class="token punctuation">,</span> test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>all_data<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

<span class="token comment">#利用LightGBM训练模型</span>
<span class="token keyword">import</span> lightgbm <span class="token keyword">as</span> lgb
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
params <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'objective'</span><span class="token punctuation">:</span> <span class="token string">'binary'</span><span class="token punctuation">,</span>
          <span class="token string">'metric'</span><span class="token punctuation">:</span> <span class="token string">'binary_logloss'</span><span class="token punctuation">,</span>
          <span class="token string">'num_round'</span><span class="token punctuation">:</span> <span class="token number">80</span><span class="token punctuation">,</span>
          <span class="token string">'verbose'</span><span class="token punctuation">:</span><span class="token number">1</span>
              <span class="token punctuation">}</span>
num_round <span class="token operator">=</span> params<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'num_round'</span><span class="token punctuation">,</span><span class="token number">1000</span><span class="token punctuation">)</span>
xtrain <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> train<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>free_raw_data<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
xeval <span class="token operator">=</span> lgb<span class="token punctuation">.</span>Dataset<span class="token punctuation">(</span>test<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> test<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>free_raw_data<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
evallist <span class="token operator">=</span> <span class="token punctuation">[</span>xtrain<span class="token punctuation">,</span> xeval<span class="token punctuation">]</span>
clf <span class="token operator">=</span> lgb<span class="token punctuation">.</span>train<span class="token punctuation">(</span>params<span class="token punctuation">,</span> xtrain<span class="token punctuation">,</span> num_round<span class="token punctuation">,</span> valid_sets<span class="token operator">=</span>evallist<span class="token punctuation">)</span>
ytrain <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&gt;=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
ytest <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>test<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">&gt;=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train classification report"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>train<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ytrain<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'*'</span><span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"test classification report"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>test<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> ytest<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>[1]	training's binary_logloss: 0.616752	valid_1's binary_logloss: 0.628188
[2]	training's binary_logloss: 0.577503	valid_1's binary_logloss: 0.59757
[3]	training's binary_logloss: 0.545282	valid_1's binary_logloss: 0.573299
[4]	training's binary_logloss: 0.517894	valid_1's binary_logloss: 0.55145
[5]	training's binary_logloss: 0.49365	valid_1's binary_logloss: 0.53399
[6]	training's binary_logloss: 0.472167	valid_1's binary_logloss: 0.518513
[7]	training's binary_logloss: 0.453641	valid_1's binary_logloss: 0.506068
[8]	training's binary_logloss: 0.437905	valid_1's binary_logloss: 0.494044
[9]	training's binary_logloss: 0.424174	valid_1's binary_logloss: 0.485643
[10]	training's binary_logloss: 0.410632	valid_1's binary_logloss: 0.477679
[11]	training's binary_logloss: 0.398761	valid_1's binary_logloss: 0.470235
[12]	training's binary_logloss: 0.388724	valid_1's binary_logloss: 0.464987
[13]	training's binary_logloss: 0.379662	valid_1's binary_logloss: 0.460591
[14]	training's binary_logloss: 0.370902	valid_1's binary_logloss: 0.457459
[15]	training's binary_logloss: 0.363174	valid_1's binary_logloss: 0.455261
[16]	training's binary_logloss: 0.356024	valid_1's binary_logloss: 0.451337
[17]	training's binary_logloss: 0.348805	valid_1's binary_logloss: 0.447478
[18]	training's binary_logloss: 0.340424	valid_1's binary_logloss: 0.444287
[19]	training's binary_logloss: 0.3332	valid_1's binary_logloss: 0.439115
[20]	training's binary_logloss: 0.326891	valid_1's binary_logloss: 0.436567
[21]	training's binary_logloss: 0.321057	valid_1's binary_logloss: 0.434214
[22]	training's binary_logloss: 0.315413	valid_1's binary_logloss: 0.433245
[23]	training's binary_logloss: 0.310579	valid_1's binary_logloss: 0.434182
[24]	training's binary_logloss: 0.305809	valid_1's binary_logloss: 0.43319
[25]	training's binary_logloss: 0.301533	valid_1's binary_logloss: 0.432078
[26]	training's binary_logloss: 0.295784	valid_1's binary_logloss: 0.430593
[27]	training's binary_logloss: 0.290461	valid_1's binary_logloss: 0.428543
[28]	training's binary_logloss: 0.285622	valid_1's binary_logloss: 0.426985
[29]	training's binary_logloss: 0.279571	valid_1's binary_logloss: 0.426044
[30]	training's binary_logloss: 0.274883	valid_1's binary_logloss: 0.427347
[31]	training's binary_logloss: 0.270582	valid_1's binary_logloss: 0.427791
[32]	training's binary_logloss: 0.265887	valid_1's binary_logloss: 0.428961
[33]	training's binary_logloss: 0.260971	valid_1's binary_logloss: 0.430992
[34]	training's binary_logloss: 0.254612	valid_1's binary_logloss: 0.429185
[35]	training's binary_logloss: 0.250871	valid_1's binary_logloss: 0.429506
[36]	training's binary_logloss: 0.245969	valid_1's binary_logloss: 0.425777
[37]	training's binary_logloss: 0.24145	valid_1's binary_logloss: 0.425065
[38]	training's binary_logloss: 0.237223	valid_1's binary_logloss: 0.423375
[39]	training's binary_logloss: 0.233457	valid_1's binary_logloss: 0.42279
[40]	training's binary_logloss: 0.229837	valid_1's binary_logloss: 0.421586
[41]	training's binary_logloss: 0.2258	valid_1's binary_logloss: 0.419546
[42]	training's binary_logloss: 0.222053	valid_1's binary_logloss: 0.420543
[43]	training's binary_logloss: 0.218142	valid_1's binary_logloss: 0.419648
[44]	training's binary_logloss: 0.214406	valid_1's binary_logloss: 0.417376
[45]	training's binary_logloss: 0.21062	valid_1's binary_logloss: 0.417219
[46]	training's binary_logloss: 0.207693	valid_1's binary_logloss: 0.418382
[47]	training's binary_logloss: 0.204459	valid_1's binary_logloss: 0.420574
[48]	training's binary_logloss: 0.201661	valid_1's binary_logloss: 0.420458
[49]	training's binary_logloss: 0.198652	valid_1's binary_logloss: 0.420256
[50]	training's binary_logloss: 0.195849	valid_1's binary_logloss: 0.41788
[51]	training's binary_logloss: 0.192828	valid_1's binary_logloss: 0.419856
[52]	training's binary_logloss: 0.189455	valid_1's binary_logloss: 0.419239
[53]	training's binary_logloss: 0.186862	valid_1's binary_logloss: 0.418061
[54]	training's binary_logloss: 0.184144	valid_1's binary_logloss: 0.420203
[55]	training's binary_logloss: 0.18186	valid_1's binary_logloss: 0.419781
[56]	training's binary_logloss: 0.179336	valid_1's binary_logloss: 0.418251
[57]	training's binary_logloss: 0.176953	valid_1's binary_logloss: 0.418373
[58]	training's binary_logloss: 0.174188	valid_1's binary_logloss: 0.421177
[59]	training's binary_logloss: 0.171624	valid_1's binary_logloss: 0.422029
[60]	training's binary_logloss: 0.169554	valid_1's binary_logloss: 0.421043
[61]	training's binary_logloss: 0.167043	valid_1's binary_logloss: 0.420784
[62]	training's binary_logloss: 0.164732	valid_1's binary_logloss: 0.421378
[63]	training's binary_logloss: 0.162674	valid_1's binary_logloss: 0.421023
[64]	training's binary_logloss: 0.161026	valid_1's binary_logloss: 0.422021
[65]	training's binary_logloss: 0.159152	valid_1's binary_logloss: 0.423376
[66]	training's binary_logloss: 0.157098	valid_1's binary_logloss: 0.423112
[67]	training's binary_logloss: 0.154923	valid_1's binary_logloss: 0.424078
[68]	training's binary_logloss: 0.152742	valid_1's binary_logloss: 0.423512
[69]	training's binary_logloss: 0.150701	valid_1's binary_logloss: 0.422217
[70]	training's binary_logloss: 0.149009	valid_1's binary_logloss: 0.420999
[71]	training's binary_logloss: 0.147453	valid_1's binary_logloss: 0.421606
[72]	training's binary_logloss: 0.145442	valid_1's binary_logloss: 0.4223
[73]	training's binary_logloss: 0.143639	valid_1's binary_logloss: 0.421754
[74]	training's binary_logloss: 0.14174	valid_1's binary_logloss: 0.421546
[75]	training's binary_logloss: 0.13988	valid_1's binary_logloss: 0.423675
[76]	training's binary_logloss: 0.138371	valid_1's binary_logloss: 0.423968
[77]	training's binary_logloss: 0.136794	valid_1's binary_logloss: 0.424537
[78]	training's binary_logloss: 0.134842	valid_1's binary_logloss: 0.425823
[79]	training's binary_logloss: 0.132775	valid_1's binary_logloss: 0.424314
[80]	training's binary_logloss: 0.131154	valid_1's binary_logloss: 0.42698
train classification report
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       439
           1       0.99      0.95      0.97       273

    accuracy                           0.98       712
   macro avg       0.98      0.97      0.97       712
weighted avg       0.98      0.98      0.98       712

************************************************************
test classification report
              precision    recall  f1-score   support

           0       0.83      0.93      0.88       110
           1       0.86      0.70      0.77        69

    accuracy                           0.84       179
   macro avg       0.84      0.81      0.82       179
weighted avg       0.84      0.84      0.83       179
</code></pre> 
<h3><a id="SHAP_256"></a>SHAP值的常规用法</h3> 
<pre><code class="prism language-python">!pip install shap
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> shap
shap<span class="token punctuation">.</span>initjs<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Collecting shap
  Downloading shap-0.40.0-cp37-cp37m-manylinux2010_x86_64.whl (564 kB)
[K     |████████████████████████████████| 564 kB 3.6 MB/s 
[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.1)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)
Collecting slicer==0.0.7
  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)
Requirement already satisfied: packaging&gt;20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)
Requirement already satisfied: tqdm&gt;4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)
Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;20.9-&gt;shap) (3.0.6)
Requirement already satisfied: llvmlite&lt;0.35,&gt;=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (0.34.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (57.4.0)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;shap) (1.15.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (3.0.0)
Installing collected packages: slicer, shap
Successfully installed shap-0.40.0 slicer-0.0.7
</code></pre> 
<p><img src="https://images2.imgbox.com/10/97/TMIZU9uR_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment">#如果数据量大，这个运行的会非常慢</span>
explainer <span class="token operator">=</span> shap<span class="token punctuation">.</span>TreeExplainer<span class="token punctuation">(</span>clf<span class="token punctuation">)</span>
shap_values <span class="token operator">=</span> explainer<span class="token punctuation">.</span>shap_values<span class="token punctuation">(</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#获取shap value</span>
np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>shap_values<span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment">#看一下shap value的dim</span>
</code></pre> 
<pre><code>(2, 712, 9)
</code></pre> 
<p>shap值是一个三维的数据。一个样本有两个shap值。</p> 
<p>第一个维度控制的是选择哪个类别的shap值，第一个维度是0表示0（negative）类，第一个维度是1表示1（positive）类。</p> 
<p>后面两个维度就是每个样本和每个特征的shap值。</p> 
<pre><code class="prism language-python"><span class="token punctuation">(</span>shap_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token operator">-</span><span class="token number">1</span><span class="token operator">*</span> shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>True
</code></pre> 
<p>可以看到0类的shap值和1类的shap值是相反的</p> 
<h4><a id="shap_319"></a>单个样本的shap值</h4> 
<p>可能的应用场景：</p> 
<ul><li>分析bad case：分析分错样本和分对的样本差异</li><li>业务向的分析：例如，在流失场景中分析用户流失的具体原因</li></ul> 
<p>我们以看第一个样本的正类的shap值为例</p> 
<pre><code class="prism language-python">train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>T
</code></pre> 
<pre><code>Pclass        3.0000
Sex           1.0000
Age          20.0000
SibSp         1.0000
Parch         1.0000
Ticket      187.0000
Fare         15.7417
Cabin       147.0000
Embarked      0.0000
Name: 622, dtype: float64
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#查看单个样本的特征贡献的第一种方法</span>
shap<span class="token punctuation">.</span>initjs<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment"># colab需要在每个cell上运行这个命令，如果你是jupyter notebook或jupyter lab可以把这行注释掉</span>
shap<span class="token punctuation">.</span>plots<span class="token punctuation">.</span>force<span class="token punctuation">(</span>explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/4d/73/aIWgzued_o.png" alt="在这里插入图片描述"></p> 
<p>上面的图表示的是： 对一个样本来说，各个特征是如何把预测值从base value推到f(x)(最终的输出值)的。说明了各个特征的贡献。红色的表示向正向（往右）推动预测值；蓝色的表示向正负（往左）推动预测值的。每个特征图块的大小表示shap值的大小。base value是指的模型对训练集的所有样本的（这个参考资料中都没有明确说明 这个是我试出来的）预测值的均值。对于回归问题就是均值，如果对于分类问题是每个类别的均值。是<code>explainer.expected_value</code>的值。</p> 
<pre><code class="prism language-python"><span class="token comment">#看一下base value</span>
explainer<span class="token punctuation">.</span>expected_value
</code></pre> 
<pre><code>[0.908824118858436, -0.908824118858436]
</code></pre> 
<p>因为是分类问题，所以explainer.expected_value有两个值，第一个是0类预测均值，第二个是1类的均值。 SHAP对于xgboost和lightgbm取的是对数几率转换. 还有个问题需要注意下</p> 
<pre><code class="prism language-python">y_train_prob <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'shap base value:'</span><span class="token punctuation">,</span> explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">' 取log的预测值的均值：'</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_train_prob<span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_train_prob<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>shap base value: -0.908824118858436  取log的预测值的均值： -0.9088241188584363
</code></pre> 
<p>可以看到上面的结果，shap的base value和取log的预测值的均值是基本相等的。 如果看的是test的shap 取log的预测值就会和base value有明显差异。</p> 
<pre><code class="prism language-python"><span class="token comment">#查看单个样本的特征贡献的第二种方法</span>
shap<span class="token punctuation">.</span>plots<span class="token punctuation">.</span>_waterfall<span class="token punctuation">.</span>waterfall_legacy<span class="token punctuation">(</span>explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/b1/1d/gxT9Fg5P_o.png" alt="在这里插入图片描述"></p> 
<p>这个图的意思跟<code>shap.plots.force()</code>方法是一样的，但是我感觉看起来更加的直观。</p> 
<p>这个方法是替代<code>shap.plots.waterfall()</code>和<code>shap.plots.waterfall()</code>方法的。 这俩方法会报错。</p> 
<pre><code class="prism language-python"><span class="token comment">#查看单个样本的特征贡献的第三种方法</span>
shap<span class="token punctuation">.</span>bar_plot<span class="token punctuation">(</span>shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/4a/92/fTMw6PYW_o.png" alt="在这里插入图片描述"><br> 这个图跟前面两个是很相似的。但是没有标记base value和f(x)(最终的预测值)</p> 
<h4><a id="shap_394"></a>多个样本的shap值</h4> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>initjs<span class="token punctuation">(</span><span class="token punctuation">)</span>
shap<span class="token punctuation">.</span>force_plot<span class="token punctuation">(</span>explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#我们看下训练集所有样本的特征贡献情况</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/1e/9f/hu4uzuQ3_o.jpg" alt="在这里插入图片描述"></p> 
<p>这个图是训练集的所有样本的特征贡献情况，用鼠标华东可以看每一个样本的情况。</p> 
<p>横坐标：可以按照多种指标将样本排序，包括： 样本的相似性（就是把相似的样本排在一起），样本输出结果，原始样本顺序，各个特征值；</p> 
<p>纵坐标：可以按照最终的预测值以及各个各种的贡献值排序</p> 
<h4><a id="_410"></a>模型整体情况（特征重要性）</h4> 
<p>可能的应用场景：</p> 
<ul><li>分析模型的特征，帮助特征筛选和特征工程</li><li>模型异常时分析是否有特征穿越</li><li>业务分析： 例如，在流失场景中分析，哪些因素是用户流失的主要原因</li></ul> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>summary_plot<span class="token punctuation">(</span>shap_values<span class="token punctuation">,</span> train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>plot_type<span class="token operator">=</span><span class="token string">"bar"</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/49/b7/XpFzEH3w_o.png" alt="在这里插入图片描述"></p> 
<p>这既是利用shap值做的特征重要性的图。 这个是每个样本的0类和1类的shap值分别取绝对值再求平均得到的。</p> 
<p>这里分别展示了0类和1类的特征重要性。通过上面的分析知道，0类的shap值和1类的shap值的绝对值是一样的。所以理论上只看一个就行了。</p> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>summary_plot<span class="token punctuation">(</span>shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>plot_type<span class="token operator">=</span><span class="token string">"bar"</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/04/98/A4zUJxQq_o.png" alt="在这里插入图片描述"></p> 
<p>这个是我们经常用到的特征重要性。</p> 
<p>这个的计算方式和上面是一样的，只不过只取了1类的shap值。</p> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>summary_plot<span class="token punctuation">(</span>shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/3e/bf/vfnKUYd0_o.png" alt="在这里插入图片描述"></p> 
<p>这个可以看作是特征重要性的细致版本。这里为每个样本绘制其每个特征的SHAP值，这可以更好地理解整体模式，并允许发现预测异常值。每一行代表一个特征，横坐标为SHAP值。一个点代表一个样本，颜色表示特征值(红色高，蓝色低)。</p> 
<p>例如：性别（Sex）为例，Sex=1的shap值要小于Sex=0的shap值。联系到这个问题可以分析出来，Sex=0（即性别是female）更容易活下来（Survivied=1）。同理发现 乘客等级越低（Pclass值越大，shap值越小，越难以活下来。</p> 
<h4><a id="_451"></a>单个特征与预测结果的关系</h4> 
<p>可能的应用场景：</p> 
<ul><li>分析连续特征与预测的关系（是否有线性和非线性的关系），帮助连续特征离散化</li></ul> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>dependence_plot<span class="token punctuation">(</span><span class="token string">'Age'</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>interaction_index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e9/4b/70N0jHVj_o.png" alt="在这里插入图片描述"></p> 
<p>如图，横坐标是特征（Age）的值，纵坐标是对应的shap值，整体的趋势是先下降后升高的。这说明小孩子和老人更容易活下来。</p> 
<h4><a id="_466"></a>多个特征与预测结果的关系</h4> 
<p>可能的应用场景：</p> 
<ul><li>分析特征组合与预测的关系，判断两个特征是否有可能组成更好的特征</li></ul> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>dependence_plot<span class="token punctuation">(</span><span class="token string">'Age'</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> train<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>interaction_index<span class="token operator">=</span><span class="token string">'Pclass'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/7d/da/vRiD0dqj_o.png" alt="在这里插入图片描述"></p> 
<p>如图，横坐标是特征（Age）的值，纵坐标是对应的shap值，颜色的深浅代表Pclass。</p> 
<p>从图中可以看出来，在乘客级别较低的地方，年纪大的人更容易活下来。</p> 
<h4><a id="_483"></a>其他</h4> 
<p>SHAP不仅仅有TreeExplainer，还有其他的Explainer：</p> 
<ul><li>TreeExplainer : 适合XGBoost, LightGBM, CatBoost以及scikit-learn models里的树模型</li><li>DeepExplainer (DEEP SHAP) : 适合TensorFlow and Keras models的模型</li><li>GradientExplainer : 适合TensorFlow and Keras models的模型</li><li>KernelExplainer: 适合任何的model</li></ul> 
<h4><a id="SHAP_493"></a>深度学习使用SHAP</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
all_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'shap_tutorial/train_titantic.csv'</span><span class="token punctuation">)</span>

<span class="token comment">#删去暂时不要的列</span>
all_data<span class="token punctuation">.</span>drop<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'PassengerId'</span><span class="token punctuation">,</span><span class="token string">'Name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment">#填充缺失值</span>
all_data<span class="token punctuation">[</span><span class="token string">'Age'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
all_data<span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">'UNK'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
all_data<span class="token punctuation">[</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token string">'UNK'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment">#把Sex，Ticket，Cabin和Embarked做一个lebel encoding</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> LabelEncoder
cate_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Sex'</span><span class="token punctuation">,</span><span class="token string">'Ticket'</span><span class="token punctuation">,</span><span class="token string">'Cabin'</span><span class="token punctuation">,</span><span class="token string">'Embarked'</span><span class="token punctuation">]</span>
cate_features <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
cate_cnt <span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
<span class="token keyword">for</span> cc <span class="token keyword">in</span> cate_cols<span class="token punctuation">:</span>
    enc <span class="token operator">=</span> LabelEncoder<span class="token punctuation">(</span><span class="token punctuation">)</span>
    all_data<span class="token punctuation">[</span>cc<span class="token punctuation">]</span> <span class="token operator">=</span> enc<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>all_data<span class="token punctuation">[</span>cc<span class="token punctuation">]</span><span class="token punctuation">)</span>
    cate_cnt<span class="token punctuation">[</span>cc<span class="token punctuation">]</span> <span class="token operator">=</span> all_data<span class="token punctuation">[</span>cc<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

cate_cnt<span class="token punctuation">[</span><span class="token string">'Parch'</span><span class="token punctuation">]</span> <span class="token operator">=</span> all_data<span class="token punctuation">[</span><span class="token string">'Parch'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
cate_cnt<span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">]</span> <span class="token operator">=</span> all_data<span class="token punctuation">[</span><span class="token string">'Pclass'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
cate_cnt<span class="token punctuation">[</span><span class="token string">'SibSp'</span><span class="token punctuation">]</span> <span class="token operator">=</span> all_data<span class="token punctuation">[</span><span class="token string">'SibSp'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python">cate_cnt
</code></pre> 
<pre><code>{'Cabin': 147,
 'Embarked': 3,
 'Parch': 6,
 'Pclass': 3,
 'Sex': 1,
 'SibSp': 8,
 'Ticket': 680}
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#拆分下训练集和测试集</span>
use_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Cabin'</span><span class="token punctuation">,</span><span class="token string">'Embarked'</span><span class="token punctuation">,</span><span class="token string">'Parch'</span><span class="token punctuation">,</span><span class="token string">'Pclass'</span><span class="token punctuation">,</span><span class="token string">'Sex'</span><span class="token punctuation">,</span><span class="token string">'SibSp'</span><span class="token punctuation">,</span><span class="token string">'Ticket'</span><span class="token punctuation">]</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
y <span class="token operator">=</span> all_data<span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span>
X <span class="token operator">=</span> all_data<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
X<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Survived'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>__version__<span class="token punctuation">)</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> Input
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras <span class="token keyword">import</span> Model

<span class="token keyword">def</span> <span class="token function">mlp</span><span class="token punctuation">(</span>train<span class="token punctuation">,</span> use_cols<span class="token punctuation">)</span><span class="token punctuation">:</span>
    input_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    emb_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> c <span class="token keyword">in</span> train<span class="token punctuation">.</span>columns<span class="token punctuation">:</span>
        input_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Input<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name<span class="token operator">=</span>c<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> c <span class="token keyword">in</span> use_cols<span class="token punctuation">:</span>
            <span class="token comment">#需要做embedding</span>
            emb_feature <span class="token operator">=</span> Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>Embedding<span class="token punctuation">(</span>input_dim<span class="token operator">=</span>train<span class="token punctuation">[</span>c<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> output_dim<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">(</span>input_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            emb_feature <span class="token operator">=</span> input_list<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        emb_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>emb_feature<span class="token punctuation">)</span>
    <span class="token comment">#concate all input</span>
    all_in <span class="token operator">=</span> Concatenate<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>emb_list<span class="token punctuation">)</span>
    hidden <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span>activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>all_in<span class="token punctuation">)</span>
    hidden <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>hidden<span class="token punctuation">)</span>
    hidden <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>hidden<span class="token punctuation">)</span>
    y <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>hidden<span class="token punctuation">)</span>
    <span class="token comment">#model</span>
    model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>input_list<span class="token punctuation">,</span> outputs<span class="token operator">=</span><span class="token punctuation">[</span>y<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model
</code></pre> 
<pre><code>2.7.0
</code></pre> 
<pre><code class="prism language-python">model <span class="token operator">=</span> mlp<span class="token punctuation">(</span>X<span class="token punctuation">,</span> use_cols<span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'binary_crossentropy'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">,</span>metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'acc'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span><span class="token punctuation">[</span>X_train<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> X_train<span class="token punctuation">.</span>columns<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">18</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">[</span>X_test<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> X_test<span class="token punctuation">.</span>columns<span class="token punctuation">]</span><span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Epoch 1/18
23/23 [==============================] - 4s 26ms/step - loss: 1.4307 - acc: 0.4789 - val_loss: 0.7328 - val_acc: 0.6536
Epoch 2/18
23/23 [==============================] - 0s 8ms/step - loss: 0.6792 - acc: 0.6362 - val_loss: 0.6359 - val_acc: 0.6704
Epoch 3/18
23/23 [==============================] - 0s 9ms/step - loss: 0.6378 - acc: 0.6657 - val_loss: 0.6211 - val_acc: 0.6760
Epoch 4/18
23/23 [==============================] - 0s 11ms/step - loss: 0.6203 - acc: 0.6924 - val_loss: 0.6124 - val_acc: 0.6927
Epoch 5/18
23/23 [==============================] - 0s 10ms/step - loss: 0.6074 - acc: 0.6882 - val_loss: 0.6106 - val_acc: 0.7039
Epoch 6/18
23/23 [==============================] - 0s 12ms/step - loss: 0.5984 - acc: 0.6924 - val_loss: 0.6007 - val_acc: 0.7151
Epoch 7/18
23/23 [==============================] - 0s 12ms/step - loss: 0.5701 - acc: 0.7233 - val_loss: 0.5816 - val_acc: 0.7207
Epoch 8/18
23/23 [==============================] - 0s 14ms/step - loss: 0.5453 - acc: 0.7374 - val_loss: 0.5581 - val_acc: 0.7542
Epoch 9/18
23/23 [==============================] - 0s 9ms/step - loss: 0.5228 - acc: 0.7556 - val_loss: 0.5418 - val_acc: 0.7039
Epoch 10/18
23/23 [==============================] - 0s 7ms/step - loss: 0.4760 - acc: 0.7921 - val_loss: 0.5150 - val_acc: 0.7598
Epoch 11/18
23/23 [==============================] - 0s 7ms/step - loss: 0.4496 - acc: 0.8076 - val_loss: 0.4834 - val_acc: 0.8156
Epoch 12/18
23/23 [==============================] - 0s 10ms/step - loss: 0.4187 - acc: 0.8371 - val_loss: 0.4999 - val_acc: 0.7821
Epoch 13/18
23/23 [==============================] - 0s 12ms/step - loss: 0.3951 - acc: 0.8581 - val_loss: 0.4879 - val_acc: 0.8045
Epoch 14/18
23/23 [==============================] - 0s 10ms/step - loss: 0.3624 - acc: 0.8736 - val_loss: 0.4686 - val_acc: 0.8101
Epoch 15/18
23/23 [==============================] - 0s 13ms/step - loss: 0.3317 - acc: 0.8862 - val_loss: 0.4619 - val_acc: 0.8436
Epoch 16/18
23/23 [==============================] - 0s 11ms/step - loss: 0.2931 - acc: 0.9059 - val_loss: 0.4536 - val_acc: 0.8212
Epoch 17/18
23/23 [==============================] - 0s 9ms/step - loss: 0.2752 - acc: 0.9157 - val_loss: 0.4332 - val_acc: 0.8492
Epoch 18/18
23/23 [==============================] - 0s 11ms/step - loss: 0.2314 - acc: 0.9382 - val_loss: 0.4477 - val_acc: 0.8492

&lt;keras.callbacks.History at 0x7f47edcbd9d0&gt;
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">from</span> sklearn <span class="token keyword">import</span> metrics
ytrain_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>X_train<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> X_train<span class="token punctuation">.</span>columns<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
ytest_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>where<span class="token punctuation">(</span>model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>X_test<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> X_test<span class="token punctuation">.</span>columns<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">&gt;=</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train classification report"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>y_train<span class="token punctuation">,</span> ytrain_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'*'</span><span class="token operator">*</span><span class="token number">60</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"test classification report"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> ytest_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>train classification report
              precision    recall  f1-score   support

           0       0.91      0.99      0.95       437
           1       0.97      0.84      0.90       275

    accuracy                           0.93       712
   macro avg       0.94      0.91      0.92       712
weighted avg       0.93      0.93      0.93       712

************************************************************
test classification report
              precision    recall  f1-score   support

           0       0.85      0.93      0.89       112
           1       0.86      0.72      0.78        67

    accuracy                           0.85       179
   macro avg       0.85      0.82      0.83       179
weighted avg       0.85      0.85      0.85       179
</code></pre> 
<pre><code class="prism language-python">!pip install shap
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">"ignore"</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> shap
shap<span class="token punctuation">.</span>initjs<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (0.40.0)
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)
Requirement already satisfied: packaging&gt;20.9 in /usr/local/lib/python3.7/dist-packages (from shap) (21.3)
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)
Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (1.0.1)
Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap) (0.0.7)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)
Requirement already satisfied: tqdm&gt;4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.62.3)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging&gt;20.9-&gt;shap) (3.0.6)
Requirement already satisfied: llvmlite&lt;0.35,&gt;=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (0.34.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba-&gt;shap) (57.4.0)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;shap) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas-&gt;shap) (1.15.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (1.1.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn-&gt;shap) (3.0.0)
</code></pre> 
<p><img src="https://images2.imgbox.com/f7/ab/jyzCrhho_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token comment">#这个Explainer非常的慢，大概需要运行3分钟。如果数据量更大，时间会更长。这个比TreeExplainer慢很多。</span>
explainer <span class="token operator">=</span> shap<span class="token punctuation">.</span>KernelExplainer<span class="token punctuation">(</span>f<span class="token punctuation">,</span> X_train<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#用十个样本去评估，如果用所有的数据，会很慢</span>
shap_values <span class="token operator">=</span> explainer<span class="token punctuation">.</span>shap_values<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span> <span class="token comment">#获取shap value</span>
np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>shap_values<span class="token punctuation">)</span><span class="token punctuation">.</span>shape <span class="token comment">#看一下shap value的dim</span>
</code></pre> 
<pre><code>  100%|          | 0/712 [00:00&lt;?, ?it/s]
(712, 9)
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Survived '</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code>Pclass        3.0000
Sex           1.0000
Age          29.0000
SibSp         1.0000
Parch         0.0000
Ticket      315.0000
Fare          7.0458
Cabin       147.0000
Embarked      2.0000
Name: 477, dtype: float64
Survived  0
</code></pre> 
<p>注意这里是2维的</p> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>initjs<span class="token punctuation">(</span><span class="token punctuation">)</span>
shap<span class="token punctuation">.</span>force_plot<span class="token punctuation">(</span>explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">,</span> shap_values<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_train<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/d9/e8/WCjdbDuR_o.jpg" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python">y_train_prob <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span>X_train<span class="token punctuation">[</span>c<span class="token punctuation">]</span> <span class="token keyword">for</span> c <span class="token keyword">in</span> X_train<span class="token punctuation">.</span>columns<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'shap base value:'</span><span class="token punctuation">,</span>explainer<span class="token punctuation">.</span>expected_value<span class="token punctuation">,</span> <span class="token string">' mean of prediction: '</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>y_train_prob<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment">#上面的Explainer用了多少数据去评估，base value就是多少个样本的预测值的平均</span>
</code></pre> 
<pre><code>shap base value: 0.1138872653245926  mean of prediction:  0.113887265
</code></pre> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>summary_plot<span class="token punctuation">(</span>shap_values<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span>plot_type<span class="token operator">=</span><span class="token string">"bar"</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/8d/21/etjgfZ0c_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>dependence_plot<span class="token punctuation">(</span><span class="token string">'Age'</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span>interaction_index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/e9/f9/WPyg0Bg7_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python">shap<span class="token punctuation">.</span>dependence_plot<span class="token punctuation">(</span><span class="token string">'Age'</span><span class="token punctuation">,</span> shap_values<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span>interaction_index<span class="token operator">=</span><span class="token string">'Pclass'</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/04/4c/MARA1WHm_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Reference_751"></a>Reference</h3> 
<ul><li> <p><a href="https://shap.readthedocs.io/en/latest/index.html" rel="nofollow">SHAP python包的官网，看看例子就行</a></p> </li><li> <p><a href="https://github.com/slundberg/shap">SHAP的github，这个也是看看例子就行，有的是老的包的语法</a></p> </li><li> <p><a href="https://zhuanlan.zhihu.com/p/106320452" rel="nofollow">SHAP介绍，可以看实战演示部分</a></p> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d4b1fc1dee3268fa9537e4e363b3f0b2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">手把手教你安装JDK8~</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6d46c194ad3df0cfa3549cc29d1147be/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Hackmyvm综合靶机 | Driftingblues-4</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>