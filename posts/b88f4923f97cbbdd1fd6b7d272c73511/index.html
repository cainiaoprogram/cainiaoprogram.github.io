<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试" />
<meta property="og:description" content="【Kafka-3.x-教程】专栏：
【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门
【Kafka-3.x-教程】-【二】Kafka-生产者-Producer
【Kafka-3.x-教程】-【三】Kafka-Broker、Kafka-Kraft
【Kafka-3.x-教程】-【四】Kafka-消费者-Consumer
【Kafka-3.x-教程】-【五】Kafka-监控-Eagle
【Kafka-3.x-教程】-【六】Kafka 外部系统集成 【Flume、Flink、SpringBoot、Spark】
【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试
【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试 1）Kafka 硬件配置选择1.1.场景说明1.2.服务器台数选择1.3.磁盘选择1.4.内存选择1.5.CPU 选择1.6.网络选择 2）Kafka 生产者2.1.Kafka 生产者核心参数配置2.2.生产者如何提高吞吐量2.3.数据可靠性2.4.数据去重2.5.数据有序2.6.数据乱序 3）Kafka Broker3.1.Broker 核心参数配置3.2.服役新节点/退役旧节点3.3.增加分区3.4.增加副本因子3.5.手动调整分区副本存储3.6.Leader Partition 负载平衡3.7.自动创建主题 4）Kafka 消费者4.1.Kafka 消费者核心参数配置4.2.消费者再平衡4.3.指定 Offset 消费4.4.指定时间消费4.5.消费者事务4.6.消费者如何提高吞吐量 5）Kafka 总体5.1.如何提升吞吐量5.2.数据精准一次5.3.合理设置分区数5.4.单条日志大于1m5.5.服务器挂了 6）Kafka 压测6.1.Kafka Producer 压力测试6.2.Kafka Consumer 压力测试 1）Kafka 硬件配置选择 1.1.场景说明 100 万日活，每人每天 100 条日志，每天总共的日志条数是 100 万 * 100 条 = 1 亿条。
1 亿/24 小时/60 分/60 秒 = 1150 条/每秒钟。
每条日志大小：0.5k - 2k（取 1k）。
1150 条/每秒钟 * 1k ≈ 1m/s 。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b88f4923f97cbbdd1fd6b7d272c73511/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T16:36:18+08:00" />
<meta property="article:modified_time" content="2024-01-10T16:36:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>【Kafka-3.x-教程】专栏：</p> 
<p><a href="https://blog.csdn.net/weixin_53543905/article/details/135337489">【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135344331">【Kafka-3.x-教程】-【二】Kafka-生产者-Producer</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135406229">【Kafka-3.x-教程】-【三】Kafka-Broker、Kafka-Kraft</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135456078">【Kafka-3.x-教程】-【四】Kafka-消费者-Consumer</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135472163">【Kafka-3.x-教程】-【五】Kafka-监控-Eagle</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135475378">【Kafka-3.x-教程】-【六】Kafka 外部系统集成 【Flume、Flink、SpringBoot、Spark】</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135479341">【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试</a></p> 
<p></p> 
<div class="toc"> 
 <h4>【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试</h4> 
 <ul><li><a href="#1Kafka__12" rel="nofollow">1）Kafka 硬件配置选择</a></li><li><ul><li><a href="#11_13" rel="nofollow">1.1.场景说明</a></li><li><a href="#12_26" rel="nofollow">1.2.服务器台数选择</a></li><li><a href="#13_30" rel="nofollow">1.3.磁盘选择</a></li><li><a href="#14_41" rel="nofollow">1.4.内存选择</a></li><li><a href="#15CPU__157" rel="nofollow">1.5.CPU 选择</a></li><li><a href="#16_167" rel="nofollow">1.6.网络选择</a></li></ul> 
  </li><li><a href="#2Kafka__175" rel="nofollow">2）Kafka 生产者</a></li><li><ul><li><a href="#21Kafka__190" rel="nofollow">2.1.Kafka 生产者核心参数配置</a></li><li><a href="#22_200" rel="nofollow">2.2.生产者如何提高吞吐量</a></li><li><a href="#23_206" rel="nofollow">2.3.数据可靠性</a></li><li><a href="#24_211" rel="nofollow">2.4.数据去重</a></li><li><a href="#25_233" rel="nofollow">2.5.数据有序</a></li><li><a href="#26_237" rel="nofollow">2.6.数据乱序</a></li></ul> 
  </li><li><a href="#3Kafka_Broker_241" rel="nofollow">3）Kafka Broker</a></li><li><ul><li><a href="#31Broker__243" rel="nofollow">3.1.Broker 核心参数配置</a></li><li><a href="#32_252" rel="nofollow">3.2.服役新节点/退役旧节点</a></li><li><a href="#33_285" rel="nofollow">3.3.增加分区</a></li><li><a href="#34_293" rel="nofollow">3.4.增加副本因子</a></li><li><a href="#35_318" rel="nofollow">3.5.手动调整分区副本存储</a></li><li><a href="#36Leader_Partition__342" rel="nofollow">3.6.Leader Partition 负载平衡</a></li><li><a href="#37_346" rel="nofollow">3.7.自动创建主题</a></li></ul> 
  </li><li><a href="#4Kafka__362" rel="nofollow">4）Kafka 消费者</a></li><li><ul><li><a href="#41Kafka__365" rel="nofollow">4.1.Kafka 消费者核心参数配置</a></li><li><a href="#42_376" rel="nofollow">4.2.消费者再平衡</a></li><li><a href="#43_Offset__379" rel="nofollow">4.3.指定 Offset 消费</a></li><li><a href="#44_385" rel="nofollow">4.4.指定时间消费</a></li><li><a href="#45_393" rel="nofollow">4.5.消费者事务</a></li><li><a href="#46_395" rel="nofollow">4.6.消费者如何提高吞吐量</a></li></ul> 
  </li><li><a href="#5Kafka__404" rel="nofollow">5）Kafka 总体</a></li><li><ul><li><a href="#51_406" rel="nofollow">5.1.如何提升吞吐量</a></li><li><a href="#52_429" rel="nofollow">5.2.数据精准一次</a></li><li><a href="#53_443" rel="nofollow">5.3.合理设置分区数</a></li><li><a href="#541m_461" rel="nofollow">5.4.单条日志大于1m</a></li><li><a href="#55_465" rel="nofollow">5.5.服务器挂了</a></li></ul> 
  </li><li><a href="#6Kafka__476" rel="nofollow">6）Kafka 压测</a></li><li><ul><li><a href="#61Kafka_Producer__486" rel="nofollow">6.1.Kafka Producer 压力测试</a></li><li><a href="#62Kafka_Consumer__710" rel="nofollow">6.2.Kafka Consumer 压力测试</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1Kafka__12"></a>1）Kafka 硬件配置选择</h2> 
<h3><a id="11_13"></a>1.1.场景说明</h3> 
<p>100 万日活，每人每天 100 条日志，每天总共的日志条数是 100 万 * 100 条 = 1 亿条。</p> 
<p>1 亿/24 小时/60 分/60 秒 = 1150 条/每秒钟。</p> 
<p>每条日志大小：0.5k - 2k（取 1k）。</p> 
<p>1150 条/每秒钟 * 1k ≈ 1m/s 。</p> 
<p>高峰期每秒钟：1150 条 * 20 倍 = 23000 条。</p> 
<p>每秒多少数据量：20MB/s。</p> 
<h3><a id="12_26"></a>1.2.服务器台数选择</h3> 
<p>服务器台数 = 2 * （生产者峰值生产速率 * 副本 / 100） + 1 = 2 * （20m/s * 2 / 100） + 1 = 3 台</p> 
<p>建议 3 台服务器。</p> 
<h3><a id="13_30"></a>1.3.磁盘选择</h3> 
<p>kafka 底层主要是顺序写，固态硬盘和机械硬盘的顺序写速度差不多。</p> 
<p>建议选择普通的机械硬盘。</p> 
<p>每天总数据量：1 亿条 * 1k ≈ 100g</p> 
<p>100g * 副本 2 * 保存时间 3 天 / 0.7 ≈ 1T。</p> 
<p>建议三台服务器硬盘总大小，大于等于 1T。</p> 
<h3><a id="14_41"></a>1.4.内存选择</h3> 
<p>Kafka 内存组成：堆内存 + 页缓存</p> 
<p>1、Kafka 堆内存建议每个节点：10g ~ 15g</p> 
<p>在 kafka-server-start.sh 中修改</p> 
<pre><code class="prism language-shell"><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"x<span class="token variable">$KAFKA_HEAP_OPTS</span>"</span> <span class="token operator">=</span> <span class="token string">"x"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>
 <span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">"-Xmx10G -Xms10G"</span>
<span class="token keyword">fi</span>
</code></pre> 
<p>（1）查看 Kafka 进程号</p> 
<pre><code class="prism language-shell">jps

<span class="token number">2321</span> Kafka
<span class="token number">5255</span> Jps
<span class="token number">1931</span> QuorumPeerMain
</code></pre> 
<p>（2）根据 Kafka 进程号，查看 Kafka 的 GC 情况</p> 
<pre><code class="prism language-shell">jstat <span class="token parameter variable">-gc</span> <span class="token number">2321</span> 1s <span class="token number">10</span>

S0C  S1C  S0U   S1U     EC       EU       OC       OU       MC     MU      CCSC  CCSU  YGC YGCT FGC FGCT  GCT 
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">60416.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">60416.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">60416.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">60416.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">60416.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">61440.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">61440.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">61440.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">61440.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
<span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">0.0</span> <span class="token number">7168.0</span> <span class="token number">103424.0</span> <span class="token number">61440.0</span> <span class="token number">1986560.0</span> <span class="token number">148433.5</span> <span class="token number">52092.0</span> <span class="token number">46656.1</span> <span class="token number">6780.0</span> <span class="token number">6202.2</span> <span class="token number">13</span> <span class="token number">0.531</span> <span class="token number">0</span> <span class="token number">0.000</span> <span class="token number">0.531</span>
</code></pre> 
<p>参数说明：</p> 
<ul><li>S0C：第一个幸存区的大小；</li><li>S1C：第二个幸存区的大小</li><li>S0U：第一个幸存区的使用大小；</li><li>S1U：第二个幸存区的使用大小</li><li>EC：伊甸园区的大小；</li><li>EU：伊甸园区的使用大小</li><li>OC：老年代大小；</li><li>OU：老年代使用大小</li><li>MC：方法区大小；</li><li>MU：方法区使用大小</li><li>CCSC:压缩类空间大小；</li><li>CCSU:压缩类空间使用大小</li><li>YGC：年轻代垃圾回收次数；</li><li>YGCT：年轻代垃圾回收消耗时间</li><li>FGC：老年代垃圾回收次数；</li><li>FGCT：老年代垃圾回收消耗时间</li><li>GCT：垃圾回收消耗总时间；</li></ul> 
<p>（3）根据 Kafka 进程号，查看 Kafka 的堆内存</p> 
<pre><code class="prism language-shell">jmap <span class="token parameter variable">-heap</span> <span class="token number">2321</span>

Attaching to process ID <span class="token number">2321</span>, please wait<span class="token punctuation">..</span>.
Debugger attached successfully.
Server compiler detected.
JVM version is <span class="token number">25.212</span>-b10
using thread-local object allocation.
Garbage-First <span class="token punctuation">(</span>G1<span class="token punctuation">)</span> GC with <span class="token number">8</span> thread<span class="token punctuation">(</span>s<span class="token punctuation">)</span>
Heap Configuration:
 MinHeapFreeRatio <span class="token operator">=</span> <span class="token number">40</span>
 MaxHeapFreeRatio <span class="token operator">=</span> <span class="token number">70</span>
 MaxHeapSize <span class="token operator">=</span> <span class="token number">2147483648</span> <span class="token punctuation">(</span><span class="token number">2048</span>.0MB<span class="token punctuation">)</span>
 NewSize <span class="token operator">=</span> <span class="token number">1363144</span> <span class="token punctuation">(</span><span class="token number">1</span>.2999954223632812MB<span class="token punctuation">)</span>
 MaxNewSize <span class="token operator">=</span> <span class="token number">1287651328</span> <span class="token punctuation">(</span><span class="token number">1228</span>.0MB<span class="token punctuation">)</span>
 OldSize <span class="token operator">=</span> <span class="token number">5452592</span> <span class="token punctuation">(</span><span class="token number">5</span>.1999969482421875MB<span class="token punctuation">)</span>
 NewRatio <span class="token operator">=</span> <span class="token number">2</span>
 SurvivorRatio <span class="token operator">=</span> <span class="token number">8</span>
 MetaspaceSize <span class="token operator">=</span> <span class="token number">21807104</span> <span class="token punctuation">(</span><span class="token number">20</span>.796875MB<span class="token punctuation">)</span>
 CompressedClassSpaceSize <span class="token operator">=</span> <span class="token number">1073741824</span> <span class="token punctuation">(</span><span class="token number">1024</span>.0MB<span class="token punctuation">)</span>
 MaxMetaspaceSize <span class="token operator">=</span> <span class="token number">17592186044415</span> MB
 G1HeapRegionSize <span class="token operator">=</span> <span class="token number">1048576</span> <span class="token punctuation">(</span><span class="token number">1</span>.0MB<span class="token punctuation">)</span>
Heap Usage:
G1 Heap:
 regions <span class="token operator">=</span> <span class="token number">2048</span>
 capacity <span class="token operator">=</span> <span class="token number">2147483648</span> <span class="token punctuation">(</span><span class="token number">2048</span>.0MB<span class="token punctuation">)</span>
 used <span class="token operator">=</span> <span class="token number">246367744</span> <span class="token punctuation">(</span><span class="token number">234</span>.95458984375MB<span class="token punctuation">)</span>
 <span class="token function">free</span> <span class="token operator">=</span> <span class="token number">1901115904</span> <span class="token punctuation">(</span><span class="token number">1813</span>.04541015625MB<span class="token punctuation">)</span>
 <span class="token number">11.472392082214355</span>% used
G1 Young Generation:
Eden Space:
 regions <span class="token operator">=</span> <span class="token number">83</span>
 capacity <span class="token operator">=</span> <span class="token number">105906176</span> <span class="token punctuation">(</span><span class="token number">101</span>.0MB<span class="token punctuation">)</span>
 used <span class="token operator">=</span> <span class="token number">87031808</span> <span class="token punctuation">(</span><span class="token number">83</span>.0MB<span class="token punctuation">)</span>
 <span class="token function">free</span> <span class="token operator">=</span> <span class="token number">18874368</span> <span class="token punctuation">(</span><span class="token number">18</span>.0MB<span class="token punctuation">)</span>
 <span class="token number">82.17821782178218</span>% used
Survivor Space:
 regions <span class="token operator">=</span> <span class="token number">7</span>
 capacity <span class="token operator">=</span> <span class="token number">7340032</span> <span class="token punctuation">(</span><span class="token number">7</span>.0MB<span class="token punctuation">)</span>
 used <span class="token operator">=</span> <span class="token number">7340032</span> <span class="token punctuation">(</span><span class="token number">7</span>.0MB<span class="token punctuation">)</span>
 <span class="token function">free</span> <span class="token operator">=</span> <span class="token number">0</span> <span class="token punctuation">(</span><span class="token number">0</span>.0MB<span class="token punctuation">)</span>
 <span class="token number">100.0</span>% used
G1 Old Generation:
 regions <span class="token operator">=</span> <span class="token number">147</span>
 capacity <span class="token operator">=</span> <span class="token number">2034237440</span> <span class="token punctuation">(</span><span class="token number">1940</span>.0MB<span class="token punctuation">)</span>
 used <span class="token operator">=</span> <span class="token number">151995904</span> <span class="token punctuation">(</span><span class="token number">144</span>.95458984375MB<span class="token punctuation">)</span>
 <span class="token function">free</span> <span class="token operator">=</span> <span class="token number">1882241536</span> <span class="token punctuation">(</span><span class="token number">1795</span>.04541015625MB<span class="token punctuation">)</span>
 <span class="token number">7.471886074420103</span>% used
<span class="token number">13364</span> interned Strings occupying <span class="token number">1449608</span> bytes.
</code></pre> 
<p>2、页缓存：页缓存是 Linux 系统服务器的内存。我们只需要保证 1 个 segment（1g）中 25%的数据在内存中就好。</p> 
<p>每个节点页缓存大小 =（分区数 * 1g * 25%）/ 节点数。例如 10 个分区，页缓存大小 =（10 * 1g * 25%）/ 3 ≈ 1g</p> 
<p>建议服务器内存大于等于 11G。</p> 
<h3><a id="15CPU__157"></a>1.5.CPU 选择</h3> 
<p>num.io.threads = 8 负责写磁盘的线程数，整个参数值要占总核数的 50%。</p> 
<p>num.replica.fetchers = 1 副本拉取线程数，这个参数占总核数的 50%的 1/3。</p> 
<p>num.network.threads = 3 数据传输线程数，这个参数占总核数的 50%的 2/3。</p> 
<p>建议 32 个 cpu core。</p> 
<h3><a id="16_167"></a>1.6.网络选择</h3> 
<p>网络带宽 = 峰值吞吐量 ≈ 20MB/s 选择千兆网卡即可。</p> 
<p>100Mbps 单位是 bit；10M/s 单位是 byte ; 1byte = 8bit，100Mbps/8 = 12.5M/s。</p> 
<p>一般百兆的网卡（100Mbps ）、千兆的网卡（1000Mbps）、万兆的网卡（10000Mbps）。</p> 
<h2><a id="2Kafka__175"></a>2）Kafka 生产者</h2> 
<p>详见：<a href="https://blog.csdn.net/weixin_53543905/article/details/135344331">【Kafka-3.x-教程】-【二】Kafka-生产者-Producer</a></p> 
<pre><code>3.1.1 Updating Broker Configs
From Kafka version 1.1 onwards, some of the broker configs can be 
updated without restarting the broker. See the Dynamic Update Mode 
column in Broker Configs for the update mode of each broker config.
read-only: Requires a broker restart for update
per-broker: May be updated dynamically for each broker
cluster-wide: May be updated dynamically as a cluster-wide default.
May also be updated as a per-broker value for testing.
</code></pre> 
<h3><a id="21Kafka__190"></a>2.1.Kafka 生产者核心参数配置</h3> 
<p><img src="https://images2.imgbox.com/a1/1c/otUDJrXn_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/e5/49/8b0b4bZz_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/fd/ee/Aef9fPcw_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/91/9b/FXmeGDQV_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/8f/c6/NvHVLuyc_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_200"></a>2.2.生产者如何提高吞吐量</h3> 
<p><img src="https://images2.imgbox.com/d1/9f/JsE4iWli_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23_206"></a>2.3.数据可靠性</h3> 
<p><img src="https://images2.imgbox.com/43/3e/puijUtif_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24_211"></a>2.4.数据去重</h3> 
<p>1、参数配置<br> <img src="https://images2.imgbox.com/d0/76/24SkEOZD_o.png" alt="在这里插入图片描述"></p> 
<p>2、Kafka 的事务一共有如下 5 个 API</p> 
<pre><code class="prism language-java"><span class="token comment">// 1 初始化事务</span>
<span class="token keyword">void</span> <span class="token function">initTransactions</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment">// 2 开启事务</span>
<span class="token keyword">void</span> <span class="token function">beginTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
<span class="token comment">// 3 在事务内提交已经消费的偏移量（主要用于消费者）</span>
<span class="token keyword">void</span> <span class="token function">sendOffsetsToTransaction</span><span class="token punctuation">(</span><span class="token class-name">Map</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">OffsetAndMetadata</span><span class="token punctuation">&gt;</span></span> offsets<span class="token punctuation">,</span>
 <span class="token class-name">String</span> consumerGroupId<span class="token punctuation">)</span> <span class="token keyword">throws</span> 
<span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
<span class="token comment">// 4 提交事务</span>
<span class="token keyword">void</span> <span class="token function">commitTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
<span class="token comment">// 5 放弃事务（类似于回滚事务的操作）</span>
<span class="token keyword">void</span> <span class="token function">abortTransaction</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">ProducerFencedException</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="25_233"></a>2.5.数据有序</h3> 
<p>单分区内，有序（有条件的，不能乱序）；多分区，分区与分区间无序；</p> 
<h3><a id="26_237"></a>2.6.数据乱序</h3> 
<p><img src="https://images2.imgbox.com/6e/bc/5DOtVez6_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3Kafka_Broker_241"></a>3）Kafka Broker</h2> 
<p>详见：<a href="https://blog.csdn.net/weixin_53543905/article/details/135406229">【Kafka-3.x-教程】-【三】Kafka-Broker、Kafka-Kraft</a></p> 
<h3><a id="31Broker__243"></a>3.1.Broker 核心参数配置</h3> 
<p><img src="https://images2.imgbox.com/53/b5/ww8Z9KnV_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/e4/b8/gSwWFUnE_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/45/03/ONfHF66I_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="32_252"></a>3.2.服役新节点/退役旧节点</h3> 
<p>1、创建一个要均衡的主题。</p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> topics-to-move.json 

<span class="token punctuation">{<!-- --></span>
 <span class="token string">"topics"</span><span class="token builtin class-name">:</span> <span class="token punctuation">[</span>
 <span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span> <span class="token string">"first"</span><span class="token punctuation">}</span>
 <span class="token punctuation">]</span>,
 <span class="token string">"version"</span><span class="token builtin class-name">:</span> <span class="token number">1</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>2、生成一个负载均衡的计划。</p> 
<pre><code class="prism language-shell">bin/kafka-reassign-partitions.sh --
bootstrap-server hadoop102:9092 --topics-to-move-json-file 
topics-to-move.json --broker-list <span class="token string">"0,1,2,3"</span> <span class="token parameter variable">--generate</span>
</code></pre> 
<p>3、创建副本存储计划（所有副本存储在 broker0、broker1、broker2、broker3 中）。</p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> increase-replication-factor.json
</code></pre> 
<p>4、执行副本存储计划。</p> 
<pre><code class="prism language-shell">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increasereplication-factor.json <span class="token parameter variable">--execute</span>
</code></pre> 
<p>5、验证副本存储计划。</p> 
<pre><code class="prism language-shell">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increasereplication-factor.json <span class="token parameter variable">--verify</span>
</code></pre> 
<h3><a id="33_285"></a>3.3.增加分区</h3> 
<p>修改分区数（注意：分区数只能增加，不能减少）</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--alter</span> <span class="token parameter variable">--topic</span> first <span class="token parameter variable">--partitions</span> <span class="token number">3</span>
</code></pre> 
<h3><a id="34_293"></a>3.4.增加副本因子</h3> 
<p>1、创建 topic</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> --replication-factor <span class="token number">1</span> <span class="token parameter variable">--topic</span> four
</code></pre> 
<p>2、手动增加副本存储</p> 
<p>（1）创建副本存储计划（所有副本都指定存储在 broker0、broker1、broker2 中）。</p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> increase-replication-factor.json

<span class="token comment">#输入如下内容：</span>
<span class="token punctuation">{<!-- --></span><span class="token string">"version"</span>:1,<span class="token string">"partitions"</span>:<span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span><span class="token string">"four"</span>,<span class="token string">"partition"</span>:0,<span class="token string">"replica
s"</span>:<span class="token punctuation">[</span><span class="token number">0,1</span>,2<span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span><span class="token string">"four"</span>,<span class="token string">"partition"</span>:1,<span class="token string">"replicas"</span>:<span class="token punctuation">[</span><span class="token number">0,1</span>,2<span class="token punctuation">]</span><span class="token punctuation">}</span>,<span class="token punctuation">{<!-- --></span><span class="token string">"t
opic"</span><span class="token builtin class-name">:</span><span class="token string">"four"</span>,<span class="token string">"partition"</span>:2,<span class="token string">"replicas"</span>:<span class="token punctuation">[</span><span class="token number">0,1</span>,2<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> 
<p>（2）执行副本存储计划。</p> 
<pre><code class="prism language-shell">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increasereplication-factor.json <span class="token parameter variable">--execute</span>
</code></pre> 
<h3><a id="35_318"></a>3.5.手动调整分区副本存储</h3> 
<p>1、创建副本存储计划（所有副本都指定存储在 broker0、broker1 中）。</p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> increase-replication-factor.json

<span class="token comment">#输入如下内容：</span>
<span class="token punctuation">{<!-- --></span>
<span class="token string">"version"</span>:1,
<span class="token string">"partitions"</span>:<span class="token punctuation">[</span><span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span><span class="token string">"three"</span>,<span class="token string">"partition"</span>:0,<span class="token string">"replicas"</span>:<span class="token punctuation">[</span><span class="token number">0,1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,
<span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span><span class="token string">"three"</span>,<span class="token string">"partition"</span>:1,<span class="token string">"replicas"</span>:<span class="token punctuation">[</span><span class="token number">0,1</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,
<span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span><span class="token string">"three"</span>,<span class="token string">"partition"</span>:2,<span class="token string">"replicas"</span>:<span class="token punctuation">[</span><span class="token number">1,0</span><span class="token punctuation">]</span><span class="token punctuation">}</span>,
<span class="token punctuation">{<!-- --></span><span class="token string">"topic"</span><span class="token builtin class-name">:</span><span class="token string">"three"</span>,<span class="token string">"partition"</span>:3,<span class="token string">"replicas"</span>:<span class="token punctuation">[</span><span class="token number">1,0</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">]</span>
<span class="token punctuation">}</span>
</code></pre> 
<pre><code class="prism language-shell">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increasereplication-factor.json <span class="token parameter variable">--execute</span>
</code></pre> 
<p>3、验证副本存储计划。</p> 
<pre><code class="prism language-shell">bin/kafka-reassign-partitions.sh --bootstrap-server hadoop102:9092 --reassignment-json-file increasereplication-factor.json <span class="token parameter variable">--verify</span>
</code></pre> 
<h3><a id="36Leader_Partition__342"></a>3.6.Leader Partition 负载平衡</h3> 
<p><img src="https://images2.imgbox.com/26/4b/Gu5nBclF_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="37_346"></a>3.7.自动创建主题</h3> 
<p>如果 broker 端配置参数 <code>auto.create.topics.enable 设置为 true（默认值是 true）</code>，那么当生产者向一个未创建的主题发送消息时，会自动创建一个分区数为 num.partitions（默认值为1）、副本因子为 default.replication.factor（默认值为 1）的主题。除此之外，当一个消费者开始从未知主题中读取消息时，或者当任意一个客户端向未知主题发送元数据请求时，都会自动创建一个相应主题。这种创建主题的方式是非预期的，增加了主题管理和维护的难度。</p> 
<p><code>生产环境建议将该参数设置为 false</code>。</p> 
<p>1、向一个没有提前创建 five 主题发送数据</p> 
<pre><code class="prism language-shell">bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--topic</span> five
<span class="token operator">&gt;</span>hello world
</code></pre> 
<p>2、查看 five 主题的详情</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> five
</code></pre> 
<h2><a id="4Kafka__362"></a>4）Kafka 消费者</h2> 
<p>详见：<a href="https://blog.csdn.net/weixin_53543905/article/details/135456078">【Kafka-3.x-教程】-【四】Kafka-消费者-Consumer</a></p> 
<h3><a id="41Kafka__365"></a>4.1.Kafka 消费者核心参数配置</h3> 
<p><img src="https://images2.imgbox.com/0c/0e/aVBp8Uxi_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/8f/df/9G0AZNcw_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/5e/4e/8nxSBMv8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/39/6c/yAgMaot6_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/54/cf/BO72iudM_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="42_376"></a>4.2.消费者再平衡</h3> 
<p><img src="https://images2.imgbox.com/88/48/LFycioop_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="43_Offset__379"></a>4.3.指定 Offset 消费</h3> 
<pre><code class="prism language-java">kafkaConsumer<span class="token punctuation">.</span><span class="token function">seek</span><span class="token punctuation">(</span>topic<span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="44_385"></a>4.4.指定时间消费</h3> 
<pre><code class="prism language-java"><span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">TopicPartition</span><span class="token punctuation">,</span> <span class="token class-name">Long</span><span class="token punctuation">&gt;</span></span> timestampToSearch <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">HashMap</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
timestampToSearch<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span>topicPartition<span class="token punctuation">,</span> <span class="token class-name">System</span><span class="token punctuation">.</span><span class="token function">currentTimeMillis</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token operator">*</span> <span class="token number">24</span> <span class="token operator">*</span> <span class="token number">3600</span> <span class="token operator">*</span> <span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
kafkaConsumer<span class="token punctuation">.</span><span class="token function">offsetsForTimes</span><span class="token punctuation">(</span>timestampToSearch<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre> 
<h3><a id="45_393"></a>4.5.消费者事务</h3> 
<h3><a id="46_395"></a>4.6.消费者如何提高吞吐量</h3> 
<p>增加分区数；</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--alter</span> <span class="token parameter variable">--topic</span> first <span class="token parameter variable">--partitions</span> <span class="token number">3</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/64/e1/Ynz7n93L_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="5Kafka__404"></a>5）Kafka 总体</h2> 
<h3><a id="51_406"></a>5.1.如何提升吞吐量</h3> 
<p>1、提升生产吞吐量</p> 
<p>（1）<code>buffer.memory</code>：发送消息的缓冲区大小，默认值是 32m，可以增加到 64m。</p> 
<p>（2）<code>batch.size</code>：默认是 16k。如果 batch 设置太小，会导致频繁网络请求，吞吐量下降；如果 batch 太大，会导致一条消息需要等待很久才能被发送出去，增加网络延时。</p> 
<p>（3）<code>linger.ms</code>：这个值默认是 0，意思就是消息必须立即被发送。一般设置一个 5-100 毫秒。如果 linger.ms 设置的太小，会导致频繁网络请求，吞吐量下降；如果 linger.ms 太长，会导致一条消息需要等待很久才能被发送出去，增加网络延时。</p> 
<p>（4）<code>compression.type</code>：默认是 none，不压缩，但是也可以使用 lz4 压缩，效率还是不错的，压缩之后可以减小数据量，提升吞吐量，但是会加大 producer 端的 CPU 开销。</p> 
<p>2、增加分区</p> 
<p>3、消费者提高吞吐量</p> 
<p>（1）调整 <code>fetch.max.bytes</code> 大小，默认是 50m。</p> 
<p>（2）调整 <code>max.poll.records</code> 大小，默认是 500 条。</p> 
<p>4、增加下游消费者处理能力</p> 
<h3><a id="52_429"></a>5.2.数据精准一次</h3> 
<p>1、生产者角度</p> 
<ul><li>acks 设置为 -1 （acks=-1）。</li><li>幂等性（<code>enable.idempotence = true</code>） + 事务 。</li></ul> 
<p>2、broker 服务端角度</p> 
<ul><li>分区副本大于等于 2 （–replication-factor 2）。</li><li>ISR 里应答的最小副本数量大于等于 2 （<code>min.insync.replicas = 2</code>）。</li></ul> 
<p>3、消费者</p> 
<ul><li>事务 + 手动提交 offset （<code>enable.auto.commit = false</code>）。</li><li>消费者输出的目的地必须支持事务（MySQL、Kafka）。</li></ul> 
<h3><a id="53_443"></a>5.3.合理设置分区数</h3> 
<p>1、创建一个只有 1 个分区的 topic。</p> 
<p>2、测试这个 topic 的 producer 吞吐量和 consumer 吞吐量。</p> 
<p>3、假设他们的值分别是 Tp 和 Tc，单位可以是 MB/s。</p> 
<p>4、然后假设总的目标吞吐量是 Tt，那么分区数 = Tt / min（Tp，Tc）。</p> 
<p>例如：producer 吞吐量 = 20m/s；consumer 吞吐量 = 50m/s，期望吞吐量 100m/s；</p> 
<p>分区数 = 100 / 20 = 5 分区</p> 
<p>分区数一般设置为：3-10 个</p> 
<p>分区数不是越多越好，也不是越少越好，需要搭建完集群，进行压测，再灵活调整分区<br> 个数。</p> 
<h3><a id="541m_461"></a>5.4.单条日志大于1m</h3> 
<p><img src="https://images2.imgbox.com/61/45/yDrJyh3X_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="55_465"></a>5.5.服务器挂了</h3> 
<p>在生产环境中，如果某个 Kafka 节点挂掉。正常处理办法：</p> 
<p>1、先尝试重新启动一下，如果能启动正常，那直接解决。</p> 
<p>2、如果重启不行，考虑增加内存、增加 CPU、网络带宽。</p> 
<p>3、如果将 kafka 整个节点误删除，如果副本数大于等于 2，可以按照服役新节点的方式重新服役一个新节点，并执行负载均衡。</p> 
<h2><a id="6Kafka__476"></a>6）Kafka 压测</h2> 
<p>用 Kafka 官方自带的脚本，对 Kafka 进行压测。</p> 
<ul><li> <p>生产者压测：kafka-producer-perf-test.sh</p> </li><li> <p>消费者压测：kafka-consumer-perf-test.sh</p> </li></ul> 
<p><img src="https://images2.imgbox.com/6b/06/HibIxMuu_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="61Kafka_Producer__486"></a>6.1.Kafka Producer 压力测试</h3> 
<p>1、创建一个 test topic，设置为 3 个分区 3 个副本</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrapserver hadoop102:9092 <span class="token parameter variable">--create</span> --replication-factor <span class="token number">3</span> <span class="token parameter variable">--partitions</span> <span class="token number">3</span> <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span>
</code></pre> 
<p>2、在 /opt/module/kafka/bin 目录下面有这两个文件。我们来测试一下</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092batch.size<span class="token operator">=</span><span class="token number">16384</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">0</span>
</code></pre> 
<p>参数说明：</p> 
<ul><li>record-size 是一条信息有多大，单位是字节，本次测试设置为 1k。</li><li>num-records 是总共发送多少条信息，本次测试设置为 100 万条。</li><li>throughput 是每秒多少条信息，设成-1，表示不限流，尽可能快的生产数据，可测<br> 出生产者最大吞吐量。本次实验设置为每秒钟 1 万条。</li><li>producer-props 后面可以配置生产者相关参数，<code>batch.size 配置为 16k</code>。</li></ul> 
<p>输出结果：</p> 
<pre><code>ap.servers=hadoop102:9092,hadoop103:9092,hadoop104:9092 batch.size=16384 
linger.ms=0
37021 records sent, 7401.2 records/sec (7.23 MB/sec), 1136.0 ms avg latency, 
1453.0 ms max latency.
50535 records sent, 10107.0 records/sec (9.87 MB/sec), 1199.5 ms avg 
latency, 1404.0 ms max latency.
47835 records sent, 9567.0 records/sec (9.34 MB/sec), 1350.8 ms avg latency, 
1570.0 ms max latency.
。。。 。。。
42390 records sent, 8444.2 records/sec (8.25 MB/sec), 3372.6 ms avg latency, 
4008.0 ms max latency.
37800 records sent, 7558.5 records/sec (7.38 MB/sec), 4079.7 ms avg latency, 
4758.0 ms max latency.
33570 records sent, 6714.0 records/sec (6.56 MB/sec), 4549.0 ms avg latency, 
5049.0 ms max latency.
1000000 records sent, 9180.713158 records/sec (8.97 MB/sec), 1894.78 ms 
avg latency, 5049.00 ms max latency, 1335 ms 50th, 4128 ms 95th, 4719 ms 
99th, 5030 ms 99.9th.
</code></pre> 
<p>3、调整 batch.size 大小</p> 
<p>（1）batch.size 默认值是 16k。本次实验 batch.size 设置为 32k。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">32768</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">0</span>
</code></pre> 
<p>输出结果：</p> 
<pre><code>49922 records sent, 9978.4 records/sec (9.74 MB/sec), 64.2 ms avg latency, 
340.0 ms max latency.
49940 records sent, 9988.0 records/sec (9.75 MB/sec), 15.3 ms avg latency, 
31.0 ms max latency.
50018 records sent, 10003.6 records/sec (9.77 MB/sec), 16.4 ms avg latency, 
52.0 ms max latency.
。。。 。。。
49960 records sent, 9992.0 records/sec (9.76 MB/sec), 17.2 ms avg latency, 
40.0 ms max latency.
50090 records sent, 10016.0 records/sec (9.78 MB/sec), 16.9 ms avg latency, 
47.0 ms max latency.
1000000 records sent, 9997.600576 records/sec (9.76 MB/sec), 20.20 ms avg 
latency, 340.00 ms max latency, 16 ms 50th, 30 ms 95th, 168 ms 99th, 249 
ms 99.9th.
</code></pre> 
<p>（2）batch.size 默认值是 16k。本次实验 batch.size 设置为 4k。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">0</span>
</code></pre> 
<p>输出结果：</p> 
<pre><code>15598 records sent, 3117.1 records/sec (3.04 MB/sec), 1878.3 ms avg latency, 
3458.0 ms max latency.
17748 records sent, 3549.6 records/sec (3.47 MB/sec), 5072.5 ms avg latency, 
6705.0 ms max latency.
18675 records sent, 3733.5 records/sec (3.65 MB/sec), 6800.9 ms avg latency, 
7052.0 ms max latency.
。。。 。。。
19125 records sent, 3825.0 records/sec (3.74 MB/sec), 6416.5 ms avg latency, 
7023.0 ms max latency.
1000000 records sent, 3660.201531 records/sec (3.57 MB/sec), 6576.68 ms 
avg latency, 7677.00 ms max latency, 6745 ms 50th, 7298 ms 95th, 7507 ms 
99th, 7633 ms 99.9th.
</code></pre> 
<p>4、调整 linger.ms 时间：linger.ms 默认是 0ms。本次实验 linger.ms 设置为 50ms。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">50</span>
</code></pre> 
<p>输出结果：</p> 
<pre><code>16804 records sent, 3360.1 records/sec (3.28 MB/sec), 1841.6 ms avg latency, 
3338.0 ms max latency.
18972 records sent, 3793.6 records/sec (3.70 MB/sec), 4877.7 ms avg latency, 
6453.0 ms max latency.
19269 records sent, 3852.3 records/sec (3.76 MB/sec), 6477.9 ms avg latency, 
6686.0 ms max latency.
。。。 。。。
17073 records sent, 3414.6 records/sec (3.33 MB/sec), 6987.7 ms avg latency, 
7353.0 ms max latency.
19326 records sent, 3865.2 records/sec (3.77 MB/sec), 6756.5 ms avg latency, 
7357.0 ms max latency.
1000000 records sent, 3842.754486 records/sec (3.75 MB/sec), 6272.49 ms 
avg latency, 7437.00 ms max latency, 6308 ms 50th, 6880 ms 95th, 7289 ms 
99th, 7387 ms 99.9th.
</code></pre> 
<p>5、调整压缩方式</p> 
<p>（1）默认的压缩方式是 none。本次实验 compression.type 设置为 snappy。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">50</span> <span class="token assign-left variable">compression.type</span><span class="token operator">=</span>snappy
</code></pre> 
<p>输出结果：</p> 
<pre><code>17244 records sent, 3446.0 records/sec (3.37 MB/sec), 5207.0 ms avg latency, 
6861.0 ms max latency.
18873 records sent, 3774.6 records/sec (3.69 MB/sec), 6865.0 ms avg latency, 
7094.0 ms max latency.
18378 records sent, 3674.1 records/sec (3.59 MB/sec), 6579.2 ms avg latency, 
6738.0 ms max latency.
。。。 。。。
17631 records sent, 3526.2 records/sec (3.44 MB/sec), 6671.3 ms avg latency, 
7566.0 ms max latency.
19116 records sent, 3823.2 records/sec (3.73 MB/sec), 6739.4 ms avg latency, 
7630.0 ms max latency.
1000000 records sent, 3722.925028 records/sec (3.64 MB/sec), 6467.75 ms 
avg latency, 7727.00 ms max latency, 6440 ms 50th, 7308 ms 95th, 7553 ms 
99th, 7665 ms 99.9th.
</code></pre> 
<p>（2）默认的压缩方式是 none。本次实验 compression.type 设置为 zstd。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">50</span> <span class="token assign-left variable">compression.type</span><span class="token operator">=</span>zstd
</code></pre> 
<p>输出结果：</p> 
<pre><code>23820 records sent, 4763.0 records/sec (4.65 MB/sec), 1580.2 ms avg latency, 
2651.0 ms max latency.
29340 records sent, 5868.0 records/sec (5.73 MB/sec), 3666.0 ms avg latency, 
4752.0 ms max latency.
28950 records sent, 5788.8 records/sec (5.65 MB/sec), 5785.2 ms avg latency, 
6865.0 ms max latency.
。。。 。。。
29580 records sent, 5916.0 records/sec (5.78 MB/sec), 6907.6 ms avg latency, 
7432.0 ms max latency.
29925 records sent, 5981.4 records/sec (5.84 MB/sec), 6948.9 ms avg latency, 
7541.0 ms max latency.
1000000 records sent, 5733.583318 records/sec (5.60 MB/sec), 6824.75 ms 
avg latency, 7595.00 ms max latency, 7067 ms 50th, 7400 ms 95th, 7500 ms 
99th, 7552 ms 99.9th.
</code></pre> 
<p>（3）默认的压缩方式是 none。本次实验 compression.type 设置为 gzip。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">50</span> <span class="token assign-left variable">compression.type</span><span class="token operator">=</span>gzip
</code></pre> 
<p>输出结果：</p> 
<pre><code>27170 records sent, 5428.6 records/sec (5.30 MB/sec), 1374.0 ms avg latency, 
2311.0 ms max latency.
31050 records sent, 6210.0 records/sec (6.06 MB/sec), 3183.8 ms avg latency, 
4228.0 ms max latency.
32145 records sent, 6427.7 records/sec (6.28 MB/sec), 5028.1 ms avg latency, 
6042.0 ms max latency.
。。。 。。。
31710 records sent, 6342.0 records/sec (6.19 MB/sec), 6457.1 ms avg latency, 
6777.0 ms max latency.
31755 records sent, 6348.5 records/sec (6.20 MB/sec), 6498.7 ms avg latency, 
6780.0 ms max latency.
32760 records sent, 6548.1 records/sec (6.39 MB/sec), 6375.7 ms avg latency, 
6822.0 ms max latency.
1000000 records sent, 6320.153706 records/sec (6.17 MB/sec), 6155.42 ms 
avg latency, 6943.00 ms max latency, 6437 ms 50th, 6774 ms 95th, 6863 ms 
99th, 6912 ms 99.9th.
</code></pre> 
<p>（4）默认的压缩方式是 none。本次实验 compression.type 设置为 lz4。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">50</span> <span class="token assign-left variable">compression.type</span><span class="token operator">=</span>lz4
</code></pre> 
<p>输出结果：</p> 
<pre><code>16696 records sent, 3339.2 records/sec (3.26 MB/sec), 1924.5 ms avg latency, 
3355.0 ms max latency.
19647 records sent, 3928.6 records/sec (3.84 MB/sec), 4841.5 ms avg latency, 
6320.0 ms max latency.
20142 records sent, 4028.4 records/sec (3.93 MB/sec), 6203.2 ms avg latency, 
6378.0 ms max latency.
。。。 。。。
20130 records sent, 4024.4 records/sec (3.93 MB/sec), 6073.6 ms avg latency, 
6396.0 ms max latency.
19449 records sent, 3889.8 records/sec (3.80 MB/sec), 6195.6 ms avg latency, 
6500.0 ms max latency.
19872 records sent, 3972.8 records/sec (3.88 MB/sec), 6274.5 ms avg latency, 
6565.0 ms max latency.
1000000 records sent, 3956.087430 records/sec (3.86 MB/sec), 6085.62 ms 
avg latency, 6745.00 ms max latency, 6212 ms 50th, 6524 ms 95th, 6610 ms 
99th, 6695 ms 99.9th.
</code></pre> 
<p>6、调整缓存大小：默认生产者端缓存大小 32m。本次实验 buffer.memory 设置为 64m。</p> 
<pre><code class="prism language-shell">bin/kafka-producer-perf-test.sh <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> --record-size <span class="token number">1024</span> --num-records <span class="token number">1000000</span> <span class="token parameter variable">--throughput</span> <span class="token number">10000</span> --producer-props <span class="token assign-left variable">bootstrap.servers</span><span class="token operator">=</span>hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token assign-left variable">batch.size</span><span class="token operator">=</span><span class="token number">4096</span> <span class="token assign-left variable">linger.ms</span><span class="token operator">=</span><span class="token number">50</span> <span class="token assign-left variable">buffer.memory</span><span class="token operator">=</span><span class="token number">67108864</span>
</code></pre> 
<p>输出结果：</p> 
<pre><code>20170 records sent, 4034.0 records/sec (3.94 MB/sec), 1669.5 ms avg latency, 
3040.0 ms max latency.
21996 records sent, 4399.2 records/sec (4.30 MB/sec), 4407.9 ms avg latency, 
5806.0 ms max latency.
22113 records sent, 4422.6 records/sec (4.32 MB/sec), 7189.0 ms avg latency, 
8623.0 ms max latency.
。。。 。。。
19818 records sent, 3963.6 records/sec (3.87 MB/sec), 12416.0 ms avg 
latency, 12847.0 ms max latency.
20331 records sent, 4062.9 records/sec (3.97 MB/sec), 12400.4 ms avg 
latency, 12874.0 ms max latency.
19665 records sent, 3933.0 records/sec (3.84 MB/sec), 12303.9 ms avg 
latency, 12838.0 ms max latency.
1000000 records sent, 4020.100503 records/sec (3.93 MB/sec), 11692.17 ms 
avg latency, 13796.00 ms max latency, 12238 ms 50th, 12949 ms 95th, 13691 
ms 99th, 13766 ms 99.9th.
</code></pre> 
<h3><a id="62Kafka_Consumer__710"></a>6.2.Kafka Consumer 压力测试</h3> 
<p>1、修改 /opt/module/kafka/config/consumer.properties 文件中的一次拉取条数为 500：</p> 
<p>max.poll.records=500</p> 
<p>2、消费 100 万条日志进行压测</p> 
<pre><code class="prism language-shell">bin/kafka-consumer-perf-test.sh --bootstrap-server hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> <span class="token parameter variable">--messages</span> <span class="token number">1000000</span> <span class="token parameter variable">--consumer.config</span> config/consumer.properties
</code></pre> 
<p>参数说明：</p> 
<ul><li>–bootstrap-server 指定 Kafka 集群地址</li><li>–topic 指定 topic 的名称</li><li>–messages 总共要消费的消息个数。本次实验 100 万条。</li></ul> 
<p>输出结果：</p> 
<pre><code>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, 
nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2022-01-20 09:58:26:171, 2022-01-20 09:58:33:321, 977.0166, 136.6457, 
1000465, 139925.1748, 415, 6735, 145.0656, 148547.1418
</code></pre> 
<p>3、一次拉取条数为 2000</p> 
<p>（1）修改/opt/module/kafka/config/consumer.properties 文件中的一次拉取条数为 2000：</p> 
<p>max.poll.records=2000</p> 
<p>（2）再次执行</p> 
<pre><code class="prism language-shell">bin/kafka-consumer-perf-test.sh --broker-list hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> <span class="token parameter variable">--messages</span> <span class="token number">1000000</span> <span class="token parameter variable">--consumer.config</span> config/consumer.properties
</code></pre> 
<p>输出结果：</p> 
<pre><code>start.time, end.time, data.consumed.in.MB, MB.sec, data.consumed.in.nMsg, 
nMsg.sec, rebalance.time.ms, fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2022-01-20 10:18:06:268, 2022-01-20 10:18:12:863, 977.5146, 148.2206, 
1000975, 151777.8620, 358, 6237, 156.7283, 160489.8188
</code></pre> 
<p>4、调整 fetch.max.bytes 大小为 100m</p> 
<p>（1）修改/opt/module/kafka/config/consumer.properties 文件中的拉取一批数据大小 100m：</p> 
<p>fetch.max.bytes=104857600</p> 
<p>（2）再次执行</p> 
<pre><code class="prism language-shell">bin/kafka-consumer-perf-test.sh --broker-list hadoop102:9092,hadoop103:9092,hadoop104:9092 <span class="token parameter variable">--topic</span> <span class="token builtin class-name">test</span> <span class="token parameter variable">--messages</span> <span class="token number">1000000</span> <span class="token parameter variable">--consumer.config</span> config/consumer.properties
</code></pre> 
<p>输出结果：</p> 
<pre><code>start.time, end.time, data.consumed.in.MB, MB.sec, 
data.consumed.in.nMsg, nMsg.sec, rebalance.time.ms, 
fetch.time.ms, fetch.MB.sec, fetch.nMsg.sec
2022-01-20 10:26:13:203, 2022-01-20 10:26:19:662, 977.5146, 
151.3415, 1000975, 154973.6801, 362, 6097, 160.3272, 164175.0041
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3c1339592245ed53f810fed96eb4ec9e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【Kafka-3.x-教程】-【五】Kafka-监控-Eagle</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/01654c5bb1979ad78081b6f73256229a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">cfa一级考生复习经验分享系列（十八）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>