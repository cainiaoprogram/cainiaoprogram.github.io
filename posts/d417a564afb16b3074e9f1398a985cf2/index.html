<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Batch Normalization层的均值和方差的shape? - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Batch Normalization层的均值和方差的shape?" />
<meta property="og:description" content="BN层的均值和标准差的shape是什么样子的？ 首先，BN的工作原理是： # t is the incoming tensor of shape [B, H, W, C] # mean and stddev are computed along 0 axis and have shape [H, W, C] mean = mean(t, axis=0) stddev = stddev(t, axis=0) for i in 0..B-1: out[i,:,:,:] = norm(t[i,:,:,:], mean, stddev) 可以看到，均值和方差是[H, W, C]的样子，只在B这个维度上做gather。
但是，Conv层有一个特点，那就是权重共享，卷积核的shape是[h,w,c]的，这并不是全连接的（不是每个像素都有单独的权重），这个卷积核会划过整个图像，因此，图像处理中的BN操作，也就没有理由针对每个像素单独设计，而是也采用和卷积类似的共享参数方法： # t is still the incoming tensor of shape [B, H, W, C] # but mean and stddev are computed along (0, 1, 2) axes and have just [C] shape mean = mean(t, axis=(0, 1, 2)) stddev = stddev(t, axis=(0, 1, 2)) for i in 0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d417a564afb16b3074e9f1398a985cf2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-02-24T21:15:03+08:00" />
<meta property="article:modified_time" content="2022-02-24T21:15:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Batch Normalization层的均值和方差的shape?</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h5><a id="BNshape_0"></a>BN层的均值和标准差的shape是什么样子的？</h5> 
<h6><a id="BN_1"></a>首先，BN的工作原理是：</h6> 
<pre><code># t is the incoming tensor of shape [B, H, W, C]
# mean and stddev are computed along 0 axis and have shape [H, W, C]
mean = mean(t, axis=0)
stddev = stddev(t, axis=0)
for i in 0..B-1:
  out[i,:,:,:] = norm(t[i,:,:,:], mean, stddev)
</code></pre> 
<p>可以看到，均值和方差是[H, W, C]的样子，只在B这个维度上做gather。</p> 
<h6><a id="ConvshapehwcBN_13"></a>但是，Conv层有一个特点，那就是权重共享，卷积核的shape是[h,w,c]的，这并不是全连接的（不是每个像素都有单独的权重），这个卷积核会划过整个图像，因此，图像处理中的BN操作，也就没有理由针对每个像素单独设计，而是也采用和卷积类似的共享参数方法：</h6> 
<pre><code># t is still the incoming tensor of shape [B, H, W, C]
# but mean and stddev are computed along (0, 1, 2) axes and have just [C] shape
mean = mean(t, axis=(0, 1, 2))
stddev = stddev(t, axis=(0, 1, 2))
for i in 0..B-1, x in 0..H-1, y in 0..W-1:
  out[i,x,y,:] = norm(t[i,x,y,:], mean, stddev)
</code></pre> 
<p>换句话说，均值和方差的形状实际上是[C]这样的，[B,H,W]三个维度均需要gather。</p> 
<p><em>以上结论来自<a href="https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network" rel="nofollow">stack-overflow</a>.</em></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5d411e29acf59c832498a9358db64fa6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">在“信创”大背景下 美信时代的业务思路</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/29d4e351d26b867fe5b358809c5afc40/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">力扣网页PC端无法进入（问题得到解决）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>