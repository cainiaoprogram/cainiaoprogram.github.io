<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>2020人体姿态估计综述（Part4：3D Human Pose Estimation from Image） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="2020人体姿态估计综述（Part4：3D Human Pose Estimation from Image）" />
<meta property="og:description" content="承接之前的博文：
A 2020 Human Pose Estimation Review （Part1：2D Single Person）
A 2020 Human Pose Estimation Review （Part2：2D Top-Down Multi-Person Pose Estimation）
A 2020 Human Pose Estimation Review （Part3：2D Bottom-Up Multi-Person Pose Estimation）
目录
1 Human Pose Estimation
2 2D Single-Person Pose Estimation
3 2D Top-Down Multi-Person Pose Estimation
4 2D Bottom-Up Multi-Person Pose Estimation
5 3D Human Pose Estimation from Image
5.1 3D Human Pose Estimation
5.2 3D Human Pose Estimation from Monocular Images with Deep Convolutional Neural, ACCV2014" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4fd1d85591fdcd8ce815b0b7c9303ea7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-08-24T11:07:51+08:00" />
<meta property="article:modified_time" content="2020-08-24T11:07:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2020人体姿态估计综述（Part4：3D Human Pose Estimation from Image）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>承接之前的博文：<br> <a href="https://blog.csdn.net/qq_42974561/article/details/108025390">A 2020 Human Pose Estimation Review （Part1：2D Single Person）</a><br> <a href="https://blog.csdn.net/qq_42974561/article/details/108030150">A 2020 Human Pose Estimation Review （Part2：2D Top-Down Multi-Person Pose Estimation）</a><br> <a href="https://blog.csdn.net/qq_42974561/article/details/108091561">A 2020 Human Pose Estimation Review （Part3：2D Bottom-Up Multi-Person Pose Estimation）</a></p> 
<p><strong>目录</strong><br> <a href="https://blog.csdn.net/qq_42974561/article/details/108025390"><strong>1 Human Pose Estimation</strong></a><br> <a href="https://blog.csdn.net/qq_42974561/article/details/108025390"><strong>2 2D Single-Person Pose Estimation</strong></a><br> <a href="https://blog.csdn.net/qq_42974561/article/details/108030150"><strong>3 2D Top-Down Multi-Person Pose Estimation</strong></a><br> <a href="https://blog.csdn.net/qq_42974561/article/details/108091561"><strong>4 2D Bottom-Up Multi-Person Pose Estimation</strong></a></p> 
<p><strong>5 3D Human Pose Estimation from Image</strong><br>   5.1 3D Human Pose Estimation<br>   5.2 3D Human Pose Estimation from Monocular Images with Deep Convolutional Neural, ACCV2014<br>   5.3 Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose, CVPR2017<br>   5.4 Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach, ICCV2017<br>   5.5 A simple yet effective baseline for 3d human pose estimation, ICCV2017<br>   5.6 Semantic Graph Convolutional Networks for 3D Human Pose Regression, CVPR2019<br>   5.7 RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose   Estimation, CVPR2019<br>   5.8 3D Human Pose Estimation from Image小结</p> 
<p><a href="https://blog.csdn.net/qq_42974561/article/details/108237580"><strong>6 3D Human Pose Estimation from Video</strong></a></p> 
<h3><a id="5_3D_Human_Pose_Estimation_from_Image_24"></a>5 3D Human Pose Estimation from Image</h3> 
<h4><a id="51_3D_Human_Pose_Estimation_26"></a>5.1 3D Human Pose Estimation</h4> 
<p>3D人体姿态估计的任务是，给定一张图片或者video，预测出每个人的关节点位置(x,y,z)。通常这个3D坐标是相机坐标系下的位置。3D人体姿态估计可以有多种多样的分类方式，我这里使用输入来进行分类，基于image的3D估计以及基于Video的3D估计，前者侧重于将主流的方法，后者侧重于讲如何利用视频序列的时间、空间信息。对于多视角的输入，暂时不做特别精细的分类。<br> 现有的3D估计主要有两种思路，一种是直接从image预测3D姿态；另一种是两步走的方式，先预测2D姿态，然后将2D姿态lifting到3D姿态。相比较而言，第二种方法降低了整个任务的复杂性，网络比较容易学习2D到3D的映射，同时2D的姿态估计已经比较成熟了，同时这种方法也比较好引入reprojection做半监督，因此这种方法比较主流。<br> 3D姿态估计主要面临的难点以及可能的解决方法有这些：<br> （1）多个不同的3D姿态可以指向同一个2D姿态，导致了2D向3D推理时的模糊性：利用时域信息或者多视角<br> （2）人体姿态充满多样性：应用人体动力学先验做为限制<br> （3）人体关节的自遮挡、人与人之间的相互遮挡导致精准预测更加困难：多视角、关节点轨迹追踪<br> （4）缺少 in-the-wild 的3D数据集，模型泛化能力差：新数据集、弱监督学习</p> 
<h4><a id="52_3D_Human_Pose_Estimation_from_Monocular_Images_with_Deep_Convolutional_Neural_ACCV2014_35"></a>5.2 3D Human Pose Estimation from Monocular Images with Deep Convolutional Neural, ACCV2014</h4> 
<p><img src="https://images2.imgbox.com/9d/75/vwoWkDLz_o.png" alt="在这里插入图片描述"></p> 
<p>14年的文章了，非常早。文章结构是一个多任务结构，两个支路公用前面的特征。一个支路做Joint point regression task，就是计算各个关节点和他们对应的父关节点的相对位置，这个父子关系是根据人体骨骼模型构建的；Joint point detection task，这里构建了很多window，目的是判断某个window是否包含某个关节点i。<br> 回归任务很好理解，只是这里回归与父亲关节点的相对位置。而检测任务是这么定义的，设Bi是第i个关节点在2D的输入图像中的位置，检测分支最后输出的图像里，一个点可以对应原图的一个区域，这个点的值可以表示为关节点Bi是否在这个window里，越接近1，表示越有可能在。<br> 训练方法是比较特殊的，先单独训练检测任务，然后把检测分支block掉，保留特征提取部分，然后再单独训回归任务。</p> 
<h4><a id="53_CoarsetoFine_Volumetric_Prediction_for_SingleImage_3D_Human_Pose_CVPR2017_42"></a>5.3 Coarse-to-Fine Volumetric Prediction for Single-Image 3D Human Pose, CVPR2017</h4> 
<p>可以理解为3D上的heatmap + hourglass，采用的是lifting的方式，先预测2D pose，然后lifting到3D，当然仔细去看的话，会发现不是标准的lifting。网络是一个multi-stage的形式，针对最难预测的z，进行Coarse-to-Fine的处理。每个关节点的volume不再赘述了，就是一个3D的heatmap。<br> <img src="https://images2.imgbox.com/49/df/wVPnSZjR_o.png" alt="在这里插入图片描述"></p> 
<p>来看一下对于z的Coarse-to-Fine，作者对于每个stage生成的heatmap，设置了不同的通道数，对于每个关节点，分别对每个stage设置通道数为{1,2,4,8,16,32,64}，这样可以不断提升z的分辨率。最后形成的heatmap是三维的，作者设置的最高分辨率的为64×645×64，这样根据每个点的置信度，可以反推出关节点位置在3D空间中的位置，其实就是一个三维的heatmap。这里提一下，为什么我把它归为lifting的方式呢，因为第一个stage输出的heatmap，是64×64×1的，相当于是2D的heatmap，可以看成stage1只是去预测2D pose，后面随着每个关节点heatmap通道数的增加，才是去预测3D pose。<br> 在每个satge的连接上，作者不仅让前一个stage输出的heatmap作为输入，还把前一个stage预测得到的2D pose也作为输入，绿色的是2D heatmap，经过卷积处理后，和上个stage的输出相加，一起作为下一stage的输入，同时这里也设置了对于2D heatmap的中间监督，使得反向传播的时候，能更好地训练网络。<br> <img src="https://images2.imgbox.com/fb/de/5Q7dgvMz_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="54_Towards_3D_Human_Pose_Estimation_in_the_Wild_a_Weaklysupervised_Approach_ICCV2017_51"></a>5.4 Towards 3D Human Pose Estimation in the Wild: a Weakly-supervised Approach, ICCV2017</h4> 
<p>采用图像进行3D姿态预测的文章，作者认为直接从2D预测3D姿态具有模糊性，因为一个3D姿态可以对应多个不同的2D姿态。网络结构类似于Hourglass，输入先经过卷积层提取特征，然后过Hourglass预测出2D关节点的heatmap，这些heatmap与hourglass中产生的特征图相加，输入到深度模块进行z的预测。<br> <img src="https://images2.imgbox.com/e5/db/KRUapIY3_o.png" alt="在这里插入图片描述"></p> 
<p>训练过程中，既输入带3D标注的indoor图像，也输入只带2D标注的in-the-wild的图像。对于有3D标注的图像，会从深度估计模块开始反向传播，而对于只有2D标注的，为了能够对其输出的3D姿态进行监督，作者引入了人体动力学的限制作为一个loss。这里用的是人体骨骼相对长度，骨长度之间的比率在人体骨骼中是保持相对固定的，例如，上/下臂具有固定的长度比，左/右肩骨共享相同的长度。我个人觉得，引入动力学限制是非常重要的，但是这篇文章做的还不够，骨骼相对长度只能作为一个软限制，用来避免网络生成一些不合理的预测，而对于只带了2D标注的图像生成的3D姿态，还是需要更好的方法来使得其loss也能优化深度预测部分（例如后面会说到的reprojection）。</p> 
<h4><a id="55_A_simple_yet_effective_baseline_for_3d_human_pose_estimation_ICCV2017_57"></a>5.5 A simple yet effective baseline for 3d human pose estimation, ICCV2017</h4> 
<p>你别看他结构简单，但这篇文章说明了一件事情，就是lifting的方式，不需要非常复杂的结构，两个全连接层就能办大事，能站着把钱挣了！网络以图像作为输入，先用2D检测器得到2D pose，然后再从2D pose提升到3D pose。结构上就直接看图，一目了然，不多说了。<br> <img src="https://images2.imgbox.com/d4/c1/Nr8DhqwI_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="56_Semantic_Graph_Convolutional_Networks_for_3D_Human_Pose_Regression_CVPR2019_62"></a>5.6 Semantic Graph Convolutional Networks for 3D Human Pose Regression, CVPR2019</h4> 
<p>2019CVPR，利用语义图卷积进行 3D人体姿态估计 。 2D姿态坐标的连接方式可以看成是一张图，而图卷积可以 同时对节点特征信息与结构信息进行端对端学习 ，因此用它来学习 2D姿态图到 3D姿态图的映射关系非常合适。<br> 目前GCN的结构局限于卷积滤波器的小接收域和每个节点的共享变换矩阵。 SemGCN的提出一定程度上解决了这些局限性，论文提出了全新的语义图卷积网络，用于处理具有图结构数据的回归任务。 SemGCN学习捕获在图中没有显式表示的语义信息，例如局部和全局节点关系。这些语义关系可以通过端到端训练学习，而不需要额外的监督或手工特征。实验结果表明， SemGCN在使用的参数减少了 90%的情况下，性能仍优于现有的技术水平 。<br> <img src="https://images2.imgbox.com/6d/e2/soV3hUbq_o.png" alt="在这里插入图片描述" width="40%" height="40%"></p> 
<p>SemGCN基于这个公式来做卷积，具体的不再这里多说（因为懒地打公式，具体可以看论文…狗头）。最后的网络结构如下，图像作为输入，通过网络提取特征，然后预测2D pose。2D pose和特征图一起输入到语义图卷积网络，最后生成3D pose。<br> <img src="https://images2.imgbox.com/09/c0/0BIpLmwk_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="57_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_3D_Human_Pose_Estimation_CVPR2019_70"></a>5.7 RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose Estimation, CVPR2019</h4> 
<p>这是我比较喜欢的一篇文章，他的半监督思想是我觉得对于3D标注数据集不足的一种很好的解决方法。文章提出了一种生成对抗的训练方法，利用判别器进行弱监督，由此获得更加精准的3D pose到3D pose的预测结果；同时预测3D pose和相机参数，使得可以进行半监督学习；另外，判别器引入了骨骼长度和运动角度等约束。<br> <img src="https://images2.imgbox.com/d1/eb/sm9jRAj9_o.png" alt="在这里插入图片描述"></p> 
<p>主要包括三个部分，左侧有两个并行的网络，输入2D的坐标，预测出3D pose和相机参数，右上角为判别网络，最后判别是否是真实的3D pose，右下角为反向映射网络，用于将3D转化为2D结果，以进行半监督学习。<br> 先看Pose Generator，结构非常简单，就是两个residual block，每个block有两个全连接层，然后配上残差连接，是模仿A simple yet effective baseline的网络结构。Camera网络预测的是相机参数，这里作者用的是weak perspective，并且认为root joint是在图像中央，因此这个相机参数其实只需要scale参数。相机支路做监督时候，并不是用数据集给的gt的相机参数，而是去用弱投影模型参数K自身满足的一个条件：<br> <img src="https://images2.imgbox.com/c3/94/yRlSaiDC_o.png" alt="在这里插入图片描述"></p> 
<p>右边上支路为判别器模块，判别是否是真实的3D pose，这里结构如图所示，引入了KCS条件，使得判别器可以结合人体动力学知识来判别。右下方是投影模块，根据预测的3D pose和弱投影参数K，可以算出对应的2D pose，以此来做半监督。<br> <img src="https://images2.imgbox.com/77/20/wApX80Ot_o.png" alt="在这里插入图片描述"></p> 
<p>这个网络的设计思路是我很喜欢的，3D标注数据集不够是大家都有的问题，这里用3D到2D的投影来做半监督，可以缓解这个问题。同时将GAN的思想融入工作中，可以使得3D pose生成器泛化性能更好。我个人觉得这个工作还有一些不足，主要是没有做3D的强监督，如果可以一批数据里面，一半用只带2D标注的，用投影去半监督，另一半用有3D标注的，去做强监督，可能效果会更好。</p> 
<h4><a id="58_3D_Human_Pose_Estimation_from_Image_83"></a>5.8 3D Human Pose Estimation from Image小结</h4> 
<p>稍微总结一下基于image的3D姿态估计，可以发现基于image的3D姿态估计还是基于2D的工作的，等到了后面涉及到video时候，才能看出2D和3D方法的区别。现在的主流方法是先用成熟的2D检测器得到2D pose，然后将2D pose提升到3D。lifting网络不需要非常复杂的结构，就能达到很好的性能。<br> 我个人觉得，基于image的3D姿态估计主要研究点在于如何去解决遮挡问题，以及如何使得模型泛化能力更好。前者的话，因为无法利用序列信息，所以需要考虑多视角或者是进一步挖掘图像信息；后者的话，可以采用3D到2D的reprojection来做半监督，同时配上3D的强监督。实话实话，我觉得后面的研究重点还在是序列的预测上，基于image的预测更多的还是基础性工作。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8bb96c566794c0c7966eefaab47fe7d7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">关于映射的一些理解与常见命题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/548efa52069d76291166a07b1fd4c2a4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">初始堆-Xms与最大堆-Xmx设置为相等</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>