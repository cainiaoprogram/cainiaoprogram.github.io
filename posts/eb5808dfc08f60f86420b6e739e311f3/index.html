<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>如何本地部署基于stable-diffusion的AI绘画（jupyter，python实现，详细，附代码） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="如何本地部署基于stable-diffusion的AI绘画（jupyter，python实现，详细，附代码）" />
<meta property="og:description" content="基于stable - diffusion 的本地部署AI绘画教程 自从Stable Diffusion 1.0模型发布以来，“AI文本图片生成”真正的变成普通人也能使用的技术。同时各种国内外AI绘图软件，也不断频繁更新，AI绘画的关注度也越来越高。
以下是本人自己生成出来的一些AI绘图（夹带私货木木枭^ ^）
对应的提示语prompt为：
&#34;a cute portrait of rowlet,anime,warm style,suit , highly detailed, oil painting, concept art, smooth, sharp focus,high quality artwork&#34; 那么如果我们想要本地部署一个真正属于自己的AI绘画模型，需要哪些东西呢。
要完成本次部署，我们需要导入一些包并且用里面封装好的参数来实现相应的功能,从而实现我们要的文字出图的功能.
接下来详细介绍一下大概的步骤。
操作环境：python 3.8.13操作软件：VsCode文件格式：ipynb 需要下载的包在后面会有讲到
1. 连接显卡 !nvidia-smi 首先要让GPU连接到notebook上
单独运行该语句后，成功后会显示如下提示
2. 本地下载transformershe和diffusers包： %pip install diffusers==0.4.0 %pip install transformers scipy ftfy 由于这里是jupyter所以和python 的pip的方式有点不一样
或者通过conda下载也可以
下载成功后会有如上提示
如果后面有
RuntimeError: CUDA error: no kernel image is available for execution on the device
类似这种提示，则说明一般是cuda或者python的版本出了问题
可能是版本不对，一般要求是3.8" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/eb5808dfc08f60f86420b6e739e311f3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-29T13:17:48+08:00" />
<meta property="article:modified_time" content="2023-03-29T13:17:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">如何本地部署基于stable-diffusion的AI绘画（jupyter，python实现，详细，附代码）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="stable__diffusion_AI_0"></a>基于stable - diffusion 的本地部署AI绘画教程</h2> 
<blockquote> 
 <p>自从Stable Diffusion 1.0模型发布以来，“AI文本图片生成”真正的变成普通人也能使用的技术。同时各种国内外AI绘图软件，也不断频繁更新，AI绘画的关注度也越来越高。</p> 
</blockquote> 
<p>以下是本人自己生成出来的一些AI绘图（夹带私货木木枭^ ^）</p> 
<p><img src="https://images2.imgbox.com/92/48/3EyP8hdR_o.jpg" alt="img"></p> 
<p><img src="https://images2.imgbox.com/cd/2b/3xQanV0k_o.png" alt="image-20230328124514865"></p> 
<p>对应的提示语prompt为：</p> 
<pre><code class="prism language-python"><span class="token string">"a cute portrait of rowlet,anime,warm style,suit , highly detailed, oil painting, concept art, smooth, sharp focus,high quality artwork"</span>
</code></pre> 
<hr> 
<p>那么如果我们想要<strong>本地部署一个真正属于自己的AI绘画模型</strong>，需要哪些东西呢。</p> 
<p>要完成本次部署，我们需要导入一些包并且用里面封装好的参数来实现相应的功能,从而实现我们要的文字出图的功能.</p> 
<p>接下来详细介绍一下大概的步骤。</p> 
<table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>操作环境：</td><td>python 3.8.13</td></tr><tr><td>操作软件：</td><td>VsCode</td></tr><tr><td>文件格式：</td><td>ipynb</td></tr></tbody></table> 
<p>需要下载的包在后面会有讲到</p> 
<h3><a id="1__38"></a>1. 连接显卡</h3> 
<pre><code class="prism language-python">!nvidia<span class="token operator">-</span>smi  
</code></pre> 
<p>首先要让GPU连接到notebook上</p> 
<p>单独运行该语句后，成功后会显示如下提示</p> 
<p><img src="https://images2.imgbox.com/27/bd/R9vFq1Ki_o.gif" alt="img"></p> 
<h3><a id="2_transformershediffusers_52"></a>2. 本地下载transformershe和diffusers包：</h3> 
<pre><code class="prism language-python"><span class="token operator">%</span>pip install diffusers<span class="token operator">==</span><span class="token number">0.4</span><span class="token number">.0</span>  
<span class="token operator">%</span>pip install transformers scipy ftfy  
</code></pre> 
<p>由于这里是jupyter所以和python 的pip的方式有点不一样</p> 
<p>或者通过conda下载也可以</p> 
<p><img src="https://images2.imgbox.com/a2/05/JHfB3u4T_o.png" alt="image-20230328125439720"></p> 
<p>下载成功后会有如上提示</p> 
<p>如果后面有</p> 
<p><code>RuntimeError: CUDA error: no kernel image is available for execution on the device</code></p> 
<p>类似这种提示，则说明一般是cuda或者python的版本出了问题</p> 
<p>可能是版本不对，一般要求是3.8</p> 
<h3><a id="3_hugging_faceaccess_token_79"></a>3. 获取hugging face官网的access token：</h3> 
<p>安装好两个包后，就要开始获取用户的权限了，由于stable diffusion的hugging face上面的产品，要使用它的模型的时候需要一个token的申请。</p> 
<p>因此我们看一下如何获得申请</p> 
<pre><code class="prism language-python"><span class="token number">1.</span>	<span class="token keyword">from</span> huggingface_hub <span class="token keyword">import</span> notebook_login  
<span class="token number">2.</span>	  
<span class="token number">3.</span>	notebook_login<span class="token punctuation">(</span><span class="token punctuation">)</span>  
</code></pre> 
<p>这里的代码只有两行</p> 
<p>如果没有安装huggingface_hub这个包的话用conda下载一下就可以了</p> 
<p>也是比较容易的</p> 
<p><code>Conda install huggingface_hub </code></p> 
<p>成功运行后会出现如下内容</p> 
<p><img src="https://images2.imgbox.com/bb/fb/R8K9COah_o.png" alt="image-20230328125645500"></p> 
<p>要拿到这个token需要我们登录hugging face的官网</p> 
<p>注册一个账号，不需要手机号什么的，比较容易注册</p> 
<ul><li> <p>注册成功之后到个人设置这里</p> </li><li> <p><img src="https://images2.imgbox.com/4c/da/gbaD20r4_o.png" alt="image-20230328125725221"></p> </li><li> <p>获取token之后就可以正常运行了</p> </li><li> <p><img src="https://images2.imgbox.com/c6/31/smOgNvvW_o.png" alt="image-20230328125752109"></p> </li></ul> 
<p>成功登录获取之后如上图提示内容</p> 
<h3><a id="4_diffuserspipe_118"></a>4. 获取diffusers数据集并生成pipe管道</h3> 
<p>首先看一下这个的代码</p> 
<pre><code class="prism language-python"><span class="token number">1.</span>	<span class="token keyword">import</span> torch  
<span class="token number">2.</span>	<span class="token comment">#from torch import autocast  </span>
<span class="token number">3.</span>	<span class="token keyword">from</span> diffusers <span class="token keyword">import</span> StableDiffusionPipeline  
<span class="token number">4.</span>	  
<span class="token number">5.</span>	<span class="token comment"># make sure you're logged in with `huggingface-cli login`  </span>
<span class="token number">6.</span>	<span class="token comment">#pipe = StableDiffusionPipeline.from_pretrained("CompVis/stable-diffusion-v1-4", revision="fp16", torch_dtype=torch.float16)    </span>
<span class="token number">7.</span>	pipe <span class="token operator">=</span> StableDiffusionPipeline<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"./stable-diffusion-v1-4"</span><span class="token punctuation">)</span>   
</code></pre> 
<p>这里导入了torch包和之前下载的diffusers包</p> 
<p>进行模型，然后进行模型的加载</p> 
<p>Pipe就是加载成功后获得模型的管道了</p> 
<p>而这一句也是所有代码当中最核心的一句</p> 
<p>这里的<strong>文件路径</strong>是一个模型包</p> 
<p>可以在github或者huggingface上面都有，下载模型包</p> 
<p><a href="https://huggingface.co/CompVis/stable-diffusion-v1-4" rel="nofollow">CompVis/stable-diffusion-v1-4 · Hugging Face</a></p> 
<p>以上是官网链接</p> 
<p><img src="https://images2.imgbox.com/bc/7c/l18FcXNs_o.png" alt="image-20230329010541624"></p> 
<p>整个模型大概10GB（现在可能不止了）</p> 
<p>运行成功后没有提示语出现</p> 
<h4><a id="5pipeGPU_156"></a>5.将pipe管道部署到GPU上运行</h4> 
<p>如果我们使用CPU去跑这个模型，需要等待的时间将会非常非常的长，为了解决这个问题，这里提供了一个方法，可以将pipe管道移动到GPU上面去运行。</p> 
<pre><code class="prism language-python">pipe <span class="token operator">=</span> pipe<span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">"cuda"</span><span class="token punctuation">)</span>
</code></pre> 
<p>但是这里会跟资源的分配有关，本地的电脑如果显卡没有这么强的话，很有可能会失败，例如提示显存不够给予去运算，例如本人的电脑如果开了其他运行程序就很容易出现内存分配不够的问题</p> 
<p>如果<strong>内存不够</strong>建议可以使用谷歌提供的colab云平台来运行自己的服务，谷歌会免费分配一个显卡资源给colab的账号。</p> 
<p>内存不足的时候运行上述代码会有相应的报错，注意看报错内容即可。</p> 
<h4><a id="6_prompt_174"></a>6. 使用prompt生成图片</h4> 
<p>当我们可以正常使用GPU来跑模型之后，就可以正式开始生成我们的图片啦！</p> 
<p>我们只需要简单地输入一个字符串，就可以生成图片</p> 
<pre><code class="prism language-python"><span class="token number">1.</span>	<span class="token comment">#提示语输入内容  </span>
<span class="token number">2.</span>	prompt <span class="token operator">=</span> <span class="token string">"a photograph of an astronaut riding a horse"</span>  
<span class="token number">3.</span>	<span class="token comment">#放入pipe中运行  </span>
<span class="token number">4.</span>	image <span class="token operator">=</span> pipe<span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>   
<span class="token number">5.</span>	  
<span class="token number">6.</span>	  
<span class="token number">7.</span>	<span class="token comment">#直接显示图片  </span>
<span class="token number">8.</span>	image 

</code></pre> 
<p>运行该代码，会出现一个进度条进行等待，运行成功后如下所示。</p> 
<p><img src="https://images2.imgbox.com/da/b7/pWyW7SqJ_o.png" alt="image-20230329084230736"></p> 
<p>上图就是通过stable-diffusion模型生成的图片了</p> 
<p>给出的提示语是“a photograph of an astronauut riding a horse”</p> 
<p>可以看出给出的图片还是比较符合描述语的内容的，同时也有一种荒诞的感觉</p> 
<blockquote> 
 <p>最后：如果想要让画面更加精美，需要给prompt的内容加上更加细节的描述</p> 
 <p>如果自己想不到什么好的英文提示语，可以参考网站<a href="https://lexica.art/" rel="nofollow">Lexica</a></p> 
 <p>这个网站允许用户上传自己的prompt生成的图片</p> 
</blockquote> 
<p><img src="https://images2.imgbox.com/ac/5c/tywoLsJm_o.png" alt="image-20230329084440540"><br> 给出的图片还是比较符合描述语的内容的，同时也有一种荒诞的感觉</p> 
<blockquote> 
 <p>最后：如果想要让画面更加精美，需要给prompt的内容加上更加细节的描述</p> 
 <p>如果自己想不到什么好的英文提示语，可以参考网站<a href="https://lexica.art/" rel="nofollow">Lexica</a></p> 
 <p>这个网站允许用户上传自己的prompt生成的图片</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c4d1f17a4911bae97d174a34b8bc23a9/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Python方法：@staticmethod和@classmethod</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5e66d38a78876dca44133adaf42f9622/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">DPDK 分析，原理以及学习路线</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>