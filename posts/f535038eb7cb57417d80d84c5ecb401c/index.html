<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Python_Scrapy学习笔记（六）】Scrapy框架基本使用流程 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Python_Scrapy学习笔记（六）】Scrapy框架基本使用流程" />
<meta property="og:description" content="Scrapy框架基本使用流程 前言 本文中介绍 Scrapy 框架的基本使用流程，并以抓取汽车之家二手车数据为例进行讲解。
正文 1、Scrapy框架基本使用流程 创建爬虫项目：scrapy startprojecct 项目名
cd到项目文件夹：cd 项目名
创建爬虫文件：scrapy genspider 爬虫文件名 浏览器地址栏中的域名
定义抓取的数据结构：编写 items.py 文件
import scrapy class 项目名item(scrapy.Item): scrapy.Field() price = scrapy.Field() link = scrapy.Field() ... ... 爬虫文件解析提取数据：编写 爬虫文件名.py 文件
import scrapy from ..items import 项目名item class 类名Spider(scrapy.Spider): name = &#34;爬虫文件名&#34; # 爬虫名 allowed_domains = [&#34;浏览器地址栏中的域名&#34;] # 允许爬取的域名：在创建爬虫文件的时候指定的域名 start_urls = [&#34;&#34;] # 第一页的url地址 def parse(self, response): 解析提取数据 item=项目名item() item[&#34;name&#34;]=xxx # 数据交给管道文件处理的方法 yield item # 需要进行跟进的url地址，如何交给调度器入队列 yield scrapy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f535038eb7cb57417d80d84c5ecb401c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-17T15:45:19+08:00" />
<meta property="article:modified_time" content="2023-04-17T15:45:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Python_Scrapy学习笔记（六）】Scrapy框架基本使用流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Scrapy_0"></a>Scrapy框架基本使用流程</h2> 
<h2><a id="_3"></a>前言</h2> 
<p>本文中介绍 Scrapy 框架的基本使用流程，并以抓取汽车之家二手车数据为例进行讲解。</p> 
<h2><a id="_7"></a>正文</h2> 
<h3><a id="1Scrapy_9"></a>1、Scrapy框架基本使用流程</h3> 
<ol><li> <p>创建爬虫项目：<code>scrapy startprojecct 项目名</code></p> </li><li> <p>cd到项目文件夹：<code>cd 项目名</code></p> </li><li> <p>创建爬虫文件：<code>scrapy genspider 爬虫文件名 浏览器地址栏中的域名</code></p> </li><li> <p>定义抓取的数据结构：编写 <strong>items.py</strong> 文件</p> <pre><code class="prism language-python">   <span class="token keyword">import</span> scrapy
   <span class="token keyword">class</span> 项目名item<span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
        scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
        price <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
        link <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> </li><li> <p>爬虫文件解析提取数据：编写 <strong>爬虫文件名.py</strong> 文件</p> <pre><code class="prism language-python"><span class="token keyword">import</span> scrapy
   <span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> 项目名item
   
   <span class="token keyword">class</span> 类名Spider<span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        name <span class="token operator">=</span> <span class="token string">"爬虫文件名"</span> <span class="token comment"># 爬虫名</span>
        allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"浏览器地址栏中的域名"</span><span class="token punctuation">]</span> <span class="token comment"># 允许爬取的域名：在创建爬虫文件的时候指定的域名</span>
        start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">""</span><span class="token punctuation">]</span>  <span class="token comment"># 第一页的url地址</span>
        
        <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
            解析提取数据
            item<span class="token operator">=</span>项目名item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token operator">=</span>xxx
            <span class="token comment"># 数据交给管道文件处理的方法</span>
            <span class="token keyword">yield</span> item
            <span class="token comment"># 需要进行跟进的url地址，如何交给调度器入队列</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre> </li><li> <p>管道文件处理爬虫文件提取的数据：编写 <strong>pipelines.py</strong> 文件</p> <pre><code class="prism language-python"><span class="token keyword">class</span> 项目名spiderPipeline<span class="token punctuation">:</span>
        <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 具体处理数据的代码</span>
            <span class="token keyword">return</span> item    
</code></pre> </li><li> <p>全局配置：编写 <strong>settings.py</strong> 文件</p> <pre><code class="prism language-python">   ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token comment"># robots协议</span>
   CONCURRENT_REQUESTS <span class="token operator">=</span> <span class="token number">32</span> <span class="token comment"># 最大并发数</span>
   DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment"># 下载延迟时间</span>
   COOKIES_ENABLED <span class="token operator">=</span> <span class="token boolean">False</span> <span class="token comment"># Cookies检查</span>
   DEFAULT_REQUEST_HEADERS <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"Cookie"</span><span class="token punctuation">:</span> <span class="token string">""</span><span class="token punctuation">,</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko)"</span>
    <span class="token punctuation">}</span>  <span class="token comment"># 请求头</span>
    ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment"># 项目目录名.模块名.类名:优先级(1-1000不等)</span>
    <span class="token punctuation">}</span>  <span class="token comment"># 开启管道       </span>
</code></pre> </li><li> <p>运行爬虫：<strong>run.py</strong><br> 在项目文件夹下创建： run.py 文件并运行</p> <pre><code class="prism language-python">   <span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline
   cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">'scrapy crawl 爬虫文件名'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> </li></ol> 
<h3><a id="2scrapy_80"></a>2、scrapy框架项目启动方式</h3> 
<ol><li> <p>基于start_urls启动：从爬虫文件的start_urls变量中遍历url地址，交给调度器入队列，把下载器返回的响应对象交给爬虫文件的parse()函数处理</p> </li><li> <p>重写start_requests()方法：去掉start_urls变量</p> <pre><code class="prism language-python">   <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        生成要爬取的url地址
        利用scrapy<span class="token punctuation">.</span>Requst<span class="token punctuation">(</span><span class="token punctuation">)</span>交给调度器
</code></pre> </li></ol> 
<h3><a id="3Scrapy_92"></a>3、基于Scrapy框架实现汽车之家二手车数据抓取</h3> 
<ol><li> <p>项目需求：抓取汽车名称、价格、链接<br> <img src="https://images2.imgbox.com/7e/7e/7tGR2TEJ_o.png" alt="在这里插入图片描述"></p> </li><li> <p>url地址规律：</p> <pre><code class="prism language-python">https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>che168<span class="token punctuation">.</span>com<span class="token operator">/</span>china<span class="token operator">/</span>a0_0msdgscncgpi1ltocsp1exx0<span class="token operator">/</span>
https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>che168<span class="token punctuation">.</span>com<span class="token operator">/</span>china<span class="token operator">/</span>a0_0msdgscncgpi1ltocsp2exx0<span class="token operator">/</span>
https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>che168<span class="token punctuation">.</span>com<span class="token operator">/</span>china<span class="token operator">/</span>a0_0msdgscncgpi1ltocsp3exx0<span class="token operator">/</span>
https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>che168<span class="token punctuation">.</span>com<span class="token operator">/</span>china<span class="token operator">/</span>a0_0msdgscncgpi1ltocsp4exx0<span class="token operator">/</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
https<span class="token punctuation">:</span><span class="token operator">//</span>www<span class="token punctuation">.</span>che168<span class="token punctuation">.</span>com<span class="token operator">/</span>china<span class="token operator">/</span>a0_0msdgscncgpi1ltocsp<span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>exx0<span class="token operator">/</span>
</code></pre> </li><li> <p>创建项目和爬虫文件：</p> <pre><code class="prism language-python">scrapy startproject CarSpider <span class="token comment"># 创建项目</span>
cd CarSpider <span class="token comment"># 进入项目目录</span>
scrapy genspider car www<span class="token punctuation">.</span>che168<span class="token punctuation">.</span>com <span class="token comment"># 创建爬虫文件</span>
</code></pre> </li><li> <p>item.py：定义要抓取的数据结构，定义的方式是抓取什么数据，就写什么字段</p> <pre><code class="prism language-python"><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">CarspiderItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    <span class="token comment"># 汽车的名称、价格、和详情页链接，相当于定义了一个字典，只赋值了key，未赋值value</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    price <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    link <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>car.py：爬虫文件，提取具体的数据，给item赋值，将数据交给管道(yield item)<br> start_url ：存放第一页的url地址，在此项目中可以采用第二种项目启动方式，重写start_requests() 方法，一次性生成所有要抓取的url地址，并一次性交给调度器入队列</p> <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">CarSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"car"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.che168.com"</span><span class="token punctuation">]</span>

    <span class="token comment"># i = 1</span>

    <span class="token comment"># 1、删除掉 start_urls 变量</span>
    <span class="token comment"># start_urls = ["https://www.che168.com/china/a0_0msdgscncgpi1ltocsp1exx0/"]  # 从第一页开始</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        2、重写 start_requests() 方法：一次性生成所有要抓取的url地址，并一次性交给调度器入队列
        :return:
        """</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            url <span class="token operator">=</span> <span class="token string">"https://www.che168.com/china/a0_0msdgscncgpi1ltocsp{}exx0/"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span>
            <span class="token comment"># 交给调度器入队列，并指定解析函数</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>detail_page<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">detail_page</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> CarspiderItem<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 给item.py的CarspiderItem类做实例化</span>
        <span class="token comment"># 先写基准xpath //body/div/div/ul/li</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//body/div/div/ul[@class='viewlist_ul']/li"</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            item<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span> <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./@carname"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">"price"</span><span class="token punctuation">]</span> <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./@price"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">"link"</span><span class="token punctuation">]</span> <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"./a/@href"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">yield</span> item  <span class="token comment"># yield item：把抓取的数据提交给管道文件处理</span>
</code></pre> <p>response.xpath() 使用说明：结果为列表，列表中元素为选择器对象 ，<code>[&lt;selector xpath='xxx' data='A'&gt;,&lt;selector xpath='xxx' data='B'&gt; ]</code><br> 列表.extract()：序列化列表中所有选择器为字符串[‘A’,‘B’]<br> 列表.extract_first()|get()：序列化并提取第1个数据 ‘A’</p> </li><li> <p>pipelines.py：管道文件</p> <pre><code class="prism language-python"><span class="token comment"># useful for handling different item types with a single interface</span>
<span class="token keyword">import</span> pymysql
<span class="token keyword">from</span> <span class="token punctuation">.</span>settings <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> itemadapter <span class="token keyword">import</span> ItemAdapter


<span class="token keyword">class</span> <span class="token class-name">CarspiderPipeline</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">"price"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">"link"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 打印，执行具体的数据处理</span>
        <span class="token keyword">return</span> item
</code></pre> </li><li> <p>settings.py：进行全局配置</p> <pre><code class="prism language-python">BOT_NAME <span class="token operator">=</span> <span class="token string">"CarSpider"</span>

SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"CarSpider.spiders"</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">"CarSpider.spiders"</span>

<span class="token comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>

<span class="token comment"># 设置日志级别：DEBUG &lt; INFO &lt; WARNING &lt; ERROR &lt; CARITICAL</span>
LOG_LEVEL <span class="token operator">=</span> <span class="token string">'INFO'</span>
<span class="token comment"># 保存日志文件</span>
LOG_FILE <span class="token operator">=</span> <span class="token string">'car.log'</span>

<span class="token comment"># See also autothrottle settings and docs</span>
DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token number">1</span>

<span class="token comment"># Override the default request headers:</span>
DEFAULT_REQUEST_HEADERS <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token string">"Accept"</span><span class="token punctuation">:</span> <span class="token string">"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"</span><span class="token punctuation">,</span>
    <span class="token string">"Accept-Language"</span><span class="token punctuation">:</span> <span class="token string">"en"</span><span class="token punctuation">,</span>
    <span class="token string">"User-Agent"</span><span class="token punctuation">:</span> <span class="token string">"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko)"</span>
<span class="token punctuation">}</span>

<span class="token comment"># Configure item pipelines</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>
<span class="token comment"># 开启管道</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
    <span class="token comment"># 项目目录名.模块名.类名:优先级(1-1000不等)</span>
    <span class="token string">"CarSpider.pipelines.CarspiderPipeline"</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
    <span class="token comment"># "CarSpider.pipelines.CarMysqlPipeline": 400</span>
<span class="token punctuation">}</span>

<span class="token comment"># Set settings whose default value is deprecated to a future-proof value</span>
REQUEST_FINGERPRINTER_IMPLEMENTATION <span class="token operator">=</span> <span class="token string">"2.7"</span>
TWISTED_REACTOR <span class="token operator">=</span> <span class="token string">"twisted.internet.asyncioreactor.AsyncioSelectorReactor"</span>
FEED_EXPORT_ENCODING <span class="token operator">=</span> <span class="token string">"utf-8"</span>  <span class="token comment"># 设置数据导出的编码"utf-8" "gb18030"</span>


</code></pre> </li><li> <p>run.py：写程序入口函数 ， scrapy.cfg同目录</p> <pre><code class="prism language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">'scrapy crawl car'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> </li><li> <p>运行效果<br> <img src="https://images2.imgbox.com/a7/a6/4iuZHZG5_o.png" alt="在这里插入图片描述"></p> </li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d4e4d9dda87e3c21d18d5958e5497d2a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux 修改系统时间的两种方式</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/24858a4dd0929762e24c5152540175af/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MySQL学习-基础篇-事务</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>