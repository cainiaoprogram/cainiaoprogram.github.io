<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>DeepLearning之LSTM模型输入数据：白话降维解说 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="DeepLearning之LSTM模型输入数据：白话降维解说" />
<meta property="og:description" content="《 Dianchen666’s Deep Learning 学习笔记系列 ---- 小白角度看深度学习》
有导航，不迷路。
(1). DeepLearning之LSTM模型输入参数：time_step, input_size, batch_size的理解
(2). DeepLearning之LSTM模型输入数据：白话降维解说
本文摘要：
对于LSTM的输入参数的理解的应用。
LSTM模型真正的输入数据是什么样的？
通过LSTM的输入数据实例的讲解，更好的理解循环神经网络的输入数据。
1. LSTM的基本介绍 上次讲到了LSTM模型的输入参数的理解，这一篇讲讲我对LSTM以及循环网络模型的输入数据的理解。LSTM是循环神经网络的一个变种，加入了多个门来控制每个神经细胞的状态细胞的状态对于整个模型是非常重要的，训练模型主要是更新每个细胞的输入参数，转态参数，输入的参数，让每个细胞处于一个稳定的状态输入的数据的一般是time_step, input_size, batch_size，这三个输入参数的定义我已经在上一篇博文中谈了谈我的理解受一位博友启发，但是我发现好像没有博文对输入数据到底是什么样的，讲的非常的清晰透彻、清楚。本文尝试从非常白话的角度，来谈谈我对输入数据模样的理解。如有不对，还请多批评指正。 2. 基础参数理解 输入数据主要是三个参数，time_step, input_size, batch_size借某位博友的启发，引用一下它的话：“batch_size是指有多少组序列数据，而time_step是指每组序列数据中有多少个时刻”input_size 最好理解，就是输入的数据有几个自变量，就是有几个Xiteration与batchsize是有乘法关系的，3000条数据，100iteration，那么batchsize就是30。也就是Total sample = iteration（n）*batchsizebatch_size就是我们常说的批处理的数据量epoch=10就是进行10*100个iteration来对模型进行训练 3. 各参数确定的次序 首先应该确定的是由几个自变量，就是有几个X，由几个变量来预测另外一个y第2个应该确定的是time_step，就是确定你进行训练其中一次的有多少个时刻，这个time_step就应该是多少，换句话说就是你预测的这个y和之前的多少个时刻有关系，这样来确定。第3个就是batch_size, 原理上将batch_size可能会影响你的训练速度，因为它的定义是批大小，是一次训练所选取的样本数，为了在内存效率与内存容量之间寻找平衡，白话就是提高你的训练效率。batch_size和time_step本身没有关系，但是time_step的长短和input_size的多少会影响每一个iteration训练的速度。 3. 示意图 1.还是用一个excel的数据表来进行举例
2.时间是从2020年6月1日-6月30日，x1,x2,x3,x4,x5说明是有5个自变量，也就是Inputsize=5，y为要预测的值。
3.此时确定timestep的值，就是你预测的这个Y值是之前的几个时刻有关系，比如上图要预测的y值使用前5天的数据来进行预测，那么time_step=5，此时将上述的数据按照time_step的大小进行重构。
4.通过time_step参数对数据进行重构后，会产生新的数据组，组数=total_sample - time_step &#43; 1，如下图：26组=total(30) - time_step(5) &#43;1，每组数据都有5个时刻t
4.其中包含5个时刻数据的这一组数据称为输入数据的一个batch，而batch_size就是每一次feed数据有多少组这样的数据。batch(26) = total(30) - time_step(5) &#43;1
5.再把每一个batch的数据剖开，看看每一个batch的数据是什么样的。
6.下图为一个粗糙的示意图。讲述了在一个Batch中数据是如何进行运转的。
7.在batch1 中，T1时刻的数据分为X变量与Y变量，在T1时刻X与Y数据被同时输入到LSTM中，通过各种门的计算，输出了一个细胞状态Ct1与Ht1，这个两个变量会作为输入变量到下一个时刻的计算当中。
8.到T2时，T1时刻输出的Ct1与Ht1与T2时刻的X变量（x1x2x3x4x5）输入到LSTM模型中，通过各种门的计算，最后得到Ct2与Ht2，在输入到下一时刻，直到整个batch结束。
一个batch中会循环计算time_step次。
10.上图中，红色直线代表是的细胞状态变量的转移
红色曲线代表的是目标值也就是Ht变量的转移。 11.在执行一个batch结束后，再执行下一个batch，batchsize=30就是1个iteration中执行了30个这样的batch，在一次feed数据中。
12.重构后的batch的个数，自己定义size的大小。上图中的所有数据重构后，变成了26个batch，你可以将batchsize设置为5，设置为10，设置为20。
13.无论batchsize设置为多少，每一组数据都是按照顺序进入到模型中进行训练。
4. 总结 那么batchsize主要影响模型的什么？主要是影响模型的泛化性能，就是模型在训练之后对于test数据预测的准确性。一般来说：越大大的batchsize，会减少模型训练所需要的时间，提高模型的稳定性在合适的范围内，增大batchsize，有助于收敛的稳定性，但是再随着batchsize的增加，模型的性能会下降（泛化性能）总结来说：batchsize在变得很大(超过一个临界点)时，会降低模型的泛化能力。 下一篇说说学习率与batchsiz对模型性能的影响。 ————————————————" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/84c6def96d6b5d0cc9af9129e5fef0ab/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-07T04:25:32+08:00" />
<meta property="article:modified_time" content="2020-07-07T04:25:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">DeepLearning之LSTM模型输入数据：白话降维解说</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>《 Dianchen666’s Deep Learning 学习笔记系列 ---- 小白角度看深度学习》</p> 
<p>有导航，不迷路。</p> 
<p><a href="https://blog.csdn.net/weixin_42101836/article/details/104386371">(1). DeepLearning之LSTM模型输入参数：time_step, input_size, batch_size的理解</a></p> 
<p><a href="" rel="nofollow">(2). DeepLearning之LSTM模型输入数据：白话降维解说</a></p> 
<hr> 
<p>本文摘要：</p> 
<ol><li> <p>对于LSTM的输入参数的理解的应用。</p> </li><li> <p>LSTM模型真正的输入数据是什么样的？</p> </li><li> <p>通过LSTM的输入数据实例的讲解，更好的理解循环神经网络的输入数据。</p> </li></ol> 
<hr> 
<h2><a id="1_LSTM_21"></a>1. LSTM的基本介绍</h2> 
<ol><li>上次讲到了LSTM模型的输入参数的理解，这一篇讲讲我对LSTM以及循环网络模型的输入数据的理解。</li><li>LSTM是循环神经网络的一个变种，加入了多个门来控制每个神经细胞的状态</li><li>细胞的状态对于整个模型是非常重要的，训练模型主要是更新每个细胞的输入参数，转态参数，输入的参数，让每个细胞处于一个稳定的状态</li><li>输入的数据的一般是time_step, input_size, batch_size，这三个输入参数的定义我已经在上一篇博文中谈了谈我的理解</li><li>受一位博友启发，但是我发现好像没有博文对输入数据到底是什么样的，讲的非常的清晰透彻、清楚。</li><li>本文尝试从非常白话的角度，来谈谈我对输入数据模样的理解。</li><li>如有不对，还请多批评指正。</li></ol> 
<hr> 
<h2><a id="2__35"></a>2. 基础参数理解</h2> 
<ol><li>输入数据主要是三个参数，time_step, input_size, batch_size</li><li>借某位博友的启发，引用一下它的话：“batch_size是指有多少组序列数据，而time_step是指每组序列数据中有多少个时刻”</li><li>input_size 最好理解，就是输入的数据有几个自变量，就是有几个X</li><li>iteration与batchsize是有乘法关系的，3000条数据，100iteration，那么batchsize就是30。也就是Total sample = iteration（n）*batchsize</li><li>batch_size就是我们常说的批处理的数据量</li><li>epoch=10就是进行10*100个iteration来对模型进行训练</li></ol> 
<hr> 
<h2><a id="3__45"></a>3. 各参数确定的次序</h2> 
<ol><li>首先应该确定的是由几个自变量，就是有几个X，由几个变量来预测另外一个y</li><li>第2个应该确定的是time_step，就是确定你进行训练其中一次的有多少个时刻，这个time_step就应该是多少，换句话说就是你预测的这个y和之前的多少个时刻有关系，这样来确定。</li><li>第3个就是batch_size, 原理上将batch_size可能会影响你的训练速度，因为它的定义是批大小，是一次训练所选取的样本数，为了在内存效率与内存容量之间寻找平衡，白话就是提高你的训练效率。</li><li>batch_size和time_step本身没有关系，但是time_step的长短和input_size的多少会影响每一个iteration训练的速度。</li></ol> 
<hr> 
<h2><a id="3__56"></a>3. 示意图</h2> 
<p>1.还是用一个excel的数据表来进行举例<br> <img src="https://images2.imgbox.com/a5/d4/oEJPlRDy_o.png" alt="在这里插入图片描述"></p> 
<p>2.时间是从2020年6月1日-6月30日，x1,x2,x3,x4,x5说明是有5个自变量，也就是Inputsize=5，y为要预测的值。</p> 
<p>3.此时确定timestep的值，就是你预测的这个Y值是之前的几个时刻有关系，比如上图要预测的y值使用前5天的数据来进行预测，那么time_step=5，此时将上述的数据按照time_step的大小进行重构。</p> 
<p>4.通过time_step参数对数据进行重构后，会产生新的数据组，组数=total_sample - time_step + 1，如下图：26组=total(30) - time_step(5) +1，每组数据都有5个时刻t<br> <img src="https://images2.imgbox.com/27/f1/U4w8OzU2_o.png" alt="在这里插入图片描述"><br> 4.其中包含5个时刻数据的这一组数据称为输入数据的一个batch，而batch_size就是每一次feed数据有多少组这样的数据。batch(26) = total(30) - time_step(5) +1<br> <img src="https://images2.imgbox.com/85/9c/SFPIniVQ_o.png" alt="在这里插入图片描述"><br> 5.再把每一个batch的数据剖开，看看每一个batch的数据是什么样的。</p> 
<p>6.下图为一个粗糙的示意图。讲述了在一个Batch中数据是如何进行运转的。</p> 
<p>7.在batch1 中，T1时刻的数据分为X变量与Y变量，在T1时刻X与Y数据被同时输入到LSTM中，通过各种门的计算，输出了一个细胞状态Ct1与Ht1，这个两个变量会作为输入变量到下一个时刻的计算当中。</p> 
<p>8.到T2时，T1时刻输出的Ct1与Ht1与T2时刻的X变量（x1x2x3x4x5）输入到LSTM模型中，通过各种门的计算，最后得到Ct2与Ht2，在输入到下一时刻，直到整个batch结束。</p> 
<ol start="9"><li>一个batch中会循环计算time_step次。<br> <img src="https://images2.imgbox.com/cc/b2/2qnYhqmT_o.png" alt="在这里插入图片描述"><br> 10.上图中，红色直线代表是的细胞状态变量的转移<br> 红色曲线代表的是目标值也就是Ht变量的转移。</li></ol> 
<p>11.在执行一个batch结束后，再执行下一个batch，batchsize=30就是1个iteration中执行了30个这样的batch，在一次feed数据中。</p> 
<p>12.重构后的batch的个数，自己定义size的大小。上图中的所有数据重构后，变成了26个batch，你可以将batchsize设置为5，设置为10，设置为20。</p> 
<p>13.无论batchsize设置为多少，每一组数据都是按照顺序进入到模型中进行训练。</p> 
<h2><a id="4__89"></a>4. 总结</h2> 
<ol><li>那么batchsize主要影响模型的什么？主要是影响模型的泛化性能，就是模型在训练之后对于test数据预测的准确性。</li><li>一般来说：越大大的batchsize，会减少模型训练所需要的时间，提高模型的稳定性</li><li>在合适的范围内，增大batchsize，有助于收敛的稳定性，但是再随着batchsize的增加，模型的性能会下降（泛化性能）</li><li>总结来说：batchsize在变得很大(超过一个临界点)时，会降低模型的泛化能力。</li></ol> 
<h4><a id="batchsiz_96"></a>下一篇说说学习率与batchsiz对模型性能的影响。</h4> 
<p>————————————————<br> 参考链接，尊重原创，支持原创！</p> 
<ol><li><a href="https://blog.csdn.net/ch206265/article/details/107088040">作者：ch206265, 文章：LSTM中的batch到底是什么, https://blog.csdn.net/ch206265/article/details/107088040</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzIzNjc0MTMwMA==&amp;mid=2247489038&amp;idx=1&amp;sn=0fe971f10fb87d7a032d9c9c7d34e5ce&amp;chksm=e8d261d5dfa5e8c3746db1d9e33c954d82daf1703bf6e14204e8e5dc3edd70e669bce6922c4d&amp;mpshare=1&amp;scene=1&amp;srcid=0821reMHGS552436YGl7VRXl&amp;sharer_sharetime=1566363978925&amp;sharer_shareid=3b6e9d04c503d925d5af408b58210449#rd" rel="nofollow">作者：言有三，学习率和batchsize如何影响模型的性能？</a></li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b18638702d60f0617b282515753771f8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【cs224n学习作业】Assignment 1 - Exploring Word Vectors</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dc6b4ff2404f48b3f731eadce58272a0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">IntelliJ IDEA常用快捷键</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>