<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>日撸Java三百行：AdaBoost - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="日撸Java三百行：AdaBoost" />
<meta property="og:description" content="集成学习 集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务,有时也被称为多分类器系统(multi-classifier svstem).一般结构:先产生一组“个体学习器”(individual learner)，再用某种策略将它们结合起来.个体学习器通常由一个现有的学习算法从训练数据产生.例如决策树算法、BP神经网络算法等,
“同质”（homogeneous）集成：集成中只包含同种类型的个体学习器,例如“决策树集成”中全是决策树,“神经网络集成”中全是神经网络.同质集成中的个体学习器亦称“基学习器”,相应的学习算法称为“基学习算法”(base learning algorithm).
“异质”（heterogenous）集成：集成中包含不同类型的个体学习器,例如同时包含决策树和神经网络,个体学习器一般不称为基学习器,常称为“组件学习器”.
学习器的选择：集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能.这对“弱学习器”尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的.但需注意的是,虽然从理论上来说使用弱学习器集成足以获得好的性能,但在实践中出于种种考虑，往往会使用比较强的学习器.
要获得好的集成,个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏,并且要有“多样性”.即学习器间具有差异.个体学习器的“准确性”和“多样性”本身就存在冲突.一般的,准确性很高之后,要增加多样性就需牺牲准确性.事实上,如何产生并结合“好而不同”的个体学习器,是集成学习研究的核心.
分类：根据个体学习器的生成方式,目前的集成学习方法大致可分为两大类,即a)个体学习器间存在强依赖关系、必须串行生成的序列化方法,以及b)个体学习器间不存在强依赖关系、可同时生成的并行化方法;前者的代表是Boosting,后者的代表是Bagging 和Random Forest.
Boosting boosting中不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting是通过集中关注被已有分类器错分的那些数据来获得新的分类器。由于boosting分类的结果是基于所有分类器的加权求和结果的,且分类器权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。boosting方法拥有多个版本，其中最流行的版本AdaBoost。
AdaBoost AdaBoost是英文&#34;Adaptive Boosting&#34;（自适应增强）的缩写，AdaBoost方法的自适应在于：前一个分类器分错的样本会被用来训练下一个分类器。AdaBoost方法是一种迭代算法，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率。每一个训练样本都被赋予一个权重，表明它被某个分类器选入训练集的概率。如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它被选中的概率就被降低；相反，如果某个样本点没有被准确地分类，那么它的权重就得到提高。通过这样的方式，AdaBoost方法能“聚焦于”那些较难分（更富信息）的样本上。
AdaBoost的运行过程：
（1）训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量 D D D ,一开始这些权重都初始化成相等值
（2）首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。
（3）在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的
权重将会降低，而第一次分错的样本的权重将会提高.
为了从所有弱分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值 α \alpha α， 这些 α \alpha α值是基干每个弱分类器的错误
率进行计算的。其中，错误率 ε \varepsilon ε的定义为:
ε = 未 分 类 正 确 样 本 数 目 所 有 样 本 数 目 \varepsilon=\frac{未分类正确样本数目}{所有样本数目} ε=所有样本数目未分类正确样本数目​
α = 1 2 l n ( 1 − ε ε ) \alpha=\frac{1}{2}ln(\frac{1-\varepsilon}{\varepsilon}) α=21​ln(ε1−ε​)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/208fc8def4ac9e246fef50f5099d0172/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-13T21:31:01+08:00" />
<meta property="article:modified_time" content="2022-05-13T21:31:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">日撸Java三百行：AdaBoost</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="_0"></a>集成学习</h3> 
<p><strong>集成学习</strong>(ensemble learning)通过构建并结合多个学习器来完成学习任务,有时也被称为多分类器系统(multi-classifier svstem).一般结构:先产生一组“个体学习器”(individual learner)，再用某种策略将它们结合起来.个体学习器通常由一个现有的学习算法从训练数据产生.例如决策树算法、BP神经网络算法等,<br> <strong>“同质”</strong>（homogeneous）集成：集成中只包含同种类型的个体学习器,例如“决策树集成”中全是决策树,“神经网络集成”中全是神经网络.同质集成中的个体学习器亦称“基学习器”,相应的学习算法称为“基学习算法”(base learning algorithm).<br> <strong>“异质”</strong>（heterogenous）集成：集成中包含不同类型的个体学习器,例如同时包含决策树和神经网络,个体学习器一般不称为基学习器,常称为“组件学习器”.</p> 
<p><strong>学习器的选择</strong>：集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能.这对“弱学习器”尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的.但需注意的是,虽然从理论上来说使用弱学习器集成足以获得好的性能,但在实践中出于种种考虑，往往会使用比较强的学习器.<br> 要获得好的集成,个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏,并且要有“多样性”.即学习器间具有差异.个体学习器的“准确性”和“多样性”本身就存在冲突.一般的,准确性很高之后,要增加多样性就需牺牲准确性.事实上,如何产生并结合“好而不同”的个体学习器,是集成学习研究的核心.</p> 
<p>分类：根据个体学习器的生成方式,目前的集成学习方法大致可分为两大类,即a)个体学习器间存在强依赖关系、必须串行生成的序列化方法,以及b)个体学习器间不存在强依赖关系、可同时生成的并行化方法;前者的代表是Boosting,后者的代表是Bagging 和Random Forest.</p> 
<h3><a id="Boosting_13"></a>Boosting</h3> 
<p>boosting中不同的分类器是通过串行训练而获得的，每个新分类器都根据已训练出的分类器的性能来进行训练。boosting是通过集中关注被已有分类器错分的那些数据来获得新的分类器。由于boosting分类的结果是基于所有分类器的加权求和结果的,且分类器权重并不相等，每个权重代表的是其对应分类器在上一轮迭代中的成功度。boosting方法拥有多个版本，其中最流行的版本AdaBoost。</p> 
<h3><a id="AdaBoost_16"></a>AdaBoost</h3> 
<p>AdaBoost是英文"Adaptive Boosting"（自适应增强）的缩写，AdaBoost方法的自适应在于：前一个分类器分错的样本会被用来训练下一个分类器。AdaBoost方法是一种迭代算法，在每一轮中加入一个新的弱分类器，直到达到某个预定的足够小的错误率。每一个训练样本都被赋予一个权重，表明它被某个分类器选入训练集的概率。如果某个样本点已经被准确地分类，那么在构造下一个训练集中，它被选中的概率就被降低；相反，如果某个样本点没有被准确地分类，那么它的权重就得到提高。通过这样的方式，AdaBoost方法能“聚焦于”那些较难分（更富信息）的样本上。</p> 
<p>AdaBoost的运行过程：<br> （1）训练数据中的每个样本，并赋予其一个权重，这些权重构成了向量<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         D 
        
       
      
        D 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span></span></span></span></span> ,一开始这些权重都初始化成相等值<br> （2）首先在训练数据上训练出一个弱分类器并计算该分类器的错误率，然后在同一数据集上再次训练弱分类器。<br> （3）在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的<br> 权重将会降低，而第一次分错的样本的权重将会提高.<br> 为了从所有弱分类器中得到最终的分类结果，AdaBoost为每个分类器都分配了一个权重值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
      
        \alpha 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span></span></span></span></span>， 这些<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
      
        \alpha 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span></span></span></span></span>值是基干每个弱分类器的错误<br> 率进行计算的。其中，错误率<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ε 
        
       
      
        \varepsilon 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">ε</span></span></span></span></span>的定义为:<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ε 
         
        
          = 
         
         
          
          
            未 
           
          
            分 
           
          
            类 
           
          
            正 
           
          
            确 
           
          
            样 
           
          
            本 
           
          
            数 
           
          
            目 
           
          
          
          
            所 
           
          
            有 
           
          
            样 
           
          
            本 
           
          
            数 
           
          
            目 
           
          
         
        
       
         \varepsilon=\frac{未分类正确样本数目}{所有样本数目} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault">ε</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.363em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.677em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord cjk_fallback">所</span><span class="mord cjk_fallback">有</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">目</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord cjk_fallback">未</span><span class="mord cjk_fallback">分</span><span class="mord cjk_fallback">类</span><span class="mord cjk_fallback">正</span><span class="mord cjk_fallback">确</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">本</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">目</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          α 
         
        
          = 
         
         
         
           1 
          
         
           2 
          
         
        
          l 
         
        
          n 
         
        
          ( 
         
         
          
          
            1 
           
          
            − 
           
          
            ε 
           
          
         
           ε 
          
         
        
          ) 
         
        
       
         \alpha=\frac{1}{2}ln(\frac{1-\varepsilon}{\varepsilon}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.00744em; vertical-align: -0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">2</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathdefault" style="margin-right: 0.01968em;">l</span><span class="mord mathdefault">n</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault">ε</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mord mathdefault">ε</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></span><br> <img src="https://images2.imgbox.com/12/62/FhPAy6hH_o.png" alt="在这里插入图片描述"><br> 上图中左边是数据集，直方图的不同宽度代表每个样例的不同权重。经过一个分类器之后，加权的预测结果通过三角形中的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
      
        \alpha 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.0037em;">α</span></span></span></span></span>值进行加权。每个三角形中的输出的加权结果在圆形中求和，得到最后的结果。</p> 
<p>（4）计算出alpha之后，对权重向量D进行更新，以使得那些正确分类的样本的权重降低而错分样本的权重升高：<br> 如果某个样本被正确分类：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           i 
          
          
          
            t 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
         
          
           
           
             D 
            
           
             i 
            
           
             t 
            
           
           
           
             e 
            
            
            
              − 
             
            
              α 
             
            
           
          
          
          
            S 
           
          
            u 
           
          
            m 
           
          
            ( 
           
          
            D 
           
          
            ) 
           
          
         
        
       
         D_i^{t+1}=\frac{D_i^te^{-\alpha}}{Sum(D)} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1311em; vertical-align: -0.266995em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -2.43301em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.266995em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.40656em; vertical-align: -0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.47056em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.793556em;"><span class="" style="top: -2.44134em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.258664em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.771331em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mathdefault mtight" style="margin-right: 0.0037em;">α</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span><br> 如果某个样本被分错：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           D 
          
         
           i 
          
          
          
            t 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
         
          
           
           
             D 
            
           
             i 
            
           
             t 
            
           
           
           
             e 
            
           
             α 
            
           
          
          
          
            S 
           
          
            u 
           
          
            m 
           
          
            ( 
           
          
            D 
           
          
            ) 
           
          
         
        
       
         D_i^{t+1}=\frac{D_i^te^{\alpha}}{Sum(D)} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.1311em; vertical-align: -0.266995em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.864108em;"><span class="" style="top: -2.43301em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.266995em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.40656em; vertical-align: -0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.47056em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.05764em;">S</span><span class="mord mathdefault">u</span><span class="mord mathdefault">m</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.793556em;"><span class="" style="top: -2.44134em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.258664em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.664392em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.0037em;">α</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p> 
<p>（5）计算出D之后，AdaBoost又开始进入下一轮迭代。AdaBoost算法会不断地重复训练和调整权重的过程，直到训练错误率为0或者弱分类器的数目达到用户的指定值为止。</p> 
<pre><code>from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
</code></pre> 
<pre><code class="prism language-bash">from sklearn.datasets <span class="token function">import</span> load_iris
from sklearn.model_selection <span class="token function">import</span> train_test_split
from sklearn.ensemble <span class="token function">import</span> AdaBoostClassifier

<span class="token comment"># 1. 加载数据集</span>
iris <span class="token operator">=</span> load_iris<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> iris.data  <span class="token comment"># 数据</span>
y <span class="token operator">=</span> iris.target  <span class="token comment"># 标签</span>

<span class="token comment"># 2. 划分数据集</span>
X_trainer, X_test, Y_trainer, Y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X, y, <span class="token assign-left variable">test_size</span><span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">)</span>

<span class="token comment"># 3. AdaBoostClassifier</span>
clf <span class="token operator">=</span> AdaBoostClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
clf.fit<span class="token punctuation">(</span>X_trainer, Y_trainer<span class="token punctuation">)</span>
score <span class="token operator">=</span> clf.score<span class="token punctuation">(</span>X_test, Y_test<span class="token punctuation">)</span>  <span class="token comment"># 模型得分</span>
print<span class="token punctuation">(</span><span class="token string">"模型得分："</span>, score<span class="token punctuation">)</span>


</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/199249ce4abc39b345c0aa4dca7b2a36/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">实操 | Hive 数据倾斜问题定位排查及解决</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2d689409c9b879a425cf7497373c32dd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于 Java 机器学习自学笔记 （第63-65天：集成学习之AdaBoost）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>