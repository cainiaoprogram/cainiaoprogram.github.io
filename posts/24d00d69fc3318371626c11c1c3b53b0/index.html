<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg 4.2 从入门到精通（一）—— QT 中如何用 FFmpeg 实现软件解码 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg 4.2 从入门到精通（一）—— QT 中如何用 FFmpeg 实现软件解码" />
<meta property="og:description" content="1、背景 因为在2021年给自己定了目标和计划，学习ffmpeg，所以这篇文章是实现计划的第一步。
ffmpeg 众所周知，就不展开介绍了，下面给出 FFmpeg 4.2 windows x64 lib库和头文件的下载地址（粉丝免积分下载）：
download.csdn.net/download/u0…
本文也是属于博主的入门学习总结与分享，因此我们先从ffmpeg的软解码开始，从解码到绘制，一起体验下亲自动手的快乐。本文的语言环境基于C&#43;&#43;，界面部分是 QT。
2、流程分析 在开始看代码之前，我们必须先了解下ffmpeg软解的常规流程：
在以前的教程中我们经常见到av_regeister_all，这是旧版ffmpeg的用法，必须在开始进行初始化，新版的ffmpeg4.0之后已经不需要了，详见github： av_register_all() has been deprecated in ffmpeg 4.0。
1.1 avformat_open_input 为 AVFormatContext 分配空间，打开输入的视频数据并且探测视频的格式，这个函数里面包含了复杂的格式解析与探测算法，可解析的内容包括：视频流、音频流、视频流参数、音频流参数、视频帧索引等。用雷神的话说就是 可以算作FFmpeg的“灵魂”。
1.2 avformat_find_stream_info 获取多媒体流的信息，包括码流、帧率、时长等信息。但是有些早期格式或者裸流数据它的索引并没有放到头当中，因此需要在后面进行探测。注意一个视频文件中可能会同时包括视频文件、音频文件、字幕文件等多个媒体流。
1.3 av_find_best_stream 当视频被解封装出来后，需要分开处理音频和视频，需要找到对应的音频流和视频流，获取音视频对应的stream_index。
1.4 avcodec_find_decoder(enum AVCodecID id) &#34;Find a registered decoder with a matching codec ID.&#34; 上一步找到的AVStream中的成员变量 codecpar-&gt;codec_id 就是这儿的参数 ID，codecpar类型为AVCodecParameters。网上的很多资料为 AVCodecContext-&gt;codec_id，这个用法在FFMPEG3.4及以上版本已经被弃用了，官方推荐使用codecpar。
1.5 avcodec_alloc_context3 创建AVCodecContext并分配空间。
1.6 avcodec_parameters_to_context 该函数用于将流里面的参数，也就是AVStream里面的参数直接复制到AVCodecContext的上下文当中，执行真正的内容拷贝。avcodec_parameters_to_context()是新的API，替换了旧版本的avcodec_copy_context()。
1.7 avcodec_open2 用给定的 AVCodec 去初始化 AVCodecContext。
到这儿，解码器的初始化工作已经完成。下面就可以开始真正的解码操作了。
1.8 av_read_frame 读取码流中的音频若干帧或者视频一帧，av_read_frame()函数是新型ffmpeg的用法，对 av_read_packet 进行了封装，旧用法之所以被抛弃，就是因为以前获取的数据可能不是完整的，而av_read_frame()保证了视频数据一帧的完整性，使读出的数据总是完整的一帧。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/24d00d69fc3318371626c11c1c3b53b0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-04T15:41:08+08:00" />
<meta property="article:modified_time" content="2023-04-04T15:41:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg 4.2 从入门到精通（一）—— QT 中如何用 FFmpeg 实现软件解码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>1、背景</h3> 
<p>因为在2021年给自己定了目标和计划，学习ffmpeg，所以这篇文章是实现计划的第一步。</p> 
<p>ffmpeg 众所周知，就不展开介绍了，下面给出 FFmpeg 4.2 windows x64 lib库和头文件的下载地址（粉丝免积分下载）：</p> 
<p><a href="https://link.juejin.cn?target=https%3A%2F%2Fdownload.csdn.net%2Fdownload%2Fu012534831%2F14045436" rel="nofollow" title="download.csdn.net/download/u0…">download.csdn.net/download/u0…</a></p> 
<p>本文也是属于博主的入门学习总结与分享，因此我们先从ffmpeg的软解码开始，从解码到绘制，一起体验下亲自动手的快乐。本文的语言环境基于C++，界面部分是 QT。</p> 
<h3>2、流程分析</h3> 
<p>在开始看代码之前，我们必须先了解下ffmpeg软解的常规流程：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/4f/fa/Tb5b6zB1_o.png"></p> 
<p>在以前的教程中我们经常见到<code>av_regeister_all</code>，这是旧版ffmpeg的用法，必须在开始进行初始化，新版的ffmpeg4.0之后已经不需要了，详见github： <a href="https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fleandromoreira%2Fffmpeg-libav-tutorial%2Fissues%2F29" rel="nofollow" title="av_register_all() has been deprecated in ffmpeg 4.0">av_register_all() has been deprecated in ffmpeg 4.0</a>。</p> 
<h4>1.1 avformat_open_input</h4> 
<p>为 AVFormatContext 分配空间，打开输入的视频数据并且探测视频的格式，这个函数里面包含了复杂的格式解析与探测算法，可解析的内容包括：视频流、音频流、视频流参数、音频流参数、视频帧索引等。用雷神的话说就是 <code>可以算作FFmpeg的“灵魂”</code>。</p> 
<h4>1.2 avformat_find_stream_info</h4> 
<p>获取多媒体流的信息，包括码流、帧率、时长等信息。但是有些早期格式或者裸流数据它的索引并没有放到头当中，因此需要在后面进行探测。注意一个视频文件中可能会同时包括视频文件、音频文件、字幕文件等多个媒体流。</p> 
<h4>1.3 av_find_best_stream</h4> 
<p>当视频被解封装出来后，需要分开处理音频和视频，需要找到对应的音频流和视频流，获取音视频对应的stream_index。</p> 
<h4>1.4 avcodec_find_decoder(enum AVCodecID id)</h4> 
<p>"Find a registered decoder with a matching codec ID." 上一步找到的AVStream中的成员变量 codecpar-&gt;codec_id 就是这儿的参数 ID，codecpar类型为AVCodecParameters。网上的很多资料为 AVCodecContext-&gt;codec_id，这个用法在FFMPEG3.4及以上版本已经被弃用了，官方推荐使用codecpar。</p> 
<h4>1.5 avcodec_alloc_context3</h4> 
<p>创建AVCodecContext并分配空间。</p> 
<h4>1.6 avcodec_parameters_to_context</h4> 
<p>该函数用于将流里面的参数，也就是AVStream里面的参数直接复制到AVCodecContext的上下文当中，执行真正的内容拷贝。avcodec_parameters_to_context()是新的API，替换了旧版本的avcodec_copy_context()。</p> 
<h4>1.7 avcodec_open2</h4> 
<p>用给定的 AVCodec 去初始化 AVCodecContext。</p> 
<p>到这儿，解码器的初始化工作已经完成。下面就可以开始真正的解码操作了。</p> 
<h4>1.8 av_read_frame</h4> 
<p>读取码流中的音频若干帧或者视频一帧，av_read_frame()函数是新型ffmpeg的用法，对 av_read_packet 进行了封装，旧用法之所以被抛弃，就是因为以前获取的数据可能不是完整的，而av_read_frame()保证了视频数据一帧的完整性，使读出的数据总是完整的一帧。</p> 
<h4>1.9 avcodec_send_packet</h4> 
<p>发送数据到后台解码队列。</p> 
<pre><code class="hljs">It can be NULL (or an AVPacket with data set to NULL and
size set to 0); in this case, it is considered a flush
packet, which signals the end of the stream. Sending the
first flush packet will return success. Subsequent ones are
unnecessary and will return AVERROR_EOF. If the decoder
still has frames buffered, it will return them after sending</code></pre> 
<p>源码中关于发送一包空数据的解释： 由于ffmpeg内部会缓存帧，在av_read_frame读不到数据的时候，需要通过<code>packet.data = NULL;packet.size = 0;</code>给ffmpeg发送一包空数据，即再<code>avcodec_send_packet</code>一次，将ffmpeg里面缓存的帧全部刷出来，解决最后几帧没有解码出来的问题。</p> 
<blockquote> 
 <p><strong>【学习地址】：</strong><a href="https://link.zhihu.com/?target=https%3A//ke.qq.com/course/3202131%3FflowToken%3D1042495" rel="nofollow" title="FFmpeg/WebRTC/RTMP/NDK/Android音视频流媒体高级开发">FFmpeg/WebRTC/RTMP/NDK/Android音视频流媒体高级开发</a></p> 
 <p><strong>【文章福利】：免费领取更多音视频学习资料包、大厂面试题、技术视频和学习路线图，资料包括（C/C++，Linux，FFmpeg webRTC rtmp hls rtsp ffplay srs 等等）有需要的可以点击</strong><a href="https://link.zhihu.com/?target=https%3A//jq.qq.com/%3F_wv%3D1027%26k%3DmgauMC3k" rel="nofollow" title="1079654574">1079654574</a><strong>加群领取哦~</strong></p> 
</blockquote> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/d8/2d/rcTtf5C1_o.png"></p> 
<p>​​​​​​<strong style="color:#4f4f4f;font-size:18px;font-weight:bold;">1.10 avcodec_receive_frame</strong></p> 
<p>从解码器读取帧数据，这个函数执行完后，就已经能拿到我们的帧数据了，它被存储在 AVFrame 中。 此处需要注意的是： 一般而言，一次avcodec_send_packet()对应一次avcodec_receive_frame()，但是也会有一次对应多次的情况。这个得看具体的流，并常见于音频流，会存在一个AVPacket对应多个AVFrame的情况。因此可以看我上面的流程图有两个while循环。</p> 
<h3>3、代码示例</h3> 
<pre><code class="hljs">//头文件
​
#ifndef MAINWINDOW_H
#define MAINWINDOW_H
​
#include &lt;QMainWindow&gt;
#include&lt;thread&gt;
extern "C"
{
    #include "libavcodec/avcodec.h"
    #include "libavformat/avformat.h"
    #include "libavutil/pixfmt.h"
    #include "libswscale/swscale.h"
    #include "libavdevice/avdevice.h"
    #include &lt;libavutil/pixdesc.h&gt;
    #include &lt;libavutil/hwcontext.h&gt;
    #include &lt;libavutil/opt.h&gt;
    #include &lt;libavutil/avassert.h&gt;
    #include &lt;libavutil/imgutils.h&gt;
}
​
namespace Ui {
class MainWindow;
}
​
class MainWindow : public QMainWindow
{
    Q_OBJECT
​
public:
    explicit MainWindow(QWidget *parent = nullptr);
    ~MainWindow();
    void init();
    void play();
private:
    std::thread m_decodecThread;
    Ui::MainWindow *ui;
    AVFormatContext *pAVFormatCtx;
    AVCodecContext *pAVCodecCtx;
    SwsContext *pSwsCtx;
    uint8_t *pRgbBuffer;
    AVPacket packet;
    AVFrame *pAVFrame = NULL;
    AVFrame *pAVFrameRGB;
    int iVideoIndex = -1;
    QImage m_image;
    bool isFinish  =false;
    void decodec();
    signals:
    void signalDraw();
public slots:
    void slotDraw();
protected:
    void paintEvent(QPaintEvent *event) override;
};
​
#endif // MAINWINDOW_H
​
//CPP文件
​
#include "mainwindow.h"
#include "ui_mainwindow.h"
#include &lt;QDebug&gt;
#include &lt;QPainter&gt;
#include&lt;thread&gt;
​
MainWindow::MainWindow(QWidget *parent) :
    QMainWindow(parent),
    ui(new Ui::MainWindow)
{
    ui-&gt;setupUi(this);
    connect(this,&amp;MainWindow::signalDraw,this,&amp;MainWindow::slotDraw);
}
​
MainWindow::~MainWindow()
{
    delete ui;
}
void MainWindow::init()
{
  std::string file = "E:/Video/bb.mp4";
 //描述多媒体文件的构成及其基本信息
 if (avformat_open_input(&amp;pAVFormatCtx, file.data(), NULL, NULL) != 0)
     {
         qDebug() &lt;&lt;"open file fail";
         avformat_free_context(pAVFormatCtx);
         return;
     }
​
 //读取一部分视音频数据并且获得一些相关的信息
 if (avformat_find_stream_info(pAVFormatCtx, NULL) &lt; 0)
 {
     qDebug() &lt;&lt;"vformat find stream fail";
     avformat_close_input(&amp;pAVFormatCtx);
     return;
 }
// 根据解码器枚举类型找到解码器
    AVCodec *pAVCodec;
    int ret = av_find_best_stream(pAVFormatCtx, AVMEDIA_TYPE_VIDEO, -1, -1, &amp;pAVCodec, 0);
    if (ret &lt; 0) {
        qDebug()&lt;&lt; "av_find_best_stream faliture";
        avformat_close_input(&amp;pAVFormatCtx);
        return;
    }
    iVideoIndex = ret;
​
     pAVCodec = avcodec_find_decoder(pAVFormatCtx-&gt;streams[iVideoIndex]-&gt;codecpar-&gt;codec_id);
     if (pAVCodec == NULL)
     {
         qDebug()&lt;&lt;"not find decoder";
         return;
     }
​
 qDebug()&lt;&lt;"avcodec_open2 pAVCodec-&gt;name:" &lt;&lt; QString::fromStdString(pAVCodec-&gt;name);
​
​
    if(pAVFormatCtx-&gt;streams[iVideoIndex]-&gt;avg_frame_rate.den != 0) {
        float fps_ = pAVFormatCtx-&gt;streams[iVideoIndex]-&gt;avg_frame_rate.num / pAVFormatCtx-&gt;streams[iVideoIndex]-&gt;avg_frame_rate.den;
           qDebug() &lt;&lt;"fps:" &lt;&lt; fps_;
    }
      int64_t video_length_sec_ = pAVFormatCtx-&gt;duration/AV_TIME_BASE;
       qDebug() &lt;&lt;"video_length_sec_:" &lt;&lt; video_length_sec_;
pAVCodecCtx = avcodec_alloc_context3(pAVCodec);
     if (pAVCodecCtx == NULL)
     {
         qDebug() &lt;&lt;"get pAVCodecCtx fail";
         avformat_close_input(&amp;pAVFormatCtx);
         return;
     }
ret = avcodec_parameters_to_context(pAVCodecCtx,pAVFormatCtx-&gt;streams[iVideoIndex]-&gt;codecpar);
     if (ret &lt; 0)
     {
         qDebug() &lt;&lt;"avcodec_parameters_to_context fail";
         avformat_close_input(&amp;pAVFormatCtx);
         return;
     }
  if (avcodec_open2(pAVCodecCtx, pAVCodec, NULL) &lt; 0)
     {
         qDebug()&lt;&lt;"avcodec_open2 fail";
         return;
     }
         //为解码帧分配内存
         //AVFrame 存放从AVPacket中解码出来的原始数据
             pAVFrame = av_frame_alloc();
             pAVFrameRGB = av_frame_alloc();
       //用于视频图像的转换,将源数据转换为RGB32的目标数据
         pSwsCtx = sws_getContext(pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, pAVCodecCtx-&gt;pix_fmt,
                                              pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, AV_PIX_FMT_RGB32,
                                              SWS_BICUBIC, NULL, NULL, NULL);
​
        int  m_size = av_image_get_buffer_size(AVPixelFormat(AV_PIX_FMT_RGB32), pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, 1);
      pRgbBuffer = (uint8_t *)(av_malloc(m_size));
         //为已经分配的空间的结构体AVPicture挂上一段用于保存数据的空间
         avpicture_fill((AVPicture *)pAVFrameRGB, pRgbBuffer, AV_PIX_FMT_BGR32, pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height);
         //av_image_fill_arrays
         //AVpacket 用来存放解码数据
         av_new_packet(&amp;packet, pAVCodecCtx-&gt;width * pAVCodecCtx-&gt;height);
}
​
​
void MainWindow::play()
{
    m_decodecThread = std::thread([this]()
    {
        decodec();
    });
    m_decodecThread.detach();
}
​
void MainWindow::decodec()
{
    //读取码流中视频帧
        while (true)
        {
            int ret = av_read_frame(pAVFormatCtx, &amp;packet);
            if(ret != 0)
            {
                qDebug()&lt;&lt;"file end";
                isFinish = !isFinish;
                 return;
            }
            if (packet.stream_index != iVideoIndex)
            {
                av_packet_unref(&amp;packet);
                continue;
            }
           int iGotPic = AVERROR(EAGAIN);
//             //解码一帧视频数据
            iGotPic = avcodec_send_packet(pAVCodecCtx, &amp;packet);
            if(iGotPic!=0){
                qDebug()&lt;&lt;"avcodec_send_packet error";
                      continue;
            }
            iGotPic = avcodec_receive_frame(pAVCodecCtx, pAVFrame);
   if(iGotPic == 0){
                   //转换像素
                   sws_scale(pSwsCtx, (uint8_t const * const *)pAVFrame-&gt;data, pAVFrame-&gt;linesize, 0, pAVCodecCtx-&gt;height, pAVFrameRGB-&gt;data, pAVFrameRGB-&gt;linesize);
​
                   //构造QImage
                   QImage img(pRgbBuffer, pAVCodecCtx-&gt;width, pAVCodecCtx-&gt;height, QImage::Format_RGB32);
                   qDebug()&lt;&lt;"decode img";
                   m_image = img;
                   emit signalDraw();
  }else {
           qDebug()&lt;&lt;"decode error";
           }
​
            av_packet_unref(&amp;packet);
            std::this_thread::sleep_for(std::chrono::milliseconds(25));
        }
  //资源回收
        av_free(pAVFrame);
        av_free(pAVFrameRGB);
        sws_freeContext(pSwsCtx);
        avcodec_close(pAVCodecCtx);
        avformat_close_input(&amp;pAVFormatCtx);
}
​
void MainWindow::slotDraw()
{
    update();
}
​
void MainWindow::paintEvent(QPaintEvent *event)
{
    QPainter painter(this);
    painter.setBrush(Qt::black);
    painter.drawRect(0, 0, this-&gt;width(), this-&gt;height());
​
    if (m_image.size().width() &lt;= 0)
        return;
​
    //比例缩放
    QImage img = m_image.scaled(this-&gt;size(),Qt::KeepAspectRatio);
    int x = this-&gt;width() - img.width();
    int y = this-&gt;height() - img.height();
​
    x /= 2;
    y /= 2;
​
    //QPoint(x,y)为中心绘制图像
    painter.drawImage(QPoint(x,y),img);
}</code></pre> 
<p></p> 
<p>原文链接：<a href="https://juejin.cn/post/6998905301239857165" rel="nofollow" title="FFmpeg 4.2 从入门到精通（一）—— QT 中如何用 FFmpeg 实现软件解码 - 掘金">FFmpeg 4.2 从入门到精通（一）—— QT 中如何用 FFmpeg 实现软件解码 - 掘金</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/73a5c14b2d16d5d0e8965bed83e83a12/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue.config.js 配置 (代理、打包静态文件路径、文件大小配置)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c0a679a43bd96a3263551c6eb4958a2a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MybatisPlus使用Left Join...on...一对多多表联查和Ipage分页返回数据问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>