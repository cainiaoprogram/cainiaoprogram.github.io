<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门" />
<meta property="og:description" content="【Kafka-3.x-教程】专栏：
【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门
【Kafka-3.x-教程】-【二】Kafka-生产者-Producer
【Kafka-3.x-教程】-【三】Kafka-Broker、Kafka-Kraft
【Kafka-3.x-教程】-【四】Kafka-消费者-Consumer
【Kafka-3.x-教程】-【五】Kafka-监控-Eagle
【Kafka-3.x-教程】-【六】Kafka 外部系统集成 【Flume、Flink、SpringBoot、Spark】
【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试
【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门 1）定义2）应用场景2.1.削峰2.2.解耦2.3.异步通信 3）两种模式4）基础架构5）安装部署5.1.集群规划5.2.集群部署5.3.集群启停脚本 6）Kafka 命令行操作6.1.主题命令行操作6.2.生产者命令行操作6.3.消费者命令行操作 1）定义 试想这样一个场景，某宝或某东购物平台，上游通过 Flume 采集相关日志到 Hadoop 集群中，在平时流量小的时候，Hadoop 的写入速度在 100M/s，Flume 采集日志的速度也在 100M/s，这样下游的 Hadoop 上传速度可以和上游的 Flume 采集速度相匹配，没有问题。
那么现在到了促销季，假如双十一进行大促销，那么 Flume 采集到的数据量远超过平时的 100M/s（比如达到 200M/s），而下游的 Hadoop 速度的极限已经是 100M/s 了，此时如果不解决这个问题就会导致上游数据量无限度的堆积，导致日志服务器爆掉。
此时 Kafka 出现了，试想，如果将 Flume 采集到的数据先放入一个中间栈做保存，然后让 Hadoop 慢慢消化海量数据，那么就可以解决上述的问题。
Kafka 是一个分布式的基于发布/订阅模式的消息队列（Message Queue），主要应用于大数据实时处理领域。
目前企业中比较常见的消息队列产品主要有 Kafka、ActiveMQ 、RabbitMQ 、RocketMQ 等。
在大数据场景主要采用 Kafka 作为消息队列。在 JavaEE 开发中主要采用 ActiveMQ、RabbitMQ、RocketMQ。
2）应用场景 2.1.削峰 缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。
2.2.解耦 解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/88be951c245130ddd7a12e84f690c472/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T16:34:39+08:00" />
<meta property="article:modified_time" content="2024-01-10T16:34:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>【Kafka-3.x-教程】专栏：</p> 
<p><a href="https://blog.csdn.net/weixin_53543905/article/details/135337489">【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135344331">【Kafka-3.x-教程】-【二】Kafka-生产者-Producer</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135406229">【Kafka-3.x-教程】-【三】Kafka-Broker、Kafka-Kraft</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135456078">【Kafka-3.x-教程】-【四】Kafka-消费者-Consumer</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135472163">【Kafka-3.x-教程】-【五】Kafka-监控-Eagle</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135475378">【Kafka-3.x-教程】-【六】Kafka 外部系统集成 【Flume、Flink、SpringBoot、Spark】</a><br> <a href="https://blog.csdn.net/weixin_53543905/article/details/135479341">【Kafka-3.x-教程】-【七】Kafka 生产调优、Kafka 压力测试</a></p> 
<p></p> 
<div class="toc"> 
 <h4>【Kafka-3.x-教程】-【一】Kafka 概述、Kafka 快速入门</h4> 
 <ul><li><a href="#1_12" rel="nofollow">1）定义</a></li><li><a href="#2_27" rel="nofollow">2）应用场景</a></li><li><ul><li><a href="#21_28" rel="nofollow">2.1.削峰</a></li><li><a href="#22_34" rel="nofollow">2.2.解耦</a></li><li><a href="#23_40" rel="nofollow">2.3.异步通信</a></li></ul> 
  </li><li><a href="#3_46" rel="nofollow">3）两种模式</a></li><li><a href="#4_72" rel="nofollow">4）基础架构</a></li><li><a href="#5_102" rel="nofollow">5）安装部署</a></li><li><ul><li><a href="#51_103" rel="nofollow">5.1.集群规划</a></li><li><a href="#52_108" rel="nofollow">5.2.集群部署</a></li><li><a href="#53_289" rel="nofollow">5.3.集群启停脚本</a></li></ul> 
  </li><li><a href="#6Kafka__329" rel="nofollow">6）Kafka 命令行操作</a></li><li><ul><li><a href="#61_330" rel="nofollow">6.1.主题命令行操作</a></li><li><a href="#62_373" rel="nofollow">6.2.生产者命令行操作</a></li><li><a href="#63_386" rel="nofollow">6.3.消费者命令行操作</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1_12"></a>1）定义</h2> 
<p>试想这样一个场景，某宝或某东购物平台，上游通过 Flume 采集相关日志到 Hadoop 集群中，在平时流量小的时候，Hadoop 的写入速度在 100M/s，Flume 采集日志的速度也在 100M/s，这样下游的 Hadoop 上传速度可以和上游的 Flume 采集速度相匹配，没有问题。</p> 
<p>那么现在到了促销季，假如双十一进行大促销，那么 Flume 采集到的数据量远超过平时的 100M/s（比如达到 200M/s），而下游的 Hadoop 速度的极限已经是 100M/s 了，此时如果不解决这个问题就会导致上游数据量无限度的堆积，导致日志服务器爆掉。</p> 
<p>此时 Kafka 出现了，试想，如果将 Flume 采集到的数据先放入一个中间栈做保存，然后让 Hadoop 慢慢消化海量数据，那么就可以解决上述的问题。</p> 
<p>Kafka 是一个<code>分布式的</code>基于<code>发布</code>/<code>订阅</code>模式的<code>消息队列（Message Queue）</code>，主要应用于<code>大数据实时处理</code>领域。</p> 
<p>目前企业中比较常见的消息队列产品主要有 Kafka、ActiveMQ 、RabbitMQ 、RocketMQ 等。</p> 
<p>在大数据场景主要采用 Kafka 作为消息队列。在 JavaEE 开发中主要采用 ActiveMQ、RabbitMQ、RocketMQ。</p> 
<p><img src="https://images2.imgbox.com/36/1a/Se4Qt5Zf_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2_27"></a>2）应用场景</h2> 
<h3><a id="21_28"></a>2.1.削峰</h3> 
<p>缓冲/消峰：有助于控制和优化数据流经过系统的速度，解决生产消息和消费消息的处理速度不一致的情况。</p> 
<p><img src="https://images2.imgbox.com/0a/f1/pKzLLUGz_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_34"></a>2.2.解耦</h3> 
<p>解耦：允许你独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。</p> 
<p><img src="https://images2.imgbox.com/0f/5b/lqCrJPyQ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23_40"></a>2.3.异步通信</h3> 
<p>异步通信：<code>允许用户把一个消息放入队列，但并不立即处理它</code>，然后<code>在需要的时候再去处理它们</code>。</p> 
<p><img src="https://images2.imgbox.com/43/88/OuYVpd8D_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="3_46"></a>3）两种模式</h2> 
<p>1、点对点模式</p> 
<ul><li>消费者主动拉取数据，消息收到后清除消息</li></ul> 
<p>2、发布/订阅模式</p> 
<ul><li> <p>可以有多个topic主题（浏览、点赞、收藏、评论等）</p> </li><li> <p>消费者消费数据之后，不删除数据</p> </li><li> <p>每个消费者相互独立，都可以消费到数据</p> </li></ul> 
<p>3、对比</p> 
<p>相对于点对点模式来说，发布订阅模式的优势有：</p> 
<ul><li>消息被消费完不会被删除，可以提供给其他消费者继续消费</li><li>可以有多个 topic 进行接收消息</li><li>至于数据怎么删除，可以规定时间定期进行清理</li></ul> 
<p><img src="https://images2.imgbox.com/f0/e7/sNucteoa_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="4_72"></a>4）基础架构</h2> 
<p>1、为方便扩展，并提高吞吐量，一个 topic 分为多个 partition。</p> 
<p>2、配合分区的设计，提出消费者组的概念，组内每个消费者并行消费。</p> 
<p>3、为提高可用性，为每个partition增加若干副本，类似 NameNode HA。</p> 
<p>4、ZK 中记录谁是 leader，Kafka 2.8.0 以后也可以配置不采用 ZK。</p> 
<p><img src="https://images2.imgbox.com/77/6a/aqAH6mM1_o.png" alt="在这里插入图片描述"></p> 
<p>（1）<font color="purple">Producer：</font>消息生产者，就是向 Kafka broker 发消息的客户端。</p> 
<p>（2）<font color="purple">Consumer：</font>消息消费者，向 Kafka broker 取消息的客户端。</p> 
<p>（3）<font color="purple">Consumer Group（CG）：</font>消费者组，由多个 consumer 组成。消费者组内每个消费者负责消费不同分区的数据，一个分区只能由一个组内消费者消费；消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。</p> 
<p>（4）<font color="purple">Broker：</font>一台 Kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。</p> 
<p>（5）<font color="purple">Topic：</font>可以理解为一个队列，生产者和消费者面向的都是一个 topic。</p> 
<p>（6）<font color="purple">Partition：</font>为了实现扩展性，一个非常大的 topic 可以分布到多个 broker（即服务器）上，一个 topic 可以分为多个 partition，每个 partition 是一个有序的队列。</p> 
<p>（7）<font color="purple">Replica：</font>副本。一个 topic 的每个分区都有若干个副本，一个 Leader 和若干个 Follower。</p> 
<p>（8）<font color="purple">Leader：</font>每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是 Leader。</p> 
<p>（9）<font color="purple">Follower：</font>每个分区多个副本中的“从”，实时从 Leader 中同步数据，保持和 Leader 数据的同步。Leader 发生故障时，某个 Follower 会成为新的 Leader。</p> 
<h2><a id="5_102"></a>5）安装部署</h2> 
<h3><a id="51_103"></a>5.1.集群规划</h3> 
<p><img src="https://images2.imgbox.com/9f/7a/njZ2pBkJ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="52_108"></a>5.2.集群部署</h3> 
<p>1、<a href="http://kafka.apache.org/downloads.html" rel="nofollow">官方下载地址</a></p> 
<p>2、解压安装包</p> 
<pre><code class="prism language-shell"><span class="token function">tar</span> <span class="token parameter variable">-zxvf</span> kafka_2.12-3.0.0.tgz <span class="token parameter variable">-C</span> /opt/module/
</code></pre> 
<p>3、修改解压后的文件名称</p> 
<pre><code class="prism language-shell"><span class="token function">mv</span> kafka_2.12-3.0.0/ kafka
</code></pre> 
<p>4、进入到<code>/opt/module/kafka</code>目录，修改配置文件</p> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> config/
<span class="token function">vim</span> server.properties
</code></pre> 
<p>输入以下内容：</p> 
<pre><code class="prism language-shell"><span class="token comment">#broker 的全局唯一编号，不能重复，只能是数字。</span>
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">0</span>
<span class="token comment">#处理网络请求的线程数量</span>
<span class="token assign-left variable">num.network.threads</span><span class="token operator">=</span><span class="token number">3</span>
<span class="token comment">#用来处理磁盘 IO 的线程数量</span>
<span class="token assign-left variable">num.io.threads</span><span class="token operator">=</span><span class="token number">8</span>
<span class="token comment">#发送套接字的缓冲区大小</span>
<span class="token assign-left variable">socket.send.buffer.bytes</span><span class="token operator">=</span><span class="token number">102400</span>
<span class="token comment">#接收套接字的缓冲区大小</span>
<span class="token assign-left variable">socket.receive.buffer.bytes</span><span class="token operator">=</span><span class="token number">102400</span>
<span class="token comment">#请求套接字的缓冲区大小</span>
<span class="token assign-left variable">socket.request.max.bytes</span><span class="token operator">=</span><span class="token number">104857600</span>
<span class="token comment">#kafka 运行日志(数据)存放的路径，路径不需要提前创建，kafka 自动帮你创建，可以</span>
配置多个磁盘路径，路径与路径之间可以用<span class="token string">"，"</span>分隔
<span class="token assign-left variable">log.dirs</span><span class="token operator">=</span>/opt/module/kafka/datas
<span class="token comment">#topic 在当前 broker 上的分区个数</span>
<span class="token assign-left variable">num.partitions</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment">#用来恢复和清理 data 下数据的线程数量</span>
<span class="token assign-left variable">num.recovery.threads.per.data.dir</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment"># 每个 topic 创建时的副本数，默认时 1 个副本</span>
<span class="token assign-left variable">offsets.topic.replication.factor</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token comment">#segment 文件保留的最长时间，超时将被删除</span>
<span class="token assign-left variable">log.retention.hours</span><span class="token operator">=</span><span class="token number">168</span>
<span class="token comment">#每个 segment 文件的大小，默认最大 1G</span>
<span class="token assign-left variable">log.segment.bytes</span><span class="token operator">=</span><span class="token number">1073741824</span>
<span class="token comment"># 检查过期数据的时间，默认 5 分钟检查一次是否数据过期</span>
<span class="token assign-left variable">log.retention.check.interval.ms</span><span class="token operator">=</span><span class="token number">300000</span>
<span class="token comment">#配置连接 Zookeeper 集群地址（在 zk 根目录下创建/kafka，方便管理）</span>
<span class="token assign-left variable">zookeeper.connect</span><span class="token operator">=</span>hadoop102:2181,hadoop103:2181,hadoop104:2181/ka
fka
</code></pre> 
<p>5、分发安装包</p> 
<pre><code class="prism language-shell">xsync kafka/
</code></pre> 
<p><font color="purple">xsync 脚本：</font></p> 
<pre><code class="prism language-shell"><span class="token shebang important">#!/bin/bash</span>

<span class="token comment">#1. 判断参数个数</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token variable">$#</span> <span class="token parameter variable">-lt</span> <span class="token number">1</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
    <span class="token builtin class-name">echo</span> Not Enough Arguement<span class="token operator">!</span>
    <span class="token builtin class-name">exit</span><span class="token punctuation">;</span>
<span class="token keyword">fi</span>

<span class="token comment">#2. 遍历集群所有机器</span>
<span class="token keyword">for</span> <span class="token for-or-select variable">host</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
<span class="token keyword">do</span>
    <span class="token builtin class-name">echo</span> <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>  <span class="token variable">$host</span>  <span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span><span class="token operator">==</span>
    <span class="token comment">#3. 遍历所有目录，挨个发送</span>

    <span class="token keyword">for</span> <span class="token for-or-select variable">file</span> <span class="token keyword">in</span> <span class="token variable">$@</span>
    <span class="token keyword">do</span>
        <span class="token comment">#4. 判断文件是否存在</span>
        <span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token parameter variable">-e</span> <span class="token variable">$file</span> <span class="token punctuation">]</span>
            <span class="token keyword">then</span>
                <span class="token comment">#5. 获取父目录</span>
                <span class="token assign-left variable">pdir</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">cd</span> <span class="token parameter variable">-P</span> <span class="token punctuation">$(</span>dirname $file<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token builtin class-name">pwd</span><span class="token variable">)</span></span>

                <span class="token comment">#6. 获取当前文件的名称</span>
                <span class="token assign-left variable">fname</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span><span class="token function">basename</span> $file<span class="token variable">)</span></span>
                <span class="token function">ssh</span> <span class="token variable">$host</span> <span class="token string">"mkdir -p <span class="token variable">$pdir</span>"</span>
                <span class="token function">rsync</span> <span class="token parameter variable">-av</span> <span class="token variable">$pdir</span>/<span class="token variable">$fname</span> <span class="token variable">$host</span><span class="token builtin class-name">:</span><span class="token variable">$pdir</span>
            <span class="token keyword">else</span>
                <span class="token builtin class-name">echo</span> <span class="token variable">$file</span> does not exists<span class="token operator">!</span>
        <span class="token keyword">fi</span>
    <span class="token keyword">done</span>
<span class="token keyword">done</span>
</code></pre> 
<p>6、分别在 <strong>hadoop103</strong> 和 <strong>hadoop104</strong> 上修改配置文件<code>/opt/module/kafka/config/server.properties</code>中的 <font color="purple">broker.id=1、broker.id=2</font></p> 
<p><font color="red">注：broker.id 不得重复，整个集群中唯一。</font></p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> kafka/config/server.properties
修改:
<span class="token comment"># The id of the broker. This must be set to a unique integer for </span>
each broker.
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token punctuation">[</span>atguigu@hadoop104 module<span class="token punctuation">]</span>$ <span class="token function">vim</span> kafka/config/server.properties
修改:
<span class="token comment"># The id of the broker. This must be set to a unique integer for </span>
each broker.
<span class="token assign-left variable">broker.id</span><span class="token operator">=</span><span class="token number">2</span>
</code></pre> 
<p>7、配置环境变量</p> 
<p>（1）在<code>/etc/profile.d/my_env.sh</code>文件中增加 kafka 环境变量配置</p> 
<pre><code class="prism language-shell"><span class="token function">sudo</span> <span class="token function">vim</span> /etc/profile.d/my_env.sh
</code></pre> 
<p>增加如下内容：</p> 
<pre><code class="prism language-shell"><span class="token comment">#KAFKA_HOME</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HOME</span><span class="token operator">=</span>/opt/module/kafka
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$KAFKA_HOME</span>/bin
</code></pre> 
<p>（2）刷新一下环境变量。</p> 
<pre><code class="prism language-shell"><span class="token builtin class-name">source</span> /etc/profile
</code></pre> 
<p>（3）分发环境变量文件到其他节点，并 source。</p> 
<pre><code class="prism language-shell"><span class="token function">sudo</span> /home/atguigu/bin/xsync 
/etc/profile.d/my_env.sh
<span class="token builtin class-name">source</span> /etc/profile
<span class="token builtin class-name">source</span> /etc/profile
</code></pre> 
<p>8、启动集群</p> 
<p>（1）先启动 Zookeeper 集群，然后启动 Kafka。</p> 
<pre><code class="prism language-shell">zk.sh start
</code></pre> 
<p><font color="purple">zk.sh 脚本：</font></p> 
<pre><code class="prism language-shell"><span class="token shebang important">#!/bin/bash</span>

<span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span>
<span class="token string">"start"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
	<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
	<span class="token keyword">do</span>
		<span class="token builtin class-name">echo</span>  ------------- zookeeper <span class="token variable">$i</span> 启动 ------------
		<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">"/opt/module/zookeeper-3.5.7/bin/zkServer.sh start"</span>
	<span class="token keyword">done</span>
<span class="token punctuation">}</span>
<span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">"stop"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
	<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
	<span class="token keyword">do</span>
		<span class="token builtin class-name">echo</span>  ------------- zookeeper <span class="token variable">$i</span> 停止 ------------
		<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">"/opt/module/zookeeper-3.5.7/bin/zkServer.sh stop"</span>
	<span class="token keyword">done</span>
<span class="token punctuation">}</span>
<span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">"status"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
	<span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
	<span class="token keyword">do</span>
		<span class="token builtin class-name">echo</span>  ------------- zookeeper <span class="token variable">$i</span> 状态 ------------
		<span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">"/opt/module/zookeeper-3.5.7/bin/zkServer.sh status"</span>
	<span class="token keyword">done</span>
<span class="token punctuation">}</span>
<span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token keyword">esac</span>
</code></pre> 
<p>（2）依次在 hadoop102、hadoop103、hadoop104 节点上启动 Kafka。</p> 
<pre><code class="prism language-shell">bin/kafka-server-start.sh <span class="token parameter variable">-daemon</span> config/server.properties
</code></pre> 
<p><font color="red">注意：配置文件的路径要能够到 server.properties。</font></p> 
<p>9、关闭集群</p> 
<pre><code class="prism language-shell">bin/kafka-server-stop.sh
</code></pre> 
<h3><a id="53_289"></a>5.3.集群启停脚本</h3> 
<p>1、在<code>/home/atguigu/bin</code>目录下创建文件<code>kf.sh</code>脚本文件</p> 
<pre><code class="prism language-shell"><span class="token function">vim</span> kf.sh
</code></pre> 
<p>脚本如下：</p> 
<pre><code class="prism language-shell"><span class="token shebang important">#! /bin/bash</span>
<span class="token keyword">case</span> <span class="token variable">$1</span> <span class="token keyword">in</span>
<span class="token string">"start"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
 <span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
 <span class="token keyword">do</span>
 <span class="token builtin class-name">echo</span> <span class="token string">" --------启动 <span class="token variable">$i</span> Kafka-------"</span>
 <span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">"/opt/module/kafka/bin/kafka-server-start.sh -
daemon /opt/module/kafka/config/server.properties"</span>
 <span class="token keyword">done</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">"stop"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
 <span class="token keyword">for</span> <span class="token for-or-select variable">i</span> <span class="token keyword">in</span> hadoop102 hadoop103 hadoop104
 <span class="token keyword">do</span>
 <span class="token builtin class-name">echo</span> <span class="token string">" --------停止 <span class="token variable">$i</span> Kafka-------"</span>
 <span class="token function">ssh</span> <span class="token variable">$i</span> <span class="token string">"/opt/module/kafka/bin/kafka-server-stop.sh "</span>
 <span class="token keyword">done</span>
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token keyword">esac</span>
</code></pre> 
<p>2、添加执行权限</p> 
<pre><code class="prism language-shell"><span class="token function">chmod</span> +x kf.sh
</code></pre> 
<p>3、启动集群命令</p> 
<pre><code class="prism language-shell">kf.sh start
</code></pre> 
<p>4、停止集群命令</p> 
<pre><code class="prism language-shell">kf.sh stop
</code></pre> 
<p><font color="red">注意：停止 Kafka 集群时，一定要等 Kafka 所有节点进程全部停止后再停止 Zookeeper 集群。因为 Zookeeper 集群当中记录着 Kafka 集群相关信息，Zookeeper 集群一旦先停止，Kafka 集群就没有办法再获取停止进程的信息，只能手动杀死 Kafka 进程了。</font></p> 
<h2><a id="6Kafka__329"></a>6）Kafka 命令行操作</h2> 
<h3><a id="61_330"></a>6.1.主题命令行操作</h3> 
<p><img src="https://images2.imgbox.com/3a/a1/r78V2zpA_o.png" alt="在这里插入图片描述"></p> 
<p>1、查看操作主题命令参数</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh
</code></pre> 
<p><img src="https://images2.imgbox.com/08/55/fyUOMqQN_o.png" alt="在这里插入图片描述"></p> 
<p>2、查看当前服务器中的所有 topic</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--list</span>
</code></pre> 
<p>3、创建 first topic</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--create</span> <span class="token parameter variable">--partitions</span> <span class="token number">1</span> --replication-factor <span class="token number">3</span> <span class="token parameter variable">--topic</span> first
</code></pre> 
<p>选项说明：</p> 
<blockquote> 
 <p>–topic 定义 topic 名</p> 
 <p>–replication-factor 定义副本数</p> 
 <p>–partitions 定义分区数</p> 
</blockquote> 
<p>4、查看 first 主题的详情</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> first
</code></pre> 
<p>5、修改分区数（注意：分区数只能增加，不能减少）</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--alter</span> <span class="token parameter variable">--topic</span> first <span class="token parameter variable">--partitions</span> <span class="token number">3</span>
</code></pre> 
<p>6、再次查看 first 主题的详情</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--describe</span> <span class="token parameter variable">--topic</span> first
</code></pre> 
<p>7、删除 topic</p> 
<pre><code class="prism language-shell">bin/kafka-topics.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--delete</span> <span class="token parameter variable">--topic</span> first
</code></pre> 
<h3><a id="62_373"></a>6.2.生产者命令行操作</h3> 
<p>1、查看操作生产者命令参数</p> 
<pre><code class="prism language-shell">bin/kafka-console-producer.sh
</code></pre> 
<p><img src="https://images2.imgbox.com/4e/e3/rdSkT8Be_o.png" alt="在这里插入图片描述"></p> 
<p>2、发送消息</p> 
<pre><code class="prism language-shell">bin/kafka-console-producer.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--topic</span> first
</code></pre> 
<h3><a id="63_386"></a>6.3.消费者命令行操作</h3> 
<p>1、查看操作消费者命令参数</p> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh
</code></pre> 
<p><img src="https://images2.imgbox.com/92/4b/j3g0K8N3_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/88/25/NUfh0Y9o_o.png" alt="在这里插入图片描述"></p> 
<p>2、消费消息</p> 
<p>（1）消费 first 主题中的数据。</p> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 <span class="token parameter variable">--topic</span> first
</code></pre> 
<p>（2）把主题中所有的数据都读取出来（包括历史数据）。</p> 
<pre><code class="prism language-shell">bin/kafka-console-consumer.sh --bootstrap-server hadoop102:9092 --from-beginning <span class="token parameter variable">--topic</span> first
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/31d87ac8f64524b5269d0aa2f9dcaaab/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【从零开始学习微服务 | 第一篇】什么是微服务</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/63a431b2d88abb5933d79aa354aff769/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">echarts的dispatchAction</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>