<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python数据分析案例30——中国高票房电影分析（爬虫获取数据及分析可视化全流程） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python数据分析案例30——中国高票房电影分析（爬虫获取数据及分析可视化全流程）" />
<meta property="og:description" content="案例背景 最近总看到《消失的她》票房多少多少，《孤注一掷》票房又破了多少多少.....
于是我就想自己爬虫一下获取中国高票房的电影数据，然后分析一下。
数据来源于淘票票：影片总票房排行榜 (maoyan.com)
爬它就行。
不会爬虫的同学要这代码演示数据可以参考：数据
代码实现 首先爬虫获取数据：
数据获取 导入包
import requests; import pandas as pd from bs4 import BeautifulSoup 传入网页和请求头
url = &#39;https://piaofang.maoyan.com/rankings/year&#39; headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.62&#39;} response1 = requests.get(url,headers=headers) response.status_code 200表示获取网页文件成功
然后解析网页文件，获取电影信息数据
%%time soup = BeautifulSoup(response.text, &#39;html.parser&#39;) soup=soup.find(&#39;div&#39;, id=&#39;ranks-list&#39;) movie_list = [] for ul_tag in soup.find_all(&#39;ul&#39;, class_=&#39;row&#39;): movie_info = {} li_tags = ul_tag.find_all(&#39;li&#39;) movie_info[&#39;序号&#39;] = li_tags[0]." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/382a13819a044407ffc34cb7a84f18c2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-02T10:21:25+08:00" />
<meta property="article:modified_time" content="2024-01-02T10:21:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python数据分析案例30——中国高票房电影分析（爬虫获取数据及分析可视化全流程）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>案例背景</h3> 
<p>最近总看到《消失的她》票房多少多少，《孤注一掷》票房又破了多少多少.....</p> 
<p>于是我就想自己爬虫一下获取中国高票房的电影数据，然后分析一下。</p> 
<p>数据来源于淘票票：<a href="https://piaofang.maoyan.com/rankings/year" rel="nofollow" title="影片总票房排行榜 (maoyan.com)">影片总票房排行榜 (maoyan.com)</a></p> 
<p><img alt="" height="271" src="https://images2.imgbox.com/dc/9e/Ax3UOV3o_o.png" width="590"></p> 
<p>爬它就行。</p> 
<p>不会爬虫的同学要这代码演示数据可以参考：<a class="link-info" href="https://mbd.pub/o/bread/ZZmUmphr" rel="nofollow" title="数据">数据</a></p> 
<p>  </p> 
<hr> 
<h3>代码实现</h3> 
<p>首先爬虫获取数据：</p> 
<h4>数据获取</h4> 
<p>导入包</p> 
<pre><code class="language-python">import requests; import pandas as pd
from bs4 import BeautifulSoup
</code></pre> 
<p> 传入网页和请求头</p> 
<pre><code class="language-python">url = 'https://piaofang.maoyan.com/rankings/year'
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36 Edg/116.0.1938.62'}
response1 = requests.get(url,headers=headers)
response.status_code</code></pre> 
<p><img alt="" height="92" src="https://images2.imgbox.com/58/79/YVgaxcvI_o.png" width="322"><br> 200表示获取网页文件成功</p> 
<p>然后解析网页文件，获取电影信息数据</p> 
<pre><code class="language-python">%%time
soup = BeautifulSoup(response.text, 'html.parser')
soup=soup.find('div', id='ranks-list')
movie_list = []

for ul_tag in soup.find_all('ul', class_='row'):
    movie_info = {}
    li_tags = ul_tag.find_all('li')
    movie_info['序号'] = li_tags[0].text
    movie_info['标题'] = li_tags[1].find('p', class_='first-line').text
    movie_info['上映日期'] = li_tags[1].find('p', class_='second-line').text
    movie_info['票房(亿)'] = f'{(float(li_tags[2].text)/10000):.2f}'
    movie_info['平均票价'] = li_tags[3].text
    movie_info['平均人次'] = li_tags[4].text
    movie_list.append(movie_info)</code></pre> 
<p>数据获取完成了！ 查看字典数据：<br>  </p> 
<pre><code class="language-python">movie_list</code></pre> 
<p><img alt="" height="358" src="https://images2.imgbox.com/25/5b/GfqF9S8E_o.png" width="389"></p> 
<p>可以，很标准，没什么问题，然后把它变成数据框，查看前三行</p> 
<pre><code class="language-python">movies=pd.DataFrame(movie_list)
movies.head(3)</code></pre> 
<p><img alt="" height="220" src="https://images2.imgbox.com/d0/e3/BOKNSPoL_o.png" width="799"></p> 
<p>对数据进行一定的清洗，我们看到上映日期里面的数据有“上映”两个字，我们要去掉，然后把它变成时间格式，票房，票价，人次都要变成数值型数据。</p> 
<p>我们只取票房前250的电影，对应豆瓣250.,,,,中国票房250好叭</p> 
<p>然后我们还需要从日期里面抽取年份和月份两列数据，方便后面分析。</p> 
<pre><code class="language-python">#清洗
movies=movies.set_index('序号').loc[:'250',:]  
movies['上映日期']=pd.to_datetime(movies['上映日期'].str.replace('上映',''))
movies[['票房(亿)','平均票价','平均人次']]=movies.loc[:,['票房(亿)','平均票价','平均人次']].astype(float)
movies['年份']=movies['上映日期'].dt.year  ;   movies['月份']=movies['上映日期'].dt.month
movies.head(2)</code></pre> 
<p><img alt="" height="121" src="https://images2.imgbox.com/94/e3/rkgyOCim_o.png" width="437"></p> 
<p>数据处理完毕，开始画图分析！</p> 
<hr> 
<h4>画图分析</h4> 
<p>导入画图包</p> 
<pre><code class="language-python">import seaborn as sns
import matplotlib.pyplot as plt
plt.rcParams ['font.sans-serif'] ='SimHei'               #显示中文
plt.rcParams ['axes.unicode_minus']=False  </code></pre> 
<p> 对票房排名前20的电影画柱状图</p> 
<pre><code class="language-python">top_movies = movies.nlargest(20, '票房(亿)')
plt.figure(figsize=(7, 4),dpi=128)
ax = sns.barplot(x='票房(亿)', y='标题', data=top_movies, orient='h',alpha=0.5)
#plt.xticks(rotation=80, ha='center')

# 在柱子上标注数值
for p in ax.patches:
    ax.annotate(f'{p.get_width():.2f}', (p.get_width(), p.get_y() + p.get_height() / 2.),
                va='center', fontsize=8, color='gray', xytext=(5, 0),
                textcoords='offset points')

plt.title('票房前20的电影')
plt.xlabel('票房数量（亿）')
plt.ylabel('电影名称')
plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="" height="313" src="https://images2.imgbox.com/3a/fd/WNif4r1i_o.png" width="590"></p> 
<p>还不错，很好看，可以看到中国历史票房前20 的电影名称和他们的票房数量。</p> 
<p></p> 
<p>对平均票价和平均人次进行分析：<br>  </p> 
<pre><code class="language-python">plt.figure(figsize=(7, 6),dpi=128)
# 绘制第一个子图：平均票价点图
plt.subplot(2, 2, 1)
sns.scatterplot(y='平均票价', x='年份', data=movies,c=movies['年份'],cmap='plasma')
plt.title('平均票价点图')
plt.ylabel('平均票价')
#plt.xticks([])

plt.subplot(2, 2, 2)
sns.boxplot(y='平均票价', data=movies)
plt.title('平均票价箱线图')
plt.xlabel('平均票价')

plt.subplot(2, 2, 3)
sns.scatterplot(y='平均人次', x='年份', data=movies,c=movies['年份'],cmap='plasma')
plt.title('平均人次点图')
plt.ylabel('平均人次')

plt.subplot(2, 2, 4)
sns.boxplot(y='平均人次', data=movies)
plt.title('平均人次箱线图')
plt.xlabel('平均人次')
plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="" height="556" src="https://images2.imgbox.com/e7/36/zqpmripX_o.png" width="671"></p> 
<p>先看柱状图，可以看到平均票价和平均人次都是有一些离群点的，然后我们在左边画了他们和年份的的散点图，可以明细看到，随着年份越大，电影的平均人次越来越低，平均票价越来越高.....也就是最近的电影比起之前的电影来说，越来越贵，而且平均每场看的人越来越少......也侧面反映了我国电影业的一些“高票价”，‘幽灵剧场刷票房’ 等等乱象...</p> 
<p>我注意到2000年之前有一个电影每场人次特别高，票价很低，它是什么电影我很好奇我就查看了一下：</p> 
<pre><code class="language-python">movies[movies['年份']&lt;2000]</code></pre> 
<p><img alt="" height="109" src="https://images2.imgbox.com/b8/28/wyt5puju_o.png" width="562"></p> 
<p>原来是国民级别的《泰坦尼克号》,那没事了，名副实归。</p> 
<p></p> 
<p>不同年份的高票房电影数量：</p> 
<pre><code class="language-python">plt.figure(figsize=(7, 3), dpi=128)
year_count = movies['年份'].value_counts().sort_index()
sns.lineplot(x=year_count.index, y=year_count.values, marker='o', lw=1.5, markersize=3)
plt.fill_between(year_count.index, 0, year_count, color='lightblue', alpha=0.8)
plt.title('不同年份高票房电影数量')
plt.xlabel('年份')
plt.ylabel('电影数量')
# 在每个数据点上标注数值
for x, y in zip(year_count.index, year_count.values):
    plt.text(x, y+0.2, str(y), ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="" height="549" src="https://images2.imgbox.com/e2/18/x5XPuytZ_o.png" width="1200"></p> 
<p>可以看到，我国高票房的电影，从2010年开始高速增长，到2017年到达峰值，著名的《战狼2》就是2017年上映的，然后2018和2019略微下降，2020年断崖下跌，，为什么，懂得懂得，疫情原因嘛。</p> 
<p>对高票房电影不同月份的占比百分比分析：</p> 
<pre><code class="language-python">plt.figure(figsize=(4, 4),dpi=128)
month_count = movies['月份'].value_counts(normalize=True).sort_index()
# 绘制饼图
sns.set_palette("Set3")
plt.pie(month_count, labels=month_count.index, autopct='%.1f%%', startangle=140, counterclock=False,
        wedgeprops={'alpha': 0.9})
plt.axis('equal')  # 保证饼图是正圆形
plt.text(-0.3,1.2,'不同月份高票房电影数量',fontsize=8)
plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="" height="461" src="https://images2.imgbox.com/53/e4/7TQ6V7K4_o.png" width="480"></p> 
<p>我们可以看到，高票房电影主要集中在2月，7月，12月，三个月份区间。</p> 
<p>理由也很简单，2月春节，7月暑假，12月跨年.....电影都喜欢这三个时间段上映。</p> 
<p></p> 
<hr> 
<h4>自定义评价指标</h4> 
<p>我们上面都是之间拿票房进行分析的，我们发现，票房高的电影真的是反映了看的人多嘛？它真的是受观众喜欢的好电影嘛？</p> 
<p>数据有限，虽然我们无法剔除宣传，时间热点，导演，社会风气等等影响因素，但是我们可以把票价进行一定的控制。因为票房高的电影也有可能是票价过高造成的，所以我们用‘票房/平均票价’，然后和‘平均人次’进行一个加权求和。</p> 
<p>票房/平均票价 表示看电影的人群量，给7成权重，平均人次 给一个3层的权重，然后都进行标准化统一数据单位，加起来就成为我们自己的评价指标：</p> 
<p><br> 为了方便标准化我们先导入一个机器学习库里面sklearn的标准化函数</p> 
<pre><code class="language-python">from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()</code></pre> 
<p> 计算指标：</p> 
<pre><code class="language-python">movies['我的评价指标']=(movies['票房(亿)'].astype(float)/movies['平均票价'].astype(float))
data1=scaler.fit_transform(movies[['我的评价指标', '平均人次']])
movies['我的评价指标']=0.7*data1[:,0]+0.3*data1[:,1]
movies=movies.sort_values(by='我的评价指标',ascending=False)</code></pre> 
<p>画图查看：<br>  </p> 
<pre><code class="language-python">my_top_movies = movies.nlargest(20, '我的评价指标')
plt.figure(figsize=(7, 4),dpi=128)
ax = sns.barplot(x='我的评价指标', y='标题', data=my_top_movies, orient='h',alpha=0.6,palette='rainbow_r')
#plt.xticks(rotation=80, ha='center')

# 在柱子上标注数值
for p in ax.patches:
    ax.annotate(f'{p.get_width():.2f}', (p.get_width(), p.get_y() + p.get_height() / 2.),
                va='center', fontsize=8, color='gray', xytext=(5, 0),
                textcoords='offset points')

plt.title('前20电影')
plt.xlabel('我的评价指标')
plt.ylabel('电影名称')
plt.tight_layout()
plt.show()</code></pre> 
<p><img alt="" height="374" src="https://images2.imgbox.com/9b/7f/0YUlnaaH_o.png" width="676"></p> 
<p>和之前的最高票房前20 的作对比，这样我们能比较哪些是票房过高的电影，哪些是可能被低估的电影。</p> 
<pre><code class="language-python">def get_unique_elements(list1, list2):
    # 获取每个列表中的唯一元素
    set1 = set(list1) ; set2 = set(list2)
    unique_to_list1 = list(set1 - set2)
    unique_to_list2 = list(set2 - set1)
    common_elements = list(set1 &amp; set2)
    return unique_to_list1, common_elements, unique_to_list2
票价过高的电影,确实是好电影,被低估的电影=get_unique_elements(top_movies['标题'].to_list(), my_top_movies['标题'].to_list())</code></pre> 
<p> 这个函数的作用是选出第一个列表特有的元素，两个列表共有的元素，第二个列表特有的元素。</p> 
<p>若这个电影在票房前20里面，也在我们的评价指标前20里面，那么就是好电影。若它在在票房前20里面，不在我们的评价指标前20里面，那可能就是票价过高的“水分电影”。</p> 
<pre><code class="language-python">print(f'票价过高的电影:{票价过高的电影},\n\n确实是好电影:{确实是好电影},\n\n低估的电影:{被低估的电影}')</code></pre> 
<p><img alt="" height="186" src="https://images2.imgbox.com/3e/0b/f6lDVk0D_o.png" width="1200"></p> 
<pre>票价过高的电影:['八佰', '我和我的家乡', '独行月球', '流浪地球2'],emmmm</pre> 
<p>这几个电影，我都没怎么深入了解就不评价了......</p> 
<p></p> 
<h4>词云图</h4> 
<p>加个词云图吧，好看些：</p> 
<p>先自定义一个随机颜色函数：</p> 
<pre><code class="language-python">import numpy as np
def randomcolor():
    colorArr = ['1','2','3','4','5','6','7','8','9','A','B','C','D','E','F']
    color ="#"+''.join([np.random.choice(colorArr) for i in range(6)])
    return color
[randomcolor() for i in range(3)]</code></pre> 
<p>然后画词云图：这里用了垫图掩码，原始图片形状为这样的六角星：—— <img alt="" height="113" src="https://images2.imgbox.com/b8/51/vTH5fiD9_o.png" width="125"></p> 
<pre><code class="language-python">from wordcloud import WordCloud
from matplotlib import colors
from imageio.v2 import imread    #形状设置
mask = imread('词云.png')  

# 将'标题'和'票房'列合并为字典，以便生成词云图
word_freq = dict(zip(movies['标题'], movies['票房(亿)']))
color_list=[randomcolor() for i in range(20)]

wordcloud = WordCloud(width=1000, height=500, background_color='white',font_path='simhei.ttf',
                      max_words=50, max_font_size=50,random_state=42,mask = mask,
                          colormap=colors.ListedColormap(color_list)).generate_from_frequencies(word_freq)

plt.figure(figsize=(10, 5),dpi=256)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()</code></pre> 
<p><br><img alt="" height="1037" src="https://images2.imgbox.com/01/21/PdRp6sLh_o.png" width="1200"></p> 
<p></p> 
<p></p> 
<hr> 
<h4>总结</h4> 
<p>本次演示了从数据爬虫获取，到清洗整理，再到计算和可视化分析的全流程，再多加点图和文字分析角度，加点模型，作为大多数的本科生的论文算是差不多的工作量了。</p> 
<hr> 
<p>创作不易，看官觉得写得还不错的话点个关注和赞吧，本人会持续更新python数据分析领域的代码文章~(需要定制代码可私信)</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5883553de7bba00701f65c8d4b3cda6a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">unity图像处理简单流程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/cc1993df4083c40e85f11a910f1db7ff/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Git：基础要点</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>