<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>kafka: 基础概念回顾（生产者客户端和机架感知相关内容） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="kafka: 基础概念回顾（生产者客户端和机架感知相关内容）" />
<meta property="og:description" content="一、kafka生产者客户端 在kafka体系结构中有如下几个重要的概念：
Producer：生产者，负责生产消息并投递到kafka broker的某个的分区中Consumer：消费者，负责消费kafka若干个分区中的消息Broker：kafka服务节点 1、整体架构：数据发送流程 （1）生产者
拦截器
生产者的拦截器可以在消息发送前做一些拦截工作对数据进行相应的处理，比如：消息过滤、消息内容修改等。 package org.apache.kafka.clients.producer; import org.apache.kafka.common.Configurable; public interface ProducerInterceptor&lt;K, V&gt; extends Configurable { //在将消息序列化和计算分区之前会调⽤该⽅法，⽤来对消息进⾏相应的定制化操作，如修改消息内容 public ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record); //在消息被应答之前或者消息发送失败时调⽤该⽅法，优先于⽤⼾设定的Callback之前执⾏，如统计消息发送成功或失败的次数 public void onAcknowledgement(RecordMetadata metadata, Exception exception); public void close(); } 序列化器分区器 二、kafka数据可靠性保证 1、LEO和HW 2、工作流程 3、Leader Epoch 三、粘性分区策略 四、机架感知 1、概念 2、机架感知分区分配策略 3、验证 （1）验证目标
机架感知特性将同⼀分区的副本分散到不同的机架上rack机制消费者可以消费到follower副本中的数据 （2）参数配置
broker端配置：
配置名：broker.rack=my-rack-id 解释：broker属于的rack 配置名：replica.selector.class 解释：ReplicaSelector实现类的全名，包括路径 (⽐如 RackAwareReplicaSelector 即按 rack id 指定消费) Client端配置：
client.rack
consumer端配置配置名：client.rack解释：这个参数需要和broker端指定的 broker.rack 相同，表⽰去哪个rack中获取数据。默认：null （3）环境准备：kafka集群
kafka实例数: 4两个kafka实例broker." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ff6602bb1354f08b7fdda449c84227c4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T09:54:04+08:00" />
<meta property="article:modified_time" content="2024-01-10T09:54:04+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">kafka: 基础概念回顾（生产者客户端和机架感知相关内容）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="kafka_0"></a>一、kafka生产者客户端</h4> 
<p>在kafka体系结构中有如下几个重要的概念：</p> 
<ul><li>Producer：生产者，负责生产消息并投递到kafka broker的某个的分区中</li><li>Consumer：消费者，负责消费kafka若干个分区中的消息</li><li>Broker：kafka服务节点</li></ul> 
<h5><a id="1_7"></a>1、整体架构：数据发送流程</h5> 
<p><img src="https://images2.imgbox.com/71/90/R5GcNy9J_o.png" alt="在这里插入图片描述"><br> （1）生产者</p> 
<ul><li>拦截器<br> 生产者的拦截器可以在消息发送前做一些拦截工作对数据进行相应的处理，比如：消息过滤、消息内容修改等。</li></ul> 
<pre><code>package org.apache.kafka.clients.producer;
import org.apache.kafka.common.Configurable;
public interface ProducerInterceptor&lt;K, V&gt; extends Configurable {
		//在将消息序列化和计算分区之前会调⽤该⽅法，⽤来对消息进⾏相应的定制化操作，如修改消息内容
		public ProducerRecord&lt;K, V&gt; onSend(ProducerRecord&lt;K, V&gt; record);
		//在消息被应答之前或者消息发送失败时调⽤该⽅法，优先于⽤⼾设定的Callback之前执⾏，如统计消息发送成功或失败的次数
		public void onAcknowledgement(RecordMetadata metadata, Exception exception);
		public void close();
}
</code></pre> 
<ul><li>序列化器</li><li>分区器</li></ul> 
<h4><a id="kafka_28"></a>二、kafka数据可靠性保证</h4> 
<h5><a id="1LEOHW_29"></a>1、LEO和HW</h5> 
<h5><a id="2_31"></a>2、工作流程</h5> 
<h5><a id="3Leader_Epoch_33"></a>3、Leader Epoch</h5> 
<h4><a id="_35"></a>三、粘性分区策略</h4> 
<h4><a id="_37"></a>四、机架感知</h4> 
<h5><a id="1_39"></a>1、概念</h5> 
<h5><a id="2_41"></a>2、机架感知分区分配策略</h5> 
<h5><a id="3_43"></a>3、验证</h5> 
<p>（1）验证目标</p> 
<ul><li>机架感知特性将同⼀分区的副本分散到不同的机架上</li><li>rack机制消费者可以消费到follower副本中的数据</li></ul> 
<p>（2）参数配置<br> broker端配置：</p> 
<ul><li>配置名：broker.rack=my-rack-id 
  <ul><li>解释：broker属于的rack</li></ul> </li><li>配置名：replica.selector.class 
  <ul><li>解释：ReplicaSelector实现类的全名，包括路径 (⽐如 RackAwareReplicaSelector 即按 rack id 指定消费)</li></ul> </li></ul> 
<p>Client端配置：<br> client.rack</p> 
<ul><li>consumer端配置</li><li>配置名：client.rack</li><li>解释：这个参数需要和broker端指定的 broker.rack 相同，表⽰去哪个rack中获取数据。</li><li>默认：null</li></ul> 
<p>（3）环境准备：kafka集群</p> 
<ul><li>kafka实例数: 4</li><li>两个kafka实例broker.rack配置为0，另外两个kafka实例broker.rack配置为了2，broker端配置如下：</li></ul> 
<pre><code>server1：
broker.id=0

broker.rack=0
replica.selector.class=org.apache.kafka.common.replica.RackAwareReplicaSelector

server2：
broker.id=1
broker.rack=0
replica.selector.class=org.apache.kafka.common.replica.RackAwareReplicaSelector

server3
broker.id=2
broker.rack=2
replica.selector.class=org.apache.kafka.common.replica.RackAwareReplicaSelector

server4
broker.id=3
broker.rack=2
replica.selector.class=org.apache.kafka.common.replica.RackAwareReplicaSelector
</code></pre> 
<p>启动kafka集群，服务端⽇志信息：<br> <img src="https://images2.imgbox.com/5e/8d/vvXkvBLq_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/50/4a/Pkgt039h_o.png" alt="在这里插入图片描述"><br> 验证一：机架感知特性将同一分区的副本分散到不同的机架上<br> <img src="https://images2.imgbox.com/dc/61/0Q8Rfzxc_o.png" alt="在这里插入图片描述"><br> 创建topic rack02，副本被分配到了broker1和2<br> <img src="https://images2.imgbox.com/92/19/ZGmGl9UI_o.png" alt="在这里插入图片描述"><br> 创建topic rack03 副本被分配到了0和3<br> <img src="https://images2.imgbox.com/56/d2/3WQRVKQ9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0e/4d/wJxEg9gX_o.png" alt="在这里插入图片描述"></p> 
<p>验证二：客⼾端（消费者）验证：rack机制消费者可以消费到follower副本中的数据</p> 
<p>验证代码如下：</p> 
<pre><code>package person.xsc.train.producer;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.serialization.StringDeserializer;
import person.xsc.train.client.KafkaConsumerClient;
import person.xsc.train.constant.KafkaConstant;
import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;
public class Demo {
		public static KafkaConsumer&lt;String, String&gt; kafkaConsumer;
		public static void main(String[] args) {
				Properties properties = new Properties();
				properties.put(KafkaConstant.BOOTSTRAP_SERVERS, "localhost:9093,localhos
				properties.put(KafkaConstant.GROUP_ID, "test01");
				properties.put(KafkaConstant.ENABLE_AUTO_COMMIT, "true");
				properties.put(KafkaConstant.AUTO_COMMIT_INTERVAL_MS, "1000");
				properties.put(KafkaConstant.KEY_DESERIALIZER, StringDeserializer.class.
				properties.put(KafkaConstant.VALUE_DESERIALIZER, StringDeserializer.clas
				properties.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, "10");
				properties.put(ConsumerConfig.CLIENT_RACK_CONFIG, "0");
				properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
				kafkaConsumer = KafkaConsumerClient.createKafkaClient(properties);
				
				receiveMessage("rack02");
		}
		public static void receiveMessage(String topic) {
				TopicPartition topicPartition0 = new TopicPartition(topic, 0);
				kafkaConsumer.assign(Arrays.asList(topicPartition0));
				while(true) {
						// Kafka的消费者⼀次拉取⼀批的数据
						ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll
						//System.out.println("开始打印消息！");
						// 5.将将记录（record）的offset、key、value都打印出来
						for (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) {
								// 主题
								String topicName = consumerRecord.topic();
								int partition = consumerRecord.partition();
								// offset：这条消息处于Kafka分区中的哪个位置
								long offset = consumerRecord.offset();
								// key\value
								String key = consumerRecord.key();
								String value = consumerRecord.value();
								System.out.println(String.format("topic: %s, partition: %s, offs
						}
				}
		}
}
</code></pre> 
<p>前置背景：<br> Topic rack02的partition 0分区的副本为broker2（对应的rack为2）和broker1（对应的rack为0），其中broker2为leader（在⾮rack机制下仅能消费到leader中的数据）。</p> 
<p>在上述代码中，消费者配置中限制了rack为0，消费的分区为0，因此映射到broker1。通过测试可验证在rack机制下消费者可以消费到folloer副本中的数据，测试如下：<br> <img src="https://images2.imgbox.com/30/b7/hQaWWTzw_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_166"></a>五、机架感知存在的问题</h4>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/abb56a2f3301c8febca1cb5a6fe3a8c2/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【flink番外篇】10、对有状态或及时 UDF 和自定义算子进行单元测试</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5c7ea122833099a391cf5525131c5c09/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">设计模式之观察者模式【行为型模式】</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>