<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Hadoop 集群搭建实战 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Hadoop 集群搭建实战" />
<meta property="og:description" content="Hadoop 集群搭建实战 环境准备：
1. VMware 搭建三台CentOS 7.8主机 2. 静态IP，关闭防火墙，修改主机名，配置免密登录，集群时间同步 3. 在/opt目录下创建文件夹 mkdir -p /opt/apps/software --软件安装包存放目录 mkdir -p /opt/apps/servers --软件安装目录 4. Hadoop下载地址： https://archive.apache.org/dist/hadoop/common/hadoop-2.9.2/ 5. 上传hadoop安装文件到/opt/apps/software 集群规划：
框架hadoop-121hadoop-122hadoop-123HDFSNameNode、DataNodeDataNodeSecondaryNameNode、DataNodeYARNNodeManagerNodeManagerNodeManager、ResourceManager 安装Hadoop 登录hadoop-121节点，进入/opt/apps/software，解压安装文件到/opt/apps/servers
tar -zxvf hadoop-2.9.2.tar.gz -C /opt/apps/servers 查看是否解压成功
ls /opt/apps/servers/ 添加Hadoop到环境变量 vim /etc/profile
# hadoop export HADOOP_HOME=/opt/apps/servers/hadoop-2.9.2 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbin 使环境变量生效
source /etc/profile 验证hadoop是否安装成功
hadoop version hadoop安装目录下各个文件
drwxr-xr-x. 2 501 dialout 194 Nov 13 2018 bin drwxr-xr-x. 3 501 dialout 20 Nov 13 2018 etc drwxr-xr-x." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0f3a8eeadaff6e7daccc24b82eb6c8bb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-31T17:57:02+08:00" />
<meta property="article:modified_time" content="2021-12-31T17:57:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Hadoop 集群搭建实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Hadoop__0"></a>Hadoop 集群搭建实战</h2> 
<p>环境准备：</p> 
<pre><code class="prism language-shell"><span class="token number">1</span>. VMware 搭建三台CentOS <span class="token number">7.8</span>主机
<span class="token number">2</span>. 静态IP，关闭防火墙，修改主机名，配置免密登录，集群时间同步
<span class="token number">3</span>. 在/opt目录下创建文件夹
   <span class="token function">mkdir</span> -p /opt/apps/software --软件安装包存放目录
   <span class="token function">mkdir</span> -p /opt/apps/servers --软件安装目录
<span class="token number">4</span>. Hadoop下载地址：
   https://archive.apache.org/dist/hadoop/common/hadoop-2.9.2/
<span class="token number">5</span>. 上传hadoop安装文件到/opt/apps/software
</code></pre> 
<p>集群规划：</p> 
<table><thead><tr><th>框架</th><th>hadoop-121</th><th>hadoop-122</th><th>hadoop-123</th></tr></thead><tbody><tr><td>HDFS</td><td>NameNode、DataNode</td><td>DataNode</td><td>SecondaryNameNode、DataNode</td></tr><tr><td>YARN</td><td>NodeManager</td><td>NodeManager</td><td>NodeManager、ResourceManager</td></tr></tbody></table> 
<h3><a id="Hadoop_22"></a>安装Hadoop</h3> 
<ol><li> <p>登录hadoop-121节点，进入/opt/apps/software，解压安装文件到/opt/apps/servers</p> <pre><code class="prism language-shell"><span class="token function">tar</span> -zxvf hadoop-2.9.2.tar.gz -C /opt/apps/servers
</code></pre> </li><li> <p>查看是否解压成功</p> <pre><code class="prism language-shell"><span class="token function">ls</span> /opt/apps/servers/
</code></pre> </li><li> <p>添加Hadoop到环境变量 vim /etc/profile</p> <pre><code class="prism language-shell"><span class="token comment"># hadoop</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">HADOOP_HOME</span><span class="token operator">=</span>/opt/apps/servers/hadoop-2.9.2
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$HADOOP_HOME</span>/bin
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$HADOOP_HOME</span>/sbin
</code></pre> </li><li> <p>使环境变量生效</p> <pre><code class="prism language-shell"><span class="token builtin class-name">source</span> /etc/profile
</code></pre> </li><li> <p>验证hadoop是否安装成功</p> <pre><code class="prism language-shell">hadoop version
</code></pre> </li><li> <p>hadoop安装目录下各个文件</p> <pre><code class="prism language-shell">drwxr-xr-x. <span class="token number">2</span> <span class="token number">501</span> dialout    <span class="token number">194</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> bin
drwxr-xr-x. <span class="token number">3</span> <span class="token number">501</span> dialout     <span class="token number">20</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> etc
drwxr-xr-x. <span class="token number">2</span> <span class="token number">501</span> dialout    <span class="token number">106</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> include
drwxr-xr-x. <span class="token number">3</span> <span class="token number">501</span> dialout     <span class="token number">20</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> lib
drwxr-xr-x. <span class="token number">2</span> <span class="token number">501</span> dialout    <span class="token number">239</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> libexec
-rw-r--r--. <span class="token number">1</span> <span class="token number">501</span> dialout <span class="token number">106210</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> LICENSE.txt
-rw-r--r--. <span class="token number">1</span> <span class="token number">501</span> dialout  <span class="token number">15917</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> NOTICE.txt
-rw-r--r--. <span class="token number">1</span> <span class="token number">501</span> dialout   <span class="token number">1366</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> README.txt
drwxr-xr-x. <span class="token number">3</span> <span class="token number">501</span> dialout   <span class="token number">4096</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> sbin
drwxr-xr-x. <span class="token number">4</span> <span class="token number">501</span> dialout     <span class="token number">31</span> Nov <span class="token number">13</span>  <span class="token number">2018</span> share

主要目录介绍如下：
<span class="token number">1</span>. bin目录:对Hadoop进行操作的相关命令，如hadoop,hdfs等 
<span class="token number">2</span>. etc目录：Hadoop的配置文件目录，入hdfs-site.xml,core-site.xml等 
<span class="token number">3</span>. lib目录：Hadoop本地库（解压缩的依赖） 
<span class="token number">4</span>. sbin目录：存放的是Hadoop集群启动停止相关脚本，命令
<span class="token number">5</span>. share目录：Hadoop的一些jar,官方案例jar，文档等
</code></pre> </li></ol> 
<h3><a id="_79"></a>集群配置</h3> 
<p>Hadoop集群配置 = HDFS集群配置 + MapReduce集群配置 + Yarn集群配置</p> 
<p>HDFS集群配置</p> 
<ol><li> <p>将JDK路径明确配置给HDFS（修改hadoop-env.sh）</p> </li><li> <p>指定NameNode节点以及数据存储目录（修改core-site.xml）</p> </li><li> <p>指定SecondaryNameNode节点（修改hdfs-site.xml）</p> </li><li> <p>指定DataNode从节点（修改etc/hadoop/slaves文件，每个节点配置信息占一行）</p> </li></ol> 
<p>MapReduce集群配置</p> 
<ol><li> <p>将JDK路径明确配置给MapReduce（修改mapred-env.sh）</p> </li><li> <p>指定MapReduce计算框架运行Yarn资源调度框架（修改mapred-site.xml）</p> </li></ol> 
<p>Yarn集群配置</p> 
<ol><li> <p>将JDK路径明确配置给Yarn（修改yarn-env.sh）</p> </li><li> <p>指定ResourceManager老大节点所在计算机节点（修改yarn-site.xml）</p> </li><li> <p>指定NodeManager节点（会通过slaves文件内容确定）</p> </li></ol> 
<p>集群配置具体步骤：</p> 
<h4><a id="HDFS_109"></a>HDFS集群配置</h4> 
<pre><code class="prism language-shell">~<span class="token comment"># cd /opt/apps/servers/hadoop-2.9.2/etc/hadoop/</span>
</code></pre> 
<ol><li> <p>配置hadoop-env.sh，将JDK路径明确配置给HDFS</p> <pre><code class="prism language-shell">~<span class="token comment"># vim hadoop-env.sh</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/local/apps/jdk/jdk1.8.0_301
</code></pre> </li><li> <p>指定NameNode节点以及数据存储目录（修改core-site.xml）</p> <pre><code class="prism language-shell">~<span class="token comment"># vim core-site.xml</span>
</code></pre> <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
  <span class="token comment">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://hadoop-121:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

  <span class="token comment">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/opt/apps/servers/hadoop-2.9.2/data/tmp<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
  &lt;/property
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> <p>core-site.xml的默认配置</p> <pre><code class="prism language-shell">https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-common/core-default.xml
</code></pre> </li><li> <p>指定secondarynamenode节点(修改hdfs-site.xml)</p> <pre><code class="prism language-shell">~<span class="token comment"># vim hdfs-site.xml</span>
</code></pre> <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
  <span class="token comment">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.namenode.secondary.http-address<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop-123:50090<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

  <span class="token comment">&lt;!--副本数量 --&gt;</span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>3<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> <p>hdfs-site.xml的默认配置</p> <pre><code class="prism language-shell">https://hadoop.apache.org/docs/r2.9.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
</code></pre> </li><li> <p>指定datanode从节点(修改slaves文件，每个节点配置信息占一行)</p> <pre><code class="prism language-shell">~<span class="token comment"># vim slaves</span>
hadoop-121
hadoop-122
hadoop-123
</code></pre> <p><strong>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</strong></p> </li></ol> 
<h4><a id="MapReduce_189"></a>MapReduce集群配置</h4> 
<ol><li> <p>指定MapReduce使用的jdk路径（修改mapred-env.sh）</p> <pre><code class="prism language-shell">~<span class="token comment"># vim mapred-env.sh</span>

<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/local/apps/jdk/jdk1.8.0_301
</code></pre> </li><li> <p>指定MapReduce计算框架运行Yarn资源调度框架(修改mapred-site.xml)</p> <pre><code class="prism language-shell">~<span class="token comment"># mv mapred-site.xml.template mapred-site.xml </span>
~<span class="token comment"># vim mapred-site.xml</span>
</code></pre> <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
 <span class="token comment">&lt;!-- 指定MR运行在Yarn上 --&gt;</span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> <p>mapred-site.xml默认配置</p> <pre><code class="prism language-shell">https://hadoop.apache.org/docs/r2.9.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
</code></pre> </li></ol> 
<h4><a id="Yarn_222"></a>Yarn集群配置</h4> 
<ol><li> <p>指定JDK路径</p> <pre><code class="prism language-shell">~<span class="token comment"># vim yarn-env.sh</span>

<span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_HOME</span><span class="token operator">=</span>/usr/local/apps/jdk/jdk1.8.0_301
</code></pre> </li><li> <p>指定ResourceManager的master节点信息（修改yarn-site.xml）</p> <pre><code class="prism language-shell">~<span class="token comment"># vim yarn-site.xml</span>
</code></pre> <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
 <span class="token comment">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hadoop-123<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
 <span class="token comment">&lt;!-- Reducer获取数据的方式 --&gt;</span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
   <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> <p>yarn-site.xml的默认配置</p> <pre><code class="prism language-shell">https://hadoop.apache.org/docs/r2.9.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
</code></pre> </li><li> <p>指定NodeManager节点（slaves文件已修改）</p> </li></ol> 
<p><strong>注意：</strong></p> 
<p>Hadoop安装目录所属用户和所属用户组信息，默认是501 dialout，而我们操作Hadoop集群的用户使用的是虚拟机的root用户，所以为了避免出现信息混乱，修改Hadoop安装目录所属用户和用户组。</p> 
<pre><code class="prism language-shell">~<span class="token comment"># chown -R root:root /opt/apps/servers/hadoop-2.9.2</span>
</code></pre> 
<h3><a id="_269"></a>分发配置</h3> 
<h4><a id="rsyncscript_271"></a>编写集群分发脚本rsync-script</h4> 
<ol><li> <p>rsync 远程同步工具</p> 
  <blockquote> 
   <p>rsync主要用于备份和镜像。具有速度快、避免复制相同内容和支持符号链接的优点。</p> 
   <p>rsync和scp区别：用rsync做文件的复制要比scp的速度快，rsync只对<strong>差异文件做更新</strong>。scp是把所有文件都复制过去。</p> 
  </blockquote> 
  <ul><li> <p>基本语法</p> <pre><code class="prism language-shell"><span class="token function">rsync</span>	-rvl	<span class="token variable">$pdir</span>/<span class="token variable">$fname</span>	<span class="token variable">$user</span>@<span class="token variable">$host</span><span class="token builtin class-name">:</span><span class="token variable">$pdir</span>/<span class="token variable">$fname</span>
</code></pre> </li><li> <p>选项参数说明</p> 
    <table><thead><tr><th>选项</th><th>功能</th></tr></thead><tbody><tr><td>-r</td><td>递归</td></tr><tr><td>-v</td><td>显示复制过程</td></tr><tr><td>-l</td><td>拷贝符号连接</td></tr></tbody></table></li></ul> </li><li> <p>rsync案例</p> 
  <ul><li> <p>三台虚拟机安装rsync (执行安装需要保证机器联网)</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 ~<span class="token punctuation">]</span><span class="token comment"># yum install -y rsync</span>
</code></pre> </li><li> <p>把hadoop-121机器上的/opt/apps/software目录同步到hadoop-122服务器的root用户下的/opt/目录</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 ~<span class="token punctuation">]</span><span class="token comment"># rsync -rvl /opt/apps/software/ root@hadoop-122:/opt/apps/software</span>
</code></pre> </li></ul> </li><li> <p>脚本实现</p> 
  <ul><li> <p>在/usr/local/bin目录下创建文件rsync-script，文件内容如下：</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 bin<span class="token punctuation">]</span><span class="token comment"># vim rsync-script</span>
<span class="token comment">#!/bin/bash</span>
<span class="token comment">#1 获取命令输入参数的个数，如果个数为0，直接退出命令</span>
<span class="token assign-left variable">paramnum</span><span class="token operator">=</span><span class="token variable">$#</span>
<span class="token keyword">if</span><span class="token variable"><span class="token punctuation">((</span>paramnum<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">))</span></span><span class="token punctuation">;</span> <span class="token keyword">then</span>
<span class="token builtin class-name">echo</span> no params<span class="token punctuation">;</span>
<span class="token builtin class-name">exit</span><span class="token punctuation">;</span>
<span class="token keyword">fi</span>

<span class="token comment">#2 根据传入参数获取文件名称</span>
<span class="token assign-left variable">p1</span><span class="token operator">=</span><span class="token variable">$1</span>
<span class="token assign-left variable">file_name</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">basename</span> $p1<span class="token variable">`</span></span>
<span class="token builtin class-name">echo</span> <span class="token assign-left variable">fname</span><span class="token operator">=</span><span class="token variable">$file_name</span>

<span class="token comment">#3 获取输入参数的绝对路径</span>
<span class="token assign-left variable">pdir</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token builtin class-name">cd</span> -P <span class="token punctuation">$(</span>dirname $p1<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token builtin class-name">pwd</span><span class="token variable">`</span></span>
<span class="token builtin class-name">echo</span> <span class="token assign-left variable">pdir</span><span class="token operator">=</span><span class="token variable">$pdir</span>

<span class="token comment">#4 获取用户名称</span>
<span class="token assign-left variable">user</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span><span class="token function">whoami</span><span class="token variable">`</span></span>

<span class="token comment">#5 循环执行rsync</span>
<span class="token keyword">for</span><span class="token variable"><span class="token punctuation">((</span>host<span class="token operator">=</span><span class="token number">121</span><span class="token punctuation">;</span> host<span class="token operator">&lt;</span><span class="token number">124</span><span class="token punctuation">;</span> host<span class="token operator">++</span><span class="token punctuation">))</span></span><span class="token punctuation">;</span> <span class="token keyword">do</span>
  <span class="token builtin class-name">echo</span> ------------------- hadoop-<span class="token variable">$host</span> --------------
  <span class="token function">rsync</span> -rvl <span class="token variable">$pdir</span>/<span class="token variable">$file_name</span> <span class="token variable">$user</span>@hadoop-<span class="token variable">$host</span><span class="token builtin class-name">:</span><span class="token variable">$pdir</span>
<span class="token keyword">done</span>
</code></pre> </li><li> <p>修改rsync-script具有执行权限</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 bin<span class="token punctuation">]</span><span class="token comment"># chmod 777 rsync-script</span>
</code></pre> </li><li> <p>调用脚本分发Hadoop安装目录到其他节点</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 ~<span class="token punctuation">]</span><span class="token comment"># rsync-script /opt/apps/servers/hadoop-2.9.2</span>
</code></pre> </li></ul> </li></ol> 
<h3><a id="_352"></a>启动集群</h3> 
<h4><a id="_354"></a>单节点启动</h4> 
<p>第一次启动需先格式化NameNode，非第一次不用执行格式化NameNode操作</p> 
<pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hadoop namenode -format</span>
</code></pre> 
<p>格式化效果：</p> 
<p><img src="https://images2.imgbox.com/8e/21/BuXAUmY5_o.png" alt="请添加图片描述"><br> 格式化后创建的文件：/opt/apps/servers/hadoop-2.9.2/data/tmp/dfs/name/current</p> 
<p><img src="https://images2.imgbox.com/26/16/BnDCnrau_o.png" alt="请添加图片描述"></p> 
<ol><li> <p>在hadoop-121上启动NameNode</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hadoop-daemon.sh start namenode</span>
starting namenode, logging to /opt/apps/servers/hadoop-2.9.2/logs/hadoop-root-namenode-hadoop-01.out
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">5378</span> Jps
<span class="token number">5302</span> NameNode
</code></pre> </li><li> <p>在hadoop-121、hadoop-122、hadoop-123节点分别启动DataNode</p> <pre><code class="prism language-shell"><span class="token comment"># hadoop-121</span>
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hadoop-daemon.sh start datanode</span>
starting datanode, logging to /opt/apps/servers/hadoop-2.9.2/logs/hadoop-root-datanode-hadoop-01.out
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">5302</span> NameNode
<span class="token number">5565</span> DataNode
<span class="token number">5647</span> Jps

<span class="token comment"># hadoop-122</span>
<span class="token punctuation">[</span>root@hadoop-122 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hadoop-daemon.sh start datanode</span>
starting datanode, logging to /opt/apps/servers/hadoop-2.9.2/logs/hadoop-root-datanode-hadoop-122.out
<span class="token punctuation">[</span>root@hadoop-122 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">4324</span> DataNode
<span class="token number">4406</span> Jps

<span class="token comment"># hadoop-123</span>
<span class="token punctuation">[</span>root@hadoop-123 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hadoop-daemon.sh start datanode</span>
starting datanode, logging to /opt/apps/servers/hadoop-2.9.2/logs/hadoop-root-datanode-hadoop-123.out
<span class="token punctuation">[</span>root@hadoop-123 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">4140</span> DataNode
<span class="token number">4222</span> Jps
</code></pre> </li><li> <p>web端查看Hdfs界面</p> </li></ol> 
<p><img src="https://images2.imgbox.com/22/71/3Tprw1Kb_o.png" alt="请添加图片描述"></p> 
<ol start="4"><li> <p>Yarn集群单节点启动</p> <pre><code class="prism language-shell"><span class="token comment"># hadoop-123</span>
<span class="token punctuation">[</span>root@hadoop-123 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># yarn-daemon.sh start resourcemanager</span>
starting resourcemanager, logging to /opt/apps/servers/hadoop-2.9.2/logs/yarn-root-resourcemanager-hadoop-123.out
<span class="token punctuation">[</span>root@hadoop-123 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">4484</span> Jps
<span class="token number">4140</span> DataNode
<span class="token number">4269</span> ResourceManager
<span class="token comment"># hadoop-122</span>
<span class="token punctuation">[</span>root@hadoop-122 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># yarn-daemon.sh start nodemanager</span>
starting nodemanager, logging to /opt/apps/servers/hadoop-2.9.2/logs/yarn-root-nodemanager-hadoop-122.out
<span class="token punctuation">[</span>root@hadoop-122 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">4324</span> DataNode
<span class="token number">4516</span> Jps
<span class="token number">4453</span> NodeManager
<span class="token comment"># hadoop-121</span>
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># yarn-daemon.sh start nodemanager</span>
starting nodemanager, logging to /opt/apps/servers/hadoop-2.9.2/logs/yarn-root-nodemanager-hadoop-01.out
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">5763</span> Jps
<span class="token number">5700</span> NodeManager
<span class="token number">5302</span> NameNode
<span class="token number">5565</span> DataNode
</code></pre> <p>思考：Hadoop集群每次需要一个一个节点的启动，如果节点数量增加至成千上万，那该如何？</p> </li></ol> 
<h4><a id="_440"></a>集群群起</h4> 
<ol><li> <p>如果之前还未进行NameNode的格式化，需要进行格式化</p> <pre><code class="prism language-shell">hadoop namenode -format
</code></pre> </li><li> <p>启动HDFS</p> <pre><code class="prism language-shell"><span class="token comment"># hadoop-121</span>
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># start-dfs.sh</span>
<span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">6657</span> DataNode
<span class="token number">6520</span> NameNode
<span class="token number">7080</span> Jps
<span class="token number">6943</span> NodeManager
<span class="token comment"># hadoop-122</span>
<span class="token punctuation">[</span>root@hadoop-122 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">4812</span> DataNode
<span class="token number">4942</span> Jps
<span class="token comment"># hadoop-123</span>
<span class="token punctuation">[</span>root@hadoop-123 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># jps</span>
<span class="token number">5250</span> NodeManager
<span class="token number">4837</span> SecondaryNameNode
<span class="token number">5369</span> Jps
<span class="token number">4955</span> ResourceManager
<span class="token number">4733</span> DataNode
</code></pre> </li><li> <p>启动YARN</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-123 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># start-yarn.sh</span>
</code></pre> </li></ol> 
<p><strong>注意：</strong> NameNode和ResourceManger不是在同一台机器，不能在NameNode上启动YARN，应该在ResouceManager所在的机器上启动YARN。</p> 
<h4><a id="Hadoop_479"></a>Hadoop集群启动停止命令汇总</h4> 
<ol><li> <p>各个服务组件逐一启动/停止</p> 
  <ul><li> <p>分别启动/停止HDFS组件</p> <pre><code class="prism language-shell">hadoop-daemon.sh	start / stop	namenode / datanode / secondarynamenode
</code></pre> </li><li> <p>启动/停止YARN</p> <pre><code class="prism language-shell">yarn-daemon.sh	start / stop	resourcemanager / nodemanager
</code></pre> </li></ul> </li><li> <p>各个模块分开启动/停止（配置ssh是前提）常用</p> 
  <ul><li> <p>整体启动/停止HDFS</p> <pre><code class="prism language-shell">start-dfs.sh	/	stop-dfs.sh
</code></pre> </li><li> <p>整体启动/停止YARN</p> <pre><code class="prism language-shell">start-yarn.sh	/	stop-yarn.sh
</code></pre> </li></ul> </li></ol> 
<h3><a id="_509"></a>集群测试</h3> 
<ol><li> <p>HDFS分布式存储初体验</p> <p>从Linux本地文件系统上传下载文件验证HDFS集群是否工作正常</p> <pre><code class="prism language-shell">~<span class="token comment"># hdfs dfs -mkdir -p /test/input </span>

<span class="token comment">#本地home目录创建一个文件 </span>
~<span class="token comment"># cd /root </span>
~<span class="token comment"># vim test.txt </span>
hello hdfs 

<span class="token comment">#上传linxu文件到Hdfs </span>
~<span class="token comment"># hdfs dfs -put /root/test.txt /test/input </span>

<span class="token comment">#从Hdfs下载文件到linux本地 </span>
~<span class="token comment"># hdfs dfs -get /test/input/test.txt</span>
</code></pre> </li></ol> 
<p><img src="https://images2.imgbox.com/5c/8e/lE8fAN3G_o.png" alt="请添加图片描述"><br> 2. MapReduce分布式计算初体验</p> 
<ul><li> <p>在HDFS文件系统根目录下创建一个wcinput文件夹</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 ~<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -put wc.txt /wcinput</span>
</code></pre> </li><li> <p>在/root/目录下创建一个wc.txt文件（本地文件系统）</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 ~<span class="token punctuation">]</span><span class="token comment"># vim wc.txt</span>
hadoop mapreduce <span class="token function">yarn</span> hdfs hadoop mapreduce mapreduce <span class="token function">yarn</span> lagou lagou lagou
</code></pre> </li><li> <p>上传wc.txt到Hdfs目录/wcinput下</p> <pre><code class="prism language-shell">hdfs dfs -put wc.txt /wcinput
</code></pre> </li><li> <p>回到Hadoop目录/opt/apps/servers/hadoop-2.9.2，执行程序</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.2.jar wordcount /wcinput /wcoutput</span>
</code></pre> </li><li> <p>查看结果</p> <pre><code class="prism language-shell"><span class="token punctuation">[</span>root@hadoop-121 hadoop-2.9.2<span class="token punctuation">]</span><span class="token comment"># hdfs dfs -cat /wcoutput/part-r-00000</span>
hadoop	<span class="token number">2</span>
hdfs	<span class="token number">1</span>
lagou	<span class="token number">3</span>
mapreduce	<span class="token number">3</span>
<span class="token function">yarn</span>	<span class="token number">2</span>
</code></pre> </li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/673070d6a1eb8e60e132f23087d67199/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">postgresq子查询exists/not exists操作符用法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d95f02549b4b65dbad273cc62221daa2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ELK--- ELK简介</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>