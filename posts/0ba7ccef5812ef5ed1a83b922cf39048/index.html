<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CRNN模型Python实现笔记一 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CRNN模型Python实现笔记一" />
<meta property="og:description" content="文章目录 一、相关函数讲解1. `log_softmax()`函数2. `contiguous()`函数3. `view()`函数4. `cv2.cvtColor()`函数5. `Variable()`函数6. `torch.IntTensor()`函数7. `readlines()`函数 二、疑难代码行`preds = preds.transpose( 1, 0 ).contiguous().view( -1 )``preds_size = Variable( torch.IntTensor( [preds.size( 0 )] ) )``image = Image.fromarray(np.uint8(img)).convert(&#39;L&#39;)``image = Variable( image )``if gpu: model.load_state_dict( torch.load( model_path ) )``wrong_results.append(&#39;res:{} / label:{}&#39;.format(res,label))` 三、附录 recognizer.py代码 本博客为学习RCNN的代码实现做的笔记，仅作个人参考 一、相关函数讲解 1. log_softmax()函数 torch.nn.functional.log_softmax()是PyTorch中用来计算输入张量的log_softmax操作的函数。
log_softmax函数的计算公式为：
l o g _ s o f t m a x ( x i ) = l o g ( e x i ∑ j = 1 N e x j ) log\_softmax(x_i) = log(\frac{e^{x_i}}{\sum_{j=1}^Ne^{x_j}}) log_softmax(xi​)=log(∑j=1N​exj​exi​​)" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0ba7ccef5812ef5ed1a83b922cf39048/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-20T22:02:00+08:00" />
<meta property="article:modified_time" content="2023-01-20T22:02:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CRNN模型Python实现笔记一</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><ul><li><a href="#_2" rel="nofollow">一、相关函数讲解</a></li><li><ul><li><a href="#1_log_softmax_3" rel="nofollow">1. `log_softmax()`函数</a></li><li><a href="#2_contiguous_23" rel="nofollow">2. `contiguous()`函数</a></li><li><a href="#3_view_30" rel="nofollow">3. `view()`函数</a></li><li><a href="#4_cv2cvtColor_73" rel="nofollow">4. `cv2.cvtColor()`函数</a></li><li><a href="#5_Variable_82" rel="nofollow">5. `Variable()`函数</a></li><li><a href="#6_torchIntTensor_92" rel="nofollow">6. `torch.IntTensor()`函数</a></li><li><a href="#7_readlines_118" rel="nofollow">7. `readlines()`函数</a></li></ul> 
   </li><li><a href="#_141" rel="nofollow">二、疑难代码行</a></li><li><ul><li><a href="#preds__predstranspose_1_0_contiguousview_1__142" rel="nofollow">`preds = preds.transpose( 1, 0 ).contiguous().view( -1 )`</a></li><li><a href="#preds_size__Variable_torchIntTensor_predssize_0____157" rel="nofollow">`preds_size = Variable( torch.IntTensor( [preds.size( 0 )] ) )`</a></li><li><a href="#image__Imagefromarraynpuint8imgconvertL_165" rel="nofollow">`image = Image.fromarray(np.uint8(img)).convert('L')`</a></li><li><a href="#image__Variable_image__178" rel="nofollow">`image = Variable( image )`</a></li><li><a href="#if_gpu_modelload_state_dict_torchload_model_path___197" rel="nofollow">`if gpu: model.load_state_dict( torch.load( model_path ) )`</a></li><li><a href="#wrong_resultsappendres__labelformatreslabel_218" rel="nofollow">`wrong_results.append('res:{} / label:{}'.format(res,label))`</a></li></ul> 
   </li><li><a href="#_recognizerpy_256" rel="nofollow">三、附录 recognizer.py代码</a></li></ul> 
 </li></ul> 
</div> 
<br> 本博客为学习RCNN的代码实现做的笔记，仅作个人参考 
<p></p> 
<h3><a id="_2"></a>一、相关函数讲解</h3> 
<h4><a id="1_log_softmax_3"></a>1. <code>log_softmax()</code>函数</h4> 
<p><code>torch.nn.functional.log_softmax()</code>是PyTorch中用来计算输入张量的log_softmax操作的函数。</p> 
<p>log_softmax函数的计算公式为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          l 
         
        
          o 
         
        
          g 
         
        
          _ 
         
        
          s 
         
        
          o 
         
        
          f 
         
        
          t 
         
        
          m 
         
        
          a 
         
        
          x 
         
        
          ( 
         
         
         
           x 
          
         
           i 
          
         
        
          ) 
         
        
          = 
         
        
          l 
         
        
          o 
         
        
          g 
         
        
          ( 
         
         
          
          
            e 
           
           
           
             x 
            
           
             i 
            
           
          
          
           
           
             ∑ 
            
            
            
              j 
             
            
              = 
             
            
              1 
             
            
           
             N 
            
           
           
           
             e 
            
            
            
              x 
             
            
              j 
             
            
           
          
         
        
          ) 
         
        
       
         log\_softmax(x_i) = log(\frac{e^{x_i}}{\sum_{j=1}^Ne^{x_j}}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord" style="margin-right: 0.0278em;">_</span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right: 0.1076em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 2.6484em; vertical-align: -1.307em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3414em;"><span class="" style="top: -2.1288em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9812em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4358em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6065em;"><span class="" style="top: -3.0051em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2819em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3281em;"><span class="" style="top: -2.357em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.307em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose">)</span></span></span></span></span></span></p> 
<p>其中，x是输入的张量，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          i 
         
        
       
      
        x_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>表示x中第i个元素，N表示x的元素个数。Log_Softmax 函数的值域是<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         − 
        
       
         ∞ 
        
       
         , 
        
       
         0 
        
       
         ] 
        
       
      
        (-\infty,0] 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">−</span><span class="mord">∞</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">0</span><span class="mclose">]</span></span></span></span></span></p> 
<p>使用<code>log_softmax</code>函数可以得到更好的预测结果，因为它使预测结果归一化，每个元素都是在对数空间上的概率值。</p> 
<p>这个函数是在<code>torch.nn.functional</code>中的，可以直接使用<code>F.log_softmax()</code>或<code>torch.nn.functional.log_softmax()</code>来调用，可以使用的参数就是输入的张量，以及指定对哪一维进行softmax。</p> 
<p>输入张量需要满足一定的条件，需要是可导的，且为浮点型或双精度型。</p> 
<br> 
<br> 
<h4><a id="2_contiguous_23"></a>2. <code>contiguous()</code>函数</h4> 
<p><code>contiguous()</code>是Pytorch中的一个函数，它用来确保一个张量在内存中是连续的，返回一个内存连续的新的张量，并且不改变原始张量的值。当在处理某些需要内存连续性的操作时需要使用这个函数，如<code>torch.is_tensor()</code>，<code>torch.tensor()</code>，<code>torch.storage()</code>等。</p> 
<br> 
<br> 
<h4><a id="3_view_30"></a>3. <code>view()</code>函数</h4> 
<p><code>view()</code>是Pytorch中的一个函数，它用来对图像的尺寸进行修改。它接收一个尺寸参数作为输入，该参数指定了新图像的尺寸。返回一个新的张量，其尺寸与给定尺寸相同，并且包含与原始张量相同的元素。这个函数并不改变原始张量，而是返回一个新的张量。</p> 
<p><strong>例如：</strong></p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span>
z <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([4, 4])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([16])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>z<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([2, 8])</span>
</code></pre> 
<p>在这个例子中， x是一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         4 
        
       
         × 
        
       
         4 
        
       
      
        4\times4 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">4</span></span></span></span></span>的张量，使用view(16)函数后返回了一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         × 
        
       
         16 
        
       
      
        1\times16 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">16</span></span></span></span></span>的张量y, view(-1, 8)返回了一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         2 
        
       
         × 
        
       
         8 
        
       
      
        2\times8 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">8</span></span></span></span></span>的张量z。</p> 
<p><strong>例如:</strong></p> 
<p><code>image = image.view( 1, *image.size() )</code></p> 
<p>这一行代码使用了Pytorch中的<code>view()</code>函数来对图像进行尺寸修改。</p> 
<p>其中，<code>*image.size()</code>是一个<strong>拆包操作</strong>，它将<code>image.size()</code>的所有元素拆开并传入view()函数中。</p> 
<p><code>view(1, *image.size())</code>将图像的维度扩展为1 + image.size()的维度。这意味着它会在图像的第一维上增加一个维度，并将原来的图像的尺寸保留下来。</p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">*</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([3, 4, 5])</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># torch.Size([1, 3, 4, 5])</span>
</code></pre> 
<p>在这个例子中，x是一个3x4x5的张量，使用<code>view(1, *x.size())</code>函数后返回了一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         × 
        
       
         3 
        
       
         × 
        
       
         4 
        
       
         × 
        
       
         5 
        
       
      
        1\times3\times4\times5 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">5</span></span></span></span></span>的张量y.</p> 
<p>这段代码通常用在将图像转换为4D张量并传入神经网络中进行处理。因为神经网络中的输入一般是4维的，所以将图像转换为4维张量是很常见的操作。</p> 
<p>如果原始图像是一个3维张量，使用<code>view(1, *x.size())</code>函数可以将其转化为4维的张量，第一维是batch_size，后面三维分别对应图像的长、宽、高。</p> 
<br> 
<br> 
<h4><a id="4_cv2cvtColor_73"></a>4. <code>cv2.cvtColor()</code>函数</h4> 
<p><code>cv2.cvtColor()</code>是OpenCV中的一个函数，它可以将一幅图像从一种颜色空间转换为另一种颜色空间。该函数的第一个参数是要转换的图像，第二个参数是当前图像的颜色空间，第三个参数是目标颜色空间。例如，可以使用<code>cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</code>将一幅<strong>BGR</strong>图像转换为灰度图像。</p> 
<br> 
<br> 
<h4><a id="5_Variable_82"></a>5. <code>Variable()</code>函数</h4> 
<p><code>torch.autograd.Variable(data, requires_grad=True, grad_fn=None)</code></p> 
<p>其中，<code>data</code>表示要封装的张量， <code>requires_grad</code>表示是否需要求梯度， <code>grad_fn</code>表示是由哪个函数生成的。它接收一个Tensor张量作为输入，并返回一个新的变量。这个变量是<code>torch.autograd.Variable</code>类型的。</p> 
<br> 
<br> 
<h4><a id="6_torchIntTensor_92"></a>6. <code>torch.IntTensor()</code>函数</h4> 
<p><code>torch.IntTensor()</code>是Pytorch中用来创建<strong>整型</strong>张量的函数。它可以接收一个列表、元组、矩阵等形式的数据作为输入，并返回一个整型张量。</p> 
<p><strong>例如:</strong></p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 创建一个1维整型张量</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 创建一个2维整型张量</span>
</code></pre> 
<p>也可以使用numpy数组或者其它张量来创建新的张量</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
a <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
</code></pre> 
<p>这个函数常用于数据预处理，在训练模型前将数据转换成张量的形式，这样才能输入到模型中进行训练。</p> 
<blockquote> 
 <p>注意: Pytorch 中有多种不同类型的张量，如<code>torch.FloatTensor</code>, <code>torch.DoubleTensor</code>等, 这些张量类型可以被用在不同场景中。</p> 
</blockquote> 
<br> 
<br> 
<h4><a id="7_readlines_118"></a>7. <code>readlines()</code>函数</h4> 
<p><code>readlines()</code>是Python中文件操作的一个函数，它用于读取文件中的所有行并返回一个列表。该列表中的每个元素都是文件中的一行。</p> 
<p>语法：<br> <code>file_object.readlines()</code><br> 其中，<code>file_object</code>是一个文件对象。使用 <code>open()</code> 函数打开文件后，可以得到一个文件对象。</p> 
<p>示例：</p> 
<pre><code class="prism language-python"><span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'test.txt'</span><span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    lines <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> line <span class="token keyword">in</span> lines<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span>
</code></pre> 
<p>在这个例子中，<code>readlines()</code>函数读取了文件test.txt中的所有行，并将它们存储在lines列表中，最后通过循环打印每一行</p> 
<p>注意，使用 readlines() 函数读取文件时，整个文件都会被读取到内存中，如果文件非常大，可能会导致内存不足的问题。</p> 
<br> 
<br> 
<h3><a id="_141"></a>二、疑难代码行</h3> 
<h4><a id="preds__predstranspose_1_0_contiguousview_1__142"></a><code>preds = preds.transpose( 1, 0 ).contiguous().view( -1 )</code></h4> 
<p>这一行代码是在对一个张量preds进行三步操作：</p> 
<ol><li>首先使用transpose(1, 0)函数对preds进行矩阵转置，交换矩阵的行和列。</li><li>然后使用contiguous()函数将转置后的张量转化为内存连续的张量。</li><li>最后使用view(-1)函数对张量进行尺寸修改，将它转换为一个一维张量，其中包含与原始张量相同的元素。</li></ol> 
<blockquote> 
 <p>在这里，<code>transpose(1, 0)</code> 函数会将维度1和维度0交换，也就是说将原来的第一维和第二维交换。如果原始张量是一个二维矩阵，那么这个函数就是将这个矩阵的行和列交换。</p> 
</blockquote> 
<p>这些操作的结果是将preds张量转化为一个一维的内存连续的张量，其中包含与原始张量相同的元素。</p> 
<br> 
<br> 
<h4><a id="preds_size__Variable_torchIntTensor_predssize_0____157"></a><code>preds_size = Variable( torch.IntTensor( [preds.size( 0 )] ) )</code></h4> 
<p>上面这行代码中, <code>torch.IntTensor([preds.size(0)])</code> 创建了一个整型的张量，并将<code>preds</code>的第一维<code>（size(0)）</code>的长度作为其值，然后这个张量被包装成了一个<code>Variable</code>类型的变量<code>preds_size</code>， 这个变量存储了<code>preds</code>张量第一维的长度，而非张量。</p> 
<br> 
<br> 
<h4><a id="image__Imagefromarraynpuint8imgconvertL_165"></a><code>image = Image.fromarray(np.uint8(img)).convert('L')</code></h4> 
<p>这句代码使用了 PIL (Python Imaging Library) 库中的<code>Image.fromarray</code>函数将 numpy 数组转换为 PIL 图像，并使用<code>.convert('L')</code> 将其转换为灰度图。</p> 
<p><code>np.uint8(img)</code> 这句话是将numpy数组转化为8位无符号整型，因为PIL库中<code>Image.fromarray()</code>函数只接受<strong>uint8类型</strong>数组作为参数。</p> 
<blockquote> 
 <p>转换为灰度图的原因是灰度图只有一个通道，处理起来更简单，并且对于文本识别来说，灰度图也足够用了。</p> 
</blockquote> 
<br> 
<br> 
<h4><a id="image__Variable_image__178"></a><code>image = Variable( image )</code></h4> 
<p>这一行代码使用了Pytorch中的<code>Variable()</code>函数来将一个张量转换成变量类型。</p> 
<p>这里的<code>image</code>是一个张量，使用 Variable(image) 函数将其转换成<code>torch.autograd.Variable</code>类型的变量。</p> 
<p>torch.autograd.Variable是Pytorch中用来跟踪和计算梯度的类，它包含了三个重要的属性：</p> 
<ul><li>data : 存储了Variable所包含的数据的Tensor张量</li><li>grad : 存储了反向传播过程中用来计算梯度的张量</li><li>grad_fn : 存储了创建当前Variable的函数，用来进行反向传播。这个类主要用来在计算图中进行反向传播，计算梯度等操作，在训练神经网络时是一个非常重要的类。</li></ul> 
<p>这个操作通常在训练神经网络之前需要将数据转换成Variable类型。</p> 
<blockquote> 
 <p>注意: Pytorch已经将Variable类合并到了Tensor类中，因此在最新版本中不需要使用Variable类型。</p> 
</blockquote> 
<br> 
<br> 
<h4><a id="if_gpu_modelload_state_dict_torchload_model_path___197"></a><code>if gpu: model.load_state_dict( torch.load( model_path ) )</code></h4> 
<p>这一段代码用来检查是否使用GPU，并在使用GPU时加载模型参数。</p> 
<p>其中，变量 gpu 是一个布尔值，如果它为True，则表示当前程序正在使用GPU。</p> 
<p>如果gpu为True，则执行以下操作：</p> 
<ul><li>使用<code>torch.load()</code>函数加载模型参数，该函数读取指定路径的文件并返回一个字典，字典中包含了<strong>模型的参数</strong>。</li><li>使用<code>model.load_state_dict()</code>函数将加载的模型参数加载到模型中。</li></ul> 
<p>如果gpu为False,则表示不使用gpu进行训练或者推理操作。</p> 
<blockquote> 
 <p>这样做的好处是，如果计算资源有限，或者没有GPU可用，可以在CPU上进行推理，而不需要修改代码。</p> 
 <p>同时，这种方式也可以在有GPU的情况下进行更快的推理，而不需要修改代码。<br> 总之，这段代码提供了一种灵活的方式来选择是否使用GPU进行推理，并且可以在不修改代码的情况下切换使用GPU或者CPU。</p> 
</blockquote> 
<br> 
<br> 
<h4><a id="wrong_resultsappendres__labelformatreslabel_218"></a><code>wrong_results.append('res:{} / label:{}'.format(res,label))</code></h4> 
<p><code>.append('res:{} / label:{}'.format(res,label))</code> 表示将字符串 <code>'res:{} / label:{}'</code> 格式化，并将其添加到 <code>wrong_results</code> 数组中。</p> 
<p>其中 <code>'res:{} / label:{}'</code> 中的 {} 是占位符，它会被 <code>format()</code> 函数中传入的参数替换。</p> 
<p>即将识别结果（res）和真实标签（label）的值插入到字符串 'res:{} / label:{}'中，并添加到 wrong_results 数组中，方便后续处理。</p> 
<p>例如: 假设 res 的值为 “apple”，label 的值为 “banana”，那么这句话将会把 <code>'res:apple / label:banana'</code> 添加到 wrong_results 数组中。</p> 
<p>这样就可以方便的查看哪些结果是错误的。这段代码通常用在错误检测和错误分析中,方便追踪错误预测的结果和正确结果。</p> 
<blockquote> 
 <p>为什么这里要用fomat函数?</p> 
</blockquote> 
<p><code>'res:{} / label:{}'.format(res,label)</code> 使用了字符串格式化函数<code>format()</code>，它可以将变量的值插入到字符串中。</p> 
<p><code>{}</code>是占位符，表示要插入的变量的位置。在这里 <code>{}</code> 被 res 和 label的值替换了。</p> 
<p>使用 <code>format()</code> 函数比直接将变量拼接到字符串中更加灵活和易于维护，并且更加容易阅读。</p> 
<p><strong>例如：</strong></p> 
<pre><code class="prism language-python">name <span class="token operator">=</span> <span class="token string">'Alice'</span>
age <span class="token operator">=</span> <span class="token number">25</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'My name is {} and I am {} years old.'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>name<span class="token punctuation">,</span> age<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>输出:</strong></p> 
<pre><code class="prism language-python">My name <span class="token keyword">is</span> Alice <span class="token keyword">and</span> I am <span class="token number">25</span> years old<span class="token punctuation">.</span>
</code></pre> 
<p>这样做的好处是可以方便地更换变量值，并且可以清晰地看出变量的位置。</p> 
<br> 
<br> 
<h3><a id="_recognizerpy_256"></a>三、附录 recognizer.py代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> utils
<span class="token keyword">import</span> mydataset
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> crnn <span class="token keyword">as</span> crnn
<span class="token keyword">import</span> cv2
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> keys
<span class="token keyword">import</span> config
gpu <span class="token operator">=</span> <span class="token boolean">True</span>
<span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    gpu <span class="token operator">=</span> <span class="token boolean">False</span>


model_path <span class="token operator">=</span> <span class="token string">'./crnn_models/CRNN-0618-10w_21_990.pth'</span>
alphabet <span class="token operator">=</span> keys<span class="token punctuation">.</span>alphabet
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>alphabet<span class="token punctuation">)</span><span class="token punctuation">)</span>
imgH <span class="token operator">=</span> config<span class="token punctuation">.</span>imgH
imgW <span class="token operator">=</span> config<span class="token punctuation">.</span>imgW
model <span class="token operator">=</span> crnn<span class="token punctuation">.</span>CRNN<span class="token punctuation">(</span>imgH<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>alphabet<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
<span class="token keyword">if</span> gpu<span class="token punctuation">:</span>
    model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'loading pretrained model from %s'</span> <span class="token operator">%</span> model_path<span class="token punctuation">)</span>
<span class="token keyword">if</span> gpu<span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span> model_path <span class="token punctuation">)</span> <span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>model_path<span class="token punctuation">,</span>map_location<span class="token operator">=</span><span class="token keyword">lambda</span> storage<span class="token punctuation">,</span>loc<span class="token punctuation">:</span>storage<span class="token punctuation">)</span><span class="token punctuation">)</span>


converter <span class="token operator">=</span> utils<span class="token punctuation">.</span>strLabelConverter<span class="token punctuation">(</span>alphabet<span class="token punctuation">)</span>
transformer <span class="token operator">=</span> mydataset<span class="token punctuation">.</span>resizeNormalize<span class="token punctuation">(</span><span class="token punctuation">(</span>imgW<span class="token punctuation">,</span> imgH<span class="token punctuation">)</span><span class="token punctuation">,</span>is_test<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token triple-quoted-string string">'''
cv2.cvtColor()是OpenCV中的一个函数，它可以将一幅图像从一种颜色空间转换为另一种颜色空间。该函数的第一个参数是要转换的图像，
第二个参数是当前图像的颜色空间，第三个参数是目标颜色空间。例如，可以使用cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)将一幅BGR图像转换为灰度图像。
'''</span>
<span class="token keyword">def</span> <span class="token function">recognize_downline</span><span class="token punctuation">(</span>img<span class="token punctuation">,</span>crnn_model<span class="token operator">=</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>cvtColor<span class="token punctuation">(</span> img<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>COLOR_BGR2RGB <span class="token punctuation">)</span>
    image <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">(</span>img<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'L'</span><span class="token punctuation">)</span>
    image <span class="token operator">=</span> transformer<span class="token punctuation">(</span> image <span class="token punctuation">)</span>
    <span class="token keyword">if</span> gpu<span class="token punctuation">:</span>
        image <span class="token operator">=</span> image<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#检查 gpu 的值是否为真，如果为真则将 image 移动到 GPU 上</span>
    image <span class="token operator">=</span> image<span class="token punctuation">.</span>view<span class="token punctuation">(</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">*</span>image<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">)</span><span class="token comment">#使用 image = image.view( 1, *image.size() ) 将图像的大小调整为适合模型的大小</span>
    image <span class="token operator">=</span> Variable<span class="token punctuation">(</span> image <span class="token punctuation">)</span><span class="token comment">#使用 image = Variable( image ) 将图像转换为 PyTorch 变量</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#使用 model.eval() 将模型设置为评估模式</span>
    preds <span class="token operator">=</span> model<span class="token punctuation">(</span> image <span class="token punctuation">)</span>

    preds <span class="token operator">=</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>preds<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
    conf<span class="token punctuation">,</span> preds <span class="token operator">=</span> preds<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span> <span class="token number">2</span> <span class="token punctuation">)</span>
    preds <span class="token operator">=</span> preds<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span> <span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span> <span class="token operator">-</span><span class="token number">1</span> <span class="token punctuation">)</span>

    preds_size <span class="token operator">=</span> Variable<span class="token punctuation">(</span> torch<span class="token punctuation">.</span>IntTensor<span class="token punctuation">(</span> <span class="token punctuation">[</span>preds<span class="token punctuation">.</span>size<span class="token punctuation">(</span> <span class="token number">0</span> <span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token punctuation">)</span> <span class="token punctuation">)</span>
    raw_pred <span class="token operator">=</span> converter<span class="token punctuation">.</span>decode<span class="token punctuation">(</span> preds<span class="token punctuation">.</span>data<span class="token punctuation">,</span> preds_size<span class="token punctuation">.</span>data<span class="token punctuation">,</span> raw<span class="token operator">=</span><span class="token boolean">True</span> <span class="token punctuation">)</span>
    sim_pred <span class="token operator">=</span> converter<span class="token punctuation">.</span>decode<span class="token punctuation">(</span> preds<span class="token punctuation">.</span>data<span class="token punctuation">,</span> preds_size<span class="token punctuation">.</span>data<span class="token punctuation">,</span> raw<span class="token operator">=</span><span class="token boolean">False</span> <span class="token punctuation">)</span>
    <span class="token keyword">return</span> sim_pred<span class="token punctuation">.</span>upper<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token triple-quoted-string string">'''
#首先使用 img = cv2.cvtColor( img, cv2.COLOR_BGR2RGB ) 将图像的颜色空间从 BGR 转换为 RGB

torch.autograd.Variable(data, requires_grad=True, grad_fn=None)
其中，data表示要封装的张量， requires_grad表示是否需要求梯度， grad_fn表示是由哪个函数生成的。

使用Variable类型的对象时，我们可以将其当做普通张量一样进行操作，如加减乘除、矩阵乘法等。对其进行运算时PyTorch会自动构建计算图，并在反向传播时计算梯度。

例如，在上面的代码中，这一句 image = Variable( image ) 会将 image 转换成一个 Variable 类型的对象，表示这个张量需要进行求导。然后就可以使用这个Variable类型的对象进行后续的计算。

总的来说，Variable是Pytorch中用来表示张量的类，它封装了一个张量并且为其提供自动求导功能，在使用PyTorch进行深度学习时，经常会用到Variable来封装数据。

image = Image.fromarray(np.uint8(img)).convert('L') 这句代码使用了 PIL (Python Imaging Library) 库中的 Image.fromarray 函数将 numpy 数组转换为 PIL 图像，并使用 .convert('L') 将其转换为灰度图。

np.uint8(img) 这句话是将numpy数组转化为8位无符号整型，因为PIL库中Image.fromarray()函数只接受uint8类型数组作为参数。

转换为灰度图的原因是灰度图只有一个通道，处理起来更简单，并且对于文本识别来说，灰度图也足够用了。
'''</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    <span class="token keyword">import</span> shutil
    saved_path <span class="token operator">=</span> <span class="token string">'test_imgs/'</span>
    wrong_results <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data_set/infofile_test.txt'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span><span class="token comment">#使用 f.readlines() 读取文件中所有行，并将结果赋值给变量 content</span>
        content <span class="token operator">=</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#</span>
        num_all <span class="token operator">=</span> <span class="token number">0</span>
        num_correct <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token keyword">for</span> line <span class="token keyword">in</span> content<span class="token punctuation">:</span><span class="token comment">#使用 for line in content 循环遍历每一行，对每一行进行处理。</span>
            fname<span class="token punctuation">,</span> label <span class="token operator">=</span> line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'g:'</span><span class="token punctuation">)</span><span class="token comment">#使用 line.split('g:') 将每一行按照字符 'g:' 分割成两部分，分别赋值给变量 fname 和 label。</span>
            fname <span class="token operator">+=</span> <span class="token string">'g'</span>
            label <span class="token operator">=</span> label<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\r'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span><span class="token comment">#使用 label.replace('\r', '').replace('\n', '') 将 label 中的字符 '\r' 和 '\n' 替换为空字符</span>
            img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>fname<span class="token punctuation">)</span>
            res <span class="token operator">=</span> recognize_downline<span class="token punctuation">(</span>img<span class="token punctuation">)</span>
            <span class="token keyword">if</span> res<span class="token operator">==</span>label<span class="token punctuation">:</span>
                num_correct<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token comment"># new_name = saved_path + fname.split('/')[-1]</span>
                <span class="token comment"># shutil.copyfile(fname, new_name)</span>
                wrong_results<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">'res:{} / label:{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>res<span class="token punctuation">,</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span>
            num_all<span class="token operator">+=</span><span class="token number">1</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>fname<span class="token punctuation">,</span>res<span class="token operator">==</span>label<span class="token punctuation">,</span>res<span class="token punctuation">,</span>label<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span>num_correct<span class="token operator">/</span>num_all<span class="token punctuation">)</span>
        <span class="token comment"># print(wrong_results)</span>


<span class="token triple-quoted-string string">'''
.append('res:{} / label:{}'.format(res,label)) 表示将字符串 'res:{} / label:{}' 格式化，并将其添加到 wrong_results 数组中。

其中 'res:{} / label:{}' 中的 {} 是占位符，它会被 format() 函数中传入的参数替换。

即将识别结果（res）和真实标签（label）的值插入到字符串 'res:{} / label:{}'中，并添加到 wrong_results 数组中，方便后续处理。

例如: 假设 res 的值为 "apple"，label 的值为 "banana"，那么这句话将会把 'res:apple / label:banana' 添加到 wrong_results 数组中。

这样就可以方便的查看哪些结果是错误的。
'''</span>



</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c1ef6bffbd090d92d8445537472b6792/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">机器学习中关于随机森林和XGBoost算法的特征选择 （一）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/07822f4d83323065b611852b37e3edbe/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">web安全-SQL注入-认识安全狗-WAF绕过常用方法以及示例</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>