<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【cs224n学习作业】Assignment 1 - Exploring Word Vectors - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【cs224n学习作业】Assignment 1 - Exploring Word Vectors" />
<meta property="og:description" content="参考【cs224n学习作业】Assignment 1 CS224N课程的第一个大作业， 主要是对词向量做了一个探索， 并直观的感受了一下词嵌入或者词向量的效果。这里简单的记录一下我探索的一个过程。分为两部分， 第一部分是基于计数的单词词向量， 而第二部分，是基于词向量的预测， 是利用了已经训练好的一个词向量矩阵去介绍一下怎么进行预测， 比如可视化这些词向量啊， 找同义词或者反义词，实现单词的类比关系等。
准备工作
导入要用的包
import sys assert sys.version_info[0]==3 assert sys.version_info[1] &gt;= 5 from gensim.models import KeyedVectors # KeyedVectors:实现实体（单词、文档、图片都可以）和向量之间的映射。每个实体由其字符串id标识。 from gensim.test.utils import datapath import pprint # 输出的更加规范易读 import matplotlib.pyplot as plt plt.rcParams[&#39;figure.figsize&#39;] = [10, 5] # plt.rcParams主要作用是设置画的图的分辨率，大小等信息 import nltk nltk.download(&#39;reuters&#39;) # 这个可以从GitHub下载， 网址：https://github.com/nltk/nltk_data/tree/gh-pages/packages/corpora from nltk.corpus import reuters import numpy as np import random import scipy as sp from sklearn.decomposition import TruncatedSVD from sklearn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b18638702d60f0617b282515753771f8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-07-06T22:58:27+08:00" />
<meta property="article:modified_time" content="2020-07-06T22:58:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【cs224n学习作业】Assignment 1 - Exploring Word Vectors</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>参考<a href="https://blog.csdn.net/weixin_45684408/article/details/107167284?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522159404257319724835850016%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=159404257319724835850016&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_v1~rank_blog_v1-2-107167284.pc_v1_rank_blog_v1&amp;utm_term=NLP">【cs224n学习作业】Assignment 1 </a><br> CS224N课程的第一个大作业， 主要是对词向量做了一个探索， 并直观的感受了一下词嵌入或者词向量的效果。这里简单的记录一下我探索的一个过程。分为两部分， 第一部分是基于计数的单词词向量， 而第二部分，是基于词向量的预测， 是利用了已经训练好的一个词向量矩阵去介绍一下怎么进行预测， 比如可视化这些词向量啊， 找同义词或者反义词，实现单词的类比关系等。</p> 
<p>准备工作</p> 
<p>导入要用的包</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> sys
<span class="token keyword">assert</span> sys<span class="token punctuation">.</span>version_info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">3</span>
<span class="token keyword">assert</span> sys<span class="token punctuation">.</span>version_info<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&gt;=</span> <span class="token number">5</span>

<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> KeyedVectors 
<span class="token comment"># KeyedVectors:实现实体（单词、文档、图片都可以）和向量之间的映射。每个实体由其字符串id标识。</span>
<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>test<span class="token punctuation">.</span>utils <span class="token keyword">import</span> datapath
<span class="token keyword">import</span> pprint     <span class="token comment">#  输出的更加规范易读</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt  

plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span> 
<span class="token comment">#  plt.rcParams主要作用是设置画的图的分辨率，大小等信息</span>

<span class="token keyword">import</span> nltk

nltk<span class="token punctuation">.</span>download<span class="token punctuation">(</span><span class="token string">'reuters'</span><span class="token punctuation">)</span>    <span class="token comment"># 这个可以从GitHub下载， 网址：https://github.com/nltk/nltk_data/tree/gh-pages/packages/corpora</span>

<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> reuters
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> random
<span class="token keyword">import</span> scipy <span class="token keyword">as</span> sp
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> TruncatedSVD
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

START_TOKEN <span class="token operator">=</span> <span class="token string">'&lt;START&gt;'</span>
END_TOKEN <span class="token operator">=</span> <span class="token string">'&lt;END&gt;'</span>

np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></code></pre> 
<p>这里面的Reuters是路透社(商业和金融新闻)语料库， 是一个词库， 语料库包含10788个新闻文档，共计130万词。这些文档跨越90个类别，分为train和test，我们这次需要用其中的一个类别(crude)里面的句子。<br> 对于这个数据集以及后面要用到的数据我们直接下下不来，所以这里提供另外一个方法就是自己可以百度手动下载数据集。这些数据网上都有都是可以自行下载过来的。然后就是采用下面的函数，导入这个语料库：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">read_corpus</span><span class="token punctuation">(</span>category<span class="token operator">=</span><span class="token string">"crude"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" Read files
from the specified Reuter's category.
        Params:
            category (string):
category name
        Return:
            list of lists, with
words from each of the processed files
    """</span>
    files <span class="token operator">=</span>reuters<span class="token punctuation">.</span>fileids<span class="token punctuation">(</span>category<span class="token punctuation">)</span>    <span class="token comment"># 类别为crude文档</span>
    <span class="token comment"># 每个文档都转化为小写， 并在开头结尾加标识符</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>START_TOKEN<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>w<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">for</span> w <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>reuters<span class="token punctuation">.</span>words<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>END_TOKEN<span class="token punctuation">]</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> files<span class="token punctuation">]</span></code></pre> 
<p>这个是导入语料库的函数， 简单的进行了一下预处理， 就是在每句话的前面和后面各加了一个标识符，表示句子的开始和结束，然后把每个单词分开。 下面导入并看一下效果：</p> 
<pre><code class="prism language-python"><span class="token comment"># pprint模块格式化打印</span>
<span class="token comment"># pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *,</span>
compact<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment"># width：控制打印显示的宽度。默认为80个字符。注意：当单个对象的长度超过width时，并不会分多行显示，而是会突破规定的宽度。</span>
<span class="token comment"># compact：默认为False。如果值为False，超过width规定长度的序列会被分散打印到多行。如果为True，会尽量使序列填满width规定的宽度。</span>

reuters_corpus <span class="token operator">=</span> read_corpus<span class="token punctuation">(</span><span class="token punctuation">)</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>reuters_corpus<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> compact<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># compact 设置为False是一行一个单词</span>
</code></pre> 
<p>每个句子处理后长这样：</p> 
<p>准备工作完成，接下来就是实验的主要两部分了。</p> 
<p><strong>1:Count-Based Word Vectors</strong></p> 
<p>共现矩阵是实现这种词向量的一种方式， 我们看看共现矩阵是什么意思？ 共现矩阵计算的是单词在某些环境下一块出现的频率， 对于共现矩阵， 原文描述是这样的：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/9a/8d/N0rcwAoU_o.png"><br> 上面的话其实就是这样的一个意思， 要想建立共现矩阵，我们需要先为单词构建一个词典， 然后共现矩阵的行列都是这个词典里的单词， 看下面这个例子：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/b9/7a/Icr4ymXx_o.png"><br> 上面基于这两段文档构建出的共现矩阵长这样， 这个是怎么构建的？ 首先就是根据两个文档的单词构建一个词典， 这里面的数就是两两单词在上下文中共现的频率， 比如第一行， START和all一起出现了两次， 这就是因为两个文档里面START的窗口中都有all。 同理第二行all的那个， 我们也固定一个窗口， 发现第一个文档里面all左边是START， 右边是that， 第二个文档all左边是START， 右边是is, 那么&lt;all, START&gt;=2, &lt;all, that&gt;=1, &lt;all,<br> is&gt;=1。 下面的都是同理了。</p> 
<p>我们就是要构建这样的一个矩阵来作为每个单词的词向量， 当然这个还不是最终形式， 因为可能词典很大的话维度会特别高， 所以就相当了降维技术， 降维之后的结果就是每个单词的词向量。 这个里面使用的降维是SVD, 原理这里不说， 这里使用了Truncated SVD， 具体的实现是调用了sklearn中的包。</p> 
<p>所以我们就有了下面的这样一个思路框架：</p> 
<ol><li>对于语录料库中的文档单词， 得先构建一个词典（唯一单词且排好序）</li><li>然后我们就是基于词典和语料库，为每个单词构建词向量， 也就是共现矩阵</li><li>对共现矩阵降维，就得到了最终的词向量</li><li>可视化</li></ol> 
<p><strong>1.1为语料库中的单词构建词典</strong></p> 
<p>词典就是记录所有的单词， 但是单词唯一且有序。 那么实现这个词典的思路就是我遍历每一篇文档，先获得所有的单词， 然后去掉重复的， 然后再排序就搞定， 当然还得记录字典里的单词总数。</p> 
<pre><code class="prism language-python"><span class="token comment"># 计算出语料库中出现的不同单词，并排序。</span>
<span class="token keyword">def</span> <span class="token function">distinct_words</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" Determine a
list of distinct words for the corpus.
        Params:
            corpus (list of list of strings):
            	corpus of documents
        Return:
            corpus_words (list of strings): list of distinct words across the corpus, sorted (using python 'sorted' function)
            num_corpus_words(integer): number of distinct words across the corpus
   
"""</span>

    corpus_words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    num_corpus_words <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>
    <span class="token comment"># ------------------</span>
    <span class="token comment"># Write your implementation here.</span>
    <span class="token comment"># 首先得把所有单词放到一个列表里面, 然后用set去重， 然后排序</span>
    <span class="token keyword">for</span> everylist <span class="token keyword">in</span> corpus<span class="token punctuation">:</span>       
	corpus_words<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>everylist<span class="token punctuation">)</span>
    corpus_words <span class="token operator">=</span><span class="token builtin">sorted</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>corpus_words<span class="token punctuation">)</span><span class="token punctuation">)</span>
    num_corpus_words <span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">(</span>corpus_words<span class="token punctuation">)</span>

    <span class="token comment"># ------------------</span>
    <span class="token keyword">return</span> corpus_words<span class="token punctuation">,</span>
num_corpus_words</code></pre> 
<p><strong>1.2 构建共现矩阵</strong><br> 首先我们得定义一个M矩阵， 也就是共现矩阵， 大小就是行列都是词典的单词个数（上面图片一目了然）， 然后还得定义一个字典单词到索引的映射， 因为我们统计的时候是遍历真实文档， 而填矩阵的时候是基于字典，这两个是基于同一个单词进行联系起来的， 所以我们需要获得真实文档中单词在字典里面的索引才能去填矩阵。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">compute_co_occurrence_matrix</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> window_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Compute co-occurrence matrix for the given corpus and window_size (default of 4).

        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller number of co-occurringwords.
              For example, if we take the document "START All that glitters is not gold END" with
window size of 4,
              "All" will co-occur with "START", "that", "glitters", "is", and "not".

        Params:
            corpus (list of list of strings): corpus of documents
            window_size (int): size of context window
        Return:
            M (numpy matrix of shape (number of corpus words, number of corpus words)): 
                Co-occurence matrix of word counts. 
                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.
            word2Ind (dict):
dictionary that maps word to index (i.e. row/column number) for matrix M.

    """</span>
    words<span class="token punctuation">,</span> num_words <span class="token operator">=</span> distinct_words<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>   <span class="token comment"># 单词已经去重或者排好序  </span>
    M <span class="token operator">=</span> <span class="token boolean">None</span>
    word2Ind <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>

    <span class="token comment"># ------------------</span>
    <span class="token comment"># Write your implementation here.</span>

    word2Ind <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k<span class="token punctuation">:</span> v <span class="token keyword">for</span> <span class="token punctuation">(</span>k<span class="token punctuation">,</span> v<span class="token punctuation">)</span> inzip<span class="token punctuation">(</span>words<span class="token punctuation">,</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_words<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>num_words<span class="token punctuation">,</span>num_words<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#接下来是遍历语料库 对于每一篇文档， 我们得遍历每个单词</span>
    <span class="token comment"># 对于每个单词， 我们得找到窗口的范围， 然后再去遍历它窗口内的每个单词</span>
    <span class="token comment"># 对于这每个单词， 我们就可以在我们的M词典中进行计数， 但是要注意每个单词其实有两个索引</span>
    <span class="token comment"># 一个是词典里面的索引， 一个是文档中的索引， 我们统计的共现频率是基于字典里面的索引， </span>
    <span class="token comment"># 所以这里涉及到一个索引的转换</span>
    <span class="token comment"># 首先遍历语料库</span>
    <span class="token keyword">for</span> every_doc <span class="token keyword">in</span> corpus<span class="token punctuation">:</span>
        <span class="token keyword">for</span> cword_doc_ind<span class="token punctuation">,</span> cword inenumerate<span class="token punctuation">(</span>every_doc<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 遍历当前文档的每个单词和在文档中的索引</span>
            <span class="token comment"># 对于当前的单词， 我们先找到它在词典中的位置</span>
            cword_dic_ind <span class="token operator">=</span>word2Ind<span class="token punctuation">[</span>cword<span class="token punctuation">]</span>
          
            <span class="token comment"># 找窗口的起始和终止位置  开始位置就是当前单词的索引减去window_size, 终止位置</span>
            <span class="token comment"># 是当前索引加上windo_size+1， </span>
            window_start <span class="token operator">=</span> cword_doc_ind <span class="token operator">-</span> window_size
            window_end <span class="token operator">=</span>cword_doc_ind <span class="token operator">+</span> window_size <span class="token operator">+</span> <span class="token number">1</span>            
            <span class="token comment"># 有了窗口， 我们就要遍历窗口里面的每个单词， 然后往M里面记录就行了</span>
            <span class="token comment"># 但是还要注意一点， 就是边界问题， 因为开始单词左边肯定不够窗口大小， 结束单词</span>
            <span class="token comment"># 右边肯定不够窗口大小， 所以遍历之后得判断一下是不是左边后者右边有单词</span>
            <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>window_start<span class="token punctuation">,</span> window_end<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token comment"># 前面两个条件控制不越界， 最后一个条件控制不是它本身</span>
                <span class="token keyword">if</span> j <span class="token operator">&gt;=</span><span class="token number">0</span> <span class="token operator">and</span> j<span class="token operator">&lt;</span> <span class="token builtin">len</span><span class="token punctuation">(</span>every_doc<span class="token punctuation">)</span> <span class="token operator">and</span> j <span class="token operator">!=</span> cword_doc_ind<span class="token punctuation">:</span>
                    <span class="token comment"># 想办法加入到M， 那么得获取这个单词在词典中的位置</span>
                    oword <span class="token operator">=</span>every_doc<span class="token punctuation">[</span>j<span class="token punctuation">]</span>   <span class="token comment"># 获取到上下文单词</span>
                    oword_dic_ind <span class="token operator">=</span>word2Ind<span class="token punctuation">[</span>oword<span class="token punctuation">]</span>
                    <span class="token comment"># 加入M</span>
                    M<span class="token punctuation">[</span>cword_dic_ind<span class="token punctuation">,</span>oword_dic_ind<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

    <span class="token comment"># ------------------</span>
    <span class="token keyword">return</span> M<span class="token punctuation">,</span> word2Ind</code></pre> 
<p><strong>3.3 降维到K维</strong></p> 
<p>降维直接调用包SVD.</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">reduce_to_k_dim</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_wor
 to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from
Scikit-Learn:            -
http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html

        Params:
            M (numpy matrix of shape(number of corpus words, number of corpus words)): co-occurence matrix of word counts
            k (int): embedding size of each word after dimension reduction
        Return:
            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.
             In terms of the SVD from math class, this actually returns U * S
    """</span>    
    n_iters <span class="token operator">=</span> <span class="token number">10</span>     <span class="token comment"># Use this parameter in your call to `TruncatedSVD`</span>
    M_reduced <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Running Truncated SVD over %i words..."</span> <span class="token operator">%</span> <span class="token punctuation">(</span>M<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># ------------------</span>
        <span class="token comment"># Write your implementation here.</span>
    svd <span class="token operator">=</span>TruncatedSVD<span class="token punctuation">(</span>n_components<span class="token operator">=</span>k<span class="token punctuation">,</span> n_iter<span class="token operator">=</span>n_iters<span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">2020</span><span class="token punctuation">)</span>
    M_reduced <span class="token operator">=</span> svd<span class="token punctuation">.</span>fit_transform<span class="token punctuation">(</span>M<span class="token punctuation">)</span>
        <span class="token comment"># ------------------</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done."</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> M_reduced</code></pre> 
<p>最后可视化结果</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">plot_embeddings</span><span class="token punctuation">(</span>M_reduced<span class="token punctuation">,</span> word2Ind<span class="token punctuation">,</span> words<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Plot in a scatterplot the embeddings of the words specified in the list "words".

        NOTE: do not plot all the words listed in M_reduced / word2Ind.
        Include a label next to each point.
        Params:

            M_reduced (numpy matrix of shape (number of unique words in the corpus , k)): matrix of k-dimensioal word embeddings
            word2Ind (dict): dictionary that maps word to indices for matrix M
            words (list of strings): words whose embeddings we want to visualize

    """</span>
 
    <span class="token comment"># ------------------</span>
    <span class="token comment"># Write your implementation here.</span>
    <span class="token comment"># 遍历句子， 获得每个单词的x，y坐标</span>
    <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>
        word_dic_index <span class="token operator">=</span> word2Ind<span class="token punctuation">[</span>word<span class="token punctuation">]</span>
        x <span class="token operator">=</span>M_reduced<span class="token punctuation">[</span>word_dic_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        y <span class="token operator">=</span> M_reduced<span class="token punctuation">[</span>word_dic_index<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span>marker<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">)</span>
        <span class="token comment"># plt.text()给图形添加文本注释</span>
        plt<span class="token punctuation">.</span>text<span class="token punctuation">(</span>x<span class="token operator">+</span><span class="token number">0.0002</span><span class="token punctuation">,</span> y<span class="token operator">+</span><span class="token number">0.0002</span><span class="token punctuation">,</span> word<span class="token punctuation">,</span>fontsize<span class="token operator">=</span><span class="token number">9</span><span class="token punctuation">)</span>  <span class="token comment"># # x、y上方0.002处标注文字说明，word标注的文字，fontsize：文字大小</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># ------------------</span></code></pre> 
<p>综合以上的步骤：首先是读入数据， 然后计算共现矩阵， 然后是降维， 最后是可视化：</p> 
<pre><code class="prism language-python">reuters_corpus <span class="token operator">=</span> read_corpus<span class="token punctuation">(</span><span class="token punctuation">)</span>
M_co_occurrence<span class="token punctuation">,</span> word2Ind_co_occurrence <span class="token operator">=</span> compute_co_occurrence_matrix<span class="token punctuation">(</span>reuters_corpus<span class="token punctuation">)</span>
M_reduced_co_occurrence <span class="token operator">=</span> reduce_to_k_dim<span class="token punctuation">(</span>M_co_occurrence<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token comment"># Rescale (normalize) the rows to make them each of unit-length</span>
M_lengths <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>M_reduced_co_occurrence<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
M_normalized <span class="token operator">=</span> M_reduced_co_occurrence <span class="token operator">/</span> M_lengths<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span> <span class="token comment">#</span>
broadcasting
words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'barrels'</span><span class="token punctuation">,</span> <span class="token string">'bpd'</span><span class="token punctuation">,</span> <span class="token string">'ecuador'</span><span class="token punctuation">,</span> <span class="token string">'energy'</span><span class="token punctuation">,</span> <span class="token string">'industry'</span><span class="token punctuation">,</span> <span class="token string">'kuwait'</span><span class="token punctuation">,</span><span class="token string">'oil'</span><span class="token punctuation">,</span> <span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'petroleum'</span><span class="token punctuation">,</span> <span class="token string">'venezuela'</span><span class="token punctuation">]</span>
plot_embeddings<span class="token punctuation">(</span>M_normalized<span class="token punctuation">,</span> word2Ind_co_occurrence<span class="token punctuation">,</span> words<span class="token punctuation">)</span></code></pre> 
<p>得到结果如下：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/07/dc/m04r2Y6X_o.png"></p> 
<p><strong>2:Prediction-Based Word Vectors</strong></p> 
<p>2.1 可视化Word2Vec训练的词嵌入<br> 这一部分其实是利用了一个用Word2Vec技术训练好的词向量矩阵去测试一些有趣的效果， 看看词向量到底是干啥用的。 所以用gensim包下载了一个词向量矩阵：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">load_word2vec</span><span class="token punctuation">(</span>embeddings_fp<span class="token operator">=</span><span class="token string">"GoogleNews-vectors-negative300.bin"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Load Word2Vec Vectors
        Param:
            embeddings_fp (string) - path to .bin file of pretrained word vectors
        Return:
            wv_from_bin: All 3 million embeddings, each lengh 300
                This is the KeyedVectors format:
https://radimrehurek.com/gensim/models/deprecated/keyedvectors.html
    """</span>
    embed_size <span class="token operator">=</span> <span class="token number">300</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loading 3 million word vectors from file..."</span><span class="token punctuation">)</span>
    <span class="token comment">## 自己下载的文件</span>
    wv_from_bin <span class="token operator">=</span>KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span>embeddings_fp<span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    vocab <span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Loaded vocab size%i"</span> <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> wv_from_bin
 wv_from_bin <span class="token operator">=</span> load_word2vec<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre> 
<p>路径换成自己的数据保存路径就行<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/16/03/GXooysfp_o.png"><br> 有了这个代码，我们就能得到一个基于Word2Vec训练好的词向量矩阵（和上面我们的M矩阵是类似的，只不过得到的方式不同）， 接下来就是进行降维并可视化词嵌入：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_matrix_of_vectors</span><span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">,</span> required_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'barrels'</span><span class="token punctuation">,</span> <span class="token string">'bpd'</span><span class="token punctuation">,</span>
<span class="token string">'ecuador'</span><span class="token punctuation">,</span> <span class="token string">'energy'</span><span class="token punctuation">,</span> <span class="token string">'industry'</span><span class="token punctuation">,</span> <span class="token string">'kuwait'</span><span class="token punctuation">,</span> <span class="token string">'oil'</span><span class="token punctuation">,</span> <span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'petroleum'</span><span class="token punctuation">,</span>
<span class="token string">'venezuela'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Put the word2vec vectors into a matrix M
        Param:
            wv_from_bin: KeyedVectors object; the 3 million word2vec vectors loaded from file
        Return:
            M: numpy matrix shape (num words, 300) containing the vectors
            word2Ind: dictionary mapping each word to its row number in M
    """</span>
    <span class="token keyword">import</span> random
    words <span class="token operator">=</span><span class="token builtin">list</span><span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Shuffling words ..."</span><span class="token punctuation">)</span>
    random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>words<span class="token punctuation">)</span>
    words <span class="token operator">=</span> words<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span>       <span class="token comment"># 选10000个加入</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Putting %i words into word2Ind and matrix M..."</span> <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>
    word2Ind <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    M <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    curInd <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>           
		M<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>word_vec<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>
       	        word2Ind<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> curInd
                curInd <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
    <span class="token keyword">for</span> w <span class="token keyword">in</span> required_words<span class="token punctuation">:</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            M<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>word_vec<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>
            word2Ind<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> curInd
            curInd <span class="token operator">+=</span> <span class="token number">1</span>
        <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>
            <span class="token keyword">continue</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>M<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done."</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> M<span class="token punctuation">,</span> word2Ind

<span class="token comment"># -----------------------------------------------------------------</span>
<span class="token comment"># Run Cell to Reduce 300-Dimensinal Word Embeddings to k Dimensions</span>
<span class="token comment"># Note: This may take several minutes</span>
<span class="token comment"># -----------------------------------------------------------------</span>
M<span class="token punctuation">,</span> word2Ind <span class="token operator">=</span> get_matrix_of_vectors<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">)</span>
M_reduced <span class="token operator">=</span> reduce_to_k_dim<span class="token punctuation">(</span>M<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        
<span class="token comment"># 减到了2维</span>
words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'barrels'</span><span class="token punctuation">,</span> <span class="token string">'bpd'</span><span class="token punctuation">,</span> <span class="token string">'ecuador'</span><span class="token punctuation">,</span> <span class="token string">'energy'</span><span class="token punctuation">,</span> <span class="token string">'industry'</span><span class="token punctuation">,</span> <span class="token string">'kuwait'</span><span class="token punctuation">,</span><span class="token string">'oil'</span><span class="token punctuation">,</span> <span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'petroleum'</span><span class="token punctuation">,</span> <span class="token string">'venezuela'</span><span class="token punctuation">]</span>
plot_embeddings<span class="token punctuation">(</span>M_reduced<span class="token punctuation">,</span> word2Ind<span class="token punctuation">,</span> words<span class="token punctuation">)</span></code></pre> 
<p>结果如下：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/d7/0b/pDHMDt1s_o.png"><br> <strong>2.2 余弦相似度</strong></p> 
<p>我们已经得到了每个单词的词向量表示， 那么怎么看两个单词的相似性程度呢？ 余弦相似性是一种方式， 公式如下：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/ac/ff/J6EQFUPg_o.png"></p> 
<p>基于这个方式，我们就可以找到单词的多义词， 同义词，反义词还能实现单词的类比推理等。所以是直接调用的gensim的函数就行。</p> 
<pre><code class="prism language-python"><span class="token comment"># 找和energy最相近的10个单词</span>
wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span><span class="token string">"energy"</span><span class="token punctuation">)</span>
<span class="token comment">##结果</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'renewable_energy'</span><span class="token punctuation">,</span> <span class="token number">0.6721636056900024</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'enery'</span><span class="token punctuation">,</span> <span class="token number">0.6289607286453247</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token string">'electricity'</span><span class="token punctuation">,</span><span class="token number">0.6030439138412476</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'enegy'</span><span class="token punctuation">,</span> <span class="token number">0.6001754403114319</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'Energy'</span><span class="token punctuation">,</span> <span class="token number">0.595537006855011</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'fossil_fuel'</span><span class="token punctuation">,</span><span class="token number">0.5802257061004639</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'natural_gas'</span><span class="token punctuation">,</span> <span class="token number">0.5767925381660461</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'renewables'</span><span class="token punctuation">,</span> <span class="token number">0.5708995461463928</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">(</span><span class="token string">'fossil_fuels'</span><span class="token punctuation">,</span><span class="token number">0.5689164996147156</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token string">'renewable'</span><span class="token punctuation">,</span> <span class="token number">0.5663810968399048</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre> 
<p>再比如， 为我们可以找同义词和反义词：</p> 
<pre><code class="prism language-python">w1 <span class="token operator">=</span> <span class="token string">"man"</span>
w2 <span class="token operator">=</span> <span class="token string">"king"</span>
w3 <span class="token operator">=</span> <span class="token string">"woman"</span>
w1_w2_dist <span class="token operator">=</span> wv_from_bin<span class="token punctuation">.</span>distance<span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">)</span>
w1_w3_dist <span class="token operator">=</span> wv_from_bin<span class="token punctuation">.</span>distance<span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w3<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Synonyms {}, {} have cosine distance: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span>w1_w2_dist<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Antonyms {}, {} have cosine distance: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w3<span class="token punctuation">,</span>w1_w3_dist<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">## 结果：</span>
Synonyms man<span class="token punctuation">,</span> king have cosine distance<span class="token punctuation">:</span> <span class="token number">0.7705732733011246</span>
Antonyms man<span class="token punctuation">,</span> woman have cosine distance<span class="token punctuation">:</span> <span class="token number">0.2335987687110901</span></code></pre> 
<p>还可以实现类比关系：比如： China :Beijing = Japan : ?， 那么我们可以用下面的代码求这样的类别关系， 注意下面的positive和negative里面的单词顺序， 我们求得？其实和Japan和Beijing相似， 和China远。</p> 
<pre><code class="prism language-python"><span class="token comment"># Run this cell to answer the analogy -- man : king :: woman : x</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Bejing'</span><span class="token punctuation">,</span> <span class="token string">'Japan'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'China'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">## 结果：</span>
<span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">'Tokyo'</span><span class="token punctuation">,</span> <span class="token number">0.6124968528747559</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Osaka'</span><span class="token punctuation">,</span> <span class="token number">0.5791803598403931</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Maebashi'</span><span class="token punctuation">,</span> <span class="token number">0.5635818243026733</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Fukuoka_Japan'</span><span class="token punctuation">,</span><span class="token number">0.5362966060638428</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Nagoya'</span><span class="token punctuation">,</span> <span class="token number">0.5359445214271545</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Fukuoka'</span><span class="token punctuation">,</span> <span class="token number">0.5319067239761353</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Osaka_Japan'</span><span class="token punctuation">,</span><span class="token number">0.5298740267753601</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Nagano'</span><span class="token punctuation">,</span> <span class="token number">0.5293833017349243</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Taisuke'</span><span class="token punctuation">,</span> <span class="token number">0.5258569717407227</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 <span class="token punctuation">(</span><span class="token string">'Chukyo'</span><span class="token punctuation">,</span> <span class="token number">0.5195443034172058</span><span class="token punctuation">)</span><span class="token punctuation">]</span></code></pre> 
<p><strong>2.3 引导词向量偏差分析</strong><br> 识别单词嵌入隐含的偏见(性别、种族、性取向等)。<br> 运行下面的单元格，检查<br> (a)哪些词与“woman”和“boss”最相似，而与“man”最不相似;<br> (b)哪些词与“man”和“boss”最相似，而与“woman”最不相似。</p> 
<pre><code class="prism language-python"><span class="token comment"># Run this cell</span>
<span class="token comment"># Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be</span>
<span class="token comment"># most dissimilar from.</span>
<span class="token comment">#这里“positive”表示类似的单词列表，而“negative”表示是最不相似于。</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'boss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">,</span> <span class="token string">'boss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre> 
<p>得到结果如下：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/d4/29/u8pluF1T_o.png"><br> 2.4 独立的单词向量偏差分析</p> 
<pre><code class="prism language-python"><span class="token comment"># ------------------</span>
<span class="token comment"># Write your bias exploration code here.</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'doctor'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'nurse'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># ------------------</span></code></pre> 
<p>结果如下：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/e3/52/kpj5GoN9_o.png"><br> 【附完整代码】</p> 
<pre><code class="prism language-python"><span class="token comment"># 导入包</span>

<span class="token keyword">import</span> sys

<span class="token keyword">assert</span> sys<span class="token punctuation">.</span>version_info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">==</span><span class="token number">3</span>

<span class="token keyword">assert</span> sys<span class="token punctuation">.</span>version_info<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">&gt;=</span> <span class="token number">5</span>

 

<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>models <span class="token keyword">import</span> KeyedVectors 
<span class="token comment"># KeyedVectors:实现实体（单词、文档、图片都可以）和向量之间的映射。每个实体由其字符串id标识。</span>

<span class="token keyword">from</span> gensim<span class="token punctuation">.</span>test<span class="token punctuation">.</span>utils <span class="token keyword">import</span> datapath

<span class="token keyword">import</span> pprint     <span class="token comment">#  输出的更加规范易读</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">]</span> 
<span class="token comment">#  plt.rcParams主要作用是设置画的图的分辨率，大小等信息</span>

<span class="token comment"># import nltk</span>

<span class="token comment"># nltk.download('reuters')    # 这个可以从GitHub下载， 网址：https://github.com/nltk/nltk_data/tree/gh-pages/packages/corpora</span>

<span class="token keyword">from</span> nltk<span class="token punctuation">.</span>corpus <span class="token keyword">import</span> reuters

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">import</span> random

<span class="token keyword">import</span> rando

<span class="token keyword">import</span> scipy <span class="token keyword">as</span> sp

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> TruncatedSVD

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>decomposition <span class="token keyword">import</span> PCA

 

START_TOKEN <span class="token operator">=</span> <span class="token string">'&lt;START&gt;'</span>

END_TOKEN <span class="token operator">=</span> <span class="token string">'&lt;END&gt;'</span>

 

np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

random<span class="token punctuation">.</span>seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

 

<span class="token comment"># 导入</span>
<span class="token string">"reuters"</span> 语料库

<span class="token keyword">def</span> <span class="token function">read_corpus</span><span class="token punctuation">(</span>category<span class="token operator">=</span><span class="token string">"crude"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Read files from
the specified Reuter's category.

        Params:

            category (string):
category name

        Return:

            list of lists, with
words from each of the processed files

    """</span>

    files <span class="token operator">=</span>
reuters<span class="token punctuation">.</span>fileids<span class="token punctuation">(</span>category<span class="token punctuation">)</span>    <span class="token comment"># 类别为crude文档</span>

    <span class="token comment"># 每个文档都转化为小写， 并在开头结尾加标识符</span>

    <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>START_TOKEN<span class="token punctuation">]</span> <span class="token operator">+</span>
<span class="token punctuation">[</span>w<span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span>reuters<span class="token punctuation">.</span>words<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>END_TOKEN<span class="token punctuation">]</span> <span class="token keyword">for</span> f <span class="token keyword">in</span> files<span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 导入语料库的函数，简单的进行了一下预处理，</span>

<span class="token comment"># 在每句话的前面和后面各加了一个标识符，表示句子的开始和结束，然后把每个单词分开。</span>

<span class="token comment"># pprint模块格式化打印</span>

<span class="token comment"># pprint.pprint(object, stream=None, indent=1, width=80, depth=None, *,</span>
compact<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

<span class="token comment"># width：控制打印显示的宽度。默认为80个字符。注意：当单个对象的长度超过width时，并不会分多行显示，而是会突破规定的宽度。</span>

<span class="token comment"># compact：默认为False。如果值为False，超过width规定长度的序列会被分散打印到多行。如果为True，会尽量使序列填满width规定的宽度。</span>

reuters_corpus <span class="token operator">=</span> read_corpus<span class="token punctuation">(</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>reuters_corpus<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> compact<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> width<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>  <span class="token comment"># compact 设置为False是一行一个单词</span>

 

<span class="token comment"># 问题1.1：实现不同单词</span>

<span class="token comment"># 计算语料库的单词数量、单词集</span>

<span class="token keyword">def</span> <span class="token function">distinct_words</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Determine a
list of distinct words for the corpus.

        Params:

            corpus (list of list of
strings): corpus of documents

        Return:

            corpus_words (list of
strings): list of distinct words across the corpus, sorted (using python
'sorted' function)

            num_corpus_words
(integer): number of distinct words across the corpus

    """</span>

    corpus_words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    num_corpus_words <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>

 

    <span class="token comment"># Write your implementation</span>
here<span class="token punctuation">.</span>

    corpus <span class="token operator">=</span> <span class="token punctuation">[</span>w <span class="token keyword">for</span> sent <span class="token keyword">in</span> corpus
<span class="token keyword">for</span> w <span class="token keyword">in</span> sent<span class="token punctuation">]</span>

    corpus_words <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>corpus<span class="token punctuation">)</span><span class="token punctuation">)</span>

    corpus_words <span class="token operator">=</span>
<span class="token builtin">sorted</span><span class="token punctuation">(</span>corpus_words<span class="token punctuation">)</span>

    num_corpus_words <span class="token operator">=</span>
<span class="token builtin">len</span><span class="token punctuation">(</span>corpus_words<span class="token punctuation">)</span>

    <span class="token comment"># 返回的结果是语料库中的所有单词按照字母顺序排列的。</span>

    <span class="token keyword">return</span> corpus_words<span class="token punctuation">,</span>
num_corpus_words

 

<span class="token comment"># 问题1.2：实现共现矩阵</span>

<span class="token comment"># 计算给定语料库的共现矩阵。具体来说，对于每一个词 w，统计前、后方 window_size 个词的出现次数\</span>

<span class="token keyword">def</span> <span class="token function">compute_co_occurrence_matrix</span><span class="token punctuation">(</span>corpus<span class="token punctuation">,</span> window_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Compute
co-occurrence matrix for the given corpus and window_size (default of 4).

 

        Note: Each word in a
document should be at the center of a window. Words near edges will have a
smaller

              number of co-occurring
words.

 

              For example, if we
take the document "START All that glitters is not gold END" with
window size of 4,

              "All" will
co-occur with "START", "that", "glitters",
"is", and "not".

 

        Params:

            corpus (list of list of
strings): corpus of documents

            window_size (int): size
of context window

        Return:

            M (numpy matrix of shape
(number of corpus words, number of corpus words)):

                Co-occurence matrix
of word counts.

                The ordering of the
words in the rows/columns should be the same as the ordering of the words given
by the distinct_words function.

            word2Ind (dict):
dictionary that maps word to index (i.e. row/column number) for matrix M.

    """</span>

    words<span class="token punctuation">,</span> num_words <span class="token operator">=</span>
distinct_words<span class="token punctuation">(</span>corpus<span class="token punctuation">)</span>

    M <span class="token operator">=</span> <span class="token boolean">None</span>

    word2Ind <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>

 

    <span class="token comment"># Write your implementation</span>
here<span class="token punctuation">.</span>

    M <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>num_words<span class="token punctuation">,</span>
num_words<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_words<span class="token punctuation">)</span><span class="token punctuation">:</span>

        word2Ind<span class="token punctuation">[</span>words<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> i

 

    <span class="token keyword">for</span> sent <span class="token keyword">in</span> corpus<span class="token punctuation">:</span>

        <span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>sent<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

            ci <span class="token operator">=</span> word2Ind<span class="token punctuation">[</span>sent<span class="token punctuation">[</span>p<span class="token punctuation">]</span><span class="token punctuation">]</span>

 

            <span class="token comment"># preceding</span>

            <span class="token keyword">for</span> w <span class="token keyword">in</span> sent<span class="token punctuation">[</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> p <span class="token operator">-</span>
window_size<span class="token punctuation">)</span><span class="token punctuation">:</span>p<span class="token punctuation">]</span><span class="token punctuation">:</span>

                wi <span class="token operator">=</span> word2Ind<span class="token punctuation">[</span>w<span class="token punctuation">]</span>

                M<span class="token punctuation">[</span>ci<span class="token punctuation">]</span><span class="token punctuation">[</span>wi<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

 

            <span class="token comment"># subsequent</span>

            <span class="token keyword">for</span> w <span class="token keyword">in</span> sent<span class="token punctuation">[</span>p <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">:</span>p <span class="token operator">+</span>
<span class="token number">1</span> <span class="token operator">+</span> window_size<span class="token punctuation">]</span><span class="token punctuation">:</span>

                wi <span class="token operator">=</span> word2Ind<span class="token punctuation">[</span>w<span class="token punctuation">]</span>

                M<span class="token punctuation">[</span>ci<span class="token punctuation">]</span><span class="token punctuation">[</span>wi<span class="token punctuation">]</span> <span class="token operator">+=</span> <span class="token number">1</span>

 

    <span class="token keyword">return</span> M<span class="token punctuation">,</span> word2Ind

 

<span class="token comment"># 问题1.3：实现降到k维</span>

<span class="token comment"># 这一步是降维。</span>

<span class="token comment"># 在问题1.2得到的是一个N x N的矩阵（N是单词集的大小），使用scikit-learn实现的SVD（奇异值分解），从这个大矩阵里分解出一个含k个特制的N x k 小矩阵。</span>

<span class="token keyword">def</span> <span class="token function">reduce_to_k_dim</span><span class="token punctuation">(</span>M<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Reduce a
co-occurence count matrix of dimensionality (num_corpus_words,
num_corpus_words)

        to a matrix of
dimensionality (num_corpus_words, k) using the following SVD function from
Scikit-Learn:

            -
http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html

 

        Params:

            M (numpy matrix of shape
(number of corpus words, number of corpus words)): co-occurence matrix of word
counts

            k (int): embedding size
of each word after dimension reduction

        Return:

            M_reduced (numpy matrix
of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.

                    In terms of the
SVD from math class, this actually returns U * S

    """</span>

    n_iters <span class="token operator">=</span> <span class="token number">10</span>  <span class="token comment"># Use this parameter in your call to</span>
`TruncatedSVD`

    M_reduced <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>"Running Truncated
SVD over <span class="token operator">%</span>i words<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>" <span class="token operator">%</span> <span class="token punctuation">(</span>M<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

 

    <span class="token comment"># Write your implementation</span>
here<span class="token punctuation">.</span>

    svd <span class="token operator">=</span>
TruncatedSVD<span class="token punctuation">(</span>n_components<span class="token operator">=</span>k<span class="token punctuation">)</span>

    svd<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>M<span class="token punctuation">.</span>T<span class="token punctuation">)</span>

    M_reduced <span class="token operator">=</span> svd<span class="token punctuation">.</span>components_<span class="token punctuation">.</span>T

 

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done."</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> M_reduced

 

<span class="token comment"># 问题1.4 实现 plot_embeddings</span>

<span class="token comment"># 编写一个函数来绘制2D空间中的一组2D矢量。</span>

<span class="token comment"># 基于matplotlib，用scatter 画 “×”，用 text 写字</span>

<span class="token keyword">def</span> <span class="token function">plot_embeddings</span><span class="token punctuation">(</span>M_reduced<span class="token punctuation">,</span> word2Ind<span class="token punctuation">,</span> words<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Plot in a
scatterplot the embeddings of the words specified in the list
"words".

        NOTE: do not plot all the
words listed in M_reduced / word2Ind.

        Include a label next to each point.

 

        Params:

            M_reduced (numpy matrix
of shape (number of unique words in the corpus , 2)): matrix of 2-dimensioal
word embeddings

            word2Ind (dict):
dictionary that maps word to indices for matrix M

            words (list of strings):
words whose embeddings we want to visualize

    """</span>

    <span class="token comment"># Write your implementation</span>
here<span class="token punctuation">.</span>

    fig <span class="token operator">=</span> plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>

   
plt<span class="token punctuation">.</span>style<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">"seaborn-whitegrid"</span><span class="token punctuation">)</span>

    <span class="token keyword">for</span> word <span class="token keyword">in</span> words<span class="token punctuation">:</span>

        point <span class="token operator">=</span> M_reduced<span class="token punctuation">[</span>word2Ind<span class="token punctuation">[</span>word<span class="token punctuation">]</span><span class="token punctuation">]</span>

        plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>point<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
point<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> marker<span class="token operator">=</span><span class="token string">"^"</span><span class="token punctuation">)</span>

        plt<span class="token punctuation">.</span>annotate<span class="token punctuation">(</span>word<span class="token punctuation">,</span>
xy<span class="token operator">=</span><span class="token punctuation">(</span>point<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> point<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> xytext<span class="token operator">=</span><span class="token punctuation">(</span>point<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> point<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

 

<span class="token comment"># 测试解决方案图</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">80</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Outputted Plot:"</span><span class="token punctuation">)</span>

 

M_reduced_plot_test <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span>
<span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

word2Ind_plot_test <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'test1'</span><span class="token punctuation">:</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token string">'test2'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token string">'test3'</span><span class="token punctuation">:</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'test4'</span><span class="token punctuation">:</span> <span class="token number">3</span><span class="token punctuation">,</span>
<span class="token string">'test5'</span><span class="token punctuation">:</span> <span class="token number">4</span><span class="token punctuation">}</span>

words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'test1'</span><span class="token punctuation">,</span> <span class="token string">'test2'</span><span class="token punctuation">,</span> <span class="token string">'test3'</span><span class="token punctuation">,</span> <span class="token string">'test4'</span><span class="token punctuation">,</span> <span class="token string">'test5'</span><span class="token punctuation">]</span>

plot_embeddings<span class="token punctuation">(</span>M_reduced_plot_test<span class="token punctuation">,</span> word2Ind_plot_test<span class="token punctuation">,</span> words<span class="token punctuation">)</span>

 

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">80</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 问题1.5：共现打印分析</span>

<span class="token comment"># 将词嵌入到2个维度上，归一化，最终词向量会落到一个单位圆内，在坐标系上寻找相近的词。</span>

reuters_corpus <span class="token operator">=</span> read_corpus<span class="token punctuation">(</span><span class="token punctuation">)</span>

M_co_occurrence<span class="token punctuation">,</span> word2Ind_co_occurrence <span class="token operator">=</span>
compute_co_occurrence_matrix<span class="token punctuation">(</span>reuters_corpus<span class="token punctuation">)</span>

M_reduced_co_occurrence <span class="token operator">=</span> reduce_to_k_dim<span class="token punctuation">(</span>M_co_occurrence<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>

 

<span class="token comment"># Rescale (normalize) the rows to make them each of unit-length</span>

M_lengths <span class="token operator">=</span> np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>M_reduced_co_occurrence<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

M_normalized <span class="token operator">=</span> M_reduced_co_occurrence <span class="token operator">/</span> M_lengths<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> np<span class="token punctuation">.</span>newaxis<span class="token punctuation">]</span> <span class="token comment">#</span>
broadcasting

 

words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'barrels'</span><span class="token punctuation">,</span> <span class="token string">'bpd'</span><span class="token punctuation">,</span> <span class="token string">'ecuador'</span><span class="token punctuation">,</span> <span class="token string">'energy'</span><span class="token punctuation">,</span> <span class="token string">'industry'</span><span class="token punctuation">,</span> <span class="token string">'kuwait'</span><span class="token punctuation">,</span> <span class="token string">'oil'</span><span class="token punctuation">,</span>
<span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'petroleum'</span><span class="token punctuation">,</span> <span class="token string">'venezuela'</span><span class="token punctuation">]</span>

 

plot_embeddings<span class="token punctuation">(</span>M_normalized<span class="token punctuation">,</span> word2Ind_co_occurrence<span class="token punctuation">,</span> words<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># Part 2：基于预测的词向量</span>

<span class="token comment"># 使用gensim探索词向量，不是自己实现word2vec，所使用的词向量维度是300，由google发布。</span>

<span class="token keyword">def</span> <span class="token function">load_word2vec</span><span class="token punctuation">(</span>embeddings_fp<span class="token operator">=</span><span class="token string">"./GoogleNews-vectors-negative300.bin"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Load Word2Vec
Vectors

        Param:

            embeddings_fp (string) -
path to .bin file of pretrained word vectors

        Return:

            wv_from_bin: All 3
million embeddings, each lengh 300

                This is the KeyedVectors format:
https://radimrehurek.com/gensim/models/deprecated/keyedvectors.html

    """</span>

    embed_size <span class="token operator">=</span> <span class="token number">300</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>"Loading <span class="token number">3</span> million
word vectors <span class="token keyword">from</span> <span class="token builtin">file</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>"<span class="token punctuation">)</span>

    <span class="token comment">## 自己下载的文件</span>

    wv_from_bin <span class="token operator">=</span>
KeyedVectors<span class="token punctuation">.</span>load_word2vec_format<span class="token punctuation">(</span>embeddings_fp<span class="token punctuation">,</span> binary<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    vocab <span class="token operator">=</span>
<span class="token builtin">list</span><span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>"Loaded vocab size
<span class="token operator">%</span>i" <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> wv_from_bin

wv_from_bin <span class="token operator">=</span> load_word2vec<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 首先使用SVD降维，将300维降2维，方便打印查看。</span>

<span class="token comment"># 问题2.1：word2vec打印分析</span>

<span class="token comment"># 和问题1.5一样</span>

<span class="token keyword">def</span> <span class="token function">get_matrix_of_vectors</span><span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">,</span> required_words<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'barrels'</span><span class="token punctuation">,</span> <span class="token string">'bpd'</span><span class="token punctuation">,</span>
<span class="token string">'ecuador'</span><span class="token punctuation">,</span> <span class="token string">'energy'</span><span class="token punctuation">,</span> <span class="token string">'industry'</span><span class="token punctuation">,</span> <span class="token string">'kuwait'</span><span class="token punctuation">,</span> <span class="token string">'oil'</span><span class="token punctuation">,</span> <span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'petroleum'</span><span class="token punctuation">,</span>
<span class="token string">'venezuela'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token triple-quoted-string string">""" Put the
word2vec vectors into a matrix M.

        Param:

            wv_from_bin:
KeyedVectors object; the 3 million word2vec vectors loaded from file

        Return:

            M: numpy matrix shape
(num words, 300) containing the vectors

            word2Ind: dictionary
mapping each word to its row number in M

    """</span>

    <span class="token keyword">import</span> random

    words <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>vocab<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>"Shuffling words
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>"<span class="token punctuation">)</span>

    random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>words<span class="token punctuation">)</span>

    words <span class="token operator">=</span> words<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">10000</span><span class="token punctuation">]</span>       <span class="token comment"># 选10000个加入</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>"Putting <span class="token operator">%</span>i words
into word2Ind <span class="token operator">and</span> matrix M<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>" <span class="token operator">%</span> <span class="token builtin">len</span><span class="token punctuation">(</span>words<span class="token punctuation">)</span><span class="token punctuation">)</span>

    word2Ind <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>

    M <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    curInd <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token keyword">for</span> w <span class="token keyword">in</span> words<span class="token punctuation">:</span>

        <span class="token keyword">try</span><span class="token punctuation">:</span>

           
M<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>word_vec<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>

            word2Ind<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> curInd

            curInd <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>

            <span class="token keyword">continue</span>

    <span class="token keyword">for</span> w <span class="token keyword">in</span> required_words<span class="token punctuation">:</span>

        <span class="token keyword">try</span><span class="token punctuation">:</span>

           
M<span class="token punctuation">.</span>append<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>word_vec<span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">)</span>

            word2Ind<span class="token punctuation">[</span>w<span class="token punctuation">]</span> <span class="token operator">=</span> curInd

            curInd <span class="token operator">+=</span> <span class="token number">1</span>

        <span class="token keyword">except</span> KeyError<span class="token punctuation">:</span>

            <span class="token keyword">continue</span>

    M <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>M<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Done."</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> M<span class="token punctuation">,</span> word2Ind

 

<span class="token comment"># 测试解决方案图</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">80</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Outputted Plot:"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"-"</span> <span class="token operator">*</span> <span class="token number">80</span><span class="token punctuation">)</span>

 

M<span class="token punctuation">,</span> word2Ind <span class="token operator">=</span> get_matrix_of_vectors<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">)</span>

M_reduced <span class="token operator">=</span> reduce_to_k_dim<span class="token punctuation">(</span>M<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>        
<span class="token comment"># 减到了2维</span>

plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>

words <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'barrels'</span><span class="token punctuation">,</span> <span class="token string">'bpd'</span><span class="token punctuation">,</span> <span class="token string">'ecuador'</span><span class="token punctuation">,</span> <span class="token string">'energy'</span><span class="token punctuation">,</span> <span class="token string">'industry'</span><span class="token punctuation">,</span> <span class="token string">'kuwait'</span><span class="token punctuation">,</span>
<span class="token string">'oil'</span><span class="token punctuation">,</span> <span class="token string">'output'</span><span class="token punctuation">,</span> <span class="token string">'petroleum'</span><span class="token punctuation">,</span> <span class="token string">'venezuela'</span><span class="token punctuation">]</span>

plot_embeddings<span class="token punctuation">(</span>M_reduced<span class="token punctuation">,</span> word2Ind<span class="token punctuation">,</span> words<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 问题2.2：一词多义</span>

<span class="token comment"># 找到一个有多个含义的词（比如 “leaves”，“scoop”），这种词的top-10相似词（根据余弦相似度）里有两个词的意思不一样。比如"leaves"（叶子，花瓣）的top-10词里有"vanishes"（消失）和"stalks"（茎秆）。</span>

<span class="token comment"># 这里我找到的词是"column"（列），它的top-10里有"columnist"（专栏作家）和"article"（文章）</span>

w0 <span class="token operator">=</span> <span class="token string">"column"</span>

w0_mean <span class="token operator">=</span> wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>w0<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"column："</span><span class="token punctuation">,</span> w0_mean<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 问题2.3：近义词和反义词</span>

<span class="token comment"># 找到三个词(w1, w2, w3)，其中w1和w2是近义词，w1和w3是反义词，但是w1和w3的距离&lt;w1和w2的距离。</span>

<span class="token comment"># 例如：w1=“happy”，w2=“cheerful”，w3=“sad”</span>

w1 <span class="token operator">=</span> <span class="token string">"love"</span>

w2 <span class="token operator">=</span> <span class="token string">"like"</span>

w3 <span class="token operator">=</span> <span class="token string">"hate"</span>

w1_w2_dist <span class="token operator">=</span> wv_from_bin<span class="token punctuation">.</span>distance<span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">)</span>

w1_w3_dist <span class="token operator">=</span> wv_from_bin<span class="token punctuation">.</span>distance<span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w3<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Synonyms {}, {} have cosine distance: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w2<span class="token punctuation">,</span>
w1_w2_dist<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Antonyms {}, {} have cosine distance: {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>w1<span class="token punctuation">,</span> w3<span class="token punctuation">,</span>
w1_w3_dist<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 问题2.4：类比</span>

<span class="token comment"># man 对于 king，相当于woman对于___，这样的问题也可以用word2vec来解决</span>

<span class="token comment"># man : him :: woman : her</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"类比 man : him :: woman : her："</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'him'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

 

<span class="token comment"># 问题2.5：错误的类比</span>

<span class="token comment"># 找到一个错误的类比，树：树叶 ：：花：花瓣</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"错误的类比 tree : leaf :: flower : petal："</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'leaf'</span><span class="token punctuation">,</span> <span class="token string">'flower'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'tree'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 问题2.6：偏见分析</span>

<span class="token comment"># 注意偏见是很重要的比如性别歧视、种族歧视等，执行下面代码，分析两个问题：</span>

<span class="token comment"># (a) 哪个词与“woman”和“boss”最相似，和“man”最不相似?</span>

<span class="token comment"># (b) 哪个词与“man”和“boss”最相似，和“woman”最不相似?</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"偏见 woman : boss :: man："</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'boss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"偏见 man : boss :: woman："</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">,</span> <span class="token string">'boss'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 

<span class="token comment"># 问题2.7：自行分析偏见</span>

<span class="token comment">#     男人:女人 :: 医生:___</span>

<span class="token comment">#     女人:男人 :: 医生:___</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"自行分析偏见 woman : doctor :: man："</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">,</span> <span class="token string">'doctor'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"自行分析偏见 man : doctor :: woman："</span><span class="token punctuation">)</span>

pprint<span class="token punctuation">.</span>pprint<span class="token punctuation">(</span>wv_from_bin<span class="token punctuation">.</span>most_similar<span class="token punctuation">(</span>positive<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'man'</span><span class="token punctuation">,</span> <span class="token string">'doctor'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
negative<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'woman'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

 </code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0ea9e4c9bae893e176a020a13190082d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">divmod( )函数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/84c6def96d6b5d0cc9af9129e5fef0ab/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">DeepLearning之LSTM模型输入数据：白话降维解说</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>