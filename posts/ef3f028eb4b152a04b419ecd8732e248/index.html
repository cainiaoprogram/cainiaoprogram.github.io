<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文阅读之《Underwater scene prior inspired deep underwater image and video Enhancement (UWCNN)》 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文阅读之《Underwater scene prior inspired deep underwater image and video Enhancement (UWCNN)》" />
<meta property="og:description" content="Pattern Recognition(2020)
作者：Chongyi Li（这是水下图像增强界公认的大佬~我的偶像啊）
2020/01至今，新加坡南洋理工大学计算机科学与工程学院MMLAB研究员。
2018/10-2020/01，香港城市大学计算机科学系博后研究员，与教授Sam Kwong (IEEE fellow)一起工作。
2016/12-2017/12，澳大利亚国立大学工程研究学院联合攻读博士，师从Fatih Porikli教授(IEEE Fellow) 。
2014/09-2018/07，天津大学电气与信息工程学院攻读博士学位，师从郭继昌教授。
研究兴趣包括人工智能，机器学习，计算机视觉和图像处理，特别是在图像和视频恢复和增强领域。
Abstract 在水下场景中，波长相关的光吸收和散射会降低图像和视频的可见度。退化的水下图像和视频影响水下场景中模式识别、视觉理解和关键特征提取的准确性。文章提出了一种基于水下场景先验的水下图像增强卷积神经网络模型（UWCNN）。该模型不需要估计水下成像模型的参数，而是直接重构清晰的潜在水下图像，这得益于水下场景先验，可用于合成水下图像训练数据。此外，基于轻量级的网络结构和有效的训练数据，UWCNN模型可以很容易地扩展到水下视频进行逐帧增强。具体来说，将水下成像物理模型与水下场景的光学特性相结合，先合成不同类型的水下图像数据集，然后，针对每种水下场景类型，设计一个轻量级的CNN模型，并通过相应的训练数据进行训练。最后，将该模型直接扩展到水下视频增强。在真实和合成的水下图像和视频上的实验表明，该方法能够很好地适用于不同的水下场景。
Introduction 研究动机：
光在水下传播过程受到衰减导致颜色通道衰减。传统的图像增强方法在处理水下图像和视频时表现出局限性。此外，由于缺乏足够和有效的训练数据，基于深度学习的水下图像和视频增强方法的性能不能与基于深度学习的解决方案(例如图像分类、分析、分割、超分辨率、识别等)相匹配。为了获得更高的水下视觉质量，提高高水平视觉任务的性能，有必要开发水下图像合成和增强方法。
主要工作：
文中提出了一种新的水下图像合成算法，算法使用水下场景先验，为水下图像和视频增强提供基于数据驱动的解决方案。提出的方法被证明对不同的水类型具有优越的鲁棒性、准确性和灵活性。
贡献：
(1)提出一种新的基于水下场景先验的水下图像合成算法，该算法能够模拟多种退化的水下图像。
(2)提出了一种新的CNN模型，通过联合优化多项损失，在保留原始结构和纹理的同时，重建清晰的水下图像。
(3)提出方法可以很好地推广到具有不同颜色和可见性特征的合成和真实世界的水下图像和视频。
Related work Proposed method 首先将图像转换到HSI颜色空间。然后，其在HSI颜色空间中的饱和度和强度分量的范围被归一化为[0,1]。
在将调整后的图像转到RGB空间。UWCNN可以有效的消除真实水下图像中存在的绿色失真并改善对比度，经过后处理的UWCNN进一步提高了饱和度和亮度，揭示了更多的细节信息。
水下图像合成算法
缺乏地面真实的水下图像数据集限制了基于深度学习的水下图像增强和质量评估的发展。为了填补这一空白，提出了一种基于水下成像物理模型和水下场景光学特性的水下图像合成算法。这是第一个基于物理模型的水下图像合成算法，可以模拟不同的水类型和退化程度，这是对水下图像和视频增强发展的重要贡献。
（1）通过不同的衰减系数来描述海洋和沿海不同类型的水体。
（2）通过修改水下图像恢复模型中的光波和场景点X到相机的距离d(x)来模拟不同深度的水下图像成像过程。
Experiment Conclusion 文章提出了一个基于水下场景先验的水下图像和视频增强网络UWCNN。在合成和真实水下图像验证实验表明了该方法的鲁棒性和有效性。网络只包含十个卷积层和每个卷积层的16个特征映射，可以快速训练。在我们的网络中使用的残差学习、密集连接和SSIM损失经证明都提升了网络性能。
我的想法 存在的问题
1.通过水下成像模型设置不同的衰减系数模拟水下图像训练模型有待于验证准确性。
2.模型对于衰减严重的图像存在过度补偿的问题。
3.合成的数据很难模拟到各种衰减程度的水下图像，导致模型整体的泛化性不强。
4.论文采用MSE，PSNR，SSIM等传统有参考图像评价指标，不具有广泛性，而针对水下图像的无参考质量评价指标也是研究的一个热点，作者完全规避掉了。
后期可以尝试的改进
1.根据水下合成数据集的思想，尝试各种监督学习图像增强框架。
2.利用残差学习实现无监督学习，解决无参考图像水下图像增强问题。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ef3f028eb4b152a04b419ecd8732e248/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-21T15:53:26+08:00" />
<meta property="article:modified_time" content="2023-12-21T15:53:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文阅读之《Underwater scene prior inspired deep underwater image and video Enhancement (UWCNN)》</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:0in;text-align:center;"><span style="color:#fe2c24;"><strong>Pattern Recognition(2020)</strong></span></p> 
<p style="margin-left:0in;text-align:justify;"><img alt="" height="213" src="https://images2.imgbox.com/3a/c5/lS7s9h7f_o.png" width="271"></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">作者：Chongyi Li（这是水下图像增强界公认的大佬~我的偶像啊）</span></p> 
<p> <span style="color:#000000;">2020/01</span><span style="color:#000000;">至今，新加坡南洋理工大学计算机科学</span><span style="color:#000000;">与工程</span><span style="color:#000000;">学院</span><span style="color:#000000;">MMLAB</span><span style="color:#000000;">研究员。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">2018/10-2020/01</span><span style="color:#000000;">，香港城市大学</span><span style="color:#000000;">计算机科学</span><span style="color:#000000;">系博后</span><span style="color:#000000;">研究员，</span><span style="color:#000000;">与教授</span><span style="color:#000000;">Sam </span><span style="color:#000000;">Kwong</span><span style="color:#000000;"> (IEEE fellow)</span><span style="color:#000000;">一起工作。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">2016/12-2017/12</span><span style="color:#000000;">，澳大利亚国立大学工程研究学院</span><span style="color:#000000;">联合攻读博士，</span><span style="color:#000000;">师从</span><span style="color:#000000;">Fatih</span> <span style="color:#000000;">Porikli</span><span style="color:#000000;">教授</span><span style="color:#000000;">(IEEE Fellow) </span><span style="color:#000000;">。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">2014/09-2018/07</span><span style="color:#000000;">，天津大学</span><span style="color:#000000;">电气与信息工程学院攻读博士学位，师从郭继昌教授</span><span style="color:#000000;">。</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">研究兴趣包括人工智能，机器学习，计算机视觉和图像处理，特别是在图像和视频恢复和增强领域。</span></p> 
<h2 style="margin-left:0in;text-align:left;"><span style="color:#000000;">Abstract</span></h2> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">在水下场景中，波长相关的光吸收和散射会降低图像和视频的可见度。退化的水下图像和视频影响水下场景中模式识别、视觉理解和关键特征提取的准确性。</span><span style="color:#ff0000;">文章提出</span><span style="color:#ff0000;">了一种基于水下场景先验的水下图像增强卷积</span><span style="color:#ff0000;">神经网络模型（</span><span style="color:#ff0000;">UWCNN</span><span style="color:#ff0000;">）</span><span style="color:#000000;">。</span><span style="color:#000000;">该模型不需要估计水下成像模型的参数，而是直接重构清晰的潜在水下图像，这得益于水下场景先验，可用于合成水下图像训练数据。此外，基于轻量级的网络结构和有效的训练数据</span><span style="color:#000000;">，</span><span style="color:#000000;">UWCNN</span><span style="color:#000000;">模型可以很容易地扩展到水下视频进行逐帧增强</span><span style="color:#000000;">。</span><span style="color:#000000;">具体来说，将水下成像物理模型与水下场景的光学特性相结合</span><span style="color:#000000;">，先</span><span style="color:#ff0000;">合成不同类型的水</span><span style="color:#ff0000;">下</span><span style="color:#ff0000;">图像数据</span><span style="color:#ff0000;">集</span><span style="color:#000000;">，然后</span><span style="color:#000000;">，针对每种水下场景类型，</span><span style="color:#000000;">设计一</span><span style="color:#000000;">个轻量级的</span><span style="color:#000000;">CNN</span><span style="color:#000000;">模型，并通过相应的训练数据进行训练。最后，将该模型直接扩展到水下视频增强。在真实和合成的水下图像和视频上的实验表明，该方法能够很好地适用于不同的水下场景。</span></p> 
<h2 style="margin-left:0in;text-align:justify;"><span style="color:#000000;">Introduction</span></h2> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#073e87;"><strong>研究动机：</strong></span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">光在水下传播过程受到衰减导致颜色通道衰减。</span><span style="color:#32ae51;">传统</span><span style="color:#32ae51;">的图像增强</span><span style="color:#32ae51;">方法</span><span style="color:#000000;">在</span><span style="color:#000000;">处理水下图像和视频时表现出</span><span style="color:#32ae51;">局限性</span><span style="color:#000000;">。此外，由于</span><span style="color:#32ae51;">缺乏足够和有效的训练数据</span><span style="color:#000000;">，基于</span><span style="color:#32ae51;">深度学习</span><span style="color:#000000;">的水下图像和视频增强方法的性能不能与基于深度学习的解决方案</span><span style="color:#000000;">(</span><span style="color:#000000;">例如图像分类、分析、分割、</span><span style="color:#000000;">超</span><span style="color:#000000;">分辨率、识别等</span><span style="color:#000000;">)</span><span style="color:#000000;">相匹配。为了获得更高的水下视觉质量，提高高水平视觉任务的性能，有必要开发</span><span style="color:#ff0000;">水下图像合成</span><span style="color:#000000;">和</span><span style="color:#ff0000;">增强</span><span style="color:#000000;">方法。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#073e87;"><strong>主要工作：</strong></span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">文</span><span style="color:#000000;">中</span><span style="color:#000000;">提出</span><span style="color:#000000;">了一种新的水下图像合成算法</span><span style="color:#000000;">，算法</span><span style="color:#000000;">使用水下场景先验</span><span style="color:#000000;">，为</span><span style="color:#000000;">水下图像和视频增强</span><span style="color:#000000;">提供基于数据驱动的解决</span><span style="color:#000000;">方案。提出的方法被证明对不同的水类型具有优越的鲁棒性、准确性和灵活性</span><span style="color:#000000;">。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#073e87;"><strong>贡献：</strong></span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">(1)</span><span style="color:#000000;">提出</span><span style="color:#000000;">一种新的基于水下场景先验的水下图像合成算法，该算法能够模拟多种退化的水下图像</span><span style="color:#000000;">。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">(2)</span><span style="color:#000000;">提出</span><span style="color:#000000;">了一种新的</span><span style="color:#000000;">CNN</span><span style="color:#000000;">模型，通过联合优化多项损失，在保留原始结构和纹理的同时，重建清晰的水下</span><span style="color:#000000;">图像。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">(3)</span><span style="color:#000000;">提出方法</span><span style="color:#000000;">可以很好地推广到具有不同颜色和可见性特征的合成和真实世界的水下图像和视频。</span></p> 
<h2 style="margin-left:0in;text-align:justify;"><span style="color:#000000;">Related work</span></h2> 
<p style="margin-left:0in;text-align:justify;"><img alt="" height="354" src="https://images2.imgbox.com/c9/f6/sjyyLOdI_o.png" width="891"></p> 
<h2>Proposed method</h2> 
<p style="margin-left:0in;text-align:left;"><span style="color:#000000;">首先</span><span style="color:#000000;">将图像转换到</span><span style="color:#000000;">HSI</span><span style="color:#000000;">颜色空间。然后，其在</span><span style="color:#000000;">HSI</span><span style="color:#000000;">颜色空间中的饱和度和强度分量的范围被归一化为</span><span style="color:#000000;">[</span><span style="color:#000000;">0</span><span style="color:#000000;">,1]。</span></p> 
<p class="img-center"><img alt="" height="61" src="https://images2.imgbox.com/fe/68/Dj4zCQXZ_o.png" width="180"></p> 
<p><span style="color:#000000;">在将调整后的图像转到</span><span style="color:#000000;">RGB</span><span style="color:#000000;">空间。</span><span style="color:#000000;">UWCNN</span><span style="color:#000000;">可以有效的消除真实水下图像中存在的绿色失真并改善对比度，经过后处理的</span><span style="color:#000000;">UWCNN</span><span style="color:#000000;">进一步提高了饱和度和亮度，揭示了更多的细节信息。</span></p> 
<p><img alt="" height="282" src="https://images2.imgbox.com/31/44/ghZD7CyR_o.png" width="813"></p> 
<p> <span style="color:#073e87;"><strong>水下图像合成算法</strong></span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#ff0000;">缺乏地面真实的</span><span style="color:#ff0000;">水下图像数据</span><span style="color:#000000;">集限制了基于深度学习的水下图像增强和质量评估的发展。为了填补这一空白，提出了一种</span><span style="color:#ff0000;">基于水下成像物理模型和水下场景光学特性的水下图像合成算法</span><span style="color:#000000;">。这是</span><span style="color:#32ae51;">第一个</span><span style="color:#000000;">基于物理模型的水下图像合成算法，可以模拟不同的水类型和退化程度，这是对水下图像和视频增强发展的重要贡献。</span></p> 
<p style="margin-left:0in;text-align:left;"><span style="color:#2e3033;">（</span><span style="color:#2e3033;">1</span><span style="color:#2e3033;">）通过不同的衰减系数</span><span style="color:#2e3033;">来描述海洋和沿海不同类型的</span><span style="color:#2e3033;">水体。</span><br><span style="color:#2e3033;">（</span><span style="color:#2e3033;">2</span><span style="color:#2e3033;">）通过修改水下图像恢复模型中的光波和场景点</span><span style="color:#2e3033;">X</span><span style="color:#2e3033;">到相机的距离</span><span style="color:#2e3033;">d(x)</span><span style="color:#2e3033;">来模拟不同深度的水下图像成像过程。</span></p> 
<h2 style="margin-left:0in;text-align:left;"><span style="color:#2e3033;">Experiment</span></h2> 
<p class="img-center"><img alt="" height="527" src="https://images2.imgbox.com/d6/d5/GXXsAlE8_o.png" width="726"></p> 
<p class="img-center"><img alt="" height="479" src="https://images2.imgbox.com/0f/78/Kc8htcHr_o.png" width="509"></p> 
<h2>Conclusion</h2> 
<p><span style="color:#000000;">文章提出</span><span style="color:#000000;">了一</span><span style="color:#000000;">个基于水下场景先验的水</span><span style="color:#000000;">下图像和视频</span><span style="color:#000000;">增强网络</span><span style="color:#000000;">UWCNN</span><span style="color:#000000;">。</span><span style="color:#000000;">在合成和真实水下</span><span style="color:#000000;">图像验证实验</span><span style="color:#000000;">表明了该方法的鲁棒性和有效性</span><span style="color:#000000;">。网络只</span><span style="color:#000000;">包含十个卷积层和每个卷积层的</span><span style="color:#000000;">16</span><span style="color:#000000;">个特征</span><span style="color:#000000;">映射，可以快速训练。在</span><span style="color:#000000;">我们的网络中使用</span><span style="color:#000000;">的</span><span style="color:#000000;">残差</span><span style="color:#000000;">学习</span><span style="color:#000000;">、密集连接和</span><span style="color:#000000;">SSIM</span><span style="color:#000000;">损失经证明都提升了网络性能。</span></p> 
<h2 style="background-color:transparent;"><span style="color:#0d0016;">我的想法</span></h2> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#32ae51;">存在的问题</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">1.</span><span style="color:#000000;">通过水下成像模型设置不同的衰减系数模拟水下图像训练模型有待于验证准确性。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">2.</span><span style="color:#000000;">模型对于衰减严重的图像存在过度补偿的问题。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">3.</span><span style="color:#000000;">合成的数据很难模拟到各种衰减程度的水下图像，导致模型整体的泛化性不强。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">4.</span><span style="color:#000000;">论文采用</span><span style="color:#000000;">MSE</span><span style="color:#000000;">，</span><span style="color:#000000;">PSNR</span><span style="color:#000000;">，</span><span style="color:#000000;">SSIM</span><span style="color:#000000;">等传统有参考图像评价指标，不具有广泛性，而针对水下图像的无参考质量评价指标也是研究的一个热点，作者完全规避掉了。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#00b050;">后期可以尝试的改进</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">1.</span><span style="color:#000000;">根据水下合成数据集的思想，尝试各种监督学习图像增强框架。</span></p> 
<p style="margin-left:0in;text-align:justify;"><span style="color:#000000;">2.</span><span style="color:#000000;">利用残差学习实现</span><span style="color:#ff0000;">无监督学习</span><span style="color:#000000;">，解决无参考图像水下图像增强问题。</span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/379ba4750883f0e85307045e84e92286/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">NLP论文阅读记录 - | 使用GPT对大型文档集合进行抽象总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/39de2a93924775b922f9d43d582c4c1f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Qualcomm® AI Engine Direct 使用手册（3）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>