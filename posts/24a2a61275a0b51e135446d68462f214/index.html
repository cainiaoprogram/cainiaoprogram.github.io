<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>将注意力机制引入ResNet，视觉领域涨点技巧来了！附使用方法 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="将注意力机制引入ResNet，视觉领域涨点技巧来了！附使用方法" />
<meta property="og:description" content="最近，加州大学伯克利分校和谷歌的科研团队共同提出了一个概念上非常简单，但是功能很强大的骨架网络，该网络将自注意力机制纳入了各种计算机视觉任务，包括图像分类、目标检测和实例分割，指标都有了很大的提升，该网络叫做 BoTNet（Bottleneck Transformer）。
为什么要使用 BoTNet？设计思想 近年来，卷积骨架网络在计算机视觉的各个领域取得了非常大的进展，这得益于卷积能够有效捕捉图像中局部的信息，但是对于实例分割、目标检测和关键点检测之类的视觉任务，需要对长期的依赖进行建模。
一、为什么要引入注意力机制？传统基于卷积的体系结构，需要堆叠很多个卷积层，以全局汇总捕捉局部信息的计算结果。尽管堆叠更多的层可能能够提高这些骨架网络的性能，但是显式的对全局依赖性进行建模可能是一种更强大且更具扩展性的解决方案。
二、为什么不全部替换成注意力机制？目标检测领域的输入图像（1024像素）相比于图像分类（224像素）来说非常大。而对于自注意力机制，消耗的显存和计算量与输入的大小成4倍增长，导致训练和测试效率太低，不切实际。
因此，作者提出利用自注意力机制来替换 ResNet 的最后三个 BottleNeck Layer ，这样的结构，使用卷积提取图像中局部的信息，然后利用自注意力机制来对全局的依赖性进行建模，能够解决上述的两个问题。
网络设计 该所提方法基于ResNet网络，与ResNet的唯一区别，是在 c5 中，将 3×3 卷积替换成了 MHSA（Multi-Head Self Attention）结构。可以看到，参数量相比于ResNet减少了18.4%，加乘操作的数量增加了20%。
实验部分 作者在实例分割和目标检测上进行了实验。
相比ResNet，提升了COCO 实例分割上的性能 其中，R50 代表 ResNet-50。
相对的位置编码能够提升性能 MHSA层中有两种交互：内容和内容的交互(qkT)，以及内容和位置的交互（qrT）。而使用相对位置进行交互，带来的性能提升是非常明显的。
三个卷积都替换成 MHSA 吗？ c5中有三个卷积层，作者进行消融实验，来看是否需要三个都替换成MHSA？
结论是：三个卷积层全都替换，在小目标上效果非常好，但是大目标上效果就不太行了。作者说这可能是优化得不好，把这个留给了未来工作。
通过替换引入了全局依赖，那么性能是否与更深的卷积网络相当？ 随着卷积网络的不断加深，更容易关注到全局的信息。而使用自注意力机制直接就关注的是全局的信息，所以说使用自注意力的网络不那么深，也能够达到类似的性能。作者通过实验也说明了这一点。
通过上表，我们可以看出，当配置是[0,1,1]时，BoT 50的效果要好于 R101的效果。
可以得出结论：替换为自注意力比卷积的堆叠更加有效。
BoTNet可以提升所有ResNet家族网络的性能 这里就是增加了152层的ResNet的结果，性能也有一定的提升。
除此之外，作者还进行了非常多详细的实验，有兴趣的可以参考原论文。
使用方式 这里官方都为我们实现好了，话不多说，直接上代码。这个实现方式是基于PyTorch的，基于TensorFlow的代码在最下面有。
安装 pip install bottleneck-transformer-pytorch 使用 import torch from torch import nn from torchvision.models import resnet5 from bottleneck_transformer_pytorch import BottleStack layer = BottleStack( dim = 256, # 输入通道数 fmap_size = 56, # 对于imagenet 224 x 224的图，特征图大小为56 x 56 dim_out = 2048, # 输出通道数 proj_factor = 4, # 压缩通道的倍数，压缩后的通道数 = 输入通道数 / proj_factor downsample = True, # 第一层是否下采样 heads = 4, # MHSA 的头数 dim_head = 128, # 每个头的维度，默认128维 rel_pos_emb = False, # 是否使用相对的位置嵌入 activation = nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/24a2a61275a0b51e135446d68462f214/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-03-16T12:39:34+08:00" />
<meta property="article:modified_time" content="2021-03-16T12:39:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">将注意力机制引入ResNet，视觉领域涨点技巧来了！附使用方法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>最近，加州大学伯克利分校和谷歌的科研团队共同提出了一个概念上非常简单，但是功能很强大的骨架网络，该网络将自注意力机制纳入了各种计算机视觉任务，包括图像分类、目标检测和实例分割，指标都有了很大的提升，该网络叫做 BoTNet（Bottleneck Transformer）。</p> 
<h3><a id="_BoTNet_3"></a>为什么要使用 BoTNet？设计思想</h3> 
<p>近年来，卷积骨架网络在计算机视觉的各个领域取得了非常大的进展，这得益于卷积能够有效捕捉图像中局部的信息，但是对于实例分割、目标检测和关键点检测之类的视觉任务，需要对长期的依赖进行建模。</p> 
<p>一、为什么要引入注意力机制？传统基于卷积的体系结构，需要堆叠很多个卷积层，以全局汇总捕捉局部信息的计算结果。尽管堆叠更多的层可能能够提高这些骨架网络的性能，但是显式的对全局依赖性进行建模可能是一种更强大且更具扩展性的解决方案。</p> 
<p>二、为什么不全部替换成注意力机制？目标检测领域的输入图像（1024像素）相比于图像分类（224像素）来说非常大。而对于自注意力机制，消耗的显存和计算量与输入的大小成4倍增长，导致训练和测试效率太低，不切实际。</p> 
<p>因此，作者提出利用自注意力机制来替换 ResNet 的最后三个 BottleNeck Layer ，这样的结构，使用卷积提取图像中局部的信息，然后利用自注意力机制来对全局的依赖性进行建模，能够解决上述的两个问题。</p> 
<p><img src="https://images2.imgbox.com/58/7c/aSJFVlEp_o.png" alt="与其它视觉注意力方法的联系"></p> 
<h3><a id="_14"></a>网络设计</h3> 
<p><img src="https://images2.imgbox.com/dc/07/f0KJf8UC_o.png" alt="Bottleneck Transformer"><br> 该所提方法基于ResNet网络，与ResNet的唯一区别，是在 c5 中，将 3×3 卷积替换成了 MHSA（Multi-Head Self Attention）结构。可以看到，参数量相比于ResNet减少了18.4%，加乘操作的数量增加了20%。<br> <img src="https://images2.imgbox.com/41/1d/wrqnRTKa_o.png" alt="模型设计"></p> 
<h3><a id="_18"></a>实验部分</h3> 
<p>作者在实例分割和目标检测上进行了实验。</p> 
<h4><a id="ResNetCOCO__22"></a>相比ResNet，提升了COCO 实例分割上的性能</h4> 
<p><img src="https://images2.imgbox.com/77/3c/1LfZgPF7_o.png" alt="在这里插入图片描述"></p> 
<p>其中，R50 代表 ResNet-50。</p> 
<h4><a id="_27"></a>相对的位置编码能够提升性能</h4> 
<p><img src="https://images2.imgbox.com/b5/46/iDPiNj16_o.png" alt="在这里插入图片描述"></p> 
<p>MHSA层中有两种交互：内容和内容的交互(qk<sup>T)，以及内容和位置的交互（qr</sup>T）。而使用相对位置进行交互，带来的性能提升是非常明显的。</p> 
<h4><a id="_MHSA__32"></a>三个卷积都替换成 MHSA 吗？</h4> 
<p>c5中有三个卷积层，作者进行消融实验，来看是否需要三个都替换成MHSA？</p> 
<p><img src="https://images2.imgbox.com/a8/7b/085mgwql_o.png" alt="在这里插入图片描述"><br> 结论是：三个卷积层全都替换，在小目标上效果非常好，但是大目标上效果就不太行了。作者说这可能是优化得不好，把这个留给了未来工作。</p> 
<p><img src="https://images2.imgbox.com/f9/ed/MrDvLpXR_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_41"></a>通过替换引入了全局依赖，那么性能是否与更深的卷积网络相当？</h4> 
<p>随着卷积网络的不断加深，更容易关注到全局的信息。而使用自注意力机制直接就关注的是全局的信息，所以说使用自注意力的网络不那么深，也能够达到类似的性能。作者通过实验也说明了这一点。</p> 
<p>通过上表，我们可以看出，当配置是[0,1,1]时，BoT 50的效果要好于 R101的效果。</p> 
<p>可以得出结论：替换为自注意力比卷积的堆叠更加有效。</p> 
<h4><a id="BoTNetResNet_49"></a>BoTNet可以提升所有ResNet家族网络的性能</h4> 
<p>这里就是增加了152层的ResNet的结果，性能也有一定的提升。</p> 
<p><img src="https://images2.imgbox.com/1b/bc/iUetMgCG_o.png" alt=""></p> 
<p>除此之外，作者还进行了非常多详细的实验，有兴趣的可以参考原论文。</p> 
<h3><a id="_57"></a>使用方式</h3> 
<p>这里官方都为我们实现好了，话不多说，直接上代码。这个实现方式是基于PyTorch的，基于TensorFlow的代码在最下面有。</p> 
<h4><a id="_61"></a>安装</h4> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> bottleneck-transformer-pytorch
</code></pre> 
<h4><a id="_67"></a>使用</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">import</span> resnet5
<span class="token keyword">from</span> bottleneck_transformer_pytorch <span class="token keyword">import</span> BottleStack

layer <span class="token operator">=</span> BottleStack<span class="token punctuation">(</span>
    dim <span class="token operator">=</span> <span class="token number">256</span><span class="token punctuation">,</span>              <span class="token comment"># 输入通道数</span>
    fmap_size <span class="token operator">=</span> <span class="token number">56</span><span class="token punctuation">,</span>         <span class="token comment"># 对于imagenet 224 x 224的图，特征图大小为56 x 56</span>
    dim_out <span class="token operator">=</span> <span class="token number">2048</span><span class="token punctuation">,</span>         <span class="token comment"># 输出通道数</span>
    proj_factor <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>        <span class="token comment"># 压缩通道的倍数，压缩后的通道数 = 输入通道数 / proj_factor</span>
    downsample <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">,</span>      <span class="token comment"># 第一层是否下采样</span>
    heads <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span>              <span class="token comment"># MHSA 的头数</span>
    dim_head <span class="token operator">=</span> <span class="token number">128</span><span class="token punctuation">,</span>         <span class="token comment"># 每个头的维度，默认128维</span>
    rel_pos_emb <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">,</span>    <span class="token comment"># 是否使用相对的位置嵌入</span>
    activation <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 激活函数</span>
<span class="token punctuation">)</span>

resnet <span class="token operator">=</span> resnet50<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 定义ResNet模型</span>

backbone <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>resnet<span class="token punctuation">.</span>children<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 修改ResNet模型的最后几层</span>
model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    <span class="token operator">*</span>backbone<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    layer<span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span> <span class="token number">1000</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

<span class="token comment"># 使用 “BotNet”</span>
img <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">,</span> <span class="token number">224</span><span class="token punctuation">)</span>
preds <span class="token operator">=</span> model<span class="token punctuation">(</span>img<span class="token punctuation">)</span>  <span class="token comment"># (2, 1000)</span>
</code></pre> 
<h4><a id="_105"></a>是否有开源预训练模型？</h4> 
<p>大家知道，训练注意力模型需要非常大的显存，原始论文是使用TPU进行训练的，但是很遗憾，目前<strong>并没有</strong>公开的预训练模型。</p> 
<h3><a id="_109"></a>参考资料：</h3> 
<ul><li>原始论文：<a href="https://arxiv.org/abs/2101.11605" rel="nofollow">https://arxiv.org/abs/2101.11605</a></li><li>TensorFlow 1实现：<a href="https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2" rel="nofollow">https://gist.github.com/aravindsrinivas/56359b79f0ce4449bcb04ab4b56a57a2</a></li><li>PyTorch实现：<a href="https://github.com/lucidrains/bottleneck-transformer-pytorch/blob/main/bottleneck_transformer_pytorch/bottleneck_transformer_pytorch.py">https://github.com/lucidrains/bottleneck-transformer-pytorch/blob/main/bottleneck_transformer_pytorch/bottleneck_transformer_pytorch.py</a></li></ul> 
<p>写在后面：关于BotNet的介绍就到这里了，如果觉得这篇文章对你有帮助，欢迎点赞收藏支持我，谢谢！</p> 
<p>公众号：算法小哥克里斯</p> 
<p>知乎：https://www.zhihu.com/people/chris-2021</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8af3352d2654f2c8f6a8ee0b69b2c0d6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">PaddleOCR加载chinese_ocr_db_crnn_server/chinese_ocr_db_crnn_modile模型进行中英文混合预测（代码）实践</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/701f607a5331407f29f59db20fcd3e9a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">matlab 无穷符号,如何用matlab进行级数或数列的符号求和?matlab符号求和指令分享...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>