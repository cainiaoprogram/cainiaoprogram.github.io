<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Yolov5/Yolov7优化：卷积变体---分布移位卷积（DSConv）,提高卷积层的内存效率和速度 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Yolov5/Yolov7优化：卷积变体---分布移位卷积（DSConv）,提高卷积层的内存效率和速度" />
<meta property="og:description" content="目录
1. DSConv介绍
2.DSConv引入Yolov5
2.1修改common.py中：
2.2 加入yolo.py中：
2.3 yolov5s_DSConv2D_C3.yaml
🏆 🏆🏆🏆🏆🏆🏆Yolov5/Yolov7成长师🏆🏆🏆🏆🏆🏆🏆 🍉🍉进阶专栏Yolov5/Yolov7魔术师：http://t.csdn.cn/D4NqB 🍉🍉
✨✨✨魔改网络、复现前沿论文，组合优化创新
🚀🚀🚀小目标、遮挡物、难样本性能提升
🌰 🌰 🌰在不同数据集验证能够涨点，对小目标涨点明显 1. DSConv介绍 论文： https://arxiv.org/pdf/1901.01928v1.pdf
摘要：提出了一种卷积的变体，称为DSConv（分布偏移卷积），其可以容易地替换进标准神经网络体系结构并且实现较低的存储器使用和较高的计算速度。 DSConv将传统的卷积内核分解为两个组件：可变量化内核（VQK）和分布偏移。 通过在VQK中仅存储整数值来实现较低的存储器使用和较高的速度，同时通过应用基于内核和基于通道的分布偏移来保持与原始卷积相同的输出。 我们在ResNet50和34以及AlexNet和MobileNet上对ImageNet数据集测试了DSConv。 我们通过将浮点运算替换为整数运算，在卷积内核中实现了高达14x的内存使用量减少，并将运算速度提高了10倍。 此外，与其他量化方法不同，我们的工作允许对新任务和数据集进行一定程度的再训练。 DSConv 的总体目标是通过使用量化和分布偏移来模拟卷积层的行为。
DSConv 的设置如上图所示。为了方便和表示，让原始卷积张量的大小为 (cho, chi, k, k)，其中 cho 是下一层的通道数，chi 是当前层中的通道，k是内核的宽度和高度。
DSConv是一种深度可分离卷积（Depthwise Separable Convolution）的变体，它在计算机视觉领域被广泛使用。深度可分离卷积是一种轻量级卷积，它将标准卷积拆分为两个步骤：深度卷积和逐点卷积。深度卷积只在单个通道上进行卷积，并在每个通道上应用一个独立的卷积核。逐点卷积在所有通道上应用一个卷积核，以组合深度卷积的结果。DSConv相比于深度可分离卷积的优势在于它使用了一个可学习的卷积核来进一步提高模型的表现。
结果对比：
实验目标：在 Resnet34 和 Resnet50 中应用的 DSConv 与其他网络
实验结果：效果有明显提高
2.DSConv引入Yolov5 2.1修改common.py中： ###################### DSConv #### start by AI&amp;CV ############################### import torch.nn.functional as F from torch.nn.modules.conv import _ConvNd from torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/3f2687db6d95afed66e7a573c3943c15/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-28T15:59:19+08:00" />
<meta property="article:modified_time" content="2023-06-28T15:59:19+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Yolov5/Yolov7优化：卷积变体---分布移位卷积（DSConv）,提高卷积层的内存效率和速度</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="-toc" style="margin-left:0px;"></p> 
<p id="1.%20DSConv%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><a href="#1.%20DSConv%E4%BB%8B%E7%BB%8D" rel="nofollow">1. DSConv介绍</a></p> 
<p id="%C2%A02.DSConv%E5%BC%95%E5%85%A5Yolov5-toc" style="margin-left:0px;"><a href="#%C2%A02.DSConv%E5%BC%95%E5%85%A5Yolov5" rel="nofollow"> 2.DSConv引入Yolov5</a></p> 
<p id="2.1%E4%BF%AE%E6%94%B9common.py%E4%B8%AD%EF%BC%9A-toc" style="margin-left:40px;"><a href="#2.1%E4%BF%AE%E6%94%B9common.py%E4%B8%AD%EF%BC%9A" rel="nofollow">2.1修改common.py中：</a></p> 
<p id="2.2%C2%A0%E5%8A%A0%E5%85%A5yolo.py%E4%B8%AD%EF%BC%9A-toc" style="margin-left:40px;"><a href="#2.2%C2%A0%E5%8A%A0%E5%85%A5yolo.py%E4%B8%AD%EF%BC%9A" rel="nofollow">2.2 加入yolo.py中：</a></p> 
<p id="2.3%C2%A0yolov5s_DSConv2D_C3.yaml-toc" style="margin-left:40px;"><a href="#2.3%C2%A0yolov5s_DSConv2D_C3.yaml" rel="nofollow">2.3 yolov5s_DSConv2D_C3.yaml</a></p> 
<hr id="hr-toc"> 
<h3>🏆 🏆🏆🏆🏆🏆🏆Yolov5/Yolov7成长师🏆🏆🏆🏆🏆🏆🏆</h3> 
<h3>🍉🍉进阶专栏Yolov5/Yolov7魔术师：<a href="http://t.csdn.cn/D4NqB" rel="nofollow" title="http://t.csdn.cn/D4NqB ">http://t.csdn.cn/D4NqB </a>🍉🍉<br> ✨✨✨魔改网络、复现前沿论文，组合优化创新<br> 🚀🚀🚀小目标、遮挡物、难样本性能提升<br> 🌰 🌰 🌰在不同数据集验证能够涨点，对小目标涨点明显</h3> 
<h2 id="1.%20DSConv%E4%BB%8B%E7%BB%8D">1. DSConv介绍</h2> 
<p><img alt="" height="207" src="https://images2.imgbox.com/a8/78/alCbl6c9_o.png" width="794"></p> 
<p>论文： <a href="https://arxiv.org/pdf/1901.01928v1.pdf" rel="nofollow" title="https://arxiv.org/pdf/1901.01928v1.pdf">https://arxiv.org/pdf/1901.01928v1.pdf</a></p> 
<p>摘要：提出了一种卷积的变体，称为DSConv（分布偏移卷积），其可以容易地替换进标准神经网络体系结构并且实现较低的存储器使用和较高的计算速度。 DSConv将传统的卷积内核分解为两个组件：可变量化内核（VQK）和分布偏移。 通过在VQK中仅存储整数值来实现较低的存储器使用和较高的速度，同时通过应用基于内核和基于通道的分布偏移来保持与原始卷积相同的输出。 我们在ResNet50和34以及AlexNet和MobileNet上对ImageNet数据集测试了DSConv。 我们通过将浮点运算替换为整数运算，在卷积内核中实现了高达14x的内存使用量减少，并将运算速度提高了10倍。 此外，与其他量化方法不同，我们的工作允许对新任务和数据集进行一定程度的再训练。 </p> 
<p>DSConv 的总体目标是通过使用量化和分布偏移来模拟卷积层的行为。</p> 
<p>DSConv 的设置如上图所示。为了方便和表示，让原始卷积张量的大小为 (cho, chi, k, k)，其中 cho 是下一层的通道数，chi 是当前层中的通道，k是内核的宽度和高度。</p> 
<p class="img-center"><img alt="" height="379" src="https://images2.imgbox.com/17/54/Rmu8DEcl_o.png" width="444"></p> 
<p>        DSConv是一种深度可分离卷积（Depthwise Separable Convolution）的变体，它在计算机视觉领域被广泛使用。深度可分离卷积是一种轻量级卷积，它将标准卷积拆分为两个步骤：深度卷积和逐点卷积。深度卷积只在单个通道上进行卷积，并在每个通道上应用一个独立的卷积核。逐点卷积在所有通道上应用一个卷积核，以组合深度卷积的结果。DSConv相比于深度可分离卷积的优势在于它使用了一个可学习的卷积核来进一步提高模型的表现。</p> 
<p> 结果对比：</p> 
<p class="img-center"><img alt="" height="141" src="https://images2.imgbox.com/1a/cb/Es3u7lVB_o.png" width="500"></p> 
<p class="img-center"><img alt="" height="161" src="https://images2.imgbox.com/6a/39/WhQAZI3G_o.png" width="421"></p> 
<p>实验目标：在 Resnet34 和 Resnet50 中应用的 DSConv 与其他网络</p> 
<p>实验结果：效果有明显提高</p> 
<p><img alt="" height="362" src="https://images2.imgbox.com/91/74/tIDE3EEZ_o.png" width="889"></p> 
<p><img alt="" height="225" src="https://images2.imgbox.com/8a/8a/7sNeFM0a_o.png" width="839"></p> 
<h2 id="%C2%A02.DSConv%E5%BC%95%E5%85%A5Yolov5"> 2.DSConv引入Yolov5</h2> 
<h3 id="2.1%E4%BF%AE%E6%94%B9common.py%E4%B8%AD%EF%BC%9A">2.1修改<strong><code>common.py</code></strong>中：</h3> 
<pre><code>###################### DSConv  ####     start   by  AI&amp;CV  ###############################

import torch.nn.functional as F
from torch.nn.modules.conv import _ConvNd
from torch.nn.modules.utils import _pair

class DSConv(_ConvNd):  #https://arxiv.org/pdf/1901.01928v1.pdf
    def __init__(self, in_channels, out_channels, kernel_size, stride=1,
                 padding=None, dilation=1, groups=1, padding_mode='zeros', bias=False, block_size=32, KDSBias=False, CDS=False):
        padding = _pair(autopad(kernel_size, padding, dilation))
        kernel_size = _pair(kernel_size)
        stride = _pair(stride)
        dilation = _pair(dilation)

        blck_numb = math.ceil(((in_channels)/(block_size*groups)))
        super(DSConv, self).__init__(
            in_channels, out_channels, kernel_size, stride, padding, dilation,
            False, _pair(0), groups, bias, padding_mode)

        # KDS weight From Paper
        self.intweight = torch.Tensor(out_channels, in_channels, *kernel_size)
        self.alpha = torch.Tensor(out_channels, blck_numb, *kernel_size)

        # KDS bias From Paper
        self.KDSBias = KDSBias
        self.CDS = CDS

        if KDSBias:
            self.KDSb = torch.Tensor(out_channels, blck_numb, *kernel_size)
        if CDS:
            self.CDSw = torch.Tensor(out_channels)
            self.CDSb = torch.Tensor(out_channels)

        self.reset_parameters()

    def get_weight_res(self):
        # Include expansion of alpha and multiplication with weights to include in the convolution layer here
        alpha_res = torch.zeros(self.weight.shape).to(self.alpha.device)

        # Include KDSBias
        if self.KDSBias:
            KDSBias_res = torch.zeros(self.weight.shape).to(self.alpha.device)

        # Handy definitions:
        nmb_blocks = self.alpha.shape[1]
        total_depth = self.weight.shape[1]
        bs = total_depth//nmb_blocks

        llb = total_depth-(nmb_blocks-1)*bs

        # Casting the Alpha values as same tensor shape as weight
        for i in range(nmb_blocks):
            length_blk = llb if i==nmb_blocks-1 else bs

            shp = self.alpha.shape # Notice this is the same shape for the bias as well
            to_repeat=self.alpha[:, i, ...].view(shp[0],1,shp[2],shp[3]).clone()
            repeated = to_repeat.expand(shp[0], length_blk, shp[2], shp[3]).clone()
            alpha_res[:, i*bs:(i*bs+length_blk), ...] = repeated.clone()

            if self.KDSBias:
                to_repeat = self.KDSb[:, i, ...].view(shp[0], 1, shp[2], shp[3]).clone()
                repeated = to_repeat.expand(shp[0], length_blk, shp[2], shp[3]).clone()
                KDSBias_res[:, i*bs:(i*bs+length_blk), ...] = repeated.clone()

        if self.CDS:
            to_repeat = self.CDSw.view(-1, 1, 1, 1)
            repeated = to_repeat.expand_as(self.weight)
            print(repeated.shape)

        # Element-wise multiplication of alpha and weight
        weight_res = torch.mul(alpha_res, self.weight)
        if self.KDSBias:
            weight_res = torch.add(weight_res, KDSBias_res)
        return weight_res

    def forward(self, input):
        # Get resulting weight
        #weight_res = self.get_weight_res()

        # Returning convolution
        return F.conv2d(input, self.weight, self.bias,
                            self.stride, self.padding, self.dilation,
                            self.groups)

class DSConv2D(Conv):
    def __init__(self, inc, ouc, k=1, s=1, p=None, g=1, d=1, act=True):
        super().__init__(inc, ouc, k, s, p, g, d, act)
        self.conv = DSConv(inc, ouc, k, s, p, g, d)

class Bottleneck_DSConv2D(nn.Module):
    # Standard bottleneck
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = DSConv2D(c1, c_, 1, 1)
        self.cv2 = DSConv2D(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))

class DSConv2D_C3(C3):
    # C3 module with dsconv
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = nn.Sequential(*(Bottleneck_DSConv2D(c_, c_, shortcut, g, e=1.0) for _ in range(n)))

###################### DSConv  ####     END   by  AI&amp;CV  ###############################
</code></pre> 
<h3 id="2.2%C2%A0%E5%8A%A0%E5%85%A5yolo.py%E4%B8%AD%EF%BC%9A">2.2 加入<strong><code>yolo.py</code></strong>中：</h3> 
<pre><code>if m in {
                Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF,DWConv, MixConv2d, Focus, CrossConv,
                BottleneckCSP, C3, C3TR, C3SPP, C3Ghost, CNeB, nn.ConvTranspose2d, DWConvTranspose2d, C3x, C2f,CARAFE, DSConv2D_C3}</code></pre> 
<h3 id="2.3%C2%A0yolov5s_DSConv2D_C3.yaml">2.3 yolov5s_DSConv2D_C3.yaml</h3> 
<pre><code># YOLOv5 🚀 by Ultralytics, GPL-3.0 license

# Parameters
nc: 6  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32

# YOLOv5 v6.0 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2
   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4
   [-1, 3, C3, [128]],
   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8
   [-1, 6, C3, [256]],
   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16
   [-1, 9, C3, [512]],
   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32
   [-1, 3, C3, [1024]],
   [-1, 1, SPPF, [1024, 5]],  # 9
  ]

# YOLOv5 v6.0 head
head:
  [[-1, 1, Conv, [512, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 6], 1, Concat, [1]],  # cat backbone P4
   [-1, 3, DSConv2D_C3, [512, False]],  # 13

   [-1, 1, Conv, [256, 1, 1]],
   [-1, 1, nn.Upsample, [None, 2, 'nearest']],
   [[-1, 4], 1, Concat, [1]],  # cat backbone P3
   [-1, 3, DSConv2D_C3, [256, False]],  # 17 (P3/8-small)

   [-1, 1, Conv, [256, 3, 2]],
   [[-1, 14], 1, Concat, [1]],  # cat head P4
   [-1, 3, DSConv2D_C3, [512, False]],  # 20 (P4/16-medium)

   [-1, 1, Conv, [512, 3, 2]],
   [[-1, 10], 1, Concat, [1]],  # cat head P5
   [-1, 3, DSConv2D_C3, [1024, False]],  # 23 (P5/32-large)

   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
  ]
</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0d6a5b79947d003476681e99a8ba9546/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">opencv学习笔记——3.0</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4a8a34d1ad1b9ead12ebf2dcb96413da/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">vue项目引入外部图标</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>