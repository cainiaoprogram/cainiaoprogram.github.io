<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于android手机实时监控ipcam视频之二：mediastream2 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于android手机实时监控ipcam视频之二：mediastream2" />
<meta property="og:description" content="在项目中用到了mediastream2，mediastream2是一个框架，引擎，它驱动系统的整个流程，从接收rtp媒体流并解析到媒体解码到显示到android手机屏幕上，都是由mediastream2来驱动完成的。
mediastream2是由一个个filter来完成，我们可以把filter当做一个单独的数据处理模块，它就像一个盒子，有输入和输出接口，数据从输入接口进来，处理完成后，再从输出接口出来进入到下一个filter中，多个filter连接在一起，就组成了一个系统循环。在我们的系统中，主要流程是ipcam发送rtp媒体流，系统接收rtp媒体流并解析，然后进行解码，再显示到android手机屏幕上，因此我们定义了三个filter，分别是：RTP Recv filter(RTP媒体流接收)，Video Decoder filter（视频解码）和Android Display filter（视频输出显示），其基本流程如下：
RTP Recv-----------------&gt;Video Decoder------------------------------&gt; Android Display
首先我们要调用ms_init()这个函数，这个函数初始化mediastream2。
void ms_init(){
int i;
MSSndCardManager *cm;
#if defined(ENABLE_NLS)
bindtextdomain (GETTEXT_PACKAGE, LOCALEDIR);
#endif
#if !defined(_WIN32_WCE)
if (getenv(&#34;MEDIASTREAMER_DEBUG&#34;)!=NULL){
ortp_set_log_level_mask(ORTP_DEBUG|ORTP_MESSAGE|ORTP_WARNING|ORTP_ERROR|ORTP_FATAL);
}
#endif
#ifdef ANDROID
ortp_set_log_level_mask(ORTP_MESSAGE|ORTP_WARNING|ORTP_ERROR|ORTP_FATAL);
ortp_set_log_handler(ms_android_log_handler);
#endif
ms_message(&#34;Mediastreamer2 &#34; MEDIASTREAMER_VERSION &#34; (git: &#34; GIT_VERSION &#34;) starting.&#34;);
/* register builtin MSFilter&#39;s */
for (i=0;ms_filter_descs[i]!=NULL;i&#43;&#43;){
ms_filter_register(ms_filter_descs[i]);
}
ms_message(&#34;Registering all soundcard handlers&#34;);
cm=ms_snd_card_manager_get();
for (i=0;ms_snd_card_descs[i]!=NULL;i&#43;&#43;){
ms_snd_card_manager_register_desc(cm,ms_snd_card_descs[i]);
}
#ifdef VIDEO_ENABLED
ms_message(&#34;Registering all webcam handlers&#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/01917f56fec4f77bc55fabbff0907ff2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2014-10-28T16:12:34+08:00" />
<meta property="article:modified_time" content="2014-10-28T16:12:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于android手机实时监控ipcam视频之二：mediastream2</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>   <span style="font-size:18px"> 在项目中用到了mediastream2，mediastream2是一个框架，引擎，它驱动系统的整个流程，从接收rtp媒体流并解析到媒体解码到显示到android手机屏幕上，都是由mediastream2来驱动完成的。</span></p> 
<p><span style="font-size:18px">    mediastream2是由一个个filter来完成，我们可以把filter当做一个单独的数据处理模块，它就像一个盒子，有输入和输出接口，数据从输入接口进来，处理完成后，再从输出接口出来进入到下一个filter中，多个filter连接在一起，就组成了一个系统循环。在我们的系统中，主要流程是ipcam发送rtp媒体流，系统接收rtp媒体流并解析，然后进行解码，再显示到android手机屏幕上，因此我们定义了三个filter，分别是：RTP Recv filter(RTP媒体流接收)，Video Decoder filter（视频解码）和Android Display filter（视频输出显示），其基本流程如下：</span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">                           RTP Recv-----------------&gt;Video Decoder------------------------------&gt; Android Display</span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">    首先我们要调用ms_init()这个函数，这个函数初始化mediastream2。</span></p> 
<p><span style="font-size:18px">    void ms_init(){<!-- --><br> <span style="white-space:pre"></span>int i;<br> <span style="white-space:pre"></span>MSSndCardManager *cm;<br> <br> <br> #if defined(ENABLE_NLS)<br> <span style="white-space:pre"></span>bindtextdomain (GETTEXT_PACKAGE, LOCALEDIR);<br> #endif<br> <br> <br> #if !defined(_WIN32_WCE)<br> <span style="white-space:pre"></span>if (getenv("MEDIASTREAMER_DEBUG")!=NULL){<!-- --><br> <span style="white-space:pre"></span>ortp_set_log_level_mask(ORTP_DEBUG|ORTP_MESSAGE|ORTP_WARNING|ORTP_ERROR|ORTP_FATAL);<br> <span style="white-space:pre"></span>}<br> #endif<br> #ifdef ANDROID<br> <span style="white-space:pre"></span>ortp_set_log_level_mask(ORTP_MESSAGE|ORTP_WARNING|ORTP_ERROR|ORTP_FATAL);<br> <span style="white-space:pre"></span>ortp_set_log_handler(ms_android_log_handler);<br> #endif<br> <span style="white-space:pre"></span>ms_message("Mediastreamer2 " MEDIASTREAMER_VERSION " (git: " GIT_VERSION ") starting.");<br> <span style="white-space:pre"></span>/* register builtin MSFilter's */<br> <span style="white-space:pre"></span>for (i=0;ms_filter_descs[i]!=NULL;i++){<!-- --><br> <span style="white-space:pre"></span>ms_filter_register(ms_filter_descs[i]);<br> <span style="white-space:pre"></span>}<br> <span style="white-space:pre"></span>ms_message("Registering all soundcard handlers");<br> <span style="white-space:pre"></span>cm=ms_snd_card_manager_get();<br> <span style="white-space:pre"></span>for (i=0;ms_snd_card_descs[i]!=NULL;i++){<!-- --><br> <span style="white-space:pre"></span>ms_snd_card_manager_register_desc(cm,ms_snd_card_descs[i]);<br> <span style="white-space:pre"></span>}<br> <br> <br> #ifdef VIDEO_ENABLED<br> <span style="white-space:pre"></span>ms_message("Registering all webcam handlers");<br> <span style="white-space:pre"></span>{<!-- --><br> <span style="white-space:pre"></span>MSWebCamManager *wm;<br> <span style="white-space:pre"></span>wm=ms_web_cam_manager_get();<br> <span style="white-space:pre"></span>for (i=0;ms_web_cam_descs[i]!=NULL;i++){<!-- --><br> <span style="white-space:pre"></span>ms_web_cam_manager_register_desc(wm,ms_web_cam_descs[i]);<br> <span style="white-space:pre"></span>}<br> <span style="white-space:pre"></span>}<br> #if !defined(NO_FFMPEG)<br> <span style="white-space:pre"></span>ms_ffmpeg_check_init();<br> <span style="white-space:pre"></span>__register_ffmpeg_encoders_if_possible();<br> #endif<br> #endif<br> #ifdef PACKAGE_PLUGINS_DIR<br> <span style="white-space:pre"></span>ms_message("Loading plugins");<br> <span style="white-space:pre"></span>ms_load_plugins(PACKAGE_PLUGINS_DIR);<br> #endif<br> <br> <br> #if defined(ANDROID) &amp;&amp; defined (VIDEO_ENABLED)<br> <span style="white-space:pre"></span>if (1) {<!-- --><br> <span style="white-space:pre"></span>libmsandroidopengldisplay_init();<br> <span style="white-space:pre"></span>} else {<!-- --><br> <span style="white-space:pre"></span>if (!libmsandroiddisplay_init()) {<!-- --><br> <span style="white-space:pre"></span>libmsandroiddisplaybad_init();<br> <span style="white-space:pre"></span>}<br> <span style="white-space:pre"></span>}<br> #endif<br> <span style="white-space:pre"></span>ms_message("ms_init() done");<br> }</span></p> 
<p><span style="font-size:18px">    在这个函数里面，ms_filter_descs定义了目前支持的所有的filter，进一步分析</span></p> 
<p><span style="font-size:18px">MSFilterDesc * ms_filter_descs[]={<!-- --><br> &amp;ms_alaw_dec_desc,<br> &amp;ms_alaw_enc_desc,<br> &amp;ms_ulaw_dec_desc,<br> &amp;ms_ulaw_enc_desc,<br> &amp;ms_rtp_send_desc,<br> &amp;ms_rtp_recv_desc,<br> &amp;ms_dtmf_gen_desc,<br> &amp;ms_ice_desc,<br> &amp;ms_tee_desc,<br> &amp;ms_conf_desc,<br> &amp;ms_join_desc,<br> &amp;ms_volume_desc,<br> &amp;ms_void_sink_desc,<br> //&amp;ms_speex_dec_desc,<br> //&amp;ms_speex_enc_desc,<br> //&amp;ms_speex_ec_desc,<br> &amp;ms_file_player_desc,<br> &amp;ms_file_rec_desc,<br> //&amp;ms_resample_desc,<br> &amp;ms_equalizer_desc,<br> //&amp;ms_gsm_enc_desc,<br> //&amp;ms_gsm_dec_desc,<br> &amp;ms_tone_detector_desc,<br> &amp;ms_audio_mixer_desc,<br> &amp;ms_g722_dec_desc,<br> &amp;ms_g722_enc_desc,<br> #ifdef VIDEO_ENABLED<br> &amp;ms_mpeg4_enc_desc,<br> &amp;ms_mpeg4_dec_desc,<br> &amp;ms_h263_enc_desc,<br> &amp;ms_h263_dec_desc,<br> &amp;ms_h264_dec_desc,<br> &amp;ms_pix_conv_desc,<br> &amp;ms_size_conv_desc,<br> //&amp;ms_vp8_enc_desc,<br> //&amp;ms_vp8_dec_desc,<br> #endif<br> NULL<br> };<br> </span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">我们可以看到系统定义了很多filter，比如ms_rtp_recv_desc是RTP接收filter，ms_h264_dec_desc是H.264解码filter等等。</span></p> 
<p><span style="font-size:18px">MSFilterDesc ms_h264_dec_desc={<!-- --><br> <span style="white-space:pre"></span>.id=MS_H264_DEC_ID,<br> <span style="white-space:pre"></span>.name="MSH264Dec",<br> <span style="white-space:pre"></span>.text="A H264 decoder based on ffmpeg project.",<br> <span style="white-space:pre"></span>.category=MS_FILTER_DECODER,<br> <span style="white-space:pre"></span>.enc_fmt="H264",<br> <span style="white-space:pre"></span>.ninputs=1,<br> <span style="white-space:pre"></span>.noutputs=1,<br> <span style="white-space:pre"></span>.init=dec_init,<br> <span style="white-space:pre"></span>.process=dec_process,<br> <span style="white-space:pre"></span>.uninit=dec_uninit,<br> <span style="white-space:pre"></span>.methods=h264_dec_methods<br> };<br> </span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">在filter定义里面，id是用来标示每个filter的唯一标示符；name是起得一个名称；text是描述，上面就表示该filter是基于ffmpeg的H.264解码；category是分类，有解码器，编码器和其它三种类型；enc_fmt表示媒体类型；ninputs表示input个数，可能每个filter有多个输入接口；noutputs表示输出接口；init定义初始化函数，在调用filter之前必须 调用；process是最核心的处理函数，filter从input端接收数据就调用该函数进行数据处理；uninit定义退出函数；methods表示额外定义的一些函数，使用这个接口可以对filter进行一些参数设置工作，比如在上面的h.264解码filter中定义了专门的函数用来设置h.264解码所需要的fmtp信息。除了mediastream2自带的这些filter以外，我们还可以自己定义filter，按照上面的格式来定义，然后通过ms_filter_register函数注册进来就可以使用了。在我们系统中我们使用ms_rtp_recv_desc来完成rtp的接收解析，使用ms_h264_dec_desc来完成视频解码，使用ms_android_opengl_display_desc来完成在android上的显示。</span></p> 
<p><span style="font-size:18px">定义完成了3个filter，接收流，解码并显示，这三个filter是如何创建并连接在一起并工作起来呢？见下面的代码注释</span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">MSConnectionHelper ch;<br>     /*根据ipcam video的codec来创建相应的解码器filter，创建失败，则退出，在我们系统里面一般是h.264，但我们可以根据rtp媒体类型在自适应选择对应的解码filter*/<br>     stream-&gt;decoder=ms_filter_create_decoder(ipcam_get_codec("video")); // 创建解码filter<br>     if (stream-&gt;decoder==NULL)<br>     {<!-- --><br>         /* big problem: we don't have a registered decoderfor this payload...*/<br>         ms_error("videostream.c: No decoder available  ");<br>         return -1;<br>     }<br> <br> <br>     /*创建rtp接受filter*/<br>     stream-&gt;rtprecv = ms_filter_new (MS_RTP_RECV_ID);//创建RTP接收filter，通过MS_RTP_RECV_ID找到ms_rtp_recv_desc这个filter</span></p> 
<p><span style="font-size:18px">   /*创建rtp接收filter，需要设置rtp接收filter的会话，会话主要是接收媒体流的socket，告诉filter再哪个socket上接收rtp数据，并限制接收什么样的rtp数据，通过payload type*/</span></p> 
<p><span style="font-size:18px">/*stream-&gt;session这个是_RtpSession*， 是mediastream2定义的结构体*/<br>     ms_filter_call_method(stream-&gt;rtprecv,MS_RTP_RECV_SET_SESSION,stream-&gt;session);<br>     ms_message("ssap_ipcam_client_open:session rtpsocket=%d,rtcpsocket=%d",stream-&gt;session-&gt;rtp.socket,stream-&gt;session-&gt;rtcp.socket);<br> <br> <br>     /*创建output filter，默认是MSAndroidDisplay，表示输出到android上，通过MSAndroidDisplay找到ms_android_opengl_display_desc*/<br>     displayName = ms_strdup("MSAndroidDisplay");<br>     stream-&gt;output=ms_filter_new_from_name(displayName);<br> <br> <br>     /*以下是设置fmtp，非常重要，如果不添加fmtp，将会解码失败，mpeg4需要的fmtp在rtsp中是在sdp中<br>     带过来的，因此要获取fmtp*/<br>     char fmtp[1000];<br>     memset(fmtp,0,sizeof(fmtp));<br>     sprintf(fmtp,"config=%s",ipcam_get_fmtp("video"));<br>     ms_message("ipcam fmtp=%s",fmtp);<br>     ms_filter_call_method(stream-&gt;decoder,MS_FILTER_ADD_FMTP,(void*)fmtp);<br>     format=MS_YUV420P;<br>     ms_filter_call_method(stream-&gt;decoder,MS_FILTER_SET_PIX_FMT,&amp;format);</span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">    int tmp;<br>     /*configure the display window */<br>     disp_size.width=MS_VIDEO_SIZE_CIF_W;<br>     disp_size.height=MS_VIDEO_SIZE_CIF_H;<br>     tmp=1;</span></p> 
<p><span style="font-size:18px">/*设置一些参数，主要用来显示*/<br>     ms_filter_call_method(stream-&gt;output,MS_FILTER_SET_VIDEO_SIZE,&amp;disp_size);<br>     ms_filter_call_method(stream-&gt;output,MS_VIDEO_DISPLAY_ENABLE_AUTOFIT,&amp;tmp);<br>     ms_filter_call_method(stream-&gt;output,MS_FILTER_SET_PIX_FMT,&amp;format);<br>     //ms_filter_call_method(stream-&gt;output,MS_VIDEO_DISPLAY_SET_LOCAL_VIEW_MODE,&amp;stream-&gt;corner);<br> <br> <br>     if (stream-&gt;window_id != 0) <br>     {<!-- --><br>         ms_message("v2 sam display windows id=%d,stream=%p",stream-&gt;window_id,stream);<br>         /*设置显示的窗口id，在哪个窗口上显示video*/<br>         ms_filter_call_method(stream-&gt;output, MS_VIDEO_DISPLAY_SET_NATIVE_WINDOW_ID,stream-&gt;window_id);<br>     }<br> <br> <br>  /*以上完成了3个filter的创建，接下来将3个filter串联起来*/<br>     /* and connect the filters */<br>     ms_connection_helper_start (&amp;ch);<br>     ms_connection_helper_link (&amp;ch,stream-&gt;rtprecv,-1,0);<br>     ms_connection_helper_link (&amp;ch,stream-&gt;decoder,0,0);<br> <br> <br>     ms_connection_helper_link (&amp;ch,stream-&gt;output,0,-1);<br> <br> <br>   /*filter串联起来了以后，开始启动定时器，整个系统流程开始运转起来*/<br>     /* create the ticker */<br>     stream-&gt;ticker = ms_ticker_new();<br>     ms_ticker_set_name(stream-&gt;ticker,"Video MSTicker");<br>     /* attach the graphs */<br>     if (stream-&gt;source)<br>         ms_ticker_attach (stream-&gt;ticker, stream-&gt;source);<br>     if (stream-&gt;rtprecv)<br>         ms_ticker_attach (stream-&gt;ticker, stream-&gt;rtprecv);<br> </span></p> 
<p><span style="font-size:18px"><br> </span></p> 
<p><span style="font-size:18px">至此，mediastream2就开始运转起来了</span></p> 
<p><span style="font-size:18px">             </span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/07634c41f937ff79d31225a30dd53e25/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">数组指针（*p）[n]的用法与理解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/04e7a3926a99312123c45f46798469e3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">强大的分布式消息中间件——kafka</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>