<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>新手入门python实现神经网络，超级简单! - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="新手入门python实现神经网络，超级简单!" />
<meta property="og:description" content="前言：
这篇文章完全是为新手准备的。我们会通过用Python从头实现一个神经网络来理解神经网络的原理。
文章目录 神经元1、一个简单的例子2、编码一个神经元 把神经元组装成网络1、例子：前馈2、编码神经网络：前馈 训练神经网络 第一部分1、损失2、损失计算例子3、代码：MSE损失 训练神经网络 第二部分1、例子：计算偏导数2、训练：随机梯度下降 代码：一个完整的神经网络 神经元 首先让我们看看神经网络的基本单位，神经元。神经元接受输入，对其做一些数据操作，然后产生输出。例如，这是一个2-输入神经元：
这里发生了三个事情。首先，每个输入都跟一个权重相乘（红色）：
然后，加权后的输入求和，加上一个偏差b（绿色）：
最后，这个结果传递给一个激活函数f：
激活函数的用途是将一个无边界的输入，转变成一个可预测的形式。常用的激活函数就是S型函数：
S型函数的值域是(0, 1)。简单来说，就是把(−∞, &#43;∞)压缩到(0, 1) ，很大的负数约等于0，很大的正数约等于1。
1、一个简单的例子 2、编码一个神经元 让我们来实现一个神经元！用Python的NumPy库来完成其中的数学计算：
import numpy as np def sigmoid(x): # 我们的激活函数: f(x) = 1 / (1 &#43; e^(-x)) return 1 / (1 &#43; np.exp(-x)) class Neuron: def __init__(self, weights, bias): self.weights = weights self.bias = bias def feedforward(self, inputs): # 加权输入，加入偏置，然后使用激活函数 total = np.dot(self.weights, inputs) &#43; self.bias return sigmoid(total) weights = np." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/189905948f4e22aa2958f86fec4350d0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-25T19:33:53+08:00" />
<meta property="article:modified_time" content="2023-06-25T19:33:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">新手入门python实现神经网络，超级简单!</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>前言：</p> 
<blockquote> 
 <p>这篇文章完全是为新手准备的。我们会通过用Python从头实现一个神经网络来理解神经网络的原理。</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_8" rel="nofollow">神经元</a></li><li><ul><li><a href="#1_21" rel="nofollow">1、一个简单的例子</a></li><li><a href="#2_23" rel="nofollow">2、编码一个神经元</a></li></ul> 
  </li><li><a href="#_51" rel="nofollow">把神经元组装成网络</a></li><li><ul><li><a href="#1_56" rel="nofollow">1、例子：前馈</a></li><li><a href="#2_59" rel="nofollow">2、编码神经网络：前馈</a></li></ul> 
  </li><li><a href="#__111" rel="nofollow">训练神经网络 第一部分</a></li><li><ul><li><a href="#1_119" rel="nofollow">1、损失</a></li><li><a href="#2_128" rel="nofollow">2、损失计算例子</a></li><li><a href="#3MSE_132" rel="nofollow">3、代码：MSE损失</a></li></ul> 
  </li><li><a href="#__150" rel="nofollow">训练神经网络 第二部分</a></li><li><ul><li><a href="#1_160" rel="nofollow">1、例子：计算偏导数</a></li><li><a href="#2_164" rel="nofollow">2、训练：随机梯度下降</a></li></ul> 
  </li><li><a href="#_169" rel="nofollow">代码：一个完整的神经网络</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_8"></a>神经元</h2> 
<p>首先让我们看看神经网络的基本单位，神经元。神经元接受输入，对其做一些数据操作，然后产生输出。例如，这是一个2-输入神经元：<br> <img src="https://images2.imgbox.com/3f/18/S7TCxr2n_o.png" alt="在这里插入图片描述"><br> 这里发生了三个事情。首先，每个输入都跟一个权重相乘（红色）：<br> <img src="https://images2.imgbox.com/4a/a4/D9AqR0u8_o.png" alt="在这里插入图片描述">然后，加权后的输入求和，加上一个偏差b（绿色）：<br> <img src="https://images2.imgbox.com/74/66/rFDWTVuv_o.png" alt="在这里插入图片描述"><br> 最后，这个结果传递给一个激活函数f：<br> <img src="https://images2.imgbox.com/09/67/yp86lX2u_o.png" alt="在这里插入图片描述"><br> 激活函数的用途是将一个无边界的输入，转变成一个可预测的形式。常用的激活函数就是S型函数：</p> 
<p><img src="https://images2.imgbox.com/55/1d/gSJoySAq_o.png" alt="在这里插入图片描述"><br> S型函数的值域是(0, 1)。简单来说，就是把(−∞, +∞)压缩到(0, 1) ，很大的负数约等于0，很大的正数约等于1。</p> 
<h3><a id="1_21"></a>1、一个简单的例子</h3> 
<p><img src="https://images2.imgbox.com/7b/c2/mk6btwGG_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_23"></a>2、编码一个神经元</h3> 
<p>让我们来实现一个神经元！用Python的NumPy库来完成其中的数学计算：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># 我们的激活函数: f(x) = 1 / (1 + e^(-x))</span>
  <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">Neuron</span><span class="token punctuation">:</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> weights<span class="token punctuation">,</span> bias<span class="token punctuation">)</span><span class="token punctuation">:</span>
    self<span class="token punctuation">.</span>weights <span class="token operator">=</span> weights
    self<span class="token punctuation">.</span>bias <span class="token operator">=</span> bias

  <span class="token keyword">def</span> <span class="token function">feedforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 加权输入，加入偏置，然后使用激活函数</span>
    total <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias
    <span class="token keyword">return</span> sigmoid<span class="token punctuation">(</span>total<span class="token punctuation">)</span>

weights <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># w1 = 0, w2 = 1</span>
bias <span class="token operator">=</span> <span class="token number">4</span>                   <span class="token comment"># b = 4</span>
n <span class="token operator">=</span> Neuron<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> bias<span class="token punctuation">)</span>

x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>       <span class="token comment"># x1 = 2, x2 = 3</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>n<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token comment"># 0.9990889488055994</span>
</code></pre> 
<p>还记得这个数字吗？就是我们前面算出来的例子中的0.999。</p> 
<h2><a id="_51"></a>把神经元组装成网络</h2> 
<p>所谓的神经网络就是一堆神经元。这就是一个简单的神经网络：<br> <img src="https://images2.imgbox.com/4f/79/83MwLEc2_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>隐藏层就是输入层和输出层之间的层，隐藏层可以是多层的。</p> 
</blockquote> 
<h3><a id="1_56"></a>1、例子：前馈</h3> 
<p><img src="https://images2.imgbox.com/c9/ff/sT9codxO_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_59"></a>2、编码神经网络：前馈</h3> 
<p>接下来我们实现这个神经网络的前馈机制，还是这个图：<br> <img src="https://images2.imgbox.com/65/b3/wyAEvyfz_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token comment"># 我们的激活函数：f(x)=1/(1+e^(-x))</span>
    <span class="token keyword">return</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 单个神经元</span>
<span class="token keyword">class</span> <span class="token class-name">Neuron</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>weights<span class="token punctuation">,</span>bias<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>weights<span class="token operator">=</span>weights
        self<span class="token punctuation">.</span>bias<span class="token operator">=</span>bias
    <span class="token keyword">def</span> <span class="token function">feedforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        total<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>self<span class="token punctuation">.</span>weights<span class="token punctuation">,</span>inputs<span class="token punctuation">)</span><span class="token operator">+</span>self<span class="token punctuation">.</span>bias
        <span class="token keyword">return</span> sigmoid<span class="token punctuation">(</span>total<span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">OurNeuralNetwork</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">'''
  A neural network with:
    - 2 inputs
    - a hidden layer with 2 neurons (h1, h2)
    - an output layer with 1 neuron (o1)
  Each neuron has the same weights and bias:
    - w = [0, 1]
    - b = 0
  '''</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    weights <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    bias <span class="token operator">=</span> <span class="token number">0</span>

    <span class="token comment"># 这里是来自前一节的神经元类</span>
    self<span class="token punctuation">.</span>h1 <span class="token operator">=</span> Neuron<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> bias<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>h2 <span class="token operator">=</span> Neuron<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> bias<span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>o1 <span class="token operator">=</span> Neuron<span class="token punctuation">(</span>weights<span class="token punctuation">,</span> bias<span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">feedforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    out_h1 <span class="token operator">=</span> self<span class="token punctuation">.</span>h1<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    out_h2 <span class="token operator">=</span> self<span class="token punctuation">.</span>h2<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

    <span class="token comment"># o1的输入是h1和h2的输出</span>
    out_o1 <span class="token operator">=</span> self<span class="token punctuation">.</span>o1<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>out_h1<span class="token punctuation">,</span> out_h2<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> out_o1

network <span class="token operator">=</span> OurNeuralNetwork<span class="token punctuation">(</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>network<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 0.7216325609518421</span>
</code></pre> 
<p>结果正确，看上去没问题。</p> 
<h2><a id="__111"></a>训练神经网络 第一部分</h2> 
<p>现在有这样的数据：<br> <img src="https://images2.imgbox.com/79/5e/QzJ2bMpD_o.png" alt="在这里插入图片描述"><br> 接下来我们用这个数据来训练神经网络的权重和截距项，从而可以根据身高体重预测性别：<br> <img src="https://images2.imgbox.com/c2/24/6ZoA6zjH_o.png" alt="在这里插入图片描述"><br> 我们用0和1分别表示男性（M）和女性（F），并对数值做了转化：<br> <img src="https://images2.imgbox.com/e1/48/Y4tFqLF6_o.png" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>我这里是随意选取了135和66来标准化数据，通常会使用平均值。</p> 
</blockquote> 
<h3><a id="1_119"></a>1、损失</h3> 
<p>在训练网络之前，我们需要量化当前的网络是『好』还是『坏』，从而可以寻找更好的网络。这就是定义损失的目的。<br> 我们在这里用平均方差（MSE）损失： ，让我们仔细看看：<br> <img src="https://images2.imgbox.com/7e/cc/w2fqs7N7_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a2/e4/RBsICFCL_o.png" alt="在这里插入图片描述"><br> 被称为方差（squared error）。我们的损失函数就是所有方差的平均值。预测效果越好，损失就越少。<br> 更好的预测 = 更少的损失！</p> 
<p>训练网络 = 最小化它的损失。</p> 
<h3><a id="2_128"></a>2、损失计算例子</h3> 
<p>假设我们的网络总是输出0，换言之就是认为所有人都是男性。损失如何？<br> <img src="https://images2.imgbox.com/2a/6b/1C8sKuna_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3MSE_132"></a>3、代码：MSE损失</h3> 
<p>下面是计算MSE损失的代码：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">mse_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># y_true and y_pred are numpy arrays of the same length.</span>
  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>y_true <span class="token operator">-</span> y_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

y_true <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
y_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>mse_loss<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 0.5</span>
</code></pre> 
<blockquote> 
 <p>如果你不理解这段代码，可以看看NumPy的快速入门中关于数组的操作。</p> 
</blockquote> 
<p>好的，继续。</p> 
<h2><a id="__150"></a>训练神经网络 第二部分</h2> 
<p>现在我们有了一个明确的目标：最小化神经网络的损失。通过调整网络的权重和截距项，我们可以改变其预测结果，但如何才能逐步地减少损失？<br> 为了简化问题，假设我们的数据集中只有Alice：假设我们的网络总是输出0，换言之就是认为所有人都是男性。损失如何？<br> <img src="https://images2.imgbox.com/91/23/ibJKwd8r_o.png" alt="在这里插入图片描述"><br> 那均方差损失就只是Alice的方差：<br> 也可以把损失看成是权重和截距项的函数。让我们给网络标上权重和截距项：<br> <img src="https://images2.imgbox.com/67/c1/kTjpGlbH_o.png" alt="在这里插入图片描述"><br> 这样我们就可以把网络的损失表示为：<br> <img src="https://images2.imgbox.com/eb/ce/dRHFCz79_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="1_160"></a>1、例子：计算偏导数</h3> 
<p>我们还是看数据集中只有Alice的情况：<br> <img src="https://images2.imgbox.com/34/10/neysGskk_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_164"></a>2、训练：随机梯度下降</h3> 
<p>现在训练神经网络已经万事俱备了！我们会使用名为随机梯度下降法的优化算法来优化网络的权重和截距项，实现损失的最小化。核心就是这个更新公式：<br> <img src="https://images2.imgbox.com/e9/9d/JqFqNaj4_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_169"></a>代码：一个完整的神经网络</h2> 
<p>我们终于可以实现一个完整的神经网络了：<br> <img src="https://images2.imgbox.com/5d/2f/lKg1LJNL_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># Sigmoid activation function: f(x) = 1 / (1 + e^(-x))</span>
  <span class="token keyword">return</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">deriv_sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))</span>
  fx <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
  <span class="token keyword">return</span> fx <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> fx<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">mse_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># y_true和y_pred是相同长度的numpy数组。</span>
  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>y_true <span class="token operator">-</span> y_pred<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">OurNeuralNetwork</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">'''
  A neural network with:
    - 2 inputs
    - a hidden layer with 2 neurons (h1, h2)
    - an output layer with 1 neuron (o1)

  *** 免责声明 ***:
    下面的代码是为了简单和演示，而不是最佳的。
    真正的神经网络代码与此完全不同。不要使用此代码。
    相反，读/运行它来理解这个特定的网络是如何工作的。
  '''</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 权重，Weights</span>
    self<span class="token punctuation">.</span>w1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w3 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w4 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w5 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w6 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 截距项，Biases</span>
    self<span class="token punctuation">.</span>b1 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>b2 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>b3 <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>

  <span class="token keyword">def</span> <span class="token function">feedforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># X是一个有2个元素的数字数组。</span>
    h1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w1 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w2 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b1<span class="token punctuation">)</span>
    h2 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w3 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w4 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b2<span class="token punctuation">)</span>
    o1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w5 <span class="token operator">*</span> h1 <span class="token operator">+</span> self<span class="token punctuation">.</span>w6 <span class="token operator">*</span> h2 <span class="token operator">+</span> self<span class="token punctuation">.</span>b3<span class="token punctuation">)</span>
    <span class="token keyword">return</span> o1

  <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data<span class="token punctuation">,</span> all_y_trues<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    - data is a (n x 2) numpy array, n = # of samples in the dataset.
    - all_y_trues is a numpy array with n elements.
      Elements in all_y_trues correspond to those in data.
    '''</span>
    learn_rate <span class="token operator">=</span> <span class="token number">0.1</span>
    epochs <span class="token operator">=</span> <span class="token number">1000</span> <span class="token comment"># 遍历整个数据集的次数</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
      <span class="token keyword">for</span> x<span class="token punctuation">,</span> y_true <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span> all_y_trues<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># --- 做一个前馈(稍后我们将需要这些值)</span>
        sum_h1 <span class="token operator">=</span> self<span class="token punctuation">.</span>w1 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w2 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b1
        h1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>

        sum_h2 <span class="token operator">=</span> self<span class="token punctuation">.</span>w3 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w4 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b2
        h2 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>

        sum_o1 <span class="token operator">=</span> self<span class="token punctuation">.</span>w5 <span class="token operator">*</span> h1 <span class="token operator">+</span> self<span class="token punctuation">.</span>w6 <span class="token operator">*</span> h2 <span class="token operator">+</span> self<span class="token punctuation">.</span>b3
        o1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        y_pred <span class="token operator">=</span> o1

        <span class="token comment"># --- 计算偏导数。</span>
        <span class="token comment"># --- Naming: d_L_d_w1 represents "partial L / partial w1"</span>
        d_L_d_ypred <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">2</span> <span class="token operator">*</span> <span class="token punctuation">(</span>y_true <span class="token operator">-</span> y_pred<span class="token punctuation">)</span>

        <span class="token comment"># Neuron o1</span>
        d_ypred_d_w5 <span class="token operator">=</span> h1 <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        d_ypred_d_w6 <span class="token operator">=</span> h2 <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        d_ypred_d_b3 <span class="token operator">=</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>

        d_ypred_d_h1 <span class="token operator">=</span> self<span class="token punctuation">.</span>w5 <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        d_ypred_d_h2 <span class="token operator">=</span> self<span class="token punctuation">.</span>w6 <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>

        <span class="token comment"># Neuron h1</span>
        d_h1_d_w1 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>
        d_h1_d_w2 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>
        d_h1_d_b1 <span class="token operator">=</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>

        <span class="token comment"># Neuron h2</span>
        d_h2_d_w3 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>
        d_h2_d_w4 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>
        d_h2_d_b2 <span class="token operator">=</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>

        <span class="token comment"># --- 更新权重和偏差</span>
        <span class="token comment"># Neuron h1</span>
        self<span class="token punctuation">.</span>w1 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h1 <span class="token operator">*</span> d_h1_d_w1
        self<span class="token punctuation">.</span>w2 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h1 <span class="token operator">*</span> d_h1_d_w2
        self<span class="token punctuation">.</span>b1 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h1 <span class="token operator">*</span> d_h1_d_b1

        <span class="token comment"># Neuron h2</span>
        self<span class="token punctuation">.</span>w3 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h2 <span class="token operator">*</span> d_h2_d_w3
        self<span class="token punctuation">.</span>w4 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h2 <span class="token operator">*</span> d_h2_d_w4
        self<span class="token punctuation">.</span>b2 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h2 <span class="token operator">*</span> d_h2_d_b2

        <span class="token comment"># Neuron o1</span>
        self<span class="token punctuation">.</span>w5 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_w5
        self<span class="token punctuation">.</span>w6 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_w6
        self<span class="token punctuation">.</span>b3 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_b3

      <span class="token comment"># --- 在每次epoch结束时计算总损失 </span>
      <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        y_preds <span class="token operator">=</span> np<span class="token punctuation">.</span>apply_along_axis<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feedforward<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> mse_loss<span class="token punctuation">(</span>all_y_trues<span class="token punctuation">,</span> y_preds<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch %d loss: %.3f"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> loss<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义数据集</span>
data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
  <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># Alice</span>
  <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token comment"># Bob</span>
  <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span>   <span class="token comment"># Charlie</span>
  <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">15</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># Diana</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
all_y_trues <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># Alice</span>
  <span class="token number">0</span><span class="token punctuation">,</span> <span class="token comment"># Bob</span>
  <span class="token number">0</span><span class="token punctuation">,</span> <span class="token comment"># Charlie</span>
  <span class="token number">1</span><span class="token punctuation">,</span> <span class="token comment"># Diana</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 训练我们的神经网络!</span>
network <span class="token operator">=</span> OurNeuralNetwork<span class="token punctuation">(</span><span class="token punctuation">)</span>
network<span class="token punctuation">.</span>train<span class="token punctuation">(</span>data<span class="token punctuation">,</span> all_y_trues<span class="token punctuation">)</span>
</code></pre> 
<p>随着网络的学习，损失在稳步下降。<br> <img src="https://images2.imgbox.com/4e/39/UEH5PUzw_o.png" alt="在这里插入图片描述"><br> 现在我们可以用这个网络来预测性别了：</p> 
<pre><code class="prism language-python"><span class="token comment"># 做一些预测</span>
emily <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 128 磅, 63 英寸</span>
frank <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 155 磅, 68 英寸</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Emily: %.3f"</span> <span class="token operator">%</span> network<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>emily<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 0.951 - F</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Frank: %.3f"</span> <span class="token operator">%</span> network<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>frank<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 0.039 - M</span>
</code></pre> 
<p>把这段代码插入到上述完整的神经网络代码中：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">def</span> <span class="token function">sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
 <span class="token comment"># Sigmoid激活函数：f(x)=1/(1+e^(-x))</span>
    <span class="token keyword">return</span> <span class="token number">1</span><span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">+</span>np<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token operator">-</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">deriv_sigmoid</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># Derivative of sigmoid: f'(x)=f(x)*(1-f(x))</span>
  fx<span class="token operator">=</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
  <span class="token keyword">return</span> fx<span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>fx<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">mse_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span>y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token comment"># y_true和y_pred是相同长度的numpy数组</span>
  <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>y_true<span class="token operator">-</span>y_pred<span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">OurNeuralNetwork</span><span class="token punctuation">:</span>
  <span class="token triple-quoted-string string">'''
  A neural network with:
    - 2 inputs
    - a hidden layer with 2 neurons (h1, h2)
    - an output layer with 1 neuron (o1)

  *** 免责声明 ***:
    下面的代码是为了简单和演示，而不是最佳的。
    真正的神经网络代码与此完全不同。不要使用此代码。
    相反，读/运行它来理解这个特定的网络是如何工作的。
  '''</span>
  <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 权重，Weights</span>
    self<span class="token punctuation">.</span>w1<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w2<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w3<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w4<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w5<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>w6<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 截距项 Biaes</span>
    self<span class="token punctuation">.</span>b1<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>b2<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
    self<span class="token punctuation">.</span>b3<span class="token operator">=</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token punctuation">)</span>
  <span class="token keyword">def</span> <span class="token function">feedforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># X是一个有2个元素的数组。</span>
    h1<span class="token operator">=</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w1 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w2 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b1<span class="token punctuation">)</span>
    h2<span class="token operator">=</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w3<span class="token operator">*</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>self<span class="token punctuation">.</span>w4<span class="token operator">*</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span>self<span class="token punctuation">.</span>b2<span class="token punctuation">)</span>
    o1<span class="token operator">=</span>sigmoid<span class="token punctuation">(</span>self<span class="token punctuation">.</span>w5<span class="token operator">*</span>h1<span class="token operator">+</span>self<span class="token punctuation">.</span>w6<span class="token operator">*</span>h2<span class="token operator">+</span>self<span class="token punctuation">.</span>b3<span class="token punctuation">)</span>
    <span class="token keyword">return</span> o1
  <span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>data<span class="token punctuation">,</span>all_y_trues<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    - data is a(nx2)numpy array,n=#of samples in the dataset.
    - all_y_trues is a numpy array with n elements
    Elements in all_y_trues correspond to those in data.
    '''</span>
    learn_rate<span class="token operator">=</span><span class="token number">0.1</span>
    epochs<span class="token operator">=</span><span class="token number">1000</span> <span class="token comment">#遍历整个数组的次数</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span> 
      <span class="token keyword">for</span> x<span class="token punctuation">,</span>y_true <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>data<span class="token punctuation">,</span>all_y_trues<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># ---做一个前馈（稍后我们将需要这些值）</span>
        sum_h1<span class="token operator">=</span>self<span class="token punctuation">.</span>w1<span class="token operator">*</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>self<span class="token punctuation">.</span>w2<span class="token operator">*</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span>self<span class="token punctuation">.</span>b1
        h1<span class="token operator">=</span>sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>
        sum_h2 <span class="token operator">=</span> self<span class="token punctuation">.</span>w3 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>w4 <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>b2
        h2 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>

        sum_o1 <span class="token operator">=</span> self<span class="token punctuation">.</span>w5 <span class="token operator">*</span> h1 <span class="token operator">+</span> self<span class="token punctuation">.</span>w6 <span class="token operator">*</span> h2 <span class="token operator">+</span> self<span class="token punctuation">.</span>b3
        o1 <span class="token operator">=</span> sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        y_pred<span class="token operator">=</span>o1

        <span class="token comment"># ---计算偏导数</span>
        <span class="token comment"># ---Naming:d_L_d_w1 represents "partial L/partial w1"</span>
        d_L_d_ypred<span class="token operator">=</span><span class="token operator">-</span><span class="token number">2</span><span class="token operator">*</span><span class="token punctuation">(</span>y_true<span class="token operator">-</span>y_pred<span class="token punctuation">)</span>

        <span class="token comment"># Neuron o1</span>
        d_ypred_d_w5 <span class="token operator">=</span> h1<span class="token operator">*</span>deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        d_ypred_d_w6 <span class="token operator">=</span> h2 <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        d_ypred_d_b3 <span class="token operator">=</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>

        d_ypred_d_h1<span class="token operator">=</span>self<span class="token punctuation">.</span>w5<span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>
        d_ypred_d_h2<span class="token operator">=</span>self<span class="token punctuation">.</span>w6 <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_o1<span class="token punctuation">)</span>

        <span class="token comment"># Neuron h1</span>
        d_h1_d_w1<span class="token operator">=</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>deriv_sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>
        d_h1_d_w2<span class="token operator">=</span>x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>deriv_sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>
        d_h1_d_b1<span class="token operator">=</span>deriv_sigmoid<span class="token punctuation">(</span>sum_h1<span class="token punctuation">)</span>

        <span class="token comment"># Neuron h2</span>
        d_h2_d_w3 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>
        d_h2_d_w4 <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>
        d_h2_d_b2 <span class="token operator">=</span> deriv_sigmoid<span class="token punctuation">(</span>sum_h2<span class="token punctuation">)</span>

        <span class="token comment"># --- 更新权重和偏差</span>
        <span class="token comment"># Neuron h1</span>
        self<span class="token punctuation">.</span>w1 <span class="token operator">-=</span>learn_rate<span class="token operator">*</span>d_L_d_ypred<span class="token operator">*</span>d_ypred_d_h1<span class="token operator">*</span>d_h1_d_w1
        self<span class="token punctuation">.</span>w2 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h1 <span class="token operator">*</span> d_h1_d_w2
        self<span class="token punctuation">.</span>b1 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h1 <span class="token operator">*</span> d_h1_d_b1
        <span class="token comment"># Neuron h2</span>
        self<span class="token punctuation">.</span>w3 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h2 <span class="token operator">*</span> d_h2_d_w3
        self<span class="token punctuation">.</span>w4 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h2 <span class="token operator">*</span> d_h2_d_w4
        self<span class="token punctuation">.</span>b2 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_h2 <span class="token operator">*</span> d_h2_d_b2
        <span class="token comment"># Neuron o1</span>
        self<span class="token punctuation">.</span>w5 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_w5
        self<span class="token punctuation">.</span>w6 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_w6
        self<span class="token punctuation">.</span>b3 <span class="token operator">-=</span> learn_rate <span class="token operator">*</span> d_L_d_ypred <span class="token operator">*</span> d_ypred_d_b3

      <span class="token comment"># --- 在每次epoch结束时计算总损失</span>
      <span class="token keyword">if</span> epoch <span class="token operator">%</span> <span class="token number">10</span><span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        y_preds<span class="token operator">=</span>np<span class="token punctuation">.</span>apply_along_axis<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feedforward<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> data<span class="token punctuation">)</span>
        loss<span class="token operator">=</span>mse_loss<span class="token punctuation">(</span>all_y_trues<span class="token punctuation">,</span> y_preds<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Epoch %d loss: %.3f"</span><span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 定义数据集</span>
data<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
  <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment">#Alice</span>
  <span class="token punctuation">[</span><span class="token number">25</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment">#Bob</span>
  <span class="token punctuation">[</span><span class="token number">17</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment">#Charlie</span>
  <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token comment">#Diana</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>
all_y_trues<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>
  <span class="token number">1</span><span class="token punctuation">,</span><span class="token comment">#Alice</span>
  <span class="token number">0</span><span class="token punctuation">,</span><span class="token comment">#Bob</span>
  <span class="token number">0</span><span class="token punctuation">,</span><span class="token comment">#Charlie</span>
  <span class="token number">1</span><span class="token punctuation">,</span><span class="token comment">#Diana</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

network<span class="token operator">=</span>OurNeuralNetwork<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#训练我们的神经网络</span>
network<span class="token punctuation">.</span>train<span class="token punctuation">(</span>data<span class="token punctuation">,</span> all_y_trues<span class="token punctuation">)</span>

<span class="token comment">#做一些预测</span>
emily<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#128磅，63英寸</span>
frank<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">20</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token comment">#155磅，68英寸</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Emily:%.3f"</span><span class="token operator">%</span>network<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>emily<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Frank:%.3f"</span><span class="token operator">%</span>network<span class="token punctuation">.</span>feedforward<span class="token punctuation">(</span>frank<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>以上代码都可以直接运行</p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d137d7e8b7ffec0aa219f8028f5bfc59/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【无标题】vue中的父子组件通信</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ee13fda5b622733e8dcf300433249609/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Vue实现video视频倍速播放、调节声音、拖动进度条、生成智能字幕等</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>