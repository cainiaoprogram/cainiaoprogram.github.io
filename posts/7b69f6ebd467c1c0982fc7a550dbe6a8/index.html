<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>OBS源码分析二视频输出和画面显示流程 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="OBS源码分析二视频输出和画面显示流程" />
<meta property="og:description" content="1.第一步先看视频显示和视频编码后输出流程图 2.第二步视频显示代码详细步骤说明 在初始化视频时,启动了一个线程函数obs_video_thread(),所有画面源的合成,画面显示以及视频输出都在这个函数里触发。
void *obs_video_thread(void *param) { uint64_t last_time = 0; uint64_t interval = video_output_get_frame_time(obs-&gt;video.video); uint64_t frame_time_total_ns = 0; uint64_t fps_total_ns = 0; uint32_t fps_total_frames = 0; obs-&gt;video.video_time = os_gettime_ns(); os_set_thread_name(&#34;obs-core: graphics thread&#34;); const char *video_thread_name = profile_store_name(obs_get_profiler_name_store(), &#34;arcvideo_director_video_thread(%g&#34;NBSP&#34;ms)&#34;, interval / 1000000.); profile_register_root(video_thread_name, interval); while (!video_output_stopped(obs-&gt;video.video)) { uint64_t frame_start = os_gettime_ns(); uint64_t frame_time_ns; profile_start(video_thread_name); profile_start(tick_sources_name); last_time = tick_sources(obs-&gt;video.video_time, last_time); profile_end(tick_sources_name); profile_start(render_displays_name); render_displays(); profile_end(render_displays_name); profile_start(output_frame_name); output_frame(&amp;obs-&gt;video.main_track, obs_get_video_context(), obs_get_video()); for (int i = 0; i &lt; MAX_AUX_TRACK_CHANNELS; i&#43;&#43;) { output_frame(&amp;obs-&gt;video." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7b69f6ebd467c1c0982fc7a550dbe6a8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-10-31T19:56:00+08:00" />
<meta property="article:modified_time" content="2019-10-31T19:56:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">OBS源码分析二视频输出和画面显示流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>1.第一步先看视频显示和视频编码后输出流程图</h4> 
<p><img alt="" class="has" height="368" src="https://images2.imgbox.com/1c/25/7VFFCPMd_o.png" width="1006"></p> 
<p>                             <img alt="" class="has" height="793" src="https://images2.imgbox.com/67/da/CoURyDgC_o.png" width="771"></p> 
<p> </p> 
<h4> 2.第二步视频显示代码详细步骤说明</h4> 
<p>在初始化视频时,启动了一个线程函数obs_video_thread(),所有画面源的合成,画面显示以及视频输出都在这个函数里触发。</p> 
<pre class="has"><code class="language-cpp">void *obs_video_thread(void *param)
{
	uint64_t last_time = 0;
	uint64_t interval = video_output_get_frame_time(obs-&gt;video.video);
	uint64_t frame_time_total_ns = 0;
	uint64_t fps_total_ns = 0;
	uint32_t fps_total_frames = 0;

	obs-&gt;video.video_time = os_gettime_ns();

	os_set_thread_name("obs-core: graphics thread");

	const char *video_thread_name =
		profile_store_name(obs_get_profiler_name_store(),
			"arcvideo_director_video_thread(%g"NBSP"ms)", interval / 1000000.);
	profile_register_root(video_thread_name, interval);

	while (!video_output_stopped(obs-&gt;video.video)) {
		uint64_t frame_start = os_gettime_ns();
		uint64_t frame_time_ns;

		profile_start(video_thread_name);

		profile_start(tick_sources_name);
		last_time = tick_sources(obs-&gt;video.video_time, last_time);
		profile_end(tick_sources_name);

		profile_start(render_displays_name);
		render_displays();
		profile_end(render_displays_name);

		profile_start(output_frame_name);
		output_frame(&amp;obs-&gt;video.main_track, obs_get_video_context(), obs_get_video());
		for (int i = 0; i &lt; MAX_AUX_TRACK_CHANNELS; i++) {
			output_frame(&amp;obs-&gt;video.aux_track[i], obs_get_aux_video_context(), obs_get_aux_video(i));
		}
		profile_end(output_frame_name);

		frame_time_ns = os_gettime_ns() - frame_start;

		profile_end(video_thread_name);

		profile_reenable_thread();

		video_sleep(&amp;obs-&gt;video, &amp;obs-&gt;video.video_time, interval);

		frame_time_total_ns += frame_time_ns;
		fps_total_ns += (obs-&gt;video.video_time - last_time);
		fps_total_frames++;

		if (fps_total_ns &gt;= 1000000000ULL) {
			obs-&gt;video.video_fps = (double)fps_total_frames /
				((double)fps_total_ns / 1000000000.0);
			obs-&gt;video.video_avg_frame_time_ns =
				frame_time_total_ns / (uint64_t)fps_total_frames;

			frame_time_total_ns = 0;
			fps_total_ns = 0;
			fps_total_frames = 0;
		}
	}

	UNUSED_PARAMETER(param);
	return NULL;
}</code></pre> 
<p>tick_sources()遍历每个sources;</p> 
<pre class="has"><code class="language-cpp">static uint64_t tick_sources(uint64_t cur_time, uint64_t last_time)
{
	struct obs_core_data *data = &amp;obs-&gt;data;
	struct obs_source    *source;
	uint64_t             delta_time;
	float                seconds;

	if (!last_time)
		last_time = cur_time -
			video_output_get_frame_time(obs-&gt;video.video);

	delta_time = cur_time - last_time;
	seconds = (float)((double)delta_time / 1000000000.0);

	pthread_mutex_lock(&amp;data-&gt;sources_mutex);

	/* call the tick function of each source */
	source = data-&gt;first_source;
	while (source) {
		obs_source_video_tick(source, seconds);
		source = (struct obs_source*)source-&gt;context.next;
	}

	pthread_mutex_unlock(&amp;data-&gt;sources_mutex);

	return cur_time;
}</code></pre> 
<p>调用render_displays()将当前视频画面显示在窗口中;</p> 
<pre class="has"><code class="language-cpp">/* in obs-display.c */
extern void render_display(struct obs_display *display);

static inline void render_displays(void)
{
	struct obs_display *display;

	if (!obs-&gt;data.valid)
		return;

	gs_enter_context(obs-&gt;video.graphics);

	/* render extra displays/swaps */
	pthread_mutex_lock(&amp;obs-&gt;data.displays_mutex);

	display = obs-&gt;data.first_display;
	while (display) {
		render_display(display);
		display = display-&gt;next;
	}

	pthread_mutex_unlock(&amp;obs-&gt;data.displays_mutex);

	gs_leave_context();
}</code></pre> 
<p>output_frame()输出当前视频帧；</p> 
<pre class="has"><code class="language-cpp">​
static inline void output_frame(struct obs_video_track* track, struct video_c_t *context, struct video_d_t *data)
{
	struct obs_core_video *video = &amp;obs-&gt;video;
	int cur_texture  = track-&gt;cur_texture;
	int prev_texture = cur_texture == 0 ? NUM_TEXTURES-1 : cur_texture-1;
	struct video_data frame;
	bool frame_ready;

	memset(&amp;frame, 0, sizeof(struct video_data));

	profile_start(output_frame_gs_context_name);
	gs_enter_context(video-&gt;graphics);

	profile_start(output_frame_render_video_name);
	render_video(video, track, cur_texture, prev_texture);
	profile_end(output_frame_render_video_name);

	//render_video_ex(video, cur_texture, prev_texture);

	profile_start(output_frame_download_frame_name);
	frame_ready = download_frame(video, track, prev_texture, &amp;frame);
	profile_end(output_frame_download_frame_name);

	profile_start(output_frame_gs_flush_name);
	gs_flush();
	profile_end(output_frame_gs_flush_name);

	gs_leave_context();
	profile_end(output_frame_gs_context_name);

	if (frame_ready) {
		struct obs_vframe_info vframe_info;
		circlebuf_pop_front(&amp;track-&gt;vframe_info_buffer, &amp;vframe_info,
				sizeof(vframe_info));

		frame.timestamp = vframe_info.timestamp;
		profile_start(output_frame_output_video_data_name);
		output_video_data(video, context, data, &amp;frame, vframe_info.count, track == &amp;video-&gt;main_track || track-&gt;is_pgm);
		profile_end(output_frame_output_video_data_name);
	}

	if (++track-&gt;cur_texture == NUM_TEXTURES)
		track-&gt;cur_texture = 0;
}

​</code></pre> 
<p>调用 render_video(),渲染视频数据，在开启推流和录像功能时,调用render_output_texture(),渲染输出帧,并保存在video-&gt;convert_textures和video-&gt;output_textures中；</p> 
<p>调用stage_output_texture将画面保存到video-&gt;copy_surfaces；</p> 
<p>再调用download_frme,从video-&gt;copy_surfaces中拷贝出当前视频帧数据到video_data *frame；</p> 
<p>这样就拿到了需要输出的视频画面；</p> 
<pre class="has"><code class="language-cpp">static inline void output_video_data(struct obs_core_video *video, struct video_c_t *video_context, struct video_d_t *video_data,
		struct video_data *input_frame, int count, bool enableFtb)
{
	const struct video_output_info *info;
	struct video_frame output_frame;
	bool locked;

	info = video_output_get_info(video_context);

	locked = video_output_lock_frame(video_data, &amp;output_frame, count,
			input_frame-&gt;timestamp);
	if (locked) {

	/*modified by yshe end*/
		if (video-&gt;forceblack &amp;&amp; enableFtb) {
			//fill the output_frame to black
//			memset(output_frame.data[0], 0,output_frame.linesize[0]*info-&gt;height*3/2);
			video_frame_setblack(&amp;output_frame, info-&gt;format, info-&gt;height);
		}
		else
		{
			if (video-&gt;gpu_conversion) {
				set_gpu_converted_data(video, &amp;output_frame,
					input_frame, info);

			}
			else if (format_is_yuv(info-&gt;format)) {
				convert_frame(&amp;output_frame, input_frame, info);
			}
			else {
				copy_rgbx_frame(&amp;output_frame, input_frame, info);
			}
		}

		video_output_unlock_frame(video_data);
	}
}</code></pre> 
<p>将frame传入output_video_data(),在该函数中,调用video_output_lock_frame()函数,拷贝input-&gt;cache[last_add]给output_frame,需要注意的是,这个拷贝是将cache[]中的指针地址拷贝过来了,通过格式转换函数例如copy_rgb_frame,将input_frame中的数据内容拷贝到output_frame,实际上也就是将视频内容拷贝到了input-&gt;cache[last_add]中,再调用video_output_unlock_frame()函数,唤醒信号量video-&gt;update_semaphore,通知线程video_thread视频输出数据已就绪,执行数据输出、编码、rtmp推流。</p> 
<p>最后再调用render_displays()将当前视频画面显示在窗口中,sleep直到下一帧视频数据时间戳；</p> 
<h4>3.第二步视频编码后输出详细步骤说明</h4> 
<p>在初始化视频时,启动了一个线程函数video_thread(),这个函数一直等待视频帧数据准备就绪的信号唤醒；</p> 
<pre class="has"><code class="language-cpp">static void *video_thread(void *param)
{
	struct video_output *video = param;

	os_set_thread_name("video-io: video thread");

	const char *video_thread_name =
		profile_store_name(obs_get_profiler_name_store(),
				"video_thread(%s)", video-&gt;context.info.name);

	while (os_sem_wait(video-&gt;data.update_semaphore) == 0) {
		if (video-&gt;context.stop)
			break;

		profile_start(video_thread_name);
		while (!video-&gt;context.stop &amp;&amp; !video_output_cur_frame(&amp;video-&gt;data)) {
			video-&gt;data.total_frames++;
		}

		video-&gt;data.total_frames++;
		profile_end(video_thread_name);

		profile_reenable_thread();
	}

	return NULL;
}</code></pre> 
<p>在输出的一帧视频画面合成后唤醒该信号，在video_output_unlock_frame()里触发该信号</p> 
<pre class="has"><code class="language-cpp">void video_output_unlock_frame(video_d_t *video)
{
	if (!video) return;

	pthread_mutex_lock(&amp;video-&gt;data_mutex);

	video-&gt;available_frames--;
	os_sem_post(video-&gt;update_semaphore);

	pthread_mutex_unlock(&amp;video-&gt;data_mutex);
}</code></pre> 
<p>等到信号后执行video_output_cur_frame函数,获取视频缓存中第一帧，从video-&gt;inputs中获取输出类型调用编码器绑定的回调函数input-&gt;callback，receive_video(),进行视频数据编码，而video-&gt;update_semaphore 信号量是在所有画面合成完成后被唤醒；</p> 
<p>video-&gt;inputs中保存的是输出类型,包括推流和录像,后面将会说到是如何添加的。</p> 
<pre class="has"><code class="language-cpp">static inline bool video_output_cur_frame(struct video_output_data *video)
{
	struct cached_frame_info *frame_info;
	bool complete;
	bool skipped;

	/* -------------------------------- */

	pthread_mutex_lock(&amp;video-&gt;data_mutex);

	frame_info = &amp;video-&gt;cache[video-&gt;first_added];

	pthread_mutex_unlock(&amp;video-&gt;data_mutex);

	/* -------------------------------- */

	pthread_mutex_lock(&amp;video-&gt;input_mutex);

	for (size_t i = 0; i &lt; video-&gt;inputs.num; i++) {
		struct video_input *input = video-&gt;inputs.array+i;
		struct video_data frame = frame_info-&gt;frame;

		if (scale_video_output(input, &amp;frame))
			input-&gt;callback(input-&gt;param, &amp;frame);
	}

	pthread_mutex_unlock(&amp;video-&gt;input_mutex);

	/* -------------------------------- */

	pthread_mutex_lock(&amp;video-&gt;data_mutex);

	frame_info-&gt;frame.timestamp += video-&gt;frame_time;
	complete = --frame_info-&gt;count == 0;
	skipped = frame_info-&gt;skipped &gt; 0;

	if (complete) {
		if (++video-&gt;first_added == video-&gt;cache_size)
			video-&gt;first_added = 0;

		if (++video-&gt;available_frames == video-&gt;cache_size)
			video-&gt;last_added = video-&gt;first_added;
	} else if (skipped) {
		--frame_info-&gt;skipped;
		++video-&gt;skipped_frames;
	}

	pthread_mutex_unlock(&amp;video-&gt;data_mutex);

	/* -------------------------------- */

	return complete;
}</code></pre> 
<p>在receive_video中调用do_encode()进行编码；</p> 
<pre class="has"><code class="language-cpp">static const char *receive_video_name = "receive_video";
static void receive_video(void *param, struct video_data *frame)
{
	profile_start(receive_video_name);

	struct obs_encoder    *encoder  = param;
	struct obs_encoder    *pair     = encoder-&gt;paired_encoder;
	struct encoder_frame  enc_frame;

	if (!encoder-&gt;first_received &amp;&amp; pair) {
		if (!pair-&gt;first_received ||
		    pair-&gt;first_raw_ts &gt; frame-&gt;timestamp) {
			goto wait_for_audio;
		}
	}

	//memset(&amp;enc_frame, 0, sizeof(struct encoder_frame));

	for (size_t i = 0; i &lt; MAX_AV_PLANES; i++) {
		enc_frame.data[i]     = frame-&gt;data[i];
		enc_frame.linesize[i] = frame-&gt;linesize[i];
	}

	if (!encoder-&gt;start_ts)
		encoder-&gt;start_ts = frame-&gt;timestamp;

	enc_frame.frames = 1;
	enc_frame.pts    = encoder-&gt;cur_pts;

	do_encode(encoder, &amp;enc_frame);

	encoder-&gt;cur_pts += encoder-&gt;timebase_num;

wait_for_audio:
	profile_end(receive_video_name);
}</code></pre> 
<p>在do_encode中根据不同的编码器名称进行编码回调，各个编码器模块在程序开始加载的时候会进行注册，编码完成后调用绑定的编码完成回调。</p> 
<pre class="has"><code class="language-cpp">static const char *do_encode_name = "do_encode";
static inline void do_encode(struct obs_encoder *encoder,
		struct encoder_frame *frame)
{
	profile_start(do_encode_name);
	if (!encoder-&gt;profile_encoder_encode_name)
		encoder-&gt;profile_encoder_encode_name =
			profile_store_name(obs_get_profiler_name_store(),
					"encode(%s)", encoder-&gt;context.name);

	struct encoder_packet pkt = {0};
	bool received = false;
	bool success;

	pkt.timebase_num = encoder-&gt;timebase_num;
	pkt.timebase_den = encoder-&gt;timebase_den;
	pkt.encoder = encoder;

	profile_start(encoder-&gt;profile_encoder_encode_name);
	success = encoder-&gt;info.encode(encoder-&gt;context.data, frame, &amp;pkt,
			&amp;received);
	profile_end(encoder-&gt;profile_encoder_encode_name);
	if (!success) {
		pkt.error_code = 1;
		pthread_mutex_lock(&amp;encoder-&gt;callbacks_mutex);

		for (size_t i = encoder-&gt;callbacks.num; i &gt; 0; i--) {
			struct encoder_callback *cb;
			cb = encoder-&gt;callbacks.array + (i - 1);
			send_packet(encoder, cb, &amp;pkt);
		}

		pthread_mutex_unlock(&amp;encoder-&gt;callbacks_mutex);
		//full_stop(encoder);
		blog(LOG_INFO, "Error encoding with encoder '%s'",
				encoder-&gt;context.name);
		goto error;
	}

	if (received) {
		if (!encoder-&gt;first_received) {
			encoder-&gt;offset_usec = packet_dts_usec(&amp;pkt);
			encoder-&gt;first_received = true;
		}

		/* we use system time here to ensure sync with other encoders,
		 * you do not want to use relative timestamps here */
		pkt.dts_usec = encoder-&gt;start_ts / 1000 +
			packet_dts_usec(&amp;pkt) - encoder-&gt;offset_usec;
		pkt.sys_dts_usec = pkt.dts_usec;

		pthread_mutex_lock(&amp;encoder-&gt;callbacks_mutex);

		for (size_t i = encoder-&gt;callbacks.num; i &gt; 0; i--) {
			struct encoder_callback *cb;
			cb = encoder-&gt;callbacks.array+(i-1);
			send_packet(encoder, cb, &amp;pkt);
		}

		pthread_mutex_unlock(&amp;encoder-&gt;callbacks_mutex);
	}

error:
	profile_end(do_encode_name);
}</code></pre> 
<p>通过回调得到编码后的数据，然后rtmp对数据封装推流输出，下一篇介绍详细的推流步骤。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a6d7a4cebbf5d626759186466006edff/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">lotus ubuntu 18.04 安装(当前版本Devnet 7)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b4974a42c550b36f046a46e1fc71de97/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">素数筛(埃氏筛法、欧拉筛法)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>