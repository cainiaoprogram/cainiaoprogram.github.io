<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>英特尔® Distribution of OpenVINO™ toolkit 2021 版的发布说明 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="英特尔® Distribution of OpenVINO™ toolkit 2021 版的发布说明" />
<meta property="og:description" content="注意 2020 版的发布说明，请参阅英特尔® Distribution of OpenVINO™ toolkit 2020 版的发布说明。 简介 英特尔® Distribution of OpenVINO™ toolkit 用于快速开发应用程序和解决方案，以解决各种任务（例如：模拟人类视觉、自动语音识别、自然语言处理和推荐系统等）。该工具套件基于最新一代的人工神经网络，包括卷积神经网络 (CNN)、递归网络和基于注意力的网络，可扩展跨英特尔® 硬件的计算机视觉和非视觉工作负载，从而最大限度地提高性能。它通过从边缘到云部署的高性能、人工智能和深度学习推理来为应用程序加速。
英特尔® Distribution of OpenVINO™ toolkit
支持从边缘到云的深度学习推理。借助英特尔® CPU、英特尔® 集成显卡、英特尔® Gaussian &amp; Neural Accelerator、英特尔® 神经电脑棒 2、搭载英特尔® Movidius™ 视觉处理器的英特尔® Vision Accelerator Design 的通用 API，支持跨英特尔加速器的异构执行。通过一套易用的计算机视觉功能库和预优化内核库来加速上市时间。包括针对 CV 标准进行的调用优化，包括 OpenCV* 和 OpenCL™。 第 3 版发布中的更新和更改 主要功能和改进 升级到最新版本以获取新功能和性能改进。引入了条件编译的预览（可在开源发行版中获得），该预览可以显著减少特定模型的运行时组件（链接到应用程序的推理引擎）的二进制占用。推出针对第三代英特尔® 至强® 可扩展平台（代号 Ice Lake）的支持，可实现高级性能、安全性、效率和内置人工智能加速，以处理独特的工作负载和更强大的人工智能。全新预训练模型和对公共模型的支持，以简化开发： 预先训练的模型：机器翻译、人/车/自行车检测、文本识别和文本语音转换。公共模型：aclnet-int8 (sound_classification)、deblurgan-v2 (image_processing)、fastseg-small 和 fastseg-large（语义分割）等。 现在可以在 Windows*、Linux* 和 macOS*上使用 pip install openvino-dev，以 Python wheel 包的形式提供开发人员工具，轻松进行软件包的安装和升级。
支持变更和弃用通知 工具套件组件弃用通知：英特尔® Media SDK" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2492a4d831ef6277e179c6b8f028804c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-04-30T12:49:16+08:00" />
<meta property="article:modified_time" content="2021-04-30T12:49:16+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">英特尔® Distribution of OpenVINO™ toolkit 2021 版的发布说明</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><strong>注意</strong> 2020 版的发布说明，请参阅<a href="https://software.intel.com/content/www/cn/zh/develop/articles/openvino-relnotes-2020.html" rel="nofollow">英特尔® Distribution of OpenVINO™ toolkit 2020 版的发</a>布说明。 </p> 
<h3>简介<a id="inpage-nav-undefined"></a></h3> 
<p>英特尔® Distribution of OpenVINO™ toolkit 用于快速开发应用程序和解决方案，以解决各种任务（例如：模拟人类视觉、自动语音识别、自然语言处理和推荐系统等）。该工具套件基于最新一代的人工神经网络，包括卷积神经网络 (CNN)、递归网络和基于注意力的网络，可扩展跨英特尔® 硬件的计算机视觉和非视觉工作负载，从而最大限度地提高性能。它通过从边缘到云部署的高性能、人工智能和深度学习推理来为应用程序加速。</p> 
<p>英特尔® Distribution of OpenVINO™ toolkit</p> 
<ul><li>支持从边缘到云的深度学习推理。</li><li>借助英特尔® CPU、英特尔® 集成显卡、英特尔® Gaussian &amp; Neural Accelerator、英特尔® 神经电脑棒 2、搭载英特尔® Movidius™ 视觉处理器的英特尔® Vision Accelerator Design 的通用 API，支持跨英特尔加速器的异构执行。</li><li>通过一套易用的计算机视觉功能库和预优化内核库来加速上市时间。</li><li>包括针对 CV 标准进行的调用优化，包括 OpenCV* 和 OpenCL™。</li></ul> 
<h3>第 3 版发布中的更新和更改<a id="inpage-nav-1"></a></h3> 
<h4>主要功能和改进<a id="inpage-nav-1-undefined"></a></h4> 
<ul><li>升级到最新版本以获取新功能和性能改进。</li><li>引入了条件编译的预览（可在开源发行版中获得），该预览可以显著减少特定模型的运行时组件（链接到应用程序的推理引擎）的二进制占用。</li><li>推出针对第三代英特尔® 至强® 可扩展平台（代号 Ice Lake）的支持，可实现高级性能、安全性、效率和内置人工智能加速，以处理独特的工作负载和更强大的人工智能。</li><li>全新预训练模型和对公共模型的支持，以简化开发： 
  <ul><li><em>预先训练的模型：</em>机器翻译、人/车/自行车检测、文本识别和文本语音转换。</li><li><em>公共模型：</em>aclnet-int8 (sound_classification)、deblurgan-v2 (image_processing)、fastseg-small 和 fastseg-large（语义分割）等。</li></ul></li><li> <p>现在可以在 Windows*、Linux* 和 macOS*上使用 pip install openvino-dev，以 Python wheel 包的形式提供开发人员工具，轻松进行软件包的安装和升级。</p> </li></ul> 
<h4>支持变更和弃用通知<a id="inpage-nav-1-1"></a></h4> 
<ul><li> <p><strong>工具套件组件弃用通知：英特尔® Media SDK</strong></p> 
  <table><tbody><tr><th>弃用生效日期</th><th>2021 年 3 月 23 日</th></tr><tr><td>移除日期</td><td>2021 年 10 月</td></tr></tbody></table> 
  <ul><li>从英特尔® Distribution of OpenVINO™ 工具套件 2021.3 版本开始，英特尔® Media SDK 将于 2021 年 10 月弃用。</li><li>建议用户迁移到英特尔® oneAPI Video Processing Library (oneVPL)，作为用于视频解码、编码和处理的统一编程接口，以在 CPU、GPU 和加速器上构建便携式媒体管道。请注意 API 和功能的差异和变化。</li><li>英特尔® Distribution of OpenVINO™ 工具套件将支持英特尔® one API Video Processing Library (oneVPL)，以替代英特尔® Media SDK。</li><li>请参阅<a href="https://software.intel.com/content/www/us/en/develop/documentation/oneapi-programming-guide/top/api-based-programming/intel-oneapi-video-processing-library-onevpl.html" rel="nofollow">《oneVPL 编程指南》</a>以获取<a href="https://software.intel.com/content/www/us/en/develop/articles/upgrading-from-msdk-to-onevpl.html" rel="nofollow">从英特尔® Media SDK 迁移到 oneVPL 的指导说明</a><strong>，</strong>并获取<a href="https://spec.oneapi.com/versions/latest/elements/oneVPL/source/appendix/VPL_intel_media_sdk.html#msdk-full-name-api-removals" rel="nofollow">《API 更新文档》</a>以供参考。</li></ul></li><li> <p><strong>操作系统弃用通知：CentOS*</strong></p> 
  <table><tbody><tr><th>弃用生效日期</th><th>2021 年 3 月 23 日</th></tr><tr><td>移除日期</td><td>2021 年 10 月</td></tr></tbody></table> 
  <ul><li>英特尔® Distribution of OpenVINO™ 工具套件将继续支持 <strong>Red Hat Enterprise Linux (RHEL) 8</strong>，并将在 2022.1（2021 年 10 月）开始的新版本中放弃对 CentOS 的支持。</li><li> <p>有关支持的硬件和操作系统的完整列表，请参阅<a href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/system-requirements.html" rel="nofollow">系统要求</a>。</p> 
    <table><tbody><tr><td> </td><td> <p><strong>2021.3</strong>（此版本）</p> </td><td> <p><strong>2021.4 LTS</strong></p> </td><td> <p><strong>2022.1</strong>（2021 年 10 月）</p> </td></tr><tr><td> <p>支持</p> </td><td> <p>CentOS 7</p> <p>RHEL 8</p> </td><td> <p>CentOS 7</p> <p>RHEL 8</p> </td><td> <p>RHEL 8</p> <p> </p> </td></tr></tbody></table></li></ul></li><li> <p><strong>操作系统支持更新通知：Ubuntu* 18.0x</strong></p> 
  <table><tbody><tr><th>变更通知开始</th><th>2021 年 3 月 23 日</th></tr><tr><td>支持变更日期</td><td>2021 年 10 月</td></tr></tbody></table> 
  <ul><li> <p>Ubuntu 18.0x 将转为<strong>有限支持。 </strong> Ubuntu 18.0x 将无法支持从 2022.1 版本及更高版本新发布的英特尔® 硬件。</p> </li><li>从 2022.1（2021 年 10 月）开始，新的推荐操作系统版本将为 Ubuntu 20.0。</li><li>有关更多信息，请参见<a href="https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/system-requirements.html" rel="nofollow">系统要求</a>（从 2022.1 版本开始，推荐配置将标记为粗体）。</li></ul></li><li> <p><strong>框架弃用通知：TensorFlow* 1.x</strong></p> 
  <table><tbody><tr><th>变更通知开始</th><th>2021 年 3 月 23 日</th></tr><tr><td>支持变更日期</td><td>2021 年 10 月</td></tr></tbody></table> 
  <ul><li>TensorFlow 1.x 转为<strong>有限支持</strong>。仍支持使用 OpenVINO 2020.4 或更高版本创建的 TensorFlow 1.x 模型的任何中间表示 (IR) 文件。使用最新的 OpenVINO，仍然可以将 TensorFlow 1.x 模型转换为中间表示 (IR)。</li><li>由于 TensorFlow 已弃用 1.x，因此要为 TensorFlow 1.x 模型生成新的 IR 文件，就需要将 Python 3.6 与 NumPy 版本 1.19.2 结合使用。</li><li>英特尔® Distribution of OpenVINO™ 工具套件将在 2021 年 6 月的 2021.4 LTS 版本中继续支持 NumPy 1.19.2 版本。LTS 对 2021.4 版本的支持将延长至 2023 年 6 月。从 2021 年 10 月的 2022.1 版本开始，将不再支持 NumPy 1.19.2。</li><li>建议用户在上述情况下升级到 TensorFlow 2.x 或更高版本，或使用 TensorFlow 1.x 模型。</li><li>请参阅<a href="https://www.tensorflow.org/guide/migrate" rel="nofollow">《TensorFlow1 代码迁移到 TensorFlow 2》</a>文档和<a href="https://docs.openvinotoolkit.org/latest/openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html" rel="nofollow">《转换 TensorFlow 模型文档》</a>以获取指导说明。</li></ul></li></ul> 
<h4>模型优化器<a id="inpage-nav-1-2"></a></h4> 
<p><a href="http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html" rel="nofollow">模型优化器</a></p> 
<p>常见的变更<a id="inpage-nav-1-2-undefined"></a></p> 
<ul><li>为了避免组件 1.25.8 版本中存在安全问题，要求中将 urllib3 版本更新为了“urllib3&gt;=1.25.9”。</li><li>在 ShapeOf 子图中用 StridedSlice 操作改进了模型的重塑功能</li><li>向 IR 中的输出端口添加了框架张量名称。</li><li>实现了使用完全定义的类名在 MO 中启用/禁用转换的新方法。 您只需将完全定义的类名称放入 `MO_ENABLED_TRANSFORMS` (`MO_DISABLED_TRANSFORMS`) 变量中即可（例如， `extensions.back.NonmalizeToNormalizeL2.NormalizeToNormalizeL2`）。</li><li>为模型优化器实现了基本遥测数据的发送（用户启动了 MO、模型转换结果、MO 版本）</li></ul> 
<p>ONNX*<a id="inpage-nav-1-2-1"></a></p> 
<p>增加了对以下操作的支持：</p> 
<ul><li> <p>GatherElements - 11, 13</p> </li></ul> 
<p>TensorFlow*<a id="inpage-nav-1-2-2"></a></p> 
<ul><li> <p>现在将 CTCGreedyDecoder 转换为 OpenVINO 操作 CTCGreedyDecoderSeqLen。请参阅 OpenVINO <a href="https://docs.openvinotoolkit.org/latest/openvino_docs_ops_sequence_CTCGreedyDecoderSeqLen_6.html" rel="nofollow">操作规范</a>以了解更多信息。</p> </li></ul> 
<p>MXNet*<a id="inpage-nav-1-2-3"></a></p> 
<ul><li>增加了对以下操作的支持： 
  <ul><li>take</li></ul></li></ul> 
<p>TensorFlow 2*<a id="inpage-nav-1-2-4"></a></p> 
<ul><li>增加了对 TensorFlow2.X 对象检测 API 模型的支持，其中包括 8 个 EfficientDet 模型、10 个 SSD 模型、11 个 Faster R-CNN 模型和 Mask R-CNN 模型。</li><li>增加了对具有形状不变输入的 'while_loop' 操作的支持，即循环变量中每个张量的初始形状在每次迭代中都相同。请注意，'while_loop' 操作仅在 RNN 上下文中受支持，可能在其他上下文中不起作用。</li><li>增加了对 Keras 操作集的支持，但不包括 ConvLSTM2D、MultiHeadAttention、Masking 操作和 SELU 激活功能</li></ul> 
<h4>推理引擎<a id="inpage-nav-1-3"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html" rel="nofollow">推理引擎</a></p> 
<p>常见变更<a id="inpage-nav-1-3-undefined"></a></p> 
<ul><li>引入到推理引擎中的 CNNNetwork::getOVNameForTensor() API，允许使用框架张量名称以获取 OpenVINO 的输入/输出名称。该 API 仅适用于 ONNX 模型，支持的框架集将在下一版本中进行扩展。</li><li>增加了 InferRequest::Cancel 方法，用以取消推理请求的执行。该功能目前仅适用于 CPU 插件。 </li><li>CNNNetwork::Serialize() 方法支持序列化为 v10 IR 格式。</li><li> <p>弃用的 API：</p> 
  <ul><li> <p>已弃用 InferenceEngine::IVariableState 接口，请使用 InferenceEngine::VariableState C++ 封装器</p> </li></ul></li></ul> 
<p>推理引擎 Python API<a id="inpage-nav-1-3-1"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/ie_python_api/annotated.html" rel="nofollow">推理引擎 Python API</a></p> 
<ul><li>增加了对设置 FP16 blob 的支持</li><li>增加了 FP64 数据类型</li></ul> 
<p>CPU 插件<a id="inpage-nav-1-3-2"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_CPU.html" rel="nofollow">CPU 插件</a></p> 
<ul><li>该插件已迁移到 oneDNN v1.6。这可以提供新功能支持（例如，AVX-VNNI 指令集架构 (ISA) 的支持）和现有管道的性能优化（例如，对不支持 AVX512 的传统硬件进行 int8 推断）。</li><li>支持插件本身和 oneDNN 分支中的条件编译功能。对于特定的用户方案，该功能允许将 CPU 插件库的规模减小数倍。</li><li>提供了 BF16 推理管道增强功能。扩展了许多操作以直接支持 BF16 精度。结合 oneDNN v1.6 的新功能的集成，与 2021.2OV 版本相比，该升级带来了平均性能的大幅提高。</li><li>增加了对新运算的支持： 
  <ul><li>MVN-6</li><li>GatherElements-6</li><li>CTCGreedyDecoderSeqLen-6</li><li>ROIAlign-3</li></ul></li><li>实现了多种操作优化：Split、Pad、MVN。</li><li>对于定量模型，在吞吐量方案中显著减少了内存消耗。 </li><li>支持 InferRequest::Cancel 方法，该方法允许在中间阶段中断推理请求的执行。</li></ul> 
<p>GPU 插件<a id="inpage-nav-1-3-3"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_CL_DNN.html" rel="nofollow">GPU 插件</a></p> 
<ul><li>增加了对以下操作的支持： 
  <ul><li>MVN-6</li><li>CTCGreedyDecoderSeqLen-6</li><li>ScatterElementsUpdate-3</li><li>ScatterUpdate-3</li><li>Broadcast-3</li></ul></li><li>性能提高： 
  <ul><li>gen12lp GPU 的 int8 和 fp16 卷积内核的微调</li><li>在所有空间维度上进行 Reduce内核的优化</li><li>NCHW→NHWC 案例的转置操作优化</li></ul></li><li>缩短加载时间</li></ul> 
<p>MYRIAD 插件<a id="inpage-nav-1-3-4"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_MYRIAD.html" rel="nofollow">MYRIAD 插件</a></p> 
<ul><li>增加了针对新操作的支持： 
  <ul><li>HSwish</li><li>GatherND</li><li>Interpolate</li><li>Ceil</li></ul></li><li>为 Broadcast 运算增加了“双向”模式。</li><li>为 Proposal 运算增加了第二个可选输出。</li><li>改善了现有操作的性能： 
  <ul><li>Mish</li><li>Swish</li><li>NonMaxSuppression</li></ul></li></ul> 
<p>HDDL 插件<a id="inpage-nav-1-3-5"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_HDDL.html" rel="nofollow">HDDL 插件</a></p> 
<ul><li>与 MYRIAD 插件中相同的新操作和优化。</li><li>为 ION 驱动程序启用了对 Linux 内核 5.4 的支持。</li></ul> 
<p>GNA 插件<a id="inpage-nav-1-3-6"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_GNA.html" rel="nofollow">GNA 插件</a></p> 
<ul><li>模型导出现在可保存层名称，因此可以在导入之后再次使用。</li><li>修复了某些层组合。</li></ul> 
<h4>nGraph<a id="inpage-nav-1-4"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/openvino_docs_nGraph_DG_DevGuide.html" rel="nofollow">nGraph</a></p> 
<ul><li>引入了 opset6。全新 opset 包含以下全新操作。并非所有 OpenVINO™ 工具套件插件都支持这些操作。 
  <ul><li>MVN-6</li><li>GatherElements-6</li></ul> 
  <ul><li>CTCGreedyDecoderSeqLen -6</li><li>ExperimentalDetectronTopKROIs -6</li><li>ExperimentalDetectronGenerateProposalsSingleImage-6</li><li>ExperimentalDetectronDetectionOutput-6</li><li>ExperimentalDetectronPriorGridGenerator-6</li></ul> 
  <ul><li>ExperimentalDetectronROIFeatureExtractor-6</li></ul></li><li> <p>公共 nGraph API 的更改</p> 
  <ul><li> <p>增加了 add_parameters/remove_parameter 方法</p> </li></ul></li><li>ONNX 导入器的更改 
  <ul><li>公共 API 目录中的标头数已减少到所需的最低限度（其他标头已移至“src”目录）</li><li>新的运算符支持：GatherElements、ReduceSum (opset 13)、ExperimentalDetectron 和 PriorBoxClustered（非标准操作）、BitShift</li><li>Bert Squad opset 10 支持</li><li>ONNX 依赖项已更新为 v1.8.0</li></ul></li></ul> 
<h4>训练后优化工具 (POT)<a id="inpage-nav-1-5"></a></h4> 
<p><a href="http://docs.openvinotoolkit.org/latest/_README.html" rel="nofollow">训练后优化工具</a></p> 
<ul><li>为 INT8 量化增加了可选的逐层微调机制，该机制有助于提高量化模型的准确性。该机制由“use_layerwise_tuning”参数启用。 ​</li><li>引入了一种新的量化权重表示形式，以解决模型优化器中的相关变化。</li><li>针对量化的 mobilenetv3 和 hbonet 模型实施了性能优化。</li><li>通过 POT SW API 为 MobileNetV1 FPN 模型增加了带有 AccuracyAware 算法的 INT8 量化样本。</li><li>扩大了模型覆盖范围：额外启用了 44 个模型。</li></ul> 
<h4>神经网络压缩框架 (NNCF)<a id="inpage-nav-1-6"></a></h4> 
<ul><li>集成了 NNCF 和 OTE 的实例分割案例。</li><li>发布了 NNCF v1.6.0 for PyTorch： 
  <ul><li>增加了 UNet@Mapillary (25%) 和 SSD300@VOC (40%) 作为过滤剪枝的样本模型</li><li>批处理规范适应在默认情况下适用于所有压缩算法</li><li>ONNX 域设置为 org.openvinotoolkit 以进行自定义 OpenVINO 操作（例如，"FakeQuantize"）</li><li>CPU 的 nn.Embedding 和 nn.EmbeddingBag 权重的量化</li><li>选择优化量化标度的对数，而不是直接优化标度本身</li><li>支持插入压缩操作作为 PyTorch 操作的预挂钩</li><li>扩展了 ONNX 压缩模型导出接口，并带有一个选项，可以显式命名输入和输出张量</li><li>AutoQ - 一种用于量化的基于 AutoML 的混合精度初始化模式</li></ul></li></ul> 
<h4>深度学习工作台<a id="inpage-nav-1-7"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_Workbench_DG_Introduction.html" rel="nofollow">深度学习工作台</a></p> 
<ul><li>扩展支持界标检测和人脸识别用例 - IR 转换、AC 测量、INT8 校准、配置文件（已选中：sphereface、facenet、arcface、MobileFace、landmarks-regression-retail-0009 模型）。数据集支持扩展到 LFW 和 VGGFace2 数据集。 </li><li>增加了运行时精度分析。现在，该工具提供了运行时精度统计信息，运行时图 (Netron) 中的精度可视化，带有精度转换的表。 </li><li>基于精度分析（基于模型精度的规则集）创建和公开的建议系统。咨询系统指明了常见的性能问题，并将用户向逻辑流程引导（例如，INT8 校准等）。</li><li>新增了将 Accuracy Checker 配置从 DL Workbench 导出（例如导出到 CLI 中使用）的功能。</li><li>增加了导入外部 Accuracy Checker 配置文件的功能，并能够在 DL Workbench 中进行交互式编辑。</li><li>通过 DL Workbench 创建并公开了 OpenVINO JupyterLab 沙箱。用户现在可以结合使用 OpenVINO 沙箱和一组准备好的笔记本（分类、对象检测、语义分割、样式转换），并能够从 DL WB 移植自己的模型，以继续在 DL Workbench 中进行实验。 </li><li>模型比较模式、IR 和运行时图形可视化等方面的用户体验改进。</li><li>从英特尔® Distribution of OpenVINO™ 工具套件 2021.3 版本开始，DL Workbench 仅可作为预构建的 <a href="https://hub.docker.com/r/openvino/workbench" rel="nofollow">Docker 映像</a>使用。在 OpenVINO 安装中保留了对 DL Workbench 的引用，但现在从 DockerHub 中提取了预构建的映像，而不是从软件包中对其进行构建。 </li></ul> 
<h4>OpenCV*<a id="inpage-nav-1-8"></a></h4> 
<ul><li>已更新版本至 4.5.2。</li><li>增加了对动态加载的并行处理后端的支持（包括预构建的 TBB 插件）。</li><li>启用了 libva 互操作性支持。</li></ul> 
<h4>示例<a id="inpage-nav-1-9"></a></h4> 
<ul><li>增加了新的 Python 示例 (hello_reshape_ssd)，该示例使用 SSD-VGG 等对象检测网络进行推理。该示例显示了如何使用<a href="https://docs.openvinotoolkit.org/latest/openvino_docs_IE_DG_ShapeInference.html" rel="nofollow">形状推理</a></li><li>扩展了 C 示例 (hello_classification_async)，以显示如何使用批处理</li></ul> 
<h4>Open Model Zoo<a id="inpage-nav-1-10"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_models_intel_index.html" rel="nofollow">Open Model Zoo</a></p> 
<p>借助额外的 CNN-预训练模型和预生成的中间表示文件 (<code>.xml</code> + <code>.bin</code>) 对 Open Model Zoo 进行了扩展。颜色编码：替代 2021.2 模型、新模型、弃用模型：</p> 
<ul><li>替代 2021.2 模型： 
  <ul><li>human-pose-estimation-0005</li><li>human-pose-estimation-0006</li><li>human-pose-estimation-0007</li><li>instance-segmentation-security-0002</li><li>instance-segmentation-security-0091</li><li>instance-segmentation-security-0228</li><li>instance-segmentation-security-1039</li><li>instance-segmentation-security-1040</li><li>text-spotting-0004-detector</li><li>text-spotting-0004-recognizer-decoder</li><li>text-spotting-0004-recognizer-encoder</li></ul></li><li>新模型：  
  <ul><li>machine-translation-nar-en-de-0001</li><li>machine-translation-nar-de-en-0001</li><li>person-vehicle-bike-detection-2003</li><li>person-vehicle-bike-detection-2004</li><li>text-recognition-0013</li><li>text-to-speech-en-0001-duration-prediction</li><li>text-to-speech-en-0001-regression</li><li>text-to-speech-en-0001-generation</li></ul></li><li>弃用模型： 
  <ul><li>instance-segmentation-security-0010</li><li>instance-segmentation-security-0050</li><li>instance-segmentation-security-0083</li><li>instance-segmentation-security-1025</li><li>human-pose-estimation-0002</li><li>human-pose-estimation-0003</li><li>human-pose-estimation-0004</li></ul></li></ul> 
<p>对以下模型的支持扩展了公有模型列表：</p> 
<table><thead><tr><th> <p>模型名称</p> </th><th colspan="1"> <p>任务</p> </th><th colspan="1"> <p>框架</p> </th></tr></thead><tbody><tr><td> <p>aclnet-int8</p> </td><td colspan="1">声音分类</td><td colspan="1"> <p>PyTorch</p> </td></tr><tr><td colspan="1">deblurgan-v2</td><td colspan="1">图像处理</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">densenet-201-tf</td><td colspan="1">分类</td><td colspan="1">TensorFlow</td></tr><tr><td colspan="1">dla-34</td><td colspan="1">分类</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">fastseg-large</td><td colspan="1">语义分割</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">fastseg-small</td><td colspan="1">语义分割</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">netvlad-tf</td><td colspan="1">地点识别</td><td colspan="1">TensorFlow</td></tr><tr><td colspan="1">regnetx-3.2gf</td><td colspan="1">分类</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">rexnet-v1-x1.0</td><td colspan="1">分类</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">ssh-mxnet</td><td colspan="1">物体检测</td><td colspan="1">MxNet</td></tr></tbody></table> 
<p> </p> 
<p>重组了 Open Model Zoo 演示文件夹，以删除 &lt;omz_dir&gt;\demos\python_demos 文件夹，并在每个特定的演示子文件夹 cpp、cpp_gapi、python 下找到演示实现。注意：并非所有的 OMZ 演示都具有所有不同的实现。</p> 
<p>增加了新的演示应用程序：</p> 
<ul><li>Python face_detection_mtcnn_demo</li><li>Python deblurring_demo</li><li>Python place_recognition demo </li></ul> 
<p>object_detection_demo 扩展了新模型支持，包括扩展了支持新模型的 Yolo-V4、segmentation_demo</p> 
<p>Open Model Zoo 工具：</p> 
<ul><li>模型下载器： 
  <ul><li>当 <code>--output_dir</code> 的值是相对路径时，修复了带有存档文件的下载模型。</li></ul></li><li> <p>模型转换器：</p> 
  <ul><li>减少了 PyTorch-to-ONNX 转换阶段的内存使用量（取决于模型，减少幅度至高可达约 33%）。</li><li>如果子进程被信号终止，则现在将打印该信号的名称。</li></ul></li><li>Accuracy Checker：  
  <ul><li>增加了对 TensorFlow2.x 版本的支持作为推理后端</li><li>带有机会转储和上载图像列表的改进子集选择逻辑</li><li>增加了离线评估模式：分离推理和指标计算管道部分，并可在不同的计算机上执行</li><li>注释保存机制提供有关转换步骤的元数据</li><li>功能扩展了新的任务范围：命名实体识别，在黑暗中可见；扩展支持自动语音识别和文本到语音转换方法</li></ul></li></ul> 
<h4>深度学习流媒体播放器<a id="inpage-nav-1-11"></a></h4> 
<ul><li>更新了 gvadetect，以包括针对 YoloV4 模型的后处理。</li><li>gvatrack 中引入了新的属性 “config” 以配置跟踪算法。它可帮助开发人员指定要跟踪的最大对象数，从而减少计算量并提高吞吐量。通过帮助开发人员根据边界框的位置选择是否保留跟踪 ID，即使检测到的类由于模型不正确而发生更改，它也可以提高准确性。</li><li>在 gvadetect 和 gvainference 中增加了新属性 ‘object-class’。它提供了仅在特定对象类上运行辅助推理的功能。</li><li>通过消除在解码和推理元素之间进行视频转换的需求，提高了跨 CPU 和 GPU 的管道的性能和可移植性。</li><li>样本已更新，以接受用于推理设备选择和启用 FPS 计数器或输出视频渲染的命令行选项。这为无需修改代码而运行示例提供了更大的灵活性。</li><li>在开放源代码仓库中预览：面向 Windows 的 DL Streamer 简介。现在，您可以使用 DL Streamer 构建 Windows OS 的对象检测和对象分类管道。该预览可在 ‘preview/support-for-windows’ 分支中找到。</li><li>在开放源代码仓库中预览：引入了一个新的元素 gvasegment 来执行分割。该预览可在 ‘preview/segmentation’ 分支中找到。</li></ul> 
<h4>OpenVINO™ 模型服务器<a id="inpage-nav-1-12"></a></h4> 
<p><a href="https://github.com/openvinotoolkit/model_server">模型服务器</a></p> 
<ul><li><strong>有向无环图调度程序的自定义节点支持。</strong>即使顺序模型的输入和输出不匹配，OpenVINO 模型服务器中的自定义节点也可以简化将深度学习模型链接到完整管道的过程。在许多情况下，一个模型的输出不能直接传递给另一模型。数据可能需要分析、过滤或转换为其他格式。这些操作在人工智能框架中很难实现，或者根本不受支持。定制节点解决了这一具有挑战性的难题。它们允许使用 C++ 或 C 开发的动态库来执行任意数据转换。 </li><li><strong>DAG 多路分解 - </strong>有向无环图调度程序允许使用 Node 输出多路分解，为单独的子输出和分支管道执行来创建管道。它可以改善执行性能，并满足一些场景的需求，其中定制节点生产的任意数量的中间批次都可以分别处理，并在任何图形阶段进行收集。</li><li><strong>用于 OCR 管道的示例性自定义节点</strong> - 在 OCR 管道中已演示了用于自定义节点和执行多路分解的用例场景<a href="https://github.com/openvinotoolkit/model_server/blob/v2021.3/docs/east_ocr.md">https://github.com/openvinotoolkit/model_server/blob/v2021.3/docs/east_ocr.md</a>。它结合了 east-resnet50 模型和 CRNN 模型，实现了完整的文本检测和文本识别。  该自定义节点分析了 east-resnet50 模型的响应。根据推理结果和原始图像，它会生成检测到的文本识别框列表。输出中的每个图像将被调整为预定义的目标大小，以适合 DAG 管道 (CRNN) 中的下一个推理模型。</li><li><strong>支持状态模型 -</strong> 状态模型可识别连续推理请求之间的依赖关系。它维持推理请求之间的状态，以便下一个推理依赖于先前请求的结果。OVMS 现允许在特定序列的上下文中提交推理请求。OVMS 根据客户端的请求历史记录，对状态进行存储和建模，并响应预测结果。   <a href="https://github.com/openvinotoolkit/model_server/blob/develop/docs/stateful_models.md">https://github.com/openvinotoolkit/model_server/blob/develop/docs/stateful_models.md</a></li><li><strong>Control API -</strong> 扩展的 REST API，提供触发 OVMS 配置更新的功能。端点配置/重新加载启动应用配置更改和模型重新加载。它可以确保在特定时间部署配置更改，并确认有关重新加载操作状态的信息。端点/配置报告所有提供的模型及其版本。它简化了客户端的使用模型和连接故障排除。</li><li><strong>Helm 图表增强功能 -</strong> 增加了用于在新方案下进行部署的多个配置选项：新模型存储类、Kubernetes 资源限制、安全上下文。修复了大规模部署中存在缺陷的问题。</li><li><strong>Kubernetes 运算符</strong> - 使用面向 OVMS 的 Kubernetes 运算符启用了 OVMS 部署。该功能可用于简化 Openshift 和开源 Kubernetes 中的 OVMS 服务的大规模管理。此功能将在 <a href="https://operatorhub.io/" rel="nofollow">https://operatorhub.io</a> 中发布</li></ul> 
<h4>OpenVINO™ 安全插件<a id="inpage-nav-1-13"></a></h4> 
<ul><li>记录的 SWTPM-HWTPM 报价绑定详细信息。</li><li>使用最新的 5.0 版本的 tpm2-tools 进行了测试。</li><li>如《入门指南》中所述，将命令行选项更新为 ovsatool。</li></ul> 
<h4>新分发<a id="inpage-nav-1-14"></a></h4> 
<ul><li>Python 软件包： 
  <ul><li> <p>OpenVINO 开发人员工具现在可作为 Python wheel 包提供。如果要安装推理引擎、模型优化器、训练后优化工具和精度检查工具实用程序，只需在您的 Python 虚拟环境中运行 <strong>pip install <a href="https://pypi.org/project/openvino-dev" rel="nofollow">openvino-dev</a></strong>。 仅限运行时的 wheel 软件包 (<strong>pip install <a href="https://pypi.org/project/openvino/" rel="nofollow">openvino</a></strong>) 也已更新，并且在使用任何一个 Python 软件包时，都不再需要在 Linux 和 macOS 上设置 Windows PATH 或 LD_LIBRARY_PATH 变量。这些软件包可以安装在许多版本的 Linux 和 Windows 上，并具有以下方面的官方支持： </p> 
    <table><thead><tr><th> <p>受支持的操作系统</p> </th><th> <p>Python* 版本（64 位）</p> </th></tr></thead><tbody><tr><td>Ubuntu* 18.04 长期支持 (LTS) 版本，64 位</td><td>3.6、3.7</td></tr><tr><td>Ubuntu* 20.04 长期支持 (LTS) 版本，64 位</td><td>3.6、3.7</td></tr><tr><td>Red Hat* Enterprise Linux* 8，64 位</td><td>3.6、3.7</td></tr><tr><td>CentOS* 7，64 位</td><td>3.6、3.7</td></tr><tr><td>macOS* 10.15.x 版本</td><td>3.6、3.7、3.8</td></tr><tr><td>Windows 10*，64 位</td><td>3.6、3.7、3.8</td></tr></tbody></table></li></ul></li></ul> 
<ul><li>容器： 
  <ul><li>DockerHub 容器注册表上提供了新的 <a href="https://hub.docker.com/r/openvino/ubuntu20_dev" rel="nofollow">Ubuntu 20 dev Docker 镜像</a>。 
    <ul><li>包括推理引擎、OpenCV、示例、演示、模型优化器、训练后优化工具、精度检查工具和 Open Model Zoo 工具。</li><li>支持 CPU、GPU、VPU、GNA 和 HDDL 设备。</li></ul></li><li>新的 <a href="https://quay.io/repository/openvino/rhel8_runtime" rel="nofollow">RHEL8 运行时 Docker 镜像</a>在 Red Hat <a href="http://quay.io/" rel="nofollow">Quay.io</a> 容器注册表中可用，并支持 CPU、GPU 插件。 
    <ul><li>包括推理引擎和 OpenCV。</li><li>支持 CPU 和 GPU 设备。</li></ul></li><li>新的 <a href="https://github.com/openvinotoolkit/docker_ci/tree/master/dockerfiles/ubuntu18/build_custom">Dockerfile</a> 可使用 OpenCV 和适用于 Ubuntu 18.04 的 Open Model Zoo，从源构建推理引擎。</li></ul></li></ul> 
<h3>第 2 版发布中的更新和更改<a id="inpage-nav-2"></a></h3> 
<h4>要点综述<a id="inpage-nav-2-undefined"></a></h4> 
<ul><li>将深度学习工作台与英特尔® DevCloud for the Edge 集成以构成 Beta 版本。使用英特尔® DevCloud for the Edge 上的深度学习工作台（而不是仅本地计算机）以图形方式分析模型，从而针对多个远程硬件配置进行解决方案的比较、可视化和微调。</li><li>推出对 Red Hat Enterprise Linux (RHEL) 8.2 的支持。有关更多信息，请参阅<a href="https://software.intel.com/content/www/cn/zh/develop/tools/openvino-toolkit/system-requirements.html" rel="nofollow">系统要求</a>。 运行时包<a href="https://storage.openvinotoolkit.org/repositories/openvino/packages/2021.2/l_openvino_toolkit_runtime_rhel8_p_2021.2.185.tgz" rel="nofollow">可供</a>下载。</li><li>在模型优化器中为通过 TensorFlow 量化感知训练进行了量化的模型推出每通道量化支持（包括权重的每通道量化），通过模型压缩和延迟减少提高了性能。</li><li>预训练模型和对公共模型的支持，以简化开发： 
  <ul><li><em>公共模型：</em>Yolov4（用于对象检测）、AISpeech（用于语音识别）和 DeepLabv3（用于语义分割）</li><li><em>预训练模型：</em>人体姿势估计（更新）、公式识别多项式手写体（新增）、机器翻译（更新）、通用手语识别（新增）和文本语音转换（新增）</li></ul></li><li>全新的 OpenVINO™ 安全插件，通过安全封装和执行来控制对模型的访问。这款全新插件基于 KVM 虚拟机和 Docker* 容器，与 OpenVINO™ 模型服务器兼容，可进行封装以实现灵活部署和受控的模型访问。</li><li><a href="https://pypi.org/project/openvino-python/" rel="nofollow">PyPI</a> 项目从 <a href="https://pypi.org/project/openvino-python/" rel="nofollow">openvino-python</a> 迁移到 <a href="https://pypi.org/project/openvino" rel="nofollow">openvino</a>，2021.1 版将从默认视图中移除。通过使用 <strong>openvino-python==2021.1</strong>，依赖于该特定版本的用户将仍然可以使用该版本。</li></ul> 
<h4>模型优化器<a id="inpage-nav-2-1"></a></h4> 
<p><a href="http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html" rel="nofollow">模型优化器</a></p> 
<p>常见的变更<a id="inpage-nav-2-1-undefined"></a></p> 
<ul><li>更新了对 NumPy 组件的要求，以避免与 TensorFlow 1.x 产生兼容性问题。</li><li>借助 Eltwise 和 CTCGreedyDecoder 运算，改进了模型的重塑能力</li></ul> 
<p>ONNX*<a id="inpage-nav-2-1-1"></a></p> 
<ul><li>已支持使用“ --output”命令行参数指定模型输出<strong>张量</strong>名称的功能。</li><li>增加了对以下操作的支持： 
  <ul><li>Acosh</li><li>Asinh</li><li>Atanh</li><li>DepthToSpace-11、13</li><li>DequantizeLinear-10（zero_point 必须为常数）</li><li>HardSigmoid-1,6</li><li>QuantizeLinear-10（zero_point 必须为常数）</li><li>RedueL1-11、13</li><li>RedueL2-11、13</li><li>Resize-11, 13（除了mode="nearest"（5D+输入），mode="tf_crop_and_resize"，以及属性 exclude_outside 和 exclude_outside 使用非零值）。</li><li>ScatterND-11、13</li><li>SpaceToDepth-11、13</li></ul></li></ul> 
<p>TensorFlow*<a id="inpage-nav-2-1-2"></a></p> 
<ul><li>增加了在调整图像大小之前应用平均/刻度值时，对使用预处理块的 TensorFlow Object Detection API 模型的支持。此前仅支持在调整大小之后应用平均/标度值的情况。</li><li>将采用 FakeQuantize 方法的限值调整与 TensorFlow 方法保持一致</li><li>增加了对以下操作的支持： 
  <ul><li>GatherND</li><li>Round</li><li>NonMaxSuppression</li><li>LogSoftmax</li><li>FakeQuantWithMinMaxVarsPerChannel</li></ul></li></ul> 
<p>MXNet*<a id="inpage-nav-2-1-3"></a></p> 
<ul><li>增加了对以下操作的支持： 
  <ul><li>GatherND</li><li>Round</li></ul></li></ul> 
<p>Kaldi*<a id="inpage-nav-2-1-4"></a></p> 
<ul><li>增加了对以下操作的支持： 
  <ul><li>TdnnCompontent</li></ul></li></ul> 
<h4>推理引擎<a id="inpage-nav-2-2"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html" rel="nofollow">推理引擎</a></p> 
<p>常见变更<a id="inpage-nav-2-2-undefined"></a></p> 
<ul><li>移除了 inference_engine_legacy 上的依赖项。自 2021.2 版起，客户的应用程序不直接链接 inference_engine_legacy。inference_engine_legacy 直接通过插件链接。 </li><li>增加了对具有外部数据文件的 ONNX 模型读取的支持。要读取这些模型，仅需要将 core.ReadNetwork() 方法传入到 ONNX 模型中，外部数据文件将会自动找到并加载。</li><li>对于 ONNX 读取器，检测受支持模型的逻辑有所改进。</li><li>ONNX 依赖项已更新为 v1.7.0</li><li>增加了对 ONNX 函数的支持（运算符列表底部 <a href="https://github.com/onnx/onnx/blob/v1.7.0/docs/Operators.md">https://github.com/onnx/onnx/blob/v1.7.0/docs/Operators.md</a>）</li><li>改进了有关在 ONNX 载入器中注册自定义运算的文档和示例</li><li> <p>setBatchSize 方法现已迁移到重塑方法逻辑中，以更新模型的输入形状。此外，它还应用了对模型中的某些不可重塑模式进行松弛的智能重塑转换。现在可以对同一模型使用 setBatchSize 和重塑方法，不会导致先前版本中的未定义行为。</p> </li><li> <p>在 Windows 平台上，推理引擎库在文件属性中拥有新的“详细信息”部分。该部分包含有关动态链接库 (DLL) 的信息，包括库的描述和版本。</p> </li></ul> 
<p>废弃 API<a id="inpage-nav-2-2-1"></a></p> 
<ul><li>ExecutableNetwork::QueryState 方法被 InferRequest::QueryState 方法取代，旧方法被废弃。</li><li>IVariableState::GetLastState 方法更名为 IVariableState::GetState，旧名称被废弃</li><li> <p>IMemoryState 更名为 IVariableState，旧名称仍可使用，但不推荐</p> </li></ul> 
<p>CPU 插件<a id="inpage-nav-2-2-2"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_CPU.html" rel="nofollow">CPU 插件</a></p> 
<ul><li>增加了对新运算的支持： 
  <ul><li>Loop-5</li><li>Round-5</li><li>NonMaxSuppression-3, NonMaxSuppression-5</li><li>HSigmoid-5</li><li>LogSoftmax-5</li><li>GatherND-5</li></ul></li><li>为 CTCLoss、Pad、Permute 和 Elementwise 运算实施了多项优化。这些优化改进了客户模型上的 CPU 性能，大幅提高了 Open Model Zoo 范围内的整体性能几何平均值。</li><li>增加了对动态输入的 I64/U64 数据类型的支持（通过到 I32 的内部转换）。</li><li>改进了状态 API，现在可以用于具有多个并行推理请求的应用程序： 
  <ul><li>修复了 IVariableState::GetName() 方法的 MKLDNN 插件实施，现在返回变量 ID</li><li>在 MKLDNN 插件中增加了对 IVariableState::GetState 的支持</li></ul></li></ul> 
<p>GPU 插件<a id="inpage-nav-2-2-3"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_CL_DNN.html" rel="nofollow">GPU 插件</a></p> 
<ul><li>支持英特尔锐炬® Xe MAX 显卡（原代号为 DG1） </li><li>增加了对以下操作的支持： 
  <ul><li>HSigmoid-5</li><li>Round-5</li><li>LogSoftMax-5</li></ul></li><li>通过非对称量化改进了 int8 卷积的性能</li><li>增加了插件侧的编译内核缓存机制，可使用它代替驱动程序中的 cl_cache。</li></ul> 
<p>MYRIAD 插件<a id="inpage-nav-2-2-4"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_MYRIAD.html" rel="nofollow">MYRIAD 插件</a></p> 
<ul><li>增加了针对新操作的支持： 
  <ul><li>HSwish</li><li>GatherND</li><li>Interpolate</li><li>Ceil</li></ul></li><li>为 Broadcast 运算增加了“双向”模式。</li><li>为 Proposal 运算增加了第二个可选输出。</li><li>改善了现有操作的性能： 
  <ul><li>Mish</li><li>Swish</li><li>NonMaxSuppression</li></ul></li></ul> 
<p>HDDL 插件<a id="inpage-nav-2-2-5"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_HDDL.html" rel="nofollow">HDDL 插件</a></p> 
<ul><li>与 MYRIAD 插件中相同的新操作和优化。</li><li>为 ION 驱动程序启用了对 Linux 内核 5.4 的支持。</li></ul> 
<p>GNA 插件<a id="inpage-nav-2-2-6"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_GNA.html" rel="nofollow">GNA 插件</a></p> 
<ul><li>模型导出现在可保存层名称，因此可以在导入之后再次使用。</li><li>修复了某些层组合。</li></ul> 
<h4>nGraph<a id="inpage-nav-2-3"></a></h4> 
<ul><li>推出了 opset5。全新 opset 包含以下全新操作。并非所有 OpenVINO™ 工具套件插件都支持这些操作。 
  <ul><li>BatchNormInference-5</li><li>GRUSequence-5</li><li>RNNSequence-5</li><li>LSTMSequence-5</li><li>Loop-5</li><li>Round-5</li><li>NonMaxSuppression-5</li><li>HSigmoid-5</li><li>LogSoftmax-5</li></ul></li><li>实施了公共 nGraph 转换： 
  <ul><li>LowLatency<br> 转换展开了 TensorIterator 节点，以在低延迟下对其进行逐步推理，每次推理运算中均存储状态。 转换将迭代次数更改为 1，并使用 ReadValue 和 Assign 运算代替后向边（例如，RNN 状态输入和输出）。 可对 CPU 和 GNA 插件进行该转换。</li></ul></li><li>公共 nGraph API 变更： 
  <ul><li> <p>推出 Sink 类以方便识别属于图形中的“Sinks”（未被任何其他节点使用的节点）的运算。通过“添加/移除 Sinks”的方法扩展了 nGraph Function API。目前，只有 Assign 节点继承自 Sync 类，Result 节点是单独存储的特殊节点，并不是 Sinks。</p> </li></ul></li><li>在与英特尔® Distribution of OpenVINO™ toolkit 集成之前持续清理 nGraph 原始代码库，可移除该工具套件不支持的传统运算。</li></ul> 
<h4>神经网络压缩框架 (NNCF)<a id="inpage-nav-2-4"></a></h4> 
<ul><li>对于单级对象检测的情况，将 NNCF 与 OTE/mmdetection 集成。</li><li>发布了面向 PyTorch 的 NNCF v1.5： 
  <ul><li>切换了默认情况下设置的量化器基于传播的模式（与硬件配置更好集成）。</li><li>对 HAWQ 混合精度量化算法实施了改进：压缩比参数支持、激活量化器位宽选择、更通用的损失计算方法。</li><li>通过视觉处理器硬件配置为 EltWise 提供统一标度支持。</li><li>启用了 GPT2 压缩，在受支持的模型列表中增加了修剪后的 googlenet-v1。</li><li>有关功能的详细信息和完整列表，请参阅 <a href="https://github.com/openvinotoolkit/nncf_pytorch/blob/master/ReleaseNotes.md">NNCF 发布说明</a>。</li></ul></li></ul> 
<h4>训练后优化工具<a id="inpage-nav-2-5"></a></h4> 
<p><a href="http://docs.openvinotoolkit.org/latest/_README.html" rel="nofollow">训练后优化工具</a></p> 
<ul><li>在 POT 配置中引入了模型预设，特别是 Transformer 模型的预设，使 POT 用户可以更轻松地量化这些模型。</li><li>改进了 POT 文档，包括量化示例。增加了《常见问题解答》文档。 </li><li>扩大了模型覆盖范围：额外启用了45 个模型。</li></ul> 
<h4>深度学习工作台<a id="inpage-nav-2-6"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_Workbench_DG_Introduction.html" rel="nofollow">深度学习工作台</a></p> 
<ul><li>发行版：深度学习工作台现在可在英特尔® DevCloud for the Edge 中使用</li><li>增加了对用于风格迁移、超级分辨率和图像修复用例的 GAN 模型的支持 </li><li>增加了以 CSV 格式导出分析实验结果的功能</li></ul> 
<h4>OpenCV*<a id="inpage-nav-2-7"></a></h4> 
<ul><li>将版本更新至 4.5.1。</li><li>在 VideoCapture API 的 Media SDK (MFX) 后端增加了对宽度/高度属性的支持。</li><li>G-API：为推理和流 API 增加了更多 CV 运算和Python 绑定，并为媒体格式支持引入了 MediaFrame 数据类型（例如 NV12）。</li></ul> 
<h4>示例<a id="inpage-nav-2-8"></a></h4> 
<ul><li>语音样本命令行参数中的输入层（用于输入数据文件）和输出层（用于输出和参考文件）顺序现在可以使用新的命令行参数（-iname 和 -oname）明确指定。</li></ul> 
<h4>Open Model Zoo<a id="inpage-nav-2-9"></a></h4> 
<ul><li> <p>使用额外的 CNN 预训练模型和预生成的中间表示 (<code>.xml</code> + <code>.bin</code>) 扩展了 Open Model Zoo：</p> 
  <ul><li> <p>替换了 2021.1 模型：</p> 
    <ul><li>text-spotting-0003-detector</li><li>text-spotting-0003-recognizer-decoder</li><li>text-spotting-0003-recognizer-encoder</li></ul></li><li>已添加新模型： 
    <ul><li>bert-small-uncased-whole-word-masking-squad-int8-0002</li><li>bert-small-uncased-whole-word-masking-squad-emb-int8-0001</li><li>formula-recognition-polynomials-handwritten-0001-decoder</li><li>formula-recognition-polynomials-handwritten-0001-encoder</li><li>handwritten-simplified-chinese-recognition-0001</li><li>human-pose-estimation-0002</li><li>human-pose-estimation-0003</li><li>human-pose-estimation-0004</li><li>person-detection-0003</li></ul></li><li>最终模型： 
    <ul><li>bert-large-whole-word-masking-squad-fp32-0001 renamed to bert-large-uncased-whole-word-masking-squad-0001</li></ul></li></ul></li><li> <p>对以下模型的支持扩展了公有模型列表：</p> 
  <table><thead><tr><th> <p>模型名称</p> </th><th colspan="1"> <p>任务</p> </th><th colspan="1"> <p>框架</p> </th></tr></thead><tbody><tr><td> <p>anti-spoof-mn3</p> </td><td colspan="1">分类</td><td colspan="1"> <p>PyTorch</p> </td></tr><tr><td colspan="1">cocosnet</td><td colspan="1">图像翻译</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">colorization-v2</td><td colspan="1">图像处理</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">colorization-siggraph</td><td colspan="1">图像处理</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">common-sign-language-0001</td><td colspan="1">分类</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">efficientdet-d0-tf</td><td colspan="1">物体检测</td><td colspan="1">TensorFlow</td></tr><tr><td colspan="1">efficientdet-d1-tf</td><td colspan="1">物体检测</td><td colspan="1">TensorFlow</td></tr><tr><td colspan="1">forward-tacotron-duration-prediction</td><td colspan="1">文字转语音</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">forward-tacotron-regression</td><td colspan="1">文字转语音</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">fcrn-dp-nyu-depth-v2-tf</td><td colspan="1">深度估计</td><td colspan="1">TensorFlow</td></tr><tr><td colspan="1">hrnet-v2-c1-segmentation</td><td colspan="1">语义分割</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">mozilla-deepspeech-0.8.2</td><td colspan="1">语音识别</td><td colspan="1">TensorFlow</td></tr><tr><td colspan="1">shufflenet-v2-x1.0</td><td colspan="1">分类</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">wavernn-rnn</td><td colspan="1">文字转语音</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">wavernn-upsampler</td><td colspan="1">文字转语音</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">yolact-resnet50-fpn-pytorch</td><td colspan="1">实例分割</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">yolo-v4-tf</td><td colspan="1">物体检测</td><td colspan="1">TensorFlow</td></tr></tbody></table></li><li> <p>用着色模型的 PyTorch 变体来取代该模型的旧的 Caffe 变体。</p> 
  <ul><li>增加了新的演示应用：</li><li>Python gesture_recognition_demo（代替 asl_recognition_demo）</li><li>Python human_pose_estimation_demo（支持新的 human-pose-estimation-0002/3/4 模型）</li><li>Python image_translation_demo</li><li>Python text to speech demo</li><li>Python object_detection_demo（代替 object_detection_demo_centernet、object_detection_demo_faceboxes、object_detection_demo_retinaface、object_detection_demo_ssd_async 和 object_detection_demo_yolov3_async）</li><li>C++ object_detection_demo（替换 object_detection_demo_ssd_async 和 object_detection_demo_yolov3_async）</li></ul></li><li> <p>移除了已废弃的 object_detection_demo_faster_rcnn。</p> </li><li> <p>Open Model Zoo 工具：</p> 
  <ul><li>通过支持自定义预转化脚本扩展了 Model Converter，简化了非冻结模型图的转化。</li><li>通过覆盖新的任务（基于图像的定位、显著图检测、光流估计、DNA 测序），扩展了 Accuracy Checker。</li><li>增加了在 Accuracy Checker 中设置输入精度和获取中间指标结果的命令行选项。</li><li>改进了在 Accuracy Checker 中对 GAN 模型的处理，扩展了后处理，增加了新的指标（Inception Score 和<strong> </strong>Frechet Inception Distance）。</li><li>需要使用 Tensorflow 2.3 转换 efficientdet-d0/d1 模型。</li></ul></li></ul> 
<h4>深度学习流媒体播放器<a id="inpage-nav-2-10"></a></h4> 
<ul><li><strong>直接支持 ONNX 模型</strong>：DL Streamer gvadetect、gvaclassify 和 gvainference 元素现在将支持 CPU 上的 OpenVINO™ 推理引擎支持的 ONNX 模型，无需转换为中间表示 (IR) 格式。</li><li><strong>基于全帧和 ROI 的推理</strong>：对于连续检测和全帧分类等用例，在 gvadetect、gvaclassify 和 gvainference 元素中增加的新属性 'inference-region' 将使开发人员能够在全帧或 ROI（感兴趣区域）上运行推理。</li><li><strong>无图像对象跟踪</strong>：在 gvatrack 中引入两个新算法 'short-term imageless' 和 'zero-term imageless'，将能在不访问图像数据的情况下跟踪对象。 </li><li><strong>Docker 文件更新：</strong>使用 DL Streamer GitHub 中的 Docker 文件创建的文件夹结构与 OpenVINO™ 在 DockerHub* 上发布的 Docker 映像一致。无论选择哪种发行方式（OpenVINO Installer、OpenVINO Docker 映像、DL Streamer Docker 文件、从源构建），开发人员现在都可以按照相同的说明和准则使用 DL Streamer。</li></ul> 
<p>有关 DL Streamer 的更多信息，请参阅位于 GitHub 上的 DL Streamer 开源项目存储库<a href="https://github.com/openvinotoolkit/dlstreamer_gst">“openVINO™ 工具套件 - DL Streamer”</a>中的 DL Streamer 教程、API 参考和样本。还可访问<a href="https://docs.openvinotoolkit.org/latest/gst_samples_README.html" rel="nofollow">“DL Streamer 样本”</a>查看样本文档。</p> 
<h4>OpenVINO™ 模型服务器<a id="inpage-nav-2-11"></a></h4> 
<p><a href="https://github.com/openvinotoolkit/model_server">模型服务器</a></p> 
<ul><li><strong>有向无环图 (DAG) 调度程序</strong> -（以前为 `models ensemble`）该功能首次在 2021.1 版中以预览版的形式提供。现在它已得到官方支持，从而使定义由响应单个预测请求的多个互联模型组成的推理管道成为可能。在该版本中，我们增加了对其余 API 调用（预览版中的 DAG 不支持）的支持，特别是 `GetModelStatus` 和 `GetModelMetadata`。`GetModelStatus` 返回整个管道的状态，而 GetModelMetadata 返回管道输入和输出参数。新的 2021.2 版改进了 DAG 配置验证。</li><li><strong>直接导入 ONNX 模型</strong> - 现在可以导入 ONNX 模型，无需转换为中间表示 (IR) 格式。这有助于利用 ONNX 模型和 PyTorch 训练框架简化部署。</li><li><strong>自定义加载器以及与 OpenVINO™ 安全插件的集成</strong> - 现在可以定义自定义库，用于处理模型加载操作 - 包括与模型解密和许可证验证有关的额外步骤。要了解有关模型保护的信息，请查看<a href="https://docs.openvinotoolkit.org/latest/ovsa/ovsa_get_started.html" rel="nofollow">安全插件</a>组件的文档。</li><li><strong>流量</strong><strong>加密</strong> - 新的部署配置<strong>通过 mTLS 证书进行客户端授权，</strong>通过与 Docker 容器中的 NGINX 反向代理集成进行流量加密。 </li><li><strong>从云存储进行远程模型缓存</strong> - 进行需要重新加载模型的配置变更后，不再多次下载存储在 Google Cloud Storage (GCS)、Amazon S3 和 Azure blob 中的模型。在模型重新加载操作期间，将使用缓存的模型。更改服务的模型时，将仅在模型存储中添加相应的新版本文件夹。</li></ul> 
<h4>OpenVINO™ 安全插件<a id="inpage-nav-2-12"></a></h4> 
<p><a href="http://github.com/openvinotoolkit/security_addon">OpenVINO™ 安全插件</a></p> 
<p>该安全插件是一组工具，让模型开发人员能够使用 <a href="https://github.com/openvinotoolkit/model_server">OpenVINO™ 模型服务器</a>控制开发后对模型的访问，并检查在受控环境中运行期间对模型的访问。它由定义模型访问控制的一组开发工具、在将模型加载到模型服务器之前检查模型许可证的许可服务、位于 OpenVINO™ 模型服务器内的可在其中执行访问受控模型的隔离环境组成。</p> 
<p><strong> 安全插件的关键功能</strong></p> 
<ul><li>定义开发后对模型的访问控制。</li><li>生成限制模型使用天数的客户特定许可证。</li><li>在将模型加载到 OpenVINO™ 模型服务器之前检查许可证的有效性。</li><li>使用 OpenVINO™ 模型服务器，通过 KVM 虚拟机在隔离环境中执行模型。</li><li>通过 NGINX 控制应用程序对模型的访问。</li></ul> 
<h3>第 1 版发布中的更新和更改<a id="inpage-nav-3"></a></h3> 
<h4>要点综述<a id="inpage-nav-3-undefined"></a></h4> 
<ul><li>2020 年 10 月<strong>重要</strong>发布（2021 年版） 此版本推出了重要的全新功能，以及突破性更新和向后不兼容的修改，强烈建议您升级到此版本。 </li><li><strong>支持 TensorFlow 2.2.x</strong> 为在 TensorFlow 2.2.x 框架中训练的模型提供官方支持。</li><li><strong>支持最新硬件。</strong> 为面向物联网 (IoT) 应用程序的第十一代智能英特尔® 酷睿™ 处理器家族（原代码 Tiger Lake）提供官方支持，包括采用英特尔锐炬® Xe 显卡和英特尔® 深度学习加速指令实现全新推理性能增强，以及采用英特尔® Gaussian &amp; Neural Accelerators 2.0 实现低功耗语音处理加速。</li><li><strong>突破视觉极限。</strong> 支持端到端功能，以使用英特尔® Distribution OpenVINO™ 工具套件，该工具套件用于计算机视觉以外的工作负载，包括音频、语音、语言和推荐，并提供全新预训练模型，支持公共模型、代码样本和演示，以及 OpenVINO™ 工具套件中的非视觉工作负载。</li><li><strong>将于 2020 年第四季度发布：（测试版）集成 DL Workbench 和英特尔® DevCloud for the Edge。</strong> 开发人员现在可以使用英特尔® DevCloud for Edge 上的深度学习工作台（而不仅是本地计算机）以图形方式分析模型，针对多个远程硬件配置比较、可视化和微调解决方案。</li><li><strong><a href="https://github.com/openvinotoolkit/model_server/releases/tag/v2021.1">OpenVINO™ 模型服务器</a>。 </strong>英特尔® Distribution of OpenVINO™ toolkit 的附加组件和可扩展微服务提供了用于推理的 GRPC 或 Http/REST 端点，从而更易于将模型部署在云或边缘服务器环境中。现在，它通过 C++ 实施以减少容器占用的空间（例如，少于 500 MB），并提供更高的吞吐量和更低的延迟。</li><li>现在<strong>可以</strong>通过 <a href="https://gitee.com/openvinotoolkit-prc/" rel="nofollow">Gitee</a>* 和 <a href="https://pypi.org/project/openvino-python/" rel="nofollow">PyPI</a>* 分发方式获得。我们建议您从分发方式和下载中<a href="https://software.intel.com/content/www/cn/zh/develop/tools/openvino-toolkit/download.html" rel="nofollow">选择</a>。 </li></ul> 
<h4>与 2020.4 相比，向后不兼容的修改<a id="inpage-nav-3-1"></a></h4> 
<ul><li><a href="https://docs.openvinotoolkit.org/2020.4/deprecated.html" rel="nofollow">废弃 API 列表</a>，<a href="https://docs.openvinotoolkit.org/2020.4/_docs_IE_DG_API_Changes.html" rel="nofollow">API 变更</a></li><li>IRv7 自 2020.3 年版以来已被废弃，此版本不再受支持。您无法读取 IRv7 和较低版本的 Core:ReadNetwork，建议更新至最高版本 IRv10。IRv10 提供了简化且面向未来的操作组，该操作组与公共框架保持一致，并更好地支持低精度模型，以便在量化模式下运行时保持准确性，并支持可重塑模型。</li><li>推理引擎 NNBuilder API 已被移除。建议使用 nGraph 作为替代品，从 C++ 代码创建 CNN 图形。</li><li>以下推理引擎的公共 API 已移除： 
  <ul><li>InferencePlugin、IInferencePlugin 和 InferencEnginePluginPtr 类。请使用 <a href="https://docs.openvinotoolkit.org/2020.3/classInferenceEngine_1_1Core.html" rel="nofollow">Core</a> 类作为替代。</li><li>PluginDispatcher 类。请使用 <a href="https://docs.openvinotoolkit.org/2020.3/classInferenceEngine_1_1Core.html" rel="nofollow">Core</a> 类作为替代。</li><li>CNNNNetReader 类。请使用 <a href="https://docs.openvinotoolkit.org/2020.3/classInferenceEngine_1_1Core.html#a5e4d336b97e354f0d13e3b7a30f55df6" rel="nofollow">Core::ReadNetwork</a> 作为替代。</li><li>PrimitiveInfo、TensorInfo 和 ExecutableNetwork::GetMappedTopology。请使用 <a href="https://docs.openvinotoolkit.org/latest/classInferenceEngine_1_1ExecutableNetwork.html#a00db8bf2706042fb616e0f6683c6a847" rel="nofollow">ExecutableNetwork::GetExecGraphInfo</a> 作为替代。</li><li>ICNNNetworkStats、NetworkNodeStats、CNNNetwork::getStats 和 CNNNetwork::setStat。使用采用了 FankeQuantze 方法的 IRv10 作为 INT8流的替代品。</li><li>IShapeInferExtension 和 CNNNetwork::addExtension。将 IExtension 系列用作 nGraph::Nodes 的容器，供其实施形状推理。</li><li>来自推理引擎 Python API 的 IEPlugin。使用 Core API 作为替代。</li><li>Data::getCreatorLayer、Data::getInputTo 和 CNNLayer。使用 CNNNetwork:getFunction 来使图形发生迭代。</li></ul></li><li>从OpenVINO™ 工具套件 2020.2 版开始，此前通过 nGraph 提供的所有功能已合并至 OpenVINO™ 工具套件。因此，此前通过 ONNX RT Execution Provider for nGraph 提供的所有功能都已合并至 ONNX RT Execution Provider for OpenVINO™ 工具套件。因此，ONNX RT Execution Provider for nGraph 将于 2020 年 6 月 1 日起弃用，并于 2020 年 12 月 1 日完全移除。将迁移至 ONNX RT Execution Provider for the OpenVINO™ 工具套件，作为英特尔® 硬件人工智能推断的统一解决方案。</li><li>以下 nGraph 公共 API 将被弃用或移除： 
  <ul><li>已移除在早期版本中弃用的 nGraph 方法和类。</li><li>GetOutputElement 操作已移除。</li><li>copy_with_new_args() 已替换为 clone_with_new_inputs()。</li><li>opset0 和反向传播操作已移除。</li><li>opset0 中部分操作已移除，opset 中废弃操作已移除，上述废弃操作未在较新版本的 opset 中使用。</li><li>已移除对 JSON 格式的序列化 nGraph 函数的支持。</li><li>FusedOp 已弃用。</li></ul></li><li>nGraph 公共 API 的结构已更改。nGraph 构建器和参考实现已从 nGraph 公共 API 中移除。已合并具有融合和实验性操作的子文件夹及通用操作目录。</li><li>系统要求已更改。请查看以下部分。</li><li>英特尔® 将过渡到基于 FPGA 的下一代可编程深度学习解决方案，以提高 FPGA 深度学习的自定义水平。作为此过渡的一部分，未来标准的英特尔® Distribution of OpenVINO™ toolkit 的标准版本（非 LTS 版）将不再包含搭载英特尔® Arria® 10 FPGA 的英特尔® Vision Accelerator Design，以及搭载英特尔® Arria® 10 GX FPGA 的英特尔® Programmable Acceleration Card。英特尔® Distribution of OpenVINO™ toolkit 2020.3.X LTS 版将继续支持搭载英特尔® Arria® 10 FPGA 的英特尔® Vision Accelerator Design，以及搭载英特尔® Arria® 10 GX FPGA 的英特尔® Programmable Acceleration Card。有关基于 FPGA 的下一代可编程深度学习解决方案的问题，请与您的销售代表联系或<a href="https://plan.seek.intel.com/psg_WW_psgao3_LPCS_EN_2020_OpenVinoforFPGAs" rel="nofollow">联系我们</a>来获取最新的 FPGA 更新。</li></ul> 
<h4>模型优化器<a id="inpage-nav-3-2"></a></h4> 
<p><a href="http://docs.openvinotoolkit.org/latest/_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html" rel="nofollow">模型优化器</a></p> 
<p>常见的变更<a id="inpage-nav-3-2-undefined"></a></p> 
<ul><li>实施了多项优化转型，以 HSwish、Mish、Swish 和 SoftPlus 操作取代操作子图。</li><li><strong>默认情况下，</strong>模型优化器生成 IR 并保持形状计算子图 先前，如果提供 "--keep_shape_ops"命令行参数，则会触发该行为。该密钥在此版本中被忽略，并将在下一个版本中删除。要触发传统行为以生成固定输入形状的 IR（将操作和形状计算子图折叠为常量），请使用“--static_-shape”命令行参数。对于此类 IR，在运行时使用 Inference Engine API 更改模型输入形状可能会失败。</li><li>已修复模型优化器转换问题导致使用推理引擎重塑 API 引发不可重塑的 IR。</li><li>已启用转换，以修复原始网络中的不可重塑模式： 
  <ul><li>硬编码重塑 
    <ul><li>在 Reshape(2D)-&gt; MatMul 模式中</li><li>当模式可以融合至 ShuffleChannels 或 DepthToSpace 操作时，Reshape-&gt;Transpose-&gt;Reshape</li></ul></li><li>硬编码插值 
    <ul><li>在 Interpolate-&gt;Concat 模式中</li></ul></li></ul></li><li>为 TensorFlow 2.X 添加了专用需求文件，以及专用的安装先决条件脚本。</li><li>使用 ScadterNDUpdate-4 替换了 SparseToDense 操作。</li></ul> 
<p>ONNX*<a id="inpage-nav-3-2-1"></a></p> 
<ul><li>已支持使用“ --output”命令行参数指定模型输出<strong>张量</strong>名称的功能。</li><li>增加了对以下操作的支持： 
  <ul><li>Acosh</li><li>Asinh</li><li>Atanh</li><li>DepthToSpace-11、13</li><li>DequantizeLinear-10（zero_point 必须为常数）</li><li>HardSigmoid-1,6</li><li>QuantizeLinear-10（zero_point 必须为常数）</li><li>RedueL1-11、13</li><li>RedueL2-11、13</li><li>Resize-11, 13（除了mode="nearest"（5D+输入），mode="tf_crop_and_resize"，以及属性 exclude_outside 和 exclude_outside 使用非零值）。</li><li>ScatterND-11、13</li><li>SpaceToDepth-11、13</li></ul></li></ul> 
<p>TensorFlow*<a id="inpage-nav-3-2-2"></a></p> 
<ul><li>增加了对以下操作的支持： 
  <ul><li>Acosh</li><li>Asinh</li><li>Atanh</li><li>CTCLoss</li><li>EuclideanNorm</li><li>ExtrationImagePatches</li><li>FloorDiv</li></ul></li></ul> 
<p>MXNet*<a id="inpage-nav-3-2-3"></a></p> 
<ul><li>增加了对以下操作的支持： 
  <ul><li>Acosh</li><li>Asinh</li><li>Atanh</li></ul></li></ul> 
<p>Kaldi*<a id="inpage-nav-3-2-4"></a></p> 
<ul><li>修复了 ParallelComponent 支持的错误。目前已得到完全支持，不存在任何限制。</li></ul> 
<h4>推理引擎<a id="inpage-nav-3-3"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Deep_Learning_Inference_Engine_DevGuide.html" rel="nofollow">推理引擎</a></p> 
<p>常见变更<a id="inpage-nav-3-3-undefined"></a></p> 
<ul><li>迁移到 Windows 默认的 Microsoft Studio c++ (MSVC) 2019 编译器，可帮助您将 OpenVINO™ 运行时的二进制大小减小 2.5 倍。请查看<a href="https://software.intel.com/content/www/cn/zh/artificial-intelligence/posts/openvino-reduce-app-footprint.html" rel="nofollow">借助英特尔® Distribution of OpenVINO™ toolkit 中的最新功能来减少应用程序占</a>用空间，以了解详情</li><li>请参阅<strong>与 2020.4 相比弃用消息和向后不兼容的更改</strong>章节，以了解 API 的详细更改。</li><li>将基于 CPU 的预处理路径（即针对不同数量的通道、布局转换和颜色空间转换的调整）移植至 AVX2 和 AVX512 指令集。</li></ul> 
<p>推理引擎 Python API<a id="inpage-nav-3-3-1"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/ie_python_api/annotated.html" rel="nofollow">推理引擎 Python API</a></p> 
<ul><li>启用了 nGraph Python API，该 API 允许使用 Python 与 nGraph 函数进行通信。这可支持对已加载图形进行分析。</li><li>已启用图形节点的设置参数。 </li><li>已启用使用 Python API 读取 ONNX 模型。</li></ul> 
<p>推理引擎 C API<a id="inpage-nav-3-3-2"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/ie_c_api/modules.html" rel="nofollow">推理引擎 C API</a></p> 
<ul><li>无变更</li></ul> 
<p>CPU 插件<a id="inpage-nav-3-3-3"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_CPU.html" rel="nofollow">CPU 插件</a></p> 
<ul><li>改进了使用 MSVC 编译器构建的 CPU 插件的性能，使其与使用英特尔® 编译器构建的版本保持一致，从而支持将 MSVC 用作 Windows 上二进制分发的默认编译器。此更改使 CPU 插件和其他组件的二进制大小减少了 2 倍以上。请查看<a href="https://software.intel.com/content/www/cn/zh/artificial-intelligence/posts/openvino-reduce-app-footprint.html" rel="nofollow">借助英特尔® Distribution of OpenVINO™ toolkit 中的最新功能来减少应用程序占</a>用空间，以了解详情</li><li>增加了针对新操作的支持： 
  <ul><li>ScatterUpdate-3</li><li>ScatterElementsUpdate-3</li><li>ScatterNDUpdate-3</li><li>Interpolate-4</li><li>CTC-Loss-4</li><li>Mish-4</li><li>HSwish-4</li></ul></li></ul> 
<p>GPU 插件<a id="inpage-nav-3-3-4"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_CL_DNN.html" rel="nofollow">GPU 插件</a></p> 
<ul><li>为面向物联网 (IoT) 应用程序的第十一代智能英特尔® 酷睿™ 处理器家族（原代码 Tiger Lake）提供官方支持 </li><li>支持基于英特尔® 深度学习加速的集成显卡优化的 INT8 推理管道。</li><li>支持新操作： 
  <ul><li>Mish</li><li>Swish</li><li>SoftPlus</li><li>HSwish</li></ul></li></ul> 
<p>MYRIAD 插件<a id="inpage-nav-3-3-5"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_MYRIAD.html" rel="nofollow">MYRIAD 插件</a></p> 
<ul><li>针对具有固定输入形状和动态输出形状的 ONNX Faster R-CNN 添加了支持。</li><li>为自定义 OpenCL 层添加了针对 automatic-DMA 的支持。</li><li>增加了针对新操作的支持： 
  <ul><li>Mish</li><li>Swish</li><li>SoftPlus</li><li>Gelu</li><li>StridedSlice</li><li>在 Div 中支持 I32 数据类型</li></ul></li><li>改善了现有操作的性能： 
  <ul><li>ROIAlign</li><li>Broadcast</li><li>GEMM</li></ul></li><li>在 myriad_compile 中添加了新选项 VPU_TILING_CMX_LIMIT_KB，可限制 DMA 事务的规模。</li><li>OpenCL 编译器与 OpenVINO 一起再次分发，仅针对面向 SHAVE* 处理器的英特尔® 神经电脑棒 2。OpenCL 支持由 ComputeAorta* 提供，并在英特尔® 和 Codeplay* Software Ltd 之间的许可协议下进行分发。</li></ul> 
<p>HDDL 插件<a id="inpage-nav-3-3-6"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_HDDL.html" rel="nofollow">HDDL 插件</a></p> 
<ul><li>支持自定义 OpenCL 层的 automatic-DMA。</li><li>与 MYRIAD 插件中相同的新操作和优化。</li><li>OpenCL 编译器与 OpenVINO 一起再次分发，仅针对面向 SHAVE* 处理器的英特尔® Vision Accelerator Design 和英特尔® Movidius™ 视觉处理器组合。OpenCL 支持由 ComputeAorta* 提供，并在英特尔和 Codeplay* Software Ltd 之间的许可协议下进行分发。</li></ul> 
<p>GNA 插件<a id="inpage-nav-3-3-7"></a></p> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_supported_plugins_GNA.html" rel="nofollow">GNA 插件</a></p> 
<ul><li>新增为面向物联网 (IoT) 应用程序的第十一代智能英特尔® 酷睿™ 处理器家族（原代码 Tiger Lake）提供的官方支持。</li><li>添加了对许多其他层和层组合的支持，包括： 
  <ul><li>基于 TensorFlow 框架的模型卷积层</li><li>电源参数不同于 1 的电源层。</li><li>输入层数量大于 2 的 Concat 层</li><li>4D 元素级运算</li></ul></li><li>增加了对从流中导入模型的支持。</li><li>增加了对 Windows 的 QoS 机制的支持。</li><li>在 <a href="https://docs.openvinotoolkit.org/latest/openvino_inference_engine_tools_benchmark_tool_README.html" rel="nofollow">Python Benchmark 工具</a>中添加了对 GNA 特定参数的支持。</li></ul> 
<h4>nGraph<a id="inpage-nav-3-4"></a></h4> 
<ul><li>推出 opset4。全新 opset 包含以下全新操作。并非所有 OpenVINO™ 工具套件插件都支持这些操作。 
  <ul><li>Acosh-4</li><li>Asinh-4</li><li>Atanh-4</li><li>CTCLoss-4</li><li>HSwish-4</li><li>Interpolate-4</li><li>LSTMCell-4</li><li>Mish-4</li><li>Proposal-4</li><li>Range-4</li><li>ReduceL1-4</li><li>ReduceL2-4</li><li>ScattenNDUpdate-4</li><li>SoftPlus-4</li><li>Swish-4</li></ul></li><li>启用了 nGraph Python API，该 API 允许使用 Python 与 nGraph 函数进行通信。可帮助您对已加载的图形进行分析。 
  <ul><li> <p>已启用图形节点的设置参数。 </p> </li><li> <p>已启用使用 Python API 读取 ONNX 模型。</p> </li></ul></li><li>重构了 nGraph Transformation API，以使其具有透明的结构，并更易于使用。请访问 <a href="https://docs.openvinotoolkit.org/latest/openvino_docs_nGraph_DG_DevGuide.html" rel="nofollow">nGraph 开发人员指南</a>，以了解更多内容。</li><li>nGraph 公共 API 已与其余代码分开，ONNX 导入程序已移至前端文件夹。</li></ul> 
<h4>神经网络压缩框架 (NNCF)<a id="inpage-nav-3-5"></a></h4> 
<ul><li>NNCF v1.4 for PyTorch 已发布：</li><li>允许将修剪后的模型导出至 ONNX。</li><li>增加了对 FP16 微调以实现量化的支持。</li><li>增加了对 BatchNorm 调整的支持，作为常见的压缩算法初始化步骤。</li><li>提升了每通道量化训练的性能。性能几乎与按张量训练相当。</li><li>支持 nn.Embedding 和 nn.Conv1d 加权的默认量化。</li><li>有关详细信息，请参阅 <a href="https://github.com/openvinotoolkit/nncf_pytorch/blob/master/ReleaseNotes.md">NNCF 版本说明</a>。</li></ul> 
<h4>训练后优化工具<a id="inpage-nav-3-6"></a></h4> 
<p><a href="http://docs.openvinotoolkit.org/latest/_README.html" rel="nofollow">训练后优化工具</a></p> 
<ul><li>在“精度感知”算法中启用了量化参数的自动调整。</li><li>已加速 <em>Honest</em> Bias Correction 算法。相比 2020.4，当'use_fast_bias'= false 时，量化时间的平均提升约 4 倍。</li><li>已实现 Post-training Optimization Toolkit API 产品化。提供 API 使用演示的示例和文档，其中包括： 
  <ul><li>集成到用户的管道。</li><li>自定义数据加载器、指标计算和执行引擎。</li></ul></li><li>默认的量化方案对应于兼容模式，该模式需要在不同的硬件上提供几乎相同的精度。</li><li>扩展模型覆盖范围：已启用 44 款全新模型。</li></ul> 
<h4>深度学习工作台<a id="inpage-nav-3-7"></a></h4> 
<p><a href="https://docs.openvinotoolkit.org/latest/_docs_Workbench_DG_Introduction.html" rel="nofollow">深度学习工作台</a></p> 
<ul><li>已支持预训练 TensorFlow2.0 模型的导入和分析。 </li><li>使用 POT 显示的不同预设启用 INT8 校准。</li><li>已启用远程目标的 INT8 校准。</li><li>改进了面向 IR 和运行时图表的可视化，包括显卡交互和热图。 </li><li>在用户选择的映像中增加了推理结果的可视化。该功能处于实验模式。</li></ul> 
<h4>OpenCV*<a id="inpage-nav-3-8"></a></h4> 
<ul><li>更新版本至 4.5.0。</li><li>将上游许可证更改为 Apache 2 (<a href="https://github.com/opencv/opencv/pull/18073">PR#18073</a>)。</li><li>增加了对 OpenCV 应用程序中多个 OpenCL 环境的支持。</li></ul> 
<h4>示例<a id="inpage-nav-3-9"></a></h4> 
<ul><li>更新了推理引擎 C++ 示例，以演示如何直接加载 ONNX* 模型。</li></ul> 
<h4>Open Model Zoo<a id="inpage-nav-3-10"></a></h4> 
<ul><li> <p>使用额外的 CNN 预训练模型和预生成的中间表示 (<code>.xml</code> + <code>.bin</code>) 扩展了 Open Model Zoo：</p> 
  <ul><li> <p>替换了 2020.4 模型：</p> 
    <ul><li>face-detection-0200</li><li>face-detection-0202</li><li>face-detection-0204</li><li>face-detection-0205</li><li>face-detection-0206</li><li>person-detection-0200</li><li>person-detection-0201</li><li>person-detection-0202</li><li>person-reidentification-retail-0277</li><li>person-reidentification-retail-0286</li><li>person-reidentification-retail-0287</li><li>person-reidentification-retail-0288</li></ul></li><li>已添加新模型： 
    <ul><li>bert-large-uncased-whole-word-masking-squad-emb-0001</li><li>bert-small-uncased-whole-word-masking-squad-0002</li><li>formula-recognition-medium-scan-0001-im2latex-decoder</li><li>formula-recognition-medium-scan-0001-im2latex-encoder</li><li>horizontal-text-detection-0001</li><li>machine-translation-nar-en-ru-0001</li><li>machine-translation-nar-ru-en-0001</li><li>person-attributes-recognition-crossroad-0234</li><li>person-attributes-recognition-crossroad-0238</li><li>person-vehicle-bike-detection-2000</li><li>person-vehicle-bike-detection-2001</li><li>person-vehicle-bike-detection-2002</li><li>person-vehicle-bike-detection-crossroad-yolov3-1020</li><li>vehicle-detection-0200</li><li>vehicle-detection-0201</li><li>vehicle-detection-0202</li></ul></li><li>最终模型： 
    <ul><li>face-detection-adas-binary-0001</li><li>pedestrian-detection-adas-binary-0001</li><li>vehicle-detection-adas-binary-0001</li></ul></li></ul></li><li> <p>对以下模型的支持扩展了公有模型列表：</p> 
  <table><thead><tr><th> <p>模型名称</p> </th><th> <p>框架</p> </th></tr></thead><tbody><tr><td> <p>aclnet</p> </td><td> <p>PyTorch</p> </td></tr><tr><td colspan="1">resnest-50</td><td colspan="1">PyTorch</td></tr><tr><td colspan="1">mozilla-deepspeech-0.6.1</td><td colspan="1">Tensorflow</td></tr><tr><td colspan="1">yolo-v3-tiny-tf</td><td colspan="1">Tensorflow</td></tr></tbody></table></li><li>增加了新的演示应用程序： 
  <ul><li>bert_question_answering_embedding_demo, Python</li><li>formula_recognition_demo, Python</li><li>machine_translation_demo, Python</li><li>sound_classification_demo, Python</li><li>speech_recognition_demo, Python </li></ul></li><li>Open Model Zoo 工具： 
  <ul><li>提升了下载程序速度。</li><li>在每个模型文件夹中添加了“准确性检查程序”配置文件。为了兼容性，原有位置的软链接被保留至新位置。在未来的版本中，将删除软链接。</li><li>已简化“准确性检查程序”配置文件，无需在配置文件中指定模型 IR 或目标设备的路径和精度。将这些参数应用于“准确性检查器”命令行选项。请参阅<a href="https://github.com/openvinotoolkit/open_model_zoo/blob/develop/tools/accuracy_checker/configs/README.md">如何使用预定义配置文件的说明，</a>以了解详细信息。</li><li>已扩展准确性检查程序，通过推理引擎预处理 API 支持优化的预处理操作。</li><li>已在“准确性检查器”中启用 ONNX 模型评估，无需转换为 IR 格式。</li></ul></li></ul> 
<h4>深度学习流媒体播放器<a id="inpage-nav-3-11"></a></h4> 
<ul><li>已添加对音频分析的支持，DL Streamer 不再局限于视频内容。新增使用 AclNet 模型检测音频事件的新元件 gvaaudiodetect。为示例文件夹添加了管道的端到端示例。</li><li>添加了新元件 gvametaaggregate，以组合来自管道多个分支的结果。这有助于将管道拆分成多个分支以并行处理，随后组合各个分支的结果，创建复杂的管道。 </li><li>支持 GPU 的 VAAPI 解码、调整大小、CSC 和 DL Streamer 推理元件之间的 GPU 内存表面共享，即数据的零拷贝，以改善整体管线性能。</li><li>在 gvatrack 和 gvawatermark 元件的输入和输出时允许 GPU 内存，因此在 GPU 上执行推理时，无需使用 vaapipostproc 显式地将内存从 GPU 转换为 CPU。这不仅有助于管道在有或无 GPU 的设备之间移植，而且由于删除了内存复制步骤而提高了性能。</li><li>[预览] 将 DL Streamer OS 支持扩展至 Ubuntu 20.04。DL Streamer 将在 Ubuntu 20.04 上使用操作系统提供的 GStreamer 及其插件，因此您可以访问 GStreamer 默认安装时提供的所有元件。</li></ul> 
<p>有关 DL Streamer的 更多信息，请参阅 <a href="https://docs.openvinotoolkit.org/latest/_docs_IE_DG_Samples_Overview.html" rel="nofollow">OpenVINO™ 推理引擎样本</a>中的 DL Streamer 教程、API 参考和示例文档，以及位于 <a href="https://github.com/openvinotoolkit/dlstreamer_gst">OpenVINO™ 工具套件 - GitHub 的 DL Streamer </a>资源库中的 DL Streamer 开源项目新主页。</p> 
<h4>OpenVINO™ 模型服务器<a id="inpage-nav-3-12"></a></h4> 
<p><a href="https://github.com/openvinotoolkit/model_server">模型服务器</a></p> 
<p>模型服务器是一个可扩展的高性能工具，用于服务采用 OpenVINO™ 优化的模型。它通过 gRPC 或 HTTP/REST 端点提供推理服务，使您无需编写定制代码即可将模型更快地投入生产。</p> 
<p><strong>主要特性和优势：</strong></p> 
<ul><li>提高了单个服务器实例的可扩展性。借助新的 C ++ 实现，您可以使用具有线性可伸缩性的全部可用硬件，同时避免前端出现任何瓶颈。</li><li>减少了客户端和服务器之间的延迟。这对于高性能加速器或 CPU 尤为明显。</li><li>已减少占用空间。通过切换至 C++ 并减少依赖项，Docker 镜像大小将减少至约 450MB。</li><li>增加了对在线模型更新的支持。服务器可以监控配置文件更改，并根据需要重新加载模型，而无需重新启动服务。</li></ul> 
<p>有关模型服务器的更多信息，请参阅<a href="https://github.com/openvinotoolkit/model_server">开源回购</a>和<a href="https://github.com/openvinotoolkit/model_server/releases/tag/v2021.1">模型服务器版本说明</a>。预构建 Docker 映像可通过 <a href="https://hub.docker.com/r/openvino/model_server" rel="nofollow">openvino/model_server</a> 获取。 </p> 
<h3><a id="preview-features-terminology" name="preview-features-terminology"></a>预览功能术语<a id="inpage-nav-4"></a></h3> 
<p>预览功能是一项正在推出的功能，以便获得开发人员早期反馈。欢迎向<a href="https://software.intel.com/en-us/forums/intel-distribution-of-openvino-toolkit" rel="nofollow">论坛</a>提交有关预览功能的评论、提问和建议。</p> 
<p>预览功能的关键属性：</p> 
<ul><li>高质量实施</li><li>无法保证未来的存在、兼容性或安全性。</li></ul> 
<p><strong>注意</strong>：预览功能/支持在未来会发生变化。其在未来的版本中可能会被移除或更改。对预览功能的更改<em>不</em>需要经过废除和删除的过程。因此，不鼓励在生产代码库中使用预览功能。</p> 
<h3>已知问题<a id="inpage-nav-5"></a></h3> 
<table><thead><tr><th> <p>Jira ID</p> </th><th> <p>描述</p> </th><th> <p>组件</p> </th><th> <p>周转</p> </th></tr></thead><tbody><tr><td colspan="1">#1</td><td colspan="1">仍有许多尚待解决的问题，请参阅“<a href="https://software.intel.com/content/www/cn/zh/develop/articles/openvino-relnotes-2020.html" rel="nofollow">英特尔® Distribution of OpenVINO™ toolkit v.2020 发</a>布说明”中的“已知问题”部分</td><td colspan="1">全部</td><td colspan="1">无</td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-21670" rel="nofollow">21670</a></td><td colspan="1">当指定 8 位量化时，英特尔® GNA 插件无法对具有双峰权重分布的 FC 层进行精确量化。数值接近于 0 的权重被设置为零。</td><td colspan="1">IE GNA 插件</td><td colspan="1">目前，在这些用例中使用 16 位权重。</td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-25358" rel="nofollow">25358</a></td><td colspan="1">在 GT3e/GT4e/ICL NUC 平台上，GPU 插件可能会出现一些性能降级</td><td colspan="1">IE GPU 插件</td><td colspan="1">无</td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-24709" rel="nofollow">24709</a></td><td colspan="1">重新训练的 TensorFlow 对象检测 API RFCN 模型有显著的精度降级。只有<a href="http://download.tensorflow.org/models/object_detection/rfcn_resnet101_coco_2018_01_28.tar.gz" rel="nofollow">预训练模型</a>才会生成正确的推理结果。</td><td colspan="1">全部</td><td colspan="1">如果需要对模型进行再训练，则使用 Faster-RCNN 模型取代 RFCN 模型。</td></tr><tr><td colspan="1"> <p><a href="https://jira.devtools.intel.com/browse/CVS-26388" rel="nofollow">26388</a></p> </td><td colspan="1">由于缺少状态处理，搭载 LSTMCell 的低延迟（批量尺寸 1）图形无法正确推理。</td><td colspan="1">全部</td><td colspan="1"><s>使用废弃的 IRv7，并手动将内存层插入到 IR 图形中。</s> 或者，将状态张量添加为额外输入和输出节点，在加载图形后，将它们给予了IR 节点 ID 的 Blobs 联系起来。</td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-24101" rel="nofollow">24101</a></td><td colspan="1">如果层不进行 64 字节对齐，性能和内存的消耗可能会很差。</td><td colspan="1">IE GNA 插件</td><td colspan="1">尝试避开未进行 64 字节对齐的层，让模型 GNA 变得友好。</td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-28259" rel="nofollow">28259</a></td><td colspan="1">在 Python 接口中进行缓慢的 BERT 推理。</td><td colspan="1">IE Python</td><td colspan="1">仅在导入 PyTorch 时可见。请勿导入 PyTorch 模块。</td></tr><tr><td><a href="https://jira.devtools.intel.com/browse/CVS-35367" rel="nofollow">35367</a></td><td>[IE][TF2] 在 FP32 的最后一次张量检查中，有几个模型失败。</td><td>IE MKL-DNN 插件</td><td> </td></tr><tr><td><a href="https://jira.devtools.intel.com/browse/CVS-39060" rel="nofollow">39060</a></td><td>CentOS 7上的大量模型使 LoadNetwork 崩溃。</td><td>IE MKL-DNN 插件</td><td> </td></tr><tr><td><a href="https://jira.devtools.intel.com/browse/CVS-34087" rel="nofollow">34087</a></td><td>[cIDNN]OpenCL 驱动程序升级导致多个模型的性能降级。</td><td>clDNN</td><td> </td></tr><tr><td><a href="https://jira.devtools.intel.com/browse/CVS-33132" rel="nofollow">33132</a></td><td>[IE CLDNN] FP32 模型在 ICLU GPU 上的准确性和最后张量检验回归</td><td>IE clDNN 插件</td><td> </td></tr><tr><td><a href="https://jira.devtools.intel.com/browse/CVS-25358" rel="nofollow">25358</a></td><td>[cIDNN]R4 上 NUC 和 ICE_Lake 目标的性能下降。</td><td>IE clDNN 插件</td><td>无</td></tr><tr><td><a href="https://jira.devtools.intel.com/browse/CVS-39136" rel="nofollow">39136</a></td><td>重塑失败后调用 LoadNetwork 会引发异常</td><td>IE NG 集成</td><td> </td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-42203" rel="nofollow">42203</a></td><td colspan="1"> <p>受中国的防火墙限制，中国客户从新存储 <a href="https://storage.openvinotoolkit.org/" rel="nofollow">https://storage.openvinotoolkit.org/</a> 下载内容时可能会遇到一些问题</p> </td><td colspan="1">OMZ</td><td colspan="1">请使用含有旧存储 download.01.org 链接的分支 <a href="https://github.com/openvinotoolkit/open_model_zoo/tree/release-01org">https://github.com/openvinotoolkit/open_model_zoo/tree/release-01org</a></td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-24757" rel="nofollow">24757</a></td><td colspan="1">异构模式不适用于 GNA</td><td colspan="1">IE GNA 插件</td><td colspan="1">拆分模型以在 CPU 上运行不受支持的层</td></tr><tr><td colspan="1"><a href="https://jira.devtools.intel.com/browse/CVS-48177" rel="nofollow">48177</a></td><td colspan="1">无法使用 python3.8 导入 IE Python API</td><td colspan="1">Python API</td><td colspan="1">请在 PyPI (<a href="https://pypi.org/project/openvino/" rel="nofollow">https://pypi.org/project/openvino</a>) 上使用 wheel 软件包 </td></tr></tbody></table> 
<h3>包含在此版本中<a id="inpage-nav-6"></a></h3> 
<p>英特尔® Distribution of OpenVINO™ toolkit 提供以下版本：</p> 
<ul><li>适用于 Windows* 的 OpenVINO™ 工具套件</li><li>适用于 Linux* 的 OpenVINO™ 工具套件</li><li>适用于 macOS* 的 OpenVINO™ 工具套件</li></ul> 
<table><thead><tr><th>组件</th><th>许可</th><th colspan="1">位置</th><th colspan="1">Windows</th><th colspan="1">Linux</th><th colspan="1">macOS</th></tr></thead><tbody><tr><td> <p><strong>深度学习模型优化器</strong></p> <p>为已训练模型准备的模型优化工具</p> </td><td>Apache 2.0</td><td colspan="1"><code>&lt;install_root&gt;/deployment_tools/model_optimizer/*</code></td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td> <p><strong>深度学习推理引擎</strong></p> <p>统一的 API 将推理集成到应用程序逻辑中</p> <p><em>推理引擎标题</em></p> </td><td> <p>EULA</p> <p> </p> <p> </p> <p>Apache 2.0</p> </td><td colspan="1"> <p><code>&lt;install_root&gt;/deployment_tools/inference_engine/*</code></p> <p> </p> <p> </p> <p><code>&lt;install_root&gt;/deployment_tools/inference_engine/include/*</code></p> </td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td> <p><strong>OpenCV* 库</strong></p> <p>为英特尔® 硬件编译的 OpenCV* 社区版本</p> </td><td>Apache 2.0</td><td colspan="1"><code>&lt;install_root&gt;/opencv/*</code></td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td> <p><strong>英特尔® Media SDK 库（开源版本）</strong></p> <p>简化 OpenVINO™ 工具套件和英特尔® Media SDK 之间的集成。</p> </td><td>MIT</td><td colspan="1"><code>&lt;install_root&gt;/../mediasdk/*</code></td><td colspan="1">否</td><td colspan="1">是</td><td colspan="1">否</td></tr><tr><td> <p><strong>OpenVINO™ 工具套件文档</strong></p> <p>开发人员指南和其他文档</p> </td><td> </td><td colspan="1">可从 <a href="https://software.intel.com/content/www/cn/zh/develop/tools/openvino-toolkit.html" rel="nofollow">OpenVINO™ 工具套件产品网站获取，</a>不包含在安装程序包内。</td><td colspan="1">否</td><td colspan="1">否</td><td colspan="1">否</td></tr><tr><td> <p><strong>Open Model Zoo</strong></p> <p>来自<a href="https://github.com/opencv/open_model_zoo">英特尔® Open Model Zoo</a> 的模型文档。使用<a href="https://github.com/opencv/open_model_zoo/tree/master/model_downloader">模型下载程序</a>，下载二进制格式的模型。</p> </td><td>Apache 2.0</td><td colspan="1"><code>&lt;install_root&gt;/deployment_tools/open_model_zoo/*</code></td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td> <p><strong>推理引擎样本</strong></p> <p>说明推理引擎 API 用途的示例和演示如何在您的应用程序中使用英特尔® Distribution of OpenVINO™ toolkit 功能的示例</p> </td><td> <p>Apache 2.0</p> </td><td colspan="1"><code>&lt;install_root&gt;/deployment_tools/inference_engine/samples/*</code></td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td colspan="1"> <p><strong>深度学习工作台</strong></p> <p>支持通过 OpenVINO™ 模型优化器运行深度学习模型、将模型转换为 INT8、微调模型、运行推理，以及测量准确性。</p> </td><td colspan="1">EULA</td><td colspan="1">从英特尔® Distribution of OpenVINO™ 工具套件 2021.3 版本开始，DL Workbench 仅可作为预构建的 <a href="https://hub.docker.com/r/openvino/workbench" rel="nofollow">Docker 映像</a>使用。在 OpenVINO 安装中保留了对 DL Workbench 的引用，但现在从 DockerHub 中提取了预构建的映像，而不是从软件包中对其进行构建。 </td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td colspan="1"> <p><strong>训练后优化工具套件</strong></p> <p>设计旨在通过应用不需要重新训练（例如，训练后量化）的特定方法来将模型转化为对硬件更加友好的表示文件。</p> </td><td colspan="1">EULA</td><td colspan="1"><code>&lt;install_root&gt;/deployment_tools/tools/post_training_optimization_toolkit/*</code></td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">是</td></tr><tr><td colspan="1"> <p><strong>语音库和端到端的语音演示</strong></p> <p> </p> </td><td colspan="1">GNA 软件许可协议</td><td colspan="1"><code>&lt;install_root&gt;/data_processing/audio/speech_recognition/*</code></td><td colspan="1">是</td><td colspan="1">是</td><td colspan="1">否</td></tr><tr><td colspan="1"><strong>DL Streamer</strong></td><td colspan="1">EULA</td><td colspan="1">&lt;install_root&gt;/data_processing/dl_streamer/*</td><td colspan="1">否</td><td colspan="1">是</td><td colspan="1">否</td></tr></tbody></table> 
<p> </p> 
<h3>哪里可以下载此版本<a id="inpage-nav-7"></a></h3> 
<ul><li><a href="https://software.intel.com/content/www/cn/zh/develop/tools/openvino-toolkit/download.html" rel="nofollow">英特尔® 软件开发产品注册中心</a></li><li><a href="https://hub.docker.com/u/openvino" rel="nofollow">DockerHub*</a></li><li><a href="https://quay.io/organization/openvino" rel="nofollow">Red Hat* Quay.io</a>（从 2021.2 版本开始）</li><li> <p><a href="https://github.com/openvinotoolkit/docker_ci">DockerHub CI</a><br> DockerHub CI 框架可借助英特尔® Distribution of OpenVINO™ toolkit 生成Dockerfile、构建、测试和部署镜像。<br> 您可以添加层，并根据需求自定义 OpenVINO™ 镜像。您可以重复使用可用的 Dockerfile。</p> </li><li><a href="http://anaconda.org/intel/packages" rel="nofollow">Anaconda* Cloud</a></li><li>此外，英特尔® Distribution of OpenVINO™ toolkit Linux* 版可通过以下方式安装： 
  <ul><li><a href="https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_apt.html" rel="nofollow">APT 存储库</a></li><li><a href="https://docs.openvinotoolkit.org/latest/openvino_docs_install_guides_installing_openvino_yum.html" rel="nofollow">YUM 存储库</a></li></ul></li></ul> 
<h3>系统要求<a id="inpage-nav-8"></a></h3> 
<p>免责声明：某些硬件（包括但不限于 GPU 和 GNA）要求安装特定的驱动程序才能正常工作。驱动程序可能需要更新您的操作系统（包括 Linux 内核），请参参阅相关文档。操作系统更新应由用户处理，不包含在 OpenVINO 安装内。</p> 
<h4>英特尔® CPU 处理器<a id="inpage-nav-8-undefined"></a></h4> 
<p><strong>硬件：</strong></p> 
<ul><li>搭载英特尔® SSE4.2 支持的英特尔凌动® 处理器</li><li>搭载英特尔® 核芯显卡的英特尔® 奔腾® 处理器 N4200/5、N3350/5、N3450/5</li><li>第六代至第十一代智能英特尔® 酷睿™ 处理器</li><li>英特尔® 至强® 处理器可扩展处理器（以前称为 Skylake）</li><li>第二代智能英特尔® 至强® 可扩展处理器（原 Skylake 和 Cascade Lake）</li><li>第三代英特尔® 至强® 可扩展处理器（以前称为 Cooper Lake 和 Ice Lake）</li></ul> 
<p><strong>操作系统：</strong></p> 
<ul><li>Ubuntu* 18.04 长期支持 (LTS) 版本，64 位</li><li>Ubuntu* 20.04 长期支持 (LTS)，64 位 - 预览支持</li><li>Windows* 10、64 位</li><li>macOS* 10.15，64 位</li><li>CentOS* 7，64 位</li><li>Red Hat Enterprise Linux* 8.2，64 位</li></ul> 
<h4>英特尔® 处理器显卡<a id="inpage-nav-8-1"></a></h4> 
<p><strong>硬件：</strong></p> 
<ul><li>英特尔® 高清显卡</li><li>英特尔® 超核芯显卡</li><li>英特尔锐炬® Xe 显卡</li><li>英特尔锐炬® Xe Max 显卡 </li><li>英特尔锐炬® Pro 显卡</li></ul> 
<p><strong>操作系统：</strong></p> 
<ul><li>Ubuntu* 18.04 长期支持 (LTS) 版本，64 位</li><li>Windows* 10、64 位</li><li>Yocto* 3.0, 64 位</li></ul> 
<p><strong>注意</strong> 此安装需要未包含在英特尔 Distribution of OpenVINO 工具套件包中的驱动程序</p> 
<p><strong>注意</strong>：英特尔®️ 至强® 处理器需要支持处理器显卡的芯片组。图形处理器并未包含在所有处理器中。参见<a href="https://ark.intel.com/zh-cn/content/www/us/en/ark.html" rel="nofollow">产品规格</a>来获得关于您处理器的信息。</p> 
<h4>英特尔® Gaussian &amp; Neural Accelerator (Intel® GNA)<a id="inpage-nav-8-2"></a></h4> 
<p><strong>操作系统：</strong></p> 
<ul><li>Ubuntu* 18.04 长期支持 (LTS) 版本，64 位</li><li>Windows* 10、64 位</li></ul> 
<h4>英特尔® 视觉处理器<a id="inpage-nav-8-3"></a></h4> 
<p>搭载英特尔® Movidius™ 视觉处理器 (VPU) 的英特尔® Vision Accelerator Design<a id="inpage-nav-8-3-undefined"></a></p> 
<p><strong>操作系统：</strong></p> 
<ul><li>Ubuntu* 18.04 长期支持 (LTS) 版本，64 位（Linux 内核 5.2 和更低版本）</li><li>Windows* 10、64 位</li><li>CentOS* 7.6，64 位</li></ul> 
<p>英特尔® Movidius™ 神经电脑棒和英特尔® 神经电脑棒 2<a id="inpage-nav-8-3-1"></a></p> 
<p><strong>操作系统：</strong></p> 
<ul><li>Ubuntu* 18.04 长期支持 (LTS) 版本，64 位</li><li>CentOS* 7.6，64 位</li><li>Windows* 10、64 位</li><li>Raspbian*（仅限目标）</li></ul> 
<p>搭载英特尔® Movidius™ Myriad™ X C0 视觉处理器和 1 个 MYDX 的 AI Edge Computing Board：<a id="inpage-nav-8-3-2"></a></p> 
<p><strong>操作系统：</strong></p> 
<ul><li>Windows* 10、64 位</li></ul> 
<h3>在验证过程中使用的组件<a id="inpage-nav-9"></a></h3> 
<p>在验证过程中使用的操作系统：</p> 
<ul><li>Linux* 操作系统 
  <ul><li>搭载 Linux 内核 5.3 的 Ubuntu 18.04.3 
    <ul><li> 采用 Linux 内核 5.6 的 Ubuntu 18.04.3，适用于第十代智能英特尔® 酷睿™ 处理器（原代码为 Ice Lake）和面向物联网 (IoT) 应用程序的第十一代智能英特尔® 酷睿™ 处理器家族（原代码 Tiger Lake）</li></ul></li><li>采用 Linux 内核 5.4 的 Ubuntu 20.04.0</li><li>采用 Linux 内核 5.3 的 CentOS 7.6</li><li>Linux* 操作系统构建环境需要以下组件： 
    <ul><li><a href="https://www.gnu.org/software/gcc/" rel="nofollow">GNU 编译器收集 (GCC)*</a> 4.8 (CentOS 7)、7.5 (Ubuntu 18)、9.3 (Ubuntu 20)</li><li><a href="https://cmake.org/download/" rel="nofollow">CMake* 3.10</a> 或更高版本</li><li><a href="https://www.python.org/downloads/" rel="nofollow">Python*3.6-3.7，以及适用于 Ubuntu 20 的 Python*3.</a>8</li><li><a href="https://opencv.org/releases/" rel="nofollow">OpenCV 4.5</a></li><li>英特尔® Graphics Compute Runtime。仅 GPU 需要。 
      <ul><li>19.41</li><li>20.35，适用于第十代智能英特尔® 酷睿™ 处理器（原代码为 Ice Lake）和面向物联网 (IoT) 应用程序的第十一代智能英特尔® 酷睿™ 处理器家族（原代码 Tiger Lake）</li></ul></li></ul></li></ul></li><li>Windows 10 版本 1809（称为 Redstone 5） 
  <ul><li>Windows* 操作系统构建环境需要以下组件： 
    <ul><li><a href="https://visualstudio.microsoft.com/vs/older-downloads/" rel="nofollow">Microsoft Visual Studio* 2019</a></li><li><a href="https://cmake.org/download/" rel="nofollow">CMake* 3.1</a><a href="https://cmake.org/download/" rel="nofollow">4</a> 或更高</li><li><a href="https://www.python.org/downloads/" rel="nofollow">Python* 3.6-3.8</a></li><li><a href="https://opencv.org/releases/" rel="nofollow">OpenCV 4.5</a></li><li><a href="https://downloadcenter.intel.com/zh-cn/product/80939/Graphics-Drivers" rel="nofollow">英特尔® 核芯显卡驱动程序</a> 仅 GPU 需要。</li><li><a href="https://downloadcenter.intel.com/zh-cn/download/29993/Intel-Iris-Xe-MAX-Dedicated-Graphics-Drivers?product=80939" rel="nofollow">英特尔锐炬® Xe MAX 专用显卡驱动程序</a>。仅搭载英特尔锐炬® Xe Max 显卡的第十一代智能英特尔® 酷睿™ 处理器需要。</li><li><a href="https://downloadcenter.intel.com/zh-cn/product/202986/11th-Generation-Intel-Core-i7-Processors" rel="nofollow">https://downloadcenter.intel.com/product/202986/11th-Generation-Intel-Core-i7-Processors</a> 上有提供“通用”驱动程序，但我们注意到在 Tiger Lake 上，驱动程序 27.20.100.9126 和更新的版本有所回退，因此推荐 27.20.100.9079（2020 年 12 月 23 日）。</li></ul></li></ul></li><li>macOS 10.15 
  <ul><li> <p>macOS 构建环境需要以下组件：</p> 
    <ul><li><a href="https://developer.apple.com/xcode/" rel="nofollow">Xcode* 10.3</a></li><li><a href="https://cmake.org/download/" rel="nofollow">CMake* 3.10</a> 或更高</li><li><a href="https://www.python.org/downloads/" rel="nofollow">Python 3.6</a>-3.7</li><li><a href="https://opencv.org/releases/" rel="nofollow">OpenCV 4.5</a></li></ul></li></ul></li></ul> 
<p>用于验证的 DL 框架：</p> 
<ul><li>TensorFlow 1.15.2, 2.2.0（根据产品特性提供有限支持）</li><li>MxNet 1.5.1</li></ul> 
<p><strong>注意： </strong>上面指定的 CMake 版本是从源构建 OpenVINO 的。<strong>  </strong>从英特尔® Distribution of OpenVINO™ 工具套件构建示例和演示需要 CMake* 3.10 或更高版本（Windows 除外，在 Windows 中首先需要 CMake 3.14 支持 Visual Studio 2019）。</p> 
<h3>有用的链接<a id="inpage-nav-10"></a></h3> 
<p><strong>注意</strong>：在新窗口中打开链接。</p> 
<ul><li><a href="https://software.intel.com/content/www/cn/zh/develop/tools/openvino-toolkit.html" rel="nofollow">主页</a></li><li><a href="https://software.intel.com/content/www/cn/zh/develop/tools/openvino-toolkit/documentation.html" rel="nofollow">精选文档</a></li><li><a href="https://docs.openvinotoolkit.org/" rel="nofollow">所有文档、指南和资源</a></li><li><a href="https://software.intel.com/en-us/forums/intel-distribution-of-openvino-toolkit" rel="nofollow">社区论坛</a></li></ul> 
<p> </p> 
<h3>法律信息<a id="inpage-nav-11"></a></h3> 
<p>您使用本文档时不得涉及针对本文档所述英特尔产品的任何侵权分析或其他法律分析，也不得为此提供便利。您同意就此后起草的任何专利权利（包括此处披露的主题）授予英特尔非排他性的免版税许可。</p> 
<p>本文档未授予任何公司或其他机构知识产权许可（明示或暗示、明确或隐含地）。</p> 
<p>此处提供的信息可随时改变而毋需通知。关于最新英特尔® 产品的规格和路线图，请联系您的英特尔代表。</p> 
<p>所述产品可能包含设计缺陷或错误（即勘误表），这可能会使产品与已发布的技术规格有所偏差。可应要求提供当前的勘误表。</p> 
<p>英特尔技术特性和优势取决于系统配置，并可能需要支持的硬件、软件或服务激活。访问 <a href="https://software.intel.com/content/www/cn/zh/homepage.html" rel="nofollow">http://www.intel.cn/</a> 了解详情，或咨询生产厂家或零售商。</p> 
<p>没有任何计算机系统能保证绝对安全。</p> 
<p>英特尔、Arria、酷睿、Movidius、至强、OpenVINO 和英特尔标志是英特尔公司在美国和/或其他国家（地区）的商标。</p> 
<p>OpenCL 和 OpenCL 标识是 Apple Inc.的商标，经 Khronos 许可使用</p> 
<p>* 文中涉及的其它名称及商标属于各自所有者资产。</p> 
<p>版权所有 © 2021 英特尔公司。保留所有权利。</p> 
<p>有关编译器优化的更完整信息，请参阅我们的<a href="https://software.intel.com/en-us/articles/optimization-notice#opt-en" rel="nofollow">优化说明</a>。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e539a2754f6ab4da23cb224c04ff1f90/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">linux服务器休眠怎么唤醒,海思的Linux方案中系统怎么待机和唤醒</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e4bc0c9495bf5d70a459f785fcbbf6f4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux-FrameBuffer双缓冲机制显示图像</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>