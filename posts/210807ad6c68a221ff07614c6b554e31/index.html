<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>VHH免疫测序数据分析1 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="VHH免疫测序数据分析1" />
<meta property="og:description" content="文章目录 目的简介工具实操1.质控2.修剪3.合并双端reads4.DNA level 计数5.igblast6.根据igblast结果统计unique protein 然后根据CDR3聚类并统计unique cluster7.脚本8.最后 目的简介 根据VHH噬菌体展示筛选结果建库测序（PE300），初步分析结果如下：
1、拼接reads，得到contigs，然后统计unique contig的数量
2、注释拼接得到的contigs得到framework区和CDR区
3、分类形成clonotype：V&amp;J reference gene相同，CDR3长度相同，且相似度高于80%
4、根据上述注释信息统计clonotype count对应的unique contig count 、unique protein count 等等信息
工具 igblastcd-hitpandas 实操 1.质控 mkdir Fastqc ls | grep &#34;fq.gz$&#34; |while read id ;do (fastqc -q -t 16 -o ./Fastqc $id );done &amp; mkdir multiqc multiqc ./ -o ./multiqc #3&#39;端碱基质量有些较差，准备把低于20的碱基及其之后的序列修剪掉 2.修剪 ls |grep &#34;R1_001&#34; &gt; R1.txt ls |grep &#34;R2_001&#34; &gt; R2.txt paste R1.txt R2.txt &gt; list.txt mkdir trim &amp;&amp; cd trim cat ." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/210807ad6c68a221ff07614c6b554e31/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-08-23T13:07:53+08:00" />
<meta property="article:modified_time" content="2021-08-23T13:07:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">VHH免疫测序数据分析1</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">目的简介</a></li><li><a href="#_8" rel="nofollow">工具</a></li><li><a href="#_13" rel="nofollow">实操</a></li><li><ul><li><a href="#1_14" rel="nofollow">1.质控</a></li><li><a href="#2_23" rel="nofollow">2.修剪</a></li><li><a href="#3reads_32" rel="nofollow">3.合并双端reads</a></li><li><a href="#4DNA_level__43" rel="nofollow">4.DNA level 计数</a></li><li><a href="#5igblast_53" rel="nofollow">5.igblast</a></li><li><a href="#6igblastunique_protein_CDR3unique_cluster_64" rel="nofollow">6.根据igblast结果统计unique protein 然后根据CDR3聚类并统计unique cluster</a></li><li><a href="#7_130" rel="nofollow">7.脚本</a></li><li><a href="#8_219" rel="nofollow">8.最后</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>目的简介</h2> 
<p>根据VHH噬菌体展示筛选结果建库测序（PE300），初步分析结果如下：<br> 1、拼接reads，得到contigs，然后统计unique contig的数量<br> 2、注释拼接得到的contigs得到framework区和CDR区<br> 3、分类形成clonotype：V&amp;J reference gene相同，CDR3长度相同，且相似度高于80%<br> 4、根据上述注释信息统计clonotype count对应的unique contig count 、unique protein count 等等信息</p> 
<h2><a id="_8"></a>工具</h2> 
<ul><li>igblast</li><li>cd-hit</li><li>pandas</li></ul> 
<h2><a id="_13"></a>实操</h2> 
<h3><a id="1_14"></a>1.质控</h3> 
<pre><code class="prism language-bash"><span class="token function">mkdir</span> Fastqc
<span class="token function">ls</span> <span class="token operator">|</span> <span class="token function">grep</span> <span class="token string">"fq.gz$"</span> <span class="token operator">|</span><span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token punctuation">(</span>fastqc -q -t <span class="token number">16</span> -o ./Fastqc <span class="token variable">$id</span> <span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">done</span> <span class="token operator">&amp;</span>
<span class="token function">mkdir</span> multiqc
multiqc ./ -o ./multiqc
<span class="token comment">#3'端碱基质量有些较差，准备把低于20的碱基及其之后的序列修剪掉</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/59/9c/FmxXt6ir_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2_23"></a>2.修剪</h3> 
<pre><code class="prism language-bash"><span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"R1_001"</span> <span class="token operator">&gt;</span> R1.txt
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"R2_001"</span> <span class="token operator">&gt;</span> R2.txt
<span class="token function">paste</span> R1.txt R2.txt <span class="token operator">&gt;</span> list.txt
<span class="token function">mkdir</span> trim <span class="token operator">&amp;&amp;</span> <span class="token builtin class-name">cd</span> trim
<span class="token function">cat</span> <span class="token punctuation">..</span>/list.txt <span class="token operator">|</span><span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token punctuation">(</span>arr<span class="token operator">=</span><span class="token punctuation">(</span><span class="token variable">$id</span><span class="token punctuation">)</span><span class="token punctuation">;</span>java -jar /public/home/djs/software/Trimmomatic-0.39/trimmomatic-0.39.jar PE -phred33 <span class="token punctuation">..</span>/<span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span> <span class="token punctuation">..</span>/<span class="token variable">${arr<span class="token punctuation">[</span>1<span class="token punctuation">]</span>}</span> -baseout <span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span>.trim.fastq.gz ILLUMINACLIP:/public/home/djs/software/Trimmomatic-0.39/adapters/TruSeq3-PE.fa:2:30:10:8:true LEADING:3 TRAILING:3 SLIDINGWINDOW:4:20 MINLEN:150 <span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token keyword">done</span>
<span class="token comment">#修剪后的结果在trim文件夹，1p为R1修剪后的结果，2p为R2修剪后的结果</span>
</code></pre> 
<h3><a id="3reads_32"></a>3.合并双端reads</h3> 
<pre><code class="prism language-bash">conda search pandaseq
conda <span class="token function">install</span> pandaseq
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"1P.fastq.gz"</span> <span class="token operator">&gt;</span> 1p.txt
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"2P.fastq.gz"</span> <span class="token operator">&gt;</span> 2p.txt
<span class="token function">paste</span> 1p.txt 2p.txt <span class="token operator">&gt;</span> list.txt
<span class="token function">cat</span> list.txt <span class="token operator">|</span><span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token assign-left variable">arr</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token variable">$id</span><span class="token punctuation">)</span><span class="token punctuation">;</span>pandaseq -f <span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span> -r <span class="token variable">${arr<span class="token punctuation">[</span>1<span class="token punctuation">]</span>}</span> -F -N -o <span class="token number">12</span> -w ./<span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span>.merge<span class="token punctuation">;</span><span class="token keyword">done</span> <span class="token comment">#结果未压缩</span>
<span class="token function">cat</span> list.txt <span class="token operator">|</span><span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token assign-left variable">arr</span><span class="token operator">=</span><span class="token punctuation">(</span><span class="token variable">$id</span><span class="token punctuation">)</span><span class="token punctuation">;</span>pandaseq -f <span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span> -r <span class="token variable">${arr<span class="token punctuation">[</span>1<span class="token punctuation">]</span>}</span> -F -N -o <span class="token number">12</span> -W ./<span class="token variable">${arr<span class="token punctuation">[</span>0<span class="token punctuation">]</span>}</span>.merge<span class="token punctuation">;</span><span class="token keyword">done</span> <span class="token comment">#结果文件是bzip2格式</span>
<span class="token comment">#output后缀为merge.out.fq</span>
</code></pre> 
<h3><a id="4DNA_level__43"></a>4.DNA level 计数</h3> 
<pre><code class="prism language-bash"><span class="token comment">#fq to txt</span>
<span class="token comment">#cut PCR primer</span>
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"merge.out"</span> <span class="token operator">|</span> <span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token function">awk</span> <span class="token string">'{if(NR%4==2) print <span class="token variable">$0</span>}'</span> <span class="token variable">$id</span> <span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s/.*GGTTTCGCTACCGTGGCCCAGGCGGCC/GGTTTCGCTACCGTGGCCCAGGCGGCC/g'</span> <span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s/GAACCCAAGACA.*//g'</span> <span class="token operator">&gt;</span> <span class="token variable">${id}</span>.trim_vector<span class="token punctuation">;</span><span class="token keyword">done</span>
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"trim_vector"</span> <span class="token operator">|</span> <span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token function">awk</span> <span class="token string">'{a=length(<span class="token variable">$0</span>);print <span class="token variable">$0</span>"<span class="token entity" title="\t">\t</span>"a}'</span> <span class="token variable">$id</span> <span class="token operator">|</span> <span class="token function">sort</span> -n -k2 <span class="token operator">|</span><span class="token function">cut</span> -f1 <span class="token operator">&gt;</span> <span class="token variable">${id}</span>.sort <span class="token punctuation">;</span><span class="token keyword">done</span> 
<span class="token comment">#uniq只与临近的序列比较，所以根据序列的长度进行了一次排序</span>
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"sort"</span> <span class="token operator">|</span> <span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token function">cat</span> <span class="token variable">$id</span> <span class="token operator">|</span><span class="token function">uniq</span> -c <span class="token operator">|</span><span class="token function">sort</span> -n -k1 <span class="token operator">|</span><span class="token function">awk</span> <span class="token string">'{print "&gt;"NR"+"<span class="token variable">$1</span>;print <span class="token variable">$2</span>}'</span> <span class="token operator">&gt;</span> <span class="token variable">${id}</span>.sort.sort <span class="token punctuation">;</span><span class="token keyword">done</span> 
<span class="token comment">#此时已经统计好unique DNA sequence，并且生成了fa文件</span>
</code></pre> 
<h3><a id="5igblast_53"></a>5.igblast</h3> 
<pre><code class="prism language-bash"><span class="token function">mkdir</span> output_igblast
<span class="token function">ls</span> /public/home/djs/huiyu/BCR_NGS/trim2 <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"sort.sort"</span> <span class="token operator">|</span><span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span>
./bin/igblastn -germline_db_V ./database/alpaca_v_igblast.fasta  -germline_db_D ./database/alpaca_d_igblast.fasta -germline_db_J ./database/alpaca_j_igblast.fasta  <span class="token punctuation">\</span>
-query ~/BCR_NGS/trim2/<span class="token variable">$id</span> -organism alpaca  <span class="token punctuation">\</span>
-auxiliary_data ./optional_file/alpaca_gl.aux <span class="token punctuation">\</span>
-show_translation -extend_align5end -extend_align3end  <span class="token punctuation">\</span>
-num_alignments_V <span class="token number">1</span> -num_alignments_D <span class="token number">1</span> -num_alignments_J <span class="token number">1</span> <span class="token punctuation">\</span>
-outfmt <span class="token number">19</span>  <span class="token operator">&gt;</span> ~/trim2/output_igblast/<span class="token variable">$id</span>.txt <span class="token punctuation">;</span><span class="token keyword">done</span>
</code></pre> 
<h3><a id="6igblastunique_protein_CDR3unique_cluster_64"></a>6.根据igblast结果统计unique protein 然后根据CDR3聚类并统计unique cluster</h3> 
<pre><code class="prism language-python"><span class="token comment">#将CDR3信息转成fa文件</span>
<span class="token operator">/</span>usr<span class="token operator">/</span><span class="token builtin">bin</span><span class="token operator">/</span>python3
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
df1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"NB244-R1-H_S1_L001_R1_001.fastq.gz.trim_1P.fastq.gz.merge.out.trim_vector.sort.sort.sort.txt"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
df2 <span class="token operator">=</span> df1<span class="token punctuation">[</span><span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"stop_codon"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'F'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"vj_in_frame"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'T'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"v_frameshift"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'F'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"productive"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'T'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"complete_cdj"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'T'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
df3 <span class="token operator">=</span> df2<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"v_call"</span><span class="token punctuation">,</span><span class="token string">"j_call"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df3<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">"test1.txt"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">)</span>
exit<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-bash"><span class="token comment">#聚类</span>
<span class="token function">awk</span> <span class="token string">'BEGIN{FS="<span class="token entity" title="\t">\t</span>"} NR &gt; 1 {print "&gt;"<span class="token variable">$2</span>;print <span class="token variable">$49</span>}'</span> test1.txt  <span class="token operator">&gt;</span> cluster.fa
~/software/cd-hit-v4.8.1-2019-0228/cd-hit -i cluster.fa -o cluster.test -g <span class="token number">1</span> -c <span class="token number">0.8</span> -n <span class="token number">3</span> -d <span class="token number">0</span> -l <span class="token number">3</span>  -s <span class="token number">0.99</span> -S <span class="token number">0</span> -U <span class="token number">0</span> -sc <span class="token number">1</span>
<span class="token comment">#整理聚类信息</span>
<span class="token function">cat</span> cluster.test.clstr <span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s/.*&gt;/&gt;/g'</span><span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s/\..*//g'</span> <span class="token operator">|</span><span class="token function">tr</span> -d <span class="token string">'<span class="token entity" title="\n">\n</span>'</span> <span class="token operator">|</span> <span class="token function">sed</span> <span class="token string">'s/&gt;C/<span class="token entity" title="\n">\n</span>C/g'</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'BEGIN{FS="&gt;"} {for(i=2;i&lt;=NF;i++){print <span class="token variable">$1</span>"<span class="token entity" title="\t">\t</span>"<span class="token variable">$i</span>}}'</span> <span class="token operator">&gt;</span> test.cluster.txt
<span class="token function">sed</span> -i <span class="token string">'1i cluster_id<span class="token entity" title="\t">\t</span>sequence_id'</span> test.cluster.txt
<span class="token comment">#igblast结果精简版</span>
<span class="token function">cut</span> -f <span class="token number">2,3</span>,11,13,16,49 test1.txt <span class="token operator">&gt;</span> test2.txt
<span class="token comment">#到此结果文件基本整理完毕，接下来开始统计unique protein /unique cluster</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token operator">/</span>usr<span class="token operator">/</span><span class="token builtin">bin</span><span class="token operator">/</span>python3

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

df1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"test2.txt"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">)</span> <span class="token comment">#包含精简的i给blast结果</span>
df2 <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">"test.cluster.txt"</span><span class="token punctuation">,</span>sep<span class="token operator">=</span><span class="token string">"\t"</span><span class="token punctuation">)</span> <span class="token comment">#聚类信息</span>
df3 <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>df1<span class="token punctuation">,</span>df2<span class="token punctuation">,</span>on<span class="token operator">=</span><span class="token string">"sequence_id"</span><span class="token punctuation">)</span>
<span class="token comment">#reads拼接后其命名方式：sort后的NR+count</span>
<span class="token comment">#所以在此步骤根据sequence id还原DNA count</span>
df3<span class="token punctuation">[</span><span class="token string">"DNA_count"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df3<span class="token punctuation">[</span><span class="token string">"sequence_id"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'+'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df3<span class="token punctuation">.</span>DNA_count <span class="token operator">=</span> df3<span class="token punctuation">.</span>DNA_count<span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">"int64"</span><span class="token punctuation">)</span>
<span class="token comment">#df3.DNA_count.dtype</span>
<span class="token comment">#一般BCR-seq中的clonotype定义为V &amp; J的germline reference相同，CDR3长度相同且相似度大于80%</span>
df4 <span class="token operator">=</span> df3<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"v_call"</span><span class="token punctuation">,</span><span class="token string">"j_call"</span><span class="token punctuation">,</span><span class="token string">"cluster_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>DNA_count<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#xxxx</span>
df4<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"Cluster_count"</span>
df5 <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>df3<span class="token punctuation">,</span>df4<span class="token punctuation">,</span>on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"v_call"</span><span class="token punctuation">,</span><span class="token string">"j_call"</span><span class="token punctuation">,</span><span class="token string">"cluster_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#你可以发现cluster id相同但是V &amp; J germline reference不一定相同</span>
<span class="token comment">#因为我们是根据CDR3聚类得到的cluster id，所以后续还需要继续整理</span>
<span class="token comment">#但是此处的Cluster count 是根据V &amp; J的germline reference相同，CDR3长度相同且相似度大于80%统计的</span>
df5<span class="token punctuation">[</span><span class="token string">"clonotype"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df5<span class="token punctuation">[</span><span class="token string">"cluster_id"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"@"</span><span class="token operator">+</span>df5<span class="token punctuation">[</span><span class="token string">"v_call"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">"@"</span><span class="token operator">+</span>df5<span class="token punctuation">[</span><span class="token string">"j_call"</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#</span>
df6 <span class="token operator">=</span> df3<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">"sequence_alignment_aa"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>agg<span class="token punctuation">(</span><span class="token string">"sum"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"DNA_count"</span><span class="token punctuation">]</span>
df6<span class="token punctuation">.</span>name <span class="token operator">=</span> <span class="token string">"AA_count"</span>
df7 <span class="token operator">=</span> pd<span class="token punctuation">.</span>merge<span class="token punctuation">(</span>df5<span class="token punctuation">,</span>df6<span class="token punctuation">,</span>on<span class="token operator">=</span><span class="token string">"sequence_alignment_aa"</span><span class="token punctuation">)</span>
<span class="token comment">#上述步骤得到unique protein count</span>
df7 <span class="token operator">=</span> df7<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"clonotype"</span><span class="token punctuation">,</span><span class="token string">"cluster_id"</span><span class="token punctuation">,</span><span class="token string">"cdr3_aa"</span><span class="token punctuation">,</span><span class="token string">"Cluster_count"</span><span class="token punctuation">,</span><span class="token string">"AA_count"</span><span class="token punctuation">,</span><span class="token string">"DNA_count"</span><span class="token punctuation">,</span><span class="token string">"v_call"</span><span class="token punctuation">,</span><span class="token string">"j_call"</span><span class="token punctuation">,</span><span class="token string">"sequence_alignment_aa"</span><span class="token punctuation">,</span><span class="token string">"sequence"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
df7<span class="token punctuation">.</span>columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Clonotype_ID"</span><span class="token punctuation">,</span><span class="token string">"Cluster_ID"</span><span class="token punctuation">,</span><span class="token string">"CDR3_AA"</span><span class="token punctuation">,</span><span class="token string">"Cluster_count"</span><span class="token punctuation">,</span><span class="token string">"AA_count"</span><span class="token punctuation">,</span><span class="token string">"DNA_count"</span><span class="token punctuation">,</span><span class="token string">"V"</span><span class="token punctuation">,</span><span class="token string">"J"</span><span class="token punctuation">,</span><span class="token string">"AA_seq"</span><span class="token punctuation">,</span><span class="token string">"DNA_seq"</span><span class="token punctuation">]</span>
df7<span class="token punctuation">.</span>Cluster_ID <span class="token operator">=</span> df7<span class="token punctuation">.</span>Cluster_ID<span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span>x<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#</span>
df8 <span class="token operator">=</span> df7<span class="token punctuation">.</span>groupby<span class="token punctuation">(</span><span class="token string">"AA_seq"</span><span class="token punctuation">,</span>as_index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
df8 <span class="token operator">=</span> df8<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">"Clonotype_ID"</span><span class="token punctuation">,</span><span class="token string">"Cluster_ID"</span><span class="token punctuation">,</span><span class="token string">"CDR3_AA"</span><span class="token punctuation">,</span><span class="token string">"Cluster_count"</span><span class="token punctuation">,</span><span class="token string">"AA_count"</span><span class="token punctuation">,</span><span class="token string">"DNA_count"</span><span class="token punctuation">,</span><span class="token string">"V"</span><span class="token punctuation">,</span><span class="token string">"J"</span><span class="token punctuation">,</span><span class="token string">"AA_seq"</span><span class="token punctuation">,</span><span class="token string">"DNA_seq"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
df8 <span class="token operator">=</span> df8<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token string">"AA_count"</span><span class="token punctuation">,</span>ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token comment">#</span>
df9 <span class="token operator">=</span> df7<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Cluster_count"</span><span class="token punctuation">,</span><span class="token string">"AA_count"</span><span class="token punctuation">,</span><span class="token string">"DNA_count"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>ascending<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
df9 <span class="token operator">=</span> df9<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">"Clonotype_ID"</span><span class="token punctuation">,</span> keep<span class="token operator">=</span><span class="token string">'first'</span><span class="token punctuation">)</span>
<span class="token comment">#</span>
<span class="token keyword">with</span> pd<span class="token punctuation">.</span>ExcelWriter<span class="token punctuation">(</span><span class="token string">"result.xlsx"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> writer<span class="token punctuation">:</span>
    df7<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span>writer<span class="token punctuation">,</span> sheet_name<span class="token operator">=</span><span class="token string">"all"</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    df8<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span>writer<span class="token punctuation">,</span> sheet_name<span class="token operator">=</span><span class="token string">"AA_count"</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    df9<span class="token punctuation">.</span>to_excel<span class="token punctuation">(</span>writer<span class="token punctuation">,</span> sheet_name<span class="token operator">=</span><span class="token string">"Cluster_count"</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="7_130"></a>7.脚本</h3> 
<pre><code class="prism language-bash"><span class="token comment">#sort后缀文件为igblast结果</span>
<span class="token function">ls</span> <span class="token operator">|</span><span class="token function">grep</span> <span class="token string">"sort"</span> <span class="token operator">|</span> <span class="token keyword">while</span> <span class="token builtin class-name">read</span> <span class="token function">id</span> <span class="token punctuation">;</span><span class="token keyword">do</span> <span class="token function">bash</span> /public/home/djs/**/NGS.sh <span class="token variable"><span class="token variable">$(</span><span class="token builtin class-name">pwd</span><span class="token variable">)</span></span> <span class="token variable">${id}</span><span class="token punctuation">;</span><span class="token keyword">done</span>
<span class="token comment">#NGS.sh</span>
<span class="token comment">#！/usr/bin/bash</span>

<span class="token assign-left variable">file</span><span class="token operator">=</span><span class="token variable">${2}</span>
<span class="token assign-left variable">dir</span><span class="token operator">=</span><span class="token variable">${1}</span>

/usr/bin/python3 /public/home/djs/**/NGS_1.py <span class="token variable">${dir}</span> <span class="token variable">${file}</span>

<span class="token function">cut</span> -f <span class="token number">2,3</span>,11,13,16,49 <span class="token variable">${dir}</span>/test1.txt <span class="token operator">&gt;</span> <span class="token variable">${dir}</span>/test2.txt

<span class="token function">awk</span> <span class="token string">'BEGIN{FS="<span class="token entity" title="\t">\t</span>"} NR &gt; 1 {print "&gt;"<span class="token variable">$2</span>;print <span class="token variable">$49</span>}'</span> <span class="token variable">${dir}</span>/test1.txt  <span class="token operator">&gt;</span> <span class="token variable">${dir}</span>/cluster.fa

~/software/cd-hit-v4.8.1-2019-0228/cd-hit -i <span class="token variable">${dir}</span>/cluster.fa -o <span class="token variable">${dir}</span>/cluster.test -g <span class="token number">1</span> -c <span class="token number">0.8</span> -n <span class="token number">3</span> -d <span class="token number">0</span> -l <span class="token number">3</span>  -s <span class="token number">0.99</span> -S <span class="token number">0</span> -U <span class="token number">0</span> -sc <span class="token number">1</span>

<span class="token function">cat</span> <span class="token variable">${dir}</span>/cluster.test.clstr <span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s/.*&gt;/&gt;/g'</span><span class="token operator">|</span><span class="token function">sed</span> <span class="token string">'s/\..*//g'</span> <span class="token operator">|</span><span class="token function">tr</span> -d <span class="token string">'<span class="token entity" title="\n">\n</span>'</span> <span class="token operator">|</span> <span class="token function">sed</span> <span class="token string">'s/&gt;C/<span class="token entity" title="\n">\n</span>C/g'</span> <span class="token operator">|</span> <span class="token function">awk</span> <span class="token string">'BEGIN{FS="&gt;"} {for(i=2;i&lt;=NF;i++){print <span class="token variable">$1</span>"<span class="token entity" title="\t">\t</span>"<span class="token variable">$i</span>}}'</span> <span class="token operator">&gt;</span> <span class="token variable">${dir}</span>/test.cluster.txt

<span class="token function">sed</span> -i <span class="token string">'1i cluster_id<span class="token entity" title="\t">\t</span>sequence_id'</span> <span class="token variable">${dir}</span>/test.cluster.txt

/usr/bin/python3 /public/home/djs/**/NGS_2.py <span class="token variable">${dir}</span> <span class="token variable">${file}</span>

<span class="token comment">#NGS_1.py</span>
<span class="token comment">#!/usr/bin/python3</span>

<span class="token function">import</span> sys
<span class="token function">import</span> os
<span class="token function">import</span> numpy as np
<span class="token function">import</span> pandas as pd

Dir <span class="token operator">=</span> sys.argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
File <span class="token operator">=</span> sys.argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
os.chdir<span class="token punctuation">(</span>Dir<span class="token punctuation">)</span>
df1 <span class="token operator">=</span> pd.read_csv<span class="token punctuation">(</span>File,sep<span class="token operator">=</span><span class="token string">'<span class="token entity" title="\t">\t</span>'</span><span class="token punctuation">)</span>
df2 <span class="token operator">=</span> df1<span class="token punctuation">[</span><span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"stop_codon"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'F'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"vj_in_frame"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'T'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"v_frameshift"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'F'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"productive"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'T'</span><span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>df1<span class="token punctuation">[</span><span class="token string">"complete_vdj"</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'T'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
df3 <span class="token operator">=</span> df2.sort_values<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"v_call"</span>,<span class="token string">"j_call"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df3.to_csv<span class="token punctuation">(</span><span class="token string">"test1.txt"</span>,sep<span class="token operator">=</span><span class="token string">"<span class="token entity" title="\t">\t</span>"</span><span class="token punctuation">)</span>

<span class="token comment">#NGS_2.py</span>
<span class="token comment">#!/usr/bin/python3</span>

<span class="token function">import</span> sys
<span class="token function">import</span> os
<span class="token function">import</span> numpy as np
<span class="token function">import</span> pandas as pd

Dir <span class="token operator">=</span> sys.argv<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
File <span class="token operator">=</span> sys.argv<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
os.chdir<span class="token punctuation">(</span>Dir<span class="token punctuation">)</span>

df1 <span class="token operator">=</span> pd.read_csv<span class="token punctuation">(</span><span class="token string">"test2.txt"</span>,sep<span class="token operator">=</span><span class="token string">"<span class="token entity" title="\t">\t</span>"</span><span class="token punctuation">)</span>
df2 <span class="token operator">=</span> pd.read_csv<span class="token punctuation">(</span><span class="token string">"test.cluster.txt"</span>,sep<span class="token operator">=</span><span class="token string">"<span class="token entity" title="\t">\t</span>"</span><span class="token punctuation">)</span>
df3 <span class="token operator">=</span> pd.merge<span class="token punctuation">(</span>df1,df2,on<span class="token operator">=</span><span class="token string">"sequence_id"</span><span class="token punctuation">)</span>
df3<span class="token punctuation">[</span><span class="token string">"DNA_count"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df3<span class="token punctuation">[</span><span class="token string">"sequence_id"</span><span class="token punctuation">]</span>.map<span class="token punctuation">(</span>lambda x:x.split<span class="token punctuation">(</span><span class="token string">'+'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df3.DNA_count <span class="token operator">=</span> df3.DNA_count.astype<span class="token punctuation">(</span><span class="token string">"int64"</span><span class="token punctuation">)</span>
<span class="token comment">#df3.DNA_count.dtype</span>
df4 <span class="token operator">=</span> df3.groupby<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"v_call"</span>,<span class="token string">"j_call"</span>,<span class="token string">"cluster_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>.DNA_count.sum<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#xxxx</span>
df4.name <span class="token operator">=</span> <span class="token string">"Cluster_count"</span>
df5 <span class="token operator">=</span> pd.merge<span class="token punctuation">(</span>df3,df4,on<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"v_call"</span>,<span class="token string">"j_call"</span>,<span class="token string">"cluster_id"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#你可以发现cluster id相同但是V &amp; J germline reference不一定相同</span>
<span class="token comment">#因为我们是根据CDR3聚类得到的cluster id，所以后续还需要继续整理</span>
<span class="token comment">#但是此处的Cluster count 是根据V &amp; J的germline reference相同，CDR3长度相同且相似度大于80%统计的</span>
df5<span class="token punctuation">[</span><span class="token string">"clonotype"</span><span class="token punctuation">]</span> <span class="token operator">=</span> df5<span class="token punctuation">[</span><span class="token string">"cluster_id"</span><span class="token punctuation">]</span>.map<span class="token punctuation">(</span>lambda x:x.split<span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>+<span class="token string">"@"</span>+df5<span class="token punctuation">[</span><span class="token string">"v_call"</span><span class="token punctuation">]</span>.map<span class="token punctuation">(</span>lambda x:x.split<span class="token punctuation">(</span><span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>+<span class="token string">"@"</span>+df5<span class="token punctuation">[</span><span class="token string">"j_call"</span><span class="token punctuation">]</span>.map<span class="token punctuation">(</span>lambda x:x.split<span class="token punctuation">(</span><span class="token string">"*"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

df6 <span class="token operator">=</span> df3.groupby<span class="token punctuation">(</span><span class="token string">"sequence_alignment_aa"</span><span class="token punctuation">)</span>.agg<span class="token punctuation">(</span><span class="token string">"sum"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"DNA_count"</span><span class="token punctuation">]</span>
df6.name <span class="token operator">=</span> <span class="token string">"AA_count"</span>
df7 <span class="token operator">=</span> pd.merge<span class="token punctuation">(</span>df5,df6,on<span class="token operator">=</span><span class="token string">"sequence_alignment_aa"</span><span class="token punctuation">)</span>

df7 <span class="token operator">=</span> df7.loc<span class="token punctuation">[</span>:,<span class="token punctuation">[</span><span class="token string">"clonotype"</span>,<span class="token string">"cluster_id"</span>,<span class="token string">"cdr3_aa"</span>,<span class="token string">"Cluster_count"</span>,<span class="token string">"AA_count"</span>,<span class="token string">"DNA_count"</span>,<span class="token string">"v_call"</span>,<span class="token string">"j_call"</span>,<span class="token string">"sequence_alignment_aa"</span>,<span class="token string">"sequence"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
df7.columns <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"Clonotype_ID"</span>,<span class="token string">"Cluster_ID"</span>,<span class="token string">"CDR3_AA"</span>,<span class="token string">"Cluster_count"</span>,<span class="token string">"AA_count"</span>,<span class="token string">"DNA_count"</span>,<span class="token string">"V"</span>,<span class="token string">"J"</span>,<span class="token string">"AA_seq"</span>,<span class="token string">"DNA_seq"</span><span class="token punctuation">]</span>
df7.Cluster_ID <span class="token operator">=</span> df7.Cluster_ID.map<span class="token punctuation">(</span>lambda x:x.split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#df7.to_csv(File+"result.txt",sep="\t")</span>
<span class="token comment">#df7.to_excel(File+".all_result.xlsx",index=False,sheet_name="sheet1")</span>

df8 <span class="token operator">=</span> df7.groupby<span class="token punctuation">(</span><span class="token string">"AA_seq"</span>,as_index<span class="token operator">=</span>False<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
df8 <span class="token operator">=</span> df8.loc<span class="token punctuation">[</span>:,<span class="token punctuation">[</span><span class="token string">"Clonotype_ID"</span>,<span class="token string">"Cluster_ID"</span>,<span class="token string">"CDR3_AA"</span>,<span class="token string">"Cluster_count"</span>,<span class="token string">"AA_count"</span>,<span class="token string">"DNA_count"</span>,<span class="token string">"V"</span>,<span class="token string">"J"</span>,<span class="token string">"AA_seq"</span>,<span class="token string">"DNA_seq"</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
df8 <span class="token operator">=</span> df8.sort_values<span class="token punctuation">(</span><span class="token string">"AA_count"</span>,ascending<span class="token operator">=</span>False<span class="token punctuation">)</span>

<span class="token comment">#修改</span>
df9 <span class="token operator">=</span> df7.sort_values<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Cluster_count"</span>,<span class="token string">"AA_count"</span>,<span class="token string">"DNA_count"</span><span class="token punctuation">]</span>,ascending<span class="token operator">=</span>False<span class="token punctuation">)</span>
df9 <span class="token operator">=</span> df9.drop_duplicates<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">"Clonotype_ID"</span>, <span class="token assign-left variable">keep</span><span class="token operator">=</span><span class="token string">'first'</span><span class="token punctuation">)</span>

with pd.ExcelWriter<span class="token punctuation">(</span>File+<span class="token string">".result.xlsx"</span><span class="token punctuation">)</span> as writer:
    df7.to_excel<span class="token punctuation">(</span>writer, <span class="token assign-left variable">sheet_name</span><span class="token operator">=</span><span class="token string">"all"</span>,index<span class="token operator">=</span>False<span class="token punctuation">)</span>
    df8.to_excel<span class="token punctuation">(</span>writer, <span class="token assign-left variable">sheet_name</span><span class="token operator">=</span><span class="token string">"AA_count"</span>,index<span class="token operator">=</span>False<span class="token punctuation">)</span>
	df9.to_excel<span class="token punctuation">(</span>writer, <span class="token assign-left variable">sheet_name</span><span class="token operator">=</span><span class="token string">"Cluster_count"</span>,index<span class="token operator">=</span>False<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="8_219"></a>8.最后</h3> 
<p>如果觉得对你有帮助，可以请作者喝杯咖啡。<br> <a href="https://editor.csdn.net/md/?articleId=119905293" rel="nofollow">加糖的咖啡</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ce40ec2a00148599ae538833eeb37a89/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">OpenLayers源码解析7 ol/layer/Vector.js</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fbf314e8248524903983d7ba91871b3f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">垃圾回收机制</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>