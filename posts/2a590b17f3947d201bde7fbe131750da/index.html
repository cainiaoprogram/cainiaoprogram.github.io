<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>使用Scrapy爬取豆瓣图片 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="使用Scrapy爬取豆瓣图片" />
<meta property="og:description" content="使用Scrapy爬取豆瓣某影星的所有个人图片
以莫妮卡·贝鲁奇为例
一：首先我们在命令行进入到我们要创建的目录，输入 scrapy startproject banciyuan 创建scrapy项目
创建的项目结构如下
二：为了方便使用pycharm执行scrapy项目，新建main.py
from scrapy import cmdline cmdline.execute(&#34;scrapy crawl banciyuan&#34;.split()) 再edit configuration
然后进行如下设置，设置后之后就能通过运行main.py运行scrapy项目了
三：分析该HTML页面，创建对应spider
from scrapy import Spider import scrapy from banciyuan.items import BanciyuanItem class BanciyuanSpider(Spider): name = &#39;banciyuan&#39; allowed_domains = [&#39;movie.douban.com&#39;] start_urls = [&#34;https://movie.douban.com/celebrity/1025156/photos/&#34;] url = &#34;https://movie.douban.com/celebrity/1025156/photos/&#34; def parse(self, response): num = response.xpath(&#39;//div[@class=&#34;paginator&#34;]/a[last()]/text()&#39;).extract_first(&#39;&#39;) print(num) for i in range(int(num)): suffix = &#39;?type=C&amp;start=&#39; &#43; str(i * 30) &#43; &#39;&amp;sortby=like&amp;size=a&amp;subtype=a&#39; yield scrapy.Request(url=self.url &#43; suffix, callback=self.get_page) def get_page(self, response): href_list = response." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2a590b17f3947d201bde7fbe131750da/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-31T19:21:27+08:00" />
<meta property="article:modified_time" content="2021-05-31T19:21:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">使用Scrapy爬取豆瓣图片</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>使用Scrapy爬取豆瓣某影星的所有个人图片</p> 
<p>以<a href="https://movie.douban.com/celebrity/1025156/photos/" rel="nofollow">莫妮卡·贝鲁奇</a>为例</p> 
<p><img src="https://images2.imgbox.com/74/19/uZuPwMHT_o.png" alt="在这里插入图片描述"><br> 一：首先我们在命令行进入到我们要创建的目录，输入 <code>scrapy startproject banciyuan</code> 创建scrapy项目</p> 
<p>创建的项目结构如下<br> <img src="https://images2.imgbox.com/45/21/uIesG0jY_o.png" alt="在这里插入图片描述"><br> 二：为了方便使用pycharm执行scrapy项目，新建main.py</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> cmdline

cmdline<span class="token punctuation">.</span>execute<span class="token punctuation">(</span><span class="token string">"scrapy crawl banciyuan"</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p>再edit configuration<br> <img src="https://images2.imgbox.com/9d/02/uhv8u1yN_o.png" alt="在这里插入图片描述"><br> 然后进行如下设置，设置后之后就能通过运行main.py运行scrapy项目了<br> <img src="https://images2.imgbox.com/cf/bb/Feo8t4Uv_o.png" alt="在这里插入图片描述"><br> 三：分析该HTML页面，创建对应spider<br> <img src="https://images2.imgbox.com/a9/e9/SqQA5dTT_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Spider
<span class="token keyword">import</span> scrapy

<span class="token keyword">from</span> banciyuan<span class="token punctuation">.</span>items <span class="token keyword">import</span> BanciyuanItem


<span class="token keyword">class</span> <span class="token class-name">BanciyuanSpider</span><span class="token punctuation">(</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'banciyuan'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'movie.douban.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"https://movie.douban.com/celebrity/1025156/photos/"</span><span class="token punctuation">]</span>
    url <span class="token operator">=</span> <span class="token string">"https://movie.douban.com/celebrity/1025156/photos/"</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        num <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="paginator"]/a[last()]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            suffix <span class="token operator">=</span> <span class="token string">'?type=C&amp;start='</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>i <span class="token operator">*</span> <span class="token number">30</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'&amp;sortby=like&amp;size=a&amp;subtype=a'</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>self<span class="token punctuation">.</span>url <span class="token operator">+</span> suffix<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>get_page<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_page</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        href_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class="article"]//div[@class="cover"]/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># print(href_list)</span>
        <span class="token keyword">for</span> href <span class="token keyword">in</span> href_list<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>href<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>get_info<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">get_info</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        src <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span>
            <span class="token string">'//div[@class="article"]//div[@class="photo-show"]//div[@class="photo-wp"]/a[1]/img/@src'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>
        title <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@id="content"]/h1/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span>
        <span class="token comment"># print(response.body)</span>
        item <span class="token operator">=</span> BanciyuanItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title
        item<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span>src<span class="token punctuation">]</span>
        <span class="token keyword">yield</span> item

</code></pre> 
<p>四：items.py</p> 
<pre><code class="prism language-python"><span class="token comment"># Define here the models for your scraped items</span>
<span class="token comment">#</span>
<span class="token comment"># See documentation in:</span>
<span class="token comment"># https://docs.scrapy.org/en/latest/topics/items.html</span>

<span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">BanciyuanItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    src <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<p>pipelines.py</p> 
<pre><code class="prism language-python"><span class="token comment"># Define your item pipelines here</span>
<span class="token comment">#</span>
<span class="token comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="token comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="token comment"># useful for handling different item types with a single interface</span>
<span class="token keyword">from</span> itemadapter <span class="token keyword">import</span> ItemAdapter
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>pipelines<span class="token punctuation">.</span>images <span class="token keyword">import</span> ImagesPipeline
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">BanciyuanPipeline</span><span class="token punctuation">(</span>ImagesPipeline<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">get_media_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>item<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> meta<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'item'</span><span class="token punctuation">:</span> item<span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">file_path</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> info<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token operator">*</span><span class="token punctuation">,</span> item<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
        image_name <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token comment"># image_name.replace('.webp', '.jpg')</span>
        path <span class="token operator">=</span> <span class="token string">'%s/%s'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">' '</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> image_name<span class="token punctuation">)</span>

        <span class="token keyword">return</span> path

</code></pre> 
<p>settings.py</p> 
<pre><code class="prism language-python"><span class="token comment"># Scrapy settings for banciyuan project</span>
<span class="token comment">#</span>
<span class="token comment"># For simplicity, this file contains only settings considered important or</span>
<span class="token comment"># commonly used. You can find more settings consulting the documentation:</span>
<span class="token comment">#</span>
<span class="token comment">#     https://docs.scrapy.org/en/latest/topics/settings.html</span>
<span class="token comment">#     https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span class="token comment">#     https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span>

BOT_NAME <span class="token operator">=</span> <span class="token string">'banciyuan'</span>

SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'banciyuan.spiders'</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">'banciyuan.spiders'</span>


<span class="token comment"># Crawl responsibly by identifying yourself (and your website) on the user-agent</span>
USER_AGENT <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'User-Agent'</span><span class="token punctuation">:</span><span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.80 Safari/537.36'</span><span class="token punctuation">}</span>


<span class="token comment"># Obey robots.txt rules</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>

<span class="token comment"># Configure maximum concurrent requests performed by Scrapy (default: 16)</span>
<span class="token comment">#CONCURRENT_REQUESTS = 32</span>

<span class="token comment"># Configure a delay for requests for the same website (default: 0)</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay</span>
<span class="token comment"># See also autothrottle settings and docs</span>
<span class="token comment">#DOWNLOAD_DELAY = 3</span>
<span class="token comment"># The download delay setting will honor only one of:</span>
<span class="token comment">#CONCURRENT_REQUESTS_PER_DOMAIN = 16</span>
<span class="token comment">#CONCURRENT_REQUESTS_PER_IP = 16</span>

<span class="token comment"># Disable cookies (enabled by default)</span>
<span class="token comment">#COOKIES_ENABLED = False</span>

<span class="token comment"># Disable Telnet Console (enabled by default)</span>
<span class="token comment">#TELNETCONSOLE_ENABLED = False</span>

<span class="token comment"># Override the default request headers:</span>
<span class="token comment">#DEFAULT_REQUEST_HEADERS = {<!-- --></span>
<span class="token comment">#   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',</span>
<span class="token comment">#   'Accept-Language': 'en',</span>
<span class="token comment">#}</span>

<span class="token comment"># Enable or disable spider middlewares</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/spider-middleware.html</span>
<span class="token comment">#SPIDER_MIDDLEWARES = {<!-- --></span>
<span class="token comment">#    'banciyuan.middlewares.BanciyuanSpiderMiddleware': 543,</span>
<span class="token comment">#}</span>

<span class="token comment"># Enable or disable downloader middlewares</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html</span>
<span class="token comment">#DOWNLOADER_MIDDLEWARES = {<!-- --></span>
<span class="token comment">#    'banciyuan.middlewares.BanciyuanDownloaderMiddleware': 543,</span>
<span class="token comment">#}</span>

<span class="token comment"># Enable or disable extensions</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/extensions.html</span>
<span class="token comment">#EXTENSIONS = {<!-- --></span>
<span class="token comment">#    'scrapy.extensions.telnet.TelnetConsole': None,</span>
<span class="token comment">#}</span>

<span class="token comment"># Configure item pipelines</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
   <span class="token string">'banciyuan.pipelines.BanciyuanPipeline'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
IMAGES_STORE <span class="token operator">=</span> <span class="token string">'./images'</span>

<span class="token comment"># Enable and configure the AutoThrottle extension (disabled by default)</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/autothrottle.html</span>
<span class="token comment">#AUTOTHROTTLE_ENABLED = True</span>
<span class="token comment"># The initial download delay</span>
<span class="token comment">#AUTOTHROTTLE_START_DELAY = 5</span>
<span class="token comment"># The maximum download delay to be set in case of high latencies</span>
<span class="token comment">#AUTOTHROTTLE_MAX_DELAY = 60</span>
<span class="token comment"># The average number of requests Scrapy should be sending in parallel to</span>
<span class="token comment"># each remote server</span>
<span class="token comment">#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0</span>
<span class="token comment"># Enable showing throttling stats for every response received:</span>
<span class="token comment">#AUTOTHROTTLE_DEBUG = False</span>

<span class="token comment"># Enable and configure HTTP caching (disabled by default)</span>
<span class="token comment"># See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings</span>
<span class="token comment">#HTTPCACHE_ENABLED = True</span>
<span class="token comment">#HTTPCACHE_EXPIRATION_SECS = 0</span>
<span class="token comment">#HTTPCACHE_DIR = 'httpcache'</span>
<span class="token comment">#HTTPCACHE_IGNORE_HTTP_CODES = []</span>
<span class="token comment">#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'</span>

</code></pre> 
<p>五：爬取结果<br> <img src="https://images2.imgbox.com/4f/0b/GrZGJqIC_o.png" alt="在这里插入图片描述"><br> <a href="https://blog.csdn.net/qq_39610888/article/details/81585156">reference</a><br> <a href="https://gitee.com/zhuo-jun-zzl/spider_practice/tree/master/banciyuan" rel="nofollow">源码</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dc7dba3b773d27666cbd58a742cfa52d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">相机模型-鱼眼模型/鱼眼镜头标定基本原理及实现(2)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/07b785d811ce3b40cc47eea6765ed4f9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">两个线程交替打印数字和字母，输出1A2B3C4D...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>