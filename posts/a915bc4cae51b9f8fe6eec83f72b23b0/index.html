<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>《Focal and Global Knowledge Distillation for Detector》论文解读 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="《Focal and Global Knowledge Distillation for Detector》论文解读" />
<meta property="og:description" content="若有侵权，联系必删 论文地址：
Focal and Global Knowledge Distillation for Detectors
一、什么是知识蒸馏 首次提出知识蒸馏的概念由Hinton于2015年提出：
知识蒸馏开山之作
中文知识蒸馏研究综述：
知识蒸馏研究综述
一般地，大模型往往是单个复杂网络或者是若干网络的集合，拥有良好的性能和泛化能力，而小模型因为网络规模较小，表达能力有限。因此，可以利用大模型学习到的知识去指导小模型训练，使得小模型具有与大模型相当的性能，但是参数数量大幅降低，从而实现模型压缩与加速，这就是知识蒸馏与迁移学习在模型优化中的应用。
软硬标签 类别
Soft Target
Hard Target
马
0.7
1
狗
0.05
0
驴
0.1
0
牛
0.1
0
汽车
0.05
0
传统目标检测训练任务，通过Hard targets的标签进行训练，之后将图片出入模型进行识别，可以得到一个Soft Target。从上图可以看出，Soft Target比Hard Target传递出更多的信息，因此可以通过Soft Target作为学生模型的输入进行训练。
蒸馏温度T Soft Target的输出还不足够“Soft“，因此在对其进行处理，新增一个蒸馏温度T，T使用在softmax函数中，修正输出标签的soft度，公式如下：
随T变化各概率分布如下，当T变大，每个分类所获得的相似度就越平均（越soft），太大的话每个分类的相似度就会相同，越小会发现每个类别的差异会很大。
T的变化程度决定了学生模型关注负类别的程度，当温度很低时，模型就不会太关注负类别，特别是那些小于均值的负类别。当温度很高时，模型就会更多的关注负类别。
在训练时，从有部分信息量的负样本中学习，则温度设定高些。
防止受负样本中标签噪声的影响，温度设定低些。
蒸馏过程 训练老师模型使用较高的温度去构建Soft Labels同时使用较高的Soft Labels和T=1的Soft Labels去训练学生模型把T改为1在学生模型上做预估 损失函数： disiliation loss(soft)和student loss(hard)的加权求和
总损失：
soft Loss：
hard Loss：
其中：
piT 指Teacher模型在温度等于T的条件下softmax输出在第 i 类上的值。qiT 指Student的在温度等于T的条件下softmax输出在第 i 类上的值。vi指Teacher模型的logits， zi 指Student模型的logits， N 指总标签数量。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a915bc4cae51b9f8fe6eec83f72b23b0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-24T08:54:46+08:00" />
<meta property="article:modified_time" content="2023-11-24T08:54:46+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">《Focal and Global Knowledge Distillation for Detector》论文解读</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div>
  若有侵权，联系必删 
</div> 
<div></div> 
<div> 
 <div> 
  <div> 
   <p style="margin-left:0;text-align:justify;"><span style="color:#333333;">论文地址：</span></p> 
   <p style="margin-left:0;text-align:justify;"><a href="https://arxiv.org/abs/2111.11837" rel="nofollow" title="Focal and Global Knowledge Distillation for Detectors">Focal and Global Knowledge Distillation for Detectors</a></p> 
   <h2 style="text-align:left;"><strong><span style="color:#1a1a1a;">一、什么是知识蒸馏</span></strong></h2> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">首次提出知识蒸馏的概念由Hinton于2015年提出：</span></p> 
   <p style="margin-left:0;text-align:left;"><a href="https://arxiv.org/abs/1503.02531" rel="nofollow" title="知识蒸馏开山之作">知识蒸馏开山之作</a></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">中文知识蒸馏研究综述：</span></p> 
   <p style="margin-left:0;text-align:left;"><a href="https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&amp;dbname=CJFDLAST2022&amp;filename=JSJX202203011&amp;uniplatform=NZKPT&amp;v=Ok8Ry4WzimMZZhT8kbrZpCU3lFxjm33RigAwFplnwXbZD12H2tSKH6vXIiZ9zKPY" rel="nofollow" title="知识蒸馏研究综述">知识蒸馏研究综述</a></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        一般地，大模型往往是单个复杂网络或者是若干网络的集合，拥有良好的性能和泛化能力，而小模型因为网络规模较小，表达能力有限。因此，可以利用大模型学习到的知识去指导小模型训练，使得小模型具有与大模型相当的性能，但是参数数量大幅降低，从而实现模型压缩与加速，这就是知识蒸馏与迁移学习在模型优化中的应用。</span></p> 
   <p style="margin-left:0;text-align:left;"><img alt="997d26645f555511344724007a090495.png" src="https://images2.imgbox.com/ed/6d/xmChHtR8_o.png"></p> 
   <p style="margin-left:0;text-align:left;"></p> 
   <ol><li style="text-align:left;"><strong><span style="color:#333333;">软硬标签</span></strong></li></ol> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/4f/1f/m9XzqEav_o.png"></p> 
   <p style="margin-left:0;text-align:left;"></p> 
   <table border="1" cellspacing="0"><tbody><tr><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">类别</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">Soft Target</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">Hard Target</span></p> </td></tr><tr><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">马</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0.7</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">1</span></p> </td></tr><tr><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">狗</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0.05</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0</span></p> </td></tr><tr><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">驴</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0.1</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0</span></p> </td></tr><tr><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">牛</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0.1</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0</span></p> </td></tr><tr><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">汽车</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0.05</span></p> </td><td colspan="1" rowspan="1" style="vertical-align:middle;width:186.66666666666666px;"> <p style="margin-left:0;text-align:center;"><span style="color:#333333;">0</span></p> </td></tr></tbody></table> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        传统目标检测训练任务，通过Hard targets的标签进行训练，之后将图片出入模型进行识别，可以得到一个Soft Target。从上图可以看出，Soft Target比Hard Target传递出更多的信息，因此可以通过Soft Target作为学生模型的输入进行训练。</span></p> 
   <ol><li style="text-align:left;"><strong><span style="color:#333333;">蒸馏温度T</span></strong></li></ol> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        Soft Target的输出还不足够“Soft“，因此在对其进行处理，新增一个蒸馏温度T，T使用在softmax函数中，修正输出标签的soft度，公式如下：</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/53/07/zRmroqEK_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        随T变化各概率分布如下，当T变大，每个分类所获得的相似度就越平均（越soft），太大的话每个分类的相似度就会相同，越小会发现每个类别的差异会很大。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        T的变化程度决定了学生模型关注负类别的程度，当温度很低时，模型就不会太关注负类别，特别是那些小于均值的负类别。当温度很高时，模型就会更多的关注负类别。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        在训练时，从有部分信息量的负样本中学习，则温度设定高些。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        防止受负样本中标签噪声的影响，温度设定低些。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/06/ae/V82g4P7b_o.png"></p> 
   <ol><li style="text-align:left;"><strong><span style="color:#333333;">蒸馏过程</span></strong></li></ol> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/b1/38/OH1KWwRy_o.png"></p> 
   <p style="margin-left:0;text-align:left;"></p> 
   <ol><li style="text-align:left;"><span style="color:#333333;">训练老师模型</span></li><li style="text-align:left;"><span style="color:#333333;">使用较高的温度去构建Soft Labels</span></li><li style="text-align:left;"><span style="color:#333333;">同时使用较高的Soft Labels和T=1的Soft Labels去训练学生模型</span></li><li style="text-align:left;"><span style="color:#333333;">把T改为1在学生模型上做预估</span></li></ol> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">损失函数： </span></p> 
   <p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">        disiliation loss(soft)和student loss(hard)的加权求和</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/24/f4/Klt4U3jK_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">总损失：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/6f/f5/h6Gh0mum_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">soft Loss</span></span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/ae/a0/Dry0xe4G_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">hard Loss：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/00/26/ToUT0LrK_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">其中：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/66/21/ylJXovPl_o.png"></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/ec/15/uWtVH55F_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        piT 指Teacher模型在温度等于T的条件下softmax输出在第 i 类上的值。qiT 指Student的在温度等于T的条件下softmax输出在第 i 类上的值。vi指Teacher模型的logits， zi 指Student模型的logits， N 指总标签数量。</span></p> 
   <h2 style="text-align:left;"><strong><span style="color:#1a1a1a;">二、目标检测知识蒸馏的难点</span></strong></h2> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">     1. 前背景的不平衡对于目标检测而言是一个重要的问题，这个问题同样影响着知识蒸馏。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">     2. 不同像素之间的关系难以提取。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">     3. 目标检测相比于图像分类的复杂性使得大部分蒸馏都失败。</span></p> 
   <h2 style="text-align:left;"><strong><span style="color:#1a1a1a;">三、本论文主要思想</span></strong></h2> 
   <ol><li style="text-align:left;"><span style="color:#333333;">提出重点蒸馏区分像素和通道注意力。</span></li><li style="text-align:left;"><span style="color:#333333;">提出全局蒸馏，弥补重点蒸馏的全局信息丢失。</span></li></ol> 
   <h2 style="text-align:left;"><strong><span style="color:#1a1a1a;">四、论文介绍</span></strong></h2> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        针对前背景不平衡的问题，在空间和通道注意力上对教师网络和学生网络进行特征的可视化，其中在空间注意力上，二者在前景中的差异较大，在背景中的差异较小。这对蒸馏中的学生模型带来不同的学习难度。因此，本文选择分离出前背景进行蒸馏实验，发现当全图特征混在一起蒸馏时，为学生模型带来的提升最小，而将前景与背景分开，赋予不同的权重时，学生模型能够获得更好的表现。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/a4/bb/ZQgDN9Dz_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="color:#333333;">        针对上述结论，本文首先提出了“重点蒸馏（Focal Distillation）”：分离前背景，赋予不同的权重，并利用教师的空间与通道注意力作为权重，共同指导学生模型进行学习，计算重点蒸馏损失。由于重点蒸馏将前景与背景分开进行蒸馏，切断了前背景的联系，为此，团队提出了“全局蒸馏（Global Distillation）”解决方案：利用全局语义信息模块（Global Context Block，GcBlock）分别提取学生与教师的全局信息，并计算全局蒸馏损失。结合二者，团队最终提出了“重点与全局知识蒸馏（Focal and Global Distillation，FGD）。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/59/6a/SKwQo91j_o.png"></p> 
   <ol><li style="text-align:left;"><strong><span style="color:#1a1a1a;">重点蒸馏（Focal Distillation）</span></strong></li></ol> 
   <p style="margin-left:0;text-align:justify;"><span style="color:#333333;">        由于前背景之间的不均衡，提出重点蒸馏来分类图像并引导学生聚焦于关键像素和通道。</span></p> 
   <p style="margin-left:0;text-align:justify;"><strong><span style="color:#333333;">1.1 二进制掩码——用以区分前景和背景</span></strong></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/9f/1d/N2WL13mE_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="color:#333333;">        通过二进制掩码将图片的前景信息和背景信息进行分离，其中，r为ground truth，i，j分别表示了特征图的水平和垂直坐标。</span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">如果（i，j）落在ground truth中，否则</span></span><span style="color:#333333;">为0。</span></p> 
   <p style="margin-left:0;text-align:justify;"><strong><span style="color:#333333;">1.2 尺度掩码S——用以均衡背景和归一化</span></strong></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">        由于较大尺度的目标由于像素较多，会造成较大的损失，从而影响小目标的蒸馏。在不同的图像中，前景和背景的比例差异很大。因此，为了平等对待不同的目标，平衡前景和背景的损失，设置一个尺度mask S：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/1b/0b/CxRg07Ra_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">        其中 Hr 和 Wr 表示 gt 框r的高和宽。如果一个像素属于不同目标，则选择最小的框作为gt。</span></span></p> 
   <p style="margin-left:0;text-align:justify;"><strong><span style="color:#333333;">1.3 空间和通道attention掩码AS和AC——用以区分关键像素和通道</span></strong></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">        通过借鉴SENet和CBAM的结论，关注关键像素和通道有助于基于CNN的模型获得更好的结果。在本文中，应用类似的方法来选择局部像素和通道，然后得到相应的注意力mask。分别计算不同像素和不同通道的绝对平均值：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/d7/95/UnNmldxq_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">        其中H、W、C表示特征的高度、宽度和通道。Gs和Gc是空间和通道注意力图。然后注意力mask可以被描述为：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/f3/f3/dTk4Rn8a_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#121212;">        其中T是温度超参用于调整分布。</span></span></p> 
   <p style="margin-left:0;text-align:justify;"><strong><span style="color:#333333;">1.4 最终损失函数</span></strong></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#121212;">        学生和老师的mask之间存在显著差异。在训练过程中，采用教师的masks来指导学生。基于上述所得，计算重点损失的特征损失函数：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/e8/71/DgZ0Y7sX_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#121212;">        式中，As和Ac分别表示教师检测器的空间注意力mask和通道注意力mask。Ft和Fs分别表示教师检测器和学生检测器的特征图。α和β是平衡前景和背景之间损失的超参数。</span></span></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#121212;">        此外，本文还使用注意力损失Lat来强制学生检测器模仿教师检测器的空间和通道注意力mask：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/62/d1/qmkdiy6d_o.png"></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#121212;">        其中，t和s表示老师和学生，l()表示L1loss，γ是平衡loss的超参数。</span></span></p> 
   <p style="margin-left:0;text-align:justify;"><span style="background-color:#ffffff;"><span style="color:#121212;">        最终重点损失如下：</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/87/91/7hPpu9O3_o.png"></p> 
   <ol><li style="text-align:left;"><strong><span style="color:#1a1a1a;">全局蒸馏（Global Distillation）</span></strong></li></ol> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        在重点蒸馏中，通过局部蒸馏来分离图像，并迫使学生将注意力集中在关键部位。然而，这种蒸馏切断了前景和背景之间的关系。因此，本文又提出了全局提取，其目的是从特征图中提取不同像素之间的全局关系</span><span style="background-color:#ffffff;"><span style="color:#4d4d4d;">，</span></span><span style="color:#333333;">弥补重点蒸馏的全局信息丢失。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/5a/65/gh7ImAKQ_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        全局蒸馏用于提取不同像素之间的关系，增强前背景之间联系。利用上图中的GcBlock捕获单个图像中的全局关系信息，并强制学生检测器从老师检测器那里学习这些关系。全局损失Lgloabl如下：</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/10/d3/v8OE49B2_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        其中，输入分别是教师网络和学生网络的neck层，Wk、Wv1和Wv2表示卷积层，LN表示层归一化，Np表示特征中的像素数，λ是平衡损失的超参数。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">本论文的最终损失分别由目标检测原始损失、重点损失、全局损失三部分组成，如下：</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/ba/0e/cpWsZNmX_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        由于本论文中蒸馏损失仅在特征图（neck层</span><span style="color:#333333;">输出的）上计算得到，所以它可以很容易地被应用于各种不同的检测器。</span></p> 
   <h2 style="text-align:left;"><strong><span style="color:#1a1a1a;">五、实验部分</span></strong></h2> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        本文首先使用Res101-Res50配置在不同检测器（Faster RCNN、RetinaNet、FCOS）上对比了不同蒸馏方法（FGFI和GID），均取得最佳结果。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/0b/fe/hdmnKWsh_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        然后使用ResNeXt101-Res50配置在不同检测/分割网络（RetinaNet、Cascade Mask RCNN、RepPoints）上与FKD比较，体现更强主干和不同任务的效果。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/d9/0e/IWsDBdPh_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        可视化对比教师和学生的空间和通道attention，可以证明使用FGD增强了学生与教师特征的一致性。</span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/2a/15/fkhFLfGO_o.png"></p> 
   <p style="margin-left:0;text-align:left;"><span style="background-color:#ffffff;"><span style="color:#121212;">        此外，分别做了焦点/全局蒸馏和空间/通道attention掩码的消融，可以看到单独使用某组件均有显著提升，叠加后效果最优。</span></span></p> 
   <p class="img-center"><img alt="" src="https://images2.imgbox.com/85/0a/v4tCZJaX_o.png"></p> 
   <h2 style="text-align:left;"><strong><span style="color:#1a1a1a;">六、总结</span></strong></h2> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        本文提出了重点蒸馏和全局蒸馏相结合，通过分离前景和背景的方法，使得学生模型更多关注空间和通道注意力，最终在目标检测知识蒸馏取得了较好的效果。</span></p> 
   <p style="margin-left:0;text-align:left;"><span style="color:#333333;">        但本文中没有对超参α, β, γ, λ进行消融实验，缺乏一定的信服性。此外，个人感觉本文对整体框架图没有一个很好的解释，阅读起来稍许晦涩。最后，对于小目标检测性能仍然有很大的研究空间。</span></p> 
  </div> 
  <p></p> 
 </div> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/80d3df4a8e3d78ca9802b4c8b0d7e621/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">PaddleDetection研究报告——百度目标检测PP-YOLOE论文解读&#43;实践应用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0c413642fafc1cf325daa25a8859ed0b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pydantic.errors.PydanticUserError: If you use `@root_validator`....</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>