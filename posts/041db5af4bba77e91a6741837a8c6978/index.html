<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于卷积神经网络(CNN)模型的垃圾分类设计与实现 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于卷积神经网络(CNN)模型的垃圾分类设计与实现" />
<meta property="og:description" content="本篇博客主要内容如下：
目录
项目背景
数据集介绍
模型构建与训练
结果分析
结果对比分析
项目背景 如何通过垃圾分类管理，最大限度地实现垃圾资源利用，减少垃圾处置量，改善生存环境质量，是当前世界各国共同关注的迫切问题之一。根据国家制定的统一标准，现在生活垃圾被广泛分为四类，分别是可回收物、餐厨垃圾、有害垃圾和其他垃圾。可回收物表示适宜回收和资源利用的垃圾，主要包括废纸、塑料、玻璃、金属和布料五大类，用蓝色垃圾容器收集，通过综合处理回收利用。餐厨垃圾包括剩菜剩饭、骨头、菜根菜叶、果皮等食品类废物，用绿色垃圾容器收集等等。但是随着深度学习技术的发展，为了简单高效地对生活垃圾进行识别分类,本篇文章将实现一种基于卷积神经网络的垃圾分类识别方法。该方法只需要对图像进行简单的预处理,CNN模型便能够自动提取图像特征且池化过程能够减少参数数量,降低计算的复杂度,实验结果表明卷积神经网络,能克服传统图像分类算法的诸多缺点，当然更为复杂的模型等待大家去实验研究，讨论研究Q525894654。但是目前认为采用VGG或者global 池化方式可能效果更好一点。
数据集介绍 数据描述：
数据集一共包括四大类垃圾，分别为：其他垃圾，厨余垃圾、可回收垃圾及有害垃圾，并对其四大类进行了细致分类。具体描述如下：
&#34;0&#34;: &#34;其他垃圾/一次性快餐盒&#34;, &#34;1&#34;: &#34;其他垃圾/污损塑料&#34;, &#34;2&#34;: &#34;其他垃圾/烟蒂&#34;, &#34;3&#34;: &#34;其他垃圾/牙签&#34;, &#34;4&#34;: &#34;其他垃圾/破碎花盆及碟碗&#34;, &#34;5&#34;: &#34;其他垃圾/竹筷&#34;, &#34;6&#34;: &#34;厨余垃圾/剩饭剩菜&#34;, &#34;7&#34;: &#34;厨余垃圾/大骨头&#34;, &#34;8&#34;: &#34;厨余垃圾/水果果皮&#34;, &#34;9&#34;: &#34;厨余垃圾/水果果肉&#34;, &#34;10&#34;: &#34;厨余垃圾/茶叶渣&#34;, &#34;11&#34;: &#34;厨余垃圾/菜叶菜根&#34;, &#34;12&#34;: &#34;厨余垃圾/蛋壳&#34;, &#34;13&#34;: &#34;厨余垃圾/鱼骨&#34;, &#34;14&#34;: &#34;可回收物/充电宝&#34;, &#34;15&#34;: &#34;可回收物/包&#34;, &#34;16&#34;: &#34;可回收物/化妆品瓶&#34;, &#34;17&#34;: &#34;可回收物/塑料玩具&#34;, &#34;18&#34;: &#34;可回收物/塑料碗盆&#34;, &#34;19&#34;: &#34;可回收物/塑料衣架&#34;, &#34;20&#34;: &#34;可回收物/快递纸袋&#34;, &#34;21&#34;: &#34;可回收物/插头电线&#34;, &#34;22&#34;: &#34;可回收物/旧衣服&#34;, &#34;23&#34;: &#34;可回收物/易拉罐&#34;, &#34;24&#34;: &#34;可回收物/枕头&#34;, &#34;25&#34;: &#34;可回收物/毛绒玩具&#34;, &#34;26&#34;: &#34;可回收物/洗发水瓶&#34;, &#34;27&#34;: &#34;可回收物/玻璃杯&#34;, &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/041db5af4bba77e91a6741837a8c6978/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-02-26T17:53:43+08:00" />
<meta property="article:modified_time" content="2020-02-26T17:53:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于卷积神经网络(CNN)模型的垃圾分类设计与实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>本篇博客主要内容如下：</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF-toc" style="margin-left:0px;"><a href="#%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF" rel="nofollow">项目背景</a></p> 
<p id="%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D" rel="nofollow">数据集介绍</a></p> 
<p id="%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E4%B8%8E%E8%AE%AD%E7%BB%83-toc" style="margin-left:0px;"><a href="#%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E4%B8%8E%E8%AE%AD%E7%BB%83" rel="nofollow">模型构建与训练</a></p> 
<p id="%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90-toc" style="margin-left:0px;"><a href="#%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90" rel="nofollow">结果分析</a></p> 
<p id="%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94%E5%88%86%E6%9E%90-toc" style="margin-left:0px;"><a href="#%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94%E5%88%86%E6%9E%90" rel="nofollow">结果对比分析</a></p> 
<h2 id="%E9%A1%B9%E7%9B%AE%E8%83%8C%E6%99%AF">项目背景</h2> 
<p>如何通过垃圾分类管理，最大限度地实现垃圾资源利用，减少垃圾处置量，改善生存环境质量，是当前世界各国共同关注的迫切问题之一。根据国家制定的统一标准，现在生活垃圾被广泛分为四类，分别是可回收物、餐厨垃圾、有害垃圾和其他垃圾。可回收物表示适宜回收和资源利用的垃圾，主要包括废纸、塑料、玻璃、金属和布料五大类，用蓝色垃圾容器收集，通过综合处理回收利用。餐厨垃圾包括剩菜剩饭、骨头、菜根菜叶、果皮等食品类废物，用绿色垃圾容器收集等等。但是随着深度学习技术的发展，为了简单高效地对生活垃圾进行识别分类,本篇文章将实现一种基于卷积神经网络的垃圾分类识别方法。该方法只需要对图像进行简单的预处理,CNN模型便能够自动提取图像特征且池化过程能够减少参数数量,降低计算的复杂度,实验结果表明卷积神经网络,能克服传统图像分类算法的诸多缺点，当然更为复杂的模型等待大家去实验研究，讨论研究Q525894654。但是目前认为采用VGG或者global 池化方式可能效果更好一点。</p> 
<h2 id="%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D">数据集介绍</h2> 
<p>数据描述：</p> 
<p>数据集一共包括四大类垃圾，分别为：其他垃圾，厨余垃圾、可回收垃圾及有害垃圾，并对其四大类进行了细致分类。具体描述如下：</p> 
<pre><code>"0": "其他垃圾/一次性快餐盒",
"1": "其他垃圾/污损塑料",
"2": "其他垃圾/烟蒂",
"3": "其他垃圾/牙签",
"4": "其他垃圾/破碎花盆及碟碗",
"5": "其他垃圾/竹筷",
"6": "厨余垃圾/剩饭剩菜",
"7": "厨余垃圾/大骨头",
"8": "厨余垃圾/水果果皮",
"9": "厨余垃圾/水果果肉",
"10": "厨余垃圾/茶叶渣",
"11": "厨余垃圾/菜叶菜根",
"12": "厨余垃圾/蛋壳",
"13": "厨余垃圾/鱼骨",
"14": "可回收物/充电宝",
"15": "可回收物/包",
"16": "可回收物/化妆品瓶",
"17": "可回收物/塑料玩具",
"18": "可回收物/塑料碗盆",
"19": "可回收物/塑料衣架",
"20": "可回收物/快递纸袋",
"21": "可回收物/插头电线",
"22": "可回收物/旧衣服",
"23": "可回收物/易拉罐",
"24": "可回收物/枕头",
"25": "可回收物/毛绒玩具",
"26": "可回收物/洗发水瓶",
"27": "可回收物/玻璃杯",
"28": "可回收物/皮鞋",
"29": "可回收物/砧板",
"30": "可回收物/纸板箱",
"31": "可回收物/调料瓶",
"32": "可回收物/酒瓶",
"33": "可回收物/金属食品罐",
"34": "可回收物/锅",
"35": "可回收物/食用油桶",
"36": "可回收物/饮料瓶",
"37": "有害垃圾/干电池",
"38": "有害垃圾/软膏",
"39": "有害垃圾/过期药物"
</code></pre> 
<p>数据标签与统计结果：<br> 类别：0    该类别总样本数：469    训练集样本数：375    验证集样本数：94</p> 
<p>类别：1    该类别总样本数：471    训练集样本数：376    验证集样本数：95</p> 
<p>类别：2    该类别总样本数：440    训练集样本数：352    验证集样本数：88</p> 
<p>类别：3    该类别总样本数：150    训练集样本数：120    验证集样本数：30</p> 
<p>类别：4    该类别总样本数：458    训练集样本数：366    验证集样本数：92</p> 
<p>类别：5    该类别总样本数：413    训练集样本数：330    验证集样本数：83</p> 
<p>类别：6    该类别总样本数：463    训练集样本数：370    验证集样本数：93</p> 
<p>类别：7    该类别总样本数：422    训练集样本数：337    验证集样本数：85</p> 
<p>类别：8    该类别总样本数：455    训练集样本数：364    验证集样本数：91</p> 
<p>类别：9    该类别总样本数：482    训练集样本数：385    验证集样本数：97</p> 
<p>类别：10    该类别总样本数：474    训练集样本数：379    验证集样本数：95</p> 
<p>类别：11    该类别总样本数：806    训练集样本数：644    验证集样本数：162</p> 
<p>类别：12    该类别总样本数：450    训练集样本数：360    验证集样本数：90</p> 
<p>类别：13    该类别总样本数：466    训练集样本数：372    验证集样本数：94</p> 
<p>类别：14    该类别总样本数：448    训练集样本数：358    验证集样本数：90</p> 
<p>类别：15    该类别总样本数：514    训练集样本数：411    验证集样本数：103</p> 
<p>类别：16    该类别总样本数：459    训练集样本数：367    验证集样本数：92</p> 
<p>类别：17    该类别总样本数：740    训练集样本数：592    验证集样本数：148</p> 
<p>类别：18    该类别总样本数：462    训练集样本数：369    验证集样本数：93</p> 
<p>类别：19    该类别总样本数：491    训练集样本数：392    验证集样本数：99</p> 
<p>类别：20    该类别总样本数：284    训练集样本数：227    验证集样本数：57</p> 
<p>类别：21    该类别总样本数：825    训练集样本数：660    验证集样本数：165</p> 
<p>类别：22    该类别总样本数：452    训练集样本数：361    验证集样本数：91</p> 
<p>类别：23    该类别总样本数：415    训练集样本数：332    验证集样本数：83</p> 
<p>类别：24    该类别总样本数：424    训练集样本数：339    验证集样本数：85</p> 
<p>类别：25    该类别总样本数：781    训练集样本数：624    验证集样本数：157</p> 
<p>类别：26    该类别总样本数：464    训练集样本数：371    验证集样本数：93</p> 
<p>类别：27    该类别总样本数：623    训练集样本数：498    验证集样本数：125</p> 
<p>类别：28    该类别总样本数：485    训练集样本数：388    验证集样本数：97</p> 
<p>类别：29    该类别总样本数：479    训练集样本数：383    验证集样本数：96</p> 
<p>类别：30    该类别总样本数：388    训练集样本数：310    验证集样本数：78</p> 
<p>类别：31    该类别总样本数：496    训练集样本数：396    验证集样本数：100</p> 
<p>类别：32    该类别总样本数：376    训练集样本数：300    验证集样本数：76</p> 
<p>类别：33    该类别总样本数：373    训练集样本数：298    验证集样本数：75</p> 
<p>类别：34    该类别总样本数：517    训练集样本数：413    验证集样本数：104</p> 
<p>类别：35    该类别总样本数：443    训练集样本数：354    验证集样本数：89</p> 
<p>类别：36    该类别总样本数：297    训练集样本数：237    验证集样本数：60</p> 
<p>类别：37    该类别总样本数：380    训练集样本数：304    验证集样本数：76</p> 
<p>类别：38    该类别总样本数：445    训练集样本数：356    验证集样本数：89</p> 
<p>类别：39    该类别总样本数：487    训练集样本数：389    验证集样本数：98</p> 
<p>总类别数：40    总样本数：18967    训练集总样本数：15159    验证集总样本数：3808</p> 
<h2 id="%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA%E4%B8%8E%E8%AE%AD%E7%BB%83">模型构建与训练</h2> 
<p>模型构建代码：model.py</p> 
<pre><code>from keras.models import Sequential
from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, Activation, BatchNormalization
from keras import backend as K
from keras import optimizers, regularizers, Model
from keras.applications import vgg19, densenet

def generate_trashnet_model(input_shape, num_classes):
    # create model
    model = Sequential()
    # add model layers
    model.add(Conv2D(96, kernel_size=11, strides=4, activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D(pool_size=3, strides=2))
    model.add(Conv2D(256, kernel_size=5, strides=1, activation='relu'))
    model.add(MaxPooling2D(pool_size=3, strides=2))
    model.add(Conv2D(384, kernel_size=3, strides=1, activation='relu'))
    model.add(Conv2D(384, kernel_size=3, strides=1, activation='relu'))
    model.add(Conv2D(256, kernel_size=3, strides=1, activation='relu'))
    model.add(MaxPooling2D(pool_size=3, strides=2))

    model.add(Flatten())
    model.add(Dropout(0.5))
    model.add(Dense(4096))
    model.add(Activation(lambda x: K.relu(x, alpha=1e-3)))
    model.add(Dropout(0.5))
    model.add(Dense(4096))
    model.add(Activation(lambda x: K.relu(x, alpha=1e-3)))
    model.add(Dense(num_classes, activation="softmax"))

    # compile model using accuracy to measure model performance
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    return model


# Generate model using a pretrained architecture substituting the fully connected layer
def generate_transfer_model(input_shape, num_classes):

    # imports the pretrained model and discards the fc layer
    base_model = densenet.DenseNet121(
        include_top=False,
        weights='imagenet',
        input_tensor=None,
        input_shape=input_shape,
        pooling='max') #using max global pooling, no flatten required

   
    x = base_model.output
    #x = Dense(256, activation="relu")(x)
    x = Dense(256, activation="relu", kernel_regularizer=regularizers.l2(0.01))(x)
    x = Dropout(0.6)(x)
    x = BatchNormalization()(x)
    predictions = Dense(num_classes, activation="softmax")(x)

    # this is the model we will train
    model = Model(inputs=base_model.input, outputs=predictions)

    # compile model using accuracy to measure model performance and adam optimizer
    optimizer = optimizers.Adam(lr=0.001)
    #optimizer = optimizers.SGD(lr=0.0001, momentum=0.9, nesterov=True)
    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])

    return model</code></pre> 
<p>Total params: 7,302,470<br> Trainable params: 7,218,310<br> Non-trainable params: 84,160</p> 
<p>模型训练代码：train_test.py</p> 
<pre><code>from keras.preprocessing.image import ImageDataGenerator
from keras import backend as K
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
from model import *
#from google.colab import drive
import tensorflow as tf
import seaborn as sn
import pandas as pd


# parameters
img_width, img_height = 224, 224  # dimensions to which the images will be resized
n_epochs = 10
batch_size = 32
num_classes = 40  # categories of trash

#project_dir = '/cnn/data/'
project_dir = ''
trainset_dir = project_dir + 'dataset-splitted/training-set'
testset_dir = project_dir + 'dataset-splitted/test-set'
load_weights_file = project_dir + 'weights_save_densenet121_val_acc_86.0.h5'
save_weights_file = project_dir + 'weights_save_4.h5'

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2)

test_datagen = ImageDataGenerator(rescale=1. / 255)

train_generator = train_datagen.flow_from_directory(
    trainset_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size)

test_generator = test_datagen.flow_from_directory(
    testset_dir,
    target_size=(img_width, img_height),
    batch_size=batch_size,
    shuffle=False)

if K.image_data_format() == 'channels_first':
    input_shape = (3, img_width, img_height)
else:
    input_shape = (img_width, img_height, 3)

model = generate_transfer_model(input_shape, num_classes)


def load_weights():
    model.load_weights(load_weights_file)
    print("Weights loaded")


def fit(n_epochs):
    history = model.fit_generator(
        train_generator,
        steps_per_epoch=len(train_generator),
        epochs=n_epochs,
        validation_data=test_generator,
        validation_steps=len(test_generator))

    # list all data in history
    print(history.history.keys())
    # summarize history for accuracy
    plt.plot(history.history['acc'])
    plt.plot(history.history['val_acc'])
    plt.title('model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()
    # summarize history for loss
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

    model.save_weights(save_weights_file)


def print_layers():
    for layer in model.layers:
        print(layer.name)
        print("trainable: " + str(layer.trainable))
        print("input_shape: " + str(layer.input_shape))
        print("output_shape: " + str(layer.output_shape))
        print("_____________")


def print_classification_report():
    # Confution Matrix and Classification Report
    Y_pred = model.predict_generator(test_generator, len(test_generator))
    y_pred = np.argmax(Y_pred, axis=1)

    print('Classification Report')
    target_names = list(test_generator.class_indices.keys())
    print(classification_report(test_generator.classes, y_pred, target_names=target_names))

    print('Confusion Matrix')
    conf_mat = confusion_matrix(test_generator.classes, y_pred)
    df_cm = pd.DataFrame(conf_mat, index=target_names, columns=target_names)
    plt.figure(figsize=(10, 7))
    sn.heatmap(df_cm, annot=True)

#save keras model and convert it into tflite model
def save_model():
    # Save tf.keras model in HDF5 format.
    keras_file = "keras_model.h5"
    model.save(keras_file)

    # Convert to TensorFlow Lite model.
    converter = tf.lite.TFLiteConverter.from_keras_model_file(keras_file)
    tflite_model = converter.convert()
    open("converted_model.tflite", "wb").write(tflite_model)

    print("saved")

#print_layers()
load_weights()
#fit(n_epochs)
print_classification_report()
#save_model()</code></pre> 
<h2 id="%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90">结果分析</h2> 
<p>首先构建或者下载好数据集，直接运行train_test.py即可，训练十次左右的准确率与损失函数图像如下：</p> 
<p><img alt="" height="282" src="https://images2.imgbox.com/a4/2d/g5h2ISpM_o.png" width="393"><img alt="" height="280" src="https://images2.imgbox.com/4b/31/avapS41O_o.png" width="387"></p> 
<p>最终训练次数达到60次左右趋于稳定，准确率可达75%左右。该模型可根据需求更改为四分类问题，只需要修改numclass参数即可。</p> 
<h2 id="%E7%BB%93%E6%9E%9C%E5%AF%B9%E6%AF%94%E5%88%86%E6%9E%90">结果对比分析</h2> 
<p>该方法与传统的机器学习方法SVM相比，训练较慢，但是准确率较高，该数据集上高于6%-9%；</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/cb4da756f25482eedbcb97d4e56a855e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Nginx实战案例--并发限制与带宽限制</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e836b45b783fde090b9111e54ca8820e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">NPM关于dependencies 和 devDependencies配置详解，弄懂npm -S与-D的区别</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>