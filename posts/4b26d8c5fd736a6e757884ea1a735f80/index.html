<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>前端大文件上传 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="前端大文件上传" />
<meta property="og:description" content="大文件上传是需要前端和后端同时参与才可以实现的。
思路 大文件上传整体思路：文件切片 和 断点续传
前端思路 利用上传控件 input type=&#34;file&#34; 绑定一个change事件，在回调中通过事件对象的e.target.files拿到这个文件对象，进行文件对象的slice方法，进行切片，一个大文件就转换成多个小文件了。借助 http 的可并发性，同时上传多个切片。这样从原本传一个大文件，同时传多个小的文件切片，可以减少上传时间断点续传：前端在上传切片时，给对应的切片添加一个唯一标识符，上传到后端，服务器需要记住已上传的切片，这样下次就可以跳过之前已经上传的部分 后端思路 服务端负责接受前端传输的切片，并在接收到所有切片后合并所有切片。服务端保存已上传的切片 hash，上传相同文件要可以进行排除。 切片处理 通过上传文件的控件 input type=&#34;file&#34;以及他的change 事件拿到当前上传文件的文件对象e.target.files将文件对象 进行切片处理，利用slice方法。 createFileChunk(file, size = SIZE) { const fileChunkList = []; let cur = 0; while (cur &lt; file.size) { fileChunkList.push({ file: file.slice(cur, cur &#43; size) }); cur &#43;= size; } return fileChunkList; } 注意：循环截取.slice方法不是数组的slice方法,而是文件对象原型上的slice方法,继承自 Blob的slice
以小文件的形式 向后端发请求 Promise.all &lt;template&gt; &lt;div&gt; &lt;input type=&#34;file&#34; @change=&#34;handleFileChange&#34; /&gt; &lt;el-button @click=&#34;handleUpload&#34;&gt;upload&lt;/el-button&gt; &lt;/div&gt; &lt;/template&gt; &lt;script&gt; import axios from &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4b26d8c5fd736a6e757884ea1a735f80/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-23T14:47:59+08:00" />
<meta property="article:modified_time" content="2023-07-23T14:47:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">前端大文件上传</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="u63a3b1c2">大文件上传是需要前端和后端同时参与才可以实现的。</p> 
<h3 id="GbO5g">思路</h3> 
<p id="u62672d57">大文件上传整体思路：文件切片 和 断点续传</p> 
<h3 id="sQKO1">前端思路</h3> 
<ul><li id="u7d6c1694">利用上传控件 <code>input type="file"</code> 绑定一个<code>change</code>事件，在回调中通过事件对象的<code>e.target.files</code>拿到这个文件对象，进行文件对象的slice方法，进行切片，一个大文件就转换成多个小文件了。</li><li id="u5ef14ffc">借助 http 的可并发性，同时上传多个切片。这样从原本传一个大文件，同时传多个小的文件切片，可以减少上传时间</li><li id="u0892f467">断点续传：前端在上传切片时，给对应的切片添加一个唯一标识符，上传到后端，服务器需要记住已上传的切片，这样下次就可以跳过之前已经上传的部分</li></ul> 
<h3 id="Bv9s5">后端思路</h3> 
<ul><li id="ubf677fb5">服务端负责接受前端传输的切片，并在接收到所有切片后合并所有切片。</li><li id="ue0b32384">服务端保存已上传的切片 hash，上传相同文件要可以进行排除。</li></ul> 
<h3 id="boEfP">切片处理</h3> 
<ul><li id="u545abb70">通过上传文件的控件 <code>input type="file"</code>以及他的change 事件拿到当前上传文件的文件对象<code>e.target.files</code></li><li id="ubdf62d63">将文件对象 进行切片处理，利用slice方法。</li><li> <pre><code class="language-javascript">createFileChunk(file, size = SIZE) {
  const fileChunkList = [];
  let cur = 0;
  while (cur &lt; file.size) {
    fileChunkList.push({ file: file.slice(cur, cur + size) });
    cur += size;
  }
  return fileChunkList;
}</code></pre> </li></ul> 
<p> 注意：循环截取.slice方法不是数组的slice方法,而是文件对象原型上的slice方法,继承自 Blob的slice</p> 
<p class="img-center"><img alt="" height="204" src="https://images2.imgbox.com/c1/5c/TGvEiwkZ_o.png" width="667"></p> 
<p> 以小文件的形式 向后端发请求 <code>Promise.all</code> </p> 
<pre><code class="language-javascript">&lt;template&gt;
  &lt;div&gt;
    &lt;input type="file" @change="handleFileChange" /&gt;
    &lt;el-button @click="handleUpload"&gt;upload&lt;/el-button&gt;
  &lt;/div&gt;
&lt;/template&gt;

&lt;script&gt;
import axios from "axios";
const SIZE = 10 * 1024 * 1024;
export default {
  name: "qqqUploadIndex11",
  data: () =&gt; ({
    container: {
      file: null
    }
  }),
  methods: {
    handleFileChange(e) {
      const [file] = e.target.files;
      if (!file) return;
      Object.assign(this.$data, this.$options.data());
      this.container.file = file;
    },
    async handleUpload() {
      if (!this.container.file) return;
      const fileChunkList = this.createFileChunk(this.container.file);
      this.data = fileChunkList.map(({ file }, index) =&gt; ({
        chunk: file,
        hash: this.container.file.name + "-" + index
      }));
      await this.uploadChunks();
    },
    async uploadChunks() {
      const requestList = this.data
        .map(({ chunk, hash }) =&gt; {
          const formData = new FormData();
          formData.append("chunk", chunk);
          formData.append("hash", hash);
          formData.append("filename", this.container.file.name);
          return { formData };
        })
        .map(({ formData }) =&gt;
          axios({ url: "http://localhost:3000", data: formData })
        );
      await Promise.all(requestList);
    },
    createFileChunk(file, size = SIZE) {
      const fileChunkList = [];
      let cur = 0;
      while (cur &lt; file.size) {
        fileChunkList.push({ file: file.slice(cur, cur + size) });
        cur += size;
      }
      return fileChunkList;
    }
  }
};
&lt;/script&gt;</code></pre> 
<ul><li id="u95e6e422">后端接收到所有文件进行合并， 思路有两种 
  <ul><li>等所有小文件上传成功， 前端这边 发一个请求 给后端合并请求</li><li>切片总数据 前端告诉， 后端保存记录切片总数据 后端自己判断也可以</li></ul></li></ul> 
<p></p> 
<h3 id="FjQ7n">断点续传</h3> 
<p id="u739d7647">断点续传要实现的就是 上传过的切片 不用重复上传，后端一查这个切片上传过了 就是当上传成功了。</p> 
<p id="uf7fb5f16">断点续传的原理在于 服务端需要记住已上传的切片，这样下次上传就可以跳过之前已上传的部分</p> 
<ul><li id="u5d9b9a88">切片必须带一个可以标识切片的唯一字段，我们之前采用的是 <code>file.name + "-" + index</code> ===&gt; 利用 <code>spark-MD5</code> 插件，生成和文件内容县官的 hash 值，只要内容不变，hash 值就不变。</li><li id="u48dd4b1f">后端要记住已经上传过的切片， 当前端上传文件切片时 后端可以根据 hash 过滤</li><li id="u7c418878">全部上传后，后端会进行合并</li><li id="ue27e5b5f">文件重新上传 只要文件内容相同，都不需要重新上传 直接秒传成功。</li></ul> 
<p id="u61752799"></p> 
<h3 id="lKl7o">如何根据文件内容生成hash的过程</h3> 
<p id="ub8c5c2b5"><strong>根据文件内容生成hash</strong><br> spark-MD5 插件，可以根据文件内容生成hash值,这个值只和文件内容相关。</p> 
<ul><li id="ufcbbabe0">通过const spark = new SparkMD5.ArrayBuffer()得到一个实例 spark。</li><li id="u18f14ed1">spark实例有方法 append,可以追加一个buffer数据流， 知道读取文件内容结束以后，通过 spark的 end()， 生产对应的hash值。</li><li id="ueb14f3f5"><code><strong>FileReader</strong></code>是一个文件解析器 const reader = new FileReader()</li><li id="u34e5c668"><code>readAsArrayBuffer()</code>读取文件的内容，读取文件完成时，会触发onload事件，文件内容在<code>e.target.result</code></li><li id="u818f377d">由于 读取文件时异步的，要等到整个文件读取完，才可以 生成对应的hash值，这个过程会阻塞主线程，所以你使用 web worker解决</li></ul> 
<pre><code class="language-javascript">// 导入脚本
// import script for encrypted computing
// self代表子线程自身，即子线程的全局对象。
Worker 内部如果要加载其他脚本，有一个专门的方法importScripts()。
self.importScripts("/spark-md5.min.js");

// 生成文件 hash
// create file hash
使用self.onmessage指定监听函数的参数是一个事件对象，它的data属性包含主线程发来的数据。
self.onmessage = e =&gt; {
  const { fileChunkList } = e.data;
  // 生成 spark 实例， SparkMD5.ArrayBuffer
  const spark = new self.SparkMD5.ArrayBuffer();
  let percentage = 0;
  let count = 0;
  const loadNext = index =&gt; {
    const reader = new FileReader();// FileReader 文件解析器
    reader.readAsArrayBuffer(fileChunkList[index].file); 
    // reader.readAsArrayBuffer 可以读取文件的内容 
    // 当文件读取完成的时候 会触发 onload 把这个文件的buffer数据流
    reader.onload = e =&gt; {
      count++;
      spark.append(e.target.result);
      if (count === fileChunkList.length) {
        self.postMessage({
          percentage: 100,
          hash: spark.end()// 所有的内容读取完整之后 会返回一个hash
        });
        self.close();
      } else {
        percentage += 100 / fileChunkList.length;
        // self.postMessage()方法用来向主线程发送消息。
        self.postMessage({
          percentage
        });
        loadNext(count);
      }
    };
  };
  loadNext(0);
};</code></pre> 
<h2>webwork</h2> 
<h4 id="obIhM">难点</h4> 
<p id="uddacb311">使用spark-MD5为切片文件添加唯一标识时，因为该插件会先读取文件内容，才能生成标识，而读取内容是异步操作，会造成线程阻塞，影响后面UI交互，后面的任务只能等待着</p> 
<p id="u21e50fe9">因此在项目中采用了webWorker来解决该问题，首先创建一个子线程与主线程进行交互，将读取文件内容生成hash标识的操作交给woker子线程，最终在将结果返回主线程，主线程就可以正常交互，不会被阻塞或拖慢。</p> 
<h4 id="PMlUE">具体实现</h4> 
<p id="u1634ead2">项目中封装了一个 calculateHash方法，这个方法内部创建一个 new worker开启一个子线程并传入了这个Worker 子线线程所要执行的任务</p> 
<p id="u4490ec3e">这个方法接收一个fileChunkList参数，代表切片的文件对象</p> 
<p id="u4ff3a000">通过返回一个promise对象，在promise内部去new Woker("hash.js")</p> 
<p id="ud0ea7ae8">通过worker.postMessage({fileChunkList})将通过文件对象.slice划分的切片文件传递给子线程</p> 
<p id="ua6f260eb">子线程内部通过self.onmessage去接收主线程传递的数据，最终这个切片文件对象会出现在self.onmessage回调函数的形参的e.data属性中，其中self代表子线程的全局对象，也就是子线程自身</p> 
<p id="uc68821a7">因为要使用 spark-MD5 插件，根据内容生成hash标识，所以要先在子线程js文件中通过self.importScripts()加载我们需要的 spark-MD5 插件，这样当子线程接收到切片对象之后，就</p> 
<p id="ucf193dd9">可以 new self.SparkMD5.ArrayBuffer() 生成spark实例</p> 
<p id="uf67dff91">然后在内部封装了一个loadNext方法，该方法内部会去new FileReader(),创建文件解析器</p> 
<p id="u0708c222">接着调用reader.readAsArrayBuffer(fileChunkList[index].file) index==&gt;count</p> 
<p id="u7efd7c14">reader.readAsArrayBuffer 可以读取文件的内容 ，并转换成buffer数据流，当文件读取完成的时候，会触发 onload事件，刚刚读取文件的buffer数据流就存在e.target.result属性中</p> 
<p id="ud75ac503">然后通过 spark.append 通过spark实例调用append(e.target.result)传入对应的buffer数据流，</p> 
<p id="u6dfe45a3">接下来判断是否等于要读取文件的长度，如果等于，代表内容读取完毕</p> 
<p id="u36e569ed">就直接通过self.postMessage({hash:spark.end()}) 所有的内容读取完整之后 通过 spark的 end()方法， 生产对应的hash值，并发送给主线程，并调用self.close()关闭worker节省系统资源</p> 
<p id="uc82c8c0c">如果没有读取完毕，则继续调用loadNext(count)方法，传入count，这个count是自增之后的值，以次类推，直到读取完毕</p> 
<p id="uaaed2bde">最后主线程中定义了一个 worker.onmessage监听函数去监听子线程返回的值，也就是hash标识，同样也会出现在e.data属性中，最终通过resolve(hash)即可</p> 
<p>hash.js</p> 
<pre><code class="language-javascript">// 导入脚本
// import script for encrypted computing
self.importScripts("/spark-md5.min.js");

// 生成文件 hash
// create file hash
// new worker
self.onmessage = e =&gt; {
  const { fileChunkList } = e.data;
  const spark = new self.SparkMD5.ArrayBuffer();
  let percentage = 0;
  let count = 0;
  const loadNext = index =&gt; {
    const reader = new FileReader();
    reader.readAsArrayBuffer(fileChunkList[index].file);
    reader.onload = e =&gt; {
      count++;
      spark.append(e.target.result);
      if (count === fileChunkList.length) {
        self.postMessage({
          percentage: 100,
          hash: spark.end()
        });
        self.close();
      } else {
        percentage += 100 / fileChunkList.length;
        self.postMessage({
          percentage
        });
        loadNext(count);
      }
    };
  };
  loadNext(0);
};
</code></pre> 
<pre><code class="language-javascript">// 生成文件 hash（web-worker）
// use web-worker to calculate hash
calculateHash(fileChunkList) {
  return new Promise(resolve =&gt; {
    this.container.worker = new Worker("/hash.js");
    this.container.worker.postMessage({ fileChunkList });
    this.container.worker.onmessage = e =&gt; {
      const { percentage, hash } = e.data;
      this.hashPercentage = percentage;
      if (hash) {
        resolve(hash);
      }
    };
  });
}</code></pre> 
<p id="ub49b13ae"><a class="has-card" href="https://developer.mozilla.org/zh-CN/docs/Web/API/FileReader/readAsArrayBuffer" rel="nofollow" title="FileReader.readAsArrayBuffer() - Web API 接口参考 | MDN"><span class="link-card-box"><span class="link-title">FileReader.readAsArrayBuffer() - Web API 接口参考 | MDN</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/b9/24/hIuEwoma_o.png">https://developer.mozilla.org/zh-CN/docs/Web/API/FileReader/readAsArrayBuffer</span></span></a></p> 
<p id="u053f9f32"><a class="has-card" href="https://www.ruanyifeng.com/blog/2018/07/web-worker.html" rel="nofollow" title="Web Worker 使用教程 - 阮一峰的网络日志"><span class="link-card-box"><span class="link-title">Web Worker 使用教程 - 阮一峰的网络日志</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/c4/b8/K7T9H7hw_o.png">https://www.ruanyifeng.com/blog/2018/07/web-worker.html</span></span></a></p> 
<p id="ud374876c"><a class="has-card" href="https://developer.mozilla.org/zh-CN/docs/Web/API/FileReader" rel="nofollow" title="FileReader - Web API 接口参考 | MDN"><span class="link-card-box"><span class="link-title">FileReader - Web API 接口参考 | MDN</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/ef/97/SkJDRPYA_o.png">https://developer.mozilla.org/zh-CN/docs/Web/API/FileReader</span></span></a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/55aaa91f7260ad8d02eec142a719c7cf/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux安装jdk，Tomcat，mysql</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b2a84c46dcdfa71de04cb5b684195e4a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">实现token的无感刷新</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>