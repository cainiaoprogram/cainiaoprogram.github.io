<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>微软祭出代码大模型WaveCoder！4项代码任务2万个实例数据集，让LLM泛化能力飙升... - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="微软祭出代码大模型WaveCoder！4项代码任务2万个实例数据集，让LLM泛化能力飙升..." />
<meta property="og:description" content="视学算法报道 编辑：桃子
【视学算法导读】指令调优或许是让大模型性能提升最有潜力的方法。 用高质量数据集进行指令调优，能让大模型性能快速提升。
对此，微软研究团队训练了一个CodeOcean数据集，包含了2万个指令实例的数据集，以及4个通用代码相关任务。
与此同时，研究人员微调了一个代码大模型WaveCoder。
论文地址：https://arxiv.org/abs/2312.14187
实验结果表明，Wavecoder优于其他开源模型，在以前的代码生成任务中表现出色。
指令调优，释放「代码大模型」潜力
过去的一年，GPT-4、Gemini、Llama等大模型在一系列复杂NLP任务中取得了前所未有的性能。
这些LLM利用自监督预训练的过程，以及随后的微调，展示了强大的零/少样本的能力，能够有效遵循人类指示完成不同的任务。
然而，若想训练微调这样一个大模型，其成本非常巨大。
因此，一些相对较小的LLM，特别是代码大语言模型（Code LLM），因其在广泛的代码相关任务上的卓越的性能，而引起了许多研究者的关注。
鉴于LLM可以通过预训练获得丰富的专业知识，因此在代码语料库上进行高效的预训练，对代码大模型至关重要。
包括Codex、CodeGen、StarCoder和CodeLLaMa在内的多项研究已经成功证明，预训练过程可以显著提高大模型处理代码相关问题的能力。
此外，指令调优的多项研究（FLAN、ExT5）表明，指令调优后的模型在各种任务中的表现符合人类预期。
这些研究将数千个任务纳入训练管道，以提高预训练模型对下游任务的泛化能力。
比如，InstructGPT通过整合人类标注者编写的高质量指令数据，有效地调整了用户输入，推进指令调优的进一步探索。
斯坦福的Alpaca利用ChatGPT通过Self-Instruct的方法，自己生成指令数据，进而用于指令调优的过程。
WizardLM和WizardCoder则应用了evol-instruct的方法，进一步提高了预训练模型的有效性。
这些近来的研究都体现了，指令调优在提高大模型性能方面，展现出强大的潜力。
基于这些工作，研究人员的直觉是，指令调优可以激活大模型的潜力，然后将预训练模型微调到出色的智能水平。
对此，他们总结了指令调优的主要功能：
- 泛化
指令调优最初是为了增强大模型的跨任务泛化能力而提出的，当使用不同的NLP任务指令进行微调时，指令调优可提高模型在大量未见任务中的性能。
- 对齐
预训练模型从大量token和句子层面的自监督任务中学习，已经具备了理解文本输入的能力。指令调优为这些预训练模型提供了指令级任务，让它们能够从指令中提取原始文本语义之外的更多信息。这些额外的信息是用户的意图，能增强它们与人类用户的交互能力，从而有助于对齐。
为了通过指令调优提高代码大模型的性能，目前已有许多设计好的生成指令数据的方法，主要集中在两个方面。
例如，self-instructe、vol-instruct利用teacher LLM的零/少样本的能力来生成指令数据，这为教学数据的生成提供了一种神奇的方法。
然而，这些生成方法过于依赖于teacher LLM的性能，有时会产生大量的重复数据，便会降低微调的效率。
CodeOcean：四项任务代码相关指令数据
为了解决这些问题，如图2所示，研究人员提出了一种可以充分利用源代码，并明确控制生成数据质量的方法。
由于指令调优是为了使预训练模型与指令遵循训练集保持一致，研究人员提出了一个用于指令数据生成的LLM Generator-Disciminator（大模型生成器-判别器）框架。
通过使用生成器和判别器，最新方法可以使数据生成过程，更可定制和更可控。
该方法以原始代码作为输入，选择核心数据集，通过调整原始代码的分布，可以稳定地生成更真实的指令数据，控制数据的多样性。
针对上述挑战，研究人员将指令实例分类为4个通用的代码相关任务：代码汇总、代码生成、代码翻译、代码修复。
同时，使用数据生成策略为4个代码相关的任务生成一个由20000个指令实例的数据集，称为CodeOcean。
为了验证最新的方法，研究人员将StarCoder、CodeLLaMa、DeepseekCoder作为基础模型，根据最新的数据生成策略，微调出全新的WaveCoder模型。
与此同时，研究人员在 HumanEval、MBPP、HumanEvalPack对模型进行了评估，结果表明，WaveCoder在小规模指令调优的基准上拥有出色的性能。
代码数据生成
如上所述，研究人员选择了4个具有代表性的编码任务，并从开源数据集中收集原始代码。
以下具体介绍了训练数据生成过程。
在本节中，我们将介绍我们探索的方法细节。我们首先选择4个代表性的编码任务，并从开源数据集中收集原始代码。
对于每个任务，作者使用GPT-3.5-turbo生成指令数据进行微调。生成提示如表2所示。
如下，是LLM Generator-Disciminator整体架构，也是数据生成的完整过程。
Codesearchnet是一个包含来自 GitHub 上托管的开源库的200万对(注释、代码)的数据集。它包括6种编程语言的代码和文档。我们选择 CodeSearchNet 作为我们的基础数据集，并应用基于 coreset 的选择方法KCenterGreedy来最大化原始代码的多样性。
具体来说，生成器根据输入（a）生成指令数据。随后，判别器接受输出并生成分析结果，输出（b）包括四个键，研究人员将这些信息作为指令调优的输入和输出。
分析（c）包括每条规则的详细原因和总体答案，以检查样本是否满足所有要求。
实验评估结果
代码生成任务评估
表3显示了两个基准上不同大模型的pass@1得分。从结果来看，我们有以下观察结果:
WaveCoder大大优于使用少于20k指令调优数据（InsT Data）的指令模型训练。
经过微调过程，与基础模型和开源模型的选择相比，最新模型的性能显示出实质性的改善，但它仍然落后于专有模型的指导模型训练超过70k的训练数据。
研究人员还用HumanEvalPack上最先进的Code LLM对WaveCoder进行评分，如表4。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/053b4a3979bf5350a8a579df33f415ca/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-08T19:11:03+08:00" />
<meta property="article:modified_time" content="2024-01-08T19:11:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">微软祭出代码大模型WaveCoder！4项代码任务2万个实例数据集，让LLM泛化能力飙升...</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <h4></h4> 
 <hr> 
 <p style="text-align:center;"><strong>  视学算法</strong><strong>报道  </strong></p> 
 <p style="text-align:center;">编辑：桃子</p> 
 <h6><strong>【视学算法导读】</strong>指令调优或许是让大模型性能提升最有潜力的方法。<strong></strong></h6> 
 <p>用高质量数据集进行指令调优，能让大模型性能快速提升。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/f5/b4/sPFlaSyd_o.png" alt="d33fda1a9674a9cc4d2d7639afbd792b.png"></p> 
 <p>对此，微软研究团队训练了一个CodeOcean数据集，包含了2万个指令实例的数据集，以及4个通用代码相关任务。</p> 
 <p>与此同时，研究人员微调了一个代码大模型WaveCoder。</p> 
 <p><img src="https://images2.imgbox.com/a8/1a/Y9tdIKRl_o.png" alt="2d32ba4f0eb3405d08f5aa00b2cd17ed.png"></p> 
 <p>论文地址：https://arxiv.org/abs/2312.14187</p> 
 <p>实验结果表明，Wavecoder优于其他开源模型，在以前的代码生成任务中表现出色。</p> 
 <p>指令调优，释放「代码大模型」潜力</p> 
 <h3><br></h3> 
 <p>过去的一年，GPT-4、Gemini、Llama等大模型在一系列复杂NLP任务中取得了前所未有的性能。</p> 
 <p>这些LLM利用自监督预训练的过程，以及随后的微调，展示了强大的零/少样本的能力，能够有效遵循人类指示完成不同的任务。</p> 
 <p>然而，若想训练微调这样一个大模型，其成本非常巨大。</p> 
 <p>因此，一些相对较小的LLM，特别是代码大语言模型（Code LLM），因其在广泛的代码相关任务上的卓越的性能，而引起了许多研究者的关注。</p> 
 <p>鉴于LLM可以通过预训练获得丰富的专业知识，因此在代码语料库上进行高效的预训练，对代码大模型至关重要。</p> 
 <p>包括Codex、CodeGen、StarCoder和CodeLLaMa在内的多项研究已经成功证明，预训练过程可以显著提高大模型处理代码相关问题的能力。</p> 
 <p>此外，指令调优的多项研究（FLAN、ExT5）表明，指令调优后的模型在各种任务中的表现符合人类预期。</p> 
 <p>这些研究将数千个任务纳入训练管道，以提高预训练模型对下游任务的泛化能力。</p> 
 <p>比如，InstructGPT通过整合人类标注者编写的高质量指令数据，有效地调整了用户输入，推进指令调优的进一步探索。</p> 
 <p><img src="https://images2.imgbox.com/7d/6c/FxthDrSB_o.png" alt="1b7bfd60e639b02cf6c527088b0644c7.png"></p> 
 <p>斯坦福的Alpaca利用ChatGPT通过Self-Instruct的方法，自己生成指令数据，进而用于指令调优的过程。</p> 
 <p>WizardLM和WizardCoder则应用了evol-instruct的方法，进一步提高了预训练模型的有效性。</p> 
 <p>这些近来的研究都体现了，指令调优在提高大模型性能方面，展现出强大的潜力。</p> 
 <p>基于这些工作，研究人员的直觉是，指令调优可以激活大模型的潜力，然后将预训练模型微调到出色的智能水平。</p> 
 <p>对此，他们总结了指令调优的主要功能：</p> 
 <p><strong>- 泛化</strong></p> 
 <p>指令调优最初是为了增强大模型的跨任务泛化能力而提出的，当使用不同的NLP任务指令进行微调时，指令调优可提高模型在大量未见任务中的性能。</p> 
 <p><strong>- 对齐</strong></p> 
 <p>预训练模型从大量token和句子层面的自监督任务中学习，已经具备了理解文本输入的能力。指令调优为这些预训练模型提供了指令级任务，让它们能够从指令中提取原始文本语义之外的更多信息。这些额外的信息是用户的意图，能增强它们与人类用户的交互能力，从而有助于对齐。</p> 
 <p>为了通过指令调优提高代码大模型的性能，目前已有许多设计好的生成指令数据的方法，主要集中在两个方面。</p> 
 <p>例如，self-instructe、vol-instruct利用teacher LLM的零/少样本的能力来生成指令数据，这为教学数据的生成提供了一种神奇的方法。</p> 
 <p>然而，这些生成方法过于依赖于teacher LLM的性能，有时会产生大量的重复数据，便会降低微调的效率。</p> 
 <p>CodeOcean：四项任务代码相关指令数据</p> 
 <h3><br></h3> 
 <p>为了解决这些问题，如图2所示，研究人员提出了一种可以充分利用源代码，并明确控制生成数据质量的方法。</p> 
 <p>由于指令调优是为了使预训练模型与指令遵循训练集保持一致，研究人员提出了一个用于指令数据生成的LLM Generator-Disciminator（大模型生成器-判别器）框架。</p> 
 <p><img src="https://images2.imgbox.com/ca/07/hFnDXnME_o.png" alt="69fa6aaf3c8034edf2e36c80a3d995fa.png"></p> 
 <p>通过使用生成器和判别器，最新方法可以使数据生成过程，更可定制和更可控。</p> 
 <p>该方法以原始代码作为输入，选择核心数据集，通过调整原始代码的分布，可以稳定地生成更真实的指令数据，控制数据的多样性。</p> 
 <p>针对上述挑战，研究人员将指令实例分类为4个通用的代码相关任务：代码汇总、代码生成、代码翻译、代码修复。</p> 
 <p>同时，使用数据生成策略为4个代码相关的任务生成一个由20000个指令实例的数据集，称为CodeOcean。</p> 
 <p>为了验证最新的方法，研究人员将StarCoder、CodeLLaMa、DeepseekCoder作为基础模型，根据最新的数据生成策略，微调出全新的WaveCoder模型。</p> 
 <p>与此同时，研究人员在 HumanEval、MBPP、HumanEvalPack对模型进行了评估，结果表明，WaveCoder在小规模指令调优的基准上拥有出色的性能。</p> 
 <p><img src="https://images2.imgbox.com/8e/b3/AkFmsMy7_o.png" alt="45e9dc8e090cb21f8def4cea427651b5.png"></p> 
 <p><strong>代码数据生成</strong></p> 
 <p>如上所述，研究人员选择了4个具有代表性的编码任务，并从开源数据集中收集原始代码。</p> 
 <p>以下具体介绍了训练数据生成过程。</p> 
 <p>在本节中，我们将介绍我们探索的方法细节。我们首先选择4个代表性的编码任务，并从开源数据集中收集原始代码。</p> 
 <p>对于每个任务，作者使用GPT-3.5-turbo生成指令数据进行微调。生成提示如表2所示。</p> 
 <p><img src="https://images2.imgbox.com/5f/31/QSVsSNqt_o.png" alt="932cd2a2eea84de8ae48e19b3f8cc981.png"></p> 
 <p>如下，是LLM Generator-Disciminator整体架构，也是数据生成的完整过程。</p> 
 <p><img src="https://images2.imgbox.com/9d/30/qqRBrc9w_o.png" alt="04b57697dda5e44e8574288217c3ee4a.png"></p> 
 <p>Codesearchnet是一个包含来自 GitHub 上托管的开源库的200万对(注释、代码)的数据集。它包括6种编程语言的代码和文档。我们选择 CodeSearchNet 作为我们的基础数据集，并应用基于 coreset 的选择方法KCenterGreedy来最大化原始代码的多样性。</p> 
 <p>具体来说，生成器根据输入（a）生成指令数据。随后，判别器接受输出并生成分析结果，输出（b）包括四个键，研究人员将这些信息作为指令调优的输入和输出。</p> 
 <p>分析（c）包括每条规则的详细原因和总体答案，以检查样本是否满足所有要求。</p> 
 <p><img src="https://images2.imgbox.com/c2/25/76HIlB64_o.png" alt="b0b3e654a2d0a72422ed06cfde6baaef.png"></p> 
 <p>实验评估结果</p> 
 <h3><br></h3> 
 <p><strong>代码生成任务评估</strong></p> 
 <p>表3显示了两个基准上不同大模型的pass@1得分。从结果来看，我们有以下观察结果:</p> 
 <p>WaveCoder大大优于使用少于20k指令调优数据（InsT Data）的指令模型训练。</p> 
 <p>经过微调过程，与基础模型和开源模型的选择相比，最新模型的性能显示出实质性的改善，但它仍然落后于专有模型的指导模型训练超过70k的训练数据。</p> 
 <p><img src="https://images2.imgbox.com/3f/e1/uVDdFW0c_o.png" alt="1eff3ed36ca3ee668cd48919b15be491.png"></p> 
 <p>研究人员还用HumanEvalPack上最先进的Code LLM对WaveCoder进行评分，如表4。</p> 
 <p><img src="https://images2.imgbox.com/90/c2/2U6PmllT_o.png" alt="31481bd9d65835fe7f9c8e80f3fc1830.png"></p> 
 <p>表5列出了WaveCoder在代码汇总任务方面的结果，突出显示了以下显著的观察结果:</p> 
 <p><img src="https://images2.imgbox.com/02/44/4lu1m6Sf_o.png" alt="6566b34fdbaaa1c06ccf39250e1af31e.png"></p> 
 <p style="text-align:left;">参考资料：</p> 
 <p>https://arxiv.org/abs/2312.14187</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/8a/3b/TISJaagj_o.png" alt="b26c8c1ad66bb7b2a7dc2ab6951f4cfc.png"></p> 
 <p><img src="https://images2.imgbox.com/bf/3e/XY43N6Xf_o.png" alt="outside_default.png"></p> 
 <p>点个在看 paper不断！</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2d48314bf435e370e65f9aaa3a0c75a6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">第10课 实现多对多音视频会议功能</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f40351db7bb0d535b4dac83468b5e9d9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">全球排名第六！北京程序员年薪中位数超 60 万元，2023 全球程序员收入报告出炉...</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>