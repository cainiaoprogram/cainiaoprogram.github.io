<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>RTMP直播推流（二）音频推流 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="RTMP直播推流（二）音频推流" />
<meta property="og:description" content="音频推流java层代码：
package com.example.push.channel; import static android.media.AudioFormat.CHANNEL_IN_STEREO; import android.media.AudioFormat; import android.media.AudioRecord; import android.media.MediaRecorder; import com.example.push.LivePusher; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; public class AudioChannel { private int inputSamples; private ExecutorService executor; private AudioRecord audioRecord; private LivePusher mLivePusher; private int channels=2; private boolean isLiving; public AudioChannel(LivePusher livePusher){ mLivePusher=livePusher; //启动一个线程 线程池 executor = Executors.newSingleThreadExecutor(); //准备录音机 来采集pcm数据 传送到native层 int channelConfig; if (channels==2){ channelConfig= AudioFormat.CHANNEL_IN_STEREO; }else { channelConfig= AudioFormat.CHANNEL_IN_MONO; } mLivePusher.native_setAudioEncInfo( 44100, channels) ; //16位 两个字节 inputSamples= mLivePusher." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e4a212c0f2f680a1b3fe65dbf2e4b149/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-08T20:53:25+08:00" />
<meta property="article:modified_time" content="2022-10-08T20:53:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">RTMP直播推流（二）音频推流</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>音频推流java层代码：</p> 
<pre><code class="hljs">package com.example.push.channel;

import static android.media.AudioFormat.CHANNEL_IN_STEREO;

import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;

import com.example.push.LivePusher;

import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

public class AudioChannel {

    private  int inputSamples;
    private  ExecutorService executor;
    private  AudioRecord audioRecord;
    private LivePusher mLivePusher;
    private int channels=2;
    private boolean isLiving;

    public AudioChannel(LivePusher livePusher){
        mLivePusher=livePusher;
        //启动一个线程 线程池
         executor = Executors.newSingleThreadExecutor();
        //准备录音机 来采集pcm数据 传送到native层
        int channelConfig;
        if (channels==2){
           channelConfig= AudioFormat.CHANNEL_IN_STEREO;
        }else {
            channelConfig= AudioFormat.CHANNEL_IN_MONO;
        }

        mLivePusher.native_setAudioEncInfo( 44100, channels) ;
        //16位 两个字节
         inputSamples= mLivePusher.getInputSamples()*2;

        //最小需要的缓冲区
        int minBufferSize= AudioRecord.getMinBufferSize( 44100,channelConfig,AudioFormat.ENCODING_PCM_16BIT )*2;
        //1、麦克风 2、采样率 3、声道数
        audioRecord=new AudioRecord( MediaRecorder.AudioSource.MIC,44100,channelConfig,AudioFormat.ENCODING_PCM_16BIT ,minBufferSize&gt;inputSamples?minBufferSize:inputSamples);
    }

    public void startLive() {
        isLiving=true;
        executor.submit( new AudioTeask() );
    }
    public void stopLive() {
        isLiving=false;
    }

    public void release(){
       audioRecord.release();
    }

    class AudioTeask implements Runnable{

        @Override
        public void run() {
           //启动录音机
            audioRecord.startRecording();
            byte[] bytes=new byte[inputSamples];
            while (isLiving){
                int len=audioRecord.read( bytes,0,bytes.length);
               if (len&gt;0){
                   //送去编码
                   mLivePusher.native_pushAudio( bytes );
               }
            }
            //停止录音机
            audioRecord.stop();
        }
    }
}
</code></pre> 
<p>和直播推流类似：</p> 
<pre><code class="hljs">extern "C"
JNIEXPORT void JNICALL
Java_com_example_push_LivePusher_native_1setAudioEncInfo(JNIEnv *env, jobject instance, jint sampleRateInHz,
                                                           jint channels) {
    // TODO: implement native_setAudioEncInfo()
    if (audioChannel){
        audioChannel-&gt;setAudioEncInfo(sampleRateInHz,channels);
    }
}

extern "C"
JNIEXPORT jint JNICALL
Java_com_example_push_LivePusher_getInputSamples(JNIEnv *env, jobject instance) {
    if (audioChannel){
        return audioChannel-&gt;getInputSamples();
    }
    return -1;
}
extern "C"
JNIEXPORT void JNICALL
Java_com_example_push_LivePusher_native_1pushAudio(JNIEnv *env, jobject instance, jbyteArray data_) {


    if (!audioChannel || !readyPushing) {
        return;
    }
    jbyte *data = env-&gt;GetByteArrayElements(data_, NULL);
    audioChannel-&gt;encodeData(data);
    env-&gt;ReleaseByteArrayElements(data_, data, 0);

}</code></pre> 
<p>faac初始化</p> 
<pre><code class="hljs">void AudioChannel::setAudioEncInfo(int samplesInHZ, int channels) {
    //打开编码器
    mChannels=channels;

    //3、一次最大能输入编码器的样本数量 要编码的数据个数
    //4、最大可能的输出数据  编码后的最大字节数
     audioCodec=faacEncOpen(samplesInHZ,channels,&amp;inputSamples,&amp;maxOutputBytes);

     //设置编码器参数
     faacEncConfigurationPtr config= faacEncGetCurrentConfiguration(audioCodec);
     //指定为 mpeg4标准
     config-&gt;mpegVersion=MPEG4;
     //lc标准
     config-&gt;aacObjectType=LOW;
     //16位
     config-&gt;inputFormat=FAAC_INPUT_16BIT;
     //编码出原始数据 既不是adts也不是adif
     config-&gt;outputFormat=0;
    faacEncSetConfiguration(audioCodec,config);

    //输出缓冲区 编码后的数据 用这个缓冲区来保存
    buffer=new u_char[maxOutputBytes];
}</code></pre> 
<p>发送faac编码的音频头</p> 
<pre><code class="hljs">RTMPPacket *AudioChannel::getAudioTag() {
    u_char *buf;
    u_long len;
    faacEncGetDecoderSpecificInfo(audioCodec, &amp;buf, &amp;len);
    int bodySize = 2 + len;
    RTMPPacket *packet = new RTMPPacket;
    RTMPPacket_Alloc(packet, bodySize);
    //双声道
    packet-&gt;m_body[0] = 0xAF;
    if (mChannels == 1) {
        packet-&gt;m_body[0] = 0xAE;
    }
    packet-&gt;m_body[1] = 0x00;
    //图片数据
    memcpy(&amp;packet-&gt;m_body[2], buf, len);

    packet-&gt;m_hasAbsTimestamp = 0;
    packet-&gt;m_nBodySize = bodySize;
    packet-&gt;m_packetType = RTMP_PACKET_TYPE_AUDIO;
    packet-&gt;m_nChannel = 0x11;
    packet-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
    return packet;
}</code></pre> 
<p>发送音频数据</p> 
<pre><code class="hljs">void AudioChannel::encodeData(int8_t *data) {
    //音频编码  返回编码后数据字节的长度
    int bytelen=faacEncEncode(audioCodec, reinterpret_cast&lt;int32_t *&gt;(data), inputSamples, buffer, maxOutputBytes);
    if (bytelen &gt; 0) {
        //看表
        int bodySize = 2 + bytelen;
        RTMPPacket *packet = new RTMPPacket;
        RTMPPacket_Alloc(packet, bodySize);
        //双声道
        packet-&gt;m_body[0] = 0xAF;
        if (mChannels == 1) {
            packet-&gt;m_body[0] = 0xAE;
        }
        //编码出的声音 都是 0x01
        packet-&gt;m_body[1] = 0x01;
        //图片数据
        memcpy(&amp;packet-&gt;m_body[2], buffer, bytelen);

        packet-&gt;m_hasAbsTimestamp = 0;
        packet-&gt;m_nBodySize = bodySize;
        packet-&gt;m_packetType = RTMP_PACKET_TYPE_AUDIO;
        packet-&gt;m_nChannel = 0x11;
        packet-&gt;m_headerType = RTMP_PACKET_SIZE_LARGE;
        audioCallback(packet);
    }</code></pre> 
<p>效果图：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/9c/39/KD0qQOIA_o.png"></p> 
<p> 链接：https://pan.baidu.com/s/1T6wqTbJweKEeanTz9gR1ow <br> 提取码：9jgr <br>  </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/af943f1dd0a8f0915525c2bda3fd936a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">全排列demo</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a7cefcafb0a0a9881d0a5374dd61ad94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">HTML教程</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>