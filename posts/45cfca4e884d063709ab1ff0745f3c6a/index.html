<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【图神经网络】使用DGL框架实现简单图分类任务 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【图神经网络】使用DGL框架实现简单图分类任务" />
<meta property="og:description" content="使用DGL框架实现简单图分类任务 简单图分类任务实现过程打包一个图的小批量定义图分类器图卷积读出和分类 准备和训练核心代码参考资料 图分类（预测图的标签）是图结构数据里一类重要的问题。它的应用广泛，可见于生物信息学、化学信息学、社交网络分析、城市计算以及网络安全。随着近来学界对于图神经网络的热情持续高涨，出现了一批用图神经网络做图分类的工作。比如 训练图神经网络来预测蛋白质结构的性质，根据社交网络结构来预测用户的所属社区等（Ying et al., 2018, Cangea et al., 2018, Knyazev et al., 2018, Bianchi et al., 2019, Liao et al., 2019, Gao et al., 2019）。 本文使用DGL框架实现简单的图分类任务，任务目标有两个：
如何使用DGL批量化处理大小各异的图数据训练图神经网络完成一个简单的图分类任务 简单图分类任务 这里设计了一个简单的图分类任务。在DGL里已经实现了一个迷你图分类数据集（MiniGCDataset）。它由以下8类图结构数据组成。每一类图包含同样数量的随机样本。任务目标是训练图神经网络模型对这些样本进行分类。
实现过程 以下是使用 MiniGCDataset 的示例代码。
首先，创建了一个拥有 100 个样本的数据集。数据集中每张图随机有 16 到 32 个节点。DGL 中所有的数据集类都符合 Sequence 的抽象结构——既可以使用 dataset[i] 来访问第 i 个样本。这里每个样本包含图结构以及它对应的标签。
运行以上代码，可以画出数据集中第64个样本的图结果及其对应的标签：
打包一个图的小批量 为了更高效地训练神经网络，一个常见的做法是将多个样本打包成小批量（mini-batch）。打包尺寸相同的张量样本非常简单。比如说打包两个尺寸为 2828 的图片会得到一个 22828 的张量。相较之下，打包图面临两个挑战：
（1）图的边比较稀疏
（2）图的大小、形状各不相同
DGL 提供了名为 dgl.batch 的接口来实现打包一个图批量的功能。其核心思路非常简单**。将 n 张小图打包在一起的操作可以看成是生成一张含 n 个不相连小图的大图**。下图的可视化从直觉上解释了 dgl.batch 的功能。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/45cfca4e884d063709ab1ff0745f3c6a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-17T11:33:02+08:00" />
<meta property="article:modified_time" content="2022-11-17T11:33:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【图神经网络】使用DGL框架实现简单图分类任务</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>使用DGL框架实现简单图分类任务</h4> 
 <ul><li><a href="#_7" rel="nofollow">简单图分类任务</a></li><li><ul><li><a href="#_10" rel="nofollow">实现过程</a></li><li><a href="#_16" rel="nofollow">打包一个图的小批量</a></li><li><a href="#_37" rel="nofollow">定义图分类器</a></li><li><ul><li><a href="#_45" rel="nofollow">图卷积</a></li><li><a href="#_100" rel="nofollow">读出和分类</a></li></ul> 
   </li><li><a href="#_131" rel="nofollow">准备和训练</a></li><li><a href="#_181" rel="nofollow">核心代码</a></li><li><a href="#_245" rel="nofollow">参考资料</a></li></ul> 
 </li></ul> 
</div> 
<br> 
<strong>图分类（预测图的标签）是图结构数据里一类重要的问题</strong>。它的应用广泛，可见于生物信息学、化学信息学、社交网络分析、城市计算以及网络安全。随着近来学界对于图神经网络的热情持续高涨，出现了一批用图神经网络做图分类的工作。比如 
<strong>训练图神经网络来预测蛋白质结构的性质，根据社交网络结构来预测用户的所属社区</strong>等（Ying et al., 2018, Cangea et al., 2018, Knyazev et al., 2018, Bianchi et al., 2019, Liao et al., 2019, Gao et al., 2019）。 
<p></p> 
<p>本文使用DGL框架实现简单的图分类任务，任务目标有两个：</p> 
<ol><li>如何使用DGL批量化处理大小各异的图数据</li><li>训练图神经网络完成一个简单的图分类任务</li></ol> 
<h2><a id="_7"></a>简单图分类任务</h2> 
<p>这里设计了一个简单的图分类任务。在DGL里已经实现了一个迷你图分类数据集（MiniGCDataset）。它由以下8类图结构数据组成。每一类图包含同样数量的随机样本。任务目标是训练图神经网络模型对这些样本进行分类。<br> <img src="https://images2.imgbox.com/f2/0d/Ag8IOmyu_o.png" alt="DGL框架中的8中图"></p> 
<h3><a id="_10"></a>实现过程</h3> 
<p>以下是使用 MiniGCDataset 的示例代码。<br> 首先，创建了一个拥有 100 个样本的数据集。数据集中每张图随机有 16 到 32 个节点。DGL 中所有的数据集类都符合 Sequence 的抽象结构——既可以使用 dataset[i] 来访问第 i 个样本。这里每个样本包含图结构以及它对应的标签。<br> <img src="https://images2.imgbox.com/de/de/79czBDTp_o.png" alt="创建数据集"><br> 运行以上代码，可以画出数据集中第64个样本的图结果及其对应的标签：<br> <img src="https://images2.imgbox.com/bb/2d/GbkgJKe1_o.png" alt="网格图"></p> 
<h3><a id="_16"></a>打包一个图的小批量</h3> 
<p>为了更高效地训练神经网络，一个常见的做法是<strong>将多个样本打包成小批量（mini-batch）</strong>。打包尺寸相同的张量样本非常简单。比如说打包两个尺寸为 2828 的图片会得到一个 22828 的张量。相较之下，<strong>打包图面临两个挑战</strong>：<br> （1）图的边比较稀疏<br> （2）图的大小、形状各不相同</p> 
<p>DGL 提供了名为 <code>dgl.batch</code> 的接口来实现打包一个图批量的功能。其核心思路非常简单**。将 n 张小图打包在一起的操作可以看成是生成一张含 n 个不相连小图的大图**。下图的可视化从直觉上解释了 dgl.batch 的功能。<br> <img src="https://images2.imgbox.com/ab/bb/9PEKT6Zr_o.png" alt="dgl.batch"><br> 可以看到通过 dgl.batch 操作，生成了一张大图，其中包含了一个环状和一个星状的连通分量。其<strong>邻接矩阵表示则对应为在对角线上把两张小图的邻接矩阵拼接在一起（其余部分都为 0）</strong>。</p> 
<p>以下是使用 dgl.batch 的一个实际例子。这里，定义了一个 collate 函数来将 MiniGCDataset 里多个样本打包成一个小批量。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> dgl

<span class="token keyword">def</span> <span class="token function">collate</span><span class="token punctuation">(</span>samples<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 输入“samples”是一个列表</span>
    <span class="token comment"># 每个元素都是一个二元组(图，标签)</span>
    graphs<span class="token punctuation">,</span> labels <span class="token operator">=</span> <span class="token builtin">map</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">,</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token operator">*</span>samples<span class="token punctuation">)</span><span class="token punctuation">)</span>
    batched_graph <span class="token operator">=</span> dgl<span class="token punctuation">.</span>batch<span class="token punctuation">(</span>graphs<span class="token punctuation">)</span>
    <span class="token keyword">return</span> batched_graph<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>labels<span class="token punctuation">)</span>
</code></pre> 
<p>正如打包 N 个张量得到的还是张量，<strong>dgl.batch 返回的也是一张图</strong>。这样的设计有两点好处。<strong>首先，任何用于操作一张小图的代码可以被直接使用在一个图批量上。其次，由于 DGL 能够并行处理图中节点和边上的计算，因此同一批量内的图样本都可以被并行计算</strong>。</p> 
<h3><a id="_37"></a>定义图分类器</h3> 
<p>这里使用的图分类器和应用在图像或者语音上的分类器类似——<strong>先通过多层神经网络计算每个样本的表示（representation），再通过表示计算出每个类别的概率，最后通过向后传播计算梯度</strong>。一个常见的图分类器由以下几个步骤构成：</p> 
<ol><li>通过图卷积（Graph Convolution）层获得图中每个节点的表示。</li><li>使用「读出」操作（Readout）获得每张图的表示。</li><li>使用 Softmax 计算每个类别的概率，使用向后传播更新参数。</li></ol> 
<p>下图展示了整个流程：<br> <img src="https://images2.imgbox.com/e0/79/ZdC4dUXS_o.png" alt="图分类器的步骤">之后我们将分步讲解每一个步骤。</p> 
<h4><a id="_45"></a>图卷积</h4> 
<p>我们的图卷积操作基本类似图卷积网络 GCN（具体可以参见我们的关于 GCN 的教程）。图卷积模型可以用以下公式表示：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           h 
          
         
           v 
          
          
          
            l 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
        
          R 
         
        
          e 
         
        
          L 
         
        
          U 
         
        
          ( 
         
         
         
           b 
          
          
          
            ( 
           
          
            l 
           
          
            ) 
           
          
         
        
          + 
         
         
         
           ∑ 
          
          
          
            u 
           
          
            ∈ 
           
          
            N 
           
          
            ( 
           
          
            v 
           
          
            ) 
           
          
         
         
         
           h 
          
         
           u 
          
          
          
            ( 
           
          
            l 
           
          
            ) 
           
          
         
         
         
           W 
          
          
          
            ( 
           
          
            l 
           
          
            ) 
           
          
         
        
          ) 
         
        
       
         h_v^{l+1}=ReLU(b^{(l)}+\sum_{u\in N(v)}h_{u}^{(l)}W^{(l)}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.14611em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right: 0.10903em;">U</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 2.56601em; vertical-align: -1.51601em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05001em;"><span class="" style="top: -1.80899em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mclose mtight">)</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.51601em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 在这个例子中，对这个公式进行了微调：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           h 
          
         
           v 
          
          
          
            l 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
        
          R 
         
        
          e 
         
        
          L 
         
        
          U 
         
        
          ( 
         
         
         
           b 
          
          
          
            ( 
           
          
            l 
           
          
            ) 
           
          
         
        
          + 
         
         
         
           1 
          
          
          
            ∣ 
           
          
            N 
           
          
            ( 
           
          
            v 
           
          
            ) 
           
          
            ∣ 
           
          
         
         
         
           ∑ 
          
          
          
            u 
           
          
            ∈ 
           
          
            N 
           
          
            ( 
           
          
            v 
           
          
            ) 
           
          
         
         
         
           h 
          
         
           u 
          
          
          
            ( 
           
          
            l 
           
          
            ) 
           
          
         
         
         
           W 
          
          
          
            ( 
           
          
            l 
           
          
            ) 
           
          
         
        
          ) 
         
        
       
         h_v^{l+1}=ReLU(b^{(l)}+\frac{1}{|N(v)|} \sum_{u\in N(v)}h_{u}^{(l)}W^{(l)}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.14611em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.899108em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.188em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.00773em;">R</span><span class="mord mathdefault">e</span><span class="mord mathdefault">L</span><span class="mord mathdefault" style="margin-right: 0.10903em;">U</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">b</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 2.83744em; vertical-align: -1.51601em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathdefault" style="margin-right: 0.10903em;">N</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.03588em;">v</span><span class="mclose">)</span><span class="mord">∣</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05001em;"><span class="" style="top: -1.80899em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right: 0.10903em;">N</span><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mclose mtight">)</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.51601em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">u</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.938em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right: 0.01968em;">l</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 我们将求和替换成求平均可用来平衡度数不同的节点，在实验中这也带来了模型表现的提升。</p> 
<p>此外，<strong>在构建数据集时，给每个图里所有的节点都加上了和自己的边（自环）。这保证节点在收集邻居节点表示进行更新时也能考虑到自己原有的表示</strong>。以下是定义图卷积模型的代码。这里使用 PyTorch 作为 DGL 的后端引擎（DGL 也支持 MXNet 作为后端）。</p> 
<p>首先，使用 DGL 的内置函数定义消息传递：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> dgl<span class="token punctuation">.</span>function <span class="token keyword">as</span> fn
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn

<span class="token comment"># 将节点表示h作为信息发出</span>
msg <span class="token operator">=</span> fn<span class="token punctuation">.</span>copy_src<span class="token punctuation">(</span>src<span class="token operator">=</span><span class="token string">'h'</span><span class="token punctuation">,</span>out<span class="token operator">=</span><span class="token string">'m'</span><span class="token punctuation">)</span>
</code></pre> 
<p>其次，定义消息累和函数。这里我们对收到的消息进行平均。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">reduce</span><span class="token punctuation">(</span>nodes<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""对所有邻接点节点特征求平均并覆盖原本的节点特征"""</span>
    accum <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>nodes<span class="token punctuation">.</span>mailbox<span class="token punctuation">[</span><span class="token string">'m'</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">'h'</span><span class="token punctuation">:</span>accum<span class="token punctuation">}</span>
</code></pre> 
<p>之后，对收到的消息应用线性变换和激活函数。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">NodeApplyModule</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""将节点特征hv更新为ReLU(Whv+b)"""</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>NodeApplyModule<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>activation <span class="token operator">=</span> activation

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> node<span class="token punctuation">)</span><span class="token punctuation">:</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>node<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        h <span class="token operator">=</span> self<span class="token punctuation">.</span>activation<span class="token punctuation">(</span>h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span><span class="token string">'h'</span><span class="token punctuation">:</span> h<span class="token punctuation">}</span>
</code></pre> 
<p>最后，把所有的小模块串联起来成为 GCNLayer。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">GCNLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> activation<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GCNLayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>apply_mod <span class="token operator">=</span> NodeApplyModule<span class="token punctuation">(</span>in_feats<span class="token punctuation">,</span> out_feats<span class="token punctuation">,</span> activation<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">,</span> feature<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用 h 初始化节点特征</span>
        g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> feature
        <span class="token comment"># 使用 update_all 接口和自定义的消息传递及累和函数更新节点表示</span>
        g<span class="token punctuation">.</span>update_all<span class="token punctuation">(</span>msg<span class="token punctuation">,</span> <span class="token builtin">reduce</span><span class="token punctuation">)</span>
        g<span class="token punctuation">.</span>apply_nodes<span class="token punctuation">(</span>func<span class="token operator">=</span>self<span class="token punctuation">.</span>apply_mod<span class="token punctuation">)</span>
        <span class="token keyword">return</span> g<span class="token punctuation">.</span>ndata<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token string">'h'</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_100"></a>读出和分类</h4> 
<p>读出（<code>Readout</code>）操作的输入是图中所有节点的表示，输出则是整张图的表示。在 Google 的 Neural Message Passing for Quantum Chemistry(Gilmer et al. 2017) 论文中总结过许多不同种类的读出函数。在这个示例里，我们对图中所有节点表示取平均以作为图的表示：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           h 
          
         
           g 
          
         
        
          = 
         
         
         
           1 
          
          
          
            ∣ 
           
          
            V 
           
          
            ∣ 
           
          
         
         
         
           ∑ 
          
          
          
            v 
           
          
            ∈ 
           
          
            V 
           
          
         
         
         
           h 
          
         
           v 
          
         
        
       
         h_g=\frac{1}{|V|}\sum_{v\in V}h_v 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.980548em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">g</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.64315em; vertical-align: -1.32171em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.32144em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathdefault" style="margin-right: 0.22222em;">V</span><span class="mord">∣</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.936em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.05001em;"><span class="" style="top: -1.85566em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span><span class="mrel mtight">∈</span><span class="mord mathdefault mtight" style="margin-right: 0.22222em;">V</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.32171em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord"><span class="mord mathdefault">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.151392em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.03588em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></p> 
<p>DGL 提供了许多读出函数接口，以上公式可以很方便地用 <code>dgl.mean(g) </code>完成。<strong>最后将图的表示输入分类器。分类器对图表示先做了一个线性变换，然后得到每一类在 softmax 之前的 logits</strong>。具体代码如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">class</span> <span class="token class-name">Classifier</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> n_classes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Classifier<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 两层图卷积层</span>
        self<span class="token punctuation">.</span>layers <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>
            GCNLayer<span class="token punctuation">(</span>in_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">)</span><span class="token punctuation">,</span>
            GCNLayer<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">)</span>
        <span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 分类层</span>
        self<span class="token punctuation">.</span>classify <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span> n_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> g<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 使用节点度数作为初始节点表示</span>
        h <span class="token operator">=</span> g<span class="token punctuation">.</span>in_degrees<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 图卷积层</span>
        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
            h <span class="token operator">=</span> conv<span class="token punctuation">(</span>g<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
            g<span class="token punctuation">.</span>ndata<span class="token punctuation">[</span><span class="token string">'h'</span><span class="token punctuation">]</span> <span class="token operator">=</span> h
            <span class="token comment"># 读出函数</span>
            graph_repr <span class="token operator">=</span> dgl<span class="token punctuation">.</span>mean_nodes<span class="token punctuation">(</span>g<span class="token punctuation">,</span> <span class="token string">'h'</span><span class="token punctuation">)</span>
            <span class="token comment"># 分类层</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>classify<span class="token punctuation">(</span>graph_repr<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="_131"></a>准备和训练</h3> 
<p>阅读到这边的读者可以长舒一口气了。因为之后的训练过程和其他经典的图像，语音分类问题基本一致。首先创建了一个包含 400 张节点数量为 16~32的合成数据集。其中 320 张图作为训练数据集，80 张图作为测试集。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

<span class="token comment"># 创建一个训练数据集和测试数据集</span>
trainset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">320</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
testset <span class="token operator">=</span> MiniGCDataset<span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>

<span class="token comment"># 使用PyTorch的DataLoader和之前定义的collate函数</span>
data_loader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>trainset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate<span class="token punctuation">)</span>
</code></pre> 
<p>其次，创建一个刚刚定义的图神经网络模型对象。</p> 
<pre><code class="prism language-python"><span class="token comment"># 其次创建一个图神经网络模型对象</span>
model <span class="token operator">=</span> Classifier<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> trainset<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>
loss_func <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>训练过程则是经典的反向传播和梯度下降。</p> 
<pre><code class="prism language-python"><span class="token comment"># 训练过程是经典的反向传播和梯度下降</span>
epoch_losses <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">80</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">for</span> <span class="token builtin">iter</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>bg<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>bg<span class="token punctuation">)</span>
        label <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label<span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_loss <span class="token operator">/=</span> <span class="token punctuation">(</span><span class="token builtin">iter</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch {}, loss {:4f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epoch_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    epoch_losses<span class="token punctuation">.</span>append<span class="token punctuation">(</span>epoch_loss<span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：<br> <img src="https://images2.imgbox.com/49/b9/Ega81XyV_o.png" alt="运行结果"><br> 下图是以上模型训练的学习曲线：<br> <img src="https://images2.imgbox.com/53/80/pMpbqRqt_o.png" alt="训练损失变化示意图"><br> 在训练完成后，在测试集上验证模型的表现。出于部署教程的考量，我们限制了模型训练的时间。如果你花更多时间训练模型，应该能得到更好的表现（80%-90%）。</p> 
<p>为了更好地理解模型学到的节点和图的表示，我们使用了 t-SNE 来进行降维和可视化。<br> <img src="https://images2.imgbox.com/13/30/06EN0dcE_o.png" alt="tSNE"><br> 两张小图分别可视化了做完 1 层和 2 层图卷积后的节点表示。不同颜色代表属于不同类别的图的节点。可以看到，经过训练后，属于同一类别的节点表示更加接近。并且，经过两层图卷积后这一聚类效果更明显。其原因是因为两层卷积后每个节点能接收到 2 度范围内的邻居信息。<br> <img src="https://images2.imgbox.com/42/6b/0D8T0Bcb_o.png" alt="readout之后的tSNE"><br> 底部的大图可视化了每张图在做 softmax 前的 logits，也就是图表示。可以看到通过读出函数后，图表示能非常好地各自区分开来。这一区分度比节点表示更加明显。</p> 
<h3><a id="_181"></a>核心代码</h3> 
<pre><code class="prism language-python"><span class="token keyword">import</span> datetime
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

epochs <span class="token operator">=</span> <span class="token number">100</span>
log_step_freq <span class="token operator">=</span> <span class="token number">10</span>

dfhistory <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">,</span> <span class="token string">'loss'</span><span class="token punctuation">,</span> metric_name<span class="token punctuation">,</span> <span class="token string">'val_loss'</span><span class="token punctuation">,</span> <span class="token string">'val'</span> <span class="token operator">+</span> metric_name<span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Start Training........"</span><span class="token punctuation">)</span>
nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d %H:%M:%S'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"=========="</span> <span class="token operator">*</span> <span class="token number">8</span> <span class="token operator">+</span> <span class="token string">"%s"</span> <span class="token operator">%</span> nowtime<span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> epochs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 训练过程</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    epoch_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    metric_sum <span class="token operator">=</span> <span class="token number">0.0</span>
    step <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">for</span> <span class="token builtin">iter</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>bg<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>data_loader<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 梯度清零</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 正向传播损失</span>
        prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>bg<span class="token punctuation">)</span>
        metric<span class="token punctuation">,</span> _ <span class="token operator">=</span> metric_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span>

        label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        <span class="token comment"># 反向传播求梯度</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 打印batch级别日志</span>
        epoch_loss <span class="token operator">+=</span> loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        metric_sum <span class="token operator">+=</span> metric<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> step <span class="token operator">%</span> log_step_freq <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"[step = %d] loss: %.3f, "</span> <span class="token operator">+</span> metric_name <span class="token operator">+</span> <span class="token string">": %.3f"</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token punctuation">(</span>step<span class="token punctuation">,</span> epoch_loss <span class="token operator">/</span> step<span class="token punctuation">,</span> metric_sum <span class="token operator">/</span> step<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># 验证循环</span>
    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    val_loss <span class="token operator">=</span> <span class="token number">0.0</span>
    val_metric <span class="token operator">=</span> <span class="token number">0.0</span>
    val_step <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">for</span> val_iter<span class="token punctuation">,</span> <span class="token punctuation">(</span>bg<span class="token punctuation">,</span> label<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>val_loader<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            prediction <span class="token operator">=</span> model<span class="token punctuation">(</span>bg<span class="token punctuation">)</span>
            val_metric<span class="token punctuation">,</span> y_pred_cls <span class="token operator">=</span> metric_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
            label <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">)</span>
            val_loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>prediction<span class="token punctuation">,</span> label<span class="token punctuation">)</span>

        val_loss <span class="token operator">+=</span> val_loss<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        val_metric <span class="token operator">+=</span> val_metric<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># 记录日志</span>
    info <span class="token operator">=</span> <span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epoch_loss <span class="token operator">/</span> step<span class="token punctuation">,</span> metric_sum <span class="token operator">/</span> step<span class="token punctuation">,</span>
            val_loss <span class="token operator">/</span> val_step<span class="token punctuation">,</span> val_metric <span class="token operator">/</span> val_step<span class="token punctuation">)</span>
    dfhistory<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>epoch <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> info
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">"\nEPOCH = %d, loss = %.3f,"</span> <span class="token operator">+</span> metric_name <span class="token operator">+</span>
           <span class="token string">"  = %.3f, val_loss = %.3f, "</span> <span class="token operator">+</span> <span class="token string">"val_"</span> <span class="token operator">+</span> metric_name <span class="token operator">+</span> <span class="token string">" = %.3f"</span><span class="token punctuation">)</span>
          <span class="token operator">%</span> info<span class="token punctuation">)</span>
    nowtime <span class="token operator">=</span> datetime<span class="token punctuation">.</span>datetime<span class="token punctuation">.</span>now<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>strftime<span class="token punctuation">(</span><span class="token string">'%Y-%m-%d %H:%M:%S'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"\n"</span> <span class="token operator">+</span> <span class="token string">"=========="</span> <span class="token operator">*</span> <span class="token number">8</span> <span class="token operator">+</span> <span class="token string">"%s"</span> <span class="token operator">%</span> nowtime<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Finished Training..."</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/6f/5d/qvCOBvvr_o.png" alt="运行结果"></p> 
<h3><a id="_245"></a>参考资料</h3> 
<p>[1] https://www.jiqizhixin.com/articles/2019-01-29-2<br> [2] <a href="https://blog.csdn.net/m0_37833142/article/details/106447751">Task4：Pytorch实现模型训练与验证</a><br> [3] <a href="https://blog.csdn.net/wuzhongqiang/article/details/108880745">Pytorch实战总结篇之模型训练、评估与使用</a><br> [4] <a href="https://blog.csdn.net/leida_wt/article/details/84993848">t-SNE及pytorch实现</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ab6beabb0aa3cd97da9368bd7b3a2011/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">HCSC: Hierarchical Contrastive Selective Coding</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3a077f097a3b69f9fdda57b74feb8bdd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">信息安全——维吉尼亚密码算法（C&#43;&#43;实现）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>