<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>opencv学习——cv2.findHomography() - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="opencv学习——cv2.findHomography()" />
<meta property="og:description" content="＃第三个参数用于计算单应矩阵的方法。 可以使用以下方法： ＃0 - 使用所有点的常规方法 #CV_RANSAC - 基于RANSAC的鲁棒方法 #CV_LMEDS - 最少中位数的鲁棒方法 ＃第四个参数取值范围在1到10，绝一个点对的阈值。原图像的点经过变换后点与目标图像上对应点的误差 ＃超过误差就认为是异常值 ＃返回值中H为变换矩阵.mask是掩模，在线的点 H，mask = cv2.findHomography（src_pts，dst_pts，cv2.RANSAC，5.0） 我们之前使用了查询图像，找到其中的一些特征点，我们取另外一个训练图像，找到里面的特征，我们找到它们中间最匹配的。简单说就是我们在一组图像里找一个目标的某个部分的位置。
我们可以使用一个calib3d模块里的函数，cv2.findHomography().如果我们传了两个图像里的点集合，它会找到那个目标的透视转换。然后我们可以使用cv2.perspectiveTransform()来找目标，它需要至少4个正确的点来找变换。
我们看过可能会有一些匹配是的错误而影响结果。哟啊解决这个问题，算法使用了RANSAC或者LEAST_MEDIAN（由标志决定）。提供正确估计的好的匹配被叫做inliers，而其他的叫做outliers。cv2.findHomography()返回一个掩图来指定inlier和outlier。
code
首先，和正常一样，我们找到SIFT特征，用比率检测来找最匹配的。
import numpy as np
import cv2
from matplotlib import pyplot as plt
MIN_MATCH_COUNT = 10
img1 = cv2.imread(&#39;box.png&#39;,0) # queryImage
img2 = cv2.imread(&#39;box_in_scene.png&#39;,0) # trainImage
# Initiate SIFT detector
sift = cv2.SIFT()
# find the keypoints and descriptors with SIFT
kp1, des1 = sift.detectAndCompute(img1,None)
kp2, des2 = sift." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ff2a74b563b8aa586fdff58287cc20f4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-08-04T14:34:00+08:00" />
<meta property="article:modified_time" content="2019-08-04T14:34:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">opencv学习——cv2.findHomography()</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <pre class="has"><code>＃第三个参数用于计算单应矩阵的方法。 可以使用以下方法：
         ＃0  - 使用所有点的常规方法
         #CV_RANSAC  - 基于RANSAC的鲁棒方法
         #CV_LMEDS  - 最少中位数的鲁棒方法
         ＃第四个参数取值范围在1到10，绝一个点对的阈值。原图像的点经过变换后点与目标图像上对应点的误差
         ＃超过误差就认为是异常值
         ＃返回值中H为变换矩阵.mask是掩模，在线的点
         H，mask = cv2.findHomography（src_pts，dst_pts，cv2.RANSAC，5.0）</code></pre> 
<p>我们之前使用了查询图像，找到其中的一些特征点，我们取另外一个训练图像，找到里面的特征，我们找到它们中间最匹配的。简单说就是我们在一组图像里找一个目标的某个部分的位置。</p> 
<p>我们可以使用一个calib3d模块里的函数，cv2.findHomography().如果我们传了两个图像里的点集合，它会找到那个目标的透视转换。然后我们可以使用cv2.perspectiveTransform()来找目标，它需要至少4个正确的点来找变换。</p> 
<p>我们看过可能会有一些匹配是的错误而影响结果。哟啊解决这个问题，算法使用了RANSAC或者LEAST_MEDIAN（由标志决定）。提供正确估计的好的匹配被叫做inliers，而其他的叫做outliers。cv2.findHomography()返回一个掩图来指定inlier和outlier。</p> 
<p>code</p> 
<p>首先，和正常一样，我们找到SIFT特征，用比率检测来找最匹配的。</p> 
<blockquote> 
 <p>import numpy as np<br> import cv2<br> from matplotlib import pyplot as plt</p> 
 <p>MIN_MATCH_COUNT = 10</p> 
 <p>img1 = cv2.imread('box.png',0)          # queryImage<br> img2 = cv2.imread('box_in_scene.png',0) # trainImage</p> 
 <p># Initiate SIFT detector<br> sift = cv2.SIFT()</p> 
 <p># find the keypoints and descriptors with SIFT<br> kp1, des1 = sift.detectAndCompute(img1,None)<br> kp2, des2 = sift.detectAndCompute(img2,None)</p> 
 <p>FLANN_INDEX_KDTREE = 0<br> index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)<br> search_params = dict(checks = 50)</p> 
 <p>flann = cv2.FlannBasedMatcher(index_params, search_params)</p> 
 <p>matches = flann.knnMatch(des1,des2,k=2)</p> 
 <p># store all the good matches as per Lowe's ratio test.<br> good = []<br> for m,n in matches:<br>     if m.distance &lt; 0.7*n.distance:<br>         good.append(m)</p> 
</blockquote> 
<p>现在我们设置一个至少10个匹配的条件（有MIN_MATCH_COUNT指定）来找目标。否则就显示一个信息说没有足够的匹配。</p> 
<p>如果找到了足够的匹配，我们得到两张图像里标记的关键点的位置。他们被传到透视转换。当我们得到了3x3的转换矩阵，我们用它来把查询图像里的角转换到响应的训练图像的对应点。然后画出来。</p> 
<blockquote> 
 <p>if len(good)&gt;MIN_MATCH_COUNT:<br>     src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)<br>     dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)<br>    <br>     M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)<br>     matchesMask = mask.ravel().tolist()<br><br>     h,w = img1.shape<br>     pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)<br>     dst = cv2.perspectiveTransform(pts,M)<br><br>     img2 = cv2.polylines(img2,[np.int32(dst)],True,255,3, cv2.LINE_AA)</p> 
 <p>else:<br>     print "Not enough matches are found - %d/%d" % (len(good),MIN_MATCH_COUNT)<br>     matchesMask = None</p> 
</blockquote> 
<p>最后我们画出我们的inliers(如果成功找到了目标）或者匹配关键点（如果失败了）</p> 
<blockquote> 
 <p>draw_params = dict(matchColor = (0,255,0), # draw matches in green color<br>         singlePointColor = None,<br>         matchesMask = matchesMask, # draw only inliers<br>         flags = 2)</p> 
 <p>img3 = cv2.drawMatches(img1,kp1,img2,kp2,good,None,**draw_params)</p> 
 <p>plt.imshow(img3, 'gray'),plt.show()</p> 
</blockquote> 
<p>看下面的结果，目标被白色标出来</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/b1/ad/a6nH6Gaj_o.jpg"></p> 
<p>END</p> 
<p><br><br> 作者：xxxss<br> 链接：https://www.jianshu.com/p/d835f1a4717c<br> 来源：简书<br> 简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8a7efc8150d0e7ff625c60a361332bb3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C#使用NPOI实现Excel和DataTable的互转</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9d4f26794cd4807487047c967799dba7/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">怎样确定AD采样频率，跟转换时间有关吗。在单片机中如何设置采样频率。</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>