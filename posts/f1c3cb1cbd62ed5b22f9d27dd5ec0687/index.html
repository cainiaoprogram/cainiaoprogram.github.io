<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AI语音合成 VITS Fast Fine-tuning，半小时合成专属模型，部署训练使用讲解 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="AI语音合成 VITS Fast Fine-tuning，半小时合成专属模型，部署训练使用讲解" />
<meta property="og:description" content="前言 项目名：VITS-fast-fine-tuning （VITS 快速微调）
项目地址：https://github.com/Plachtaa/VITS-fast-fine-tuning
支持语言：中、日、英
官方简介：
这个代码库会指导你如何将自定义角色（甚至你自己），加入预训练的VITS模型中，在1小时内的微调使模型具备如下功能：
在 模型所包含的任意两个角色 之间进行声线转换
以 你加入的角色声线 进行中日英三语 文本到语音合成。
本项目使用的底模涵盖常见二次元男/女配音声线（来自原神数据集）以及现实世界常见男/女声线（来自VCTK数据集），支持中日英三语，保证能够在微调时快速适应新的声线。
数据集 干声数据收集 干声，一般指录音以后未经过任何空间性质或的后期处理和加工的纯人声。
为了保证最好的合成效果，数据集越干净越好。当然也不是必须使用干声数据，也可以使用从视频中分离的人声来进行训练，效果也还可以。
录制可以直接使用手机进行录音，如果电脑有效果较好的麦克风，也可以使用麦克风进行录制（如果可以自定义录制音频格式，建议选择wav）。
如果进行视频人声分离，我这给大家推荐几个分离相关的网站和项目。
vocalremover：https://vocalremover.org/zh/
tme_studio：https://y.qq.com/tme_studio/index.html#/editor
UVR5：https://github.com/Anjok07/ultimatevocalremovergui
demucs：https://github.com/facebookresearch/demucs
音频转码 将音频转码为wav格式，码率等配置保持原始音频质量即可。可以使用格式工厂、ShanaEncoder等转码软件进行音频转码。
音频分割 将我们的音频数据切分成多个5-15s的小段，这个范围仅供参考。需要注意的是，如果音频时长过长，在训练过程中会占用更多的显存，所以为了降低显存和显卡负担，建议大家切分成小段。
那么切分方式同样也多种多样，可以使用视频剪辑软件、音频编辑软件、格式转换软件、第三方软件等。
我这边就以windows用户为例，给大家推荐一款开源的音频批量自动分割软件slicer-gui（源自b站），官方下载地址：https://github.com/flutydeer/audio-slicer/releases/download/v1.1.0/slicer-gui-windows-v1.1.0.zip
下载完成，解压后打开，运行slicer-gui.exe
选择待处理的音频文件，设置需要切分的音频参数，选择输出路径，点击start即可。默认配置运行也可以，视情况可以微调参数。(需要注意，软件需要
完成以上分割后，我们将我们分割好的音频文件，存入一个文件夹中，需要注意的是，此文件夹的命名就是我们训练时的说话人配置，所以需要慎重取名，并不要和其他说话人重复。最后将存放音频的文件夹再存入一个名为：custom_character_voice 的文件夹中，最后打包压缩包即可。需要注意，此文件夹在源码中是默认的配置，所以建议大家保持一致，可以避免不必要的麻烦。那么最终的文件目录结构如下：
custom_character_voice ├───speaker0 │ ├───1.wav │ ├───... │ └───2.wav └───speaker1 ├───1.wav ├───... └───2.wav 环境搭建 服务器选购 本文中，以AutoDL平台为例，如果您的个人计算机显卡显存在4GB及以上（建议4GB&#43;），可以使用个人来进行训练。
AutoDL官网：https://www.autodl.com/home
完成注册后，我们选购一台合适的服务器，我这以Tesla T4为例（期间的付费实名等操作这里不做展开）。
服务器购买后，可以使用镜像，平台社区有很多作者发布了自己的镜像，可以搜索vits查找相关镜像。选择做好的镜像可以大大降低我们的环境部署的时间。大家可以直接选择以下的vits-fast的镜像，然后运行我们的服务器。
开机后，在右上角控制台，容器实例中，我们可以看到我们的服务器的相关信息。
点击JupyterLab，打开在线面板，再打开终端。
运行环境和前期准备 由于我选择的镜像是so-vits-svc-v10，会有些许出入，但整体不会对项目运行使用造成影响。
python：3.8.10
我们先安装git，在终端运行命令sudo apt install git -y
然后clone项目到/root目录。（注意，如果您选择的VITS-fast-fine-tuning的镜像，那可能需要先删除默认的VITS-fast-fine-tuning文件夹，重新clone项目）
git clone https://github.com/Plachtaa/VITS-fast-fine-tuning.git 如果您没有选择做好的官方镜像，则需要手动安装相关环境，具体可以参考官方笔记：https://colab." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f1c3cb1cbd62ed5b22f9d27dd5ec0687/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-27T10:03:39+08:00" />
<meta property="article:modified_time" content="2023-07-27T10:03:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AI语音合成 VITS Fast Fine-tuning，半小时合成专属模型，部署训练使用讲解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>前言</h2> 
<p>项目名：VITS-fast-fine-tuning （VITS 快速微调）<br> 项目地址：<a href="https://github.com/Plachtaa/VITS-fast-fine-tuning">https://github.com/Plachtaa/VITS-fast-fine-tuning</a><br> 支持语言：中、日、英<br> 官方简介：<br> 这个代码库会指导你如何将自定义角色（甚至你自己），加入预训练的VITS模型中，在1小时内的微调使模型具备如下功能：<br> 在 模型所包含的任意两个角色 之间进行声线转换<br> 以 你加入的角色声线 进行中日英三语 文本到语音合成。<br> 本项目使用的底模涵盖常见二次元男/女配音声线（来自原神数据集）以及现实世界常见男/女声线（来自VCTK数据集），支持中日英三语，保证能够在微调时快速适应新的声线。</p> 
<h2><a id="_11"></a>数据集</h2> 
<h3><a id="_13"></a>干声数据收集</h3> 
<p>干声，一般指录音以后未经过任何空间性质或的后期处理和加工的纯人声。<br> 为了保证最好的合成效果，数据集越干净越好。当然也不是必须使用干声数据，也可以使用从视频中分离的人声来进行训练，效果也还可以。</p> 
<p>录制可以直接使用手机进行录音，如果电脑有效果较好的麦克风，也可以使用麦克风进行录制（如果可以自定义录制音频格式，建议选择wav）。</p> 
<p>如果进行视频人声分离，我这给大家推荐几个分离相关的网站和项目。</p> 
<ul><li> <p>vocalremover：<a href="https://vocalremover.org/zh/" rel="nofollow">https://vocalremover.org/zh/</a><br> <img src="https://images2.imgbox.com/99/f2/sQZY7x4X_o.png" alt="-"></p> </li><li> <p>tme_studio：<a href="https://y.qq.com/tme_studio/index.html#/editor" rel="nofollow">https://y.qq.com/tme_studio/index.html#/editor</a><br> <img src="https://images2.imgbox.com/5a/aa/j6hO9IE0_o.png" alt="在这里插入图片描述"></p> </li><li> <p>UVR5：<a href="https://github.com/Anjok07/ultimatevocalremovergui">https://github.com/Anjok07/ultimatevocalremovergui</a><br> <img src="https://images2.imgbox.com/be/85/J7HLeN7d_o.png" alt="在这里插入图片描述"></p> </li><li> <p>demucs：<a href="https://github.com/facebookresearch/demucs">https://github.com/facebookresearch/demucs</a><br> <img src="https://images2.imgbox.com/78/c1/heLwEzMf_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<h3><a id="_30"></a>音频转码</h3> 
<p>将音频转码为wav格式，码率等配置保持原始音频质量即可。可以使用格式工厂、ShanaEncoder等转码软件进行音频转码。</p> 
<h3><a id="_32"></a>音频分割</h3> 
<p>将我们的音频数据切分成多个5-15s的小段，这个范围仅供参考。需要注意的是，如果音频时长过长，在训练过程中会占用更多的显存，所以为了降低显存和显卡负担，建议大家切分成小段。</p> 
<p>那么切分方式同样也多种多样，可以使用视频剪辑软件、音频编辑软件、格式转换软件、第三方软件等。<br> 我这边就以windows用户为例，给大家推荐一款开源的音频批量自动分割软件<strong>slicer-gui</strong>（源自b站），官方下载地址：<a href="https://github.com/flutydeer/audio-slicer/releases/download/v1.1.0/slicer-gui-windows-v1.1.0.zip">https://github.com/flutydeer/audio-slicer/releases/download/v1.1.0/slicer-gui-windows-v1.1.0.zip</a></p> 
<p>下载完成，解压后打开，运行<strong>slicer-gui.exe</strong><br> <img src="https://images2.imgbox.com/98/21/fAuj0TVB_o.png" alt="在这里插入图片描述"></p> 
<p>选择待处理的音频文件，设置需要切分的音频参数，选择输出路径，点击<strong>start</strong>即可。默认配置运行也可以，视情况可以微调参数。(需要注意，软件需要<br> <img src="https://images2.imgbox.com/a4/85/epsHyVbS_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/c2/61/l2mWb8e4_o.png" alt="在这里插入图片描述"></p> 
<p>完成以上分割后，我们将我们分割好的音频文件，存入一个文件夹中，需要注意的是，此文件夹的命名就是我们训练时的说话人配置，所以需要慎重取名，并不要和其他说话人重复。最后将存放音频的文件夹再存入一个名为：<strong>custom_character_voice</strong> 的文件夹中，最后打包压缩包即可。需要注意，此文件夹在源码中是默认的配置，所以建议大家保持一致，可以避免不必要的麻烦。那么最终的文件目录结构如下：</p> 
<pre><code>custom_character_voice
├───speaker0
│   ├───1.wav
│   ├───...
│   └───2.wav
└───speaker1
    ├───1.wav
    ├───...
    └───2.wav
</code></pre> 
<h2><a id="_58"></a>环境搭建</h2> 
<h3><a id="_60"></a>服务器选购</h3> 
<p>本文中，以AutoDL平台为例，如果您的个人计算机显卡显存在4GB及以上（建议4GB+），可以使用个人来进行训练。<br> AutoDL官网：<a href="https://www.autodl.com/home" rel="nofollow">https://www.autodl.com/home</a><br> 完成注册后，我们选购一台合适的服务器，我这以Tesla T4为例（期间的付费实名等操作这里不做展开）。<br> <img src="https://images2.imgbox.com/bb/c5/VwoEn1FP_o.png" alt="在这里插入图片描述"></p> 
<p>服务器购买后，可以使用镜像，平台社区有很多作者发布了自己的镜像，可以搜索vits查找相关镜像。选择做好的镜像可以大大降低我们的环境部署的时间。大家可以直接选择以下的vits-fast的镜像，然后运行我们的服务器。<br> <img src="https://images2.imgbox.com/09/f2/crrXIgVe_o.png" alt="在这里插入图片描述"></p> 
<p>开机后，在右上角控制台，容器实例中，我们可以看到我们的服务器的相关信息。<br> <img src="https://images2.imgbox.com/3a/1e/tpQBAyqq_o.png" alt="在这里插入图片描述"><br> 点击<code>JupyterLab</code>，打开在线面板，再打开终端。<br> <img src="https://images2.imgbox.com/a0/53/4IV2QK64_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_75"></a>运行环境和前期准备</h3> 
<p>由于我选择的镜像是so-vits-svc-v10，会有些许出入，但整体不会对项目运行使用造成影响。<br> python：3.8.10<br> <img src="https://images2.imgbox.com/9a/f8/hby63jd1_o.png" alt="在这里插入图片描述"></p> 
<p>我们先安装<strong>git</strong>，在终端运行命令<code>sudo apt install git -y</code><br> 然后clone项目到<code>/root</code>目录。（注意，如果您选择的<strong>VITS-fast-fine-tuning</strong>的镜像，那可能需要先删除默认的<code>VITS-fast-fine-tuning</code>文件夹，重新clone项目）</p> 
<pre><code class="prism language-powershell">git clone https:<span class="token operator">/</span><span class="token operator">/</span>github<span class="token punctuation">.</span>com/Plachtaa/VITS-fast-fine-tuning<span class="token punctuation">.</span>git
</code></pre> 
<p>如果您没有选择做好的官方镜像，则需要手动安装相关环境，具体可以参考官方笔记：<a href="https://colab.research.google.com/drive/1pn1xnFfdLK63gVXDwV4zCXfVeo8c-I-0?usp=sharing" rel="nofollow">https://colab.research.google.com/drive/1pn1xnFfdLK63gVXDwV4zCXfVeo8c-I-0?usp=sharing</a></p> 
<h4><a id="1__90"></a>1. 安装运行环境</h4> 
<pre><code class="prism language-bash"><span class="token builtin class-name">cd</span> VITS-fast-fine-tuning
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> --force-reinstall regex
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> --force-reinstall numba
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> --force-reinstall soundfile
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> --force-reinstall gradio
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token assign-left variable">imageio</span><span class="token operator">==</span><span class="token number">2.4</span>.1
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> youtube-dl
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> moviepy
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">-r</span> requirements.txt
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> pyzmq
<span class="token builtin class-name">cd</span> monotonic_align/
<span class="token function">mkdir</span> monotonic_align
python setup.py build_ext <span class="token parameter variable">--inplace</span>
<span class="token builtin class-name">cd</span> <span class="token punctuation">..</span>
<span class="token function">mkdir</span> pretrained_models
<span class="token function">wget</span> https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/sampled_audio4ft_v2.zip
<span class="token function">unzip</span> sampled_audio4ft_v2.zip
<span class="token function">mkdir</span> video_data
<span class="token function">mkdir</span> raw_audio
<span class="token function">mkdir</span> denoised_audio
<span class="token function">mkdir</span> custom_character_voice
<span class="token function">mkdir</span> segmented_character_voice
</code></pre> 
<h4><a id="2_115"></a>2.下载预训练模型（以下步骤如果不进行训练，皆可以跳过）</h4> 
<p>可以根据自己的需求下载对应的模型，不一定全部都下载。</p> 
<pre><code class="prism language-bash"><span class="token function">mkdir</span> pretrained_models/<span class="token punctuation">{<!-- --></span>C,CJ,CJE<span class="token punctuation">}</span>

<span class="token function">wget</span> https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth <span class="token parameter variable">-O</span> ./pretrained_models/CJ/D_0.pth
<span class="token function">wget</span> https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth <span class="token parameter variable">-O</span> ./pretrained_models/CJ/G_0.pth
<span class="token function">wget</span> https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json <span class="token parameter variable">-O</span> ./pretrained_models/CJ/finetune_speaker.json

<span class="token function">wget</span> https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth <span class="token parameter variable">-O</span> ./pretrained_models/CJE/D_0.pth
<span class="token function">wget</span> https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth <span class="token parameter variable">-O</span> ./pretrained_models/CJE/G_0.pth
<span class="token function">wget</span> https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json <span class="token parameter variable">-O</span> ./pretrained_models/CJE/finetune_speaker.json

<span class="token function">wget</span> https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/D_0.pth <span class="token parameter variable">-O</span> ./pretrained_models/C/D_0.pth
<span class="token function">wget</span> https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/G_0.pth <span class="token parameter variable">-O</span> ./pretrained_models/C/G_0.pth
<span class="token function">wget</span> https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/config.json <span class="token parameter variable">-O</span> ./pretrained_models/C/finetune_speaker.json
</code></pre> 
<p>下载好后，需要将配置文件和预训练模型移动到指定路径，我这里提供了shell脚本，您可以创建名为 init.sh 的文件，贴入以下内容，然后通过 <strong>bash init.sh CJE</strong> 来运行脚本，选择需要使用的预训练模型。最后就是预训练模型的传参，分别是 CJE、CJ、C。</p> 
<pre><code class="prism language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$1</span>"</span> <span class="token operator">=</span> <span class="token string">"CJE"</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/CJE/* pretrained_models/
    <span class="token function">rm</span> <span class="token parameter variable">-rf</span> OUTPUT_MODEL/*
    <span class="token comment">#rm -rf custom_character_voice/*</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/CJE/finetune_speaker.json configs/
<span class="token keyword">elif</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$1</span>"</span> <span class="token operator">=</span> <span class="token string">"CJ"</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/CJ/* pretrained_models/
    <span class="token function">rm</span> <span class="token parameter variable">-rf</span> OUTPUT_MODEL/*
    <span class="token comment">#rm -rf custom_character_voice/*</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/CJ/finetune_speaker.json configs/
<span class="token keyword">elif</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$1</span>"</span> <span class="token operator">=</span> <span class="token string">"C"</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/C/* pretrained_models/
    <span class="token function">rm</span> <span class="token parameter variable">-rf</span> OUTPUT_MODEL/*
    <span class="token comment">#rm -rf custom_character_voice/*</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/C/finetune_speaker.json configs/
<span class="token keyword">else</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/CJE/* pretrained_models/
    <span class="token function">rm</span> <span class="token parameter variable">-rf</span> OUTPUT_MODEL/*
    <span class="token comment">#rm -rf custom_character_voice/*</span>
    <span class="token function">cp</span> <span class="token parameter variable">-rf</span> pretrained_models/CJE/finetune_speaker.json configs/
<span class="token keyword">fi</span>

</code></pre> 
<h4><a id="3_166"></a>3.上传数据集并解压</h4> 
<p>将我们前面准备好的数据集上传到服务器中<br> <img src="https://images2.imgbox.com/75/cc/UQioNby3_o.png" alt="在这里插入图片描述"></p> 
<p>然后使用unzip命令（如果没有可以使用apt安装），解压到项目路径中，注意图片路径<br> <img src="https://images2.imgbox.com/2f/83/6AEm2NKS_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="4_174"></a>4.数据预处理</h4> 
<p>我这里提供了shell脚本，您可以创建一个<strong>data_pre.sh</strong>的文件，将以下内容写入，然后使用<strong>bash data_pre.sh</strong> 运行，第一个传参是选择训练的目标语言（需要有配套的预训练模型），第二个传参为0表示不使用预训练模型，直接进行训练，非0则使用预训练模型。例如： <strong>bash data_pre.sh CJE</strong> 就是使用预训练模型CJE训练CJE三语模型。</p> 
<pre><code class="prism language-bash"><span class="token shebang important">#!/bin/bash</span>
<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token variable">$#</span> <span class="token parameter variable">-eq</span> <span class="token number">1</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>
        <span class="token assign-left variable">lang</span><span class="token operator">=</span><span class="token variable">$1</span>
<span class="token keyword">else</span>
        <span class="token assign-left variable">lang</span><span class="token operator">=</span>CJE
<span class="token keyword">fi</span>
python scripts/video2audio.py
python scripts/denoise_audio.py
python scripts/long_audio_transcribe.py <span class="token parameter variable">--languages</span> <span class="token string">"<span class="token variable">$lang</span>"</span> <span class="token parameter variable">--whisper_size</span> large
python scripts/short_audio_transcribe.py <span class="token parameter variable">--languages</span> <span class="token string">"<span class="token variable">$lang</span>"</span> <span class="token parameter variable">--whisper_size</span> large
python scripts/resample.py

<span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"<span class="token variable">$2</span>"</span> <span class="token operator">=</span> <span class="token string">"0"</span> <span class="token punctuation">]</span>
<span class="token keyword">then</span>
	python preprocess_v2.py <span class="token parameter variable">--languages</span> <span class="token string">"<span class="token variable">$lang</span>"</span>
<span class="token keyword">else</span>
	python preprocess_v2.py <span class="token parameter variable">--add_auxiliary_data</span> True <span class="token parameter variable">--languages</span> <span class="token string">"<span class="token variable">$lang</span>"</span>
<span class="token keyword">fi</span>
</code></pre> 
<h2><a id="_198"></a>训练</h2> 
<p>在完成运行环境和前期准备后，则可以进行我们的训练了。<br> 打开<strong>终端</strong>，在<strong>项目根目录</strong>运行以下命令即可，其中 -m 后为模型输出路径， --max_epochs 后为最大迭代次数，到达后会自动停止。您可以根据自己需求自行更改，默认为存储在 <strong>OUTPUT_MODEL</strong>文件夹中，训练100个迭代。</p> 
<pre><code>mkdir OUTPUT_MODEL
python finetune_speaker_v2.py -m "./OUTPUT_MODEL" --max_epochs "100" --drop_speaker_embed True
</code></pre> 
<p>下面是训练日志内容，可以看到训练相关的配置，迭代次数，损失率，输出的模型等内容。等待训练完成即可，期间也可以随时终止训练。</p> 
<p><img src="https://images2.imgbox.com/38/ff/6kECf8Qz_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_209"></a>推理合成</h2> 
<p>将我们的模型和配置文件放到指定文件夹下（配置文件放到<strong>项目根目录</strong>，模型放到<strong>OUTPUT_MODEL</strong>文件夹下），项目根目录运行以下命令，打开web UI服务，进行推理。其中 --model_dir 后就是模型路径，可以自行修改，配置文件默认读取的 项目路径下的 <strong>finetune_speaker.json</strong> 。<br> 需要注意的是，默认服务跑在 <strong>http://127.0.0.1:7860</strong>，如果您需要公网访问，可以做修改端口至<strong>6006</strong>，开放AutoDL对应实例的<strong>自定义服务</strong>功能，或者自建内网穿透。</p> 
<pre><code class="prism language-bash">python VC_inference.py <span class="token parameter variable">--model_dir</span> ./OUTPUT_MODEL/G_latest.pth <span class="token parameter variable">--share</span> True
</code></pre> 
<p>为了方便，可以在个人电脑上进行合成，将模型和配置文件下载到本地，然后使用官方提供的windows合成包，下载链接：<a href="https://github.com/Plachtaa/VITS-fast-fine-tuning/releases/download/webui-v1.1/inference.rar">https://github.com/Plachtaa/VITS-fast-fine-tuning/releases/download/webui-v1.1/inference.rar</a><br> 解压后，将我们的模型和配置文件都放到解压后的根目录内，模型改名为<strong>G_latest.pth</strong>，配置文件改名为<strong>finetune_speaker.json</strong>，运行<strong>inference.exe</strong>即可自动加载。<br> 页面简单易懂，就可以尽情合成了。<br> <img src="https://images2.imgbox.com/05/f2/XW0ezGK4_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/44ce4178b8b7818db3e68e94f57637fc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Gstreamer-音频数据播放之PCM</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/47e57c07f04f49f1e6b80ccf4b07fcb1/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">LSTM/GRU详细代码解析&#43;完整代码实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>