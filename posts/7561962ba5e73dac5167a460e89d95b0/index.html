<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YoloV5实战：手把手教物体检测——YoloV5 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YoloV5实战：手把手教物体检测——YoloV5" />
<meta property="og:description" content="目录
摘要
训练
1、下载代码
2、配置环境
3、准备数据集
4、生成数据集
5、修改配置参数
6、修改train.py的参数
7、查看训练结果
测试
摘要 YOLOV5严格意义上说并不是YOLO的第五个版本，因为它并没有得到YOLO之父Joe Redmon的认可，但是给出的测试数据总体表现还是不错。详细数据如下：
YOLOv5并不是一个单独的模型，而是一个模型家族，包括了YOLOv5s、YOLOv5m、YOLOv5l、YOLOv5x、YOLOv5x&#43;TTA，这点有点儿像EfficientDet。由于没有找到V5的论文，我们也只能从代码去学习它。总体上和YOLOV4差不多，可以认为是YOLOV5的加强版。
项目地址：GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite
训练 1、下载代码 项目地址：GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite，最近作者又更新了一些代码。
2、配置环境 matplotlib&gt;=3.2.2 numpy&gt;=1.18.5 opencv-python&gt;=4.1.2 pillow PyYAML&gt;=5.3 scipy&gt;=1.4.1 tensorboard&gt;=2.2 torch&gt;=1.6.0 torchvision&gt;=0.7.0 tqdm&gt;=4.41.0 3、准备数据集 数据集采用Labelme标注的数据格式，数据集从RSOD数据集中获取了飞机和油桶两类数据集，并将其转为Labelme标注的数据集。
数据集的地址： https://pan.baidu.com/s/1iTUpvA9_cwx1qiH8zbRmDg
提取码：gr6g
或者：LabelmeData.zip_物体检测yolov5-深度学习文档类资源-CSDN下载
将下载的数据集解压后放到工程的根目录。为下一步生成测试用的数据集做准备。如下图：
4、生成数据集 YoloV5的数据集和以前版本的数据集并不相同，我们先看一下转换后的数据集。
数据结构如下图：
images文件夹存放train和val的图片
labels里面存放train和val的物体数据，里面的每个txt文件和images里面的图片是一一对应的。
txt文件的内容如下：
格式：物体类别 x y w h 坐标是不是真实的坐标，是将坐标除以宽高后的计算出来的，是相对于宽和高的比例。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7561962ba5e73dac5167a460e89d95b0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-26T16:02:09+08:00" />
<meta property="article:modified_time" content="2022-12-26T16:02:09+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YoloV5实战：手把手教物体检测——YoloV5</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"></p> 
<p><strong>目录</strong></p> 
<p id="%E6%91%98%E8%A6%81-toc" style="margin-left:0px;"><a href="#%E6%91%98%E8%A6%81" rel="nofollow">摘要</a></p> 
<p id="%E8%AE%AD%E7%BB%83-toc" style="margin-left:0px;"><a href="#%E8%AE%AD%E7%BB%83" rel="nofollow">训练</a></p> 
<p id="1%E3%80%81%E4%B8%8B%E8%BD%BD%E4%BB%A3%E7%A0%81-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E4%B8%8B%E8%BD%BD%E4%BB%A3%E7%A0%81" rel="nofollow">1、下载代码</a></p> 
<p id="2%E3%80%81%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83" rel="nofollow">2、配置环境</a></p> 
<p id="3%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#3%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">3、准备数据集</a></p> 
<p id="4%E3%80%81%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#4%E3%80%81%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">4、生成数据集</a></p> 
<p id="5%E3%80%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0-toc" style="margin-left:40px;"><a href="#5%E3%80%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0" rel="nofollow">5、修改配置参数</a></p> 
<p id="6%E3%80%81%E4%BF%AE%E6%94%B9train.py%E7%9A%84%E5%8F%82%E6%95%B0-toc" style="margin-left:40px;"><a href="#6%E3%80%81%E4%BF%AE%E6%94%B9train.py%E7%9A%84%E5%8F%82%E6%95%B0" rel="nofollow">6、修改train.py的参数</a></p> 
<p id="7%E3%80%81%E6%9F%A5%E7%9C%8B%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C-toc" style="margin-left:40px;"><a href="#7%E3%80%81%E6%9F%A5%E7%9C%8B%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C" rel="nofollow">7、查看训练结果</a></p> 
<p id="%E6%B5%8B%E8%AF%95-toc" style="margin-left:0px;"><a href="#%E6%B5%8B%E8%AF%95" rel="nofollow">测试</a></p> 
<hr id="hr-toc"> 
<h2><strong>摘要</strong></h2> 
<p>YOLOV5严格意义上说并不是YOLO的第五个版本，因为它并没有得到YOLO之父Joe Redmon的认可，但是给出的测试数据总体表现还是不错。详细数据如下：</p> 
<p><img alt="" height="198" src="https://images2.imgbox.com/ab/ec/BKkdEgzw_o.png" width="554"></p> 
<p></p> 
<p>YOLOv5并不是一个单独的模型，而是一个模型家族，包括了YOLOv5s、YOLOv5m、YOLOv5l、YOLOv5x、YOLOv5x+TTA，这点有点儿像EfficientDet。由于没有找到V5的论文，我们也只能从代码去学习它。总体上和YOLOV4差不多，可以认为是YOLOV5的加强版。</p> 
<p>项目地址：<a href="https://github.com/ultralytics/YOLOv5" title="GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite">GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite</a></p> 
<h2 id="%E8%AE%AD%E7%BB%83"><strong>训练</strong></h2> 
<h3 id="1%E3%80%81%E4%B8%8B%E8%BD%BD%E4%BB%A3%E7%A0%81"><strong>1、下载代码</strong></h3> 
<p>项目地址：<a href="https://github.com/ultralytics/YOLOv5" title="GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite">GitHub - ultralytics/yolov5: YOLOv5 🚀 in PyTorch &gt; ONNX &gt; CoreML &gt; TFLite</a>，最近作者又更新了一些代码。</p> 
<p><img alt="" height="425" src="https://images2.imgbox.com/29/fe/KK91gq9v_o.png" width="554"></p> 
<p></p> 
<h3 id="2%E3%80%81%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83"><strong>2、配置环境</strong></h3> 
<pre style="margin-left:0cm;"><code class="language-html">matplotlib&gt;=3.2.2

numpy&gt;=1.18.5

opencv-python&gt;=4.1.2

pillow

PyYAML&gt;=5.3

scipy&gt;=1.4.1

tensorboard&gt;=2.2

torch&gt;=1.6.0

torchvision&gt;=0.7.0

tqdm&gt;=4.41.0</code></pre> 
<p></p> 
<h3 id="3%E3%80%81%E5%87%86%E5%A4%87%E6%95%B0%E6%8D%AE%E9%9B%86"><strong>3、准备数据集</strong></h3> 
<p>数据集采用Labelme标注的数据格式，数据集从RSOD数据集中获取了飞机和油桶两类数据集，并将其转为Labelme标注的数据集。</p> 
<p>数据集的地址： https://pan.baidu.com/s/1iTUpvA9_cwx1qiH8zbRmDg</p> 
<p>提取码：gr6g</p> 
<p>或者：<a href="https://download.csdn.net/download/hhhhhhhhhhwwwwwwwwww/14003627" title="LabelmeData.zip_物体检测yolov5-深度学习文档类资源-CSDN下载">LabelmeData.zip_物体检测yolov5-深度学习文档类资源-CSDN下载</a></p> 
<p>将下载的数据集解压后放到工程的根目录。为下一步生成测试用的数据集做准备。如下图：</p> 
<p><img alt="" height="244" src="https://images2.imgbox.com/54/b4/Aj1MDQok_o.png" width="260"></p> 
<h3 id="4%E3%80%81%E7%94%9F%E6%88%90%E6%95%B0%E6%8D%AE%E9%9B%86"><strong>4、生成数据集</strong></h3> 
<p>YoloV5的数据集和以前版本的数据集并不相同，我们先看一下转换后的数据集。</p> 
<p>数据结构如下图：</p> 
<p><img alt="https://img-blog.csdnimg.cn/20200924200709826.png" height="248" src="https://images2.imgbox.com/52/9b/ryd1GOUf_o.png" width="318"></p> 
<p>images文件夹存放train和val的图片</p> 
<p>labels里面存放train和val的物体数据，里面的每个txt文件和images里面的图片是一一对应的。</p> 
<p>txt文件的内容如下：</p> 
<p><img alt="https://img-blog.csdnimg.cn/2020092420072036.png" height="179" src="https://images2.imgbox.com/8c/0a/SbzOHfPf_o.png" width="628"></p> 
<p>格式：物体类别 x y w h  </p> 
<p>坐标是不是真实的坐标，是将坐标除以宽高后的计算出来的，是相对于宽和高的比例。</p> 
<p>下面我们编写生成数据集的代码，新建LabelmeToYoloV5.py，然后写入下面的代码。</p> 
<pre><code class="language-python">import os

import numpy as np

import json

from glob import glob

import cv2

from sklearn.model_selection import train_test_split

from os import getcwd



classes = ["aircraft", "oiltank"]

# 1.标签路径

labelme_path = "LabelmeData/"

isUseTest = True  # 是否创建test集

# 3.获取待处理文件

files = glob(labelme_path + "*.json")

files = [i.replace("\\", "/").split("/")[-1].split(".json")[0] for i in files]

print(files)

if isUseTest:

    trainval_files, test_files = train_test_split(files, test_size=0.1, random_state=55)

else:

    trainval_files = files

# split

train_files, val_files = train_test_split(trainval_files, test_size=0.1, random_state=55)





def convert(size, box):

    dw = 1. / (size[0])

    dh = 1. / (size[1])

    x = (box[0] + box[1]) / 2.0 - 1

    y = (box[2] + box[3]) / 2.0 - 1

    w = box[1] - box[0]

    h = box[3] - box[2]

    x = x * dw

    w = w * dw

    y = y * dh

    h = h * dh

    return (x, y, w, h)





wd = getcwd()

print(wd)





def ChangeToYolo5(files, txt_Name):

    if not os.path.exists('tmp/'):

        os.makedirs('tmp/')

    list_file = open('tmp/%s.txt' % (txt_Name), 'w')

    for json_file_ in files:

        json_filename = labelme_path + json_file_ + ".json"

        imagePath = labelme_path + json_file_ + ".jpg"

        list_file.write('%s/%s\n' % (wd, imagePath))

        out_file = open('%s/%s.txt' % (labelme_path, json_file_), 'w')

        json_file = json.load(open(json_filename, "r", encoding="utf-8"))

        height, width, channels = cv2.imread(labelme_path + json_file_ + ".jpg").shape

        for multi in json_file["shapes"]:

            points = np.array(multi["points"])

            xmin = min(points[:, 0]) if min(points[:, 0]) &gt; 0 else 0

            xmax = max(points[:, 0]) if max(points[:, 0]) &gt; 0 else 0

            ymin = min(points[:, 1]) if min(points[:, 1]) &gt; 0 else 0

            ymax = max(points[:, 1]) if max(points[:, 1]) &gt; 0 else 0

            label = multi["label"]

            if xmax &lt;= xmin:

                pass

            elif ymax &lt;= ymin:

                pass

            else:

                cls_id = classes.index(label)

                b = (float(xmin), float(xmax), float(ymin), float(ymax))

                bb = convert((width, height), b)

                out_file.write(str(cls_id) + " " + " ".join([str(a) for a in bb]) + '\n')

                print(json_filename, xmin, ymin, xmax, ymax, cls_id)

ChangeToYolo5(train_files, "train")

ChangeToYolo5(val_files, "val")

ChangeToYolo5(test_files, "test")</code></pre> 
<p></p> 
<p>这段代码执行完成会在LabelmeData生成每个图片的txt标注数据，同时在tmp文件夹下面生成训练集、验证集和测试集的txt，txt记录的是图片的路径，为下一步生成YoloV5训练和测试用的数据集做准备。在tmp文件夹下面新建MakeData.py文件，生成最终的结果，目录结构如下图：</p> 
<p><img alt="" height="149" src="https://images2.imgbox.com/d5/02/RAcEYN7L_o.png" width="257"></p> 
<p></p> 
<p>打开MakeData.py,写入下面的代码。</p> 
<pre><code class="language-python">import shutil
import os

file_List = ["train", "val", "test"]
for file in file_List:
    if not os.path.exists('../VOC/images/%s' % file):
        os.makedirs('../VOC/images/%s' % file)
    if not os.path.exists('../VOC/labels/%s' % file):
        os.makedirs('../VOC/labels/%s' % file)
    print(os.path.exists('../tmp/%s.txt' % file))
    f = open('../tmp/%s.txt' % file, 'r')
    lines = f.readlines()
    for line in lines:
        print(line)
        line = "/".join(line.split('/')[-5:]).strip()
        shutil.copy(line, "../VOC/images/%s" % file)
        line = line.replace('JPEGImages', 'labels')
        line = line.replace('jpg', 'txt')
        shutil.copy(line, "../VOC/labels/%s/" % file)</code></pre> 
<p>执行完成后就可以生成YoloV5训练使用的数据集了。结果如下：</p> 
<p><img alt="" height="182" src="https://images2.imgbox.com/b4/f6/U2KmZGG1_o.png" width="241"></p> 
<h3 id="5%E3%80%81%E4%BF%AE%E6%94%B9%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0"><strong>5、修改配置参数</strong></h3> 
<pre style="margin-left:0cm;"><code class="language-html">打开voc.yaml文件，修改里面的配置参数</code></pre> 
<pre style="margin-left:0cm;"><code class="language-html">train: VOC/images/train/  # 训练集图片的路径</code></pre> 
<pre style="margin-left:0cm;"><code class="language-html">val: VOC/images/val/  # 验证集图片的路径</code></pre> 
<pre style="margin-left:0cm;"><code class="language-html"># number of classes

nc: 2 #检测的类别，本次数据集有两个类别所以写2



# class names

names: ["aircraft", "oiltank"]#类别的名称，和转换数据集时的list对应</code></pre> 
<h3 id="6%E3%80%81%E4%BF%AE%E6%94%B9train.py%E7%9A%84%E5%8F%82%E6%95%B0"><strong>6、修改train.py的参数</strong></h3> 
<pre style="margin-left:0cm;"><code class="language-html">cfg参数是YoloV5 模型的配置文件，模型的文件存放在models文件夹下面，按照需求填写不同的文件。</code></pre> 
<p></p> 
<pre style="margin-left:0cm;"><code class="language-html">weights参数是YoloV5的预训练模型，和cfg对应，例：cfg配置的是yolov5s.yaml，weights就要配置yolov5s.pt</code></pre> 
<pre style="margin-left:0cm;"><code class="language-html">data是配置数据集的配置文件，我们选用的是voc.yaml，所以配置data/voc.yaml</code></pre> 
<pre style="margin-left:0cm;"><code class="language-html">修改上面三个参数就可以开始训练了，其他的参数根据自己的需求修改。修改后的参数配置如下：</code></pre> 
<pre style="margin-left:0cm;"><code class="language-html">parser.add_argument('--weights', type=str, default='yolov5s.pt', help='initial weights path')

parser.add_argument('--cfg', type=str, default='yolov5s.yaml', help='model.yaml path')

parser.add_argument('--data', type=str, default='data/voc.yaml', help='data.yaml path')</code></pre> 
<p> 修改完成后，就可以开始训练了。如下图所示：</p> 
<p><img alt="" height="285" src="https://images2.imgbox.com/59/ef/OJF8Cjea_o.png" width="554"></p> 
<p>多卡并行</p> 
<pre style="margin-left:0cm;"><code class="language-python"> python -m torch.distributed.run --nproc_per_node 2 train.py --batch 64 --data coco.yaml --weights yolov5s.pt --device 0,1</code></pre> 
<h3 id="7%E3%80%81%E6%9F%A5%E7%9C%8B%E8%AE%AD%E7%BB%83%E7%BB%93%E6%9E%9C" style="margin-left:0cm;">7、查看训练结果</h3> 
<p style="margin-left:0cm;">在经历了300epoch训练之后，我们会在runs文件夹下面找到训练好的权重文件和训练过程的一些文件。如图：</p> 
<p style="margin-left:0cm;"><img alt="" height="216" src="https://images2.imgbox.com/79/2a/fRaPdgWd_o.png" width="554"></p> 
<p style="margin-left:0cm;"><img alt="" height="554" src="https://images2.imgbox.com/57/a8/MlFRPBr4_o.png" width="554"></p> 
<p style="margin-left:0cm;"><img alt="" height="554" src="https://images2.imgbox.com/b8/8c/EIGm3rcN_o.png" width="554"></p> 
<p style="margin-left:0cm;"><img alt="" height="277" src="https://images2.imgbox.com/4c/3c/CPkfq9G6_o.png" width="554"></p> 
<p style="margin-left:0cm;"><img alt="" height="576" src="https://images2.imgbox.com/8a/61/EVVxp9X8_o.png" width="640"></p> 
<p style="margin-left:0cm;"></p> 
<p style="margin-left:0cm;"></p> 
<p style="margin-left:0cm;"></p> 
<p style="margin-left:0cm;"></p> 
<p style="margin-left:0cm;"></p> 
<h2 id="%E6%B5%8B%E8%AF%95" style="margin-left:0cm;">测试</h2> 
<p style="margin-left:0cm;">首先需要在voc.yaml中增加测试集的路径，打开voc.yaml，在val字段后面增加test: tmp/test.txt这行代码，如图：</p> 
<p style="margin-left:0cm;"><img alt="" height="292" src="https://images2.imgbox.com/b4/27/xddUrjNZ_o.png" width="407"></p> 
<p style="margin-left:0cm;"></p> 
<p style="margin-left:0cm;">修改test.py中的参数，下面的这几个参数要修改。</p> 
<p style="margin-left:0cm;"><span style="color:#a9b7c6;">parser = argparse.ArgumentParser(</span><span style="color:#aa4926;">prog</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'test.py'</span><span style="color:#a9b7c6;">)<br> parser.add_argument(</span><span style="color:#6a8759;">'--weights'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">nargs</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'+'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">type</span><span style="color:#a9b7c6;">=</span><span style="color:#8888c6;">str</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">default</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'runs/exp7/weights/best.pt'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">help</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'model.pt path(s)'</span><span style="color:#a9b7c6;">)<br> parser.add_argument(</span><span style="color:#6a8759;">'--data'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">type</span><span style="color:#a9b7c6;">=</span><span style="color:#8888c6;">str</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">default</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'data/voc.yaml'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">help</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'*.data path'</span><span style="color:#a9b7c6;">)<br> parser.add_argument(</span><span style="color:#6a8759;">'--batch-size'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">type</span><span style="color:#a9b7c6;">=</span><span style="color:#8888c6;">int</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">default</span><span style="color:#a9b7c6;">=</span><span style="color:#6897bb;">2</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">help</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'size of each image batch'</span><span style="color:#a9b7c6;">)<br> parser.add_argument(</span><span style="color:#6a8759;">'--save-txt'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">default</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'True'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">action</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'store_true'</span><span style="color:#cc7832;">, </span><span style="color:#aa4926;">help</span><span style="color:#a9b7c6;">=</span><span style="color:#6a8759;">'save results to *.txt'</span><span style="color:#a9b7c6;">)</span></p> 
<p style="margin-left:0cm;"><span style="color:#a9b7c6;">在</span><span style="color:#a9b7c6;">275</span><span style="color:#a9b7c6;">行</span> <span style="color:#a9b7c6;">修改</span><span style="color:#a9b7c6;">test</span><span style="color:#a9b7c6;">的方法，增加保存测试结果的路径。这样测试完成后就可以在</span><span style="color:#a9b7c6;">inference\images</span><span style="color:#a9b7c6;">查看到测试的图片，在</span><span style="color:#a9b7c6;">inference\output</span><span style="color:#a9b7c6;">中查看到保存的测试结果。</span></p> 
<p style="margin-left:0cm;"><span style="color:#a9b7c6;">如图：</span></p> 
<p style="margin-left:0cm;"><img alt="" height="263" src="https://images2.imgbox.com/9a/c7/V8oWKIFd_o.png" width="554"></p> 
<p style="margin-left:0cm;"></p> 
<p style="margin-left:0cm;"><span style="color:#a9b7c6;">下面是运行的结果：</span></p> 
<p style="margin-left:0cm;"><img alt="" height="344" src="https://images2.imgbox.com/b0/8e/DimV7CTG_o.png" width="554"></p> 
<p style="margin-left:0cm;">代码和模型：<a href="https://download.csdn.net/download/hhhhhhhhhhwwwwwwwwww/13094352" title="手把手教物体检测yolov5-master.zip_yolov5-master使用-深度学习文档类资源-CSDN下载">手把手教物体检测yolov5-master.zip_yolov5-master使用-深度学习文档类资源-CSDN下载</a></p> 
<p style="margin-left:0cm;"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0669449e0b17cbbed787db24ad5dd013/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">声明式服务调用OpenFeign</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/de2119a4f77ed4a61a7bd0215be616e9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Merry Christmas！一起用C语言绘制一个动态的圣诞树吧</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>