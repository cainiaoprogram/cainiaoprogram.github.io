<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>总结3（9.20-9.26） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="总结3（9.20-9.26）" />
<meta property="og:description" content="开学第3周，本周在常规课程学习的基础上，报名了六级考试，开始坚持每天背一点单词。完成了李沐深度学习5-8课时的学习，以下是我对部分作业题的代码编写和总结。
三、线性代数作业题 3.1.我们在本节中定义了形状（2,3,4）的张量X。len(X)的输出结果是什么？对于任意形状的张量X,len(X)是否总是对应于X特定轴的长度?这个轴是什么? import torch X = torch.arange(24).reshape(2, 3, 4) len(X) 输出结果为2。因为len(X)的输出总是对应第0轴的长度。
3.2.运行A/A.sum(axis=1)，看看会发生什么。你能分析原因吗？ A=torch.arange(20).reshape(5,4) A/A.sum(axis=1) #改为A/A.sum(axis=0)可行 输出结果报错，因为A是5*4矩阵A.sum(axis=1)是一个1*5向量无法触发广播机制。若改为axis=0，则可行。
3.3.当你在曼哈顿的两点之间旅行时，你需要在坐标上走多远，也就是说，就大街和街道而言？你能斜着走吗？ 不能斜着走，用一范数来刻画距离。
3.4.向linalg.norm函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?
A=torch.ones(12).reshape(2,2,3) print(A) A=A.float() torch.norm(A)##所有值的L2范数 输出结果：
tensor(3.4641) 对更多轴的张量求范数时，仍然是把所有数据进行求。
四、微分和求导作业题 4.1.绘制函数和其在x = 1处切线的图像。 import numpy as np from d2l import torch as d2l x=np.arange(0.5,2,0.1)#生成一组数，起点x=0.5，终点x=2，步长是0.1 def f(x): return x**3-x**(-1) d2l.plot(x,[f2(x),4*x-4],&#39;x&#39;,&#39;f(x)&#39;,legend=[&#39;f(x)&#39;,&#39;Tangent line (x=1)&#39;]) 输出结果：
4.2.为什么计算二阶导数比一阶导数的开销要更大？ 因为计算二阶导数需要先求一阶导数。
4.3.在运行反向传播函数之后，立即再次运行它，看看会发生什么。 会报错，因为不允许连续backward，前向过程建立计算图，反向传播后释放需要更新x.grad才可以再backward。
4.4.在控制流的例子中，我们计算d关于a的导数，如果我们将变量a更改为随机向量或矩阵，会发生什么？此时，计算结果f(a)不再是标量。结果会发生什么？我们如何分析这个结果？ 对向量矩阵直接进行反向传播会报错。对非标量调用`backward`需要传入一个`gradient`参数，该参数指定微分函数关于`self`的梯度。
4.5.重新设计一个求控制流梯度的例子。运行并分析结果。 def f(a): if a.norm() &gt; 10: b = 2*a else: b = a&#43;2 return b a = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/791063c5038e2621672c1e47925f5b69/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-26T17:45:25+08:00" />
<meta property="article:modified_time" content="2021-09-26T17:45:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">总结3（9.20-9.26）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>       开学第3周，本周在常规课程学习的基础上，报名了六级考试，开始坚持每天背一点单词。完成了李沐深度学习5-8课时的学习，以下是我对部分作业题的代码编写和总结。</p> 
<h2>三、线性代数作业题</h2> 
<h4>3.1.我们在本节中定义了形状（2,3,4）的张量X。len(X)的输出结果是什么？<strong>对于任意形状的张量X,len(X)是否总是对应于X特定轴的长度?这个轴是什么?</strong></h4> 
<pre><code class="language-python">import torch
X = torch.arange(24).reshape(2, 3, 4)
len(X)</code></pre> 
<p>    输出结果为2。因为len(X)的输出总是对应第0轴的长度。</p> 
<h4>3.2.运行A/A.sum(axis=1)，看看会发生什么。你能分析原因吗？</h4> 
<pre><code>A=torch.arange(20).reshape(5,4)
A/A.sum(axis=1) #改为A/A.sum(axis=0)可行</code></pre> 
<p>      输出结果报错，因为A是5*4矩阵A.sum(axis=1)是一个1*5向量无法触发广播机制。若改为axis=0，则可行。</p> 
<h4>3.3.当你在曼哈顿的两点之间旅行时，你需要在坐标上走多远，也就是说，就大街和街道而言？你能斜着走吗？</h4> 
<p>      不能斜着走，用一范数来刻画距离<img alt="\|\mathbf{x-y}\|_1" class="mathcode" src="https://images2.imgbox.com/6c/15/tmOA5V43_o.png">。</p> 
<p><strong>3.4.向linalg.norm函数提供3个或更多轴的张量，并观察其输出。对于任意形状的张量这个函数计算得到什么?</strong></p> 
<pre><code>A=torch.ones(12).reshape(2,2,3)
print(A)
A=A.float()
torch.norm(A)##所有值的L2范数</code></pre> 
<p>输出结果：</p> 
<pre><code>tensor(3.4641)</code></pre> 
<p>     对更多轴的张量求范数时，仍然是把所有数据进行求。</p> 
<h2 id="四、微分和求导作业题">四、微分和求导作业题</h2> 
<h4>4.1.绘制函数<img alt="y = f(x) = x^3 - \frac{1}{x}" class="mathcode" src="https://images2.imgbox.com/7f/19/cMmXgOFK_o.png">和其在x = 1处切线的图像。 </h4> 
<pre><code>import numpy as np
from d2l import torch as d2l 
x=np.arange(0.5,2,0.1)#生成一组数，起点x=0.5，终点x=2，步长是0.1
def f(x):
    return x**3-x**(-1)
d2l.plot(x,[f2(x),4*x-4],'x','f(x)',legend=['f(x)','Tangent line (x=1)'])</code></pre> 
<p> 输出结果：</p> 
<p style="text-align:center;"><img alt="" height="268" src="https://images2.imgbox.com/56/67/Ht41hrgz_o.png" width="427"></p> 
<h4> 4.2.为什么计算二阶导数比一阶导数的开销要更大？</h4> 
<p>     因为计算二阶导数需要先求一阶导数。</p> 
<h4>4.3.在运行反向传播函数之后，立即再次运行它，看看会发生什么。 </h4> 
<p>     会报错，因为不允许连续backward，前向过程建立计算图，反向传播后释放需要更新x.grad才可以再backward。</p> 
<h4>4.4.在控制流的例子中，我们计算<code>d</code>关于<code>a</code>的导数，如果我们将变量<code>a</code>更改为随机向量或矩阵，会发生什么？此时，计算结果<code>f(a)</code>不再是标量。结果会发生什么？我们如何分析这个结果？</h4> 
<p>     对向量矩阵直接进行反向传播会报错。对非标量调用`backward`需要传入一个`gradient`参数，该参数指定微分函数关于`self`的梯度。</p> 
<h4>4.5.重新设计一个求控制流梯度的例子。运行并分析结果。</h4> 
<pre><code>def f(a):
    if a.norm() &gt; 10:
        b = 2*a
    else:
        b = a+2
    return b

a = torch.randn(10, requires_grad=True)
d = f(a)
print(d)
#d.backward()
d.sum().backward()#等价于d.backward(torch.ones(len(a)))
a.grad</code></pre> 
<p>运行结果：</p> 
<pre><code>tensor([1.0999, 2.2732, 1.8459, 0.1245, 2.4950, 1.9525, 4.6292, 2.4428, 2.4967,
        1.2529], grad_fn=&lt;AddBackward0&gt;)
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])</code></pre> 
<h4>4.6.使𝑓(𝑥)=sin(𝑥)，绘制𝑓(𝑥)和𝑑𝑓(𝑥)𝑑𝑥的图像，其中后者不使用𝑓′(𝑥)=cos(𝑥)。</h4> 
<pre><code>x=torch.arange(-5,5,0.1,requires_grad=True) 
y=torch.sin(x)#f=sinx(x)
grad=torch.zeros(len(y))#创建保存f'(x[i]) 导数的向量grad
x1=x.detach().numpy()#tensor转array才可以调用绘图函数
y1=y.detach().numpy()
for i in  range(len(grad)): #求sinx在每一个x[i]处的导数
    y[i].backward(retain_graph=True) #自动求导
    grad[i]=x.grad[i]
d2l.plot(x1,[y1,grad],'x','f(x)',legend=['f(x)','df(x)'])</code></pre> 
<p>运行结果：</p> 
<p style="text-align:center;"><img alt="" height="279" src="https://images2.imgbox.com/b0/81/aPcpyrgz_o.png" width="434"></p> 
<p></p> 
<p>        总结：这周上课状态越来越好了，但仍然有一些课程跟不太上，作业题不会写。可能是因为前两周没有及时把课上内容弄懂积累下来的所以跟不上。深度学习方面课程也是越来越难，虽然作业题都比较简单，但确画了课后很多时间。总体学习效率还是偏低，一周过得很快，希望下周能更加努力。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/868757481f681633d05142b79770cde3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">ffmpeg编译命令</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/23ef8d494ab70383205422a4bc368b9c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;实操 - True and false</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>