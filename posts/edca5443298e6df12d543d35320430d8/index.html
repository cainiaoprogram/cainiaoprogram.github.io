<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例" />
<meta property="og:description" content="🍊作者简介：秃头小苏，致力于用最通俗的语言描述问题
🍊往期回顾：对抗生成网络GAN系列——GAN原理及手写数字生成小案例
🍊近期目标：写好专栏的每一篇文章
🍊支持小苏：点赞👍🏼、收藏⭐、留言📩
文章目录 对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例写在前面DCGAN重点知识把握DCGAN简介DCGAN生成模型、判别模型设计✨✨✨生成网络模型🧅🧅🧅判别模型网络🧅🧅🧅 DCGAN人脸生成实战✨✨✨数据集加载🧅🧅🧅生成模型搭建🧅🧅🧅模型训练🧅🧅🧅 番外篇——使用服务器训练如何保存图片和训练损失✨✨✨小结 本节已录制视频：DCGAN简介及人脸图像生成案例🧨🧨🧨
对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例 写在前面 ​ 前段时间，我已经写过一篇关于GAN的理论讲解，并且结合理论做了一个手写数字生成的小案例，对GAN原理不清楚的可以点击☞☞☞跳转了解详情。🌱🌱🌱
​ 为唤醒大家的记忆，这里我再来用一句话对GAN的原理进行总结：GAN网络即是通过生成器和判别器的不断相互对抗，不断优化，直到判别器难以判断生成器生成图像的真假。
​ 那么接下来我就要开始讲述DCGAN了喔，读到这里我就默认大家对GAN的原理已经掌握了，开始发车。🚖🚖🚖
DCGAN重点知识把握 DCGAN简介 ​ 我们先来看一下DCGAN的全称——Deep Convolutional Genrative Adversarial Networks。这大家应该都能看懂叭，就是说这次我们将生成对抗网络和深度学习结合到一块儿了，现在看这篇文章的一些观点其实觉得是很平常的，没有特别出彩之处，但是这篇文章是在16年发布的，在当时能提出一些思想确实是难得。
​ 其实呢，这篇文章的原理和GAN基本是一样的。不同之处只在生成网络模型和判别网络模型的搭建上，因为这篇文章结合了深度学习嘛，所以在模型搭建中使用了卷积操作【注：在上一篇GAN网络模型搭建中我们只使用的全连接层】。介于此，我不会再介绍DCGAN的原理，重点将放在DCGAN网络模型的搭建上。【注：这样看来DCGAN就很简单了，确实也是这样的。但是大家也不要掉以轻心喔，这里还是有一些细节的，我也是花了很长的时间来阅读文档和做实验来理解的，觉得理解差不多了，才来写了这篇文章。】
​ 那么接下来就来讲讲DCGAN生成模型和判别模型的设计，跟我一起来看看叭！！！
DCGAN生成模型、判别模型设计✨✨✨ ​ 在具体到生成模型和判别模型的设计前，我们先来看论文中给出的一段话，如下图所示：
​ 这里我还是翻译一下，如下图所示：
​ 上图给出了设计生成模型和判别模型的基本准则，后文我们搭建模型时也是严格按照这个来的。【注意上图黄色背景的分数卷积喔，后文会详细叙述】
生成网络模型🧅🧅🧅 ​ 话不多说，直接放论文中生成网络结构图，如下：
图1 生成网络模型 ​ 看到这张图不知道大家是否有几秒的迟疑，反正我当时是这样的，这个结构给人一种熟悉的感觉，但又觉得非常的陌生。好了，不卖关子了，我们一般看到的卷积结构都是特征图的尺寸越来越小，是一个下采样的过程；而这个结构特征图的尺寸越来越大，是一个上采样的过程。那么这个上采样是怎么实现的呢，这就要说到主角分数卷积了。【又可以叫转置卷积（transposed convolution）和反卷积（deconvolution），但是pytorch官方不建议取反卷积的名称，论文中更是说这个叫法是错误的，所以我们尽量不要去用反卷积这个名称，同时后文我会统一用转置卷积来表述，因为这个叫法最多，我认为也是最贴切的】
关于转置卷积的理论可以参考我的这篇博文：转置卷积详解（原理&#43;实验）🥨🥨🥨
判别模型网络🧅🧅🧅 ​ 同样的，直接放出判别模型的网络结构图，如下：【注：这部分原论文中没有给出图例，我自己简单画了一个，没有论文中图示美观，但也大致能表示卷积的过程，望大家见谅】
​ 判别网络真的没什么好讲的，就是传统的卷积操作，对卷积不了解的建议阅读一下我的这篇文章🧨🧨🧨
​ 这里我给出程序执行的网络模型结构的结果，这部分就结束了：
DCGAN人脸生成实战✨✨✨ ​ 这部分我们将来实现一个人脸生成的实战项目，我们先来看一下人脸一步步生成的动画效果，如下图所示：
​ 我们可以看到随着迭代次数增加，人脸生成的效果是越来越好的，说句不怎么恰当的话，最后生成的图片是像个人的。看到这里，是不是都兴致勃勃了呢，下面就让我们一起来学学叭。🏆🏆🏆
​ 秉持着授人以鱼不如授人以渔的原则，这里我就不带大家一句一句的分析代码了，都是比较简单的，官方文档写的也非常详细，我再叙述一篇也没有什么意义。哦，对了，这部分代码参考的是pytorch官网上DCGAN的教程，链接如下：DCGAN实战教程🎈🎈🎈
​ 我来简单介绍一下官方教程的使用，点击上文链接会进入下图的界面：这个界面正常滑动就是对这个项目的解释，包括原理、代码及代码运行结果，大家首先要做的应该是阅读一遍这个文档，基本可以解决大部分的问题。那么接下来对于不明白的就可以点击下图中绿框链接修改一些代码来调试我们不懂的问题，这样基本就都会明白了。【框1是google提供的一个免费的GPU运算平台，就类似是云端的jupyter notebook ，但这个需要梯子，大家自备；框2 是下载notebook到本地；框3是项目的Github地址】
​ 那方法都教给大家了，大家快去试试叭！！！
​ 作为一个负责的博主👨‍🦳👨‍🦳👨‍🦳，当然不会就甩一个链接就走人啦，下面我会帮助大家排查一下代码中的一些难点，大家看完官方文档后如果有不明白的记得回来看看喔。🥂🥂🥂当然，如果有什么不理解的地方且我下文没有提及欢迎评论区讨论交流。🛠🛠🛠
数据集加载🧅🧅🧅 ​ 首先我来说一下数据集的加载，这部分不难，却十分重要。对于我们自己的数据集，我们先用ImageFolder方法创建dataset,代码如下：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/edca5443298e6df12d543d35320430d8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-09T13:10:55+08:00" />
<meta property="article:modified_time" content="2023-02-09T13:10:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>🍊作者简介：<a href="https://juejin.cn/user/1359414174686455" rel="nofollow">秃头小苏</a>，致力于用最通俗的语言描述问题</p> 
 <p>🍊往期回顾：<a href="https://juejin.cn/post/7120443914854613029" rel="nofollow">对抗生成网络GAN系列——GAN原理及手写数字生成小案例</a></p> 
 <p>🍊近期目标：写好专栏的每一篇文章</p> 
 <p>🍊支持小苏：点赞👍🏼、收藏⭐、留言📩</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#GANDCGAN_15" rel="nofollow">对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例</a></li><li><ul><li><a href="#_17" rel="nofollow">写在前面</a></li><li><a href="#DCGAN_27" rel="nofollow">DCGAN重点知识把握</a></li><li><ul><li><a href="#DCGAN_29" rel="nofollow">DCGAN简介</a></li><li><a href="#DCGAN_39" rel="nofollow">DCGAN生成模型、判别模型设计✨✨✨</a></li><li><ul><li><a href="#_53" rel="nofollow">生成网络模型🧅🧅🧅</a></li><li><a href="#_68" rel="nofollow">判别模型网络🧅🧅🧅</a></li></ul> 
   </li></ul> 
   </li><li><a href="#DCGAN_86" rel="nofollow">DCGAN人脸生成实战✨✨✨</a></li><li><ul><li><a href="#_109" rel="nofollow">数据集加载🧅🧅🧅</a></li><li><a href="#_140" rel="nofollow">生成模型搭建🧅🧅🧅</a></li><li><a href="#_182" rel="nofollow">模型训练🧅🧅🧅</a></li></ul> 
   </li><li><a href="#_257" rel="nofollow">番外篇——使用服务器训练如何保存图片和训练损失✨✨✨</a></li><li><a href="#_309" rel="nofollow">小结</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<blockquote> 
 <p>本节已录制视频：<a href="https://www.bilibili.com/video/BV1Vy4y1Q7ZC/?vd_source=12c43aedc12b9cf10b775c0015015b86" rel="nofollow">DCGAN简介及人脸图像生成案例</a>🧨🧨🧨</p> 
</blockquote> 
<h2><a id="GANDCGAN_15"></a>对抗生成网络GAN系列——DCGAN简介及人脸图像生成案例</h2> 
<h3><a id="_17"></a>写在前面</h3> 
<p>​  前段时间，我已经写过一篇关于GAN的理论讲解，并且结合理论做了一个手写数字生成的小案例，对GAN原理不清楚的可以点击<a href="https://juejin.cn/post/7120443914854613029" rel="nofollow">☞☞☞</a>跳转了解详情。🌱🌱🌱</p> 
<p>​   为唤醒大家的记忆，这里我再来用一句话对GAN的原理进行总结：<font color="#ff00ff"><strong>GAN网络即是通过生成器和判别器的不断相互对抗，不断优化，直到判别器难以判断生成器生成图像的真假。</strong></font></p> 
<p>​   那么接下来我就要开始讲述DCGAN了喔，读到这里我就默认大家对GAN的原理已经掌握了，开始发车。🚖🚖🚖</p> 
<p> </p> 
<h3><a id="DCGAN_27"></a>DCGAN重点知识把握</h3> 
<h4><a id="DCGAN_29"></a>DCGAN简介</h4> 
<p>​   我们先来看一下DCGAN的全称——<code>Deep Convolutional Genrative Adversarial Networks</code>。这大家应该都能看懂叭，就是说这次我们将生成对抗网络和深度学习结合到一块儿了，现在看这篇文章的一些观点其实觉得是很平常的，没有特别出彩之处，但是这篇文章是在16年发布的，在当时能提出一些思想确实是难得。</p> 
<p>​   其实呢，这篇文章的原理和GAN基本是一样的。不同之处只在生成网络模型和判别网络模型的搭建上，因为这篇文章结合了深度学习嘛，所以在模型搭建中使用了卷积操作<font color="#ff00ff"><strong>【注：在上一篇<a href="https://juejin.cn/post/7120443914854613029" rel="nofollow">GAN</a>网络模型搭建中我们只使用的全连接层】</strong></font>。介于此，我不会再介绍DCGAN的原理，重点将放在DCGAN网络模型的搭建上。<font color="rede">【注：这样看来DCGAN就很简单了，确实也是这样的。但是大家也不要掉以轻心喔，这里还是有一些细节的，我也是花了很长的时间来阅读文档和做实验来理解的，觉得理解差不多了，才来写了这篇文章。】</font></p> 
<p>​   那么接下来就来讲讲DCGAN生成模型和判别模型的设计，跟我一起来看看叭！！！</p> 
<p> </p> 
<h4><a id="DCGAN_39"></a>DCGAN生成模型、判别模型设计✨✨✨</h4> 
<p>​   在具体到生成模型和判别模型的设计前，我们先来看论文中给出的一段话，如下图所示：</p> 
<img src="https://images2.imgbox.com/f3/32/ZyyFOh59_o.png" alt="image-20220722151528431"> 
<p>​   这里我还是翻译一下，如下图所示：</p> 
<p><img src="https://images2.imgbox.com/67/7f/o9PepVXm_o.png" alt="image-20220722153212125"></p> 
<p>​   上图给出了设计生成模型和判别模型的基本准则，后文我们搭建模型时也是严格按照这个来的。<font color="red">【注意上图黄色背景的分数卷积喔，后文会详细叙述】</font></p> 
<p> </p> 
<h5><a id="_53"></a>生成网络模型🧅🧅🧅</h5> 
<p>​   话不多说，直接放论文中生成网络结构图，如下：</p> 
<p><img src="https://images2.imgbox.com/56/6b/wT7w87df_o.png" alt="image-20220722154308221"></p> 
<center>
  图1 生成网络模型 
</center> 
<p>​   看到这张图不知道大家是否有几秒的迟疑，反正我当时是这样的，这个结构给人一种熟悉的感觉，但又觉得非常的陌生。好了，不卖关子了，我们一般看到的卷积结构都是特征图的尺寸越来越小，是一个下采样的过程；而这个结构特征图的尺寸越来越大，是一个上采样的过程。那么这个上采样是怎么实现的呢，这就要说到主角<mark>分数卷积</mark>了。<font color="#ff00ff"><strong>【又可以叫转置卷积（transposed convolution）和反卷积（deconvolution），但是pytorch官方不建议取反卷积的名称，论文中更是说这个叫法是错误的，所以我们尽量不要去用反卷积这个名称，同时后文我会统一用转置卷积来表述，因为这个叫法最多，我认为也是最贴切的】</strong></font></p> 
<hr> 
<p>关于转置卷积的理论可以参考我的这篇博文：<a href="https://blog.csdn.net/qq_47233366/article/details/127310195?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22127310195%22,%22source%22:%22qq_47233366%22%7D">转置卷积详解（原理+实验）</a>🥨🥨🥨</p> 
<hr> 
<p> </p> 
<h5><a id="_68"></a>判别模型网络🧅🧅🧅</h5> 
<p>​   同样的，直接放出判别模型的网络结构图，如下：<font color="red"><strong>【注：这部分原论文中没有给出图例，我自己简单画了一个，没有论文中图示美观，但也大致能表示卷积的过程，望大家见谅】</strong></font></p> 
<p><img src="https://images2.imgbox.com/91/98/5e0niOg2_o.png" alt=""></p> 
<p>​   判别网络真的没什么好讲的，就是传统的卷积操作，对卷积不了解的建议阅读一下我的<a href="https://juejin.cn/post/7085159671324999688" rel="nofollow">这篇文章</a>🧨🧨🧨</p> 
<p>​   这里我给出程序执行的网络模型结构的结果，这部分就结束了：</p> 
<p><img src="https://images2.imgbox.com/2e/3f/GmagoQPx_o.png" alt="image-20220722221744353"></p> 
<p> </p> 
<h3><a id="DCGAN_86"></a>DCGAN人脸生成实战✨✨✨</h3> 
<p>​   这部分我们将来实现一个人脸生成的实战项目，我们先来看一下人脸一步步生成的动画效果，如下图所示：</p> 
<p><img src="https://images2.imgbox.com/fc/50/jGlSWVqs_o.gif" alt="在这里插入图片描述"></p> 
<p>​  我们可以看到随着迭代次数增加，人脸生成的效果是越来越好的，说句不怎么恰当的话，最后生成的图片是像个人的。看到这里，是不是都兴致勃勃了呢，下面就让我们一起来学学叭。🏆🏆🏆</p> 
<p>​  秉持着授人以鱼不如授人以渔的原则，这里我就不带大家一句一句的分析代码了，都是比较简单的，官方文档写的也非常详细，我再叙述一篇也没有什么意义。哦，对了，这部分代码参考的是pytorch官网上DCGAN的教程，链接如下：<a href="https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html#generative-adversarial-networks" rel="nofollow">DCGAN实战教程</a>🎈🎈🎈</p> 
<p>​   我来简单介绍一下官方教程的使用，点击上文链接会进入下图的界面：这个界面正常滑动就是对这个项目的解释，包括原理、代码及代码运行结果，大家首先要做的应该是阅读一遍这个文档，基本可以解决大部分的问题。那么接下来对于不明白的就可以点击下图中绿框链接修改一些代码来调试我们不懂的问题，这样基本就都会明白了。<font color="#gbfwe"><strong>【框1是google提供的一个免费的GPU运算平台，就类似是云端的<code>jupyter notebook</code> ，但这个需要梯子，大家自备；框2 是下载notebook到本地；框3是项目的Github地址】</strong></font></p> 
<img src="https://images2.imgbox.com/51/ca/TsXXzR66_o.png" alt="image-20220722235309784"> 
<p>​   那方法都教给大家了，大家快去试试叭！！！</p> 
<p>​   作为一个负责的博主👨‍🦳👨‍🦳👨‍🦳，当然不会就甩一个链接就走人啦，下面我会帮助大家排查一下代码中的一些难点，大家看完官方文档后如果有不明白的记得回来看看喔。🥂🥂🥂当然，如果有什么不理解的地方且我下文没有提及欢迎评论区讨论交流。🛠🛠🛠</p> 
<hr> 
<p> </p> 
<h4><a id="_109"></a>数据集加载🧅🧅🧅</h4> 
<p>​   首先我来说一下数据集的加载，这部分不难，却十分重要。对于我们自己的数据集，我们先用<code>ImageFolder</code>方法创建<code>dataset</code>,代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># Create the dataset</span>
dataset <span class="token operator">=</span> dset<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root<span class="token operator">=</span>dataroot<span class="token punctuation">,</span>
                           transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
                               transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span>image_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                               transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span>image_size<span class="token punctuation">)</span><span class="token punctuation">,</span>
                               transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                               transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                           <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>​   需要强调的是<code>root=dataroot</code>表示我们自己数据集的路径，在这个路径下必须还有一个子目录。怎么理解呢，我举个例子。比如我现在有一个人脸图片数据集，其存放在文件夹2下面，我们不能将root的路径指定为文件夹2，而是将文件夹2放入一个新文件夹1里面，root的路径指定为文件夹1。</p> 
<p><img src="https://images2.imgbox.com/17/6c/yZUgefvv_o.png" alt=""></p> 
<p>​   对于上面代码的transforms操作做一个简要的概括，<code>transforms.Resize</code>将图片尺寸进行缩放、<code>transforms.CenterCrop</code>对图片进行中心裁剪、<code>transforms.ToTensor、transforms.Normalize</code>最终会将图片数据归一化到[-1,1]之间，这部分不懂的可以参考我的这篇博文：<a href="https://juejin.cn/post/7087397616731815966" rel="nofollow">pytorch中的transforms.ToTensor和transforms.Normalize理解</a>🍚🍚🍚</p> 
<p>​   有了<code>dataset</code>后，就可以通过<code>DataLoader</code>方法来加载数据集了，代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment"># Create the dataloader</span>
dataloader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>
                                         shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_workers<span class="token operator">=</span>workers<span class="token punctuation">)</span>
</code></pre> 
<hr> 
<p> </p> 
<h4><a id="_140"></a>生成模型搭建🧅🧅🧅</h4> 
<p>​   接下来我们来说说生成网络模型的搭建，代码如下：<font color="red"><strong>不知道大家有没有发现pytorch官网此部分搭建的网络模型和论文中给出的是有一点差别的，这里我修改成了和论文中一样的模型，从训练效果来看，两者差别是不大的。</strong></font>【注：下面代码是我修改过的】</p> 
<pre><code class="prism language-python"><span class="token comment"># Generator Code</span>

<span class="token keyword">class</span> <span class="token class-name">Generator</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> ngpu<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Generator<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ngpu <span class="token operator">=</span> ngpu
        self<span class="token punctuation">.</span>main <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            <span class="token comment"># input is Z, going into a convolution</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span> nz<span class="token punctuation">,</span> ngf <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>ngf <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># state size. (ngf*16) x 4 x 4</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span>ngf <span class="token operator">*</span> <span class="token number">16</span><span class="token punctuation">,</span> ngf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>ngf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># state size. (ngf*8) x 8 x 8</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span> ngf <span class="token operator">*</span> <span class="token number">8</span><span class="token punctuation">,</span> ngf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>ngf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># state size. (ngf*4) x 16 x 16</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span> ngf <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> ngf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>ngf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token comment"># state size. (ngf * 2) x 32 x 32</span>
            nn<span class="token punctuation">.</span>ConvTranspose2d<span class="token punctuation">(</span> ngf <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">,</span> nc<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># state size. (nc) x 64 x 64</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>main<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
</code></pre> 
<p>​   我觉得这个模型搭建步骤大家应该都是较为清楚的，但我当时对这个第一步即从一个100维的噪声向量如何变成变成一个1024*4*4的特征图还是比较疑惑的。这里就为大家解答一下，我们可以看看在训练过程中传入的噪声代码,即输入为：<code> noise = torch.randn(b_size, nz, 1, 1, device=device)</code>，这是一个100*1*1的特征图，这样是不是一下子恍然大悟了呢，那我们的第一步也就是从100*1*1的特征图经转置卷积变成1024*4*4的特征图。</p> 
<hr> 
<p> </p> 
<h4><a id="_182"></a>模型训练🧅🧅🧅</h4> 
<p>​   这部分我在上一篇<a href="https://juejin.cn/post/7120443914854613029" rel="nofollow">GAN网络</a>讲解中已经介绍过，但是我没有细讲，这里我想重点讲一下BCELOSS损失函数。【就是二值交叉熵损失函数啦】我们先来看一下pytorch官网对这个函数的解释，如下图所示：</p> 
<p><img src="https://images2.imgbox.com/a9/48/6EYrBbQd_o.png" alt="image-20220723142323032"></p> 
<p>​   其中N表示batch_size，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          w 
         
        
          n 
         
        
       
      
        w_n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>应该表示一个权重系数，默认为1【这个是我猜的哈，在官网没看到对这一部分的解释】，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          y 
         
        
          n 
         
        
       
      
        y_n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0359em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>表示标签值，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          n 
         
        
       
      
        x_n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>表示数据。我们会对每个batch_size的数据都计算一个<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          l 
         
        
          n 
         
        
       
      
        l_n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.0197em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> ，最后求平均或求和。【默认求均值】</p> 
<p>​   看到这里大家可能还是一知半解，不用担心，我举一个小例子大家就明白了。首先我们初始化一些输入数据和标签：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> math
<span class="token builtin">input</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
target <span class="token operator">=</span> torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>​   来看看输入数据和标签的结果：</p> 
<p><img src="https://images2.imgbox.com/cb/b3/x7LKYmBX_o.png" alt="image-20220723144544905"></p> 
<p>​   接着我们要让输入数据经过Sigmoid函数将其归一化到[0,1]之间【BCELOSS函数要求】：</p> 
<pre><code class="prism language-python">m <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
m<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
</code></pre> 
<p>​   输出的结果如下：</p> 
<p><img src="https://images2.imgbox.com/6e/4c/75oegtSp_o.png" alt="image-20220723145022493"></p> 
<p>​   最后我们就可以使用BCELOSS函数计算输入数据和标签的损失了：</p> 
<pre><code class="prism language-python">loss <span class="token operator">=</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss<span class="token punctuation">(</span>m<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span>
</code></pre> 
<p>​ 输出结果如下：</p> 
<p><img src="https://images2.imgbox.com/52/0c/Rpuz6v4F_o.png" alt=""></p> 
<p>​ <mark>大家记住这个值喔！！！</mark></p> 
<p>​   上文似乎只是介绍了BCELOSS怎么用，具体怎么算的好像并不清楚，下面我们就根据官方给的公式来一步一步手动计算这个损失，看看结果和调用函数是否一致，如下：</p> 
<pre><code class="prism language-python">r11 <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.8172</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.8172</span><span class="token punctuation">)</span>
r12 <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.8648</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.8648</span><span class="token punctuation">)</span>
r13 <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.4122</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.4122</span><span class="token punctuation">)</span>

r21 <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.3266</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.3266</span><span class="token punctuation">)</span>
r22 <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.6902</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.6902</span><span class="token punctuation">)</span>
r23 <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.5620</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.5620</span><span class="token punctuation">)</span>

r31 <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.2024</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.2024</span><span class="token punctuation">)</span>
r32 <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.2884</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.2884</span><span class="token punctuation">)</span>
r33 <span class="token operator">=</span> <span class="token number">0</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">0.5554</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">*</span> math<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span><span class="token number">0.5554</span><span class="token punctuation">)</span>

BCELOSS <span class="token operator">=</span> <span class="token operator">-</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">9</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>r11 <span class="token operator">+</span> r12<span class="token operator">+</span> r13 <span class="token operator">+</span> r21 <span class="token operator">+</span> r22 <span class="token operator">+</span> r23 <span class="token operator">+</span> r31 <span class="token operator">+</span> r32 <span class="token operator">+</span> r33<span class="token punctuation">)</span>
</code></pre> 
<p>​  来看看结果叭：</p> 
<p><img src="https://images2.imgbox.com/9d/b5/qbBO3irB_o.png" alt="image-20220723145941661"></p> 
<p>​   你会发现调用<code>BCELOSS</code>函数和手动计算的结果是一致的，只是精度上有差别，这说明我们前面所说的理论公式是正确的。【注：官方还提供了一种函数——<a href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html" rel="nofollow"><code>BCEWithLogitsLoss</code></a>，其和<code>BCELOSS</code>大致一样，只是对输入的数据不需要再调用Sigmoid函数将其归一化到[0,1]之间，感兴趣的可以阅读看看】</p> 
<p>​   这个损失函数讲完训练部分就真没什么可讲的了，哦，这里得提一下，在计算生成器的损失时，我们不是最小化<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
       
         g 
        
       
         ( 
        
       
         1 
        
       
         − 
        
       
         D 
        
       
         ( 
        
       
         G 
        
       
         ( 
        
       
         Z 
        
       
         ) 
        
       
         ) 
        
       
         ) 
        
       
      
        log(1-D(G(Z))) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0715em;">Z</span><span class="mclose">)))</span></span></span></span></span> ，而是最大化<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         l 
        
       
         o 
        
       
         g 
        
       
         D 
        
       
         ( 
        
       
         G 
        
       
         ( 
        
       
         z 
        
       
         ) 
        
       
         ) 
        
       
      
        logD(G(z)) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span><span class="mopen">(</span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.044em;">z</span><span class="mclose">))</span></span></span></span></span> 。这个在GAN网络论文中也有提及，我<a href="https://juejin.cn/post/7120443914854613029" rel="nofollow">上一篇</a>没有说明这点，这里说声抱歉，论文中说是这样会更好的收敛，这里大家注意一下就好。</p> 
<p> </p> 
<h3><a id="_257"></a>番外篇——使用服务器训练如何保存图片和训练损失✨✨✨</h3> 
<p>​  不知道大家运行这个代码有没有遇到这样尬尴的处境：</p> 
<ol><li>无法科学上网，用不了google提供的免费GPU</li><li>自己电脑没有GPU，这个模型很难跑完</li><li>有服务器，但是官方提供的代码并没有保存最后生成的图片和损失，自己又不会改</li></ol> 
<p>​   前两个我没法帮大家解决，那么我就来说说怎么来保存图片和训练损失。首先来说说怎么保存图片，这个就很简单啦，就使用一个<code>save_image</code>函数即可，具体如下图所示：【在训练部分添加】</p> 
<p><img src="https://images2.imgbox.com/f7/cc/qfXvFi6p_o.png" alt="image-20220723162639573"></p> 
<p>​   接下来说说怎么保存训练损失，通过<code>torch.save()</code>方法保存代码如下：</p> 
<pre><code class="prism language-python"><span class="token comment">#保存LOSS</span>
G_losses <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>G_losses<span class="token punctuation">)</span>
D_losses <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>D_losses<span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>G_losses<span class="token punctuation">,</span> <span class="token string">'LOSS\\GL'</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>D_losses<span class="token punctuation">,</span> <span class="token string">'LOSS\\DL'</span><span class="token punctuation">)</span>
</code></pre> 
<p>​   代码执行完后，损失保存在LOSS文件夹下，一个文件为GL，一个为DL。这时候我们需要创建一个<code>.py文件</code>来加载损失并可视化，<code>.py</code>文件内容如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


<span class="token comment">#绘制LOSS曲线</span>
G_losses <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'F:\\老师发放论文\\经典网络模型\\GAN系列\\DCGAN\\LOSS\\GL'</span><span class="token punctuation">)</span>
D_losses <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'F:\\老师发放论文\\经典网络模型\\GAN系列\\DCGAN\\LOSS\\DL'</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Generator and Discriminator Loss During Training"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>G_losses<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"G"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>D_losses<span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">"D"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">"iterations"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">"Loss"</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>​  最后来看看保存的图片和损失，如下图所示：<br> <img src="https://images2.imgbox.com/42/d6/FKiNjNF6_o.jpg" alt="image_4_3165"></p> 
<img src="https://images2.imgbox.com/94/99/ZdOZtv6B_o.png" alt="image-20220723163500724"> 
<p> </p> 
<h3><a id="_309"></a>小结</h3> 
<p>​   至此，DCGAN就全部讲完啦，希望大家都能有所收获。有什么问题欢迎评论区讨论交流！！！GAN系列近期还会出cycleGAN的讲解和四季风格转换的demo，后期会考虑出瑕疵检测方面的GAN网络，如AnoGAN等等，敬请期待。🏵🏵🏵</p> 
<p>如若文章对你有所帮助，那就🛴🛴🛴</p> 
<p><img src="https://images2.imgbox.com/e3/0c/C70QVUHC_o.gif" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9bd1ba132b5af38fbacfe9b7cb293a29/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">STM32CubeMX配置HAL库实现SPI-DMA的递归调用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/65169d24d7ad42ce615d0b0ae7d6cd78/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何实现大文件上传：秒传、断点续传、分片上传</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>