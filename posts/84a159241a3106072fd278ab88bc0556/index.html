<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python-爬虫（Scrapy爬虫框架，爬取豆瓣读书和评分） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python-爬虫（Scrapy爬虫框架，爬取豆瓣读书和评分）" />
<meta property="og:description" content="文章目录 1.Scrapy注意点2. Scrapy爬取豆瓣读书和评分代码部分数据定义items.py爬虫部分spiders/book.py数据存储部分pipelines.py启动爬虫执行cmd命令 start.py 1.Scrapy注意点 Scrapy是爬虫框架。
它分为一下部分，其中引擎是核心
Scrapy Engine(引擎):负责spider、ltemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。Scheduler(调度器):它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。默认使用16个线程爬取数据Downloader(下载器):负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给spider来处理。Spider(爬虫):它负责处理所有Responses,从中分析提取数据，获取ltem字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)。ltem Pipeline(管道):它负责处理Spider中获取到的ltem，并进行后期处理（详细分析、过滤、存储等)的地方。（将爬虫爬取到的数据进行存储）Downloader Middlewares(下载中间件):一个可以自定义扩展下载功能的组件。Spider Middlewares (Spider中间件):一个可以自定扩展和操作引擎和spider中间通信的功能组件。 通过pip install scrapy在终端上下载这个爬虫框架。
注意：框架不能像包一样直接导入，需要生成框架结构，在这个结构上操作
启动框架：
首先在终端上进入到要生成项目的路径.
然后输入scrapy startproject 项目名启动框架
此时项目路径下会有一个框架生成的文件夹
之后生成爬虫文件命令如图：
先进入爬虫spiders文件夹中，输入scrapy genspider 爬虫文件名称 爬取网页的链接命令生成爬虫文件。这里以豆瓣读书为例
最后使用scrapy crawl &#43;爬虫名（book）来启动爬虫，因为在终端不方便数据查询，所以一般会使用其他方式启动。
这里创建新文件运行这个命令
运行结果scrapy日志信息是红色输出，网页源码以白色输出。
2. Scrapy爬取豆瓣读书和评分 scrapy爬取基本流程如下：
设置爬虫基础参数 settings.py爬虫数据封装管道 设置爬虫基础参数
这里不遵守这个协议，否则爬取不到什么信息了。改成False
默认爬取的线程数，可以取消注释，并修改数目，默认16个线程。
爬取网页后暂停的时间数目，默认不暂停。
请求头，这里需要至少要修改成浏览器信息
设定保存优先级，数字越大，优先级越小。用于多种保存方式下，哪一种保存方式优先。
代码部分 数据定义items.py # Define here the models for your scraped items # # See documentation in: # https://docs.scrapy.org/en/latest/topics/items.html import scrapy # 封装数据 class TestscrapyItem(scrapy." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/84a159241a3106072fd278ab88bc0556/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-29T12:34:02+08:00" />
<meta property="article:modified_time" content="2022-09-29T12:34:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python-爬虫（Scrapy爬虫框架，爬取豆瓣读书和评分）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#1Scrapy_2" rel="nofollow">1.Scrapy注意点</a></li><li><a href="#2_Scrapy_44" rel="nofollow">2. Scrapy爬取豆瓣读书和评分</a></li><li><ul><li><a href="#_69" rel="nofollow">代码部分</a></li><li><ul><li><a href="#itemspy_70" rel="nofollow">数据定义items.py</a></li><li><a href="#spidersbookpy_90" rel="nofollow">爬虫部分spiders/book.py</a></li><li><a href="#pipelinespy_122" rel="nofollow">数据存储部分pipelines.py</a></li><li><a href="#cmd_startpy_153" rel="nofollow">启动爬虫执行cmd命令 start.py</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="1Scrapy_2"></a>1.Scrapy注意点</h2> 
<p>Scrapy是爬虫框架。</p> 
<p>它分为一下部分，其中引擎是核心</p> 
<ol><li>Scrapy Engine(引擎):负责spider、ltemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。</li><li>Scheduler(调度器):它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。默认使用16个线程爬取数据</li><li>Downloader(下载器):负责下载Scrapy Engine(引擎)发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine(引擎)，由引擎交给spider来处理。</li><li>Spider(爬虫):它负责处理所有Responses,从中分析提取数据，获取ltem字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler(调度器)。</li><li>ltem Pipeline(管道):它负责处理Spider中获取到的ltem，并进行后期处理（详细分析、过滤、存储等)的地方。（将爬虫爬取到的数据进行存储）</li><li>Downloader Middlewares(下载中间件):一个可以自定义扩展下载功能的组件。</li><li>Spider Middlewares (Spider中间件):一个可以自定扩展和操作引擎和spider中间通信的功能组件。</li></ol> 
<p>通过pip install scrapy在终端上下载这个爬虫框架。</p> 
<p>注意：框架不能像包一样直接导入，需要生成框架结构，在这个结构上操作</p> 
<p>启动框架：</p> 
<p>首先在终端上进入到要生成项目的路径.</p> 
<p>然后输入<code>scrapy startproject 项目名</code>启动框架<br> <img src="https://images2.imgbox.com/e9/ef/Ll8B90zB_o.png" alt="在这里插入图片描述"><br> 此时项目路径下会有一个框架生成的文件夹</p> 
<p><img src="https://images2.imgbox.com/23/a5/nuTKISkP_o.png" alt="在这里插入图片描述"></p> 
<p>之后生成爬虫文件命令如图：<br> <img src="https://images2.imgbox.com/cd/36/htqbFdeq_o.png" alt="在这里插入图片描述"></p> 
<p>先进入爬虫spiders文件夹中，输入<code>scrapy genspider 爬虫文件名称 爬取网页的链接</code>命令生成爬虫文件。这里以<a href="https://book.douban.com/top250?start=0" rel="nofollow">豆瓣读书为例</a></p> 
<p><img src="https://images2.imgbox.com/39/cc/FmaOdZ0N_o.png" alt="在这里插入图片描述"></p> 
<p>最后使用scrapy crawl +爬虫名（book）来启动爬虫，因为在终端不方便数据查询，所以一般会使用其他方式启动。</p> 
<p>这里创建新文件运行这个命令<br> <img src="https://images2.imgbox.com/2a/c2/hnu7Wvsw_o.png" alt="在这里插入图片描述"><br> 运行结果scrapy日志信息是红色输出，网页源码以白色输出。</p> 
<h2><a id="2_Scrapy_44"></a>2. Scrapy爬取豆瓣读书和评分</h2> 
<p>scrapy爬取基本流程如下：</p> 
<ol><li>设置爬虫基础参数 settings.py</li><li>爬虫</li><li>数据封装</li><li>管道</li></ol> 
<p><strong>设置爬虫基础参数</strong><br> <img src="https://images2.imgbox.com/ad/31/YUzUWAJp_o.png" alt="在这里插入图片描述"><br> 这里不遵守这个协议，否则爬取不到什么信息了。改成False</p> 
<p><img src="https://images2.imgbox.com/b9/6c/ReY8kiyx_o.png" alt="在这里插入图片描述"><br> 默认爬取的线程数，可以取消注释，并修改数目，默认16个线程。</p> 
<p><img src="https://images2.imgbox.com/6e/ec/1h4I7uVg_o.png" alt="在这里插入图片描述"><br> 爬取网页后暂停的时间数目，默认不暂停。</p> 
<p><img src="https://images2.imgbox.com/11/72/WDiV1cIL_o.png" alt="在这里插入图片描述"><br> 请求头，这里需要至少要修改成浏览器信息</p> 
<p><img src="https://images2.imgbox.com/6f/b7/OUvMmmkB_o.png" alt="在这里插入图片描述"><br> 设定保存优先级，数字越大，优先级越小。用于多种保存方式下，哪一种保存方式优先。</p> 
<h3><a id="_69"></a>代码部分</h3> 
<h4><a id="itemspy_70"></a>数据定义items.py</h4> 
<pre><code class="prism language-python"><span class="token comment"># Define here the models for your scraped items</span>
<span class="token comment">#</span>
<span class="token comment"># See documentation in:</span>
<span class="token comment"># https://docs.scrapy.org/en/latest/topics/items.html</span>

<span class="token keyword">import</span> scrapy


<span class="token comment"># 封装数据</span>
<span class="token keyword">class</span> <span class="token class-name">TestscrapyItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    rating_nums <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

</code></pre> 
<h4><a id="spidersbookpy_90"></a>爬虫部分spiders/book.py</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> scrapy
<span class="token keyword">import</span> re
<span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> TestscrapyItem


<span class="token keyword">class</span> <span class="token class-name">BookSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'book'</span>  <span class="token comment"># 通过这个名字启动爬虫</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'book.douban.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://book.douban.com/top250?start=0'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># response是爬虫返回的网页数据</span>
        <span class="token comment"># print(response.text)</span>

        <span class="token comment"># 封装对象</span>
        items <span class="token operator">=</span> TestscrapyItem<span class="token punctuation">(</span><span class="token punctuation">)</span>

        title <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">'&lt;a href=".*?" οnclick=.*?;moreurl.*?; title="(.*?)"'</span><span class="token punctuation">,</span> response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>
        rating_nums <span class="token operator">=</span> re<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token string">'&lt;span class="rating_nums"&gt;(.*?)&lt;/span&gt;'</span><span class="token punctuation">,</span> response<span class="token punctuation">.</span>text<span class="token punctuation">)</span>

        <span class="token comment"># print(rating_nums)</span>
        <span class="token comment"># 封装数据给pipelines</span>
        <span class="token keyword">for</span> title<span class="token punctuation">,</span> rating_nums <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span> rating_nums<span class="token punctuation">)</span><span class="token punctuation">:</span>
            items<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title
            items<span class="token punctuation">[</span><span class="token string">'rating_nums'</span><span class="token punctuation">]</span> <span class="token operator">=</span> rating_nums
            <span class="token keyword">yield</span> items <span class="token comment">#给pipelines</span>

</code></pre> 
<h4><a id="pipelinespy_122"></a>数据存储部分pipelines.py</h4> 
<pre><code class="prism language-python"><span class="token comment"># Define your item pipelines here</span>
<span class="token comment">#</span>
<span class="token comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span>
<span class="token comment"># See: https://docs.scrapy.org/en/latest/topics/item-pipeline.html</span>


<span class="token comment"># useful for handling different item types with a single interface</span>
<span class="token keyword">from</span> itemadapter <span class="token keyword">import</span> ItemAdapter


<span class="token comment"># 保存数据</span>
<span class="token keyword">class</span> <span class="token class-name">TestscrapyPipeline</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span> <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data.txt'</span><span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">  评分:</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>item<span class="token punctuation">[</span><span class="token string">'rating_nums'</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">\n==========\n"</span></span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item  <span class="token comment"># 通知爬虫，这个数据已经保存成功了</span>

    <span class="token comment"># 析构函数</span>
    <span class="token keyword">def</span> <span class="token function">__del__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span><span class="token builtin">file</span><span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'文件保存成功'</span><span class="token punctuation">)</span>

</code></pre> 
<h4><a id="cmd_startpy_153"></a>启动爬虫执行cmd命令 start.py</h4> 
<pre><code class="prism language-python"><span class="token keyword">import</span> os

os<span class="token punctuation">.</span>system<span class="token punctuation">(</span><span class="token string">'scrapy crawl book'</span><span class="token punctuation">)</span>
</code></pre> 
<p>运行结果</p> 
<p><img src="https://images2.imgbox.com/5f/2f/3ckAhlX9_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6e/f3/POIxhbWr_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b2839d258c43aebbc3b3e3f2c5b98e5e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">2022 阿里全球数学竞赛获奖名单公布，其中 00 后选手占了一半多，如何评价这一现象？</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/107bbd48e7cf75fa53ff9658ef55842e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">uniapp使用输入框固定在底部键盘弹起把输入框挡住问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>