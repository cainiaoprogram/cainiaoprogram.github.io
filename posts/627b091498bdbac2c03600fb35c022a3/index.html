<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Greenplum6.x安装PXF插件 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Greenplum6.x安装PXF插件" />
<meta property="og:description" content="目录 Greenplum6.x安装PXF插件目录 1 安装Hadoop与Hive的客户端 1.1 在大数据平台的主节点(namenode)上打包客户端 1.2 把文件scp到Greenplum的master节点上 2 Greenplum的master节点解压文件配置环境变量 2.1 解压文件 2.2 对文件重命名 2.3 为 gpadmin配置环境变量 3 PXF安装 3.1 PXF 初始化 3.2 创建新的文件夹 3.3 修改pxf-env.sh配置文件 3.4 把配置文件复制到目录下 3.5 PXF 同步文件 3.6 开启PXF 4 测试PXF 4.1 查看hive与hdfs数据 4.1 测试PXF连接Hive 4.2 测试PXF连接Haddop 5 PXF单节点安装说明 1 安装Hadoop与Hive的客户端 以下实例是在ambari管理的大数据平台,hdp版本是2.6.5.0
1.1在大数据平台的主节点(namenode)上打包客户端 1、登录到ambari的主节点，登录hdfs用户，进入到/usr/hdp/2.6.5.0-292下 2、以此打包安装好的hadoop与hive与hbase的组件 [hdfs@*** 2.6.5.0-292]$ zip -r hadoop-2.6.zip hadoop [hdfs@*** 2.6.5.0-292]$ zip -r hive-2.6.zip hive [hdfs@*** 2.6.5.0-292]$ zip -r hbase-2.6.zip hbase 1.2把文件scp到Greenplum的master节点上 [hdfs@*** 2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/627b091498bdbac2c03600fb35c022a3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-06-18T13:37:57+08:00" />
<meta property="article:modified_time" content="2020-06-18T13:37:57+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Greenplum6.x安装PXF插件</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E7%9B%AE%E5%BD%95">目录</h2> 
<pre>Greenplum6.x安装PXF插件目录
1 安装Hadoop与Hive的客户端  
  1.1 在大数据平台的主节点(namenode)上打包客户端  
  1.2 把文件scp到Greenplum的master节点上
2 Greenplum的master节点解压文件配置环境变量  
  2.1 解压文件  
  2.2 对文件重命名  
  2.3 为 gpadmin配置环境变量
3  PXF安装  
   3.1 PXF 初始化  
   3.2 创建新的文件夹  
   3.3 修改pxf-env.sh配置文件  
   3.4 把配置文件复制到目录下  
   3.5 PXF 同步文件  
   3.6 开启PXF
 4 测试PXF  
   4.1 查看hive与hdfs数据  
   4.1 测试PXF连接Hive  
   4.2 测试PXF连接Haddop
 5 PXF单节点安装说明</pre> 
<h2 id="1-%E5%AE%89%E8%A3%85Hadoop%E4%B8%8EHive%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF">1 安装Hadoop与Hive的客户端</h2> 
<p>以下实例是在ambari管理的大数据平台,hdp版本是2.6.5.0</p> 
<h3 id="1.1%E5%9C%A8%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E4%B8%BB%E8%8A%82%E7%82%B9(namenode)%E4%B8%8A%E6%89%93%E5%8C%85%E5%AE%A2%E6%88%B7%E7%AB%AF">1.1在大数据平台的主节点(namenode)上打包客户端</h3> 
<pre>1、登录到ambari的主节点，登录hdfs用户，进入到/usr/hdp/2.6.5.0-292下
2、以此打包安装好的hadoop与hive与hbase的组件


[hdfs@*** 2.6.5.0-292]$ zip -r hadoop-2.6.zip hadoop

[hdfs@*** 2.6.5.0-292]$ zip -r hive-2.6.zip hive

[hdfs@*** 2.6.5.0-292]$ zip -r hbase-2.6.zip hbase</pre> 
<h3 id="1.2%E6%8A%8A%E6%96%87%E4%BB%B6scp%E5%88%B0Greenplum%E7%9A%84master%E8%8A%82%E7%82%B9%E4%B8%8A">1.2把文件scp到Greenplum的master节点上</h3> 
<pre>[hdfs@*** 2.6.5.0-292]$ scp -r hadoop-2.6.zip  gpmaster@gpadmin:/home/gpadmin

[hdfs@*** 2.6.5.0-292]$ scp -r hive-2.6.zip  gpmaster@gpadmin:/home/gpadmin

[hdfs@*** 2.6.5.0-292]$ scp -r hbase-2.6.zip  gpmaster@gpadmin:/home/gpadmin


gpmaster : 主节点的IP地址的映射gpadmin : master节点上的用户/home/gpadmin : 文件保存的路径</pre> 
<h2 id="2-Greenplum%E7%9A%84master%E8%8A%82%E7%82%B9%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">2 Greenplum的master节点解压文件配置环境变量</h2> 
<h3 id="2.1-%E8%A7%A3%E5%8E%8B%E6%96%87%E4%BB%B6">2.1 解压文件</h3> 
<pre>[gpadmin@*** ~]$ unzip hadoop-2.6.zip

[gpadmin@*** ~]$ unzip hive-2.6.zip

[gpadmin@*** ~]$ unzip hbase-2.6.zip</pre> 
<h3 id="2.2-%E5%AF%B9%E6%96%87%E4%BB%B6%E9%87%8D%E5%91%BD%E5%90%8D">2.2 对文件重命名</h3> 
<pre>[gpadmin@*** ~]$ mv  hadoop  hadoop-2.6

[gpadmin@*** ~]$ mv  hive  hive-2.6

[gpadmin@*** ~]$ mv  hbase  hbase-2.6</pre> 
<h3 id="2.3-%E4%B8%BA-gpadmin%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">2.3 为 gpadmin配置环境变量</h3> 
<pre>在以下文件中加入以下配置
[gpadmin@*** ~]$ vim  /home/gpadmin/.bashrc

source /usr/local/greenplum-db/greenplum_path.sh

export JAVA_HOME=/opt/java/jdk1.8.0_11
export PXF_HOME=/usr/local/greenplum-db-6.1.0/pxf/
export PXF_CONF=/usr/local/greenplum-db-6.1.0/pxf/conf
export HADOOP_HOME=/home/gpadmin/hadoop-2.6
export HIVE_HOME=/home/gpadmin/hive-2.6
export HADOOP_CONF_DIR=/home/gpadmin/hadoop-2.6/conf
export HIVE_CONF=/home/gpadmin/hive-2.6/conf
export GP_HOME=/usr/local/greenplum-db-6.1.0/
export PATH=$JAVA_HOME/bin:$GP_HOME/bin:$PATH

export PATH=$JAVA_HOME/bin:$HADOOP_HOME/bin:$HIVE_HOME/bin:$HADOOP_CONF_DIR:$HIVE_CONF:$PATH
export PATH=$PXF_HOME/bin:$PXF_CONF:$PATH</pre> 
<h2 id="3--PXF%E5%AE%89%E8%A3%85">3 PXF安装</h2> 
<p>在greenplum的master节点以gpadmin用户登录</p> 
<h3 id="3.1-PXF-%E5%88%9D%E5%A7%8B%E5%8C%96">3.1 PXF 初始化</h3> 
<pre>[gpadmin@*** ~ ]$ source /home/gpadmin/.bashrc
[gpadmin@*** ~ ]$ pxf cluster init

初始化之后会在$PXF_HOME目录下看到pxf-service新生产的文件夹</pre> 
<h3 id="3.2-%E5%88%9B%E5%BB%BA%E6%96%B0%E7%9A%84%E6%96%87%E4%BB%B6%E5%A4%B9">3.2 创建新的文件夹</h3> 
<p>在$PXF_HOME/servers目录下创建hdp-prod文件夹</p> 
<p>在$PXF_HOME/conf/servers目录下创建hdp-prod文件夹</p> 
<h3 id="3.3-%E4%BF%AE%E6%94%B9pxf-env.sh%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6">3.3 修改pxf-env.sh配置文件</h3> 
<pre>[gpadmin@***~]$ cd $PXF_HOME/conf/conf把

export PXF_USER_IMPERSONATION=true

改成

export PXF_USER_IMPERSONATION=false</pre> 
<h3 id="3.4-%E6%8A%8A%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6%E5%88%B0%E7%9B%AE%E5%BD%95%E4%B8%8B">3.4 把配置文件复制到目录下</h3> 
<pre>1、把hadoop相关的hdfs-site.xml/core-site.xml/mapred-site.xml/yarn-site.xml 
复制到$PXF_HOME/servers/hdp-prod与$PXF_HOME/conf/servers/conf下


2、把hive相关的hive-env.sh/hive-site.xml/mapred-site.xml
复制到$PXF_HOME/servers/hdp-prod与$PXF_HOME/conf/servers/conf下


3、把hbase相关的hbase-env.sh/hbase-site.xml
复制到$PXF_HOME/servers/hdp-prod与$PXF_HOME/conf/servers/conf下</pre> 
<h3 id="3.5-PXF-%E5%90%8C%E6%AD%A5%E6%96%87%E4%BB%B6">3.5 PXF 同步文件</h3> 
<pre>[gpadmin@***~]$ pxf cluster sync</pre> 
<h3 id="3.6-%E5%BC%80%E5%90%AFPXF">3.6 开启PXF</h3> 
<pre>[gpadmin@***  ~]$ pxf cluster start</pre> 
<h2 id="4-%E6%B5%8B%E8%AF%95PXF">4 测试PXF</h2> 
<h3 id="4.1-%E6%9F%A5%E7%9C%8Bhive%E4%B8%8Ehdfs%E6%95%B0%E6%8D%AE">4.1 查看hive与hdfs数据</h3> 
<pre>查看hive中的表hive&gt; use udt;hive&gt; select * from test;
OK
1       1
2       2
Time taken: 0.584 seconds, Fetched: 2 row(s)

test是在udt的schema下
查看hadoop上数据
$ hadoop fs -cat  /hawq_data/test.txt
dnsdde,ededed
sddde,dedw
swewd,wreref

hadoop上的数据是以逗号分隔的数据</pre> 
<h3 id="4.1-%E6%B5%8B%E8%AF%95PXF%E8%BF%9E%E6%8E%A5Hive">4.1 测试PXF连接Hive</h3> 
<pre>创建pxf插件CREATE  EXTENSION  pxf;
创建测试外部表CREATE EXTERNAL TABLE hive_test(
id text,
name text
)
LOCATION ('pxf://udt.test?PROFILE=Hive&amp;SERVER=hdp-prod') 
FORMAT 'custom' (formatter='pxfwritable_import');

查询数据
select * from salesinfo_hiveprofile; 
id | name
----+------
 2  | 2
 1  | 1
(2 rows)</pre> 
<h3 id="4.2-%E6%B5%8B%E8%AF%95PXF%E8%BF%9E%E6%8E%A5Haddop">4.2 测试PXF连接Haddop</h3> 
<pre>创建测试外部表
CREATE EXTERNAL TABLE hadoop_test (
a varchar(100),
b varchar(100) 
) 
LOCATION ('pxf://hawq_data/test.txt?PROFILE=hdfs:text&amp;SERVER=hdp-prod') 
ON ALL FORMAT 'text' (delimiter E',') ENCODING 'UTF8';

查看数据
select * from test;   
a    |   b   
--------+-------- 
dnsdde | ededed 
sddde  | dedw 
swewd  | wreref
(3 rows)</pre> 
<h2 id="5-PXF%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85%E8%AF%B4%E6%98%8E">5 PXF单节点安装说明</h2> 
<p>如果Greenplum是单节点的安装或者想单台机器运行pxf，可以把cluster命令是pxf init/pxf start/pxf stop等</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/32ecc96020f70d8e84b8c5b07aee6a28/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">gcode指令大全</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3b32acd56f7c5e33800340ca21ca7099/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">JavaEE大作业</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>