<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python&#43;正则表达式爬取京东商品数据信息 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python&#43;正则表达式爬取京东商品数据信息" />
<meta property="og:description" content="爬取数据的方式有很多种，正则表达式，scrapy，从接口中爬取动态网页的数据…今天我们讲的是用正则表达式来爬取京东一个大米商品的具体信息。
正则表达式的优点：可以精准的爬取我们想要的数据信息
缺点：爬取的速度会很慢，时间就会变得很长，就容易被反爬虫，封ip
若想爬取大量数据的信息，就需要分为三部分进行
1：爬取一个大米商品的具体信息(也就是下图中的蓝色部分)
2：爬取一整个页面上的所有的商品的信息(也就是这个页面上所有的商品)
3：分页爬取(也就是下图中的蓝色部分，一共一百页)
这次主要针对第一个爬取一个大米商品的具体信息进行讲解，剩下的两个爬取所有和分页爬取将到下一次进行讲解。
爬虫步骤：1：发送请求（request），获取响应内容。
2：解析内容
3：运行函数
下面我们就开始吧
我们爬取的网址是
https://item.jd.com/56986006225.html 一：导入相应的库
import re from urllib import request re库用来进行正则表达式匹配
request用来发送请求
库的安装都可以用以下指令来进行安装
pip install re pip install urllib 二：建立一个spider类（因为我们的爬虫是在类里进行的），在类下写正则表达式
class Spider(): inform = &#39;&lt;div class=&#34;p-parameter&#34;&gt;([\s\S]*?)&lt;/div&gt;&#39; dianming = &#39;target=\&#39;_blank\&#39;&gt;([\s\S]*?)&lt;/a&gt;&#39; name =&#39;商品名称：([\s\S]*?)&lt;/li&gt;\n&#39; bianhao = &#39;商品编号：([\s\S]*?)&lt;/li&gt;\n&#39; maozhong = &#39;商品毛重：([\s\S]*?)&lt;/li&gt;\n&#39; chaidi = &#39;商品产地：([\s\S]*?)&lt;/li&gt;\n&#39; jinghanliang = &#39;净含量：([\s\S]*?)&lt;/li&gt;\n&#39; fenlei = &#39;分类：([\s\S]*?)&lt;/li&gt;\n&#39; baozhuang = &#39;包装：([\s\S]*?)&lt;/li&gt;\n&#39; jiage = &#39;&lt;div class=&#34;dd&#34;&gt;([\s\S]*?)&lt;/div&gt;&#39; pinjia = &#39;&lt;div class=&#34;tab-con&#34;&gt;([\s\S]*?)&lt;/div&gt;&#39; 正则表达式的匹配要学习的内容有很多，但是要说有没有一种正则表达式可以匹配数字或者文字。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ee71227f9049e0c5ed07e4c77d1152d0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-12-03T14:50:20+08:00" />
<meta property="article:modified_time" content="2019-12-03T14:50:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python&#43;正则表达式爬取京东商品数据信息</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>爬取数据的方式有很多种，正则表达式，scrapy，从接口中爬取动态网页的数据…今天我们讲的是用正则表达式来爬取京东一个大米商品的具体信息。<br> 正则表达式的优点：可以精准的爬取我们想要的数据信息<br> 缺点：爬取的速度会很慢，时间就会变得很长，就容易被反爬虫，封ip<br> 若想爬取大量数据的信息，就需要分为三部分进行<br> 1：爬取一个大米商品的具体信息(也就是下图中的蓝色部分)<br> <img src="https://images2.imgbox.com/bc/35/8nzABbaU_o.png" alt="在这里插入图片描述"></p> 
<p>2：爬取一整个页面上的所有的商品的信息(也就是这个页面上所有的商品)<br> <img src="https://images2.imgbox.com/82/be/5nCmQsr6_o.png" alt="在这里插入图片描述"><br> 3：分页爬取(也就是下图中的蓝色部分，一共一百页)<br> <img src="https://images2.imgbox.com/5b/2a/k0mXyzM6_o.png" alt="在这里插入图片描述"><br> 这次主要针对第一个爬取一个大米商品的具体信息进行讲解，剩下的两个爬取所有和分页爬取将到下一次进行讲解。</p> 
<p><strong>爬虫步骤：1：发送请求（request），获取响应内容。<br> 2：解析内容<br> 3：运行函数</strong></p> 
<p>下面我们就开始吧<br> 我们爬取的网址是</p> 
<pre><code class="prism language-bash">https://item.jd.com/56986006225.html
</code></pre> 
<p>一：导入相应的库</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> re      
from urllib <span class="token function">import</span> request
</code></pre> 
<p>re库用来进行正则表达式匹配<br> request用来发送请求<br> 库的安装都可以用以下指令来进行安装</p> 
<pre><code class="prism language-bash">pip <span class="token function">install</span> re
pip <span class="token function">install</span> urllib
</code></pre> 
<p>二：建立一个spider类（因为我们的爬虫是在类里进行的），在类下写正则表达式</p> 
<pre><code class="prism language-bash">class Spider<span class="token punctuation">(</span><span class="token punctuation">)</span>:
    inform <span class="token operator">=</span> <span class="token string">'&lt;div class="p-parameter"&gt;([\s\S]*?)&lt;/div&gt;'</span>
    dianming <span class="token operator">=</span> <span class="token string">'target=\'_blank\'&gt;([\s\S]*?)&lt;/a&gt;'</span>
    name  <span class="token operator">=</span><span class="token string">'商品名称：([\s\S]*?)&lt;/li&gt;\n'</span>
    bianhao <span class="token operator">=</span> <span class="token string">'商品编号：([\s\S]*?)&lt;/li&gt;\n'</span>
    maozhong <span class="token operator">=</span> <span class="token string">'商品毛重：([\s\S]*?)&lt;/li&gt;\n'</span>
    chaidi <span class="token operator">=</span> <span class="token string">'商品产地：([\s\S]*?)&lt;/li&gt;\n'</span>
    jinghanliang <span class="token operator">=</span> <span class="token string">'净含量：([\s\S]*?)&lt;/li&gt;\n'</span>
    fenlei <span class="token operator">=</span> <span class="token string">'分类：([\s\S]*?)&lt;/li&gt;\n'</span>
    baozhuang <span class="token operator">=</span> <span class="token string">'包装：([\s\S]*?)&lt;/li&gt;\n'</span>
    jiage <span class="token operator">=</span> <span class="token string">'&lt;div class="dd"&gt;([\s\S]*?)&lt;/div&gt;'</span>
    pinjia <span class="token operator">=</span> <span class="token string">'&lt;div class="tab-con"&gt;([\s\S]*?)&lt;/div&gt;'</span>
</code></pre> 
<p>正则表达式的匹配要学习的内容有很多，但是要说有没有一种正则表达式可以匹配数字或者文字。</p> 
<pre><code class="prism language-bash"><span class="token punctuation">(</span><span class="token punctuation">[</span>\s\S<span class="token punctuation">]</span>*?<span class="token punctuation">)</span>
</code></pre> 
<p>其实是有的，只要在自己想匹配内容的位置上把内容删掉，然后换上([\s\S]*?)就可以了，这样就可以匹配到自己想要的内容。</p> 
<p>【那么，正则表达式是怎么写的呢，有两种方式，第一种是在自己想爬的网站上按F12，就变成了这个样子<br> <img src="https://images2.imgbox.com/db/0a/axDPP2EX_o.png" alt="在这里插入图片描述"><br> 然后点上图的那个红色圆圈，就可以选取自己想爬取的内容，比如说我们想爬取商品名称，就选中商品名称就可以了，然后右边就会出现相应内容的源代码。<br> <img src="https://images2.imgbox.com/99/20/GqNFJ9wC_o.png" alt="在这里插入图片描述"><br> 然后把内容去掉，换成正则表达式就可以了，**但是这样经常会匹配到空的字符串，因为网页上的源代码和发送给我们的源代码是不一样的，可能会有/n /r/n 等字符匹配不到。**第二种方式等到文章后面在讲，可以精确匹配到内容(在这里讲可能会有同学听不懂)】</p> 
<p>三：发送请求（request），获取响应内容</p> 
<pre><code class="prism language-bash">    def __fetch_content<span class="token punctuation">(</span>self,url<span class="token punctuation">)</span>:       <span class="token comment">#抓取网页地址</span>
        r <span class="token operator">=</span> request.urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span>   <span class="token comment">#发送请求给浏览器</span>
        htmls <span class="token operator">=</span> r.read<span class="token punctuation">(</span><span class="token punctuation">)</span>                 <span class="token comment">#读取浏览器的返回并赋值</span>
        htmls <span class="token operator">=</span> str<span class="token punctuation">(</span>htmls, encoding <span class="token operator">=</span> <span class="token string">'gb18030'</span><span class="token punctuation">)</span>     <span class="token comment">#把返回的html转换成字符串，并进行编码转换</span>
        <span class="token keyword">return</span> htmls                               <span class="token comment">#返回htmls</span>
</code></pre> 
<p>只要你想用正则表达式爬任何网站，这一段代码基本上就是不变的，起到了向网址发送请求的获取html的作用</p> 
<p>四：解析内容</p> 
<pre><code class="prism language-bash">    def __analysis<span class="token punctuation">(</span>self,htmls<span class="token punctuation">)</span>:
        infom_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.inform,htmls<span class="token punctuation">)</span>
        <span class="token keyword">for</span> html <span class="token keyword">in</span> infom_html:
            dianming_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.dianming, html<span class="token punctuation">)</span>
            name_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.name, html<span class="token punctuation">)</span>
            bianhao_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.bianhao,html<span class="token punctuation">)</span>
            maozhong_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.maozhong,html<span class="token punctuation">)</span>
            chaidi_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.chaidi,html<span class="token punctuation">)</span>
            jinghualiang_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.jinghanliang,html<span class="token punctuation">)</span>
            fenlei_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.fenlei,html<span class="token punctuation">)</span>
            baozhuang_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.baozhuang,html<span class="token punctuation">)</span>
            anchors <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'品牌'</span>:dianming_html,
                    <span class="token string">'商品名称'</span>:name_html,
                    <span class="token string">'商品编号'</span>:bianhao_html,
                    <span class="token string">'商品毛重'</span>:maozhong_html,
                    <span class="token string">'商品产地'</span>:chaidi_html,
                    <span class="token string">'净含量'</span>:jinghualiang_html,
                    <span class="token string">'分类'</span>:fenlei_html,
                    <span class="token string">'包装'</span>:baozhuang_html<span class="token punctuation">}</span>
            print<span class="token punctuation">(</span>anchors<span class="token punctuation">)</span>
</code></pre> 
<p>在这里我们用re库的findall来匹配内容，接受两个参数，一个是正则表达式(如Spider.inform…)，另一个是在哪里匹配(如htmls)<br> 在这里，infom_html的作用是在网页返回的htmls里缩小了匹配范围，更加容易匹配到内容<br> 随后我定义了输出格式，anchors，以字典的形式输出来</p> 
<p>五：运行函数</p> 
<pre><code class="prism language-bash">    def go<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:              <span class="token comment">#运行函数</span>
        url <span class="token operator">=</span> <span class="token string">'https://item.jd.com/56986006225.html'</span>
        htmls <span class="token operator">=</span> self.__fetch_content<span class="token punctuation">(</span>url<span class="token punctuation">)</span>          <span class="token comment">#获取网址</span>
        anchors <span class="token operator">=</span> self.__analysis<span class="token punctuation">(</span>htmls<span class="token punctuation">)</span>         <span class="token comment">#用正则表达式匹配</span>
</code></pre> 
<p>这一步的作用是传递我们要爬的网址url，来运行以上定义的两个函数</p> 
<p>六：实例化类对象，运行类</p> 
<pre><code class="prism language-bash">spider <span class="token operator">=</span> Spider<span class="token punctuation">(</span><span class="token punctuation">)</span>
spider.go<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>这里就不多说了，就是起到了运行class Spider 类的作用</p> 
<p>全体代码：</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> re
from urllib <span class="token function">import</span> request
class Spider<span class="token punctuation">(</span><span class="token punctuation">)</span>:
    inform <span class="token operator">=</span> <span class="token string">'&lt;div class="p-parameter"&gt;([\s\S]*?)&lt;/div&gt;'</span>
    dianming <span class="token operator">=</span> <span class="token string">'target=\'_blank\'&gt;([\s\S]*?)&lt;/a&gt;'</span>
    name  <span class="token operator">=</span><span class="token string">'商品名称：([\s\S]*?)&lt;/li&gt;\n'</span>
    bianhao <span class="token operator">=</span> <span class="token string">'商品编号：([\s\S]*?)&lt;/li&gt;\n'</span>
    maozhong <span class="token operator">=</span> <span class="token string">'商品毛重：([\s\S]*?)&lt;/li&gt;\n'</span>
    chaidi <span class="token operator">=</span> <span class="token string">'商品产地：([\s\S]*?)&lt;/li&gt;\n'</span>
    jinghanliang <span class="token operator">=</span> <span class="token string">'净含量：([\s\S]*?)&lt;/li&gt;\n'</span>
    fenlei <span class="token operator">=</span> <span class="token string">'分类：([\s\S]*?)&lt;/li&gt;\n'</span>
    baozhuang <span class="token operator">=</span> <span class="token string">'包装：([\s\S]*?)&lt;/li&gt;\n'</span>
    jiage <span class="token operator">=</span> <span class="token string">'&lt;div class="dd"&gt;([\s\S]*?)&lt;/div&gt;'</span>
    pinjia <span class="token operator">=</span> <span class="token string">'&lt;div class="tab-con"&gt;([\s\S]*?)&lt;/div&gt;'</span>

    def __fetch_content<span class="token punctuation">(</span>self,url<span class="token punctuation">)</span>:
        r <span class="token operator">=</span> request.urlopen<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
        htmls <span class="token operator">=</span> r.read<span class="token punctuation">(</span><span class="token punctuation">)</span>
        htmls <span class="token operator">=</span> str<span class="token punctuation">(</span>htmls,encoding<span class="token operator">=</span><span class="token string">'gb18030'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> htmls

    def __analysis<span class="token punctuation">(</span>self,htmls<span class="token punctuation">)</span>:
        infom_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.inform,htmls<span class="token punctuation">)</span>
        <span class="token keyword">for</span> html <span class="token keyword">in</span> infom_html:
            dianming_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.dianming, html<span class="token punctuation">)</span>
            name_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.name, html<span class="token punctuation">)</span>
            bianhao_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.bianhao,html<span class="token punctuation">)</span>
            maozhong_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.maozhong,html<span class="token punctuation">)</span>
            chaidi_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.chaidi,html<span class="token punctuation">)</span>
            jinghualiang_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.jinghanliang,html<span class="token punctuation">)</span>
            fenlei_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.fenlei,html<span class="token punctuation">)</span>
            baozhuang_html <span class="token operator">=</span> re.findall<span class="token punctuation">(</span>Spider.baozhuang,html<span class="token punctuation">)</span>
            anchors <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'品牌'</span>:dianming_html,
                    <span class="token string">'商品名称'</span>:name_html,
                    <span class="token string">'商品编号'</span>:bianhao_html,
                    <span class="token string">'商品毛重'</span>:maozhong_html,
                    <span class="token string">'商品产地'</span>:chaidi_html,
                    <span class="token string">'净含量'</span>:jinghualiang_html,
                    <span class="token string">'分类'</span>:fenlei_html,
                    <span class="token string">'包装'</span>:baozhuang_html<span class="token punctuation">}</span>
            print<span class="token punctuation">(</span>anchors<span class="token punctuation">)</span>

    def go<span class="token punctuation">(</span>self<span class="token punctuation">)</span>:              <span class="token comment">#运行函数</span>
        url <span class="token operator">=</span> <span class="token string">'https://item.jd.com/56986006225.html'</span>
        htmls <span class="token operator">=</span> self.__fetch_content<span class="token punctuation">(</span>url<span class="token punctuation">)</span>          <span class="token comment">#获取网址输入</span>
        anchors <span class="token operator">=</span> self.__analysis<span class="token punctuation">(</span>htmls<span class="token punctuation">)</span>         <span class="token comment">#用正则表达式匹配</span>

spider <span class="token operator">=</span> Spider<span class="token punctuation">(</span><span class="token punctuation">)</span>
spider.go<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>输出：<br> <img src="https://images2.imgbox.com/19/d9/JiNvt2RW_o.png" alt="在这里插入图片描述"><br> 最后，讲解一下正则表达式匹配的第二种方式，<br> 1：在def_analysis(self,htmls):里设置断点，然后进行调试</p> 
<p><img src="https://images2.imgbox.com/cf/f2/THlehBwA_o.png" alt="在这里插入图片描述"><br> 圆的为断点，长方形的为调试，等待一会后出现<br> <img src="https://images2.imgbox.com/ec/30/NdXzN7Ob_o.png" alt="在这里插入图片描述"><br> 然后右边就会出现你匹配到的情况，在里面找到htmls，点view然后把里面的内容复制到一个word文档里，在里面进行匹配，一定可以匹配到自己想要的内容。</p> 
<p>至此，爬取一个商品的具体信息已经结束了，接下来会讲解如何爬取一整个网页上的信息，和分页爬取。我们以后再见吧。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/80f6d06249f8c51f74938d0a006e2222/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">微信小程序访问WebService接口返回500错误解决过程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/78a0ac4bcf405ae4df40e2b7c5be87b0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java的ssh传输文件</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>