<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【YOLOV5-5.x 源码解读】common.py - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【YOLOV5-5.x 源码解读】common.py" />
<meta property="og:description" content="目录 前言0、导入需要的包和基本配置1、基本组件1.1、autopad1.2、Conv1.3、Focus1.4、Bottleneck1.5、BottleneckCSP1.6、C31.7、SPP1.8、Concat1.9、Contract、Expand 2、注意力模块2.1、transformer自注意力模块2.2、SE注意力模块2.3、CBAM注意力模块2.4、CA注意力模块 3、模型扩展模块3.1、NMS3.2、AutoShape3.3、Detections3.4、Classify 总结Reference 前言 源码： YOLOv5源码.
导航: 【YOLOV5-5.x 源码讲解】整体项目文件导航.
注释版全部项目文件已上传至GitHub: yolov5-5.x-annotations.
这个模块存放着yolov5网络搭建常见Common模块。
yolov5s网络结构图：
0、导入需要的包和基本配置 import math # 数学函数模块 from copy import copy # 数据拷贝模块 分浅拷贝和深拷贝 from pathlib import Path # Path将str转换为Path对象 使字符串路径易于操作的模块 import numpy as np # numpy数组操作模块 import pandas as pd # panda数组操作模块 import requests # Python的HTTP客户端库 import torch # pytorch深度学习框架 import torch.nn as nn # 专门为神经网络设计的模块化接口 from PIL import Image # 图像基础操作模块 from torch.cuda import amp # 混合精度训练模块 from utils." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9a9a56656d4b46da58ec93fe8d563c1c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-03T14:54:07+08:00" />
<meta property="article:modified_time" content="2022-04-03T14:54:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【YOLOV5-5.x 源码解读】common.py</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">前言</a></li><li><a href="#0_13" rel="nofollow">0、导入需要的包和基本配置</a></li><li><a href="#1_34" rel="nofollow">1、基本组件</a></li><li><ul><li><a href="#11autopad_37" rel="nofollow">1.1、autopad</a></li><li><a href="#12Conv_57" rel="nofollow">1.2、Conv</a></li><li><a href="#13Focus_94" rel="nofollow">1.3、Focus</a></li><li><a href="#14Bottleneck_131" rel="nofollow">1.4、Bottleneck</a></li><li><a href="#15BottleneckCSP_157" rel="nofollow">1.5、BottleneckCSP</a></li><li><a href="#16C3_197" rel="nofollow">1.6、C3</a></li><li><a href="#17SPP_230" rel="nofollow">1.7、SPP</a></li><li><a href="#18Concat_257" rel="nofollow">1.8、Concat</a></li><li><a href="#19ContractExpand_276" rel="nofollow">1.9、Contract、Expand</a></li></ul> 
  </li><li><a href="#2_320" rel="nofollow">2、注意力模块</a></li><li><ul><li><a href="#21transformer_333" rel="nofollow">2.1、transformer自注意力模块</a></li><li><a href="#22SE_441" rel="nofollow">2.2、SE注意力模块</a></li><li><a href="#23CBAM_492" rel="nofollow">2.3、CBAM注意力模块</a></li><li><a href="#24CA_623" rel="nofollow">2.4、CA注意力模块</a></li></ul> 
  </li><li><a href="#3_689" rel="nofollow">3、模型扩展模块</a></li><li><ul><li><a href="#31NMS_694" rel="nofollow">3.1、NMS</a></li><li><a href="#32AutoShape_722" rel="nofollow">3.2、AutoShape</a></li><li><a href="#33Detections_810" rel="nofollow">3.3、Detections</a></li><li><a href="#34Classify_906" rel="nofollow">3.4、Classify</a></li></ul> 
  </li><li><a href="#_937" rel="nofollow">总结</a></li><li><a href="#Reference_947" rel="nofollow">Reference</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>前言</h2> 
<p>源码： <a href="https://github.com/ultralytics/yolov5">YOLOv5源码</a>.<br> 导航: <a href="https://blog.csdn.net/qq_38253797/article/details/119043919">【YOLOV5-5.x 源码讲解】整体项目文件导航</a>.<br> 注释版全部项目文件已上传至GitHub: <a href="https://github.com/SCAU-HuKai/yolov5-5.x-annotations">yolov5-5.x-annotations</a>.</p> 
<p>这个模块存放着yolov5网络搭建常见Common模块。</p> 
<p>yolov5s网络结构图：<br> <img src="https://images2.imgbox.com/7e/9f/62w8QCsw_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="0_13"></a>0、导入需要的包和基本配置</h2> 
<pre><code class="prism language-py"><span class="token keyword">import</span> math                <span class="token comment"># 数学函数模块</span>
<span class="token keyword">from</span> copy <span class="token keyword">import</span> copy      <span class="token comment"># 数据拷贝模块 分浅拷贝和深拷贝</span>
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path   <span class="token comment"># Path将str转换为Path对象 使字符串路径易于操作的模块</span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np         <span class="token comment"># numpy数组操作模块</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd        <span class="token comment"># panda数组操作模块</span>
<span class="token keyword">import</span> requests            <span class="token comment"># Python的HTTP客户端库</span>
<span class="token keyword">import</span> torch               <span class="token comment"># pytorch深度学习框架</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn      <span class="token comment"># 专门为神经网络设计的模块化接口</span>
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image      <span class="token comment"># 图像基础操作模块</span>
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>cuda <span class="token keyword">import</span> amp <span class="token comment"># 混合精度训练模块</span>

<span class="token keyword">from</span> utils<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> letterbox
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>general <span class="token keyword">import</span> non_max_suppression<span class="token punctuation">,</span> make_divisible<span class="token punctuation">,</span> scale_coords<span class="token punctuation">,</span> increment_path<span class="token punctuation">,</span> xyxy2xywh<span class="token punctuation">,</span> save_one_box
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>plots <span class="token keyword">import</span> colors<span class="token punctuation">,</span> plot_one_box
<span class="token keyword">from</span> utils<span class="token punctuation">.</span>torch_utils <span class="token keyword">import</span> time_synchronized
</code></pre> 
<h2><a id="1_34"></a>1、基本组件</h2> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>从上面的yolov5s的结构图可以看出，下面的这些组件就是组成yolov5s的一些基本组件。</p> 
<h3><a id="11autopad_37"></a>1.1、autopad</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块可以根据输入的卷积核计算该卷积模块所需的pad值。将会用于下面会讲到的Conv函数和Classify函数中。</p> 
<p>autopad模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">def</span> <span class="token function">autopad</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""用于Conv函数和Classify函数中
    根据卷积核大小k自动计算卷积核padding数（0填充） 
    v5中只有两种卷积：
       1、下采样卷积:conv3x3 s=2 p=k//2=1 
       2、feature size不变的卷积:conv1x1 s=1 p=k//2=1
    :params k: 卷积核的kernel_size
    :return p: 自动计算的需要pad值（0填充）
    """</span>
    <span class="token keyword">if</span> p <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        p <span class="token operator">=</span> k <span class="token operator">//</span> <span class="token number">2</span> <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">[</span>x <span class="token operator">//</span> <span class="token number">2</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> k<span class="token punctuation">]</span>  <span class="token comment"># 自动计算pad数</span>
    <span class="token keyword">return</span> p
</code></pre> 
<h3><a id="12Conv_57"></a>1.2、Conv</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个函数是整个网络中最基础的组件，由卷积层 + BN层 + 激活函数 组成，具体结构如下图：</p> 
<p><img src="https://images2.imgbox.com/23/54/hhdNdgdi_o.png" alt="在这里插入图片描述"><br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>既然是基础的组件，那么肯定会在很多的模块中被调用，如Focus、Bottleneck、BottleneckCSP、C3、SPP、DWConv、TransformerBlock等。</p> 
<p>Conv模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Conv</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在Focus、Bottleneck、BottleneckCSP、C3、SPP、DWConv、TransformerBloc等模块中调用
        Standard convolution  conv+BN+act
        :params c1: 输入的channel值
        :params c2: 输出的channel值
        :params k: 卷积的kernel_size
        :params s: 卷积的stride
        :params p: 卷积的padding  一般是None  可以通过autopad自行计算需要pad的padding数
        :params g: 卷积的groups数  =1就是普通的卷积  &gt;1就是深度可分离卷积
        :params act: 激活函数类型   True就是SiLU()/Swish   False就是不使用激活函数
                     类型是nn.Module就使用传进来的激活函数类型
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Conv<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token punctuation">,</span> s<span class="token punctuation">,</span> autopad<span class="token punctuation">(</span>k<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>g<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># conv</span>
        self<span class="token punctuation">.</span>bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>c2<span class="token punctuation">)</span>  <span class="token comment"># bn</span>
        self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>SiLU<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">if</span> act <span class="token keyword">is</span> <span class="token boolean">True</span> <span class="token keyword">else</span> <span class="token punctuation">(</span>act <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>act<span class="token punctuation">,</span> nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span> <span class="token keyword">else</span> nn<span class="token punctuation">.</span>Identity<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># activation</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">fuseforward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""用于Model类的fuse函数
        融合conv+bn 加速推理 一般用于测试/验证阶段
        """</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>另外这个类中还有一个特殊函数 fuseforward ，这是一个前向加速推理模块，在前向传播过程中，通过融合conv + bn层，达到加速推理的作用，一般用于测试或验证阶段。</p> 
<h3><a id="13Focus_94"></a>1.3、Focus</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是yolov5作者自己设计的一个模块，用在了模型的一开始，将输入图像先 slice 成4份，再做concat。结构如下所示：<br> <img src="https://images2.imgbox.com/2c/eb/NCyWmWr0_o.png" alt="在这里插入图片描述"><br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>设计思路：理论上从高分辨率图像中，周期性的抽出像素点重构到低分辨率图像中，即将图像相邻的四个位置进行堆叠，聚焦wh维度信息到c通道空，提高每个点感受野，并减少原始信息的丢失。这个组件并不是为了增加网络的精度的，而是为了减少计算量，增加速度。</p> 
<p>Focus模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Focus</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> act<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在yolo.py的parse_model函数中被调用
        理论：从高分辨率图像中，周期性的抽出像素点重构到低分辨率图像中，即将图像相邻的四个位置进行堆叠，
            聚焦wh维度信息到c通道空，提高每个点感受野，并减少原始信息的丢失，该模块的设计主要是减少计算量加快速度。
        Focus wh information into c-space 把宽度w和高度h的信息整合到c空间中
        先做4个slice 再concat 最后再做Conv
        slice后 (b,c1,w,h) -&gt; 分成4个slice 每个slice(b,c1,w/2,h/2)
        concat(dim=1)后 4个slice(b,c1,w/2,h/2)) -&gt; (b,4c1,w/2,h/2)
        conv后 (b,4c1,w/2,h/2) -&gt; (b,c2,w/2,h/2)
        :params c1: slice后的channel
        :params c2: Focus最终输出的channel
        :params k: 最后卷积的kernel
        :params s: 最后卷积的stride
        :params p: 最后卷积的padding
        :params g: 最后卷积的分组情况  =1普通卷积  &gt;1深度可分离卷积
        :params act: bool激活函数类型  默认True:SiLU()/Swish  False:不用激活函数
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Focus<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1 <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token punctuation">,</span> s<span class="token punctuation">,</span> p<span class="token punctuation">,</span> g<span class="token punctuation">,</span> act<span class="token punctuation">)</span>  <span class="token comment"># concat后的卷积（最后的卷积）</span>
        <span class="token comment"># self.contract = Contract(gain=2)  # 也可以调用Contract函数实现slice操作</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token comment"># x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)  有点像做了个下采样</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> x<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># return self.conv(self.contract(x))</span>
</code></pre> 
<h3><a id="14Bottleneck_131"></a>1.4、Bottleneck</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模式是一个标准的 bottleneck 模块，非常简单，就是由一些 1x1conv、3x3conv、残差块组成，具体的结构如下所示：<br> <img src="https://images2.imgbox.com/69/48/fKYWXE0P_o.png" alt="在这里插入图片描述"></p> 
<p>Bottleneck模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Bottleneck</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在BottleneckCSP和yolo.py的parse_model中调用
        Standard bottleneck  Conv+Conv+shortcut
        :params c1: 第一个卷积的输入channel
        :params c2: 第二个卷积的输出channel
        :params shortcut: bool 是否有shortcut连接 默认是True
        :params g: 卷积分组的个数  =1就是普通卷积  &gt;1就是深度可分离卷积
        :params e: expansion ratio  e*c2就是第一个卷积的输出channel=第二个卷积的输入channel
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Bottleneck<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>                    <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>       <span class="token comment"># 1x1</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> g<span class="token operator">=</span>g<span class="token punctuation">)</span>  <span class="token comment"># 3x3</span>
        self<span class="token punctuation">.</span>add <span class="token operator">=</span> shortcut <span class="token keyword">and</span> c1 <span class="token operator">==</span> c2    <span class="token comment"># shortcut=True and c1 == c2 才能做shortcut</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> x <span class="token operator">+</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>add <span class="token keyword">else</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="15BottleneckCSP_157"></a>1.5、BottleneckCSP</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是由Bottleneck模块和CSP结构组成。CSP结构来源于2019年发表的一篇论文：<a href="https://arxiv.org/abs/1911.11929" rel="nofollow">CSPNet: A New Backbone that can Enhance Learning Capability of CNN</a>.如果不是很清楚这个结构或者想了解这篇论文的，可以看看我的另一篇博客：<a href="https://blog.csdn.net/qq_38253797/article/details/117157473">【论文复现】CSPNet（2019）</a>.</p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块和上面yolov5s中的C3模块等效，如果要用的话直接在yolov5s.yaml文件中讲C3改成BottleneckCSP即可，但是一般来说不用改，因为C3更好。</p> 
<p>BottleneckCSP模块具体的结构如下所示：<br> <img src="https://images2.imgbox.com/f6/e0/xSX1QPMb_o.png" alt="在这里插入图片描述"></p> 
<p>BottleneckCSP模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">BottleneckCSP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在C3模块和yolo.py的parse_model模块调用
        CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
        :params c1: 整个BottleneckCSP的输入channel
        :params c2: 整个BottleneckCSP的输出channel
        :params n: 有n个Bottleneck
        :params shortcut: bool Bottleneck中是否有shortcut，默认True
        :params g: Bottleneck中的3x3卷积类型  =1普通卷积  &gt;1深度可分离卷积
        :params e: expansion ratio c2xe=中间其他所有层的卷积核个数/中间所有层的输入输出channel数
        """</span>
        <span class="token comment"># ch_in, ch_out, number, shortcut, groups, expansion</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>BottleneckCSP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv4 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> c_<span class="token punctuation">)</span>  <span class="token comment"># applied to cat(cv2, cv3)  2*c_</span>
        self<span class="token punctuation">.</span>act <span class="token operator">=</span> nn<span class="token punctuation">.</span>LeakyReLU<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        <span class="token comment"># 叠加n次Bottleneck</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>Bottleneck<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> shortcut<span class="token punctuation">,</span> g<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        y1 <span class="token operator">=</span> self<span class="token punctuation">.</span>cv3<span class="token punctuation">(</span>self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y2 <span class="token operator">=</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv4<span class="token punctuation">(</span>self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>self<span class="token punctuation">.</span>bn<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>y1<span class="token punctuation">,</span> y2<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="16C3_197"></a>1.6、C3</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是一种简化版的BottleneckCSP，因为除了Bottleneck部分只有3个卷积，可以减少参数，所以取名C3。而作者之所以用C3来带代替BottleneckCSP也是有原因的，作者原话：</p> 
<blockquote> 
 <p>C3() is an improved version of CSPBottleneck(). It is simpler, faster and and lighter with similar performance and better fuse characteristics.</p> 
</blockquote> 
<p>C3模块具体的结构如下所示：<br> <img src="https://images2.imgbox.com/d1/e3/Tc481MUy_o.png" alt="在这里插入图片描述"></p> 
<p>C3模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">C3</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在C3TR模块和yolo.py的parse_model模块调用
        CSP Bottleneck with 3 convolutions
        :params c1: 整个BottleneckCSP的输入channel
        :params c2: 整个BottleneckCSP的输出channel
        :params n: 有n个Bottleneck
        :params shortcut: bool Bottleneck中是否有shortcut，默认True
        :params g: Bottleneck中的3x3卷积类型  =1普通卷积  &gt;1深度可分离卷积
        :params e: expansion ratio c2xe=中间其他所有层的卷积核个数/中间所有层的输入输出channel数
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>C3<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cv3 <span class="token operator">=</span> Conv<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> c_<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># act=FReLU(c2)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>Bottleneck<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> shortcut<span class="token punctuation">,</span> g<span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 实验性 CrossConv</span>
        <span class="token comment"># self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv3<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>m<span class="token punctuation">(</span>self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="17SPP_230"></a>1.7、SPP</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块的主要目的是为了将更多不同分辨率的特征进行融合，得到更多的信息。</p> 
<p>SPP模块具体的结构如下所示：<br> <img src="https://images2.imgbox.com/89/bc/M3YwqbTl_o.png" alt="在这里插入图片描述"></p> 
<p>SPP模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">SPP</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在yolo.py的parse_model模块调用
        空间金字塔池化 Spatial pyramid pooling layer used in YOLOv3-SPP
        :params c1: SPP模块的输入channel
        :params c2: SPP模块的输出channel
        :params k: 保存着三个maxpool的卷积核大小 默认是(5, 9, 13)
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SPP<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> c1 <span class="token operator">//</span> <span class="token number">2</span>  <span class="token comment"># hidden channels</span>
        self<span class="token punctuation">.</span>cv1 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 第一层卷积</span>
        self<span class="token punctuation">.</span>cv2 <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c_ <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> c2<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 最后一层卷积  +1是因为有len(k)+1个输入</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">[</span>nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span>x<span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span>x <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> k<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>cv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>cv2<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span>m<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> m <span class="token keyword">in</span> self<span class="token punctuation">.</span>m<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h3><a id="18Concat_257"></a>1.8、Concat</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个函数是讲自身（a list of tensors）按照某个维度进行concat，常用来合并前后两个feature map，也就是上面yolov5s结构图中的Concat。</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Concat</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dimension<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""在yolo.py的parse_model模块调用
        Concatenate a list of tensors along dimension
        :params dimension: 沿着哪个维度进行concat
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Concat<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>d <span class="token operator">=</span> dimension

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># x: a list of tensors</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>x<span class="token punctuation">,</span> self<span class="token punctuation">.</span>d<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="19ContractExpand_276"></a>1.9、Contract、Expand</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这两个函数是用于改变feature map的维度，并不是很常用。Contract函数改变输入特征的shape，将feature map的w和h维度(缩小)的数据收缩到channel维度上(放大)。如：x(1,64,80,80) to x(1,256,40,40)。Expand函数也是改变输入特征的shape，不过与Contract的相反， 是将channel维度(变小)的数据扩展到W和H维度(变大)。如：x(1,64,80,80) to x(1,16,160,160)。</p> 
<p>代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Contract</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""用在yolo.py的parse_model模块 用的不多
    改变输入特征的shape 将w和h维度(缩小)的数据收缩到channel维度上(放大)
    Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> gain<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gain <span class="token operator">=</span> gain

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 1 64 80 80</span>
        s <span class="token operator">=</span> self<span class="token punctuation">.</span>gain  <span class="token comment"># 2</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H <span class="token operator">//</span> s<span class="token punctuation">,</span> s<span class="token punctuation">,</span> W <span class="token operator">//</span> s<span class="token punctuation">,</span> s<span class="token punctuation">)</span>  <span class="token comment"># x(1,64,40,2,40,2)</span>
        <span class="token comment"># permute: 改变tensor的维度顺序</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># x(1,2,2,64,40,40)</span>
        <span class="token comment"># .view: 改变tensor的维度</span>
        <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C <span class="token operator">*</span> s <span class="token operator">*</span> s<span class="token punctuation">,</span> H <span class="token operator">//</span> s<span class="token punctuation">,</span> W <span class="token operator">//</span> s<span class="token punctuation">)</span>  <span class="token comment"># x(1,256,40,40)</span>

<span class="token keyword">class</span> <span class="token class-name">Expand</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""用在yolo.py的parse_model模块  用的不多
    改变输入特征的shape 将channel维度(变小)的数据扩展到W和H维度(变大)
    Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> gain<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>gain <span class="token operator">=</span> gain

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 1 64 80 80</span>
        s <span class="token operator">=</span> self<span class="token punctuation">.</span>gain  <span class="token comment"># 2</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> s<span class="token punctuation">,</span> s<span class="token punctuation">,</span> C <span class="token operator">//</span> s <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span>  <span class="token comment"># x(1,2,2,16,80,80)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># x(1,16,80,2,80,2)</span>
        <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> C <span class="token operator">//</span> s <span class="token operator">**</span> <span class="token number">2</span><span class="token punctuation">,</span> H <span class="token operator">*</span> s<span class="token punctuation">,</span> W <span class="token operator">*</span> s<span class="token punctuation">)</span>  <span class="token comment"># x(1,16,160,160)</span>
</code></pre> 
<p>会用在yolo.py的parse_model模块（用的不多）：<br> <img src="https://images2.imgbox.com/50/c5/dN8KFRNB_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="2_320"></a>2、注意力模块</h2> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>注意力机制一直是比较火热的研究方向。注意力机制主要是告诉模型那里更重要，什么更重要，并赋予其一个更大权重，而那些不重要的区域就赋予一个较小的权重，让模型更关注于重要的区域；同时也会起到一个结合全局信息的作用。</p> 
<p>关于注意力机制使用的一些个人看法，不一定正确：</p> 
<ol><li>在上采样+concat之后接一个注意力机制可能会更好？</li><li>channel-wise比spatial-wise更好用？</li><li>backbone结尾使用一个注意力机制？</li><li>每个block（如residual block）结尾使用比每个Conv里使用更好？</li></ol> 
<p>这些只是我总结的一些注意力机制使用的常见模式，不一定适用全部的模型或者数据集，还是需要多多实验。</p> 
<h3><a id="21transformer_333"></a>2.1、transformer自注意力模块</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个部分是作者根据论文： <a href="https://arxiv.org/pdf/1706.03762.pdf" rel="nofollow">Attention is all you need</a> 和 <a href="https://arxiv.org/abs/2010.11929" rel="nofollow">（ViT）An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a>两篇论文中提出的Transformer自注意力机制，稍加改编而来的。</p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>关于transformer的论文我看的比较少，笔记都是记在ipad上，我是跟着 <a href="https://www.bilibili.com/video/BV1Di4y1c7Zm?p=5&amp;spm_id_from=pageDriver" rel="nofollow">Transformer从零详细解读(可能是你见过最通俗易懂的讲解)</a>. 和 <a href="https://www.bilibili.com/video/BV1v3411r78R?from=search&amp;seid=12070149695619006113" rel="nofollow">李宏毅老师视频</a>. 这两个视频入的门。后面再看论文和源码。不过学的还是比较浅，就不多说了，如果想进一步了解的可以按照这个路线进行学习。</p> 
<p>如下图是整个transformer的结构，我们这里代码部分只用了左边的Encoding部分：<br> <img src="https://images2.imgbox.com/b8/4a/6Z4uQYKN_o.png" alt="在这里插入图片描述"></p> 
<p>transformer自注意力模块代码：</p> 
<pre><code class="prism language-py"><span class="token comment"># transformer</span>
<span class="token keyword">class</span> <span class="token class-name">TransformerLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
     Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
     视频: https://www.bilibili.com/video/BV1Di4y1c7Zm?p=5&amp;spm_id_from=pageDriver
          https://www.bilibili.com/video/BV1v3411r78R?from=search&amp;seid=12070149695619006113
     这部分相当于原论文中的单个Encoder部分(只移除了两个Norm部分, 其他结构和原文中的Encoding一模一样)
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>q <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>k <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>v <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token comment"># 输入: query、key、value</span>
        <span class="token comment"># 输出: 0 attn_output 即通过self-attention之后，从每一个词语位置输出来的attention 和输入的query它们形状一样的</span>
        <span class="token comment">#      1 attn_output_weights 即attention weights 每一个单词和任意另一个单词之间都会产生一个weight</span>
        self<span class="token punctuation">.</span>ma <span class="token operator">=</span> nn<span class="token punctuation">.</span>MultiheadAttention<span class="token punctuation">(</span>embed_dim<span class="token operator">=</span>c<span class="token punctuation">,</span> num_heads<span class="token operator">=</span>num_heads<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c<span class="token punctuation">,</span> c<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 多头注意力机制 + 残差(这里移除了LayerNorm for better performance)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>ma<span class="token punctuation">(</span>self<span class="token punctuation">.</span>q<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>k<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>v<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> x
        <span class="token comment"># feed forward 前馈神经网络 + 残差(这里移除了LayerNorm for better performance)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> x
        <span class="token keyword">return</span> x
<span class="token keyword">class</span> <span class="token class-name">TransformerBlock</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Vision Transformer https://arxiv.org/abs/2010.11929
    视频: https://www.bilibili.com/video/BV1Di4y1c7Zm?p=5&amp;spm_id_from=pageDriver
         https://www.bilibili.com/video/BV1v3411r78R?from=search&amp;seid=12070149695619006113
    这部分相当于原论文中的Encoders部分 只替换了一些编码方式和最后Encoders出来数据处理方式
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> num_heads<span class="token punctuation">,</span> num_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> <span class="token boolean">None</span>
        <span class="token keyword">if</span> c1 <span class="token operator">!=</span> c2<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>conv <span class="token operator">=</span> Conv<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c2<span class="token punctuation">,</span> c2<span class="token punctuation">)</span>  <span class="token comment"># learnable position embedding 位置编码</span>
        self<span class="token punctuation">.</span>tr <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">[</span>TransformerLayer<span class="token punctuation">(</span>c2<span class="token punctuation">,</span> num_heads<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_layers<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># encoder * n</span>
        self<span class="token punctuation">.</span>c2 <span class="token operator">=</span> c2  <span class="token comment"># 输出channel</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>conv <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># embedding</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        b<span class="token punctuation">,</span> _<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h <span class="token operator">=</span> x<span class="token punctuation">.</span>shape
        p <span class="token operator">=</span> x<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        p <span class="token operator">=</span> p<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        p <span class="token operator">=</span> p<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
        p <span class="token operator">=</span> p<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
        e <span class="token operator">=</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>p<span class="token punctuation">)</span>         <span class="token comment"># positional encoding</span>
        x <span class="token operator">=</span> p <span class="token operator">+</span> e                  <span class="token comment"># 残差</span>

        x <span class="token operator">=</span> self<span class="token punctuation">.</span>tr<span class="token punctuation">(</span>x<span class="token punctuation">)</span>             <span class="token comment"># encode * n</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>         <span class="token comment"># encoders结束 维度处理</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>b<span class="token punctuation">,</span> self<span class="token punctuation">.</span>c2<span class="token punctuation">,</span> w<span class="token punctuation">,</span> h<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
<span class="token keyword">class</span> <span class="token class-name">C3TR</span><span class="token punctuation">(</span>C3<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    这部分是根据上面的C3结构改编而来的, 将原先的Bottleneck替换为调用TransformerBlock模块 
    """</span>
    <span class="token comment"># C3 module with TransformerBlock()</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> shortcut<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> e<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> n<span class="token punctuation">,</span> shortcut<span class="token punctuation">,</span> g<span class="token punctuation">,</span> e<span class="token punctuation">)</span>
        c_ <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>c2 <span class="token operator">*</span> e<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>m <span class="token operator">=</span> TransformerBlock<span class="token punctuation">(</span>c_<span class="token punctuation">,</span> c_<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> n<span class="token punctuation">)</span>
</code></pre> 
<p>使用方式：<br> 1、修改yolov5s.yaml的backbone部分：</p> 
<pre><code class="prism language-py"><span class="token comment"># YOLOv5 backbone</span>
backbone<span class="token punctuation">:</span>
  <span class="token comment"># [from, number, module, args]</span>
  <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Focus<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 0-P1/2</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 1-P2/4</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 3-P3/8</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 5-P4/16</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 7-P5/32</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> SPP<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3TR<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 9  &lt;-------- C3TR() Transformer module</span>
  <span class="token punctuation">]</span>
</code></pre> 
<p>2、yolo.py中的parse_model函数调用C3TR函数：<br> <img src="https://images2.imgbox.com/9a/b9/qoOdfUf1_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22SE_441"></a>2.2、SE注意力模块</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是自己写的实验性模块，SELayer来自论文： <a href="https://arxiv.org/abs/1709.01507" rel="nofollow">Squeeze-and-Excitation Networks</a>。相关的理论请看：<a href="https://blog.csdn.net/qq_38253797/article/details/117329519">【论文复现】SENet（2019）</a>。<br> <img src="https://images2.imgbox.com/27/61/EEniKqWS_o.png" alt="在这里插入图片描述"><br> SELayer模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">SELayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># SE注意力机制模块</span>
    <span class="token comment"># https://arxiv.org/abs/1709.01507</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SELayer<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avgpool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c1 <span class="token operator">//</span> r<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>l2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>c1 <span class="token operator">//</span> r<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sig <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _ <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>avgpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> c<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>l1<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>l2<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>sig<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        y <span class="token operator">=</span> y<span class="token punctuation">.</span>view<span class="token punctuation">(</span>b<span class="token punctuation">,</span> c<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x <span class="token operator">*</span> y<span class="token punctuation">.</span>expand_as<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<p>如何添加注意力机制？这里提供其中一个改动方法，大家也可以尝试自己的方法，效果可能都不同。</p> 
<pre><code class="prism language-py"><span class="token comment"># YOLOv5 backbone</span>
backbone<span class="token punctuation">:</span>
  <span class="token comment"># [from, number, module, args]</span>
  <span class="token punctuation">[</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Focus<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># 0-P1/2                 #1</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># 1-P2/4              #2</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment">#3</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># 3-P3/8              #4</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment">#5</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># 5-P4/16             #6</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment">#7</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># 7-P5/32            #8</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> SPP<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment">#9</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment"># 9                   #10</span>
    <span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> SELayer<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment">#10</span>
  <span class="token punctuation">]</span>
</code></pre> 
<p>yolo.py:<br> <img src="https://images2.imgbox.com/52/69/HPXfk09p_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="23CBAM_492"></a>2.3、CBAM注意力模块</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是自己写的实验性模块，CBAM来自论文： <a href="https://arxiv.org/abs/1807.06521" rel="nofollow">CBAM</a>。相关的理论请看：<a href="https://blog.csdn.net/qq_38253797/article/details/117292848">【论文复现】CBAM（2018）</a>。</p> 
<p>通道注意力模块（CAM）:<br> <img src="https://images2.imgbox.com/40/28/THLnWqDc_o.png" alt="在这里插入图片描述"><br> 空间注意力模块（SAM）:<br> <img src="https://images2.imgbox.com/b5/fb/pUCh6euB_o.png" alt="在这里插入图片描述"><br> CBAM：<br> <img src="https://images2.imgbox.com/e0/57/zXQuaMiR_o.png" alt="在这里插入图片描述"></p> 
<p>CBAM模块所有代码:</p> 
<pre><code class="prism language-py"><span class="token comment"># CBAM</span>
<span class="token keyword">class</span> <span class="token class-name">CBAM</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span>c2<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CBAM<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>channel_attention <span class="token operator">=</span> ChannelAttention<span class="token punctuation">(</span>c1<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>spatial_attention <span class="token operator">=</span> SpatialAttention<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>channel_attention<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">*</span> x
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>spatial_attention<span class="token punctuation">(</span>out<span class="token punctuation">)</span> <span class="token operator">*</span> out
        <span class="token keyword">return</span> out
<span class="token keyword">class</span> <span class="token class-name">ChannelAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> ratio<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        :params: in_planes 输入模块的feature map的channel
        :params: ratio 降维/升维因子
        通道注意力则是将一个通道内的信息直接进行全局处理，容易忽略通道内的信息交互
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>ChannelAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>avg_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 平均池化，是取整个channel所有元素的均值 [3,5,5] =&gt; [3,1,1]</span>
        self<span class="token punctuation">.</span>max_pool <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveMaxPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># 最大池化，是取整个channel所有元素的最大值[3,5,5] =&gt; [3,1,1]</span>

        <span class="token comment"># shared MLP</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes<span class="token punctuation">,</span> in_planes <span class="token operator">//</span> ratio<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>in_planes <span class="token operator">//</span> ratio<span class="token punctuation">,</span> in_planes<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        avg_out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        max_out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>self<span class="token punctuation">.</span>relu1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>self<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        out <span class="token operator">=</span> avg_out <span class="token operator">+</span> max_out
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>out<span class="token punctuation">)</span>
<span class="token keyword">class</span> <span class="token class-name">SpatialAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""对空间注意力来说，由于将每个通道中的特征都做同等处理，容易忽略通道间的信息交互"""</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>SpatialAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 这里要保持卷积后的feature尺度不变，必须要padding=kernel_size//2</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> kernel_size<span class="token punctuation">,</span> padding<span class="token operator">=</span>kernel_size <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>sigmoid <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>                               <span class="token comment"># 输入x = [b, c, 56, 56]</span>
        avg_out <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment"># avg_out = [b, 1, 56, 56]  求x的每个像素在所有channel相同位置上的平均值</span>
        max_out<span class="token punctuation">,</span> _ <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># max_out = [b, 1, 56, 56]  求x的每个像素在所有channel相同位置上的最大值</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>avg_out<span class="token punctuation">,</span> max_out<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token comment"># x = [b, 2, 56, 56]  concat操作</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>                               <span class="token comment"># x = [b, 1, 56, 56]  卷积操作，融合avg和max的信息，全方面考虑</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<p>如何添加注意力机制？这里提供其中一个改动方法，大家也可以尝试自己的方法，效果可能都不同。</p> 
<p>yolov5s-cbam.yaml</p> 
<pre><code class="prism language-yaml"><span class="token comment"># parameters</span>
<span class="token key atrule">nc</span><span class="token punctuation">:</span> <span class="token number">80</span>  <span class="token comment"># number of classes</span>
<span class="token key atrule">depth_multiple</span><span class="token punctuation">:</span> <span class="token number">0.33</span>  <span class="token comment"># model depth multiple</span>
<span class="token key atrule">width_multiple</span><span class="token punctuation">:</span> <span class="token number">0.50</span>  <span class="token comment"># layer channel multiple</span>

<span class="token comment"># anchors</span>
<span class="token key atrule">anchors</span><span class="token punctuation">:</span>
  <span class="token comment">#- [5,6, 7,9, 12,10]      # P2/4</span>
  <span class="token punctuation">-</span> <span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span><span class="token number">30</span><span class="token punctuation">,</span> <span class="token number">33</span><span class="token punctuation">,</span><span class="token number">23</span><span class="token punctuation">]</span>  <span class="token comment"># P3/8</span>
  <span class="token punctuation">-</span> <span class="token punctuation">[</span><span class="token number">30</span><span class="token punctuation">,</span><span class="token number">61</span><span class="token punctuation">,</span> <span class="token number">62</span><span class="token punctuation">,</span><span class="token number">45</span><span class="token punctuation">,</span> <span class="token number">59</span><span class="token punctuation">,</span><span class="token number">119</span><span class="token punctuation">]</span>  <span class="token comment"># P4/16</span>
  <span class="token punctuation">-</span> <span class="token punctuation">[</span><span class="token number">116</span><span class="token punctuation">,</span><span class="token number">90</span><span class="token punctuation">,</span> <span class="token number">156</span><span class="token punctuation">,</span><span class="token number">198</span><span class="token punctuation">,</span> <span class="token number">373</span><span class="token punctuation">,</span><span class="token number">326</span><span class="token punctuation">]</span>  <span class="token comment"># P5/32</span>

<span class="token comment"># YOLOv5 backbone</span>
<span class="token key atrule">backbone</span><span class="token punctuation">:</span>
  <span class="token comment"># [from, number, module, args]               # [c=channels,module,kernlsize,strides]-  1代表来自上一层输出</span>
  <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Focus<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 0-P1/2           [c=3,64*0.5=32,3]  举例，输出通道数*width_multiple:=64*0.5</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 1-P2/4</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                   <span class="token comment"># 举例，3*width_multiple:=3*0.33=1</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 3-P3/8</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 5-P4/16</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 7-P5/32</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> SPP<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">,</span> <span class="token number">13</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 9</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token comment">#13</span>

  <span class="token punctuation">]</span>

<span class="token comment"># YOLOv5 head</span>
<span class="token key atrule">head</span><span class="token punctuation">:</span>
  <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> nn.Upsample<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'nearest'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Concat<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># cat backbone P4</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 13</span>

   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> nn.Upsample<span class="token punctuation">,</span> <span class="token punctuation">[</span>None<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token string">'nearest'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Concat<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># cat backbone P3</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 19 (P3/8-small)</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token comment">#[-1, 3, C3, [256]],</span>

   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">18</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Concat<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># cat head P4</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 23 (P4/16-medium)       [256, 256, 1, False]</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token comment">#[-1, 3, C3, [512]],</span>

   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Conv<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                           <span class="token comment">#[256, 256, 3, 2]</span>
   <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">14</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Concat<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># cat head P5</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> C3<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token boolean important">False</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># 27 (P5/32-large)       [512, 512, 1, False]</span>
   <span class="token punctuation">[</span><span class="token number">-1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> CBAM<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1024</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
   <span class="token comment">#[-1, 3, C3, [1024]],</span>

   <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">22</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> ASFF_Detect<span class="token punctuation">,</span> <span class="token punctuation">[</span>nc<span class="token punctuation">,</span> anchors<span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token boolean important">True</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>  <span class="token comment"># ASFF_Detect(P3, P4, P5,mult,rfb)</span>
  <span class="token punctuation">]</span>


</code></pre> 
<p>yolo.py:<br> <img src="https://images2.imgbox.com/0a/b1/bDv0Ys71_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="24CA_623"></a>2.4、CA注意力模块</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>CA（Coordinate Attention）协同注意力机制。来自于CVPR2021的一份最新论文中： <a href="https://arxiv.org/abs/2103.02907" rel="nofollow">https://arxiv.org/abs/2103.02907</a>. 论文源码： <a href="https://github.com/Andrew-Qibin/CoordAttention/blob/main/coordatt.py">https://github.com/Andrew-Qibin/CoordAttention/blob/main/coordatt.py</a>.</p> 
<p>如下图（左边SE，中间CBAM，右边CA）：<br> <img src="https://images2.imgbox.com/40/4a/1s2hkDgc_o.png" alt="在这里插入图片描述"></p> 
<p>CA注意力代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">CoorAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    CA Coordinate Attention 协同注意力机制
    论文 CVPR2021: https://arxiv.org/abs/2103.02907
    源码: https://github.com/Andrew-Qibin/CoordAttention/blob/main/coordatt.py
    CA注意力机制是一个Spatial Attention 相比于SAM的7x7卷积, CA建立了远程依赖
    可以考虑把SE + CA合起来用试试？
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inp<span class="token punctuation">,</span> oup<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CoorAttention<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># [B, C, H, W] -&gt; [B, C, H, 1]</span>
        self<span class="token punctuation">.</span>pool_h <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># [B, C, H, W] -&gt; [B, C, 1, W]</span>
        self<span class="token punctuation">.</span>pool_w <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        mip <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> inp <span class="token operator">//</span> reduction<span class="token punctuation">)</span>   <span class="token comment"># 对中间层channel做一个限制 不得少于8</span>

        <span class="token comment"># 将x轴信息和y轴信息融合在一起</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>inp<span class="token punctuation">,</span> mip<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bn1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span>mip<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>act <span class="token operator">=</span> Hardswish<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 这里自己可以实验什么激活函数最佳 论文里是hard-swish</span>

        self<span class="token punctuation">.</span>conv_h <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>mip<span class="token punctuation">,</span> oup<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv_w <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>mip<span class="token punctuation">,</span> oup<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        identity <span class="token operator">=</span> x

        n<span class="token punctuation">,</span> c<span class="token punctuation">,</span> h<span class="token punctuation">,</span> w <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># [B, C, H, W] -&gt; [B, C, H, 1]</span>
        x_h <span class="token operator">=</span> self<span class="token punctuation">.</span>pool_h<span class="token punctuation">(</span>x<span class="token punctuation">)</span>   <span class="token comment"># h avg pool</span>
        <span class="token comment"># [B, C, H, W] -&gt; [B, C, 1, W] -&gt; [B, C, W, 1]</span>
        x_w <span class="token operator">=</span> self<span class="token punctuation">.</span>pool_w<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># w avg pool</span>

        y <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>x_h<span class="token punctuation">,</span> x_w<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment"># [B, C, H+W, 1]</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>bn1<span class="token punctuation">(</span>y<span class="token punctuation">)</span>
        y <span class="token operator">=</span> self<span class="token punctuation">.</span>act<span class="token punctuation">(</span>y<span class="token punctuation">)</span>

        <span class="token comment"># split  x_h: [B, C, H, 1]  x_w: [B, C, W, 1]</span>
        x_h<span class="token punctuation">,</span> x_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>split<span class="token punctuation">(</span>y<span class="token punctuation">,</span> <span class="token punctuation">[</span>h<span class="token punctuation">,</span> w<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token comment"># [B, C, W, 1] -&gt; [B, C, 1, W]</span>
        x_w <span class="token operator">=</span> x_w<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

        a_h <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_h<span class="token punctuation">(</span>x_h<span class="token punctuation">)</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
        a_w <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_w<span class="token punctuation">(</span>x_w<span class="token punctuation">)</span><span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># 基于W和H方向做注意力机制 建立远程依赖关系</span>
        out <span class="token operator">=</span> identity <span class="token operator">*</span> a_w <span class="token operator">*</span> a_h

        <span class="token keyword">return</span> out
</code></pre> 
<p>整个模块没做过什么实验，有条件的朋友可以做做消融实验，不同位置或者SE+CA结合等等。</p> 
<h2><a id="3_689"></a>3、模型扩展模块</h2> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>下面的几个函数都是属于模型的扩展模块。yolov5的作者将搭建模型的函数功能写的很齐全。不光包含搭建模型部分，还考虑到了各个方面其他的功能，比如给模型搭载nms功能、给模型封装成包含前处理、推理、后处理的模块(预处理 + 推理 + nms)、二次分类等等功能。如下图（功能齐全）：<img src="https://images2.imgbox.com/e0/71/z9SFWtKO_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="31NMS_694"></a>3.1、NMS</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是给模型搭载nms功能，直接调用的general.py文件的non_max_suppression函数，但是我们一般不会用， 一般是在前向推理结束后再调用non_max_suppression函数。</p> 
<p>NMS模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">NMS</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""在yolo.py中Model类的nms函数中使用
    NMS非极大值抑制 Non-Maximum Suppression (NMS) module
    给模型model封装nms  增加模型的扩展功能  但是我们一般不用 一般是在前向推理结束后再调用non_max_suppression函数
    """</span>
    conf <span class="token operator">=</span> <span class="token number">0.25</span>     <span class="token comment"># 置信度阈值              confidence threshold</span>
    iou <span class="token operator">=</span> <span class="token number">0.45</span>      <span class="token comment"># iou阈值                IoU threshold</span>
    classes <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 是否nms后只保留特定的类别 (optional list) filter by class</span>
    max_det <span class="token operator">=</span> <span class="token number">1000</span>  <span class="token comment"># 每张图片的最大目标个数    maximum number of detections per image</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>NMS<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        :params x[0]: [batch, num_anchors(3个yolo预测层), (x+y+w+h+1+num_classes)]
        直接调用的是general.py中的non_max_suppression函数给model扩展nms功能
        """</span>
        <span class="token keyword">return</span> non_max_suppression<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>conf<span class="token punctuation">,</span> iou_thres<span class="token operator">=</span>self<span class="token punctuation">.</span>iou<span class="token punctuation">,</span> classes<span class="token operator">=</span>self<span class="token punctuation">.</span>classes<span class="token punctuation">,</span> max_det<span class="token operator">=</span>self<span class="token punctuation">.</span>max_det<span class="token punctuation">)</span>
</code></pre> 
<p>在yolo.py中Model类的nms函数中调用：<br> <img src="https://images2.imgbox.com/c0/9f/QXBvN8uU_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="32AutoShape_722"></a>3.2、AutoShape</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这个模块是一个模型扩展模块，给模型封装成包含前处理、推理、后处理的模块(预处理 + 推理 + nms)，用的不多。</p> 
<p>AutoShape模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">AutoShape</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""在yolo.py中Model类的autoshape函数中使用
    将model封装成包含前处理、推理、后处理的模块(预处理 + 推理 + nms)  也是一个扩展模型功能的模块
    autoshape模块在train中不会被调用，当模型训练结束后，会通过这个模块对图片进行重塑，来方便模型的预测
    自动调整shape，我们输入的图像可能不一样，可能来自cv2/np/PIL/torch 对输入进行预处理 调整其shape，
    调整shape在datasets.py文件中,这个实在预测阶段使用的,model.eval(),模型就已经无法训练进入预测模式了
    input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    """</span>
    conf <span class="token operator">=</span> <span class="token number">0.25</span>     <span class="token comment"># 置信度阈值 NMS confidence threshold</span>
    iou <span class="token operator">=</span> <span class="token number">0.45</span>      <span class="token comment"># NMS IoU threshold</span>
    classes <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 是否nms后只保留特定的类别 (optional list) filter by class</span>
    max_det <span class="token operator">=</span> <span class="token number">1000</span>  <span class="token comment"># maximum number of detections per image</span>

    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> model<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>AutoShape<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 开启验证模式</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">autoshape</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'AutoShape already enabled, skipping... '</span><span class="token punctuation">)</span>  <span class="token comment"># model already converted to model.autoshape()</span>
        <span class="token keyword">return</span> self

    <span class="token decorator annotation punctuation">@torch<span class="token punctuation">.</span>no_grad</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">640</span><span class="token punctuation">,</span> augment<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> profile<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 这里的imgs针对不同的方法读入，官方也给了具体的方法，size是图片的尺寸，就比如最上面图片里面的输入608*608*3</span>
        <span class="token comment"># Inference from various sources. For height=640, width=1280, RGB images example inputs are:</span>
        <span class="token comment">#   filename:   imgs = 'data/images/zidane.jpg'</span>
        <span class="token comment">#   URI:             = 'https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg'</span>
        <span class="token comment">#   OpenCV:          = cv2.imread('image.jpg')[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)</span>
        <span class="token comment">#   PIL:             = Image.open('image.jpg')  # HWC x(640,1280,3)</span>
        <span class="token comment">#   numpy:           = np.zeros((640,1280,3))  # HWC</span>
        <span class="token comment">#   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)</span>
        <span class="token comment">#   multiple:        = [Image.open('image1.jpg'), Image.open('image2.jpg'), ...]  # list of images</span>
        t <span class="token operator">=</span> <span class="token punctuation">[</span>time_synchronized<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
        p <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># for device and type</span>

        <span class="token comment"># 图片如果是tensor格式 说明是预处理过的, 直接正常进行前向推理即可 nms在推理结束进行(函数外写)</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>Tensor<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># torch</span>
            <span class="token keyword">with</span> amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span>enabled<span class="token operator">=</span>p<span class="token punctuation">.</span>device<span class="token punctuation">.</span><span class="token builtin">type</span> <span class="token operator">!=</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">return</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>p<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>type_as<span class="token punctuation">(</span>p<span class="token punctuation">)</span><span class="token punctuation">,</span> augment<span class="token punctuation">,</span> profile<span class="token punctuation">)</span>  <span class="token comment"># inference</span>

        <span class="token comment"># 图片不是tensor格式 就先对图片进行预处理  Pre-process</span>
        n<span class="token punctuation">,</span> imgs <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">,</span> imgs<span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>imgs<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># number of images, list of images</span>
        shape0<span class="token punctuation">,</span> shape1<span class="token punctuation">,</span> files <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment"># image and inference shapes, filenames</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> im <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>imgs<span class="token punctuation">)</span><span class="token punctuation">:</span>
            f <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'image</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span>  <span class="token comment"># filename</span>
            <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>im<span class="token punctuation">,</span> <span class="token builtin">str</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># filename or uri</span>
                im<span class="token punctuation">,</span> f <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>im<span class="token punctuation">,</span> stream<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">.</span>raw <span class="token keyword">if</span> im<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'http'</span><span class="token punctuation">)</span> <span class="token keyword">else</span> im<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> im
            <span class="token keyword">elif</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>im<span class="token punctuation">,</span> Image<span class="token punctuation">.</span>Image<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># PIL Image</span>
                im<span class="token punctuation">,</span> f <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>im<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>im<span class="token punctuation">,</span> <span class="token string">'filename'</span><span class="token punctuation">,</span> f<span class="token punctuation">)</span> <span class="token keyword">or</span> f
            files<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Path<span class="token punctuation">(</span>f<span class="token punctuation">)</span><span class="token punctuation">.</span>with_suffix<span class="token punctuation">(</span><span class="token string">'.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>name<span class="token punctuation">)</span>
            <span class="token keyword">if</span> im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">:</span>  <span class="token comment"># image in CHW</span>
                im <span class="token operator">=</span> im<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># reverse dataloader .transpose(2, 0, 1)</span>
            im <span class="token operator">=</span> im<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">3</span><span class="token punctuation">]</span> <span class="token keyword">if</span> im<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">3</span> <span class="token keyword">else</span> np<span class="token punctuation">.</span>tile<span class="token punctuation">(</span>im<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment"># enforce 3ch input</span>
            s <span class="token operator">=</span> im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>  <span class="token comment"># HWC</span>
            shape0<span class="token punctuation">.</span>append<span class="token punctuation">(</span>s<span class="token punctuation">)</span>  <span class="token comment"># image shape</span>
            g <span class="token operator">=</span> <span class="token punctuation">(</span>size <span class="token operator">/</span> <span class="token builtin">max</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># gain</span>
            shape1<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>y <span class="token operator">*</span> g <span class="token keyword">for</span> y <span class="token keyword">in</span> s<span class="token punctuation">]</span><span class="token punctuation">)</span>
            imgs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> im <span class="token keyword">if</span> im<span class="token punctuation">.</span>data<span class="token punctuation">.</span>contiguous <span class="token keyword">else</span> np<span class="token punctuation">.</span>ascontiguousarray<span class="token punctuation">(</span>im<span class="token punctuation">)</span>  <span class="token comment"># update</span>
        shape1 <span class="token operator">=</span> <span class="token punctuation">[</span>make_divisible<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>stride<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>shape1<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># inference shape</span>
        x <span class="token operator">=</span> <span class="token punctuation">[</span>letterbox<span class="token punctuation">(</span>im<span class="token punctuation">,</span> new_shape<span class="token operator">=</span>shape1<span class="token punctuation">,</span> auto<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token keyword">for</span> im <span class="token keyword">in</span> imgs<span class="token punctuation">]</span>  <span class="token comment"># pad image</span>
        x <span class="token operator">=</span> np<span class="token punctuation">.</span>stack<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token keyword">if</span> n <span class="token operator">&gt;</span> <span class="token number">1</span> <span class="token keyword">else</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">]</span>  <span class="token comment"># stack image</span>
        x <span class="token operator">=</span> np<span class="token punctuation">.</span>ascontiguousarray<span class="token punctuation">(</span>x<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># BHWC to BCHW</span>
        x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>p<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">.</span>type_as<span class="token punctuation">(</span>p<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.</span>  <span class="token comment"># uint8 to fp16/32</span>
        t<span class="token punctuation">.</span>append<span class="token punctuation">(</span>time_synchronized<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">with</span> amp<span class="token punctuation">.</span>autocast<span class="token punctuation">(</span>enabled<span class="token operator">=</span>p<span class="token punctuation">.</span>device<span class="token punctuation">.</span><span class="token builtin">type</span> <span class="token operator">!=</span> <span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># 预处理结束再进行前向推理  Inference</span>
            y <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">,</span> augment<span class="token punctuation">,</span> profile<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># forward 前向推理</span>
            t<span class="token punctuation">.</span>append<span class="token punctuation">(</span>time_synchronized<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token comment"># 前向推理结束后 进行后处理Post-process  nms</span>
            y <span class="token operator">=</span> non_max_suppression<span class="token punctuation">(</span>y<span class="token punctuation">,</span> self<span class="token punctuation">.</span>conf<span class="token punctuation">,</span> iou_thres<span class="token operator">=</span>self<span class="token punctuation">.</span>iou<span class="token punctuation">,</span> classes<span class="token operator">=</span>self<span class="token punctuation">.</span>classes<span class="token punctuation">,</span> max_det<span class="token operator">=</span>self<span class="token punctuation">.</span>max_det<span class="token punctuation">)</span>  <span class="token comment"># NMS</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>
                scale_coords<span class="token punctuation">(</span>shape1<span class="token punctuation">,</span> y<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> shape0<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 将nms后的预测结果映射回原图尺寸</span>
            t<span class="token punctuation">.</span>append<span class="token punctuation">(</span>time_synchronized<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

            <span class="token keyword">return</span> Detections<span class="token punctuation">(</span>imgs<span class="token punctuation">,</span> y<span class="token punctuation">,</span> files<span class="token punctuation">,</span> t<span class="token punctuation">,</span> self<span class="token punctuation">.</span>names<span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p>在yolo.py中Model类的autoshape函数中使用：<br> <img src="https://images2.imgbox.com/8f/ff/BSLmZuaR_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="33Detections_810"></a>3.3、Detections</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>对推理结果进行一些处理，用的真的不多，整个yolov5只在上面的AutoShape函数结尾调用了一下，感兴趣的可以看看，偷下懒，我就不看了。</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Detections</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""用在AutoShape函数结尾
    detections class for YOLOv5 inference results
    """</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> imgs<span class="token punctuation">,</span> pred<span class="token punctuation">,</span> files<span class="token punctuation">,</span> times<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Detections<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        d <span class="token operator">=</span> pred<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>device  <span class="token comment"># device</span>
        gn <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token operator">*</span><span class="token punctuation">[</span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">,</span> <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">,</span> device<span class="token operator">=</span>d<span class="token punctuation">)</span> <span class="token keyword">for</span> im <span class="token keyword">in</span> imgs<span class="token punctuation">]</span>  <span class="token comment"># normalizations</span>
        self<span class="token punctuation">.</span>imgs <span class="token operator">=</span> imgs  <span class="token comment"># list of images as numpy arrays</span>
        self<span class="token punctuation">.</span>pred <span class="token operator">=</span> pred  <span class="token comment"># list of tensors pred[0] = (xyxy, conf, cls)</span>
        self<span class="token punctuation">.</span>names <span class="token operator">=</span> names  <span class="token comment"># class names</span>
        self<span class="token punctuation">.</span>files <span class="token operator">=</span> files  <span class="token comment"># image filenames</span>
        self<span class="token punctuation">.</span>xyxy <span class="token operator">=</span> pred  <span class="token comment"># xyxy pixels</span>
        self<span class="token punctuation">.</span>xywh <span class="token operator">=</span> <span class="token punctuation">[</span>xyxy2xywh<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> pred<span class="token punctuation">]</span>  <span class="token comment"># xywh pixels</span>
        self<span class="token punctuation">.</span>xyxyn <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token operator">/</span> g <span class="token keyword">for</span> x<span class="token punctuation">,</span> g <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>xyxy<span class="token punctuation">,</span> gn<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># xyxy normalized</span>
        self<span class="token punctuation">.</span>xywhn <span class="token operator">=</span> <span class="token punctuation">[</span>x <span class="token operator">/</span> g <span class="token keyword">for</span> x<span class="token punctuation">,</span> g <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>xywh<span class="token punctuation">,</span> gn<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># xywh normalized</span>
        self<span class="token punctuation">.</span>n <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>pred<span class="token punctuation">)</span>  <span class="token comment"># number of images (batch size)</span>
        self<span class="token punctuation">.</span>t <span class="token operator">=</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span><span class="token punctuation">(</span>times<span class="token punctuation">[</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">-</span> times<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1000</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>n <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># timestamps (ms)</span>
        self<span class="token punctuation">.</span>s <span class="token operator">=</span> shape  <span class="token comment"># inference BCHW shape</span>

    <span class="token keyword">def</span> <span class="token function">display</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> pprint<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> show<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> save<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> crop<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> render<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> save_dir<span class="token operator">=</span>Path<span class="token punctuation">(</span><span class="token string">''</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>im<span class="token punctuation">,</span> pred<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span><span class="token builtin">zip</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>imgs<span class="token punctuation">,</span> self<span class="token punctuation">.</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'image </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">}</span></span><span class="token string">/</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>pred<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string">x</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>im<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> '</span></span>
            <span class="token keyword">if</span> pred <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> c <span class="token keyword">in</span> pred<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    n <span class="token operator">=</span> <span class="token punctuation">(</span>pred<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> c<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># detections per class</span>
                    <span class="token builtin">str</span> <span class="token operator">+=</span> <span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>n<span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token string">'s'</span> <span class="token operator">*</span> <span class="token punctuation">(</span>n <span class="token operator">&gt;</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">, "</span></span>  <span class="token comment"># add to string</span>
                <span class="token keyword">if</span> show <span class="token keyword">or</span> save <span class="token keyword">or</span> render <span class="token keyword">or</span> crop<span class="token punctuation">:</span>
                    <span class="token keyword">for</span> <span class="token operator">*</span>box<span class="token punctuation">,</span> conf<span class="token punctuation">,</span> cls <span class="token keyword">in</span> pred<span class="token punctuation">:</span>  <span class="token comment"># xyxy, confidence, class</span>
                        label <span class="token operator">=</span> <span class="token string-interpolation"><span class="token string">f'</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>self<span class="token punctuation">.</span>names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>conf<span class="token punctuation">:</span><span class="token format-spec">.2f</span><span class="token punctuation">}</span></span><span class="token string">'</span></span>
                        <span class="token keyword">if</span> crop<span class="token punctuation">:</span>
                            save_one_box<span class="token punctuation">(</span>box<span class="token punctuation">,</span> im<span class="token punctuation">,</span> <span class="token builtin">file</span><span class="token operator">=</span>save_dir <span class="token operator">/</span> <span class="token string">'crops'</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">/</span> self<span class="token punctuation">.</span>files<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
                        <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># all others</span>
                            plot_one_box<span class="token punctuation">(</span>box<span class="token punctuation">,</span> im<span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">,</span> color<span class="token operator">=</span>colors<span class="token punctuation">(</span>cls<span class="token punctuation">)</span><span class="token punctuation">)</span>

            im <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>im<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>im<span class="token punctuation">,</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span> <span class="token keyword">else</span> im  <span class="token comment"># from np</span>
            <span class="token keyword">if</span> pprint<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">.</span>rstrip<span class="token punctuation">(</span><span class="token string">', '</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> show<span class="token punctuation">:</span>
                im<span class="token punctuation">.</span>show<span class="token punctuation">(</span>self<span class="token punctuation">.</span>files<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># show</span>
            <span class="token keyword">if</span> save<span class="token punctuation">:</span>
                f <span class="token operator">=</span> self<span class="token punctuation">.</span>files<span class="token punctuation">[</span>i<span class="token punctuation">]</span>
                im<span class="token punctuation">.</span>save<span class="token punctuation">(</span>save_dir <span class="token operator">/</span> f<span class="token punctuation">)</span>  <span class="token comment"># save</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token string">'Saved'</span> <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string"> </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>f<span class="token punctuation">}</span></span><span class="token string">"</span></span><span class="token punctuation">,</span> end<span class="token operator">=</span><span class="token string">','</span> <span class="token keyword">if</span> i <span class="token operator">&lt;</span> self<span class="token punctuation">.</span>n <span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string-interpolation"><span class="token string">f' to </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>save_dir<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> render<span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>imgs<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>asarray<span class="token punctuation">(</span>im<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">print</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>display<span class="token punctuation">(</span>pprint<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># print results</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span><span class="token builtin">tuple</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>s<span class="token punctuation">)</span><span class="token punctuation">}</span></span><span class="token string">'</span></span> <span class="token operator">%</span> self<span class="token punctuation">.</span>t<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">show</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>display<span class="token punctuation">(</span>show<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># show results</span>

    <span class="token keyword">def</span> <span class="token function">save</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> save_dir<span class="token operator">=</span><span class="token string">'runs/hub/exp'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        save_dir <span class="token operator">=</span> increment_path<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span>save_dir <span class="token operator">!=</span> <span class="token string">'runs/hub/exp'</span><span class="token punctuation">,</span> mkdir<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># increment save_dir</span>
        self<span class="token punctuation">.</span>display<span class="token punctuation">(</span>save<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> save_dir<span class="token operator">=</span>save_dir<span class="token punctuation">)</span>  <span class="token comment"># save results</span>

    <span class="token keyword">def</span> <span class="token function">crop</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> save_dir<span class="token operator">=</span><span class="token string">'runs/hub/exp'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        save_dir <span class="token operator">=</span> increment_path<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span>save_dir <span class="token operator">!=</span> <span class="token string">'runs/hub/exp'</span><span class="token punctuation">,</span> mkdir<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># increment save_dir</span>
        self<span class="token punctuation">.</span>display<span class="token punctuation">(</span>crop<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> save_dir<span class="token operator">=</span>save_dir<span class="token punctuation">)</span>  <span class="token comment"># crop results</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'Saved results to </span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>save_dir<span class="token punctuation">}</span></span><span class="token string">\n'</span></span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">render</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>display<span class="token punctuation">(</span>render<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># render results</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>imgs

    <span class="token keyword">def</span> <span class="token function">pandas</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])</span>
        new <span class="token operator">=</span> copy<span class="token punctuation">(</span>self<span class="token punctuation">)</span>  <span class="token comment"># return copy</span>
        ca <span class="token operator">=</span> <span class="token string">'xmin'</span><span class="token punctuation">,</span> <span class="token string">'ymin'</span><span class="token punctuation">,</span> <span class="token string">'xmax'</span><span class="token punctuation">,</span> <span class="token string">'ymax'</span><span class="token punctuation">,</span> <span class="token string">'confidence'</span><span class="token punctuation">,</span> <span class="token string">'class'</span><span class="token punctuation">,</span> <span class="token string">'name'</span>  <span class="token comment"># xyxy columns</span>
        cb <span class="token operator">=</span> <span class="token string">'xcenter'</span><span class="token punctuation">,</span> <span class="token string">'ycenter'</span><span class="token punctuation">,</span> <span class="token string">'width'</span><span class="token punctuation">,</span> <span class="token string">'height'</span><span class="token punctuation">,</span> <span class="token string">'confidence'</span><span class="token punctuation">,</span> <span class="token string">'class'</span><span class="token punctuation">,</span> <span class="token string">'name'</span>  <span class="token comment"># xywh columns</span>
        <span class="token keyword">for</span> k<span class="token punctuation">,</span> c <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'xyxy'</span><span class="token punctuation">,</span> <span class="token string">'xyxyn'</span><span class="token punctuation">,</span> <span class="token string">'xywh'</span><span class="token punctuation">,</span> <span class="token string">'xywhn'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>ca<span class="token punctuation">,</span> ca<span class="token punctuation">,</span> cb<span class="token punctuation">,</span> cb<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            a <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">5</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>names<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> x<span class="token punctuation">.</span>tolist<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">]</span>  <span class="token comment"># update</span>
            <span class="token builtin">setattr</span><span class="token punctuation">(</span>new<span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token punctuation">[</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>x<span class="token punctuation">,</span> columns<span class="token operator">=</span>c<span class="token punctuation">)</span> <span class="token keyword">for</span> x <span class="token keyword">in</span> a<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> new

    <span class="token keyword">def</span> <span class="token function">tolist</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># return a list of Detections objects, i.e. 'for result in results.tolist():'</span>
        x <span class="token operator">=</span> <span class="token punctuation">[</span>Detections<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>imgs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>pred<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>names<span class="token punctuation">,</span> self<span class="token punctuation">.</span>s<span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>n<span class="token punctuation">)</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> d <span class="token keyword">in</span> x<span class="token punctuation">:</span>
            <span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'imgs'</span><span class="token punctuation">,</span> <span class="token string">'pred'</span><span class="token punctuation">,</span> <span class="token string">'xyxy'</span><span class="token punctuation">,</span> <span class="token string">'xyxyn'</span><span class="token punctuation">,</span> <span class="token string">'xywh'</span><span class="token punctuation">,</span> <span class="token string">'xywhn'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
                <span class="token builtin">setattr</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> k<span class="token punctuation">,</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>d<span class="token punctuation">,</span> k<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># pop out of list</span>
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>n
</code></pre> 
<h3><a id="34Classify_906"></a>3.4、Classify</h3> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>这是一个二级分类模块，什么是二级分类模块？比如做车牌的识别，先识别出车牌 ，如果想对车牌上的字进行识别，就需要二级分类进一步检测。如果对模型输出的分类再进行分类，就可以用这个模块。不过这里这个类写的比较简单，若进行复杂的二级分类，可以根据自己的实际任务可以改写，这里代码不唯一。这里的功能和torch_utils.py中的load_classifier函数功能相似，不过我们这里是给模型自定义的，可以直接加载在模型上。用的不多的。</p> 
<p>Classify模块代码：</p> 
<pre><code class="prism language-py"><span class="token keyword">class</span> <span class="token class-name">Classify</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> g<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        这是一个二级分类模块, 什么是二级分类模块? 比如做车牌的识别, 先识别出车牌, 如果想对车牌上的字进行识别, 就需要二级分类进一步检测.
        如果对模型输出的分类再进行分类, 就可以用这个模块. 不过这里这个类写的比较简单, 若进行复杂的二级分类, 可以根据自己的实际任务可以改写, 这里代码不唯一.
        Classification head, i.e. x(b,c1,20,20) to x(b,c2)
        用于第二级分类   可以根据自己的任务自己改写，比较简单
        比如车牌识别 检测到车牌之后还需要检测车牌在哪里，如果检测到侧拍后还想对车牌上的字再做识别的话就要进行二级分类
        """</span>
        <span class="token comment"># ch_in, ch_out, kernel, stride, padding, groups</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Classify<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>aap <span class="token operator">=</span> nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># to x(b,c1,1,1)  自适应平均池化操作</span>
        self<span class="token punctuation">.</span>conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>c1<span class="token punctuation">,</span> c2<span class="token punctuation">,</span> k<span class="token punctuation">,</span> s<span class="token punctuation">,</span> autopad<span class="token punctuation">(</span>k<span class="token punctuation">,</span> p<span class="token punctuation">)</span><span class="token punctuation">,</span> groups<span class="token operator">=</span>g<span class="token punctuation">)</span>  <span class="token comment"># to x(b,c2,1,1)</span>
        self<span class="token punctuation">.</span>flat <span class="token operator">=</span> nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 展平</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 先自适应平均池化操作， 然后拼接</span>
        z <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>self<span class="token punctuation">.</span>aap<span class="token punctuation">(</span>y<span class="token punctuation">)</span> <span class="token keyword">for</span> y <span class="token keyword">in</span> <span class="token punctuation">(</span>x <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># cat if list</span>
        <span class="token comment"># 对z进行展平操作</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>flat<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv<span class="token punctuation">(</span>z<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># flatten to x(b,c2)</span>
</code></pre> 
<h2><a id="_937"></a>总结</h2> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
       
      
        \qquad 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0em; vertical-align: 0em;"></span><span class="mspace" style="margin-right: 2em;"></span></span></span></span></span>由于yolov5是函数式的编程，所以yolov5把每个模块写成了一个个的函数形式，这个文件的代码是整个网络搭建的基石，所以一定要牢牢掌握。第一部分的基本组件除了1.9的2个函数其他的8个函数都很重要；第二部分是包括yolov5作者自己探索的自注意力和我这阵子学习的一些注意力机制，我都加了进来，大家看了一尽情的尝试；第三部分的内容并不是很重要的，只是对模型功能进行了一系列的扩展，可看可不看。</p> 
<p>–2021.08.24 10:24</p> 
<h2><a id="Reference_947"></a>Reference</h2> 
<p>CSDN XiaoGShou: <a href="https://blog.csdn.net/XiaoGShou/article/details/117351971?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162919967016780269827948%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=162919967016780269827948&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-3-117351971.first_rank_v2_pc_rank_v29&amp;utm_term=common.py&amp;spm=1018.2226.3001.4187">yolov5 代码解读 --common.py</a></p> 
<p>CSDN weixin_45483906: <a href="https://blog.csdn.net/weixin_45483906/article/details/115129644#comments_16644451">YoloV5系列(2)-model解析</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/333de7d945179efb8251f9d70ff27520/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">木马攻击获得Windows7的权限</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f571f82dec34fd13c93476f78063812a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">第一节:Keras深度学习框架之环境搭建</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>