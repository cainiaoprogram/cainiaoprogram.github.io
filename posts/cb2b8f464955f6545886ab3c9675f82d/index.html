<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>推荐一个刚开源很火的Github项目：OpenVoice（即时语音克隆） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="推荐一个刚开源很火的Github项目：OpenVoice（即时语音克隆）" />
<meta property="og:description" content="博主最近在逛Github，发现一个刚推出的Star指数迅速上升的Github开源项目，该项目可实现提取部分语音的片段就可以仿照说话者的特色去生成不同语言，甚至不同情感、口音、韵律、停顿和语调，也就是使用它可以细致地控制语音风格。这个项目是myshell-ai开源的OpenVoice项目。
项目地址：https://github.com/myshell-ai/OpenVoice
仅开源了不到三周，就有了6.1k的star，还是可以的。
OpenVoice除了灵活的语音风格控制外，还实现了零样本跨语言语音克隆，也就是不需要庞大说话者训练集中的语言，与先前的方法不同，先前的方法通常需要为所有语言提供大规模说话者多语言（MSML）数据集，而OpenVoice可以在没有该语言的大规模说话者训练数据的情况下将语音克隆到新语言中，下面是它的功能详细介绍：
We introduce OpenVoice, a versatile voice cloning approach that requires only a short audio clip from the reference speaker to replicate their voice and generate speech in multiple languages. OpenVoice represents a significant advancement in addressing the following open challenges in the field: 1) Flexible Voice Style Control. OpenVoice enables granular control over voice styles, including emotion, accent, rhythm, pauses, and intonation, in addition to replicating the tone color of the reference speaker." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/cb2b8f464955f6545886ab3c9675f82d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-04T23:07:30+08:00" />
<meta property="article:modified_time" content="2024-01-04T23:07:30+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">推荐一个刚开源很火的Github项目：OpenVoice（即时语音克隆）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-dracula">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/28/29/7iHVfMjz_o.png" alt="在这里插入图片描述"></p> 
<p>博主最近在逛Github，发现一个刚推出的<code>Star</code>指数迅速上升的<code>Github</code>开源项目，该项目可实现<font color="red">提取部分语音的片段就可以仿照说话者的特色去生成不同<u><strong>语言</strong></u>，甚至不同<u><strong>情感</strong></u>、<u><strong>口音</strong></u>、<u><strong>韵律</strong></u>、<u><strong>停顿</strong></u>和<u><strong>语调</strong></u>，也就是使用它可以细致地控制语音风格</font>。这个项目是myshell-ai开源的<a href="https://github.com/myshell-ai/OpenVoice">OpenVoice</a>项目。</p> 
<blockquote> 
 <p>项目地址：<a href="https://github.com/myshell-ai/OpenVoice">https://github.com/myshell-ai/OpenVoice</a></p> 
</blockquote> 
<p>仅开源了不到三周，就有了6.1k的star，还是可以的。<br> <img src="https://images2.imgbox.com/a0/3e/K7EZtl3m_o.png" alt="在这里插入图片描述"><br> <code>OpenVoice</code>除了灵活的语音风格控制外，还实现了<u><strong>零样本跨语言语音克隆</strong></u>，也就是不需要庞大说话者训练集中的语言，与先前的方法不同，先前的方法通常需要为所有语言提供大规模说话者多语言（<code>MSML</code>）数据集，而<code>OpenVoice</code>可以在没有该语言的大规模说话者训练数据的情况下将语音克隆到新语言中，下面是它的功能详细介绍：</p> 
<blockquote> 
 <p>We introduce OpenVoice, a versatile voice cloning approach that requires only a short audio clip from the reference speaker to replicate their voice and generate speech in multiple languages. OpenVoice represents a significant advancement in addressing the following open challenges in the field: 1) Flexible Voice Style Control. OpenVoice enables granular control over voice styles, including emotion, accent, rhythm, pauses, and intonation, in addition to replicating the tone color of the reference speaker. The voice styles are not directly copied from and constrained by the style of the reference speaker. Previous approaches lacked the ability to flexibly manipulate voice styles after cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves zero-shot cross-lingual voice cloning for languages not included in the massive-speaker training set. Unlike previous approaches, which typically require extensive massive-speaker multi-lingual (MSML) dataset for all languages, OpenVoice can clone voices into a new language without any massive-speaker training data for that language. OpenVoice is also computationally efficient, costing tens of times less than commercially available APIs that offer even inferior performance. To foster further research in the field, we have made the source code and trained model publicly accessible. We also provide qualitative results in our demo website. Prior to its public release, our internal version of OpenVoice was used tens of millions of times by users worldwide between May and October 2023, serving as the backend of MyShell.</p> 
</blockquote> 
<p>从下面官网提供的流程可以看到，<code>OpenVoice</code>基于一定的文本内容+口音情感风格参数生成了一个基础的说话者<code>TTS</code>模型，然后基于此模型，用户只需要输入自己的声音片段，便可以根据里面的口音生成不同语言且可控的说话风格。<br> <img src="https://images2.imgbox.com/56/a3/WZM6eYhM_o.png" alt="在这里插入图片描述"></p> 
<p>具体的视频和演示效果大家可以去官网查看：<a href="https://research.myshell.ai/open-voice" rel="nofollow">https://research.myshell.ai/open-voice</a><br> <img src="https://images2.imgbox.com/52/56/ObDLejxi_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5f00c13d89639890f278ef5e6df909e4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">双指针-＞算法实现</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/085b6ba19788c38a7246058a21945f18/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">类和对象及其关系</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>