<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>离线大数据调度框架 -- 1、需求分析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="离线大数据调度框架 -- 1、需求分析" />
<meta property="og:description" content=" 1、启动flume将指定文件【文件内容每一分钟增加若干行，模拟nginx日志】自动同步到HDFS。
要求：
将文件归档时间设置为1小时；归档文件存储格式设置为LZO；HDFS文件按天分文件夹进行存储，不能全部同步到一个文件夹中； 2、配置MR任务并依赖flume任务
要求：
将日志文件解析到hive表每天对应的分区中查看每天分区日志里面是否有其它天的日志【Event Time和处理时间可能不一致】假设当天分区存在其它天的日志，请设计一个方案保证当天的分区只能有当天的数据，并且保证所有的数据不会丢失（不能每次都扫描所有的日志）选做：将日志解析文件存储为parquet文件类型 3、通过sqoop命令行显示mysql里面有多少数据表；通过azkaban配置sqoop任务，将product、member、order三表同步到hive表
要求：
每天设置全量同步相关数据每天设置一个新的分区同步进一步思考 【只要指定数据源数据库、源表和输出hive库、hive表，可以实现所有表在一个任务中就可以实现同步，并且每个map的数据是相对均匀的】 ？？？ 4、hive相关调度
计算每天有多少pv、uv、订单量、收入、注册用户数 （使用1个sql）计算访问product页面的用户中，有多少比例在30分钟内下单并且支付成功对应的商品更改前一个sql，需要做到支持变更不同的页面类型（正则）和目标时间，支持指定时间间隔的转化率分析（写明设计思路）通过sql计算每个商品的每天的pv、uv并存入新建的hive表，格式自己定义计算每个商品每天的pv、uv的环比情况（今天-昨天/昨天），并且筛选出环比增长最大的和最小的（负数&lt;正数）计算每天的登录用户数中新老用户占比，并且统计新老用户分别的pv、uv （新老用户的判断标准？？？）设计一个udaf，将用户当前行为之前30分钟内的actionid行为存为一个list，其中list中的序号代表由远到近的时间序（参考collect_set的udaf）基于udaf重写第二个作业的sql，对比有何不同 5、配置sqoop任务将hive任务结果导入mysql数据库
计算每个商品的每天的pv、uv并存入新建的hive表每天同步到mysql的表中 6、基于你现有知识，设计自己的框架
框架适用方需求如下：【前2个需求通过写shell脚本暴露通用参数】
业务方不想知道你怎么同步，只想在使用的时候指定源数据库、源表和输出hive库、hive表，第二天自动同步全量信息。对日志解析而言，业务方不想知道你是通过什么引擎实现的，只希望写个输入路径，输出hive表，分区和解析逻辑，其它过程系统自动完成业务放不想写add jar这样的方式创建临时函数，如何设计一个规范保证业务方可以直接使用你生成的udf，可以注册为常用函数，也可以用其它方式 【把udf函数加入hive启动服务，在hive-site.xml的hive.aux.jars.path中添加jar包路径】sqoop导入数据库太慢了，如何设计一种方案：在任务中，直接将结果写入数据库，业务方不想知道中间细节，只希望hive查询结果可以直接插入数据库（不做转化） 【此处数据库应该指mySQL数据库】 hive-contrib模块的GenericUDFDBOutput " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/6ce7cef0f8103db3cf4f8b512c03320f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-02-27T12:05:54+08:00" />
<meta property="article:modified_time" content="2019-02-27T12:05:54+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">离线大数据调度框架 -- 1、需求分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>1、启动flume将指定文件【文件内容每一分钟增加若干行，模拟nginx日志】自动同步到HDFS。</p> 
<p>    要求：</p> 
<ul><li>将文件归档时间设置为1小时；</li><li>归档文件存储格式设置为LZO；</li><li>HDFS文件<strong>按天</strong>分文件夹进行存储，不能全部同步到一个文件夹中；</li></ul> 
<p>2、配置<strong>MR任务</strong>并依赖<strong>flume任务</strong></p> 
<p>    要求：</p> 
<ul><li>将日志文件解析到hive表每天对应的分区中</li><li>查看每天分区日志里面是否有其它天的日志【<span style="color:#f33b45;"><strong>Event Time和处理时间可能不一致</strong></span>】</li><li>假设当天分区存在其它天的日志，请设计一个方案<strong>保证当天的分区只能有当天的数据</strong>，并且保证所有的数据不会丢失（不能每次都扫描所有的日志）</li><li>选做：将<strong>日志解析文件</strong>存储为<strong>parquet文件类型</strong></li></ul> 
<p> 3、通过sqoop命令行显示mysql里面有多少数据表；通过azkaban配置sqoop任务，将product、member、order三表同步到hive表</p> 
<p>    要求：</p> 
<ul><li>每天设置全量<strong>同步</strong>相关数据</li><li><strong>每天</strong>设置一个<strong>新的分区</strong></li><li><span style="color:#f33b45;"><strong>同步</strong></span>进一步思考 【只要指定数据源数据库、源表和输出hive库、hive表，可以实现<strong>所有表</strong>在一个任务中就可以实现同步，并且<strong>每个map的数据</strong>是<strong>相对均匀</strong>的】 ？？？</li></ul> 
<p>4、hive相关调度</p> 
<ul><li>计算每天有多少pv、uv、订单量、收入、注册用户数 （使用1个sql）</li><li>计算访问product页面的用户中，有多少比例在30分钟内下单并且支付成功对应的商品</li><li>更改前一个sql，需要做到支持<strong>变更不同的页面类型</strong>（正则）和<strong>目标时间</strong>，支持<strong>指定时间间隔</strong>的<strong>转化率</strong>分析（写明设计思路）</li><li><span style="color:#f33b45;">通过sql计算每个商品的每天的pv、uv并存入新建的hive表，格式自己定义</span></li><li>计算每个商品每天的pv、uv的环比情况（今天-昨天/昨天），并且筛选出环比增长最大的和最小的（负数&lt;正数）</li><li>计算每天的登录用户数中新老用户占比，并且统计新老用户分别的pv、uv  （<span style="color:#f33b45;"><strong>新老用户的判断标准？？？</strong></span>）</li><li>设计一个udaf，将用户当前行为之前30分钟内的actionid行为存为一个list，其中list中的序号代表由远到近的时间序（参考collect_set的udaf）</li><li>基于udaf重写第二个作业的sql，对比有何不同</li></ul> 
<p>5、配置sqoop任务将hive任务结果导入mysql数据库</p> 
<ul><li>计算每个商品的每天的pv、uv并存入新建的hive表<strong>每天</strong>同步到mysql的表中 </li></ul> 
<p> </p> 
<p>6、基于你现有知识，设计自己的框架</p> 
<p>    框架适用方需求如下：【前2个需求通过写shell脚本暴露通用参数】</p> 
<ul><li>业务方不想知道你怎么同步，只想在使用的时候指定源数据库、源表和输出hive库、hive表，第二天自动同步全量信息。</li><li>对日志解析而言，业务方不想知道你是通过什么引擎实现的，只希望写个<strong>输入路径</strong>，<strong>输出hive表</strong>，<strong>分区</strong>和<strong>解析逻辑</strong>，其它过程系统自动完成</li><li>业务放不想写add jar这样的方式创建临时函数，如何设计一个<strong>规范</strong>保证业务方可以<strong>直接使用</strong>你生成的<strong>udf</strong>，可以<strong>注册为常用函数</strong>，也可以用其它方式 【<span style="color:#f33b45;">把udf函数加入hive启动服务，在hive-site.xml的hive.aux.jars.path中添加jar包路径</span>】</li><li>sqoop导入数据库太慢了，如何设计一种方案：在任务中，<strong>直接将结果写入数据库</strong>，业务方不想知道中间细节，只希望<strong>hive查询结果可以直接插入数据库</strong>（不做转化） 【此处数据库应该指mySQL数据库】 hive-contrib模块的GenericUDFDBOutput</li></ul> 
<p> </p> 
<p><img alt="" class="has" height="479" src="https://images2.imgbox.com/8b/1a/ZM17kcvU_o.png" width="758"></p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e415e6b6ab8d21a43386482df1e71140/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">BottomNavigationView&#43;Fragment实现主页面布局，并解决fragment重叠和数据保存的问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/66f10eb2ed246e1893ecd734627b8ad4/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;-P4-从另一个小程序接着说</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>