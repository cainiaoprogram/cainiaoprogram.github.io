<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>FFmpeg解码的软解及硬解（cuda和qsv）使用方法 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="FFmpeg解码的软解及硬解（cuda和qsv）使用方法" />
<meta property="og:description" content="本次使用的ffmpeg版本是4.2，解码的调用方式为：
int32_t iRet = -1;
// 最后一个包解码完成后，需要取完解码器中剩余的缓存帧;
// 调用avcodec_send_packet时塞空包进去,;
// 解码器就会知道所有包解码完成，再调用avcodec_receive_frame时，将会取出缓存帧;
// AVPacket packet;
// av_init_packet(&amp;packet);
// pkt.data = NULL;
// pkt.size = 0;
// avcodec_send_packet(ctx, pkt);
iRet = avcodec_send_packet(ctx, pkt);
if (iRet != 0 &amp;&amp; iRet != AVERROR(EAGAIN)) {
get_ffmepg_err_str(iRet);
if (iRet == AVERROR_EOF)
iRet = 0;
return iRet;
}
while (true) {
// 每解出来一帧，丢到队列中;
iRet = avcodec_receive_frame(ctx, frame);
if (iRet != 0) {
if (iRet == AVERROR(EAGAIN)) {" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/6713db770d421035f0d822617b472ce7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-04T17:42:55+08:00" />
<meta property="article:modified_time" content="2023-03-04T17:42:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">FFmpeg解码的软解及硬解（cuda和qsv）使用方法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div class="kdocs-document"> 
 <p style="text-align:null;">本次使用的ffmpeg版本是4.2，解码的调用方式为：</p> 
 <p style="text-align:left;">int32_t iRet = -1;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">// 最后一个包解码完成后，需要取完解码器中剩余的缓存帧;</p> 
 <p style="text-align:left;">// 调用avcodec_send_packet时塞空包进去,;</p> 
 <p style="text-align:left;">// 解码器就会知道所有包解码完成，再调用avcodec_receive_frame时，将会取出缓存帧;</p> 
 <p style="text-align:left;">// AVPacket packet;</p> 
 <p style="text-align:left;">// av_init_packet(&amp;packet);</p> 
 <p style="text-align:left;">// pkt.data = NULL;</p> 
 <p style="text-align:left;">// pkt.size = 0;</p> 
 <p style="text-align:left;">// avcodec_send_packet(ctx, pkt);</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">iRet = avcodec_send_packet(ctx, pkt);</p> 
 <p style="text-align:left;">if (iRet != 0 &amp;&amp; iRet != AVERROR(EAGAIN)) {<!-- --></p> 
 <p style="text-align:left;"> get_ffmepg_err_str(iRet);</p> 
 <p style="text-align:left;"> if (iRet == AVERROR_EOF)</p> 
 <p style="text-align:left;"> iRet = 0;</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">while (true) {<!-- --></p> 
 <p style="text-align:left;"> // 每解出来一帧，丢到队列中;</p> 
 <p style="text-align:left;"> iRet = avcodec_receive_frame(ctx, frame);</p> 
 <p style="text-align:left;"> if (iRet != 0) {<!-- --></p> 
 <p style="text-align:left;"> if (iRet == AVERROR(EAGAIN)) {<!-- --></p> 
 <p style="text-align:left;"> return 0;</p> 
 <p style="text-align:left;"> } else</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> PushRenderBuffer();</p> 
 <p style="text-align:left;"> // 音频解码后，如果需要重采样，也可以在此处进行resample;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:null;">以前的版本解码方式为：</p> 
 <p style="text-align:left;">int32_t iRet = -1;</p> 
 <p style="text-align:left;">iRet = avcodec_send_packet(ctx, pkt);</p> 
 <p style="text-align:left;">if (iRet != 0 &amp;&amp; iRet != AVERROR(EAGAIN)) {<!-- --></p> 
 <p style="text-align:left;"> get_ffmepg_err_str(iRet);</p> 
 <p style="text-align:left;"> if (iRet == AVERROR_EOF)</p> 
 <p style="text-align:left;"> iRet = 0;</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">avcodec_decode_video2(pCodecCtx, frame, iGotPicture, pkt);</p> 
 <p style="text-align:null;">新旧版本更新时，注意接口的使用方法，新版本avcodec_send_packet一次，需要循环调用avcodec_receive_frame多次，返回EAGAIN后，结束当前这次的解码，音频解码也是一样</p> 
 <p style="text-align:null;">一、软件解码：</p> 
 <p style="text-align:null;">先上一段代码，再做下说明，这是解码视频文件，以AVStream的方式获取文件信息，再创建解码器</p> 
 <p style="text-align:left;">int32_t ret = avformat_open_input(&amp;m_pAVFormatIC, pPath, NULL, NULL);</p> 
 <p style="text-align:left;">if (avformat_find_stream_info(m_pAVFormatIC, NULL) &lt; 0) {<!-- --></p> 
 <p style="text-align:left;"> return;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;">for (uint32_t i = 0; i &lt; m_pAVFormatIC-&gt;nb_streams; i++) {<!-- --></p> 
 <p style="text-align:left;"> switch (m_pAVFormatIC-&gt;streams[i]-&gt;codec-&gt;codec_type) {<!-- --></p> 
 <p style="text-align:left;"> case AVMEDIA_TYPE_VIDEO:</p> 
 <p style="text-align:left;"> // 视频流;</p> 
 <p style="text-align:left;"> AVCodec *find_codec = avcodec_find_decoder(m_pAVFormatIC-&gt;streams[i]-&gt;codec-&gt;codec_id);</p> 
 <p style="text-align:left;"> AVCodecContext *codec_ctx = avcodec_alloc_context3(find_codec);</p> 
 <p style="text-align:left;"> avcodec_parameters_to_context(codec_ctx, m_pAVFormatIC-&gt;streams[i]-&gt;codecpar);</p> 
 <p style="text-align:left;"> codec_ctx-&gt;opaque = this;</p> 
 <p style="text-align:left;"> codec_ctx-&gt;thread_count = 5;</p> 
 <p style="text-align:left;"> codec_ctx-&gt;thread_safe_callbacks = 1;</p> 
 <p style="text-align:left;"> // avcodec_receive_frame的frame数据内存交由自己申请，自己释放，减少内存申请及拷贝;</p> 
 <p style="text-align:left;"> codec_ctx-&gt;get_buffer2 = DemuxStream::CustomFrameAllocBuffer;</p> 
 <p style="text-align:left;"> avcodec_open2(codec_ctx, find_codec, NULL);</p> 
 <p style="text-align:left;"> continue;</p> 
 <p style="text-align:left;"> case AVMEDIA_TYPE_AUDIO:</p> 
 <p style="text-align:left;"> // 音频流;</p> 
 <p style="text-align:left;"> // 同上;</p> 
 <p style="text-align:left;"> continue;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:null;">1、m_pAVFormatIC-&gt;streams[i]-&gt;codec-&gt;codec_type 来判断是否包含音频和视频数据，如果是mp3文件，codec_type有Video是表示MP3的封面图片帧;</p> 
 <p style="text-align:null;">2、avcodec_find_decoder和avcodec_alloc_context3创建的指针，不需要覆盖stream中的指针，这是错误的用法，stream只是记录当前文件的流信息，不要用来保存context，创建的context由自己来保管；</p> 
 <p style="text-align:null;">3、avcodec_parameters_to_context，一定要做，这是把解析到的留信息设置到context，不需要在自己一个参数一个参数的设置；</p> 
 <p style="text-align:null;">4、多线程软解，thread_count不修改的话默认值是1，使用单个线程进行解码，遇到一些大文件，比如4K，30帧以上的视频流时，解码速度是跟不上的，有两种方案：多线程软解或者硬件解码（后面说）</p> 
 <p style="text-align:null;">thread_count为0，表示由ffmpeg调用最大线程数来进行软解，我的电脑的6核12线程，被创建了13个线程进行解码，实际上这会资源过剩，可以根据实际使用情况设置指定线程数量进行解码，这里我设置的是5,</p> 
 <p style="text-align:null;">切记！在设置thread_count大于1的值时，一定要把thread_safe_callbacks设置为1，否则的话必定会产生崩溃；</p> 
 <p style="text-align:null;">默认时，thread_safe_callbacks是为0，thread_count是1或者0的时候，都不需要这个标记</p> 
 <p style="text-align:null;">5、自行分配avcodec_receive_frame中frame的数据内存</p> 
 <p style="text-align:null;">调用avcodec_receive_frame获取到解码完成后的视频帧，如果需要获取视频的数据流，需要将frame中的data拷贝到连续的内存地址中，具体方法：</p> 
 <p style="text-align:left;">uint8_t* AllocBufferByFrame(const AVFrame *frame)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> if (!frame)</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> int32_t s = av_image_get_buffer_size((AVPixelFormat)frame-&gt;format,</p> 
 <p style="text-align:left;"> frame-&gt;width,</p> 
 <p style="text-align:left;"> frame-&gt;height, 1);</p> 
 <p style="text-align:left;"> if (s &lt;= 0)</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> return new uint8_t[s]{0};</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">int32_t FillBufferFromFrame(uint8_t* alloced_buffer, const AVFrame *frame)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> if (!alloced_buffer || !frame)</p> 
 <p style="text-align:left;"> return -1;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> uint8_t* dst_data[4]{};</p> 
 <p style="text-align:left;"> int dst_linesize[4]{};</p> 
 <p style="text-align:left;"> int32_t ret = av_image_fill_arrays(dst_data, dst_linesize, alloced_buffer,</p> 
 <p style="text-align:left;"> (AVPixelFormat)frame-&gt;format,</p> 
 <p style="text-align:left;"> frame-&gt;width,</p> 
 <p style="text-align:left;"> frame-&gt;height,</p> 
 <p style="text-align:left;"> 1);</p> 
 <p style="text-align:left;"> if (ret &lt;= 0)</p> 
 <p style="text-align:left;"> return ret;</p> 
 <p style="text-align:left;"> av_image_copy(dst_data, dst_linesize,</p> 
 <p style="text-align:left;"> (const uint8_t **)frame-&gt;data,</p> 
 <p style="text-align:left;"> frame-&gt;linesize,</p> 
 <p style="text-align:left;"> (AVPixelFormat)frame-&gt;format,</p> 
 <p style="text-align:left;"> frame-&gt;width,</p> 
 <p style="text-align:left;"> frame-&gt;height);</p> 
 <p style="text-align:left;"> return ret;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">uint8_t *buffer = AllocBufferByFrame(frame);</p> 
 <p style="text-align:left;">FillBufferFromFrame(buffer, frame);</p> 
 <p style="text-align:left;">// 使用完buffer的地方，释放buffer的内存;</p> 
 <p style="text-align:null;">按照这种使用方法，同一帧的数据会申请两份，解码器中申请了一份，拷贝到buffer中一份，增加了内存消耗以及数据拷贝，ffmpeg提供了解码时frame的内存由自己管理的回调接口，get_buffer2，这个回调接口在调用avcodec_receive_frame时，如果自定义了函数指针，将会调用自定义的函数接口，在接口内完成frame的data，linesize，buf的内容填充，在回调时，frame中的format，width，height已经被填充，可以直接拿来使用，注意：在get_buffer2的回调里，flag是AV_GET_BUFFER_FLAG_REF（1），我们申请的内存会被其他frame复用，不能直接释放，应该通过绑定的free接口来释放，我这里申请的是连续内存，回调free的接口每个平面都会调用，只有第一个平面也就是data[0]的时候，才能delete，方法如下：</p> 
 <p style="text-align:left;">void DemuxStream::CustomFrameFreeBuffer(void *opaque, uint8_t *data)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> //申请的空间是连续的，只有第一个data，也就是data[0]的时候再删除，否则会崩溃;</p> 
 <p style="text-align:left;"> int i = (int)opaque;</p> 
 <p style="text-align:left;"> if (i == 0)</p> 
 <p style="text-align:left;"> delete data;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">int DemuxStream::CustomFrameAllocBuffer(struct AVCodecContext *s, AVFrame *frame, int flags)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> int32_t size = av_image_get_buffer_size((AVPixelFormat)frame-&gt;format,</p> 
 <p style="text-align:left;"> frame-&gt;width,</p> 
 <p style="text-align:left;"> frame-&gt;height, 1);</p> 
 <p style="text-align:left;"> if (size &lt;= 0)</p> 
 <p style="text-align:left;"> return -1;</p> 
 <p style="text-align:left;"> // 这是由自己申请的内存，avcodec_receive_frame使用完后要自己释放;</p> 
 <p style="text-align:left;"> uint8_t *buffer = new uint8_t[size]{0};</p> 
 <p style="text-align:left;"> uint8_t* dst_data[AV_NUM_DATA_POINTERS]{};</p> 
 <p style="text-align:left;"> int dst_linesize[AV_NUM_DATA_POINTERS]{};</p> 
 <p style="text-align:left;"> int32_t ret = av_image_fill_arrays(dst_data, dst_linesize, buffer,</p> 
 <p style="text-align:left;"> (AVPixelFormat)frame-&gt;format, frame-&gt;width, frame-&gt;height, 1);</p> 
 <p style="text-align:left;"> if (ret &lt; 0) {<!-- --></p> 
 <p style="text-align:left;"> delete[] buffer;</p> 
 <p style="text-align:left;"> return ret;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> for (int i = 0; i &lt; AV_NUM_DATA_POINTERS; i++) {<!-- --></p> 
 <p style="text-align:left;"> frame-&gt;linesize[i] = dst_linesize[i];</p> 
 <p style="text-align:left;"> frame-&gt;data[i] = dst_data[i];</p> 
 <p style="text-align:left;"> frame-&gt;buf[i] = av_buffer_create(frame-&gt;data[i],</p> 
 <p style="text-align:left;"> frame-&gt;linesize[i] * frame-&gt;height,</p> 
 <p style="text-align:left;"> DemuxStream::CustomFrameFreeBuffer,</p> 
 <p style="text-align:left;"> (void *)i, 0);</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> return 0;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">// 解码时伪代码;</p> 
 <p style="text-align:left;">avcodec_send_packet(ctx, pkt);</p> 
 <p style="text-align:left;">while (true) {<!-- --></p> 
 <p style="text-align:left;"> // 每解出来一帧，丢到队列中;</p> 
 <p style="text-align:left;"> iRet = avcodec_receive_frame(ctx, frame);</p> 
 <p style="text-align:left;"> if (iRet != 0) {<!-- --></p> 
 <p style="text-align:left;"> if (iRet == AVERROR(EAGAIN)) {<!-- --></p> 
 <p style="text-align:left;"> return 0;</p> 
 <p style="text-align:left;"> } else</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> push_render_buffer(frame);</p> 
 <p style="text-align:left;"> //使用完成后，调用av_frame_unref,内存回收会在CustomFrameFreeBuffer执行;</p> 
 <p style="text-align:left;"> //因为自行申请的buffer，交给ffmpeg后，有可能会被复用，不能直接删除buffer;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:null;"><span class="kdocs-bold" style="font-weight:bold;">二、硬件解码</span></p> 
 <p style="text-align:null;">硬件解码需要编译的ffmpeg库支持，具体编译方法就不再此赘述，本次用到的硬件解码为英伟达cuda和英特尔的qsv，硬解解码器的创建跟软解有所不同，使用的过程也只是存在一点差异</p> 
 <p style="text-align:null;"><span class="kdocs-bold" style="font-weight:bold;">1、英伟达，cuda</span></p> 
 <p style="text-align:left;">AVPixelFormat DemuxStream::GetHwFormat(AVCodecContext * ctx, const AVPixelFormat * pix_fmts)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> const enum AVPixelFormat *p;</p> 
 <p style="text-align:left;"> DemuxStream *pThis = (DemuxStream *)ctx-&gt;opaque;</p> 
 <p style="text-align:left;"> for (p = pix_fmts; *p != -1; p++) {<!-- --></p> 
 <p style="text-align:left;"> if (*p == pThis-&gt;m_AVStreamInfo.hw_pix_fmt) {<!-- --></p> 
 <p style="text-align:left;"> return *p;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> fprintf(stderr, "Failed to get HW surface format.\n");</p> 
 <p style="text-align:left;"> return AV_PIX_FMT_NONE;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;">AVCodecContext * DemuxStream::GetCudaDecoder(AVStream *stream)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> int32_t ret = avformat_open_input(&amp;m_pAVFormatIC, pPath, NULL, NULL);</p> 
 <p style="text-align:left;"> if (ret &lt; 0)</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> if (avformat_find_stream_info(m_pAVFormatIC, NULL) &lt; 0)</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> ret = av_find_best_stream(m_pAVFormatIC, AVMEDIA_TYPE_VIDEO, -1, -1, &amp;find_codec, 0);</p> 
 <p style="text-align:left;"> if (ret &lt; 0)</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> for (int i = 0;; i++) {<!-- --></p> 
 <p style="text-align:left;"> const AVCodecHWConfig *config = avcodec_get_hw_config(find_codec, i);</p> 
 <p style="text-align:left;"> if (!config) {<!-- --></p> 
 <p style="text-align:left;"> // 没找到cuda解码器，不能使用;</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> if (config-&gt;device_type == AV_HWDEVICE_TYPE_CUDA) {<!-- --></p> 
 <p style="text-align:left;"> // 找到了cuda解码器，记录对应的AVPixelFormat,后面get_format需要使用;</p> 
 <p style="text-align:left;"> m_AVStreamInfo.hw_pix_fmt = config-&gt;pix_fmt;</p> 
 <p style="text-align:left;"> m_AVStreamInfo.device_type = AV_HWDEVICE_TYPE_CUDA;</p> 
 <p style="text-align:left;"> break;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> AVCodecContext *decoder_ctx = avcodec_alloc_context3(find_codec);</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> avcodec_parameters_to_context(decoder_ctx, m_pAVFormatIC-&gt;stream[video_index]-&gt;codecpar);</p> 
 <p style="text-align:left;"> decoder_ctx-&gt;opaque = this;</p> 
 <p style="text-align:left;"> decoder_ctx-&gt;get_format = DemuxStream::GetHwFormat;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> if (m_AVStreamInfo.hw_device_ctx) {<!-- --></p> 
 <p style="text-align:left;"> av_buffer_unref(&amp;m_AVStreamInfo.hw_device_ctx);</p> 
 <p style="text-align:left;"> m_AVStreamInfo.hw_device_ctx = NULL;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> if (av_hwdevice_ctx_create(&amp;m_AVStreamInfo.hw_device_ctx, m_AVStreamInfo.device_type,</p> 
 <p style="text-align:left;"> NULL, NULL, 0) &lt; 0) {<!-- --></p> 
 <p style="text-align:left;"> fprintf(stderr, "Failed to create specified HW device.\n");</p> 
 <p style="text-align:left;"> // 创建硬解设备context失败，不能使用;</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> decoder_ctx-&gt;hw_device_ctx = av_buffer_ref(m_AVStreamInfo.hw_device_ctx);</p> 
 <p style="text-align:left;"> avcodec_open2(decoder_ctx, find_codec, NULL);</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:null;">avcodec_get_hw_config，从当前硬解的配置中，遍历寻找适用于当前AvCodec的cuda配置，找到后记录cuda解码后的AVPixelFormat，后面解码器初始化时会使用到这个pix_fmt；</p> 
 <p style="text-align:null;">设置get_format的回调接口，在回调接口里面，会遍历cuda解码器支持的输出格式，匹配记录的pix_fmt才可以使用，在get_format如果没有找到匹配的硬解设置，可以返回指定类型的软解输出格式，解码器会自动切换到软解进行解码</p> 
 <p style="text-align:null;">初始化cuda解码器之前，先创建硬解设备context，赋值AVCodecContext-&gt;hw_device_ctx为其引用</p> 
 <p style="text-align:null;">至此cuda解码器创建完成，接下来是解码获取视频帧，硬解获得的视频帧后续的处理方式与软解是一样的，硬解比软解多了一步av_hwframe_transfer_data，在avcodec_receive_frame执行完成后，获得的frame中的数据时GPU的数据，是不能直接拿出来用的，需要通过av_hwframe_transfer_data转到内存数据，转换完成后记得把frame的属性通过av_frame_copy_props设置给hw_frame，这里的硬解获取视频帧同样适用于qsv硬解；</p> 
 <p style="text-align:left;">iRet = avcodec_send_packet(ctx, pkt);</p> 
 <p style="text-align:left;">if (iRet != 0 &amp;&amp; iRet != AVERROR(EAGAIN)) {<!-- --></p> 
 <p style="text-align:left;"> get_ffmepg_err_str(iRet);</p> 
 <p style="text-align:left;"> if (iRet == AVERROR_EOF)</p> 
 <p style="text-align:left;"> iRet = 0;</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;">while (true) {<!-- --></p> 
 <p style="text-align:left;"> // 每解出来一帧，丢到队列中;</p> 
 <p style="text-align:left;"> iRet = avcodec_receive_frame(ctx, frame);</p> 
 <p style="text-align:left;"> if (iRet != 0) {<!-- --></p> 
 <p style="text-align:left;"> if (iRet == AVERROR(EAGAIN)) {<!-- --></p> 
 <p style="text-align:left;"> return 0;</p> 
 <p style="text-align:left;"> } else</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> if (m_pStreamInfo-&gt;hw_pix_fmt != AV_PIX_FMT_NONE &amp;&amp;</p> 
 <p style="text-align:left;"> m_pStreamInfo-&gt;device_type != AV_HWDEVICE_TYPE_NONE) {<!-- --></p> 
 <p style="text-align:left;"> AVFrame *hw_frame = av_frame_alloc();</p> 
 <p style="text-align:left;"> iRet = av_hwframe_transfer_data(hw_frame, frame, 0);</p> 
 <p style="text-align:left;"> if (iRet &lt; 0) {<!-- --></p> 
 <p style="text-align:left;"> av_frame_unref(hw_frame);</p> 
 <p style="text-align:left;"> return iRet;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> av_frame_copy_props(hw_frame, frame);</p> 
 <p style="text-align:left;"> // hw_frame中的data，就是硬解完成后的视频帧数据;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:null;"><span class="kdocs-bold" style="font-weight:bold;">2、英特尔硬解，qsv</span></p> 
 <p style="text-align:null;">qsv的解码器创建的方式与cuda不同，解码获取视频帧内容与cuda完全一致，解码的部分看上面，qsv的解码器创建和cuda的区别在于，初始化AVCodecContext-&gt;hw_frames_ctx，cuda是在avcodec_open2之前创建，qsv是在get_format的回调里创建，并且qsv需要做一些额外的设置；</p> 
 <p style="text-align:null;">另外在查找codec_id的时候，需要加上“_qsv”的后缀，这个所支持的qsv的编码格式，可以通过ffmpeg.exe查看到</p> 
 <p style="text-align:null;">其他部分与cuda的创建基本一致</p> 
 <p style="text-align:left;">AVPixelFormat DemuxStream::GetHwFormat(AVCodecContext * ctx, const AVPixelFormat * pix_fmts)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> const enum AVPixelFormat *p;</p> 
 <p style="text-align:left;"> DemuxStream *pThis = (DemuxStream *)ctx-&gt;opaque;</p> 
 <p style="text-align:left;"> for (p = pix_fmts; *p != -1; p++) {<!-- --></p> 
 <p style="text-align:left;"> if (*p == pThis-&gt;m_AVStreamInfo.hw_pix_fmt &amp;&amp; *p == AV_PIX_FMT_QSV) {<!-- --></p> 
 <p style="text-align:left;"> if (pThis-&gt;HwQsvDecoderInit(ctx) &lt; 0)</p> 
 <p style="text-align:left;"> return AV_PIX_FMT_NONE;</p> 
 <p style="text-align:left;"> return *p;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> fprintf(stderr, "Failed to get HW surface format.\n");</p> 
 <p style="text-align:left;"> return AV_PIX_FMT_NONE;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">int DemuxStream::HwQsvDecoderInit(AVCodecContext * ctx)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> DemuxStream *pThis = (DemuxStream *)ctx-&gt;opaque;</p> 
 <p style="text-align:left;"> AVHWFramesContext *frames_ctx;</p> 
 <p style="text-align:left;"> AVQSVFramesContext *frames_hwctx;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> /* create a pool of surfaces to be used by the decoder */</p> 
 <p style="text-align:left;"> ctx-&gt;hw_frames_ctx = av_hwframe_ctx_alloc(pThis-&gt;m_qsv_device_ref);</p> 
 <p style="text-align:left;"> if (!ctx-&gt;hw_frames_ctx)</p> 
 <p style="text-align:left;"> return -1;</p> 
 <p style="text-align:left;"> frames_ctx = (AVHWFramesContext*)ctx-&gt;hw_frames_ctx-&gt;data;</p> 
 <p style="text-align:left;"> frames_hwctx = (AVQSVFramesContext *)frames_ctx-&gt;hwctx;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> frames_ctx-&gt;format = AV_PIX_FMT_QSV;</p> 
 <p style="text-align:left;"> frames_ctx-&gt;sw_format = ctx-&gt;sw_pix_fmt;</p> 
 <p style="text-align:left;"> frames_ctx-&gt;width = FFALIGN(ctx-&gt;coded_width, 32);</p> 
 <p style="text-align:left;"> frames_ctx-&gt;height = FFALIGN(ctx-&gt;coded_height, 32);</p> 
 <p style="text-align:left;"> frames_ctx-&gt;initial_pool_size = 16;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> frames_hwctx-&gt;frame_type = MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET;</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> return av_hwframe_ctx_init(ctx-&gt;hw_frames_ctx);</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;">AVCodecContext * DemuxStream::GetQsvDecoder(AVStream *stream)</p> 
 <p style="text-align:left;">{<!-- --></p> 
 <p style="text-align:left;"> AVCodecContext *decoder_ctx = nullptr;</p> 
 <p style="text-align:left;"> int ret = av_hwdevice_ctx_create(&amp;m_qsv_device_ref, AV_HWDEVICE_TYPE_QSV,</p> 
 <p style="text-align:left;"> "auto", NULL, 0);</p> 
 <p style="text-align:left;"> if (ret &lt; 0) {<!-- --></p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> AVCodec *find_decoder = avcodec_find_decoder(stream-&gt;codec-&gt;codec_id);</p> 
 <p style="text-align:left;"> if (!find_decoder) {<!-- --></p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> find_decoder = avcodec_find_decoder_by_name((std::string(find_decoder-&gt;name) + "_qsv").c_str());</p> 
 <p style="text-align:left;"> if (!find_decoder) {<!-- --></p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> </p> 
 <p style="text-align:left;"> for (int i = 0;; i++) {<!-- --></p> 
 <p style="text-align:left;"> const AVCodecHWConfig *config = avcodec_get_hw_config(find_decoder, i);</p> 
 <p style="text-align:left;"> if (!config) {<!-- --></p> 
 <p style="text-align:left;"> fprintf(stderr, "Decoder %s does not support device type %s.\n",</p> 
 <p style="text-align:left;"> find_decoder-&gt;name, av_hwdevice_get_type_name(AV_HWDEVICE_TYPE_QSV));</p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> if (config-&gt;device_type == AV_HWDEVICE_TYPE_QSV) {<!-- --></p> 
 <p style="text-align:left;"> m_AVStreamInfo.hw_pix_fmt = config-&gt;pix_fmt;</p> 
 <p style="text-align:left;"> m_AVStreamInfo.device_type = AV_HWDEVICE_TYPE_QSV;</p> 
 <p style="text-align:left;"> break;</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> }</p> 
 <p style="text-align:left;"> if (m_AVStreamInfo.device_type == AV_HWDEVICE_TYPE_NONE ||</p> 
 <p style="text-align:left;"> m_AVStreamInfo.hw_pix_fmt == AV_PIX_FMT_NONE)</p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> decoder_ctx = avcodec_alloc_context3(find_decoder);</p> 
 <p style="text-align:left;"> if (!decoder_ctx)</p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> if (avcodec_parameters_to_context(decoder_ctx, stream-&gt;codecpar) &lt; 0)</p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> decoder_ctx-&gt;opaque = this;</p> 
 <p style="text-align:left;"> decoder_ctx-&gt;get_format = DemuxStream::GetHwFormat;</p> 
 <p style="text-align:left;"> ret = avcodec_open2(decoder_ctx, NULL, NULL);</p> 
 <p style="text-align:left;"> if (ret &lt; 0)</p> 
 <p style="text-align:left;"> goto failed;</p> 
 <p style="text-align:left;"> return decoder_ctx;</p> 
 <p style="text-align:left;">failed:</p> 
 <p style="text-align:left;"> m_AVStreamInfo.hw_pix_fmt = AV_PIX_FMT_NONE;</p> 
 <p style="text-align:left;"> m_AVStreamInfo.device_type = AV_HWDEVICE_TYPE_NONE;</p> 
 <p style="text-align:left;"> av_buffer_unref(&amp;m_qsv_device_ref);</p> 
 <p style="text-align:left;"> m_qsv_device_ref = nullptr;</p> 
 <p style="text-align:left;"> avcodec_free_context(&amp;decoder_ctx);</p> 
 <p style="text-align:left;"> return nullptr;</p> 
 <p style="text-align:left;">}</p> 
 <p style="text-align:null;">原文链接：<a class="kdocs-link" style="color:#0A6CFF;" href="https://link.zhihu.com/?target=https%3A//ffmpeg.0voice.com/forum.php%3Fmod%3Dviewthread%26tid%3D994%26extra%3D" rel="nofollow noopener noreferrer" target="_blank">FFmpeg解码的软解及硬解（cuda和qsv）使用方法 - 资料 - 音视频开发中文网 - 构建全国最权威的音视频技术交流分享论坛</a></p> 
 <p style="text-align:left;"><span class="kdocs-color" style="color:#C21C13;"><span class="kdocs-bold" style="font-weight:bold;">★文末名片可以免费领取音视频开发学习资料，内容包括（FFmpeg ，webRTC ，rtmp ，hls ，rtsp ，ffplay ，srs）以及音视频学习路线图等等。</span></span></p> 
 <p style="text-align:left;"><span class="kdocs-color" style="color:#C21C13;"><span class="kdocs-bold" style="font-weight:bold;">见下方!↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓↓</span></span></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7fb9b3155521f0d734e82fce4e7d6630/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">视觉学习笔记4——学习研究ORB-SLAM3</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2bbd11ff5693c1f88df37819d5cbb128/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">安装VMware tools后，虚拟机依然无法全屏问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>