<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>混淆矩阵 confusion matrices - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="混淆矩阵 confusion matrices" />
<meta property="og:description" content="百度百科 混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。具体评价指标有总体精度、制图精度、用户精度等，这些精度指标从不同的侧面反映了图像分类的精度。 [1] 在人工智能中，混淆矩阵（confusion matrix）是可视化工具，特别用于监督学习，在无监督学习一般叫做匹配矩阵。在图像精度评价中，主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。混淆矩阵是通过将每个实测像元的位置和分类与分类图像中的相应位置和分类相比较计算的。
混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。每一列中的数值表示真实数据被预测为该类的数目：如下图，第一行第一列中的43表示有43个实际归属第一类的实例被预测为第一类，同理，第一行第二列的2表示有2个实际归属为第一类的实例被错误预测为第二类。
如有150个样本数据，预测为1,2,3类各为50个。分类结束后得到的混淆矩阵为：
、
每一行之和表示该类别的真实样本数量，每一列之和表示被预测为该类别的样本数量，第一行说明有43个属于第一类的样本被正确预测为了第一类，有两个属于第一类的样本被错误预测为了第二类。
分类模型的评估指标 原文链接：https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839
混淆矩阵是ROC曲线绘制的基础，同时它也是衡量分类型模型准确度中最基本，最直观，计算最简单的方法。
混淆矩阵是评判模型结果的指标，属于模型评估的一部分。此外，混淆矩阵多用于判断分类器（Classifier）的优劣，适用于分类型的数据模型，如分类树（Classification Tree）、逻辑回归（Logistic Regression）、线性判别分析（Linear Discriminant Analysis）等方法。
在分类型模型评判的指标中，常见的方法有如下三种：
混淆矩阵（也称误差矩阵，Confusion Matrix）ROC曲线AUC面积 以分类模型中最简单的二分类为例，对于这种问题，我们的模型最终需要判断样本的结果是0还是1，或者说是positive还是negative。
我们通过样本的采集，能够直接知道真实情况下，哪些数据结果是positive，哪些结果是negative。同时，我们通过用样本数据跑出分类型模型的结果，也可以知道模型认为这些数据哪些是positive，哪些是negative。
因此，我们就能得到这样四个基础指标，我称他们是一级指标（最底层的）：
真实值是positive，模型认为是positive的数量（True Positive=TP） 真实值是positive，模型认为是negative的数量（False Negative=FN）：这就是统计学上的第一类错误（Type I Error） 真实值是negative，模型认为是positive的数量（False Positive=FP）：这就是统计学上的第二类错误（Type II Error） 真实值是negative，模型认为是negative的数量（True Negative=TN） 将这四个指标一起呈现在表格中，就能得到如下这样一个矩阵，我们称它为混淆矩阵（Confusion Matrix）：
但是，混淆矩阵里面统计的是个数，有时候面对大量的数据，光凭算个数，很难衡量模型的优劣。因此混淆矩阵在基本的统计结果上又延伸了如下4个指标，我称他们是二级指标（通过最底层指标加减乘除得到的）：
准确率（Accuracy）—— 针对整个模型
精确率（Precision）
灵敏度（Sensitivity）：就是召回率（Recall）
特异度（Specificity）
我用表格的方式将这四种指标的定义、计算、理解进行了汇总：
通过上面的四个二级指标，可以将混淆矩阵中数量的结果转化为0-1之间的比率。便于进行标准化的衡量。
三级指标 这个指标叫做F1 Score。他的计算公式是：
其中，P代表Precision，R代表Recall。
F1-Score指标综合了Precision与Recall的产出的结果。F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。
混淆矩阵的实例 当分类问题是二分问题是，混淆矩阵可以用上面的方法计算。当分类的结果多于两种的时候，混淆矩阵同时适用。
一下面的混淆矩阵为例，我们的模型目的是为了预测样本是什么动物，这是我们的结果：
通过混淆矩阵，我们可以得到如下结论：
Accuracy
在总共66个动物中，我们一共预测对了10 &#43; 15 &#43; 20=45个样本，所以准确率（Accuracy）=45/66 = 68.2%。
以猫为例，我们可以将上面的图合并为二分问题：
Precision
所以，以猫为例，模型的结果告诉我们，66只动物里有13只是猫，但是其实这13只猫只有10只预测对了。模型认为是猫的13只动物里，有1条狗，两只猪。所以，Precision（猫）= 10/13 = 76.9%
Recall" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/54b41552d13ea9846fdcfdc29f799e5e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-12-18T10:51:59+08:00" />
<meta property="article:modified_time" content="2019-12-18T10:51:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">混淆矩阵 confusion matrices</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>百度百科</h4> 
<p>混淆矩阵也称误差矩阵，是表示精度评价的一种标准格式，用n行n列的矩阵形式来表示。具体评价指标有总体精度、制图精度、用户精度等，这些精度指标从不同的侧面反映了图像分类的精度。 [1]<a name="ref_%5B1%5D_2781781"> </a> 在人工智能中，混淆矩阵（confusion matrix）是可视化工具，特别用于<a href="https://baike.baidu.com/item/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/9820109" rel="nofollow">监督学习</a>，在<a href="https://baike.baidu.com/item/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/810193" rel="nofollow">无监督学习</a>一般叫做匹配矩阵。在图像精度评价中，主要用于比较分类结果和实际测得值，可以把分类结果的精度显示在一个混淆矩阵里面。混淆矩阵是通过将每个实测<a href="https://baike.baidu.com/item/%E5%83%8F%E5%85%83" rel="nofollow">像元</a>的位置和分类与分类图像中的相应位置和分类相比较计算的。</p> 
<p>混淆矩阵的每一列代表了预测类别，每一列的总数表示预测为该类别的数据的数目；每一行代表了数据的真实归属类别，每一行的数据总数表示该类别的数据实例的数目。每一列中的数值表示真实数据被预测为该类的数目：如下图，第一行第一列中的43表示有43个实际归属第一类的实例被预测为第一类，同理，第一行第二列的2表示有2个实际归属为第一类的实例被错误预测为第二类。</p> 
<p>如有150个样本数据，预测为1,2,3类各为50个。分类结束后得到的混淆矩阵为：</p> 
<p>                                                                       <img alt="" class="has" height="177" src="https://images2.imgbox.com/9c/1b/9uYLNCpL_o.png" width="221">、</p> 
<p>每一行之和表示该类别的真实样本数量，每一列之和表示被预测为该类别的样本数量，第一行说明有43个属于第一类的样本被正确预测为了第一类，有两个属于第一类的样本被错误预测为了第二类。</p> 
<h4>分类模型的评估指标</h4> 
<p><span style="color:#3399ea;">原文链接：https://blog.csdn.net/Orange_Spotty_Cat/article/details/80520839</span></p> 
<p>混淆矩阵是ROC曲线绘制的基础，同时它也是衡量分类型模型准确度中最基本，最直观，计算最简单的方法。</p> 
<p>混淆矩阵是评判模型结果的指标，属于模型评估的一部分。此外，混淆矩阵多用于判断分类器（Classifier）的优劣，适用于分类型的数据模型，如分类树（Classification Tree）、逻辑回归（Logistic Regression）、线性判别分析（Linear Discriminant Analysis）等方法。</p> 
<p>在分类型模型评判的指标中，常见的方法有如下三种：</p> 
<ol><li>混淆矩阵（也称误差矩阵，Confusion Matrix）</li><li>ROC曲线</li><li>AUC面积</li></ol> 
<p>以分类模型中最简单的二分类为例，对于这种问题，我们的模型最终需要判断样本的结果是0还是1，或者说是positive还是negative。</p> 
<p>我们通过样本的采集，能够直接知道真实情况下，哪些数据结果是positive，哪些结果是negative。同时，我们通过用样本数据跑出分类型模型的结果，也可以知道模型认为这些数据哪些是positive，哪些是negative。</p> 
<p>因此，我们就能得到这样四个基础指标，我称他们是一级指标（最底层的）：</p> 
<ul><li>    真实值是positive，模型认为是positive的数量（True Positive=TP）</li><li>    真实值是positive，模型认为是negative的数量（False Negative=FN）：这就是统计学上的第一类错误（Type I Error）</li><li>    真实值是negative，模型认为是positive的数量（False Positive=FP）：这就是统计学上的第二类错误（Type II Error）</li><li>    真实值是negative，模型认为是negative的数量（True Negative=TN）</li></ul> 
<p>将这四个指标一起呈现在表格中，就能得到如下这样一个矩阵，我们称它为混淆矩阵（Confusion Matrix）：<br>                                              <img alt="" class="has" height="181" src="https://images2.imgbox.com/e1/d7/nplHJ9yH_o.png" width="353"></p> 
<p>但是，混淆矩阵里面统计的是个数，有时候面对大量的数据，光凭算个数，很难衡量模型的优劣。因此混淆矩阵在基本的统计结果上又延伸了如下4个指标，我称他们是二级指标（通过最底层指标加减乘除得到的）：</p> 
<p>    准确率（Accuracy）—— 针对整个模型<br>     精确率（Precision）<br>     灵敏度（Sensitivity）：就是召回率（Recall）<br>     特异度（Specificity）</p> 
<p>我用表格的方式将这四种指标的定义、计算、理解进行了汇总：<br><img alt="" class="has" height="331" src="https://images2.imgbox.com/67/81/855mjLYA_o.png" width="793"></p> 
<p>通过上面的四个二级指标，可以将混淆矩阵中数量的结果转化为0-1之间的比率。便于进行标准化的衡量。</p> 
<h4>三级指标</h4> 
<p>这个指标叫做F1 Score。他的计算公式是：</p> 
<p><img alt="" class="has" height="118" src="https://images2.imgbox.com/52/f4/82or70CX_o.png" width="341"></p> 
<p>其中，P代表Precision，R代表Recall。</p> 
<p>F1-Score指标综合了Precision与Recall的产出的结果。F1-Score的取值范围从0到1的，1代表模型的输出最好，0代表模型的输出结果最差。</p> 
<h3><strong>混淆矩阵的实例</strong></h3> 
<p>当分类问题是二分问题是，混淆矩阵可以用上面的方法计算。当分类的结果多于两种的时候，混淆矩阵同时适用。</p> 
<p>一下面的混淆矩阵为例，我们的模型目的是为了预测样本是什么动物，这是我们的结果：</p> 
<p>                                             <img alt="" class="has" height="226" src="https://images2.imgbox.com/34/cf/jeiK8EH5_o.png" width="441"></p> 
<p>通过混淆矩阵，我们可以得到如下结论：</p> 
<p><strong>Accuracy</strong></p> 
<p>在总共66个动物中，我们一共预测对了10 + 15 + 20=45个样本，所以准确率（Accuracy）=45/66 = 68.2%。</p> 
<p>以猫为例，我们可以将上面的图合并为二分问题：</p> 
<p>                                                             <img alt="" class="has" height="181" src="https://images2.imgbox.com/d3/65/CVC2NCcU_o.png" width="353"></p> 
<p>Precision</p> 
<p>所以，以猫为例，模型的结果告诉我们，66只动物里有13只是猫，但是其实这13只猫只有10只预测对了。模型认为是猫的13只动物里，有1条狗，两只猪。所以，Precision（猫）= 10/13 = 76.9%</p> 
<p>Recall</p> 
<p>以猫为例，在总共18只真猫中，我们的模型认为里面只有10只是猫，剩下的3只是狗，5只都是猪。这5只八成是橘猫，能理解。所以，Recall（猫）= 10/18 = 55.6%</p> 
<p>Specificity</p> 
<p>以猫为例，在总共48只不是猫的动物中，模型认为有45只不是猫。所以，Specificity（猫）= 45/48 = 93.8%。</p> 
<p>虽然在45只动物里，模型依然认为错判了6只狗与4只猫，但是从猫的角度而言，模型的判断是没有错的。</p> 
<p>（这里是参见了Wikipedia，Confusion Matrix的解释,https://en.wikipedia.org/wiki/Confusion_matrix）</p> 
<p>F1-Score</p> 
<p>通过公式，可以计算出，对猫而言，F1-Score=（2 * 0.769 *  0.556）/（ 0.769 +  0.556） = 64.54%</p> 
<p>同样，我们也可以分别计算猪与狗各自的二级指标与三级指标值。</p> 
<h4>Python代码实现混淆矩阵</h4> 
<p><span style="color:#3399ea;">from：</span><a href="https://baijiahao.baidu.com/s?id=1619821729031070174&amp;wfr=spider&amp;for=pc" rel="nofollow"><span style="color:#3399ea;">https://baijiahao.baidu.com/s?id=1619821729031070174&amp;wfr=spider&amp;for=pc</span></a></p> 
<p>Python中的sklearn库提供了相应的方法来输出矩阵数据，非常方便，函数如下：</p> 
<p>sklearn.metrics.confusion_matrix(y_true, y_pred, labels=None, sample_weight=None)</p> 
<p>其中，y_true:是样本真实分类结果，y_pred 是样本预测分类结果 ，labels是所给出的类别，通过这个可对类别进行选择 ，sample_weight 是样本权重。这里我们用代码演示三分类问题混淆矩阵（这里我们用confusion_matrix生成矩阵数据，然后用seaborn的热度图绘制出混淆矩阵数据），如下：</p> 
<pre class="has"><code>#导入依赖包
import seaborn as sns;from sklearn.metrics 
import confusion_matrix
import matplotlib.pyplot as pltsns.set()
y_true = ["cat", "dog", "cat", "cat", "dog", "rebit"] 
y_pred = ["dog", "dog", "rebit", "cat", "dog", "cat"]
C2= confusion_matrix(y_true, y_pred, 
labels=["dog", "rebit", "cat"])
sns.heatmap(C2,annot=True)</code></pre> 
<p>                                   <img alt="" class="has" height="349" src="https://images2.imgbox.com/de/05/JVIzegRq_o.png" width="500"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5a89d849422cc714d931726217eb869c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">如何实现统计numpy列表中各元素的个数</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2d9e7410695ef197b5b13c452bfe50a9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">centos 使用 scl 软件集</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>