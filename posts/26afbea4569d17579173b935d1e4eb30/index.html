<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>轻量化神经网络整理 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="轻量化神经网络整理" />
<meta property="og:description" content="轻量化网络整理 基本的知识储备一、人工结构轻量化设计1.1 mobileNet V1，V2结构1.1.1 V1：Depthwise Separable Convolution1.1.2 V2：1、 linear Bottlennecks 1.2 shuffleNet结构1.2.1 V1：逐点分组卷积（point group convolution）和通道洗牌机制（channel shuffle）1.2.2 V2：停止使用分组卷积，使用Channel split 二、网络学习结构轻量化设计2.1 MnasNet2.2 NetAdapt2.3 MobileNetV3 三、减少特征层的冗余参考博客 基本的知识储备 CNN（卷积神经网络）的参数，计算量，FLOPs，Multi-Add概念详解：
Multi-Add： 卷积神经网络的卷积过程包含两个操作 乘法操作和加法操作
CNN参数：
卷积的参数即在一个卷积窗口内的计算个数也可以理解为一个卷积结果元素产生的运算操作。以331的输入被33卷积核卷积，参数有331个乘法操作和33-1个加法操作一共有331&#43;33-1=17个参数。
拓展到CNN参数：
（KhKwCi &#43; KhKwCi - 1） Co = （2KhKwCi - 1） Co （没有偏置bias的情况）
其中 Kh：卷积核高 Kw：卷积核宽 Ci：卷积核通道数 Co：输出通道数（卷积核的个数）
有偏置项：
（KhKwCi &#43; KhKwCI - 1）* Co &#43; Co = 2KhKw*Co
**CNN的计算量：**对所有输出特征图的所有元素的求和
CNN参数 * Ho * Wo
FLOPS： 注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/26afbea4569d17579173b935d1e4eb30/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-05T21:15:11+08:00" />
<meta property="article:modified_time" content="2022-04-05T21:15:11+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">轻量化神经网络整理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>轻量化网络整理</h4> 
 <ul><li><a href="#_1" rel="nofollow">基本的知识储备</a></li><li><a href="#_25" rel="nofollow">一、人工结构轻量化设计</a></li><li><ul><li><a href="#11_mobileNet_V1V2_26" rel="nofollow">1.1 mobileNet V1，V2结构</a></li><li><ul><li><a href="#111_V1Depthwise_Separable_Convolution_27" rel="nofollow">1.1.1 V1：Depthwise Separable Convolution</a></li><li><a href="#112_V21%09linear_Bottlennecks_33" rel="nofollow">1.1.2 V2：1、 linear Bottlennecks</a></li></ul> 
   </li><li><a href="#12_shuffleNet_41" rel="nofollow">1.2 shuffleNet结构</a></li><li><ul><li><a href="#121_V1point_group_convolutionchannel_shuffle_42" rel="nofollow">1.2.1 V1：逐点分组卷积（point group convolution）和通道洗牌机制（channel shuffle）</a></li><li><a href="#122_V2Channel_split_46" rel="nofollow">1.2.2 V2：停止使用分组卷积，使用Channel split</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_63" rel="nofollow">二、网络学习结构轻量化设计</a></li><li><ul><li><a href="#21_MnasNet_65" rel="nofollow">2.1 MnasNet</a></li><li><a href="#22_NetAdapt_80" rel="nofollow">2.2 NetAdapt</a></li><li><a href="#23_MobileNetV3_87" rel="nofollow">2.3 MobileNetV3</a></li></ul> 
  </li><li><a href="#_91" rel="nofollow">三、减少特征层的冗余</a></li><li><a href="#_99" rel="nofollow">参考博客</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>基本的知识储备</h2> 
<p>CNN（卷积神经网络）的参数，计算量，FLOPs，Multi-Add概念详解：<br> <strong>Multi-Add：</strong> 卷积神经网络的卷积过程包含两个操作 乘法操作和加法操作<br> <strong>CNN参数：</strong><br> 卷积的参数即在一个卷积窗口内的计算个数也可以理解为一个卷积结果元素产生的运算操作。以3<em>3</em>1的输入被3<em>3卷积核卷积，参数有3</em>3<em>1个乘法操作和3</em>3-1个加法操作一共有3<em>3</em>1+3<em>3-1=17个参数。<br> <strong>拓展到CNN参数：</strong><br> （Kh</em>Kw<em>Ci + Kh</em>Kw<em>Ci - 1）</em> Co = （2<em>Kh</em>Kw<em>Ci - 1）</em> Co （没有偏置bias的情况）<br> 其中 Kh：卷积核高 Kw：卷积核宽 Ci：卷积核通道数 Co：输出通道数（卷积核的个数）<br> 有偏置项：<br> （Kh<em>Kw</em>Ci + Kh<em>Kw</em>CI - 1）* Co + Co = 2<em>Kh</em>Kw*Co</p> 
<p>**CNN的计算量：**对所有输出特征图的所有元素的求和<br> CNN参数 * Ho * Wo</p> 
<p><strong>FLOPS：</strong> 注意全大写，是floating point operations per second的缩写，意指每秒浮点运算次数，理解为计算速度。是一个衡量硬件性能的指标。</p> 
<p><strong>FLOPs：</strong> 注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数，理解为计算量。可以用来衡量算法/模型的复杂度。<br> 这里FLOPs就等于CNN的计算量。<br> <strong>常规卷积的参数量：</strong><br> 假设卷积核尺寸 ：D<sub>k</sub> × D<sub>k</sub> × M × N<br> D<sub>k</sub> 是空间尺寸，M是输入通道，N输出通道，D<sub>F</sub> 输出特征图尺寸<br> 该卷积过程计算量：<br> D<sub>k</sub> × D<sub>k</sub> × M × N × D<sub>F</sub> × D<sub>F</sub></p> 
<h2><a id="_25"></a>一、人工结构轻量化设计</h2> 
<h3><a id="11_mobileNet_V1V2_26"></a>1.1 mobileNet V1，V2结构</h3> 
<h4><a id="111_V1Depthwise_Separable_Convolution_27"></a>1.1.1 V1：Depthwise Separable Convolution</h4> 
<p>论文：MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications<br> 将传统卷积过程分两步实现：深度卷积（Depthwise Convolution）和逐点卷积（Pointwise Convolution）。<br> <img src="https://images2.imgbox.com/b5/83/LgS0mUav_o.png" alt="在这里插入图片描述"><br> 深度可分离卷积的计算量 = 分离卷积 + 逐点卷积 = D<sub>k</sub> × D<sub>k</sub> × M × D<sub>F</sub> × D<sub>F</sub> + M × N × D<sub>F</sub> × D<sub>F</sub></p> 
<h4><a id="112_V21%09linear_Bottlennecks_33"></a>1.1.2 V2：1、 linear Bottlennecks</h4> 
<p>论文：MobileNetV2: Inverted Residuals and Linear Bottlenecks<br> <strong>linear Bottlennecks:</strong> 在深度可分离卷积前后增加卷积机构，在前端增加PW层，将输出PW曾后的ReLU层更改为线性层。前端增加PW层的目的是为了提升通道数，因为DW卷积本身没有改变通道数的能力，在输入通道数少的情况下，DW也只能对少的通道进行操作，这样回限制后面抽取特征的能力。<br> <img src="https://images2.imgbox.com/c6/1d/hxy2SdVt_o.png" alt="在这里插入图片描述"><br> <strong>Inverted residual block</strong>是输入通道数很少，1<em>1卷积数据扩张，再经过3</em>3DW卷积进行特征抽取，最后1*1卷积数据升维，整个过程：输入特征 -&gt; 扩张 -&gt; 提取特征 -&gt; 压缩 。<br> <img src="https://images2.imgbox.com/6f/67/bqGMDD9N_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="12_shuffleNet_41"></a>1.2 shuffleNet结构</h3> 
<h4><a id="121_V1point_group_convolutionchannel_shuffle_42"></a>1.2.1 V1：逐点分组卷积（point group convolution）和通道洗牌机制（channel shuffle）</h4> 
<p>论文：ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices<br> <img src="https://images2.imgbox.com/91/13/H51cpehj_o.png" alt="在这里插入图片描述"><br> 分组卷积从通道层面减少计算量，但是切断组件的特征联系。通道洗牌机制将不同分组之间的卷积结果进行交换，缓解了该问题。</p> 
<h4><a id="122_V2Channel_split_46"></a>1.2.2 V2：停止使用分组卷积，使用Channel split</h4> 
<p>论文：ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design<br> <img src="https://images2.imgbox.com/29/89/CkCdJ3Pj_o.png" alt="在这里插入图片描述"><br> V2进行的结构更改，遵循实验得出的四个网络轻量化经验：<br> 1）use "balanced\ convolutions (equal channel width);<br> 平衡通道数<br> 2）be aware of the cost of using group convolution;<br> 分组卷积成本<br> 3）reduce the degree of fragmentation;<br> 减少琐碎化程度<br> 4）reduce element-wiseoperations.<br> 减少逐个元素操作<br> 因此，V2只进行了一次分组，中间过程使用了MobileV2中的线性瓶颈结构。</p> 
<p>以该网络为主干网络，对二阶段目标检测程序进行轻量化。<strong>2019 ThunderNet: Towards Real-time Generic Object Detection。</strong> 在ARM上实现了实时检测</p> 
<h2><a id="_63"></a>二、网络学习结构轻量化设计</h2> 
<p>因为博主的研究方向对强化学习涉猎不多，对具体实现步骤不了解，因此只对最近碰到的论文中的想法进行科普式展开。</p> 
<h3><a id="21_MnasNet_65"></a>2.1 MnasNet</h3> 
<p>论文：MnasNet: Platform-Aware Neural Architecture Search for Mobile<br> <img src="https://images2.imgbox.com/98/9c/t1zEphOv_o.png" alt="在这里插入图片描述"><br> 轻量化整体思路，controller生成网络模型，训练器训练提升准确度，在移动平台测试延时，最后返回得分。<br> <img src="https://images2.imgbox.com/4e/fe/xznnTz07_o.png" alt="contorller中moduels生成思路"><br> 图中显示了搜索空间的基线结构。我们将CNN模型划分为一系列预定义的块，逐渐降低输入分辨率，并像许多CNN模型一样增加过滤器大小。每个块都有一组相同的层，它们的操作和连接由每个块子搜索空间决定。具体来说，块i的子搜索空间由以下选项组成<br> •卷积运算ConvOp:常规conv (conv)、深度conv (dconv)、移动倒瓶颈conv。<br> 卷积内核大小:3x3, 5x5。<br> •挤压-激励比SERatio: 0,0.25。<br> •跳过ops （SkipOp）:池，身份剩余，或没有跳过。<br> •输出滤波器尺寸Fi。<br> •每个块Ni的层数。<br> 文中我们使用MobileNetV2作为参考对所有搜索选项进行离散化。</p> 
<p>但是该方法在ImageNet训练集训练时，Controller生成8000个模型，最有只有15个模型跑完ImageNet训练。</p> 
<h3><a id="22_NetAdapt_80"></a>2.2 NetAdapt</h3> 
<p>论文：NetAdapt: Platform-Aware Neural Network Adaptation for Mobile Applications<br> <img src="https://images2.imgbox.com/e2/a0/SuoG7Kyq_o.png" alt="在这里插入图片描述"><br> 1）step1：按照给定的资源约束选择当前层需要剪掉的filter数量，文章中是基于在实验平台上实验得到的结果进行选择剪裁的数量，在对应的filter被剪裁掉之后与之对应后续层的channel数也应做相应的修改；<br> 2）step2：在确定好需要剪裁掉的filter数量之后就需要确定那些不重要的filter需要被剪裁掉。对此，文章使用的重要性选择方式是使用上一轮迭代产生的梯度信息，将其L2-norm，之后按照其值选择最不重要的几个，将这些filter裁掉。除了这种基于梯度的方法还可以使用基于特征图间相互作用的方法，例如使用Lasso回归。<br> 3）step3：对当前裁剪的层进行short-term的finetune使其恢复精度。在所有的层完成裁剪之后选择其满足资源需求且finetune之后网络性能最好的一个；<br> 4）step4：判断当前迭代论述的模型是否满足算法预先设计的资源需求限制，若满足则对模型进行long-term的finetune得到最后的结果；</p> 
<h3><a id="23_MobileNetV3_87"></a>2.3 MobileNetV3</h3> 
<p>论文：Searching for MobileNetV3<br> V3：在MobileNet V2的基础上，使用MnasNet进行全局的网络结构优化。然后，使用NetAdapt优化每层的滤波器个数。</p> 
<h2><a id="_91"></a>三、减少特征层的冗余</h2> 
<p>论文：GhostNet: More Features from Cheap Operations<br> GhostNet：针对特征层冗余问题<br> <img src="https://images2.imgbox.com/61/95/eElKCYh0_o.png" alt="在这里插入图片描述"><br> 所谓冗余指特征图中有很多相似的特征图，因此引出思路，可否用一小部分特征图通过线性变换去生成特征图。论文中的线性操作是采用的卷积。<br> <img src="https://images2.imgbox.com/4b/9f/Hp9sXG0s_o.png" alt="在这里插入图片描述"><br> 该方法的计算量：<br> <img src="https://images2.imgbox.com/92/5c/Cz4LDHve_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_99"></a>参考博客</h2> 
<p><a href="https://blog.csdn.net/YOULANSHENGMENG/article/details/121159448">深度学习网络结构</a><br> <a href="https://blog.csdn.net/Julialove102123/article/details/80042929?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164670409016780274146315%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164670409016780274146315&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~sobaiduend~default-2-80042929.nonecase&amp;utm_term=Linear%20Bottlenecks&amp;spm=1018.2226.3001.4450">MobileNet V2 讲解</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e79fcf442f00f466c0daf747ed28f7d0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">给定一个字符串str，给定一个字符串类型的数组arr，/出现的字符都是小写英文arr每一个字符串，/代表一张贴纸，你可以把单个字符剪开使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bb2f6da072af6476f9d2d25013615685/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">接入alipay-sdk</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>