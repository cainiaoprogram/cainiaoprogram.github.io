<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>金融风控实战——迁移学习 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="金融风控实战——迁移学习" />
<meta property="og:description" content="迁移学习 为什么做迁移？
源域样本和目标域样本分布有区别，目标域样本量又不够。
场景 思考我们平时建模会使用到迁移学习的一些场景：
1）新开了某个消费分期的场景只有少量样本，需要用其他场景的数据进行建模；
2）业务被迫停止3个月后项目重启，大部分训练样本比较老旧，新的训练样本又不够；
3）在某个新的国家开展了类似国内的业务，因为国情不同，显然部分特征分布是不同的；
主要任务 缩小边缘分布之间和条件分布下的差异。
几个基本概念：
Domain（域）：包括两部分：feature space（特征空间）和probability（概率）。所以当domain不同的时候，分两种情况。可能是feature space不同，也可能是feature space一样但probability不同；
Task（任务）：包括两部分： label space（标记空间）和objective predictive function（目标预测函数）。同理，当task不同的时候，也分两种情况。可能是label space不同，也可能是label space一样但function不同；
Source（源）是用于训练模型的域/任务；
Targe（任务）是要用前者的模型对自己的数据进行预测/分类/聚类等机器学习任务的域/任务。
通常我们说的迁移学习就是指将知识从源域迁移到目标域的过程。
比如我们有大量英短银渐层的图片，和少量美短起司的照片，想训练一个判别当前的猫是不是美短起司的学习器。如果我们用英短银渐层图片来作为样本，显然训练的模型是不能用来判别美短起司的，用美短起司的样本来训练，样本量又太小。这时候我们可能会使用英短银渐层来训练一个卷积神经网络，然后将这个网络的中间结构取出来作为目标模型的前半部分，然后在少量的美短起司的样本上再继续学习后面的几层网络（再训练、再学习）。熟悉卷积神经网络的同学可能知道，CNN的前几层主要学习的是轮廓和局部形状等共性特征。这样通过前面的学习，我们就知道了猫咪的共性，再通过对起司的学习得到细节上的差异。
然后在提迁移学习前，首先说另一种学习方法，叫做增量学习。
增量学习主要关注的是灾难性遗忘（Catastrophic forgetting），平衡新知识与旧知识之间的关系。但我们可以用它来模拟神经网络中的finetune.
Xgboost提供两种增量训练的方式：
一种是在当前迭代树的基础上增加新树，原树不变;（层迁移，两只小猫咪的例子）另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。 （fine—tuning） 增量学习有什么用呢？
我们可以仿照神经网络中的基于模型的迁移学习，先用一部分样本训练前几棵树，然后用新的样本学习后面的树，通常我们可能用源域与目标域的混合数据训练前几棵树，以得到更好的表达能力，最后用目标域的数据训练后面几棵树。
import xgboost as xgb from sklearn.datasets import load_digits # 训练数据 xgb_params_01 = {} digits_2class = load_digits(2) X_2class = digits_2class[&#39;data&#39;] y_2class = digits_2class[&#39;target&#39;] dtrain_2class = xgb.DMatrix(X_2class, label=y_2class) gbdt_03 = xgb.train(xgb_params_01, dtrain_2class, num_boost_round=3) # 训练三棵树的模型 gbdt_03a = xgb." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b2fc158ec67d3bbc164275ceb60665cb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-10T21:57:51+08:00" />
<meta property="article:modified_time" content="2022-03-10T21:57:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">金融风控实战——迁移学习</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h4><a id="_0"></a>迁移学习</h4> 
<p><strong>为什么做迁移？</strong></p> 
<p>源域样本和目标域样本分布有区别，目标域样本量又不够。</p> 
<h5><a id="_5"></a>场景</h5> 
<p>思考我们平时建模会使用到迁移学习的一些场景：</p> 
<p>1）新开了某个消费分期的场景只有少量样本，需要用其他场景的数据进行建模；<br> 2）业务被迫停止3个月后项目重启，大部分训练样本比较老旧，新的训练样本又不够；<br> 3）在某个新的国家开展了类似国内的业务，因为国情不同，显然部分特征分布是不同的；</p> 
<h5><a id="_12"></a>主要任务</h5> 
<p><mark><strong>缩小边缘分布之间和条件分布下的差异。</strong></mark><br> <img src="https://images2.imgbox.com/1b/8d/C953UBav_o.jpg" alt="在这里插入图片描述"></p> 
<p>几个基本概念：</p> 
<ul><li> <p>Domain（域）：包括两部分：feature space（特征空间）和probability（概率）。所以当domain不同的时候，分两种情况。可能是feature space不同，也可能是feature space一样但probability不同；</p> </li><li> <p>Task（任务）：包括两部分： label space（标记空间）和objective predictive function（目标预测函数）。同理，当task不同的时候，也分两种情况。可能是label space不同，也可能是label space一样但function不同；</p> </li><li> <p>Source（源）是用于训练模型的域/任务；</p> </li><li> <p>Targe（任务）是要用前者的模型对自己的数据进行预测/分类/聚类等机器学习任务的域/任务。</p> </li></ul> 
<p>通常我们说的<strong>迁移学习</strong>就是指将知识从<strong>源域</strong>迁移到<strong>目标域</strong>的过程。</p> 
<p>比如我们有大量英短银渐层的图片，和少量美短起司的照片，想训练一个判别当前的猫是不是美短起司的学习器。如果我们用英短银渐层图片来作为样本，显然训练的模型是不能用来判别美短起司的，用美短起司的样本来训练，样本量又太小。<mark>这时候我们可能会使用英短银渐层来训练一个卷积神经网络，然后将这个网络的中间结构取出来作为目标模型的前半部分，然后在少量的美短起司的样本上再继续学习后面的几层网络（再训练、再学习）</mark>。熟悉卷积神经网络的同学可能知道，CNN的前几层主要学习的是轮廓和局部形状等共性特征。这样通过前面的学习，我们就知道了猫咪的共性，再通过对起司的学习得到细节上的差异。</p> 
<p>然后在提迁移学习前，首先说另一种学习方法，叫做<strong>增量学习</strong>。</p> 
<p>增量学习主要关注的是灾难性遗忘（Catastrophic forgetting），平衡新知识与旧知识之间的关系。但我们可以用它来模拟神经网络中的finetune.</p> 
<p>Xgboost提供两种增量训练的方式：</p> 
<ul><li>一种是在当前迭代树的基础上增加新树，原树不变;（层迁移，两只小猫咪的例子）</li><li>另一种是当前迭代树结构不变，重新计算叶节点权重，同时也可增加新树。 （fine—tuning）</li></ul> 
<p>增量学习有什么用呢？</p> 
<p>我们可以仿照神经网络中的基于模型的迁移学习，先用一部分样本训练前几棵树，然后用新的样本学习后面的树，通常我们可能用源域与目标域的混合数据训练前几棵树，以得到更好的表达能力，最后用目标域的数据训练后面几棵树。</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> xgboost as xgb
from sklearn.datasets <span class="token function">import</span> load_digits <span class="token comment"># 训练数据</span>
 
xgb_params_01 <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
 
digits_2class <span class="token operator">=</span> load_digits<span class="token punctuation">(</span>2<span class="token punctuation">)</span>
X_2class <span class="token operator">=</span> digits_2class<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span>
y_2class <span class="token operator">=</span> digits_2class<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span>
 
dtrain_2class <span class="token operator">=</span> xgb.DMatrix<span class="token punctuation">(</span>X_2class, label<span class="token operator">=</span>y_2class<span class="token punctuation">)</span>

gbdt_03 <span class="token operator">=</span> xgb.train<span class="token punctuation">(</span>xgb_params_01, dtrain_2class, num_boost_round<span class="token operator">=</span>3<span class="token punctuation">)</span> <span class="token comment"># 训练三棵树的模型</span>

gbdt_03a <span class="token operator">=</span> xgb.train<span class="token punctuation">(</span>xgb_params_01, dtrain_2class, num_boost_round<span class="token operator">=</span>7, xgb_model<span class="token operator">=</span>gbdt_03<span class="token punctuation">)</span> <span class="token comment"># 在原模型基础上继续训练</span>
</code></pre> 
<h5><a id="_61"></a>深度学习常见的迁移方法</h5> 
<ul><li>模型再优化（fine—tuning，小量样本调优，会造成过拟合，我们就会做一些迁移的手段，比如说保守训练，先用原模型的参数作为基础继续再用新的数据集做训练，这样我们就能在这些参数上面加一些正则化，保证参数的改变不会太大）</li><li>层迁移（两只小猫咪）</li><li>域对抗迁移（两个domain，M1国内（大量的样本）、M2国外（少量样本），我们希望模型最大化label准确率，最小化domain分类准确率，我希望模型能区分好人还是坏人，而不能区分这个人属于M1的域还是M2的域）<br> <img src="https://images2.imgbox.com/6b/31/9cIiw726_o.png" alt="在这里插入图片描述"><br> M1国内有label，M2国外无label。M1+M2=TM，TM打来自于M1还是M2的标签</li></ul> 
<p>目前有突破的迁移学习算法基本上可以概括这几类：</p> 
<h5><a id="___70"></a>基于实例的迁移学习方法 （可以保留模型的解释性，本门课的重点）</h5> 
<ul><li>代表有Dai等人提出的基于实例的 <mark>TrAdaBoost 迁移学习算法</mark>。<mark>当目标域</mark>中的样本被错误地分类之后，可以认为这个样本是很难分类的，因此增大这个样本的权重，在下一次的训练中这个样本所占的比重变大 。如果<mark>源域</mark>中的一个样本被错误地分类了，可以认为这个样本对于目标数据是不同的，因此降低这个样本的权重，降低这个样本在分类器中所占的比重。</li></ul> 
<h5><a id="_73"></a>基于特征的迁移学习方法</h5> 
<p>可以分为<strong>基于特征选择的迁移学习方法</strong>和<strong>基于特征映射的迁移学习方法</strong>。</p> 
<ul><li> <p>基于特征选择的迁移学习方法是识别出源领域与目标领域中共有的特征表示，然后利用这些特征进行知识迁移。</p> </li><li> <p>基于特征映射的迁移学习方法是把各个领域的数据从原始高维特征空间映射到低维特征空间，在该低维空间下，源领域数据与目标领域数据拥有相同的分布。这样就可以利用低维空间表示的有标签的源领域样本数据训练分类器，对目标测试数据进行预测。</p> </li></ul> 
<h5><a id="_81"></a>基于模型的迁移学习方法</h5> 
<ul><li>由源域学习到的模型应用到目标域上，再根据目标域学习新的模型。该方法首先针对已有标记的数据，利用决策树构建鲁棒性的行为识别模型，然后针对无标定数据，利用K-Means聚类等方法寻找最优化的标定参数。比如 TRCNN等</li></ul> 
<p>我们平时用的最多的就是基于实例的迁移学习方法，今天主要围绕样本的选择上做展开。</p> 
<p>下面介绍几个统计概念</p> 
<h5><a id="joint_distribution_89"></a>联合分布（joint distribution）</h5> 
<p>很多情况下，我们对于几个变量同时的取值有关问题感兴趣，例如我们需要知道事件“ lntellegence = high 且Grade＝ A”的概率。分析这样的事件，则需要考虑两个随机变量的联合分布（joint distribution）。下图为联合分布的一个例子。</p> 
<pre><code class="prism language-bash">from IPython.display <span class="token function">import</span> Image
Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/1.png'</span>, width<span class="token operator">=</span>600<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/28/12/ecpQyEoz_o.png" alt="在这里插入图片描述"><br> 上图表示了随机变量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         I 
        
       
         , 
        
       
         D 
        
       
         , 
        
       
         G 
        
       
      
        I,D,G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault">G</span></span></span></span></span>的一个联合分布，其中包含3个变量，分别是：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         I 
        
       
      
        I 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span></span></span></span></span>（学生智力，有0和1两个取值）、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         D 
        
       
      
        D 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span></span></span></span></span>（试卷难度，有0和1两个取值）、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         G 
        
       
      
        G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault">G</span></span></span></span></span>（成绩等级，有1、2、3三个取值）。故而这三个离散的随机变量共有 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         2 
        
       
         × 
        
       
         2 
        
       
         × 
        
       
         3 
        
       
         = 
        
       
         12 
        
       
      
        2×2×3=12 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">3</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">1</span><span class="mord">2</span></span></span></span></span>种联合分布状态。</p> 
<p>上表中我们可以读出系统取值为这 12 个联合分布状态中任一个的概率，例如：<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         P 
        
       
         ( 
        
       
         I 
        
       
         = 
        
       
         0 
        
       
         , 
        
       
         D 
        
       
         = 
        
       
         0 
        
       
         , 
        
       
         G 
        
       
         = 
        
       
         1 
        
       
         ) 
        
       
         = 
        
       
         0.126. 
        
       
      
        P(I=0,D=0,G=1)=0.126. 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.02778em;">D</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.87777em; vertical-align: -0.19444em;"></span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault">G</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span><span class="mord">6</span><span class="mord">.</span></span></span></span></span></p> 
<h5><a id="_102"></a>条件分布</h5> 
<p>当对于一组随机变量，考虑其中某些变量取值特定值时，其余变量的分布是一种条件分布问题。</p> 
<p>可以看到，条件分布率就是在边缘分布率的基础上都加上“另一个随机变量取定某值”这个条件。<br> 简单来说，对于二纬离散随机变量有:</p> 
<p><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          ( 
         
        
          X 
         
        
          = 
         
         
         
           x 
          
         
           i 
          
         
        
          ∣ 
         
        
          Y 
         
        
          = 
         
         
         
           y 
          
         
           j 
          
         
        
          ) 
         
        
          = 
         
         
          
          
            P 
           
          
            ( 
           
          
            X 
           
          
            = 
           
           
           
             x 
            
           
             i 
            
           
          
            , 
           
          
            Y 
           
          
            = 
           
           
           
             y 
            
           
             j 
            
           
          
            ) 
           
          
          
          
            P 
           
          
            ( 
           
          
            Y 
           
          
            = 
           
           
           
             y 
            
           
             j 
            
           
          
            ) 
           
          
         
        
       
         P(X=x_i|Y=y_j)=\frac{P(X=x_i,Y=y_j)}{P(Y=y_j)} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1.03611em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 2.39911em; vertical-align: -0.972108em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.427em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord"><span class="mord mathdefault">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.166667em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.972108em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p> 
<p>为在 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Y 
        
       
         = 
        
        
        
          y 
         
        
          j 
         
        
       
      
        Y=y_j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right: 0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.03588em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right: 0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em;"><span class=""></span></span></span></span></span></span></span></span></span></span> 条件下 X 的条件分布率. （其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em;"></span><span class="mord mathdefault">i</span></span></span></span></span>为固定的），也称作该联合分布在<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Y 
        
       
      
        Y 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.22222em;">Y</span></span></span></span></span>上的条件分布。</p> 
<p>回到 3.2 中例子来看，下图中表是概率的联合分布，表中随便去掉所有包含某个值的行，就能对分布表进行缩减。</p> 
<p>例如可以去掉所有 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         G 
        
       
      
        G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault">G</span></span></span></span></span> 不为 1 的行，这样就只剩下了 1、4、7、10 行，这样他们的概率之和就不为 1 了，所以需要重新标准化（Renormalization），从而推得原联合分布在 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         G 
        
       
      
        G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault">G</span></span></span></span></span> 上的条件分布4。如图为推导过程。</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/2.png'</span>, width<span class="token operator">=</span>600<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/73/83/tV1e6C7M_o.png" alt="在这里插入图片描述"><br> 剔除无关取值（<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         G 
        
       
      
        G 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault">G</span></span></span></span></span> 不为 1 的行）</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/3.png'</span>, width<span class="token operator">=</span>600<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/c1/9e/amFKqt6U_o.png" alt="在这里插入图片描述"><br> 标准化得到的值</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/4.png'</span>, width<span class="token operator">=</span>600<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/be/b0/bfrErhGQ_o.png" alt="在这里插入图片描述"><br> 即得到之前的联合分布在变量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         G 
        
       
         r 
        
       
         a 
        
       
         d 
        
       
         e 
        
       
         ( 
        
       
         g 
        
       
         ) 
        
       
      
        Grade(g) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathdefault">G</span><span class="mord mathdefault" style="margin-right: 0.02778em;">r</span><span class="mord mathdefault">a</span><span class="mord mathdefault">d</span><span class="mord mathdefault">e</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.03588em;">g</span><span class="mclose">)</span></span></span></span></span>上的条件分布为上图右边的表格。</p> 
<p>反之也可以把所有含有某个值得行相加，这就是接下来要讲的边缘化（Marginalization）。由此可得上图中联合分布在变量 Ｄ 上的边缘分布如下图右表。</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/5.png'</span>, width<span class="token operator">=</span>600<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/df/e8/Agxf0s50_o.png" alt="在这里插入图片描述"></p> 
<h5><a id="_141"></a>边缘分布</h5> 
<p>一旦定义了随机变量，我们就可以在能够用 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         X 
        
       
      
        X 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span></span></span></span></span> 描述的事件上考虑分布。这个分布通常称为随机变量 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         X 
        
       
      
        X 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span></span></span></span></span> 的边缘分布（marginal distribution) ,记为 P(X) . 这时单独只考虑 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         X 
        
       
      
        X 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">X</span></span></span></span></span> 的取值，与其它随机变量取什么值的概率无关了。</p> 
<p>例如，3.2 中联合分布例子里，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         I 
        
       
      
        I 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em;"></span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span></span></span></span></span> 的边缘分布为：</p> 
<p><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         　 
        
       
         　 
        
       
         P 
        
       
         ( 
        
       
         I 
        
       
         = 
        
       
         0 
        
       
         ) 
        
       
         = 
        
       
         0.126 
        
       
         + 
        
       
         0.168 
        
       
         + 
        
       
         0.126 
        
       
         + 
        
       
         0.009 
        
       
         + 
        
       
         0.045 
        
       
         + 
        
       
         0.126 
        
       
      
        　　P(I=0)=0.126+0.168+0.126+0.009+0.045+0.126 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">0</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">6</span><span class="mord">8</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">9</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">4</span><span class="mord">5</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">1</span><span class="mord">2</span><span class="mord">6</span></span></span></span></span><br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         　 
        
       
         　 
        
       
         P 
        
       
         ( 
        
       
         I 
        
       
         = 
        
       
         1 
        
       
         ) 
        
       
         = 
        
       
         0.252 
        
       
         + 
        
       
         0.0224 
        
       
         + 
        
       
         0.0056 
        
       
         + 
        
       
         0.06 
        
       
         + 
        
       
         0.036 
        
       
         + 
        
       
         0.024 
        
       
      
        　　P(I=1)=0.252+0.0224+0.0056+0.06+0.036+0.024 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mord">2</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">5</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">3</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span></span></span></span></span></p> 
<h5><a id="_149"></a>独立同分布</h5> 
<p>我们建模的时候一直在强调<strong>独立同分布</strong>，那么什么叫 <strong>独立同分布</strong>？</p> 
<p>独立同分布即指变量均服从同一种分布,并且变量之间是相互独立的（在多数情况下其实是不满足的,但往往选择忽略并不紧密的联系）。例如随机变量X1和X2，两个变量独立即指X1的出现并不影响X2，同理X2的出现并不影响X1，并且X1和X2所在的样本集具有相同的分布形状和分布参数。</p> 
<p>对离散随机变量具有相同的分布律，对连续随机变量则有相同的概率密度函数，有着相同的分布函数，相同的期望和方差。<br> <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         　 
        
       
         　 
        
       
         P 
        
       
         ( 
        
       
         I 
        
       
         = 
        
       
         1 
        
       
         ) 
        
       
         = 
        
       
         0.252 
        
       
         + 
        
       
         0.0224 
        
       
         + 
        
       
         0.0056 
        
       
         + 
        
       
         0.06 
        
       
         + 
        
       
         0.036 
        
       
         + 
        
       
         0.024 
        
       
      
        　　P(I=1)=0.252+0.0224+0.0056+0.06+0.036+0.024 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord cjk_fallback">　</span><span class="mord cjk_fallback">　</span><span class="mord mathdefault" style="margin-right: 0.13889em;">P</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right: 0.07847em;">I</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.277778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.277778em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">2</span><span class="mord">5</span><span class="mord">2</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span><span class="mord">2</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">0</span><span class="mord">5</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.72777em; vertical-align: -0.08333em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">3</span><span class="mord">6</span><span class="mspace" style="margin-right: 0.222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.222222em;"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em;"></span><span class="mord">0</span><span class="mord">.</span><span class="mord">0</span><span class="mord">2</span><span class="mord">4</span></span></span></span></span></p> 
<p><strong>再回想一下我们的主要任务：</strong></p> 
<p><strong>缩小边缘分布之间和条件分布下的差异。</strong></p> 
<h4><a id="_162"></a>实现方法</h4> 
<p>刚刚说了我们的主要任务是 <strong>缩小边缘分布和条件分布下的差异。</strong></p> 
<p>那么如何实现这两个目标呢？</p> 
<p>1）缩小训练集与测试集的边缘分布的距离，通常的做法是清洗训练样本，去除一些异常点或者减少他们的权重。这样可以将训练样本的分布与测试样本的分布保持一致。</p> 
<p>2）如果想减少条件分布的差异呢？用决策树举例子，我们还需要在决策树划分的每一层的样本中，重复上述过程，才可以保证条件概率分布也是相近的。</p> 
<p>我们这里不得不介绍一下另一个Boosting的树模型–AdaBoost</p> 
<p>这是它的迭代过程。</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/6.png'</span>, width<span class="token operator">=</span>500<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/f8/49/hQlmpI0Y_o.png" alt="在这里插入图片描述"><br> 如果不搞清楚他的原理，看Tradaboost代码可能会一脸问号。</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/7.png'</span>, width<span class="token operator">=</span>600<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/10/1d/ZzCEDpB7_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/9.png'</span>, width<span class="token operator">=</span>500<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/37/09/wOdEmfTp_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="TrAdaboost_191"></a>TrAdaboost</h4> 
<h5><a id="_193"></a>简述</h5> 
<p>它是Adaboost学习方法发展而来，作者是Wenyuan Dai。TrAdaboost算法是用来解决训练集和测试集分布不同的问题。在迁移学习的某些情况下，一个训练集中会包含大量的辅助训练样本和少量的源训练样本，我们会将两个不同分布的训练集放在一起训练，这种方法也称为基于实例的迁移学习方法。</p> 
<h5><a id="_197"></a>原理</h5> 
<p>1）Tradaboost是由Adaboost算法演变而来的，我们先来看Adaboost算法的基本思想：当一个训练样本被错误分类，算法就会认为这个样本是难分类的，就相应地给此样本增加样本权重，下次训练时这个样本被分错的概率就会降低。</p> 
<p>2）类似地，在一个包含源训练数据和辅助训练数据的训练集中，TrAdaboost算法也会对训练样本进行权重调整，对于源数据样本，权重调整策略跟Adaboost差不多：如果一个源训练样本被错误分类，根据这一次源样本训练时的错误率进行调整，增加权重，降低下次训练时的分类误差；对于辅助训练样本：当它们被误分类后，算法则认为它们是与目标数据很不同的，于是降低它们的权重，权重调整的依据是Hedge(b);</p> 
<p>3）<mark>Tradaboost通过提升多个弱分类器，对后半（N／2～N）个弱分类器进行综合投票，得出最后的决策</mark>。</p> 
<pre><code class="prism language-bash">Image<span class="token punctuation">(</span>filename<span class="token operator">=</span><span class="token string">'./image/10.png'</span>, width<span class="token operator">=</span>500<span class="token punctuation">)</span> 
</code></pre> 
<p><img src="https://images2.imgbox.com/20/cb/venYDRqW_o.png" alt="在这里插入图片描述"><br> TrAdaBoost 和 AdaBoost 主要区别在于：</p> 
<p>1）TrAdaBoost 的输入是 Ds （源域）和 Dt （目标域）对应的两个数据集，并从 Ds 中只选取对学习任务 Tt 最有用的知识；<br> 2）TrAdaBoost 在计算模型误差时，仅考虑在 Dt 上的误差；<br> 3）TrAdaBoost 在 Ds 和 Dt 中使用不同的样本调权方式；<br> 4）TrAdaBoost 仅使用学习到的所有基学习器中，后训练的半数基学习器来预测模型效果。</p> 
<p><mark>样本的初始权重设置和基分类器选取比较关键</mark>。初始权重设置是较强的先验信息，而且，如果初始权重设置不当，也会影响计算稳定性。我们可以通过不同领域的样本比例，或根据不同类别样本对应的比例，或综合考虑前二者来设置初始权重。另外，基分类器的选取也会影响迭代轮数、计算稳定性和模型最终效果。</p> 
<h5><a id="_218"></a>案例：跨国家跨场景迁移模型</h5> 
<p>某知名金融公司在印度新展开的小额现金贷产品，积累了少量Label样本（约1200条），用于建模样本量显然不够，考虑到虽然国家不同，但借款用户的本质大体相似。考虑从国内大额产品的存量客户上面做迁移，首先制作四个变量。制作变量时要保证国内与印度客群都有这个字段并且字段的含义能保证一致。所以当前的问题就变成了：将知识从国内样本（源域）迁移至只有少量样本的印度客群（目标域）。</p> 
<pre><code class="prism language-bash"><span class="token function">import</span> pandas as pd
from sklearn.metrics <span class="token function">import</span> roc_auc_score,roc_curve,auc
from sklearn.model_selection <span class="token function">import</span> train_test_split
from sklearn <span class="token function">import</span> metrics
from sklearn.linear_model <span class="token function">import</span> LogisticRegression
from sklearn.svm <span class="token function">import</span> LinearSVC
<span class="token function">import</span> numpy as np
<span class="token function">import</span> random
<span class="token function">import</span> math
from sklearn.calibration <span class="token function">import</span> CalibratedClassifierCV
data <span class="token operator">=</span> pd.read_excel<span class="token punctuation">(</span><span class="token string">"/Users/zhucan/Desktop/tra_sample.xlsx"</span><span class="token punctuation">)</span>
data.head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/45/e9/AybQtmSN_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-bash">data.shape
<span class="token comment">#(95806, 6)</span>
data.type.unique<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#array(['target', 'origin', 'offtime'], dtype=object)  #offtime国外的样本的测试集</span>

feature_lst <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'zx_score'</span>,<span class="token string">'msg_cnt'</span>,<span class="token string">'phone_num_cnt'</span>,<span class="token string">'register_days'</span><span class="token punctuation">]</span>
train <span class="token operator">=</span> data<span class="token punctuation">[</span>data.type <span class="token operator">==</span> <span class="token string">'target'</span><span class="token punctuation">]</span>.reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token function">diff</span> <span class="token operator">=</span> data<span class="token punctuation">[</span>data.type <span class="token operator">==</span> <span class="token string">'origin'</span><span class="token punctuation">]</span>.reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
val <span class="token operator">=</span> data<span class="token punctuation">[</span>data.type <span class="token operator">==</span> <span class="token string">'offtime'</span><span class="token punctuation">]</span>.reset_index<span class="token punctuation">(</span><span class="token punctuation">)</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>

print<span class="token punctuation">(</span>train.shape<span class="token punctuation">)</span>
print<span class="token punctuation">(</span>diff.shape<span class="token punctuation">)</span>
val.shape
<span class="token comment">#(14527, 7)</span>
<span class="token comment">#(65304, 7)</span>
<span class="token comment">#(15975, 7)</span>

<span class="token comment">#trans_S, trans_A, label_S, label_A, test</span>
train <span class="token operator">=</span> train.loc<span class="token punctuation">[</span>:1200<span class="token punctuation">]</span>

trans_S <span class="token operator">=</span> train<span class="token punctuation">[</span>feature_lst<span class="token punctuation">]</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#目标域</span>
label_S <span class="token operator">=</span> train<span class="token punctuation">[</span><span class="token string">'bad_ind'</span><span class="token punctuation">]</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
trans_S.shape
<span class="token comment">#(1201, 4)</span>
trans_A <span class="token operator">=</span> diff<span class="token punctuation">[</span>feature_lst<span class="token punctuation">]</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#源域</span>
label_A <span class="token operator">=</span> diff<span class="token punctuation">[</span><span class="token string">'bad_ind'</span><span class="token punctuation">]</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
trans_A.shape
<span class="token comment">#(65304, 4)</span>
val_x <span class="token operator">=</span>  val<span class="token punctuation">[</span>feature_lst<span class="token punctuation">]</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
val_y <span class="token operator">=</span> val<span class="token punctuation">[</span><span class="token string">'bad_ind'</span><span class="token punctuation">]</span>.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token function">test</span> <span class="token operator">=</span> val_x.copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
test.shape
<span class="token comment">#(15975, 4)</span>
</code></pre> 
<pre><code class="prism language-bash">lr_model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span>0.1,class_weight <span class="token operator">=</span> <span class="token string">'balanced'</span>,solver <span class="token operator">=</span> <span class="token string">'liblinear'</span><span class="token punctuation">)</span>
lr_model.fit<span class="token punctuation">(</span>trans_S,label_S<span class="token punctuation">)</span>

y_pred <span class="token operator">=</span> lr_model.predict_proba<span class="token punctuation">(</span>trans_S<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>
fpr_lr_train,tpr_lr_train,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>label_S,y_pred<span class="token punctuation">)</span>
train_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr_train - tpr_lr_train<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">'train_ks : '</span>,train_ks<span class="token punctuation">)</span>

y_pred <span class="token operator">=</span> lr_model.predict_proba<span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>
fpr_lr,tpr_lr,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>val_y,y_pred<span class="token punctuation">)</span>
val_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr - tpr_lr<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">'val_ks : '</span>,val_ks<span class="token punctuation">)</span>

from matplotlib <span class="token function">import</span> pyplot as plt
plt.plot<span class="token punctuation">(</span>fpr_lr_train,tpr_lr_train,label <span class="token operator">=</span> <span class="token string">'train LR'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span>fpr_lr,tpr_lr,label <span class="token operator">=</span> <span class="token string">'evl LR'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span><span class="token punctuation">[</span>0,1<span class="token punctuation">]</span>,<span class="token punctuation">[</span>0,1<span class="token punctuation">]</span>,<span class="token string">'k--'</span><span class="token punctuation">)</span>
plt.xlabel<span class="token punctuation">(</span><span class="token string">'False positive rate'</span><span class="token punctuation">)</span>
plt.ylabel<span class="token punctuation">(</span><span class="token string">'True positive rate'</span><span class="token punctuation">)</span>
plt.title<span class="token punctuation">(</span><span class="token string">'ROC Curve'</span><span class="token punctuation">)</span>
plt.legend<span class="token punctuation">(</span>loc <span class="token operator">=</span> <span class="token string">'best'</span><span class="token punctuation">)</span>
plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#train_ks :  0.48500238435860754</span>
<span class="token comment">#val_ks :  0.3887057754389137</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/db/15/ZycEIZIl_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-bash">trans_data <span class="token operator">=</span> np.concatenate<span class="token punctuation">((</span>trans_A, trans_S<span class="token punctuation">)</span>, axis<span class="token operator">=</span>0<span class="token punctuation">)</span>
trans_label <span class="token operator">=</span> np.concatenate<span class="token punctuation">((</span>label_A, label_S<span class="token punctuation">)</span>, axis<span class="token operator">=</span>0<span class="token punctuation">)</span>

lr_model <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span>0.3,class_weight <span class="token operator">=</span> <span class="token string">'balanced'</span>,solver <span class="token operator">=</span> <span class="token string">'liblinear'</span><span class="token punctuation">)</span>
lr_model.fit<span class="token punctuation">(</span>trans_A,label_A<span class="token punctuation">)</span>

y_pred <span class="token operator">=</span> lr_model.predict_proba<span class="token punctuation">(</span>trans_data<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>
fpr_lr_train,tpr_lr_train,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>trans_label,y_pred<span class="token punctuation">)</span>
train_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr_train - tpr_lr_train<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">'train_ks : '</span>,train_ks<span class="token punctuation">)</span>

y_pred <span class="token operator">=</span> lr_model.predict_proba<span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>
fpr_lr,tpr_lr,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>val_y,y_pred<span class="token punctuation">)</span>
val_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr - tpr_lr<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">'val_ks : '</span>,val_ks<span class="token punctuation">)</span>

from matplotlib <span class="token function">import</span> pyplot as plt
plt.plot<span class="token punctuation">(</span>fpr_lr_train,tpr_lr_train,label <span class="token operator">=</span> <span class="token string">'train LR'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span>fpr_lr,tpr_lr,label <span class="token operator">=</span> <span class="token string">'evl LR'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span><span class="token punctuation">[</span>0,1<span class="token punctuation">]</span>,<span class="token punctuation">[</span>0,1<span class="token punctuation">]</span>,<span class="token string">'k--'</span><span class="token punctuation">)</span>
plt.xlabel<span class="token punctuation">(</span><span class="token string">'False positive rate'</span><span class="token punctuation">)</span>
plt.ylabel<span class="token punctuation">(</span><span class="token string">'True positive rate'</span><span class="token punctuation">)</span>
plt.title<span class="token punctuation">(</span><span class="token string">'ROC Curve'</span><span class="token punctuation">)</span>
plt.legend<span class="token punctuation">(</span>loc <span class="token operator">=</span> <span class="token string">'best'</span><span class="token punctuation">)</span>
plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#train_ks :  0.4910909493184976</span>
<span class="token comment">#val_ks :  0.33077621830414</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/4c/53/7f6p6bo1_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-bash"><span class="token function">import</span> numpy as np
from sklearn <span class="token function">import</span> tree

<span class="token comment">#逻辑回归的学习率、权重的大小，影响整体收敛的快慢</span>
<span class="token comment">#初始权重很重要</span>

<span class="token comment"># H 测试样本分类结果</span>
<span class="token comment"># TrainS 目标域样本</span>
<span class="token comment"># TrainA 源域样本</span>
<span class="token comment"># LabelS 目标域标签</span>
<span class="token comment"># LabelA 源域标签</span>
<span class="token comment"># Test  测试样本</span>
<span class="token comment"># N 迭代次数</span>

<span class="token comment">#计算weight</span>
def calculate_P<span class="token punctuation">(</span>weights, label<span class="token punctuation">)</span>:
    total <span class="token operator">=</span> np.sum<span class="token punctuation">(</span>weights<span class="token punctuation">)</span>
    <span class="token keyword">return</span> np.asarray<span class="token punctuation">(</span>weights / total, order<span class="token operator">=</span><span class="token string">'C'</span><span class="token punctuation">)</span>

<span class="token comment">#用逻辑回归作为基分类器，输出概率</span>
def train_classify<span class="token punctuation">(</span>trans_data, trans_label, test_data, P<span class="token punctuation">)</span>:
    clf <span class="token operator">=</span> LogisticRegression<span class="token punctuation">(</span>C<span class="token operator">=</span>0.3,class_weight <span class="token operator">=</span> <span class="token string">'balanced'</span>,solver<span class="token operator">=</span><span class="token string">'liblinear'</span><span class="token punctuation">)</span>
    clf.fit<span class="token punctuation">(</span>trans_data, trans_label, sample_weight<span class="token operator">=</span>P<span class="token punctuation">[</span>:, 0<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> clf.predict_proba<span class="token punctuation">(</span>test_data<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>,clf

<span class="token comment">#计算在目标域上面的错误率</span>
def calculate_error_rate<span class="token punctuation">(</span>label_R, label_H, weight<span class="token punctuation">)</span>:
    total <span class="token operator">=</span> np.sum<span class="token punctuation">(</span>weight<span class="token punctuation">)</span>
    <span class="token keyword">return</span> np.sum<span class="token punctuation">(</span>weight<span class="token punctuation">[</span>:, 0<span class="token punctuation">]</span> / total * np.abs<span class="token punctuation">(</span>label_R - label_H<span class="token punctuation">))</span>  <span class="token comment">#预测-真实</span>

<span class="token comment">#根据逻辑回归输出的score的得到标签，注意这里不能用predict直接输出标签</span>
def put_label<span class="token punctuation">(</span>score_H,thred<span class="token punctuation">)</span>:
    new_label_H <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> score_H:
        <span class="token keyword">if</span> i <span class="token operator">&lt;=</span> thred:
            new_label_H.append<span class="token punctuation">(</span>0<span class="token punctuation">)</span>
        else:
            new_label_H.append<span class="token punctuation">(</span>1<span class="token punctuation">)</span>
    <span class="token keyword">return</span> new_label_H

<span class="token comment">#指定迭代次数，相当于集成模型中基模型的数量</span>
N<span class="token operator">=</span>500

trans_data <span class="token operator">=</span> np.concatenate<span class="token punctuation">((</span>trans_A, trans_S<span class="token punctuation">)</span>, axis<span class="token operator">=</span>0<span class="token punctuation">)</span>
trans_label <span class="token operator">=</span> np.concatenate<span class="token punctuation">((</span>label_A, label_S<span class="token punctuation">)</span>, axis<span class="token operator">=</span>0<span class="token punctuation">)</span>

row_A <span class="token operator">=</span> trans_A.shape<span class="token punctuation">[</span>0<span class="token punctuation">]</span>
row_S <span class="token operator">=</span> trans_S.shape<span class="token punctuation">[</span>0<span class="token punctuation">]</span>
row_T <span class="token operator">=</span> test.shape<span class="token punctuation">[</span>0<span class="token punctuation">]</span>

test_data <span class="token operator">=</span> np.concatenate<span class="token punctuation">((</span>trans_data, test<span class="token punctuation">)</span>, axis<span class="token operator">=</span>0<span class="token punctuation">)</span>

<span class="token comment"># 初始化权重</span>
weights_A <span class="token operator">=</span> np.ones<span class="token punctuation">(</span><span class="token punctuation">[</span>row_A, 1<span class="token punctuation">]</span><span class="token punctuation">)</span>/row_A
weights_S <span class="token operator">=</span> np.ones<span class="token punctuation">(</span><span class="token punctuation">[</span>row_S, 1<span class="token punctuation">]</span><span class="token punctuation">)</span>/row_S*2
weights <span class="token operator">=</span> np.concatenate<span class="token variable"><span class="token punctuation">((</span>weights_A<span class="token punctuation">,</span> weights_S<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

bata <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">+</span> np.sqrt<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">*</span> np.log<span class="token punctuation">(</span>row_A <span class="token operator">/</span> N<span class="token punctuation">))</span></span><span class="token punctuation">)</span>

<span class="token comment"># 存储每次迭代的标签和bata值？</span>
bata_T <span class="token operator">=</span> np.zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>1, N<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># 存每一次迭代的 error_rate / (1 - error_rate)</span>
result_label <span class="token operator">=</span> np.ones<span class="token punctuation">(</span><span class="token punctuation">[</span>row_A + row_S + row_T, N<span class="token punctuation">]</span><span class="token punctuation">)</span>

predict <span class="token operator">=</span> np.zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>row_T<span class="token punctuation">]</span><span class="token punctuation">)</span>

trans_data <span class="token operator">=</span> np.asarray<span class="token punctuation">(</span>trans_data, order<span class="token operator">=</span><span class="token string">'C'</span><span class="token punctuation">)</span>
trans_label <span class="token operator">=</span> np.asarray<span class="token punctuation">(</span>trans_label, order<span class="token operator">=</span><span class="token string">'C'</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> np.asarray<span class="token punctuation">(</span>test_data, order<span class="token operator">=</span><span class="token string">'C'</span><span class="token punctuation">)</span>

best_ks <span class="token operator">=</span> -1    <span class="token comment">#最优KS</span>
best_round <span class="token operator">=</span> -1 <span class="token comment">#最优基模型数量</span>
best_model <span class="token operator">=</span> -1 <span class="token comment">#最优模型</span>

<span class="token comment"># 初始化结束</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span>N<span class="token punctuation">)</span>:
    P <span class="token operator">=</span> calculate_P<span class="token punctuation">(</span>weights, trans_label<span class="token punctuation">)</span>

    result_label<span class="token punctuation">[</span>:, i<span class="token punctuation">]</span>,model <span class="token operator">=</span> train_classify<span class="token punctuation">(</span>trans_data, trans_label,
                                        test_data, P<span class="token punctuation">)</span>
    score_H <span class="token operator">=</span> result_label<span class="token punctuation">[</span>row_A:row_A + row_S, i<span class="token punctuation">]</span>
    pctg <span class="token operator">=</span> np.sum<span class="token punctuation">(</span>data.bad_ind<span class="token punctuation">)</span>/len<span class="token punctuation">(</span>data.bad_ind<span class="token punctuation">)</span>
    thred <span class="token operator">=</span> pd.DataFrame<span class="token punctuation">(</span>score_H<span class="token punctuation">)</span>.quantile<span class="token punctuation">(</span>1-pctg<span class="token punctuation">)</span><span class="token punctuation">[</span>0<span class="token punctuation">]</span>
    label_H <span class="token operator">=</span> put_label<span class="token punctuation">(</span>score_H,thred<span class="token punctuation">)</span>
    error_rate <span class="token operator">=</span> calculate_error_rate<span class="token punctuation">(</span>label_S, label_H,
                                      weights<span class="token punctuation">[</span>row_A:row_A + row_S, :<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> error_rate <span class="token operator">&gt;</span> 0.5:
        error_rate <span class="token operator">=</span> 0.5
    <span class="token keyword">if</span> error_rate <span class="token operator">==</span> 0:
        N <span class="token operator">=</span> i
        <span class="token keyword">break</span>  <span class="token comment"># 防止过拟合</span>
        <span class="token comment"># error_rate = 0.001</span>

    bata_T<span class="token punctuation">[</span>0, i<span class="token punctuation">]</span> <span class="token operator">=</span> error_rate / <span class="token punctuation">(</span>1 - error_rate<span class="token punctuation">)</span>

    <span class="token comment"># 调整目标域样本权重</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>row_S<span class="token punctuation">)</span>:
        weights<span class="token punctuation">[</span>row_A + j<span class="token punctuation">]</span> <span class="token operator">=</span> weights<span class="token punctuation">[</span>row_A + j<span class="token punctuation">]</span> * np.power<span class="token punctuation">(</span>bata_T<span class="token punctuation">[</span>0, i<span class="token punctuation">]</span>,
                                                           <span class="token punctuation">(</span>-np.abs<span class="token punctuation">(</span>result_label<span class="token punctuation">[</span>row_A + j, i<span class="token punctuation">]</span> - label_S<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">))</span><span class="token punctuation">)</span>

    <span class="token comment"># 调整源域样本权重</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> range<span class="token punctuation">(</span>row_A<span class="token punctuation">)</span>:
        weights<span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> weights<span class="token punctuation">[</span>j<span class="token punctuation">]</span> * np.power<span class="token punctuation">(</span>bata, np.abs<span class="token punctuation">(</span>result_label<span class="token punctuation">[</span>j, i<span class="token punctuation">]</span> - label_A<span class="token punctuation">[</span>j<span class="token punctuation">]</span><span class="token punctuation">))</span>

        
    y_pred <span class="token operator">=</span> result_label<span class="token punctuation">[</span><span class="token punctuation">(</span>row_A + row_S<span class="token punctuation">)</span>:,i<span class="token punctuation">]</span>
    fpr_lr_train,tpr_lr_train,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>val_y,y_pred<span class="token punctuation">)</span>
    train_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr_train - tpr_lr_train<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
    print<span class="token punctuation">(</span><span class="token string">'test_ks : '</span>,train_ks,<span class="token string">'当前第'</span>,i+1,<span class="token string">'轮'</span><span class="token punctuation">)</span>
    
    
    <span class="token keyword">if</span> train_ks <span class="token operator">&gt;</span> best_ks <span class="token keyword">:</span>
        best_ks <span class="token operator">=</span> train_ks
        best_round <span class="token operator">=</span> i
        best_model <span class="token operator">=</span> model
<span class="token comment">#test_ks :  0.15578884442899515 当前第 1 轮</span>
<span class="token comment">#test_ks :  0.14516536326608226 当前第 2 轮</span>
<span class="token comment">#test_ks :  0.15162300261719303 当前第 3 轮</span>
<span class="token comment">#test_ks :  0.1558032631518237 当前第 4 轮</span>
<span class="token comment"># . . . </span>
<span class="token comment">#test_ks :  0.38762651455043984 当前第 498 轮</span>
<span class="token comment">#test_ks :  0.38762651455043984 当前第 499 轮</span>
<span class="token comment">#test_ks :  0.38762651455043984 当前第 500 轮</span>

y_pred <span class="token operator">=</span> best_model.predict_proba<span class="token punctuation">(</span>trans_S<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>
fpr_lr_train,tpr_lr_train,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>label_S,y_pred<span class="token punctuation">)</span>
train_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr_train - tpr_lr_train<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">'train_ks : '</span>,train_ks<span class="token punctuation">)</span>

y_pred <span class="token operator">=</span> best_model.predict_proba<span class="token punctuation">(</span>test<span class="token punctuation">)</span><span class="token punctuation">[</span>:,1<span class="token punctuation">]</span>
fpr_lr,tpr_lr,_ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>val_y,y_pred<span class="token punctuation">)</span>
val_ks <span class="token operator">=</span> abs<span class="token punctuation">(</span>fpr_lr - tpr_lr<span class="token punctuation">)</span>.max<span class="token punctuation">(</span><span class="token punctuation">)</span>
print<span class="token punctuation">(</span><span class="token string">'val_ks : '</span>,val_ks<span class="token punctuation">)</span>

from matplotlib <span class="token function">import</span> pyplot as plt
plt.plot<span class="token punctuation">(</span>fpr_lr_train,tpr_lr_train,label <span class="token operator">=</span> <span class="token string">'train LR'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span>fpr_lr,tpr_lr,label <span class="token operator">=</span> <span class="token string">'evl LR'</span><span class="token punctuation">)</span>
plt.plot<span class="token punctuation">(</span><span class="token punctuation">[</span>0,1<span class="token punctuation">]</span>,<span class="token punctuation">[</span>0,1<span class="token punctuation">]</span>,<span class="token string">'k--'</span><span class="token punctuation">)</span>
plt.xlabel<span class="token punctuation">(</span><span class="token string">'False positive rate'</span><span class="token punctuation">)</span>
plt.ylabel<span class="token punctuation">(</span><span class="token string">'True positive rate'</span><span class="token punctuation">)</span>
plt.title<span class="token punctuation">(</span><span class="token string">'ROC Curve'</span><span class="token punctuation">)</span>
plt.legend<span class="token punctuation">(</span>loc <span class="token operator">=</span> <span class="token string">'best'</span><span class="token punctuation">)</span>
plt.show<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment">#train_ks :  0.4629947544110634</span>
<span class="token comment">#val_ks :  0.39846160021324123</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/bf/3a/Gc1Rj8nT_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/da592182b8dcc94402463197ddd95223/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">NMS(非极大值抑制)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2b3541f517af9375be32b5aa3738d5e3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">检查自己电脑GPU个数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>