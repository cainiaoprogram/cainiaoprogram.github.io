<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ES 的存储原理 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ES 的存储原理" />
<meta property="og:description" content="目录
一、ES是什么
二、ES基本结构
2.1、结构图
2.2、基本概念
2.3、与关系数据库概念的类比
2.4、数据如何读写
2.5 容灾能力
三、ES的文件存储结构
每个分片的事务日志（Transaction Log）
Index文件夹内文件含义(lucene文件夹)
四、存储步骤
页缓存 （文件系统缓存）
​编辑
整体存储步骤流程图
4.1、写入缓存（内存）
4.2、refresh 刷入页缓存（文件系统缓存）
4.3、刷入 refresh 页缓存的同时，写入 translog
4.4、数据 flush 落盘 disk 4.5、Translog的页缓存（内存缓存）
4.6 flush
4.7 整体存储步骤讲解
五、Es的其他操作
5.1、Doc删除
5.2、Doc更新 = 删除 &#43; 新增
5.3、段合并
参考文章
一、ES是什么 一个分布式的实时文档存储，每个字段可以被索引与搜索
一个分布式实时分析搜索引擎
能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据
基于Lucene，隐藏复杂性，提供简单易用的Restful API接口、Java API接口（还有其他语言的API接口）。ES是一个可高度扩展的全文搜索和分析引擎。它能够快速地、近乎实时地存储、查询和分析大量数据。
二、ES基本结构 2.1、结构图 简单讲解：
Node相当于服务器，上图就是4个服务器，也叫4个数据节点比如我的商品数据表的index是 es_product ，我可以把数据切割成3份，那么每一份就是一个 Shared（类似于Mysql的table分表），比如上图的index1，有3个主Shared假如我想把不同业务的数据分开存，比如我有外卖的数据，有商超的数据，那么加前缀，waimai_es_product，shangcha_es_product（类似于Mysql的分库）R-shared就是副本shared，只负责复制Primary给下来的数据，只有当primary挂了，他才上位。（保证系统稳定性，为什么P-s1和 R-s1不能放在一起，那放一起一起挂了不就完犊子了） 2.2、基本概念 集群（cluster）
ES集群由若干节点组成，这些节点在同一个网络内，cluster-name相同
节点（node）
一个ES的实例，本质上是一个java进程，生产环境一般建议一台机器上运行一个ES实例。节点可以分布在不同的机房。
节点有如下分类：
1、master节点：集群中的一个节点会被选为master节点，它将负责管理集群范畴的变更，例如创建或删除索引，添加节点到集群或从集群删除节点。master节点无需参与文档层面的变更和搜索，这意味着仅有一个master节点并不会因流量增长而成为瓶颈。任意一个节点都可以成为 master 节点。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/1102a34513a190380c3d35588811b726/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-04T19:46:25+08:00" />
<meta property="article:modified_time" content="2023-12-04T19:46:25+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ES 的存储原理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="id-1、ES是什么-toc" style="margin-left:0px;"><a href="#id-1%E3%80%81ES%E6%98%AF%E4%BB%80%E4%B9%88" rel="nofollow">一、ES是什么</a></p> 
<p id="id-2、ES基本结构-toc" style="margin-left:0px;"><a href="#id-2%E3%80%81ES%E5%9F%BA%E6%9C%AC%E7%BB%93%E6%9E%84" rel="nofollow">二、ES基本结构</a></p> 
<p id="id-2.1、结构图-toc" style="margin-left:80px;"><a href="#id-2.1%E3%80%81%E7%BB%93%E6%9E%84%E5%9B%BE" rel="nofollow">2.1、结构图</a></p> 
<p id="id-2.2、基本概念-toc" style="margin-left:80px;"><a href="#id-2.2%E3%80%81%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5" rel="nofollow">2.2、基本概念</a></p> 
<p id="id-2.3、与关系数据库概念的类比-toc" style="margin-left:80px;"><a href="#id-2.3%E3%80%81%E4%B8%8E%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5%E7%9A%84%E7%B1%BB%E6%AF%94" rel="nofollow">2.3、与关系数据库概念的类比</a></p> 
<p id="2.4%E3%80%81%E6%95%B0%E6%8D%AE%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99-toc" style="margin-left:80px;"><a href="#2.4%E3%80%81%E6%95%B0%E6%8D%AE%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99" rel="nofollow">2.4、数据如何读写</a></p> 
<p id="%C2%A02.5%20%E5%AE%B9%E7%81%BE%E8%83%BD%E5%8A%9B-toc" style="margin-left:80px;"><a href="#%C2%A02.5%20%E5%AE%B9%E7%81%BE%E8%83%BD%E5%8A%9B" rel="nofollow">2.5 容灾能力</a></p> 
<p id="3%E3%80%81ES%E7%9A%84%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84-toc" style="margin-left:0px;"><a href="#3%E3%80%81ES%E7%9A%84%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84" rel="nofollow">三、ES的文件存储结构</a></p> 
<p id="%E6%AF%8F%E4%B8%AA%E5%88%86%E7%89%87%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%EF%BC%88Transaction%20Log%EF%BC%89-toc" style="margin-left:80px;"><a href="#%E6%AF%8F%E4%B8%AA%E5%88%86%E7%89%87%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%EF%BC%88Transaction%20Log%EF%BC%89" rel="nofollow">每个分片的事务日志（Transaction Log）</a></p> 
<p id="Index%E6%96%87%E4%BB%B6%E5%A4%B9%E5%86%85%E6%96%87%E4%BB%B6%E5%90%AB%E4%B9%89(lucene%E6%96%87%E4%BB%B6%E5%A4%B9)-toc" style="margin-left:80px;"><a href="#Index%E6%96%87%E4%BB%B6%E5%A4%B9%E5%86%85%E6%96%87%E4%BB%B6%E5%90%AB%E4%B9%89%28lucene%E6%96%87%E4%BB%B6%E5%A4%B9%29" rel="nofollow">Index文件夹内文件含义(lucene文件夹)</a></p> 
<p id="%E5%9B%9B%E3%80%81%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%9B%9B%E3%80%81%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%EF%BC%9A" rel="nofollow">四、存储步骤</a></p> 
<p id="%E9%A1%B5%E7%BC%93%E5%AD%98%C2%A0%EF%BC%88%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%EF%BC%89-toc" style="margin-left:80px;"><a href="#%E9%A1%B5%E7%BC%93%E5%AD%98%C2%A0%EF%BC%88%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%EF%BC%89" rel="nofollow">页缓存 （文件系统缓存）</a></p> 
<p id="%E2%80%8B%E7%BC%96%E8%BE%91-toc" style="margin-left:80px;"><a href="#%E2%80%8B%E7%BC%96%E8%BE%91" rel="nofollow">​编辑</a></p> 
<p id="%E6%95%B4%E4%BD%93%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%E6%B5%81%E7%A8%8B%E5%9B%BE-toc" style="margin-left:80px;"><a href="#%E6%95%B4%E4%BD%93%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%E6%B5%81%E7%A8%8B%E5%9B%BE" rel="nofollow">整体存储步骤流程图</a></p> 
<p id="4.1%E3%80%81%E5%86%99%E5%85%A5%E7%BC%93%E5%AD%98%EF%BC%88%E5%86%85%E5%AD%98%EF%BC%89-toc" style="margin-left:80px;"><a href="#4.1%E3%80%81%E5%86%99%E5%85%A5%E7%BC%93%E5%AD%98%EF%BC%88%E5%86%85%E5%AD%98%EF%BC%89" rel="nofollow">4.1、写入缓存（内存）</a></p> 
<p id="4.2%E3%80%81refresh%20%E5%88%B7%E5%85%A5%E9%A1%B5%E7%BC%93%E5%AD%98%EF%BC%88%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%EF%BC%89-toc" style="margin-left:80px;"><a href="#4.2%E3%80%81refresh%20%E5%88%B7%E5%85%A5%E9%A1%B5%E7%BC%93%E5%AD%98%EF%BC%88%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%EF%BC%89" rel="nofollow">4.2、refresh 刷入页缓存（文件系统缓存）</a></p> 
<p id="4.3%E3%80%81%E5%88%B7%E5%85%A5%20refresh%20%E9%A1%B5%E7%BC%93%E5%AD%98%E7%9A%84%E5%90%8C%E6%97%B6%EF%BC%8C%E5%86%99%E5%85%A5%20translog-toc" style="margin-left:80px;"><a href="#4.3%E3%80%81%E5%88%B7%E5%85%A5%20refresh%20%E9%A1%B5%E7%BC%93%E5%AD%98%E7%9A%84%E5%90%8C%E6%97%B6%EF%BC%8C%E5%86%99%E5%85%A5%20translog" rel="nofollow">4.3、刷入 refresh 页缓存的同时，写入 translog</a></p> 
<p id="4.4%E3%80%81%E6%95%B0%E6%8D%AE%20flush%20%E8%90%BD%E7%9B%98%20disk%C2%A0-toc" style="margin-left:80px;"><a href="#4.4%E3%80%81%E6%95%B0%E6%8D%AE%20flush%20%E8%90%BD%E7%9B%98%20disk%C2%A0" rel="nofollow">4.4、数据 flush 落盘 disk </a></p> 
<p id="4.5%E3%80%81Translog%E7%9A%84%E9%A1%B5%E7%BC%93%E5%AD%98%EF%BC%88%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%EF%BC%89-toc" style="margin-left:80px;"><a href="#4.5%E3%80%81Translog%E7%9A%84%E9%A1%B5%E7%BC%93%E5%AD%98%EF%BC%88%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%EF%BC%89" rel="nofollow">4.5、Translog的页缓存（内存缓存）</a></p> 
<p id="4.6%20flush-toc" style="margin-left:80px;"><a href="#4.6%20flush" rel="nofollow">4.6 flush</a></p> 
<p id="%C2%A04.7%20%E6%95%B4%E4%BD%93%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%E8%AE%B2%E8%A7%A3-toc" style="margin-left:80px;"><a href="#%C2%A04.7%20%E6%95%B4%E4%BD%93%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%E8%AE%B2%E8%A7%A3" rel="nofollow"> 4.7 整体存储步骤讲解</a></p> 
<p id="%E5%85%AD%E3%80%81Es%E7%9A%84%E5%85%B6%E4%BB%96%E6%93%8D%E4%BD%9C-toc" style="margin-left:0px;"><a href="#%E5%85%AD%E3%80%81Es%E7%9A%84%E5%85%B6%E4%BB%96%E6%93%8D%E4%BD%9C" rel="nofollow">五、Es的其他操作</a></p> 
<p id="6.1%E3%80%81Doc%E5%88%A0%E9%99%A4-toc" style="margin-left:80px;"><a href="#6.1%E3%80%81Doc%E5%88%A0%E9%99%A4" rel="nofollow">5.1、Doc删除</a></p> 
<p id="6.2%E3%80%81Doc%E6%9B%B4%E6%96%B0%20%3D%20%E5%88%A0%E9%99%A4%20%2B%20%E6%96%B0%E5%A2%9E-toc" style="margin-left:80px;"><a href="#6.2%E3%80%81Doc%E6%9B%B4%E6%96%B0%20%3D%20%E5%88%A0%E9%99%A4%20%2B%20%E6%96%B0%E5%A2%9E" rel="nofollow">5.2、Doc更新 = 删除 + 新增</a></p> 
<p id="6.3%E3%80%81%E6%AE%B5%E5%90%88%E5%B9%B6-toc" style="margin-left:80px;"><a href="#6.3%E3%80%81%E6%AE%B5%E5%90%88%E5%B9%B6" rel="nofollow">5.3、段合并</a></p> 
<p id="%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0" rel="nofollow">参考文章</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p></p> 
<p></p> 
<p></p> 
<h2 id="id-1、ES是什么">一、ES是什么</h2> 
<ul><li> <p>一个分布式的实时文档存储，每个字段可以被索引与搜索</p> </li><li> <p>一个分布式实时分析搜索引擎</p> </li><li> <p>能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据</p> </li><li> <p>基于Lucene，隐藏复杂性，提供简单易用的Restful API接口、Java API接口（还有其他语言的API接口）。ES是一个可高度扩展的全文搜索和分析引擎。它能够快速地、近乎实时地存储、查询和分析大量数据。</p> </li></ul> 
<h2 id="id-2、ES基本结构">二、ES基本结构</h2> 
<h4 id="id-2.1、结构图">2.1、结构图</h4> 
<p><img alt="" height="288" src="https://images2.imgbox.com/5e/77/Pw7IoClZ_o.png" width="736"></p> 
<p><img alt="" height="452" src="https://images2.imgbox.com/66/84/tqBcaMDQ_o.png" width="825"></p> 
<p>简单讲解：</p> 
<ol><li>Node相当于服务器，上图就是4个服务器，也叫4个数据节点</li><li>比如我的商品数据表的index是 es_product ，我可以把数据切割成3份，那么每一份就是一个 Shared<strong><span style="color:#fe2c24;">（类似于Mysql的table分表）</span></strong>，比如上图的index1，有3个主Shared</li><li>假如我想把不同业务的数据分开存，比如我有外卖的数据，有商超的数据，那么加前缀，waimai_es_product，shangcha_es_product<strong><span style="color:#fe2c24;">（类似于Mysql的分库）</span></strong></li><li>R-shared就是副本shared，只负责复制Primary给下来的数据，只有当primary挂了，他才上位。（保证系统稳定性，为什么P-s1和 R-s1不能放在一起，那放一起一起挂了不就完犊子了）</li></ol> 
<p></p> 
<h4 id="id-2.2、基本概念">2.2、基本概念</h4> 
<ul><li> <p>集群（cluster）</p> <p>ES集群由若干节点组成，这些节点在同一个网络内，cluster-name相同</p> </li><li> <p>节点（node）</p> <p>一个ES的实例，本质上是一个java进程，生产环境一般建议一台机器上运行一个ES实例。节点可以分布在不同的机房。</p> </li><li> <p>节点有如下分类：</p> <p>1、master节点：集群中的一个节点会被选为master节点，它将负责管理集群范畴的变更，例如创建或删除索引，添加节点到集群或从集群删除节点。master节点无需参与文档层面的变更和搜索，这意味着仅有一个master节点并不会因流量增长而成为瓶颈。任意一个节点都可以成为 master 节点。</p> <p>2、data节点：持有数据和倒排索引。默认情况下，每个节点都可以通过设定配置文件中的node.data属性为true(默认)成为数据节点。如果需要一个专门的主节点，应将其node.data属性设置为false。<br> 3、client节点：如果将node.master属性和node.data属性都设置为false，那么该节点就是一个客户端节点，扮演一个负载均衡的角色，将到来的请求路由到集群中的各个节点。也叫<span style="color:#fe2c24;">协调节点</span>，这个节点不需要配置的，只要任何一个节点接收到请求，并且请求不需要这个节点处理，只需要他进行转发的场景下，这个节点就被叫做协调节点。</p> </li><li>上面俩节点通过配置指定：</li><li> <pre><code>node.master: true/false 
node.data: true/false</code></pre> <p><img alt="" height="290" src="https://images2.imgbox.com/e3/c3/Kf8x5f3P_o.png" width="431"></p> <p>一个节点可以既为Master节点，又为Data节点，<span style="color:#fe2c24;">但是为什么不推荐？</span> <br> 因为Data节点请求过多，负载过高的时候，可能会导致es假死，也就是可能导致其他节点认为该 Master挂了，另外 Data节点会进行gc 回收，这个过程也可能影响 Master节点的正常响应。所以强烈建议 Master 只做集群管理工作，不参与data的index与query</p> </li><li> <p>索引（index）</p> <p>文档的容器，一类文档的集合</p> </li><li> <p>分片（shard）</p> <p>单个节点由于物理机硬件限制，存储的文档是有限的，如果一个索引包含海量文档，则不能在单个节点存储。ES提供分片机制，同一个索引可以存储在不同分片（数据容器）中，这些分片又可以存储在集群中不同节点上。</p> <p>分片分为主分片(primary shard) 以及从分片(replica shard) </p> <p>1、主分片与从分片关系：从分片只是主分片的一个副本，它用于提供数据的冗余副本 </p> <p>2、从分片应用：在硬件故障时提供数据保护，同时服务于搜索和检索这种只读请求 </p> <p>3、是否可变：索引中的主分片的数量在索引创建后就固定下来了，但是从分片的数量可以随时改变 </p> </li><li> <p>文档（document）</p> <p>可搜索的最小单元 ，json格式保存</p> </li></ul> 
<h4 id="id-2.3、与关系数据库概念的类比">2.3、与关系数据库概念的类比</h4> 
<table><tbody><tr><th> <p>RDBMS</p> </th><th> <p>ES</p> </th></tr><tr><td> <p>Table</p> </td><td> <p>Index</p> </td></tr><tr><td> <p>Row</p> </td><td> <p>Document</p> </td></tr><tr><td> <p>Column</p> </td><td> <p>Field</p> </td></tr><tr><td> <p>Schema</p> </td><td> <p>Mapping</p> </td></tr><tr><td> <p>SQL</p> </td><td> <p>DSL</p> </td></tr></tbody></table> 
<p><span style="color:#fe2c24;">分片(Shard)在数据库概念映射里面类似于分表（水平拆分）</span></p> 
<p></p> 
<p id="1%E3%80%81index%E3%80%81type%E7%9A%84%E5%88%9D%E8%A1%B7"><strong>index、type的初衷</strong></p> 
<p>之前es将index、type类比于关系型数据库（例如mysql）中database、table，这么考虑的目的是“方便管理数据之间的关系”。</p> 
<p><u>【本来为了方便管理数据之间的关系，类比database-table 设计了index-type模型】</u></p> 
<p id="2%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E7%8E%B0%E5%9C%A8%E8%A6%81%E7%A7%BB%E9%99%A4type%EF%BC%9F"><a name="t2"></a><strong>为什么现在要移除type？</strong></p> 
<p>a. 在关系型数据库中table是独立的（独立存储），但<span style="color:#fe2c24;">es中同一个index中不同type是存储在同一个索引中的（lucene的索引文件）</span>，因此不同type中相同名字的字段的定义（mapping）必须一致。如果是mysql，两个table中的age字段，2个table可以分别定义成int和string，但是es不行，必须一样</p> 
<p>b. 不同类型的“记录”存储在同一个index中，会影响lucene的压缩性能。</p> 
<p></p> 
<h4 id="2.4%E3%80%81%E6%95%B0%E6%8D%AE%E5%A6%82%E4%BD%95%E8%AF%BB%E5%86%99">2.4、数据如何读写</h4> 
<p><img alt="" height="504" src="https://images2.imgbox.com/37/fb/tWX9gF0i_o.png" width="972"></p> 
<p></p> 
<p>1、所有数据的处理都由 Primary Shared去处理</p> 
<pre><code>shard = hash(routing) % number_of_primary_shards</code></pre> 
<p>2、假如客户端请求 Node2 写入数据，比如是往spu-record这个index写入数据，此时根据路由字段（一般是主键id）路由到数据应该写入到分片3 Shared3 上，那么此时会找到分片3所在的节点Node3，Node2转发请求给Node3去处理，Node3写入Primary主分片，写入后同步给分片3的副本Replica，同步数据成功后，会告知Node3接收数据成功，Node3发送写入成功Reponse告知Node2，Node2把response发给客户端。<span style="color:#fe2c24;">（Primary-shared和Replicaa-shared都可以处理读流量）</span></p> 
<p><span style="color:#fe2c24;">思考：</span>如果现在请求流量打到了node2上面，但是数据所在的Primary-shared在node3上， replica-shared在node1上，那么此时到底是请求哪个shared？ 那如果请求流量是打到node1上面呢？</p> 
<p>如果请求流量打到了 Node2 上，但是数据所在的 Primary Shard 在 Node3 上，而 Replica Shard 在 Node1 上，那么 Elasticsearch 会将请求转发到 Node3 上的 Primary Shard 进行处理。如果 Node3 上的 Primary Shard 不可用，Elasticsearch 会将请求转发到 Node1 上的 Replica Shard 进行处理。</p> 
<p>如果请求流量打到了 Node1 上，但是数据所在的 Primary Shard 在 Node3 上，而 Replica Shard 在 Node1 上，那么 Elasticsearch 会将请求转发到 Node1 上的 Replica Shard 进行处理。如果 Node1 上的 Replica Shard 不可用，Elasticsearch 会将请求转发到 Node3 上的 Primary Shard 进行处理。</p> 
<p>需要注意的是，请求转发的过程可能会导致一定的延迟，因此在设计 Elasticsearch 集群时，需要合理分配数据和 Shard，避免数据倾斜和请求瓶颈。同时，也需要考虑硬件资源的限制，避免过多的数据迁移和请求转发导致系统性能下降。</p> 
<p></p> 
<p>3、读取数据如下图，假如请求Node2，但是数据在Node3，那么会转发请求到Node3去拿到数据转发给客户端。</p> 
<p><img alt="" height="510" src="https://images2.imgbox.com/dc/75/JV0iigYi_o.png" width="943"></p> 
<h4 id="%C2%A02.5%20%E5%AE%B9%E7%81%BE%E8%83%BD%E5%8A%9B">2.5 容灾能力</h4> 
<p><img alt="" height="533" src="https://images2.imgbox.com/49/bb/gEfSvaxT_o.png" width="1060"></p> 
<p>1、假如服务器 Node3 挂了</p> 
<p>2、Node3上有2个primary节点，shared3 和 shared7，此时 Node1 上的shared7的副本会晋升成 Primary Shard，Node4 上的 shared3 的副本也会晋升成 Primary Shard 。<span style="color:#fe2c24;">晋升后，即可马上对外提供服务。</span></p> 
<p>3、由于配置了副本数是1，所以会把已经丢失的 s3 s7 s2 s5这四个 shard 在其他Node上复制一份。（如果有200G数据，千兆网络，拷贝完需要1600秒。如果没有replica，则这1600秒内这些Shard就不能服务。所以，要求设计的时候，每个shard的数据不能存放太大，避免容灾长时间的复制数据。）</p> 
<h2></h2> 
<h2 id="3%E3%80%81ES%E7%9A%84%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84">三、ES的文件存储结构</h2> 
<p>1、如何去服务器找到es的配置文件</p> 
<pre><code class="language-bash">ps -ef | grep java</code></pre> 
<p>2、找到文件夹所在位置 es.path.home</p> 
<pre><code class="language-bash">-Des.path.home=/opt/company/apps/elasticsearch/current</code></pre> 
<p>找到 config文件夹</p> 
<pre><code class="language-bash">/opt/company/apps/elasticsearch/current/config</code></pre> 
<p>找到es服务的配置文件 elasticsearch.yml</p> 
<pre><code class="language-bash">less elasticsearch.yml</code></pre> 
<p>找到 path.data</p> 
<pre><code class="language-bash">path.data: /opt/company/es_data</code></pre> 
<p>tree 命令，或者 find . -type d -maxdepth 3</p> 
<p><img alt="" height="275" src="https://images2.imgbox.com/b2/20/37UwZ45P_o.png" width="473"></p> 
<p>上面的 foo 是索引名称，有些可能用索引的 uuid 代替。</p> 
<p>data/elasticsearch/nodes/0<span style="color:#fe2c24;">（这个0是固定的）</span>/indices/foo/0 （这个0是foo位于这个Node上的shard分片）</p> 
<h4 id="%E6%AF%8F%E4%B8%AA%E5%88%86%E7%89%87%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%97%A5%E5%BF%97%EF%BC%88Transaction%20Log%EF%BC%89">每个分片的事务日志（Transaction Log）</h4> 
<p>Elasticsearch事务日志确保可以安全地将数据索引到Elasticsearch，而无需为每个文档执行低级Lucene提交。提交Lucene索引会在Lucene级别创建一个新的segment，即执行fsync()，会导致大量磁盘I / O影响性能。</p> 
<p>为了接受索引文档并使其可搜索而不需要完整的Lucene提交，Elasticsearch将其添加到Lucene IndexWriter并将其附加到事务日志中。在每个refresh_interval之后，它将在Lucene索引上调用reopen()，这将使数据可以在不需要提交的情况下进行搜索。这是Lucene Near Real Time API的一部分。当IndexWriter最终由于自动刷新事务日志或由于显式刷新操作而提交时，先前的事务日志将被丢弃并且新的事务日志将取代它。</p> 
<p>如果需要恢复，将首先恢复在Lucene中写入磁盘的segments，然后重放事务日志，以防止丢失尚未完全提交到磁盘的操作。</p> 
<h4 id="Index%E6%96%87%E4%BB%B6%E5%A4%B9%E5%86%85%E6%96%87%E4%BB%B6%E5%90%AB%E4%B9%89(lucene%E6%96%87%E4%BB%B6%E5%A4%B9)">Index文件夹内文件含义(lucene文件夹)</h4> 
<p><img alt="" height="435" src="https://images2.imgbox.com/c8/ce/GpOeNt0u_o.png" width="1073"></p> 
<p></p> 
<table><thead><tr><th>Name</th><th>Extension</th><th>Brief Description</th></tr></thead><tbody><tr><td>Segment Info</td><td>.si</td><td>segment的元数据文件</td></tr><tr><td>Compound File</td><td>.cfs, .cfe</td><td>一个segment包含了如下表的各个文件，为减少打开文件的数量，在segment小的时候，segment的所有文件内容都保存在cfs文件中，cfe文件保存了lucene各文件在cfs文件的位置信息</td></tr><tr><td>Fields</td><td>.fnm</td><td>保存了fields的相关信息</td></tr><tr><td>Field Index</td><td>.fdx</td><td>正排存储文件的元数据信息</td></tr><tr><td>Field Data</td><td>.fdt</td><td>存储了正排存储数据，写入的原文存储在这</td></tr><tr><td>Term Dictionary</td><td>.tim</td><td>倒排索引的元数据信息</td></tr><tr><td>Term Index</td><td>.tip</td><td>倒排索引文件，存储了所有的倒排索引数据</td></tr><tr><td>Frequencies</td><td>.doc</td><td>保存了每个term的doc id列表和term在doc中的词频</td></tr><tr><td>Positions</td><td>.pos</td><td>Stores position information about where a term occurs in the index<br> 全文索引的字段，会有该文件，保存了term在doc中的位置</td></tr><tr><td>Payloads</td><td>.pay</td><td>Stores additional per-position metadata information such as character offsets and user payloads<br> 全文索引的字段，使用了一些像payloads的高级特性会有该文件，保存了term在doc中的一些高级特性</td></tr><tr><td>Norms</td><td>.nvd, .nvm</td><td>文件保存索引字段加权数据</td></tr><tr><td>Per-Document Values</td><td>.dvd, .dvm</td><td>lucene的docvalues文件，即数据的列式存储，用作聚合和排序</td></tr><tr><td>Term Vector Data</td><td>.tvx, .tvd, .tvf</td><td>Stores offset into the document data file<br> 保存索引字段的矢量信息，用在对term进行高亮，计算文本相关性中使用</td></tr><tr><td>Live Documents</td><td>.liv</td><td>记录了segment中删除的doc</td></tr></tbody></table> 
<p></p> 
<h2 id="%E5%9B%9B%E3%80%81%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%EF%BC%9A">四、存储步骤</h2> 
<h4 id="%E9%A1%B5%E7%BC%93%E5%AD%98%C2%A0%EF%BC%88%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%EF%BC%89">页缓存 （文件系统缓存）</h4> 
<p> 为了提升对文件的读写效率，Linux 内核会以页大小（4KB）为单位，将文件划分为多数据块。当用户对文件中的某个数据块进行读写操作时，内核首先会申请一个内存页（称为 <code>页缓存</code>）与文件中的数据块进行绑定。如下图所示：<br><br><img alt="" height="586" src="https://images2.imgbox.com/a7/77/8euuiLVM_o.png" width="1200"></p> 
<p></p> 
<h4 id="%E6%95%B4%E4%BD%93%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%E6%B5%81%E7%A8%8B%E5%9B%BE">整体存储步骤流程图</h4> 
<p></p> 
<p><img alt="" height="416" src="https://images2.imgbox.com/84/a8/A2WG7vup_o.png" width="1012">  </p> 
<p></p> 
<h4 id="4.1%E3%80%81%E5%86%99%E5%85%A5%E7%BC%93%E5%AD%98%EF%BC%88%E5%86%85%E5%AD%98%EF%BC%89">4.1、写入缓存（内存）</h4> 
<p>Doc会先被搜集到内存中的Buffer内，这个时候<span style="color:#fe2c24;">还无法被搜索到</span>，如下图所示：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/a2/84/kukCX1YB_o.png"></p> 
<h4 id="4.2%E3%80%81refresh%20%E5%88%B7%E5%85%A5%E9%A1%B5%E7%BC%93%E5%AD%98%EF%BC%88%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%BC%93%E5%AD%98%EF%BC%89" style="background-color:transparent;">4.2、refresh 刷入页缓存（文件系统缓存）</h4> 
<p>Lucene支持对新段写入和打开，可以使文档在<span style="color:#fe2c24;">没有完全刷入硬盘</span>的状态下就能<span style="color:#fe2c24;">对搜索可见</span>，而且是一个开销较小的操作，可以频繁进行。</p> 
<p>下面是一个已经将Docs刷入段，但还没有完全提交的示意图：</p> 
<p></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/26/e4/MuaG9pNc_o.png"></p> 
<p>我们可以看到，新段虽然还没有被完全提交，但是已经对搜索可见了。</p> 
<p>引入refresh操作的目的是提高ES的实时性，使添加文档尽可能快的被搜索到，同时又避免频繁fsync带来性能开销，依靠的就是文件系统缓存OS cache里缓存的文件可以被打开(open/reopen)和读取，而这个os cache实际是一块内存区域，而非磁盘，所以操作是很快的，这就是ES被称为近实时搜索的原因。</p> 
<p>refresh默认执行的间隔是1秒，可以使用<code>refreshAPI</code>进行手动操作，但一般不建议这么做。还可以通过合理设置<code>refresh_interval</code>在近实时搜索和索引速度间做权衡。</p> 
<p></p> 
<h4 id="4.3%E3%80%81%E5%88%B7%E5%85%A5%20refresh%20%E9%A1%B5%E7%BC%93%E5%AD%98%E7%9A%84%E5%90%8C%E6%97%B6%EF%BC%8C%E5%86%99%E5%85%A5%20translog">4.3、刷入 refresh 页缓存的同时，<strong>写入 translog</strong></h4> 
<p><span style="color:#fe2c24;">translog记录的是已经在内存生成(segments)并存储到os cache但是还没写到磁盘的那些索引操作。</span></p> 
<p>index segment刷入 refresh 到os cache后就可以打开供查询，这个操作是有潜在风险的，因为os cache中的数据有可能在意外的故障中丢失，而此时数据必备并未刷入到os disk，此时数据丢失将是不可逆的，这个时候就需要一种机制，<span style="color:#fe2c24;">可以将对es的操作记录下来</span>，来确保当出现故障的时候，已经落地到磁盘的数据不会丢失，并在重启的时候可以从操作记录中将数据恢复过来。elasticsearch提供了translog来记录这些操作，结合os cached segments数据定时落盘来实现数据可靠性保证（flush）。</p> 
<p>文档被添加到buffer同时追加到translog：</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/6c/7a/VwNZoQxz_o.png"></p> 
<h4>        </h4> 
<h4 id="4.4%E3%80%81%E6%95%B0%E6%8D%AE%20flush%20%E8%90%BD%E7%9B%98%20disk%C2%A0">4.4、数据 flush 落盘 disk </h4> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/d0/27/BAox5GLF_o.png"></p> 
<p>每隔一段时间（例如translog变得太大），index会被flush到磁盘，新的translog文件被创建，commit执行结束后，会发生以下事件：</p> 
<ul><li>所有内存中的buffer会被写入新段</li><li>buffer被清空</li><li>一个提交点被写入磁盘</li><li>文件系统缓存通过<code>fsync</code> flush</li><li>之前的旧translog被删除</li></ul> 
<h4 id="4.5%E3%80%81Translog%E7%9A%84%E9%A1%B5%E7%BC%93%E5%AD%98%EF%BC%88%E5%86%85%E5%AD%98%E7%BC%93%E5%AD%98%EF%BC%89">4.5、Translog的页缓存（内存缓存）</h4> 
<p>translog本身也是磁盘文件，频繁的写入磁盘会带来巨大的IO开销，<span style="color:#fe2c24;">因此对translog的追加写入操作的同样操作的是os cache</span>，因此也需要定时落盘（fsync）。<strong>translog落盘的时间间隔直接决定了ES的可靠性</strong>，因为宕机可能导致这个时间间隔内所有的ES操作既没有生成segment磁盘文件，又没有记录到Translog磁盘文件中，导致这期间的所有操作都丢失且无法恢复。</p> 
<p>translog的fsync是ES在后台自动执行的，默认是每5秒钟主动进行一次translog fsync，或者当translog文件大小大于512MB主动进行一次fsync，对应的配置是</p> 
<pre><code>index.translog.flush_threshold_period
index.translog.flush_threshold_size</code></pre> 
<p>当 Elasticsearch 启动的时候， 它会从磁盘中使用最后一个提交点去恢复已知的段，并且会重放 translog 中所有在最后一次提交后发生的变更操作。</p> 
<p>translog 也被用来提供实时 CRUD 。当你试着通过ID来RUD一个Doc，它会在从相关的段检索之前先检查 translog 中最新的变更。</p> 
<p>默认<code>translog</code>是每5秒或是每次请求完成后被<code>fsync</code>到磁盘（在主分片和副本分片都会）。也就是说，如果你发起一个index, delete, update, bulk请求写入translog并被fsync到主分片和副本分片的磁盘前不会反回200状态。</p> 
<p>这样会带来一些性能损失，可以通过设为异步fsync，但是必须接受由此带来的丢失少量数据的风险。</p> 
<pre><code>PUT /my_index/_settings
{
    "index.translog.durability": "async",
    "index.translog.sync_interval": "5s"
}</code></pre> 
<h4 id="4.6%20flush">4.6 flush</h4> 
<p><code>flush</code>就是执行commit清空、干掉老translog的过程。默认每个分片30分钟或者是translog过于大的时候自动flush一次。可以通过flush API手动触发，但是只会在重启节点或关闭某个索引的时候这样做，因为这可以让未来ES恢复的速度更快(translog文件更小)。</p> 
<p>满足下列条件之一就会触发冲刷操作：</p> 
<ul><li> <p>内存缓冲区已满，相关参数： <code>indices.memory.index_buffer</code></p> </li><li> <p>自上次冲刷后超过了一定的时间，相关参数：<code>index.translog.flush_threshold_period</code></p> </li><li> <p>事物日志达到了一定的阔值，相关参数：<code>index.translog.flush_threshold_size</code></p> </li></ul> 
<p></p> 
<h4 id="%C2%A04.7%20%E6%95%B4%E4%BD%93%E5%AD%98%E5%82%A8%E6%AD%A5%E9%AA%A4%E8%AE%B2%E8%A7%A3"> 4.7 整体存储步骤讲解</h4> 
<p><img alt="" height="416" src="https://images2.imgbox.com/d6/03/dUvsF8wp_o.png" width="1012"></p> 
<ol><li>数据写入buffer缓冲和translog日志文件中。<br> 当你写一条数据document的时候，一方面写入到mem buffer缓冲中，一方面同时写入到translog日志文件中。</li><li>buffer满了或者每隔1秒(可配)，refresh将mem buffer中的数据生成index segment文件并写入os cache，此时index segment可被打开以供search查询读取，这样文档就可以被搜索到了（注意，此时文档还没有写到磁盘上）；然后清空mem buffer供后续使用。可见，refresh实现的是文档从内存移到文件系统缓存的过程。（其实都在内存内操作）</li><li>重复上两个步骤，新的segment不断添加到os cache，mem buffer不断被清空，而translog的数据不断增加，随着时间的推移，translog文件会越来越大。</li><li>当translog长度达到一定程度的时候，会触发flush操作，否则默认每隔30分钟也会定时flush，其主要过程：<br> 4.1. 执行refresh操作将mem buffer中的数据写入到新的segment并写入os cache，然后打开本segment以供search使用，最后再次清空mem buffer。<br> 4.2. 一个commit point被写入磁盘，这个commit point中标明所有的index segment。<br> 4.3. filesystem cache（os cache）中缓存的所有的index segment文件被fsync强制刷到磁盘os disk，当index segment被fsync强制刷到磁盘上以后，就会被打开，供查询使用。<br> 4.4. translog被清空和删除，创建一个新的translog。</li></ol> 
<h2 id="%E5%85%AD%E3%80%81Es%E7%9A%84%E5%85%B6%E4%BB%96%E6%93%8D%E4%BD%9C">五、Es的其他操作</h2> 
<h4 id="6.1%E3%80%81Doc%E5%88%A0%E9%99%A4">5.1、Doc删除</h4> 
<p>删除一个ES文档不会立即从磁盘上移除，它只是被标记成已删除。因为段是不可变的，所以文档既不能从旧的段中移除，旧的段也不能更新以反映文档最新的版本。</p> 
<p>ES的做法是，每一个提交点包括一个<code>.del</code>文件（还包括新段），包含了段上已经被标记为删除状态的文档。所以，当一个文档被做删除操作，实际上只是在<code>.del</code>文件中将该文档标记为删除，依然会在查询时被匹配到，只不过在最终返回结果之前会被从结果中删除。ES将会在用户之后添加更多索引的时候，在后台进行要删除内容的清理。</p> 
<h4 id="6.2%E3%80%81Doc%E6%9B%B4%E6%96%B0%20%3D%20%E5%88%A0%E9%99%A4%20%2B%20%E6%96%B0%E5%A2%9E">5.2、Doc更新 = 删除 + 新增</h4> 
<p>文档的更新操作和删除是类似的：当一个文档被更新，旧版本的文档被标记为删除，新版本的文档在新的段中索引。<br> 该文档的不同版本都会匹配一个查询，但是较旧的版本会从结果中删除。</p> 
<h4 id="6.3%E3%80%81%E6%AE%B5%E5%90%88%E5%B9%B6">5.3、段合并</h4> 
<p>通过每秒自动刷新创建新的段，用不了多久段的数量就爆炸了，每个段消费大量文件句柄，内存，cpu资源。更重要的是，每次搜索请求都需要依次检查每个段。段越多，查询越慢。</p> 
<p>ES通过后台合并段解决这个问题。ES利用段合并的时机来真正从文件系统删除那些version较老或者是被标记为删除的文档。被删除的文档（或者是version较老的）不会再被合并到新的更大的段中。</p> 
<p>可见，段合并主要有两个目的：</p> 
<ul><li>第一个是将分段的总数量保持在受控的范围内（这用来保障查询的性能）。</li><li>第二个是真正地删除文挡。</li></ul> 
<p>ES对一个不断有数据写入的索引处理流程如下：</p> 
<ol><li>索引过程中，refresh会不断创建新的段，并打开它们。</li><li>合并过程会在后台选择一些小的段合并成大的段，这个过程不会中断索引和搜索。</li></ol> 
<p>合并过程如图：</p> 
<p></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/43/28/ZZSSEa0A_o.png"></p> 
<p>从上图可以看到，段合并之前，旧有的Commit和没Commit的小段皆可被搜索。</p> 
<p>段合并后的操作:</p> 
<ul><li>新的段flush到硬盘</li><li>编写一个包含新段的新提交点，并排除旧的较小段。</li><li>新的段打开供搜索</li><li>旧的段被删除</li></ul> 
<p>合并完成后新的段可被搜索，旧的段被删除，如下图所示：</p> 
<p></p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/ff/10/RSlh95zg_o.png"></p> 
<p></p> 
<p><strong>注意</strong>：段合并过程虽然看起来很爽，但是大段的合并可能会占用大量的IO和CPU，如果不加以控制，可能会大大降低搜索性能。段合并的optimize API 不是非常特殊的情况下千万不要使用，默认策略已经足够好了。不恰当的使用可能会将你机器的资源全部耗尽在段合并上，导致无法搜索、无法响应。</p> 
<p></p> 
<p></p> 
<h2 id="%E5%8F%82%E8%80%83%E6%96%87%E7%AB%A0">参考文章</h2> 
<p>1、 <a class="link-info" href="https://elasticsearch.cn/article/6178" rel="nofollow" title="Day 7 - Elasticsearch中数据是如何存储的">Day 7 - Elasticsearch中数据是如何存储的</a></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5771ec73468945c8cfd9731894e878dc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">METR-LA数据集介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/c66377455cd8574076af0de49b60b751/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">PEMS数据集与.h5文件读取</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>