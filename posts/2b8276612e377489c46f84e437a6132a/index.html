<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO / Sparser DETR / Lite DETR） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO / Sparser DETR / Lite DETR）" />
<meta property="og:description" content="计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO） 计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO）1. DN DETR1.1 Stablize Hungarian Matching1.2 Denoising1.3 Attention Mask 2. DINO2.1 Contrastive Denoising3.2 Mix Query3.3 Look Forward Twice 3. Sparse DETR3.1 Encoder Token Sparsification3.2 Scoring Network3.3 Encoder Auxiliary Loss and Top-K Decoder Queries 4. Lite DETR4.1 Motivation and Analysis4.2 Interleaved Update4.3 Key-aware Deformable Attention 计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO） 自DETR年提出来之后，许多Paper针对DETR中收敛速度慢、检测效果差等问题进行了针对性优化，在
计算机视觉算法——基于Transformer的目标检测（DETR / Deformable DETR / Dynamic DETR / DETR 3D）
计算机视觉算法——基于Transformer的目标检测（Efficient DETR / Anchor DETR / Conditional DETR / DAB DETR）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2b8276612e377489c46f84e437a6132a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-26T16:13:15+08:00" />
<meta property="article:modified_time" content="2023-11-26T16:13:15+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO / Sparser DETR / Lite DETR）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO）</h4> 
 <ul><li><a href="#TransformerDN_DETR__DINO_2" rel="nofollow">计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO）</a></li><li><ul><li><a href="#1_DN_DETR_9" rel="nofollow">1. DN DETR</a></li><li><ul><li><a href="#11_Stablize_Hungarian_Matching_12" rel="nofollow">1.1 Stablize Hungarian Matching</a></li><li><a href="#12_Denoising_21" rel="nofollow">1.2 Denoising</a></li><li><a href="#13_Attention_Mask_51" rel="nofollow">1.3 Attention Mask</a></li></ul> 
   </li><li><a href="#2_DINO_400" rel="nofollow">2. DINO</a></li><li><ul><li><a href="#21_Contrastive_Denoising_402" rel="nofollow">2.1 Contrastive Denoising</a></li><li><a href="#32_Mix_Query_408" rel="nofollow">3.2 Mix Query</a></li><li><a href="#33_Look_Forward_Twice_415" rel="nofollow">3.3 Look Forward Twice</a></li></ul> 
   </li><li><a href="#3_Sparse_DETR_436" rel="nofollow">3. Sparse DETR</a></li><li><ul><li><a href="#31_Encoder_Token_Sparsification_439" rel="nofollow">3.1 Encoder Token Sparsification</a></li><li><a href="#32_Scoring_Network_448" rel="nofollow">3.2 Scoring Network</a></li><li><a href="#33_Encoder_Auxiliary_Loss_and_TopK_Decoder_Queries_464" rel="nofollow">3.3 Encoder Auxiliary Loss and Top-K Decoder Queries</a></li></ul> 
   </li><li><a href="#4_Lite_DETR_473" rel="nofollow">4. Lite DETR</a></li><li><ul><li><a href="#41_Motivation_and_Analysis_476" rel="nofollow">4.1 Motivation and Analysis</a></li><li><a href="#42_Interleaved_Update_479" rel="nofollow">4.2 Interleaved Update</a></li><li><a href="#43_Keyaware_Deformable_Attention_498" rel="nofollow">4.3 Key-aware Deformable Attention</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="TransformerDN_DETR__DINO_2"></a>计算机视觉算法——基于Transformer的目标检测（DN DETR / DINO）</h2> 
<p>自DETR年提出来之后，许多Paper针对DETR中收敛速度慢、检测效果差等问题进行了针对性优化，在<br> <a href="https://blog.csdn.net/weixin_44580210/article/details/125951431?spm=1001.2014.3001.5501">计算机视觉算法——基于Transformer的目标检测（DETR / Deformable DETR / Dynamic DETR / DETR 3D）</a><br> <a href="https://blog.csdn.net/weixin_44580210/article/details/133428227?spm=1001.2014.3001.5501">计算机视觉算法——基于Transformer的目标检测（Efficient DETR / Anchor DETR / Conditional DETR / DAB DETR）</a><br> 中我们对DETR以及其部分优化方法进行了总结，本篇博客我们针对这些优化方法进行进一步补充。</p> 
<h3><a id="1_DN_DETR_9"></a>1. DN DETR</h3> 
<p>DN DETR发表于2022年CVPR，该论文的主要贡献是<strong>在训练过程中引入了去噪任务，进一步加速了训练收敛速度</strong>，仅用12个Epochs就可以得到不错的效果</p> 
<h4><a id="11_Stablize_Hungarian_Matching_12"></a>1.1 Stablize Hungarian Matching</h4> 
<p>在Anchor DETR、Conditional DETR、DAB DETR等一系列工作中，研究方向多集中在<strong>如何修改网络结构或者给Learnable Query赋予先验以加速网络的收敛</strong>，而DN DETR则引入了一个新的思路，<strong>如何稳定匈牙利匹配的过程来加速收敛</strong>。</p> 
<p>匈牙利匹配是基于全局最优的思想通过规则定义的Cost矩阵计算出匹配的结果，由于匹配的离散性和训练的随机性，这会使得<strong>Query和Ground Truth的匹配是一个非常不稳定的过程</strong>。</p> 
<p>DN DETR提出的方法是取消匈牙利匹配过程，我们先验地告诉每一个Query它需要学习的GroundTruth是哪个，但是如果直接给Query提供对应GroundTruth的监督，会使得这个任务对于DN DETR过于简单。因此作者考虑到<strong>给GroundTruth加入噪声作为输入，然后使用GroundTruth来重建输出，让DN DETR去完成去噪任务</strong>。因为每个Query对应的GroundTruth是稳定不变的，也就避免了上上述不稳定匹配的过程。</p> 
<p>下面我们来看看是DN DETR是如何添加噪声的：</p> 
<h4><a id="12_Denoising_21"></a>1.2 Denoising</h4> 
<p>DN DETR带Denoising的训练过程如下图所示：<br> <img src="https://images2.imgbox.com/cc/ef/E7arOx1F_o.png" alt="在这里插入图片描述" width="1000"><br> 从图中我们可以看到，<strong>Denoising Part是一个完全增量的模块，原始基于匈牙利匹配的Matching Part并不会丢弃</strong>。DN DETR是基于DAB DETR进行开发的，在DAB DETR中，Query被分成了Content Query和Position Query两部分，因此对于真值的噪声添加我们也分为Content和Positoin两部分</p> 
<p><strong>Content Noise</strong><br> Content Noise即对GT Label添加噪声，由于GT Label是一个数字，如果只是将这个数字修改另外一个数字肯定是不够的，我们需要<strong>将加噪的GT Label编码为Embedding向量</strong>，具体来说我们需要做如下操作：</p> 
<ol><li>在模型中设置一个Embedding Matrix，由其<strong>对加噪的GT Label进行编码得到对应的Class Embedding</strong>；</li><li>考虑到对Matching Part的友好性，<strong>在Class Embedding部分拼接了指示向量Indicator</strong>，用来甄别Query到底是做Denoising任务还是Matching任务；</li><li>在原始的DETR中，Query的Content部分是初始化为零向量，在这里我们需要对Query的Content部分进行改造，对于左Denosing任务Content Query<strong>初始化为‘Non Object’类别</strong>，这个值应该不小于GT Label的类别数Num_Classes并且通过Embedding Matrix进行编码。对于做Denoising任务的Content Query则<strong>初始化为0到Num_Classes-1</strong>，同样通过Embedding Matrix进行编码。</li></ol> 
<p><strong>Position Noise</strong><br> Position Noise即对4D Anchor Box部分添加噪声。这部分噪声可以概括为<strong>中心点位移</strong>和<strong>尺度缩放</strong>：</p> 
<ol><li>中心点位移：首先从均匀分布中采样一个扰动参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           λ 
          
         
           1 
          
         
        
          ∈ 
         
        
          ( 
         
        
          0 
         
        
          , 
         
        
          1 
         
        
          ) 
         
        
       
         \lambda_1 \in(0,1) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>，然后分别计算中心点<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          x 
         
        
          , 
         
        
          y 
         
        
       
         x,y 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span></span></span></span>对应偏移量为<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           ∣ 
          
         
           Δ 
          
         
           x 
          
         
           ∣ 
          
         
           = 
          
          
          
            λ 
           
          
            1 
           
          
         
           x 
          
         
           , 
          
         
           ∣ 
          
         
           Δ 
          
         
           y 
          
         
           ∣ 
          
         
           = 
          
          
          
            λ 
           
          
            1 
           
          
         
           y 
          
         
        
          |\Delta x|=\lambda _1 x,| \Delta y \mid=\lambda_1 y 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∣Δ</span><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">∣Δ</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∣=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span></span></span></span></span>由于<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          x 
         
        
          = 
         
         
         
           w 
          
         
           2 
          
         
        
       
         x=w_2 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.5806em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0269em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          y 
         
        
          = 
         
         
         
           h 
          
         
           2 
          
         
        
       
         y=h_2 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，于是扰动后中心点<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          x 
         
        
          ± 
         
        
          Δ 
         
        
          x 
         
        
          , 
         
        
          y 
         
        
          ± 
         
        
          Δ 
         
        
          y 
         
        
          ) 
         
        
       
         ({x} \pm \Delta {x}, {y} \pm \Delta {y}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">x</span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span><span class="mclose">)</span></span></span></span></span>还位于原框内</li><li>尺度缩放：同样从均匀分布中采集一个扰动参数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           λ 
          
         
           2 
          
         
        
          ∈ 
         
        
          ( 
         
        
          0 
         
        
          , 
         
        
          1 
         
        
          ) 
         
        
       
         \lambda_2 \in(0,1) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span></span>，然后也是分别计算宽高对应的偏移量<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           ∣ 
          
         
           Δ 
          
         
           w 
          
         
           ∣ 
          
         
           = 
          
          
          
            λ 
           
          
            2 
           
          
         
           w 
          
         
           , 
          
         
           ∣ 
          
         
           Δ 
          
         
           h 
          
         
           ∣ 
          
         
           = 
          
          
          
            λ 
           
          
            2 
           
          
         
           h 
          
         
        
          |\Delta w|=\lambda_2 w,| \Delta h \mid=\lambda_2 h 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">∣Δ</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mord">∣</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">∣Δ</span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∣=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal">h</span></span></span></span></span></span>，最终得到缩放后的宽高<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          1 
         
        
          ± 
         
         
         
           λ 
          
         
           2 
          
         
        
          ) 
         
        
          w 
         
        
          , 
         
        
          ( 
         
        
          1 
         
        
          ± 
         
         
         
           λ 
          
         
           2 
          
         
        
          ) 
         
        
          h 
         
        
       
         (1 \pm \lambda_2) w,(1 \pm \lambda_2) h 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right: 0.0269em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">±</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathnormal">h</span></span></span></span></span>，也就是说，宽高会缩放至原来的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          0 
         
        
       
         0 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">0</span></span></span></span></span>到<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          2 
         
        
       
         2 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">2</span></span></span></span></span>倍</li></ol> 
<p>对于不同噪声影响的大小，作者在实验部分进行的对比：<br> <img src="https://images2.imgbox.com/f9/f7/FYCUfcNg_o.png" alt="在这里插入图片描述" width="600"></p> 
<p><strong>Denoising Groups</strong><br> 为了更充分地利用Denosing任务去提升模型的学习效率，我们可以让模型堆每个Ground Truth在不同程度的噪声下都拥有纠错能力，作者设置了Denoising Groups，即多个去噪组，每个Ground Truth在每组内都会有一个Noised Query负责去预测。</p> 
<p><strong>在每组内Ground Truth和Query是One-to-One的关系，但是总和每组来看Ground Truth和Query就是One-to-Many的关系</strong>。在CNN的目标检测方法中经常使用到这种One-to-Many的关系，即由多个Anchor去预测同一个Ground Truth，这种训练监督方式会导致这些方法避免不了使用NMS进行后处理，但是在DN DETR中，<strong>这种One-to-Many的关系仅在训练的时候起到加速收敛的作用，但是在实际推理时仍然是使用Matching Part的二分匹配的结果</strong>，因此可以避免NMS<br> <img src="https://images2.imgbox.com/7f/2f/jyxYE2KJ_o.png" alt="在这里插入图片描述" width="400"><br> 从上图的实验对比结果可以看出来，适当增加Denosing Group可以提高模型AP。</p> 
<h4><a id="13_Attention_Mask_51"></a>1.3 Attention Mask</h4> 
<p>在Transformer的构建中，如果没有特殊处理，Denosing Part的Query和Matching Part的Query是会进行Attention交互的。<strong>Denosing Part的Query中包含大量Ground Truth信息的，如果Matching Part的Query通过Attention获取到了这些Ground Truth的信息，学习的效果肯定会大打折扣</strong>。因此作者在训练过程中添加了Attention Mask来组织Ground Truth的信息泄露。</p> 
<p>如何设置Attention Mask呢？</p> 
<ol><li><strong>Matching Part的Queries不能看到Denoising Part的Query</strong>，原因上面已经分析过。</li><li><strong>不同Denoising Group的Queries不能相互看到</strong>，原因是每个Denoising Group中必定有一个Query拥有当前Query负责预测的Ground Truth的信息，如果拿当前Query和其他Denosing Group的Queries进行Attention势必会导致信息泄露。</li><li><strong>相同Denoising Group的Queries可以相互看到</strong>，原因是对于同组的Queries各自负责的Ground Truth都是不相同的，因此相互Attention不会存在信息泄露。</li></ol> 
<p>从下面实验结果看，Attention Mask在训练过程中起到了至关重要的作用：<br> <img src="https://images2.imgbox.com/20/dd/fZHlq0d1_o.png" alt="在这里插入图片描述" width="480"><br> 下面我们通过代码看看上述各个要点是如何实现的：<br> DN DETR的代码主要是基于DAB DETR的工程实现的，主要代码实现在dn_component.py脚本中，首先是构建Noise和Attention Mask的部分：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">prepare_for_dn</span><span class="token punctuation">(</span>dn_args<span class="token punctuation">,</span> embedweight<span class="token punctuation">,</span> batch_size<span class="token punctuation">,</span> training<span class="token punctuation">,</span> num_queries<span class="token punctuation">,</span> num_classes<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">,</span> label_enc<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    prepare for dn components in forward function
    Args:
        dn_args: (targets, args.scalar, args.label_noise_scale, args.box_noise_scale, args.num_patterns) from engine input
        embedweight: positional queries as anchor
        training: whether it is training or inference
        num_queries: number of queries
        num_classes: number of classes
        hidden_dim: transformer hidden dimenstion
        label_enc: label encoding embedding

    Returns: input_query_label, input_query_bbox, attn_mask, mask_dict
    """</span>
    <span class="token keyword">if</span> training<span class="token punctuation">:</span>
    	<span class="token comment"># targets是list[dict]，每个dict中存储的一张图片上ground truth的所有目标框的label和boxes，一个target就是一个batch</span>
    	<span class="token comment"># scalar代表的去噪的组数，默认是5</span>
        targets<span class="token punctuation">,</span> scalar<span class="token punctuation">,</span> label_noise_scale<span class="token punctuation">,</span> box_noise_scale<span class="token punctuation">,</span> num_patterns <span class="token operator">=</span> dn_args
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        num_patterns <span class="token operator">=</span> dn_args

    <span class="token keyword">if</span> num_patterns <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        num_patterns <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token comment"># 用于指示匹配的任务的向量，全部初始化为0</span>
    indicator0 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>num_queries <span class="token operator">*</span> num_patterns<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment"># label_enc = nn.Embedding(num_classes + 1, hidden_dim - 1), num_class+1的原因是tgt的初始值为num_classes，代表non object，hidden_dim-1的原因是需要concate indicator0，在原detr中tgt初始化为零向量</span>
    tgt <span class="token operator">=</span> label_enc<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>num_queries <span class="token operator">*</span> num_patterns<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment"># content部分:(num_queries*num_patterns,hidden_dim)</span>
    tgt <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>tgt<span class="token punctuation">,</span> indicator0<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	<span class="token comment"># position部分:(num_queries,4)-&gt;(num_query*num_patterns,4)</span>
    refpoint_emb <span class="token operator">=</span> embedweight<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>num_patterns<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> training<span class="token punctuation">:</span>
    	<span class="token comment"># 每张图片上所有ground truth的数量是不一样的</span>
        known <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones_like<span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> targets<span class="token punctuation">]</span>
        <span class="token comment"># know_idx中元素是shape为(num_gt_img, 1)，值为1的tensor, 后序用于记录每个目标框的索引</span>
        know_idx <span class="token operator">=</span> <span class="token punctuation">[</span>torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>t<span class="token punctuation">)</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> known<span class="token punctuation">]</span>
        <span class="token comment"># 记录batch中图片的ground truth的数量</span>
        known_num <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token builtin">sum</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> known<span class="token punctuation">]</span>
        <span class="token comment"># you can uncomment this to use fix number of dn queries</span>
        <span class="token comment"># if int(max(known_num))&gt;0:</span>
        <span class="token comment">#     scalar=scalar//int(max(known_num))</span>

        <span class="token comment"># can be modified to selectively denosie some label or boxes; also known label prediction</span>
        <span class="token comment"># torch.cat是把batch中所有的ground truth的索引排成一排</span>
        unmask_bbox <span class="token operator">=</span> unmask_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>known<span class="token punctuation">)</span>
        labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> targets<span class="token punctuation">]</span><span class="token punctuation">)</span>
        boxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>t<span class="token punctuation">[</span><span class="token string">'boxes'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> t <span class="token keyword">in</span> targets<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 记录每个ground truth的图片在在整个batch中是第几张图片</span>
        batch_idx <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>full_like<span class="token punctuation">(</span>t<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> i<span class="token punctuation">)</span> <span class="token keyword">for</span> i<span class="token punctuation">,</span> t <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>targets<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
		<span class="token comment"># 记录每个ground truth在整个batch中的位置，</span>
        known_indice <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>unmask_label <span class="token operator">+</span> unmask_bbox<span class="token punctuation">)</span>
        known_indice <span class="token operator">=</span> known_indice<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># add noise</span>
        <span class="token comment"># 将indice，labels,batch_id,bounding box复制到所有去噪组中去</span>
        known_indice <span class="token operator">=</span> known_indice<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>scalar<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        known_labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>scalar<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        known_bid <span class="token operator">=</span> batch_idx<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>scalar<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        known_bboxs <span class="token operator">=</span> boxes<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>scalar<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token comment"># 用于在label上添加噪声</span>
        known_labels_expaned <span class="token operator">=</span> known_labels<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
		<span class="token comment"># 用于在boxes上添加噪声</span>
        known_bbox_expand <span class="token operator">=</span> known_bboxs<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># noise on the label</span>
        <span class="token keyword">if</span> label_noise_scale <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        	<span class="token comment"># (scalar*num_gts_batch,) 从均匀分布中采样</span>
            p <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>known_labels_expaned<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token comment"># 选择一半的label进行添加噪声</span>
            chosen_indice <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>p <span class="token operator">&lt;</span> <span class="token punctuation">(</span>label_noise_scale<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment"># usually half of bbox noise</span>
            <span class="token comment"># 论文中的flip操作，随机选择任意的类别作为噪声</span>
            new_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint_like<span class="token punctuation">(</span>chosen_indice<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>  <span class="token comment"># randomly put a new one here</span>
            known_labels_expaned<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> chosen_indice<span class="token punctuation">,</span> new_label<span class="token punctuation">)</span>
        <span class="token comment"># noise on the box</span>
        <span class="token keyword">if</span> box_noise_scale <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            diff <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>known_bbox_expand<span class="token punctuation">)</span>
            <span class="token comment"># bounding box的中心点坐标</span>
            diff<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> known_bbox_expand<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">/</span> <span class="token number">2</span>
            <span class="token comment"># bounding box的猖狂</span>
            diff<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> known_bbox_expand<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
            <span class="token comment"># 在原来ground truth的boxes上加上偏移量，并且保证添加噪声后框的中心点在原来的框内</span>
            known_bbox_expand <span class="token operator">+=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>rand_like<span class="token punctuation">(</span>known_bbox_expand<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">2</span> <span class="token operator">-</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                           diff<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> box_noise_scale
            known_bbox_expand <span class="token operator">=</span> known_bbox_expand<span class="token punctuation">.</span>clamp<span class="token punctuation">(</span><span class="token builtin">min</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token builtin">max</span><span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>

        m <span class="token operator">=</span> known_labels_expaned<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        input_label_embed <span class="token operator">=</span> label_enc<span class="token punctuation">(</span>m<span class="token punctuation">)</span> <span class="token comment"># 对添加噪声的ground truth进行编码</span>
        <span class="token comment"># add dn part indicator</span>
        indicator1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span>input_label_embed<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        input_label_embed <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>input_label_embed<span class="token punctuation">,</span> indicator1<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 
        input_bbox_embed <span class="token operator">=</span> inverse_sigmoid<span class="token punctuation">(</span>known_bbox_expand<span class="token punctuation">)</span>
        single_pad <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token builtin">max</span><span class="token punctuation">(</span>known_num<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 整个batch中一张图片最多的ground truth的数量</span>
        pad_size <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>single_pad <span class="token operator">*</span> scalar<span class="token punctuation">)</span> <span class="token comment"># 相当于将同一个ground truth的不同噪声组拼接成一行，然后repeate成batch size行</span>
        padding_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>pad_size<span class="token punctuation">,</span> hidden_dim<span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        padding_bbox <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>pad_size<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># 将去噪任务和匹配任务的query拼接在一起</span>
        input_query_label <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>padding_label<span class="token punctuation">,</span> tgt<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        input_query_bbox <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>padding_bbox<span class="token punctuation">,</span> refpoint_emb<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

		<span class="token comment"># 由于上面input_query_label和input_query_box是padded的并且初始化为0，因此需要将每张图片真实有效的noised label和noisd boxes放到正确的位置上</span>
        <span class="token comment"># map in order</span>
        map_known_indice <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>known_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        	<span class="token comment"># 得到每个ground truth在每张图片上的独立索引</span>
            map_known_indice <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> num <span class="token keyword">in</span> known_num<span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment"># [1,2, 1,2,3]</span>
            <span class="token comment"># 计算每个ground truth在每张图片生成的所有去噪组上的索引</span>
            map_known_indice <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>map_known_indice <span class="token operator">+</span> single_pad <span class="token operator">*</span> i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>scalar<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>known_bid<span class="token punctuation">)</span><span class="token punctuation">:</span>
        	<span class="token comment"># 将去噪任务中的noised labels和noises boxes放到对应的位置上</span>
            input_query_label<span class="token punctuation">[</span><span class="token punctuation">(</span>known_bid<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> map_known_indice<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_label_embed <span class="token comment"># 属于那张图片，是这张图片上的第几个噪声组的第几个label</span>
            input_query_bbox<span class="token punctuation">[</span><span class="token punctuation">(</span>known_bid<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> map_known_indice<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> input_bbox_embed

        tgt_size <span class="token operator">=</span> pad_size <span class="token operator">+</span> num_queries <span class="token operator">*</span> num_patterns
        attn_mask <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>tgt_size<span class="token punctuation">,</span> tgt_size<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">0</span>
        <span class="token comment"># match query cannot see the reconstruct</span>
        attn_mask<span class="token punctuation">[</span>pad_size<span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>pad_size<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
        <span class="token comment"># reconstruct cannot see each other</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>scalar<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 按照制定的规则设置attention mask</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                attn_mask<span class="token punctuation">[</span>single_pad <span class="token operator">*</span> i<span class="token punctuation">:</span>single_pad <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> single_pad <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>pad_size<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
            <span class="token keyword">if</span> i <span class="token operator">==</span> scalar <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">:</span>
                attn_mask<span class="token punctuation">[</span>single_pad <span class="token operator">*</span> i<span class="token punctuation">:</span>single_pad <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>single_pad <span class="token operator">*</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                attn_mask<span class="token punctuation">[</span>single_pad <span class="token operator">*</span> i<span class="token punctuation">:</span>single_pad <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> single_pad <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>pad_size<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
                attn_mask<span class="token punctuation">[</span>single_pad <span class="token operator">*</span> i<span class="token punctuation">:</span>single_pad <span class="token operator">*</span> <span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>single_pad <span class="token operator">*</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">True</span>
        mask_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'known_indice'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>known_indice<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># (scalar*num_gts_batch,) 每个 gt 在整个 batch 中的索引</span>
            <span class="token string">'batch_idx'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>batch_idx<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token comment"># (num_gts_batch,)  每个 gt 所在图片的 batch 索引</span>
            <span class="token string">'map_known_indice'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span>map_known_indice<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># (num_gts_batch*scalar,)  噪声 queries(非 padding 的) 的索引</span>
            <span class="token string">'known_lbs_bboxes'</span><span class="token punctuation">:</span> <span class="token punctuation">(</span>known_labels<span class="token punctuation">,</span> known_bboxs<span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># (scalar*num_gts_batch,), (scalar*num_gts_batch,4)</span>
            <span class="token string">'know_idx'</span><span class="token punctuation">:</span> know_idx<span class="token punctuation">,</span>  <span class="token comment"># List[Tensor]: 其中每个 Tensor 的 shape 是 (num_gt_img,1)  每个 gt 在其图片中的索引</span>
            <span class="token string">'pad_size'</span><span class="token punctuation">:</span> pad_size  <span class="token comment"># 该 batch 中噪声 queries 的数量(包括 padding 的)</span>
        <span class="token punctuation">}</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># no dn for inference</span>
        input_query_label <span class="token operator">=</span> tgt<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># (num_queries*num_patterns,hidden_dim)-&gt;(batch_size,num_queries*num_patterns,hidden_dim)</span>
        input_query_bbox <span class="token operator">=</span> refpoint_emb<span class="token punctuation">.</span>repeat<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token comment"># (num_query*num_patterns,4)-&gt;(batch_size,num_query*num_patterns,4)</span>
        attn_mask <span class="token operator">=</span> <span class="token boolean">None</span>
        mask_dict <span class="token operator">=</span> <span class="token boolean">None</span>
        
	<span class="token comment"># 將 batch 的维度置换到第二維(dim1)，以适配 transformer 的輸入</span>
    input_query_label <span class="token operator">=</span> input_query_label<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    input_query_bbox <span class="token operator">=</span> input_query_bbox<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> input_query_label<span class="token punctuation">,</span> input_query_bbox<span class="token punctuation">,</span> attn_mask<span class="token punctuation">,</span> mask_dict
</code></pre> 
<p>其次从输出中分离去噪任务和匹配任务的部分：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">dn_post_process</span><span class="token punctuation">(</span>outputs_class<span class="token punctuation">,</span> outputs_coord<span class="token punctuation">,</span> mask_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    post process of dn after output from the transformer
    put the dn part in the mask_dict
    """</span>
    <span class="token keyword">if</span> mask_dict <span class="token keyword">and</span> mask_dict<span class="token punctuation">[</span><span class="token string">'pad_size'</span><span class="token punctuation">]</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token comment"># 取出去噪任务的结果</span>
        <span class="token comment"># (num_layers,batch,pad_size,num_classes)</span>
        output_known_class <span class="token operator">=</span> outputs_class<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>mask_dict<span class="token punctuation">[</span><span class="token string">'pad_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        <span class="token comment"># (num_layers,batch,pad_size,4)</span>
        output_known_coord <span class="token operator">=</span> outputs_coord<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span>mask_dict<span class="token punctuation">[</span><span class="token string">'pad_size'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        
		<span class="token comment"># 让 outputs_class &amp; outputs_coord 保持为原始 DETR 匹配任务的预测结果，与原始DETR架构兼容</span>
        outputs_class <span class="token operator">=</span> outputs_class<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> mask_dict<span class="token punctuation">[</span><span class="token string">'pad_size'</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        outputs_coord <span class="token operator">=</span> outputs_coord<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> mask_dict<span class="token punctuation">[</span><span class="token string">'pad_size'</span><span class="token punctuation">]</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>

        <span class="token comment"># 將去噪任务的预测結果记录到 mask_dict</span>
        mask_dict<span class="token punctuation">[</span><span class="token string">'output_known_lbs_bboxes'</span><span class="token punctuation">]</span><span class="token operator">=</span><span class="token punctuation">(</span>output_known_class<span class="token punctuation">,</span>output_known_coord<span class="token punctuation">)</span>
    <span class="token keyword">return</span> outputs_class<span class="token punctuation">,</span> outputs_coord
</code></pre> 
<p>然后是Loss计算前进行的预处理部分，主要对去噪任务的Query去Padding，仅对真实有效的Query计算Loss：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">prepare_for_loss</span><span class="token punctuation">(</span>mask_dict<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    prepare dn components to calculate loss
    Args:
        mask_dict: a dict that contains dn information
    """</span>
    <span class="token comment"># (num_layers,batch,pad_size,num_classes), (num_layers,batch,pad_size,4)</span>
    output_known_class<span class="token punctuation">,</span> output_known_coord <span class="token operator">=</span> mask_dict<span class="token punctuation">[</span><span class="token string">'output_known_lbs_bboxes'</span><span class="token punctuation">]</span>
    <span class="token comment"># (num_dn_groups*num_gts_batch,), (num_dn_groups*num_gts_batch,4)</span>
    known_labels<span class="token punctuation">,</span> known_bboxs <span class="token operator">=</span> mask_dict<span class="token punctuation">[</span><span class="token string">'known_lbs_bboxes'</span><span class="token punctuation">]</span>
    <span class="token comment"># (num_dn_groups*num_gts_batch,) 非 Padding 部分的 Queries 索引</span>
    map_known_indice <span class="token operator">=</span> mask_dict<span class="token punctuation">[</span><span class="token string">'map_known_indice'</span><span class="token punctuation">]</span>
	<span class="token comment"># (num_dn_groups*num_gts_batch,) 將所有 GT 在 Batch 中排序的索引</span>
    known_indice <span class="token operator">=</span> mask_dict<span class="token punctuation">[</span><span class="token string">'known_indice'</span><span class="token punctuation">]</span>
	<span class="token comment"># (num_gts_batch,) 每个 GT 所在图片的 Batch 索引(即是该 batch 中的第几张图)</span>
    batch_idx <span class="token operator">=</span> mask_dict<span class="token punctuation">[</span><span class="token string">'batch_idx'</span><span class="token punctuation">]</span>
    <span class="token comment"># (num_dn_groups*num_gts_batch,) 所有去噪組每个 GT/Queries 所在图片的 Batch 索引</span>
    bid <span class="token operator">=</span> batch_idx<span class="token punctuation">[</span>known_indice<span class="token punctuation">]</span>

	<span class="token comment"># 过滤，仅保留非 Padding 部分的 Quries 对应的预测结果</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>output_known_class<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        output_known_class <span class="token operator">=</span> output_known_class<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">(</span>bid<span class="token punctuation">,</span> map_known_indice<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
        output_known_coord <span class="token operator">=</span> output_known_coord<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">(</span>bid<span class="token punctuation">,</span> map_known_indice<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    num_tgt <span class="token operator">=</span> known_indice<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> known_labels<span class="token punctuation">,</span> known_bboxs<span class="token punctuation">,</span> output_known_class<span class="token punctuation">,</span> output_known_coord<span class="token punctuation">,</span> num_tgt
</code></pre> 
<p>最后是Loss计算部分：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">compute_dn_loss</span><span class="token punctuation">(</span>mask_dict<span class="token punctuation">,</span> training<span class="token punctuation">,</span> aux_num<span class="token punctuation">,</span> focal_alpha<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    compute dn loss in criterion
    Args:
        mask_dict: a dict for dn information
        training: training or inference flag
        aux_num: aux loss number
        focal_alpha:  for focal loss
    """</span>
    losses <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    <span class="token comment"># 先计算Transformer最后一层的预测结果对应的Loss</span>
    <span class="token keyword">if</span> training <span class="token keyword">and</span> <span class="token string">'output_known_lbs_bboxes'</span> <span class="token keyword">in</span> mask_dict<span class="token punctuation">:</span>
    	<span class="token comment"># 过滤掉Padding部分的Queries的预测记过，使得GT与Query的预测结果一一对应</span>
        known_labels<span class="token punctuation">,</span> known_bboxs<span class="token punctuation">,</span> output_known_class<span class="token punctuation">,</span> output_known_coord<span class="token punctuation">,</span> \
        num_tgt <span class="token operator">=</span> prepare_for_loss<span class="token punctuation">(</span>mask_dict<span class="token punctuation">)</span>
        losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>tgt_loss_labels<span class="token punctuation">(</span>output_known_class<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> known_labels<span class="token punctuation">,</span> num_tgt<span class="token punctuation">,</span> focal_alpha<span class="token punctuation">)</span><span class="token punctuation">)</span>
        losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>tgt_loss_boxes<span class="token punctuation">(</span>output_known_coord<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> known_bboxs<span class="token punctuation">,</span> num_tgt<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        losses<span class="token punctuation">[</span><span class="token string">'tgt_loss_bbox'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        losses<span class="token punctuation">[</span><span class="token string">'tgt_loss_giou'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        losses<span class="token punctuation">[</span><span class="token string">'tgt_loss_ce'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
        losses<span class="token punctuation">[</span><span class="token string">'tgt_class_error'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>

	<span class="token comment"># 计算Transformer除最后一层外其余每层预测结果对应的Loss</span>
    <span class="token keyword">if</span> aux_num<span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>aux_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># dn aux loss</span>
            <span class="token keyword">if</span> training <span class="token keyword">and</span> <span class="token string">'output_known_lbs_bboxes'</span> <span class="token keyword">in</span> mask_dict<span class="token punctuation">:</span>
                l_dict <span class="token operator">=</span> tgt_loss_labels<span class="token punctuation">(</span>output_known_class<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> known_labels<span class="token punctuation">,</span> num_tgt<span class="token punctuation">,</span> focal_alpha<span class="token punctuation">)</span>
                l_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k <span class="token operator">+</span> <span class="token string-interpolation"><span class="token string">f'_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> l_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>l_dict<span class="token punctuation">)</span>
                l_dict <span class="token operator">=</span> tgt_loss_boxes<span class="token punctuation">(</span>output_known_coord<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> known_bboxs<span class="token punctuation">,</span> num_tgt<span class="token punctuation">)</span>
                l_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k <span class="token operator">+</span> <span class="token string-interpolation"><span class="token string">f'_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> l_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>l_dict<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                l_dict <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
                l_dict<span class="token punctuation">[</span><span class="token string">'tgt_loss_bbox'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
                l_dict<span class="token punctuation">[</span><span class="token string">'tgt_class_error'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
                l_dict<span class="token punctuation">[</span><span class="token string">'tgt_loss_giou'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
                l_dict<span class="token punctuation">[</span><span class="token string">'tgt_loss_ce'</span><span class="token punctuation">]</span> <span class="token operator">=</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span>
                l_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>k <span class="token operator">+</span> <span class="token string-interpolation"><span class="token string">f'_</span><span class="token interpolation"><span class="token punctuation">{<!-- --></span>i<span class="token punctuation">}</span></span><span class="token string">'</span></span><span class="token punctuation">:</span> v <span class="token keyword">for</span> k<span class="token punctuation">,</span> v <span class="token keyword">in</span> l_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">}</span>
                losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>l_dict<span class="token punctuation">)</span>
    <span class="token keyword">return</span> losses

<span class="token keyword">def</span> <span class="token function">tgt_loss_boxes</span><span class="token punctuation">(</span>src_boxes<span class="token punctuation">,</span> tgt_boxes<span class="token punctuation">,</span> num_tgt<span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Compute the losses related to the bounding boxes, the L1 regression loss and the GIoU loss
       targets dicts must contain the key "boxes" containing a tensor of dim [nb_target_boxes, 4]
       The target boxes are expected in format (center_x, center_y, w, h), normalized by the image size.
    """</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tgt_boxes<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'tgt_loss_bbox'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'tgt_loss_giou'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>

	<span class="token comment"># 计算 L1 Loss</span>
    loss_bbox <span class="token operator">=</span> F<span class="token punctuation">.</span>l1_loss<span class="token punctuation">(</span>src_boxes<span class="token punctuation">,</span> tgt_boxes<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">)</span>

    losses <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
    losses<span class="token punctuation">[</span><span class="token string">'tgt_loss_bbox'</span><span class="token punctuation">]</span> <span class="token operator">=</span> loss_bbox<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_tgt

	<span class="token comment"># 计算 GIOU Loss</span>
    loss_giou <span class="token operator">=</span> <span class="token number">1</span> <span class="token operator">-</span> torch<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>box_ops<span class="token punctuation">.</span>generalized_box_iou<span class="token punctuation">(</span>
        box_ops<span class="token punctuation">.</span>box_cxcywh_to_xyxy<span class="token punctuation">(</span>src_boxes<span class="token punctuation">)</span><span class="token punctuation">,</span>
        box_ops<span class="token punctuation">.</span>box_cxcywh_to_xyxy<span class="token punctuation">(</span>tgt_boxes<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    losses<span class="token punctuation">[</span><span class="token string">'tgt_loss_giou'</span><span class="token punctuation">]</span> <span class="token operator">=</span> loss_giou<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_tgt
    <span class="token keyword">return</span> losses


<span class="token keyword">def</span> <span class="token function">tgt_loss_labels</span><span class="token punctuation">(</span>src_logits_<span class="token punctuation">,</span> tgt_labels_<span class="token punctuation">,</span> num_tgt<span class="token punctuation">,</span> focal_alpha<span class="token punctuation">,</span> log<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Classification loss (NLL)
    targets dicts must contain the key "labels" containing a tensor of dim [nb_target_boxes]
    """</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>tgt_labels_<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">{<!-- --></span>
            <span class="token string">'tgt_loss_ce'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            <span class="token string">'tgt_class_error'</span><span class="token punctuation">:</span> torch<span class="token punctuation">.</span>as_tensor<span class="token punctuation">(</span><span class="token number">0.</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
	<span class="token comment"># 增加Batch的维度</span>
    src_logits<span class="token punctuation">,</span> tgt_labels<span class="token operator">=</span> src_logits_<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tgt_labels_<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>

	<span class="token comment"># 制作One Hot类别标签，类别为(1,num_dn_groups*num_gts_batch,num_classes+1)</span>
    target_classes_onehot <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span>src_logits<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> src_logits<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> src_logits<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                        dtype<span class="token operator">=</span>src_logits<span class="token punctuation">.</span>dtype<span class="token punctuation">,</span> layout<span class="token operator">=</span>src_logits<span class="token punctuation">.</span>layout<span class="token punctuation">,</span> device<span class="token operator">=</span>src_logits<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
    target_classes_onehot<span class="token punctuation">.</span>scatter_<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> tgt_labels<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    target_classes_onehot <span class="token operator">=</span> target_classes_onehot<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
	
	<span class="token comment"># 计算Focal Loss</span>
    loss_ce <span class="token operator">=</span> sigmoid_focal_loss<span class="token punctuation">(</span>src_logits<span class="token punctuation">,</span> target_classes_onehot<span class="token punctuation">,</span> num_tgt<span class="token punctuation">,</span> alpha<span class="token operator">=</span>focal_alpha<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">*</span> src_logits<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>

    losses <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'tgt_loss_ce'</span><span class="token punctuation">:</span> loss_ce<span class="token punctuation">}</span>

    losses<span class="token punctuation">[</span><span class="token string">'tgt_class_error'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">-</span> accuracy<span class="token punctuation">(</span>src_logits_<span class="token punctuation">,</span> tgt_labels_<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> losses

<span class="token keyword">def</span> <span class="token function">sigmoid_focal_loss</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> num_boxes<span class="token punctuation">,</span> alpha<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.25</span><span class="token punctuation">,</span> gamma<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    Loss used in RetinaNet for dense detection: https://arxiv.org/abs/1708.02002.
    Args:
        inputs: A float tensor of arbitrary shape.
                The predictions for each example.
        targets: A float tensor with the same shape as inputs. Stores the binary
                 classification label for each element in inputs
                (0 for the negative class and 1 for the positive class).
        alpha: (optional) Weighting factor in range (0,1) to balance
                positive vs negative examples. Default = -1 (no weighting).
        gamma: Exponent of the modulating factor (1 - p_t) to
               balance easy vs hard examples.
    Returns:
        Loss tensor
    """</span>

    <span class="token comment"># 將原始输出转换为 0~1 概率</span>
    prob <span class="token operator">=</span> inputs<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 计算二元交叉熵损失</span>
    <span class="token comment"># (1,num_dn_groups*num_gts_batch,num_classes)</span>
    ce_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> targets<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">)</span>
    <span class="token comment"># focal loss 的套路：降低置信度高的样本(包括正負樣本)的权重，对原始 BCE Loss 加权</span>
    p_t <span class="token operator">=</span> prob <span class="token operator">*</span> targets <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> prob<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> targets<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> ce_loss <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> p_t<span class="token punctuation">)</span> <span class="token operator">**</span> gamma<span class="token punctuation">)</span>

    <span class="token comment"># 对正负样本加权</span>
    <span class="token keyword">if</span> alpha <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        alpha_t <span class="token operator">=</span> alpha <span class="token operator">*</span> targets <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> targets<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> alpha_t <span class="token operator">*</span> loss

    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_boxes
</code></pre> 
<p>以上就是DN DETR的主要代码，总而言之，一方面去噪任务中Query与GT是确定性关系，避免了匈牙利匹配带来的不稳定；另外一方面，多个去噪Groups的设置，相当于引入了One-to-Many的学习方式，使得模型学习更加充分。优化有网络的收敛速度和精度都有明显提升：<br> <img src="https://images2.imgbox.com/25/f2/YY5gQlZT_o.png" alt="在这里插入图片描述" width="700"></p> 
<h3><a id="2_DINO_400"></a>2. DINO</h3> 
<p>DINO发表于2023年3月份，该模型的主要从Contrastive Denosing、Mix Query Slection和Look Forward Twice三个方面进行优化，第一次让DETR系列的检测器取得了目标检测SOTA性能。下面我们从这三个方面依次展开学习下细节：</p> 
<h4><a id="21_Contrastive_Denoising_402"></a>2.1 Contrastive Denoising</h4> 
<p>在DN DETR中的去噪部分，我们为每一个真值都分配了一组带不同噪声的Query，作者认为这样会导致所有和去噪相关的Query<strong>只会学习正样本，而缺少了对负样本的学习</strong>。因此<strong>对于噪声较大的Query，我们就应该认为其为负样本，在去噪任务中监督‘No Object’类别</strong>，如下图所示：<br> <img src="https://images2.imgbox.com/07/2e/YPT7JeBt_o.png" alt="在这里插入图片描述" width="700"><br> 如上右图所示，训练过程中会设置两个超参<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          λ 
         
        
          1 
         
        
       
      
        \lambda_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          λ 
         
        
          2 
         
        
       
      
        \lambda_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，当噪声水平小于<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          λ 
         
        
          1 
         
        
       
      
        \lambda_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>时，我们就认为其是正样本，当噪声水平大于<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          λ 
         
        
          1 
         
        
       
      
        \lambda_1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>并且小于<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          λ 
         
        
          2 
         
        
       
      
        \lambda_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>时，我们就认为其是负样本，负责预测‘No Object’类别。并且作者在论文中提到，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          λ 
         
        
          2 
         
        
       
      
        \lambda_2 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>也会设置得比较小，这样<strong>可以使得Query去学会区分位于真值附近的负样本难例，进一步抑制模型对同一目标输出重复框</strong>，如下图所示，左图是DN DETR的检测结果，在箭头所指的小男孩区域网络输出了三个重叠的检测框，但是在右侧DINO的检测结果中这个问题得到了改善：<br> <img src="https://images2.imgbox.com/64/e1/li8o0KfT_o.png" alt="在这里插入图片描述" width="800"><br> 在训练过程中，每个去噪Group会有<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         2 
        
       
         × 
        
       
         n 
        
       
      
        2\times n 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7278em; vertical-align: -0.0833em;"></span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">n</span></span></span></span></span>个Queries，对于正样本的监督对Box回归仍然是采用L1和GIOU Loss，分类仍然是采用Focal Loss，对于负样本则仅使用Focal Loss对分类进行监督。</p> 
<h4><a id="32_Mix_Query_408"></a>3.2 Mix Query</h4> 
<p><img src="https://images2.imgbox.com/7e/4f/rpWDGdOn_o.png" alt="在这里插入图片描述" width="1000"></p> 
<p>在原始DETR和DN DETR中，在训练和推理的过程中Decoder <strong>Content Queries都是初始化为全0</strong>的Tensor并不会从Encoder Features里面获取任何信息，而<strong>Positional Queries则是一个通过nn.Embedding初始化</strong>并且可学习的Tensor；Deformable DETR的Decoder中<strong>Content Quires和Positional Queries均是可学习的</strong>，为了进一步提高性能，Deformable DETR可以执行一个二阶段的筛选，<strong>从Encoder输出的Feature中选择得分Top K的特征Tensor来作为Decoder Quries的先验</strong>。</p> 
<p>在DINO DETR将上述两种方式进行了混合，Positional Quires从Encoder的Top K的特征中进行初始化，而Content Queries仍然初始化为全为0的Tensor，作者认为，<strong>Encoder输出的特征还没有进过Decoder的Refinement</strong>，作为Content先验会导致混淆，比如一个选择的Feature可能包括多个物体或者一个物体的一部分，但是作为Positional Queris先验是可以帮助更好地去从Encoder中获取信息的。</p> 
<h4><a id="33_Look_Forward_Twice_415"></a>3.3 Look Forward Twice</h4> 
<p><img src="https://images2.imgbox.com/54/f4/VIVblx1X_o.png" alt="在这里插入图片描述" width="900"><br> 在Deformable DETR中，为了稳定训练过程在Iterative Box Refinement在会进行Gradient Detached，上图虚线表示的就是Gradient Detached的位置，在Look Forward Once模式中，<strong>第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层的参数只会被第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层的Auxiliary Loss所更新</strong>，但是作者认为，结合上一层的Refinement信息来对当前层的Box进行预测会更有帮助，因此在Look Forward Twice模式中，<strong>第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层的参数会同时被第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
       
         i 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层和第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          i 
         
        
          + 
         
        
          1 
         
        
       
         i+1 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7429em; vertical-align: -0.0833em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>层的Auxiliary Loss所影响</strong>，具体影响方式如下：</p> 
<p>对于每一层的预测<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          b 
         
        
          i 
         
         
         
           ( 
          
         
           p 
          
         
           r 
          
         
           e 
          
         
           d 
          
         
           ) 
          
         
        
       
      
        b_i^{(pred)} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">p</span><span class="mord mathnormal mtight">re</span><span class="mord mathnormal mtight">d</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的精度主要由<strong>当前层的初值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
          
          
            i 
           
          
            − 
           
          
            1 
           
          
         
        
       
         b_{i-1} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span></strong>（即上一层的预测值）和<strong>当前层的预测偏移</strong><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Δ 
        
        
        
          b 
         
        
          i 
         
        
       
      
        \Delta b_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>两部分决定，对于Look Forward Once，第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层的Auxiliary Loss产生的梯度仅更新预测偏移<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Δ 
        
        
        
          b 
         
        
          i 
         
        
       
      
        \Delta b_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，梯度信息会在第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层到第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
         − 
        
       
         1 
        
       
      
        i-1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7429em; vertical-align: -0.0833em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>层中被Detach掉；但是对于Look Forward Twice，则同时更新当前层的初值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          b 
         
         
         
           i 
          
         
           − 
          
         
           1 
          
         
        
       
      
        b_{i-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和当前层的预测偏移<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Δ 
        
        
        
          b 
         
        
          i 
         
        
       
      
        \Delta b_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>两部分，如何更新初值<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          b 
         
         
         
           i 
          
         
           − 
          
         
           1 
          
         
        
       
      
        b_{i-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>呢？最简单的办法就是直接将<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          b 
         
         
         
           i 
          
         
           − 
          
         
           1 
          
         
        
       
      
        b_{i-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span> Gradient Detach前的<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          b 
         
         
         
           i 
          
         
           − 
          
         
           1 
          
         
        
          ′ 
         
        
       
      
        b_{i-1}^{\prime} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0689em; vertical-align: -0.317em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4413em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.317em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Δ 
        
        
        
          b 
         
        
          i 
         
        
       
      
        \Delta b_{i} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>相加作为第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层的输出，如下步骤所示：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Δ 
         
         
         
           b 
          
         
           i 
          
         
        
          = 
         
         
          
          
            Layer 
           
          
            ⁡ 
           
          
         
           i 
          
         
         
         
           ( 
          
          
          
            b 
           
           
           
             i 
            
           
             − 
            
           
             1 
            
           
          
         
           ) 
          
         
        
       
         \Delta b_i=\operatorname{Layer}_{\mathrm{i}}\left(b_{i-1}\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mop"><span class="mord mathrm">Layer</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2234em;"><span class="" style="top: -2.4559em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2441em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
         
           i 
          
         
           ′ 
          
         
        
          = 
         
        
          Update 
         
        
          ⁡ 
         
         
         
           ( 
          
          
          
            b 
           
           
           
             i 
            
           
             − 
            
           
             1 
            
           
          
         
           , 
          
         
           Δ 
          
          
          
            b 
           
          
            i 
           
          
         
           ) 
          
         
        
       
         b_i^{\prime}=\operatorname{Update}\left(b_{i-1}, \Delta b_i\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0489em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Update</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
         
           i 
          
         
        
          = 
         
        
          Detach 
         
        
          ⁡ 
         
         
         
           ( 
          
          
          
            b 
           
          
            i 
           
          
            ′ 
           
          
         
           ) 
          
         
        
       
         b_i=\operatorname{Detach}\left(b_i^{\prime}\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0519em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Detach</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
         
           i 
          
         
           (pred)  
          
         
        
          = 
         
        
          Update 
         
        
          ⁡ 
         
         
         
           ( 
          
          
          
            b 
           
           
           
             i 
            
           
             − 
            
           
             1 
            
           
          
            ′ 
           
          
         
           , 
          
         
           Δ 
          
          
          
            b 
           
          
            i 
           
          
         
           ) 
          
         
        
       
         b_i^{\text {(pred) }}=\operatorname{Update}\left(b_{i-1}^{\prime}, \Delta b_i\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.3217em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.0448em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.2198em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">(pred) </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.2em; vertical-align: -0.35em;"></span><span class="mop"><span class="mord mathrm">Update</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3053em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span></span></span></span></span></span>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Update 
        
       
         ⁡ 
        
       
         ( 
        
       
         ⋅ 
        
       
         , 
        
       
         ⋅ 
        
       
         ) 
        
       
      
        \operatorname{Update}(\cdot, \cdot) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Update</span></span><span class="mopen">(</span><span class="mord">⋅</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">⋅</span><span class="mclose">)</span></span></span></span></span>是通过预测的偏移<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Δ 
        
        
        
          b 
         
        
          i 
         
        
       
      
        \Delta b_i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord">Δ</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>更新<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          b 
         
         
         
           i 
          
         
           − 
          
         
           1 
          
         
        
       
      
        b_{i-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>。</p> 
<p>如下是各个模块带来的收益，可以看到Mixed Query Selection、Contrastive Denoising，Look Forward Twice分别带来了0.5，0.5和0.4的提高<br> <img src="https://images2.imgbox.com/b5/f6/GN8Ihk4d_o.png" alt="在这里插入图片描述"></p> 
<p>最终，DINO的和其他SOTA方法的对比如下：<br> <img src="https://images2.imgbox.com/40/6d/TFOLpA6b_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="3_Sparse_DETR_436"></a>3. Sparse DETR</h3> 
<p>Sparser DETR发表于ICLR 2022，前面的文章优化的角度主要是如何加快DETR训练的收敛速度和收敛精度，而本文考虑的主要是如何优化推理速度，主要贡献是通过Sparse Query的方式降低Encoder复杂度，从而在Deformable DETR的基础上将推理速度提高了38%</p> 
<h4><a id="31_Encoder_Token_Sparsification_439"></a>3.1 Encoder Token Sparsification</h4> 
<p>作者在文章中首先分析到Deformable DETR使用多尺度特征虽然提高了检测器的性能，但是同时也增加了更多的Query，<strong>导致Deformable DETR的推理速度实际上比原始DETR还要慢</strong>。而实际上我们检测的图像通常包含大量的背景区域，背景区域的Query和前景区域的Query被同等对待会造成大量的冗余计算，在Deformable DETR中使用Two Stage模式证明了<strong>仅使用前景区域的Query可以实现更好的检测性能</strong>，在本文中，作者通过实验发现：</p> 
<ol><li>在COCO数据集上对一个完全收敛的Deformable DETR进行推理，发现Decoder相关的Encoder中的Token数量仅占总数量的45%</li><li>从头重新训练一个新的检测器，但是只更新部分Encoder Token，这些Encoder Token是根据另外一个已经充分训练好的检测器的Decoder挑选的，新训练的检测器大约只有0.1AP的性能损失。</li></ol> 
<p>由此可见对Encoder Token进行稀疏化是一个可行的优化方向，那么如何进行稀疏化呢？本文Sparse DETR，主要网络结构如下：<br> <img src="https://images2.imgbox.com/8b/2a/cxWFG1jd_o.png" alt="在这里插入图片描述" width="800"><br> Sparse DETR中核心的三个模块分别是Scoring Network，Encoder Auxiliary Loss和Top-K Decoder Queries，下面分别介绍</p> 
<h4><a id="32_Scoring_Network_448"></a>3.2 Scoring Network</h4> 
<p>Scoring Network的作用是输入一个Encoder的特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          feat  
         
        
       
      
        \mathbf{x}_{\text {feat }} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5944em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">feat </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和保留比例<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ρ 
        
       
      
        \rho 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">ρ</span></span></span></span></span>，输出的是特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
        
          feat  
         
        
       
      
        \mathbf{x}_{\text {feat }} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.5944em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">feat </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>中每个Token的显著度，其中满足前<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ρ 
        
       
         % 
        
       
      
        \rho \% 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9444em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">ρ</span><span class="mord">%</span></span></span></span></span>显著度的区域定义为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Ω 
         
        
          s 
         
        
          ρ 
         
        
       
      
        \Omega_s^\rho 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9303em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ρ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，对于第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
      
        i 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6595em;"></span><span class="mord mathnormal">i</span></span></span></span></span>层的Layer更新第<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         i 
        
       
         − 
        
       
         1 
        
       
      
        i-1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7429em; vertical-align: -0.0833em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>层特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          x 
         
         
         
           i 
          
         
           − 
          
         
           1 
          
         
        
       
      
        \mathbf{x}_{i-1} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6528em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span></span></span></span></span>的方式如下：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           x 
          
         
           i 
          
         
           j 
          
         
        
          = 
         
         
         
           { 
          
          
           
            
             
              
              
                x 
               
               
               
                 i 
                
               
                 − 
                
               
                 1 
                
               
              
                j 
               
              
             
            
            
             
              
              
                j 
               
              
                ∉ 
               
               
               
                 Ω 
                
               
                 s 
                
               
                 ρ 
                
               
              
             
            
           
           
            
             
              
              
                LN 
               
              
                ⁡ 
               
               
               
                 ( 
                
               
                 FFN 
                
               
                 ⁡ 
                
                
                
                  ( 
                 
                 
                 
                   z 
                  
                 
                   i 
                  
                 
                   j 
                  
                 
                
                  ) 
                 
                
               
                 + 
                
                
                
                  z 
                 
                
                  i 
                 
                
                  j 
                 
                
               
                 ) 
                
               
              
             
            
            
             
              
              
                j 
               
              
                ∈ 
               
               
               
                 Ω 
                
               
                 s 
                
               
                 ρ 
                
               
              
                , 
               
              
                 where  
               
               
               
                 z 
                
               
                 i 
                
               
                 j 
                
               
              
                = 
               
              
                LN 
               
              
                ⁡ 
               
               
               
                 ( 
                
               
                 DefAttn 
                
               
                 ⁡ 
                
                
                
                  ( 
                 
                 
                 
                   x 
                  
                  
                  
                    i 
                   
                  
                    − 
                   
                  
                    1 
                   
                  
                 
                   j 
                  
                 
                
                  , 
                 
                 
                 
                   x 
                  
                  
                  
                    i 
                   
                  
                    − 
                   
                  
                    1 
                   
                  
                 
                
                  ) 
                 
                
               
                 + 
                
                
                
                  x 
                 
                 
                 
                   i 
                  
                 
                   − 
                  
                 
                   1 
                  
                 
                
                  j 
                 
                
               
                 ) 
                
               
              
                , 
               
              
             
            
           
          
         
        
       
         \mathbf{x}_i^j= \begin{cases}\mathbf{x}_{i-1}^j &amp; j \notin \Omega_s^\rho \\ \operatorname{LN}\left(\operatorname{FFN}\left(\mathbf{z}_i^j\right)+\mathbf{z}_i^j\right) &amp; j \in \Omega_s^\rho, \text { where } \mathbf{z}_i^j=\operatorname{LN}\left(\operatorname{DefAttn}\left(\mathbf{x}_{i-1}^j, \mathbf{x}_{i-1}\right)+\mathbf{x}_{i-1}^j\right),\end{cases} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.2194em; vertical-align: -0.2769em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.24em; vertical-align: -1.37em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size4">{<!-- --></span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.87em;"><span class="" style="top: -4.012em;"><span class="pstrut" style="height: 3.15em;"></span><span class="mord"><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3352em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -2.43em;"><span class="pstrut" style="height: 3.15em;"></span><span class="mord"><span class="mop"><span class="mord mathrm">LN</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mop"><span class="mord mathrm">FFN</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathbf">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord"><span class="mord mathbf">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.37em;"><span class=""></span></span></span></span></span><span class="arraycolsep" style="width: 1em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.87em;"><span class="" style="top: -4.012em;"><span class="pstrut" style="height: 3.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel"><span class="mord"><span class="mrel">∈</span></span><span class="mord vbox"><span class="thinbox"><span class="llap"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="inner"><span class="mord"><span class="mord">/</span><span class="mspace" style="margin-right: 0.0556em;"></span></span></span><span class="fix"></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ρ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -2.43em;"><span class="pstrut" style="height: 3.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ρ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord text"><span class="mord"> where </span></span><span class="mord"><span class="mord mathbf">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2769em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mop"><span class="mord mathrm">LN</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mop"><span class="mord mathrm">DefAttn</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3352em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9426em;"><span class="" style="top: -2.4231em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.1809em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.3352em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.37em;"><span class=""></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span>即属于高显著度区域的Token通过Deformable Attention进行Refine，而属于低显著度区域的Token则直接透传。</p> 
<p><strong>那么如何训练Scoring Network或者说如何定义显著度这个指标呢？</strong></p> 
<p>在介绍最终的方法前，论文中首先提到了一种使用Objectness Score的方法，Objectness Score指的是在Backbone的Feature上直接接一个和最终检测头相同的结构的检测头，并同样使用匈牙利计算损失，这个检测头输出的前<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ρ 
        
       
         % 
        
       
      
        \rho \% 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9444em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">ρ</span><span class="mord">%</span></span></span></span></span>得分的检测结果就可以作为高显著度区域<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          Ω 
         
        
          s 
         
        
          ρ 
         
        
       
      
        \Omega_s^\rho 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9303em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord">Ω</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -2.453em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">s</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">ρ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，这个方法是简单有效的，但是问题也很明显，其计算高显著度区域的过程中完全没有考虑到Decoder</p> 
<p>在本文中是<strong>使用Transfomer中的Decoder Cross Attention Map（DAM）进行定义的</strong>，使用DAM的原因是在训练过程中Decoder的Attention就是逐步集中到到Encoder输出Token的部分子集上的，这和我们想要的显著度的定义一脉相承。<strong>在Dense Attention中，DAM可以直接通过将各层Decoder Layer中的Attention Map相加，在Deformable Attention中，DAM可以将Offsets和Encoder Tokens相关的Object Queries的Attention Weights进行累加。</strong> 然后我们将这些累加获得的DAM作为伪真值建立一个BCE损失来训练一个Scoring Network：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           L 
          
         
           dam  
          
         
        
          = 
         
        
          − 
         
         
         
           1 
          
         
           N 
          
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           N 
          
         
        
          BCE 
         
        
          ⁡ 
         
         
         
           ( 
          
         
           g 
          
          
           
           
             ( 
            
            
            
              x 
             
            
              feat  
             
            
           
             ) 
            
           
          
            i 
           
          
         
           , 
          
          
           
           
             D 
            
           
             A 
            
           
             M 
            
           
          
            i 
           
           
           
             b 
            
           
             i 
            
           
             n 
            
           
          
         
           ) 
          
         
        
       
         \mathcal{L}_{\text {dam }}=-\frac{1}{N} \sum_{i=1}^N \operatorname{BCE}\left(g\left(\mathbf{x}_{\text {feat }}\right)_i, \mathrm{DAM}_i^{\mathrm{bin}}\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathcal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">dam </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3.106em; vertical-align: -1.2777em;"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.3214em;"><span class="" style="top: -2.314em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.686em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.8283em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mop"><span class="mord mathrm">BCE</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size2">(</span></span><span class="mord mathnormal" style="margin-right: 0.0359em;">g</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathbf">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">feat </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.162em;"><span class="" style="top: -2.4003em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2997em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">DAM</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.9223em;"><span class="" style="top: -2.453em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span class="" style="top: -3.1362em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathrm mtight">bin</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size2">)</span></span></span></span></span></span></span></span>上述流程可以通过下图进行总结：<br> <img src="https://images2.imgbox.com/9f/cf/lLeYC71f_o.png" alt="在这里插入图片描述" width="800"><br> 论文中提到，可能有的同学会觉得在训练前期，Decoder收敛效果不好可能会影响到DAM的准确性，但是通过实验就是证明使用DAM会比Objectness Score效果要好，如下图所示：<br> <img src="https://images2.imgbox.com/94/26/RHpBV9DM_o.png" alt="在这里插入图片描述" width="700"></p> 
<h4><a id="33_Encoder_Auxiliary_Loss_and_TopK_Decoder_Queries_464"></a>3.3 Encoder Auxiliary Loss and Top-K Decoder Queries</h4> 
<p>在DETR中，Auxilary Loss通常是加载Decoder Layer上，在Encoder中由于Encoder Token的数量太多，Encoder Auxiliary Loss将会带来巨大的计算量，但是在Sparse DETR中，由于Encoder Token已经被稀疏化，因此添加Auxiliary Loss并不会造成过大的负担，因此在Spase DETR中添加了Encoder Auxiliary Loss帮助区分Encoder中的混淆特征，进一步提高模型的最终检测性能，如下左图就体现了添加了Auxiliary Loss的收益：<br> <img src="https://images2.imgbox.com/ea/7b/f4QiDzfB_o.png" alt="在这里插入图片描述" width="500"><br> 在Deformable DETR的Two Stage模式中，是通过Decoder的检测头对Encoder的Feature进行打分，然后选取部分Feature进行Object Query的初始化，在Sparser DETR中，由于我们加了Auxiliary Loss，因为我们可以通过Auxiliary Detection Head对Encoder输出的特征进行打分，然后选取部分作为Decoder Queries的初始化。</p> 
<p>综上所述是Sparse DETR的主要内容，如下是精度和效率对比：<br> <img src="https://images2.imgbox.com/0e/22/uoYRQxtv_o.png" alt="在这里插入图片描述" width="800"><br> 可以看到，Sparse DETR在FPS提高的基础上，AP相对于Deformable DETR并没有下降。总而言之，<strong>Sparse DETR主要是通过添加一个Scoring Network输出一个Deformable Attention Map来对Encoder Token进行稀疏化，正式由于稀疏化带来的好处，进一步引入了Encoder Auxiliary Loss和Top-K Decoder Queries来提升网络性能</strong>。</p> 
<h3><a id="4_Lite_DETR_473"></a>4. Lite DETR</h3> 
<p>Lite DETR发表于CVPR 2023，通Sparse DETR一样，Lite DETR考虑的主要是如何优化推理速度，在本文中通过Interleaved Update和Key-aware Deformable Attention使得在降低60%的GFLOPS的基础上保持了99%的检测精度</p> 
<h4><a id="41_Motivation_and_Analysis_476"></a>4.1 Motivation and Analysis</h4> 
<p>Multi Scale Features对于DETR的精度提升是重要的，但是高分辨率特征的Token的数量是低分辨率的4倍，在DINO中，如果去掉<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
         / 
        
       
         8 
        
       
      
        1/8 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1/8</span></span></span></span></span>分辨率（高分辨率）Feature上的Token的话将在GLOPS上减少48%，但是AP也会损失4.9%，在小目标AP上的损失甚至会达到10.2%。作者认为**，高分辨率特征只拥有的是局部信息更容易收敛，并且在多尺度特征训练的过程中，这些局部信息是会有冗余的**，因此作者考虑是否有办法<strong>在训练过程中更加关注与低分辨率特征的更新，减少高分辨率特征更新计算同时保持整个网络的性能。</strong></p> 
<h4><a id="42_Interleaved_Update_479"></a>4.2 Interleaved Update</h4> 
<p>论文将多尺度特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         S 
        
       
      
        S 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span></span></span></span></span>划分为低层级特征（高分辨率）<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          L 
         
        
       
         ∈ 
        
        
        
          R 
         
         
          
          
            N 
           
          
            L 
           
          
         
           × 
          
          
          
            d 
           
          
            model  
           
          
         
        
       
      
        F_L \in \mathbb{R}^{N_L \times d_{\text {model }}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.109em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1433em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>和高层级特征（低分辨率）<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          H 
         
        
       
         ∈ 
        
        
        
          R 
         
         
          
          
            N 
           
          
            H 
           
          
         
           × 
          
          
          
            d 
           
          
            model  
           
          
         
        
       
      
        F_H \in \mathbb{R}^{N_H \times d_{\text {model }}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3567em; margin-left: -0.109em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1433em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          N 
         
        
          H 
         
        
       
      
        N_H 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          N 
         
        
          L 
         
        
       
      
        N_L 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>分辨是两者的Token数量，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          N 
         
        
          H 
         
        
       
         ≈ 
        
       
         6 
        
       
         % 
        
       
         ∼ 
        
       
         33 
        
       
         % 
        
        
        
          N 
         
        
          L 
         
        
       
      
        N_H \approx 6 \% \sim 33 \% N_L 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8056em; vertical-align: -0.0556em;"></span><span class="mord">6%</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∼</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.9em; vertical-align: -0.15em;"></span><span class="mord">33%</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，在Lite DETR的网络结构中，会在更新<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         A 
        
       
      
        A 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal">A</span></span></span></span></span>次高层级特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          H 
         
        
       
      
        F_H 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>后只更新<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         1 
        
       
      
        1 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">1</span></span></span></span></span>次低层级特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          L 
         
        
       
      
        F_L 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，这种更新方式就被定义为Interleaved Update。<br> <img src="https://images2.imgbox.com/78/e2/CaAJMDXq_o.png" alt="在这里插入图片描述" width="800"></p> 
<p>对于高层级特征的更新方式如下：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Q 
         
        
          = 
         
         
         
           F 
          
         
           H 
          
         
        
          , 
         
        
          K 
         
        
          = 
         
        
          V 
         
        
          = 
         
        
          Concat 
         
        
          ⁡ 
         
         
         
           ( 
          
          
          
            F 
           
          
            H 
           
          
         
           , 
          
          
          
            F 
           
          
            L 
           
          
         
           ) 
          
         
        
       
         \mathbf{Q}=F_H, \mathbf{K}=\mathbf{V}=\operatorname{Concat}\left(F_H, F_L\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8805em; vertical-align: -0.1944em;"></span><span class="mord mathbf">Q</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8805em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">K</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Concat</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           F 
          
         
           H 
          
         
           ′ 
          
         
        
          = 
         
        
          K 
         
        
          D 
         
        
          A 
         
        
          ( 
         
        
          Q 
         
        
          , 
         
        
          K 
         
        
          , 
         
        
          V 
         
        
          ) 
         
        
       
         F_H^{\prime}=K D A(\mathbf{Q}, \mathbf{K}, \mathbf{V}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0489em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">KD</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mclose">)</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
           Output  
         
        
          = 
         
        
           Concat  
         
         
         
           ( 
          
          
          
            F 
           
          
            H 
           
          
            ′ 
           
          
         
           , 
          
          
          
            F 
           
          
            L 
           
          
         
           ) 
          
         
        
       
         \text { Output }=\text { Concat }\left(F_H^{\prime}, F_L\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord text"><span class="mord"> Output </span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0519em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord"> Concat </span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         K 
        
       
         A 
        
       
         D 
        
       
      
        KAD 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">K</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right: 0.0278em;">D</span></span></span></span></span>为Key-aware Deformable Attention，下文将介绍。<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Q 
        
       
      
        \mathbf{Q} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8805em; vertical-align: -0.1944em;"></span><span class="mord mathbf">Q</span></span></span></span></span>是高层级特征，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         K 
        
       
      
        \mathbf{K} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf">K</span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         V 
        
       
      
        \mathbf{V} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span></span></span></span></span>为高低层级特征，输出则是将更新后的高层级特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          H 
         
        
          ′ 
         
        
       
      
        F_H^{\prime} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0272em; vertical-align: -0.2753em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4247em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2753em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和未更新的低层级特征<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          H 
         
        
          ′ 
         
        
       
      
        F_H^{\prime} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0272em; vertical-align: -0.2753em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4247em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2753em;"><span class=""></span></span></span></span></span></span></span></span></span></span>Concate结果，在这个过程中，<strong>高层级特征和高层级特征进行Attention时类似于Self Attention，在和低层级特征进行Attention时类似于Cross Attention</strong>。</p> 
<p>对于低层级特征的更新方式如下：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Q 
         
        
          = 
         
         
         
           F 
          
         
           L 
          
         
        
          , 
         
        
          K 
         
        
          = 
         
        
          V 
         
        
          = 
         
        
          Concat 
         
        
          ⁡ 
         
         
         
           ( 
          
          
          
            F 
           
          
            H 
           
          
            ′ 
           
          
         
           , 
          
          
          
            F 
           
          
            L 
           
          
         
           ) 
          
         
        
       
         \mathbf{Q}=F_L, \mathbf{K}=\mathbf{V}=\operatorname{Concat}\left(F_H^{\prime}, F_L\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8805em; vertical-align: -0.1944em;"></span><span class="mord mathbf">Q</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8805em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">K</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0519em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Concat</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3283em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           F 
          
         
           L 
          
         
           ′ 
          
         
        
          = 
         
        
          K 
         
        
          D 
         
        
          A 
         
        
          ( 
         
        
          Q 
         
        
          , 
         
        
          K 
         
        
          , 
         
        
          V 
         
        
          ) 
         
        
       
         F_L^{\prime}=K D A(\mathbf{Q}, \mathbf{K}, \mathbf{V}) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0489em; vertical-align: -0.247em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">KD</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mclose">)</span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
           Output  
         
        
          = 
         
        
           Concat  
         
         
         
           ( 
          
          
          
            F 
           
          
            L 
           
          
            ′ 
           
          
         
           , 
          
          
          
            F 
           
          
            H 
           
          
            ′ 
           
          
         
           ) 
          
         
        
       
         \text { Output }=\text { Concat }\left(F_L^{\prime}, F_H^{\prime}\right) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord text"><span class="mord"> Output </span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.0519em; vertical-align: -0.25em;"></span><span class="mord text"><span class="mord"> Concat </span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8019em;"><span class="" style="top: -2.453em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.247em;"><span class=""></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;">)</span></span></span></span></span></span></span>其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          H 
         
        
          ′ 
         
        
       
      
        F_H^{\prime} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0272em; vertical-align: -0.2753em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4247em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0813em;">H</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2753em;"><span class=""></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          F 
         
        
          L 
         
        
          ′ 
         
        
       
      
        F_L^{\prime} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0272em; vertical-align: -0.2753em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.7519em;"><span class="" style="top: -2.4247em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">L</span></span></span><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2753em;"><span class=""></span></span></span></span></span></span></span></span></span></span>分别为更新后的高层级特征和低层级特征。为了进一步减小计算量，在Deformable Attention计算时使用的Feed Forward的隐藏层通道数也进行了适当的减小。</p> 
<h4><a id="43_Keyaware_Deformable_Attention_498"></a>4.3 Key-aware Deformable Attention</h4> 
<p>在原始的Deformable DETR中，Query <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Q 
        
       
      
        Q 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">Q</span></span></span></span></span>将会被划分为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         M 
        
       
      
        M 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span></span></span></span></span>个Head，每个Head将在<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         L 
        
       
      
        L 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal">L</span></span></span></span></span>层特征上分别生成<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         K 
        
       
      
        K 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">K</span></span></span></span></span>个点作为Value，因此每个Query的采样点总数为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          N 
         
        
          v 
         
        
       
         = 
        
       
         M 
        
       
         × 
        
       
         L 
        
       
         × 
        
       
         K 
        
       
      
        N_v=M \times L \times K 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1514em;"><span class="" style="top: -2.55em; margin-left: -0.109em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em;"></span><span class="mord mathnormal" style="margin-right: 0.109em;">M</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.7667em; vertical-align: -0.0833em;"></span><span class="mord mathnormal">L</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">K</span></span></span></span></span>，其Sample的Offset <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         Δ 
        
       
         p 
        
       
      
        \Delta p 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span></span></span></span></span>和对应的Attention Weights都是直接从Query通过两个线性映射层<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          W 
         
        
          p 
         
        
       
         ∈ 
        
        
        
          R 
         
         
          
          
            d 
           
          
            model  
           
          
         
           × 
          
          
          
            N 
           
          
            v 
           
          
         
        
       
         ∈ 
        
        
        
          R 
         
         
          
          
            d 
           
          
            model  
           
          
         
           × 
          
          
          
            d 
           
          
            model  
           
          
         
        
       
      
        W^p\in \mathbb{R}^{d_{\text {model }} \times N_v}\in \mathbb{R}^{d_{\text {model }} \times d_{\text {model }}} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7224em; vertical-align: -0.0391em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.6644em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8882em; vertical-align: -0.0391em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.109em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.1645em;"><span class="" style="top: -2.357em; margin-left: -0.109em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.143em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8491em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8491em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3448em;"><span class="" style="top: -2.3488em; margin-left: 0em; margin-right: 0.0714em;"><span class="pstrut" style="height: 2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">model </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1512em;"><span class=""></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>和<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          W 
         
        
          A 
         
        
       
      
        W^A 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8413em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span></span></span></span></span></span></span></span>生成的：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          Δ 
         
        
          p 
         
        
          = 
         
        
          Q 
         
         
         
           W 
          
         
           p 
          
         
        
       
         \Delta p=\mathbf{Q} W^p 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8778em; vertical-align: -0.1944em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.9088em; vertical-align: -0.1944em;"></span><span class="mord mathbf">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7144em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          V 
         
        
          = 
         
        
          Samp 
         
        
          ⁡ 
         
        
          ( 
         
        
          S 
         
        
          , 
         
        
          p 
         
        
          + 
         
        
          Δ 
         
        
          p 
         
        
          ) 
         
         
         
           W 
          
         
           V 
          
         
        
       
         \mathbf{V}=\operatorname{Samp}(S, p+\Delta p) W^V 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Samp</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1413em; vertical-align: -0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          DeformAttn 
         
        
          ⁡ 
         
        
          ( 
         
        
          Q 
         
        
          , 
         
        
          V 
         
        
          ) 
         
        
          = 
         
        
          Softmax 
         
        
          ⁡ 
         
         
         
           ( 
          
         
           Q 
          
          
          
            W 
           
          
            A 
           
          
         
           ) 
          
         
        
          V 
         
        
       
         \operatorname{DeformAttn}(\mathbf{Q}, \mathbf{V})=\operatorname{Softmax}\left(\mathbf{Q} W^A\right) \mathbf{V} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">DeformAttn</span></span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1.2413em; vertical-align: -0.35em;"></span><span class="mop"><span class="mord mathrm">Softmax</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size1">(</span></span><span class="mord mathbf">Q</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">A</span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size1">)</span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span></span></span></span></span></span>这个过程中，Query在不与Key进行交互的前提下就决定了每个采样点的重要性，这是因为在原始的Deformable DETR中，在Encoder中，因为<strong>所有的Multi-Scale Features都会作为Queries参与Self Attention，因此能快速地知道每个采样的重要性</strong>。但是在Lite DETR中，由于<strong>每次更新只有部分尺度的Feature参与</strong>，因此很难同时决定采样点以及每个采样点的重要性，因此本文还提出了一个Key-aware Deformable Attention，如下：<span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          V 
         
        
          = 
         
        
          S 
         
        
          a 
         
        
          m 
         
        
          p 
         
        
          ( 
         
        
          S 
         
        
          , 
         
        
          p 
         
        
          + 
         
        
          Δ 
         
        
          p 
         
        
          ) 
         
         
         
           W 
          
         
           V 
          
         
        
       
         \mathbf{V}=S a m p(S, p+\Delta p) W^V 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mord mathnormal">am</span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1413em; vertical-align: -0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.2222em;">V</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          K 
         
        
          = 
         
        
          Samp 
         
        
          ⁡ 
         
        
          ( 
         
        
          S 
         
        
          , 
         
        
          p 
         
        
          + 
         
        
          Δ 
         
        
          p 
         
        
          ) 
         
         
         
           W 
          
         
           K 
          
         
        
       
         \mathbf{K}=\operatorname{Samp}(S, p+\Delta p) W^K 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6861em;"></span><span class="mord mathbf">K</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mop"><span class="mord mathrm">Samp</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0576em;">S</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathnormal">p</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1413em; vertical-align: -0.25em;"></span><span class="mord">Δ</span><span class="mord mathnormal">p</span><span class="mclose">)</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8913em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0715em;">K</span></span></span></span></span></span></span></span></span></span></span></span></span><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          K 
         
        
          D 
         
        
          A 
         
        
          ( 
         
        
          Q 
         
        
          , 
         
        
          K 
         
        
          , 
         
        
          V 
         
        
          ) 
         
        
          = 
         
        
          Softmax 
         
        
          ⁡ 
         
         
         
           ( 
          
          
           
            
            
              Q 
             
            
              K 
             
            
           
             T 
            
           
           
            
            
              d 
             
            
              k 
             
            
           
          
         
           ) 
          
         
        
          V 
         
        
       
         K D A(\mathbf{Q}, \mathbf{K}, \mathbf{V})=\operatorname{Softmax}\left(\frac{\mathbf{Q K}^T}{\sqrt{d_k}}\right) \mathbf{V} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">KD</span><span class="mord mathnormal">A</span><span class="mopen">(</span><span class="mord mathbf">Q</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf">K</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span><span class="mclose">)</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 3em; vertical-align: -1.25em;"></span><span class="mop"><span class="mord mathrm">Softmax</span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top: 0em;"><span class="delimsizing size4">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.5943em;"><span class="" style="top: -2.2528em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8572em;"><span class="svg-align" style="top: -3em;"><span class="pstrut" style="height: 3em;"></span><span class="mord" style="padding-left: 0.833em;"><span class="mord"><span class="mord mathnormal">d</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0315em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span><span class="" style="top: -2.8172em;"><span class="pstrut" style="height: 3em;"></span><span class="hide-tail" style="min-width: 0.853em; height: 1.08em;"> 
                    <svg width="400em" height="1.08em" viewbox="0 0 400000 1080" preserveaspectratio="xMinYMin slice"> 
                     <path d="M95,702
c-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14
c0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54
c44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10
s173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429
c69,-144,104.5,-217.7,106.5,-221
l0 -0
c5.3,-9.3,12,-14,20,-14
H400000v40H845.2724
s-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7
c-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z
M834 80h400000v40h-400000z"></path> 
                    </svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.1828em;"><span class=""></span></span></span></span></span></span></span><span class="" style="top: -3.23em;"><span class="pstrut" style="height: 3em;"></span><span class="frac-line" style="border-bottom-width: 0.04em;"></span></span><span class="" style="top: -3.677em;"><span class="pstrut" style="height: 3em;"></span><span class="mord"><span class="mord"><span class="mord"><span class="mord mathbf">QK</span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.9173em;"><span class="" style="top: -3.139em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.1389em;">T</span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.93em;"><span class=""></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top: 0em;"><span class="delimsizing size4">)</span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord mathbf" style="margin-right: 0.016em;">V</span></span></span></span></span></span>这个其实就普通的Cross Attention保持一致，这样有Key参与能更好地帮助不同尺度特征进行更新。<br> <img src="https://images2.imgbox.com/c2/ba/i80QOgyQ_o.png" alt="在这里插入图片描述" width="500"></p> 
<p>以上就是Lite DETR的主要内容，在论文中作者还和Sparse DETR进行了对比，Sparse DETR的三个缺点如下：</p> 
<ol><li>难以在不同模型中进行泛化；</li><li>由于优先并且隐式监督，Scoring Network的输出不一定是最优的；</li><li>需要引入诸如Auxiliary Encoder Detection Loss类的其他的结构；</li></ol> 
<p>相比之下，Sparse DETR的改动确实要少些，Sparse DETR和其他SOTA方法对比如下：<img src="https://images2.imgbox.com/63/6c/0QudHdaD_o.png" alt="在这里插入图片描述" width="500"><br> 总而言之，<strong>Lite DETR是通过实现高层级特征和低层级特征的迭代更新来减少冗余的特征更新，为了保证更新的准确性而引入了Key-aware Deformable Attention，进而减小计算量</strong>。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/beedf8a3b877d4a4ca13729c3484b1a3/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">第三十二周：文献阅读&#43;RNN&#43;SVM</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b2213beb75a4e8d1f3b3a430b368f101/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于51单片机的音乐喷泉设计</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>