<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习——基础概念 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习——基础概念" />
<meta property="og:description" content="一. 机器学习基础概念 总结过层中，我结合了头歌上的相关公开课程：详见
（一）.什么是机器学习？ 机器学习致力于通过计算的手段，利用经验来改善系统的性能。
“经验”——&gt;通常“数据”形式存在——&gt;产生“模型”的算法被称为“学习算法”
（二）.基本术语 1.数据集： 记录的集合。其中每一条记录关于一个事件或者对象，称为一个“示例”，或者“样本”。
2.属性（或特征） 反映事件或对象在某方面的表现或者性质的事项，如色泽，根蒂，敲声；
3.属性值 属性上的取值成为“属性值”
4.属性空间 属性张成的空间称为“属性空间”，或样本空间，输入空间
5.特征向量 有属性作为坐标轴，由各属性组成一个点。由于空间中的每个点对应一个坐标向量，因此每一个示例也称为一个“特征向量”。
6.维数 若一个示例由d个属性描述，Xi为d维样本空间X中的一个向量，Xij是指样本Xi在第j个属性上的取值。d称为样本Xi的维数。
7.数据集 定义：数据的总和称为数据集。分类：
(1)训练集：用来学习或者叫训练的数据集。
(2)测试集： 8.样例 拥有标记信息（描述特征或属性的信息）的示例，一般用（xi，yi）表示第i个示例，其中yi∈Y是示例xi的标记，Y是所有标记的集合，称为标记空间或输出空间。
9.学习任务 监督学习
（1）定义：监督学习是从标记的训练数据来推断一个功能的机器学习任务。训练数据包括一套训练示例。在监督学习中，每个实例都是由一个输入对象(通常为矢量)和一个期望的输出值(也称为监督信号)组成。
（2）代表：分类和回归。监督学习是训练神经网络和决策树的常见技术。这两种技术高度依赖事先确定的分类系统给出的信息，对于神经网络，分类系统利用信息判断网络的错误，然后不断调整网络参数。对于决策树，分类系统用它来判断哪些属性提供了最多的信息。
（3）常见监督算法：线性回归算法、BP神经网络算法、决策树、支持向量机、KNN等。
（4）弱监督学习：为什么需要弱监督学习
①现实的数据往往缺乏标签；
②数据标注过程的高成本；
③很多任务很难获得如全部真实标签这样的强监督信息；半监督学习（自我训练）
详细信息，推荐——&gt;半监督学习
无监督学习
（1）定义：根据类别未知(没有被标记)的训练样本解决模式识别中的各种问题，称之为无监督学习。
（2）常见无监督算法：主成分分析方法PCA等，等距映射方法、局部线性嵌入方法、拉普拉斯特征映射方法、黑塞局部线性嵌入方法和局部切空间排列方法等。
（3）聚类：
①聚类算法一般有五种方法，最主要的是划分方法和层次方法两种。
②划分聚类算法通过优化评价函数把数据集分割为K个部分，它需要K作为输入参数。典型的分割聚类算法有K-means算法, K-medoids算法、CLARANS算法。
③层次聚类由不同层次的分割聚类组成，层次之间的分割具有嵌套的关系。它不需要输入参数，这是它优于分割聚类算法的一个明显的优点，其缺点是终止条件必须具体指定。典型的分层聚类算法有BIRCH算法、DBSCAN算法和CURE算法等。
④利用聚类结果，可以提取数据集中隐藏信息，对未来数据进行分类和预测。应用于数据挖掘，模式识别，图像处理等。
（4）无监督学习的方法分类：
① 一类为基于概率密度函数估计的直接方法：指设法找到各类别在特征空间的分布参数，再进行分类。
②另一类是称为基于样本间相似性度量的简洁聚类方法：其原理是设法定出不同类别的核心或初始内核，然后依据样本与核心之间的相似性度量将样本聚集成不同的类别。二者的区别
10.训练、验证、测试、评估 首先我们先通过一个形象的类比来了解一下什么是训练、验证、测试与评估。
训练–学生的课本；学生根据课本里的内容来掌握知识。
验证–作业，通过作业可以知道不同学生学习情况、进步的速度快慢。
测试–考试，考的题是平常都没有见过，考察学生举一反三的能力。
评估–分数，通过分数的高低了解学生对知识点的掌握情况。
训练：从数据中学得模型的过程称为“学习”(learning)或“训练”(training),这个过程通过执行某个学习算法来完成.
验证：对同一个学习算法,当使用不同的参数配置时，也会产生不同的模型.那么，选用哪一个学习算法、使用哪一种参数配置，这就是机器学习中的“模型选择”(modelselection)问题。对学习出来的模型，微调他们的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。
测试：使用一个“测试集”(testing set)来测试学习器对新样本的判别能力,然后以测试集上的“测试误差”(testing error)作为泛化误差的近似。**值得注意的是：**测试集应该尽可能与训练集互斥，即测试样本尽量不在训练集中出现、未在训练过程中使用过.
评估：
（1）把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”(error),学习器在训练集上的误差称为“训练误差”(training error)或“经验误差”(empirical error)，在新样本上的误差称为“泛化误差”(generalizationerror)。显然,我们希望得到泛化误差小的学习器。
（2）评估方法
留出法
①“留出法”(hold-out)直接将数据集D划分为两个互斥的集合,其中一个集合作为训练集S,另一个作为测试集T.在S上训练出模型后，用T来评估其测试误差,作为对泛化误差的估计.
②注意：
a.训练/测试集的划分尽可能保持数据分布的一致性。
b.一般采用若干次随即划分、重复进行实验评估后取平均值作为留出法的评估结果。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/69045b6a9462deb60c06d6bd892d4913/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-22T19:15:31+08:00" />
<meta property="article:modified_time" content="2022-05-22T19:15:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习——基础概念</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="__0"></a>一. 机器学习基础概念</h2> 
<p>总结过层中，我结合了头歌上的相关公开课程：<a href="https://www.educoder.net/paths/3326" rel="nofollow">详见</a></p> 
<h3><a id="_2"></a>（一）.什么是机器学习？</h3> 
<p>机器学习致力于通过计算的手段，利用经验来改善系统的性能。</p> 
<p>“经验”——&gt;通常“数据”形式存在——&gt;产生“模型”的算法被称为“学习算法”</p> 
<h3><a id="_8"></a>（二）.基本术语</h3> 
<h4><a id="1_10"></a>1.数据集：</h4> 
<p>记录的集合。其中每一条记录关于一个事件或者对象，称为一个“示例”，或者“样本”。</p> 
<h4><a id="2_15"></a>2.属性（或特征）</h4> 
<p>反映事件或对象在某方面的表现或者性质的事项，如色泽，根蒂，敲声；</p> 
<h4><a id="3_19"></a>3.属性值</h4> 
<p>属性上的取值成为“属性值”</p> 
<h4><a id="4_23"></a>4.属性空间</h4> 
<p>属性张成的空间称为“属性空间”，或样本空间，输入空间</p> 
<h4><a id="5_26"></a>5.特征向量</h4> 
<p>有属性作为坐标轴，由各属性组成一个点。由于空间中的每个点对应一个坐标向量，因此每一个示例也称为一个“特征向量”。</p> 
<h4><a id="6_28"></a>6.维数</h4> 
<p>若一个示例由d个属性描述，Xi为d维样本空间X中的一个向量，Xij是指样本Xi在第j个属性上的取值。d称为样本Xi的维数。</p> 
<h4><a id="7_30"></a>7.数据集</h4> 
<ul><li>定义：数据的总和称为数据集。</li><li>分类：<br> (1)训练集：用来学习或者叫训练的数据集。<br> (2)测试集：</li><li></ul> 
<h4><a id="8_36"></a>8.样例</h4> 
<p>拥有标记信息（描述特征或属性的信息）的示例，一般用（xi，yi）表示第i个示例，其中yi∈Y是示例xi的标记，Y是所有标记的集合，称为标记空间或输出空间。</p> 
<h4><a id="9_38"></a>9.学习任务</h4> 
<ul><li>监督学习<br> （1）定义：监督学习是从标记的训练数据来推断一个功能的机器学习任务。训练数据包括一套训练示例。<strong>在监督学习中，每个实例都是由一个输入对象(通常为矢量)和一个期望的输出值(也称为监督信号)组成。</strong><br> （2）代表：分类和回归。监督学习是训练神经网络和决策树的常见技术。这两种技术高度依赖事先确定的分类系统给出的信息，<strong>对于神经网络，分类系统利用信息判断网络的错误，然后不断调整网络参数。对于决策树，分类系统用它来判断哪些属性提供了最多的信息。</strong><br> （3）常见监督算法：线性回归算法、BP神经网络算法、决策树、支持向量机、KNN等。<br> （4）弱监督学习：</li><li>为什么需要弱监督学习<br> ①现实的数据往往缺乏标签；<br> ②数据标注过程的高成本；<br> ③很多任务很难获得如全部真实标签这样的强监督信息；</li><li>半监督学习（自我训练）<br> 详细信息，推荐——&gt;<a href="https://zhuanlan.zhihu.com/p/349107869" rel="nofollow">半监督学习</a><br> <img src="https://images2.imgbox.com/40/16/8puqFhg0_o.png" alt="在这里插入图片描述"></li><li>无监督学习<br> （1）定义：根据类别未知(没有被标记)的训练样本解决模式识别中的各种问题，称之为无监督学习。<br> （2）常见无监督算法：主成分分析方法PCA等，等距映射方法、局部线性嵌入方法、拉普拉斯特征映射方法、黑塞局部线性嵌入方法和局部切空间排列方法等。<br> （3）聚类：<br> ①聚类算法一般有五种方法，最主要的是划分方法和层次方法两种。<br> ②<strong>划分聚类算法</strong>通过<strong>优化评价函数</strong>把数据集分割为K个部分，它需要K作为输入参数。典型的分割聚类算法有K-means算法, K-medoids算法、CLARANS算法。<br> ③<strong>层次聚类</strong>由不同层次的分割聚类组成，层次之间的分割具有嵌套的关系。它不需要输入参数，这是它优于分割聚类算法的一个明显的优点，其缺点是终止条件必须具体指定。典型的分层聚类算法有BIRCH算法、DBSCAN算法和CURE算法等。<br> ④利用聚类结果，可以提取数据集中隐藏信息，对<strong>未来数据进行分类和预测</strong>。应用于数据挖掘，模式识别，图像处理等。<br> （4）无监督学习的方法分类：<br> ① 一类为基于概率密度函数估计的直接方法：指设法找到各类别在特征空间的分布参数，再进行分类。<br> ②另一类是称为基于样本间相似性度量的简洁聚类方法：其原理是设法定出不同类别的核心或初始内核，然后依据样本与核心之间的相似性度量将样本聚集成不同的类别。</li><li>二者的区别<br> <img src="https://images2.imgbox.com/ea/86/nFRj8yTy_o.png" alt="监督学习与无监督学习区别"></li></ul> 
<h3><a id="10_64"></a>10.训练、验证、测试、评估</h3> 
<p>首先我们先通过一个形象的类比来了解一下什么是训练、验证、测试与评估。<br> 训练–学生的课本；学生根据课本里的内容来掌握知识。<br> 验证–作业，通过作业可以知道不同学生学习情况、进步的速度快慢。<br> 测试–考试，考的题是平常都没有见过，考察学生举一反三的能力。<br> 评估–分数，通过分数的高低了解学生对知识点的掌握情况。</p> 
<ul><li> <p><strong>训练</strong>：从数据中学得模型的过程称为“学习”(learning)或“训练”(training),这个过程通过执行某个学习算法来完成.</p> </li><li> <p><strong>验证</strong>：对同一个学习算法,当使用不同的参数配置时，也会产生不同的模型.那么，选用哪一个学习算法、使用哪一种参数配置，这就是机器学习中的“模型选择”(modelselection)问题。对学习出来的模型，微调他们的参数，如在神经网络中选择隐藏单元数。验证集还用来确定网络结构或者控制模型复杂程度的参数。</p> </li><li> <p><strong>测试</strong>：使用一个“测试集”(testing set)来测试学习器对新样本的判别能力,然后以测试集上的“测试误差”(testing error)作为泛化误差的近似。**值得注意的是：**测试集应该尽可能与训练集互斥，即测试样本尽量不在训练集中出现、未在训练过程中使用过.</p> </li><li> <p><strong>评估</strong>：<br> （1）把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”(error),学习器在训练集上的误差称为“训练误差”(training error)或“经验误差”(empirical error)，在新样本上的误差称为“泛化误差”(generalizationerror)。显然,我们希望得到泛化误差小的学习器。<br> （2）评估方法</p> </li><li> <p><strong>留出法</strong><br> ①“留出法”(hold-out)<strong>直接</strong>将数据集D划分为两个互斥的集合,其中一个集合作为训练集S,另一个作为测试集T.在S上训练出模型后，用T来评估其测试误差,作为对泛化误差的估计.<br> ②注意：<br> a.训练/测试集的划分尽可能保持数据分布的一致性。<br> b.一般采用若干次随即划分、重复进行实验评估后取平均值作为留出法的评估结果。<br> c.训练/测试集样本比例通常为2:1或4:1</p> </li><li> <p><strong>交叉验证法</strong><br> “交叉验证法”(cross validation)先将数据集D划分为k个大小相似的<strong>互斥子集</strong>.每个子集D都尽可能保持数据分布的一致性,即从D中通过分层采样得到.然后，每次用k-1个子集的并集作为训练集,余下的那个子集作为测试集;这样就可获得k组训练/测试集,从而可进行k次训练和测试,最终返回的是这k个测试结果的均值.显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于k的取值,为强调这一点,通常把交叉验证法称为“k折交叉验证”(k-fold crossvalidation).k最常用的取值是10，此时称为10折交叉验证;其他常用的k值有5、20等.下图为10折交叉验证的示意图。<img src="https://images2.imgbox.com/b3/2e/GCjpj3NY_o.png" alt="在这里插入图片描述"><br> 假定数据集D中包含m个样本,若令k = m ,则得到了交叉验证法的一个特例:留一法(Leave-One-Out,简称LOO).显然，留一法不受随机样本划分方式的影响。</p> </li><li> <p><strong>自助法</strong><br> 给定包含m个样本的数据集D，我们对它进行采样产生数据集D’:每次随机从D中挑选一个样本,将其拷贝放入D’,然后再将该样本放回初始数据集D中,使得该样本在下次采样时仍有可能被采到;这个过程重复执行m次后,我们就得到了包含m个样本的数据集D’，这就是自助采样的结果.<br> <strong>自助法在数据集较小难以有效划分训练集和测试集时很有用。</strong><br> （3）评估标准<br> ①准确率（Accuracy）的定义是：对于给定的测试集，分类模型正确分类的样本数与总样本数之比；</p> </li></ul> 
<p>②精确率（Precision）的定义是：对于给定测试集的某一个类别，分类模型预测正确的比例，或者说：分类模型预测的正样本中有多少是真正的正样本；</p> 
<p>③召回率（Recall）的定义为：对于给定测试集的某一个类别，样本中的正类有多少被分类模型预测正确召回率的定义为：对于给定测试集的某一个类别，样本中的正类有多少被分类模型预测正确；</p> 
<p>④F1_score，在理想情况下，我们希望模型的精确率越高越好，同时召回率也越高越高，但是，现实情况往往事与愿违，在现实情况下，精确率和召回率像是坐在跷跷板上一样，往往出现一个值升高，另一个值降低，那么，有没有一个指标来综合考虑精确率和召回率了，这个指标就是F1值。F1值的计算公式为：<br> <img src="https://images2.imgbox.com/e4/d2/x8ORV8wQ_o.png" alt="在这里插入图片描述"><br> （4）性能度量<br> ①定义:衡量泛化能力的评价标准称为性能度量。性能度量反映了任务需求，对比不同模型的能力时，使用不同的性能度量会导致不用的评判结果。在进行模型选择时，需要根据算法、数据以及任务需求综合选择合适的性能度量。<br> 而回归任务中，最常用的性能度量时“均方误差”（MSE)：<img src="https://images2.imgbox.com/82/6b/RyoqjhiR_o.png" alt="在这里插入图片描述"></p> 
<p>②分类<br> a.错误率与精度</p> 
<p>错误率：分类错误的样本数占总数的比例。</p> 
<p>精度：分类正确的样本数占总数的比例。</p> 
<p>对样例集 D ， 分类错误率定义为：<br> <img src="https://images2.imgbox.com/f6/3c/aAHEvG0t_o.png" alt="在这里插入图片描述"><br> 精度则定义为：<img src="https://images2.imgbox.com/5e/0e/mifkj8vQ_o.png" alt="在这里插入图片描述"><br> 对于数据分布 Ð 和概率密度函数 p(.) ， 错误率与精度可分别描述为：<br> <img src="https://images2.imgbox.com/0a/df/sy0ys0u0_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/96/36/GNGO7Jyr_o.png" alt="在这里插入图片描述"><br> b.查准率§、查全率®与F1</p> 
<p>在信息检索等应用中，我们通常会关系“检索出来的信息中有多少比例是用户感兴趣的”。此时查准率（precision）与查全率（recall）更适用于此类需求的性能度量。</p> 
<table><thead><tr><th>真实情况</th><th>预测结果</th><th>预测结果</th></tr></thead><tbody><tr><td></td><td>正例</td><td>反例</td></tr><tr><td>正例</td><td>TP</td><td>FN</td></tr><tr><td>反例</td><td>FP</td><td>TN</td></tr></tbody></table> 
<p>P=TP/(TP+FP)<br> R=TP/(TP+FN)<br> P与R成反比，在平衡点（BEP)时：P=R<br> <img src="https://images2.imgbox.com/28/de/pCGIwOBb_o.png" alt="在这里插入图片描述"><br> F1度量：<br> F1=2XPXR/(P+R)=2TP/(样例总数+TP-TN)<br> 商品推荐是，查准率更重要，而在逃犯信息检索式，查全率更重要。</p> 
<p>c.ROC与AUC<br> ROC 全称是"受试者工作特征" (Receiver Operating Characteristic) 曲线。ROC 曲线的纵轴是"真正例率" (True Positive Rate，简称 TPR)，横轴是"假正例率" (False PositiveRate， FPR),其中<img src="https://images2.imgbox.com/ca/ec/wCl1sGCF_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/00/dc/Hnx21KF0_o.png" alt="在这里插入图片描述"><br> AUC（Area Under Curve） 可通过ROC曲线下各部分的面积求和而得。因为ROC曲线一般都处于y=x这条直线的上方，所以取值范围在0.5和1之间，使用AUC作为评价指标是因为ROC曲线在很多时候并不能清晰地说明哪个分类器的效果更好，而AUC作为一个数值，其值越大代表分类器效果更好。</p> 
<p>值得注意的是：类似于PR图</p> 
<ul><li>若一个学习器的 ROC 曲线被另 一个学习器的曲线完全"包住"， 则可断言后者的性能优于前者；</li><li>若两个学习器的 ROC 曲线发生交叉，则难以-般性地断言两者孰优孰劣 . 此时比较 AUC 。</li></ul> 
<p>d.代价敏感错误率与代价曲线<br> 以二分类任务为例，可根据任务的领域知识设定一个"代价矩阵" (cost matrix) 。costij表示将第 i 类样本预测为第 j 类样本的代价。一般来说 ，costii=0; 若将第 0 类判别为第 1 类所造成的损失更大，则cost01&gt;cost 10；损失程度相差越大cost01与cost10值的差别越大。<br> <img src="https://images2.imgbox.com/c1/45/dfIus91Y_o.png" alt="在这里插入图片描述"><br> 代价敏感 (cost-sensitive)错误率为：<img src="https://images2.imgbox.com/20/90/hlQXwxRA_o.png" alt="在这里插入图片描述"><br> <strong>代价曲线： 在非均等代价下， 代价曲线能直接反映出学习器的期望总体代价。</strong><br> 代价曲线横轴是取值为 [0 ，1]的正例概率代价：<img src="https://images2.imgbox.com/b0/29/qTAh8ah0_o.png" alt="在这里插入图片描述"><br> 其中 p 是样例为正例的概率。纵轴是取值为 [0 ， 1] 的归一化代价：<img src="https://images2.imgbox.com/37/c2/vbWVP0ht_o.png" alt="在这里插入图片描述"><br> 代价曲线的绘制： ROC 曲线上每一点对应了代价平面上的一条线段，设ROC 曲线上点的坐标为 (TPR， FPR) ，则可相应计算出 FNR，然后在代价平面上绘制一条从 (0，FPR) 到 (1，FNR) 的线段，线段下的面积即表示了该条件下的期望总体代价;如此将 ROC 曲线土的每个点转化为代价平面上的一条线段，取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价。<img src="https://images2.imgbox.com/41/a3/RjqVGpDl_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/aabdba990b4728d2e22c8f08d20575a6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">sort目标跟踪算法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d1e471c230660f6bc72d550037b34fa9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">redis优化篇</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>