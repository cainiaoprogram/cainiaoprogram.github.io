<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CPN:Cascaded Pyramid Network for Multi-Person Pose Estimation_及CPN实现 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CPN:Cascaded Pyramid Network for Multi-Person Pose Estimation_及CPN实现" />
<meta property="og:description" content="文章目录 Cascaded Pyramid Network for Multi-Person Pose Estimation优点CPN两阶段网络：GlobalNet 和 RefineNet多人关键点估计1.人体边界框检测2. CPN 实验技巧实验结果 Cascaded Pyramid Network for Multi-Person Pose Estimation 论文链接
tf实现源码
pytorch实现源码
论文解决的任务场景为多人姿态估计.多人姿态估计所面临的挑战，关键点遮挡，关键点不可见，复杂背景等.提出的 Cascaded Pyramid Network (CPN) 方法，即着重于处理 “困难hard” 关键点.
优点 提出了一种金字塔型的串接模型，即CPN（cascaded pyramid network），这个模型能够同时兼顾人体关节点的局部信息以及全局信息，结果取得了不错的效果;
使用了在线难例挖掘（online hard keypoints mining）的技术，这对于人体姿态估计任务中一些存在遮挡的“hard”的关键点的预测有所帮助；
测试阶段考量了soft-NMS和传统的hard-NMS（非极大值抑制）在human detection阶段产生的影响，结论是soft-NMS对于最后的结果是有所帮助的。
CPN两阶段网络：GlobalNet 和 RefineNet CPN 包括两阶段网络：GlobalNet 和 RefineNet
[1] - GlobalNet - 特征金字塔网络(feature pyramid network)，用于定位估计 “简单simple” 关键点，比如，eyes 和 hands；但难以精确识别遮挡或不可见的关键点.
[2] - RefineNet - 通过将 GlobalNet 得到的所有层次的特征表示整合一起，并结合在线困难关键点挖掘loss(online hard keypoint mining loss)，定位检测 “困难hard” 关键点." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/c67ef3f06cdb00ee7321f9c549aa9a6f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-06-21T10:54:07+08:00" />
<meta property="article:modified_time" content="2019-06-21T10:54:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CPN:Cascaded Pyramid Network for Multi-Person Pose Estimation_及CPN实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Cascaded_Pyramid_Network_for_MultiPerson_Pose_Estimation_1" rel="nofollow">Cascaded Pyramid Network for Multi-Person Pose Estimation</a></li><li><ul><li><a href="#_9" rel="nofollow">优点</a></li><li><a href="#CPNGlobalNet__RefineNet_17" rel="nofollow">CPN两阶段网络：GlobalNet 和 RefineNet</a></li><li><a href="#_28" rel="nofollow">多人关键点估计</a></li><li><ul><li><a href="#1_35" rel="nofollow">1.人体边界框检测</a></li><li><a href="#2_CPN_42" rel="nofollow">2. CPN</a></li></ul> 
   </li><li><a href="#_75" rel="nofollow">实验</a></li><li><ul><li><a href="#_77" rel="nofollow">技巧</a></li><li><a href="#_93" rel="nofollow">实验结果</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="Cascaded_Pyramid_Network_for_MultiPerson_Pose_Estimation_1"></a>Cascaded Pyramid Network for Multi-Person Pose Estimation</h2> 
<p><a href="https://arxiv.org/abs/1711.07319" rel="nofollow">论文链接</a><br> <a href="https://github.com/chenyilun95/tf-cpn">tf实现源码</a><br> <a href="https://github.com/GengDavid/pytorch-cpn">pytorch实现源码</a></p> 
<p>论文解决的任务场景为多人姿态估计.多人姿态估计所面临的挑战，关键点遮挡，关键点不可见，复杂背景等.提出的 Cascaded Pyramid Network (CPN) 方法，即着重于处理 “困难hard” 关键点.</p> 
<h3><a id="_9"></a>优点</h3> 
<ol><li> <p>提出了一种金字塔型的串接模型，即CPN（cascaded pyramid network），这个模型能够同时兼顾人体关节点的局部信息以及全局信息，结果取得了不错的效果;</p> </li><li> <p>使用了在线难例挖掘（online hard keypoints mining）的技术，这对于人体姿态估计任务中一些存在遮挡的“hard”的关键点的预测有所帮助；</p> </li><li> <p>测试阶段考量了soft-NMS和传统的hard-NMS（非极大值抑制）在human detection阶段产生的影响，结论是soft-NMS对于最后的结果是有所帮助的。</p> </li></ol> 
<h3><a id="CPNGlobalNet__RefineNet_17"></a>CPN两阶段网络：GlobalNet 和 RefineNet</h3> 
<p>CPN 包括两阶段网络：GlobalNet 和 RefineNet<br> [1] - GlobalNet - 特征金字塔网络(feature pyramid network)，用于定位估计 “简单simple” 关键点，比如，eyes 和 hands；但难以精确识别遮挡或不可见的关键点.</p> 
<p>[2] - RefineNet - 通过将 GlobalNet 得到的所有层次的特征表示整合一起，并结合在线困难关键点挖掘loss(online hard keypoint mining loss)，定位检测 “困难hard” 关键点.</p> 
<p>一般情况下，多人姿态估计问题的解决方案是 top-down 的，即，首先采用检测器检测人体边界框；然后采用关键点估计方法估计每个人体边界框内的人体关键点. CPN 算法即是对每个人体边界框内进行关键点估计.</p> 
<p>此外，CPN 还探索了其它可能影响多人关键点估计的其它因素，比如人体检测器，数据预处理等.</p> 
<h3><a id="_28"></a>多人关键点估计</h3> 
<p>主要包括两部分，</p> 
<p>[1] - 人体边界框检测 Human Detector</p> 
<p>[2] - 关键点估计 CPN</p> 
<h4><a id="1_35"></a>1.人体边界框检测</h4> 
<p>直接采用基于 FPN 目标检测算法. 其中，采用 Mask R-CNN 中的 ROIAlign 替换 FPN 的 ROIPooling.</p> 
<p>目标检测器训练时，使用了 COCO 数据集的全部 18 个类别；但只有人体类别的边界框被用于多人关键点估计任务.</p> 
<p><img src="https://images2.imgbox.com/84/b6/Pypsp4jP_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="2_CPN_42"></a>2. CPN</h4> 
<p>单人姿态估计算法：</p> 
<p>[stacked hourglass] - 堆叠 8 个 hourglass，每个 hourglass 由下采样，上采样，以及残差连接组成；但，实际上堆叠 2 个 hourglass 模块，则足以达到与 8 个 hourglass 模块相当的效果.</p> 
<p>CPN(cascaded pyramid network) 网络如下图：<br> <img src="https://images2.imgbox.com/eb/8a/PjoFaICn_o.png" alt="在这里插入图片描述"><br> CPN主要包括两个子网络：</p> 
<p>[1] - GlobalNet</p> 
<p>基于 ResNet backbone.</p> 
<p>我们记不同的 conv 特征的最后一个残差模块分别为 C2,C3,C4,C5. 在 C2 - C5 后接 3x3 conv 核，以生成关键点的 heatmaps.</p> 
<p>如下图 中，C2 和 C3 的 feature maps 分辨率较大，但语义信息较少. 而 C4 和 C5 的 feature maps 语义信息较多，但分辨率较低(由于卷积步长和 pooling 的作用).</p> 
<p>因此，一般采用 U-型 结构同时保持特征层的空间分辨率和语义信息. 而 FPN 进一步提升.</p> 
<p>GlobalNet 采用类似于 FPN 的特征金字塔结构，进行关键点估计. 与 FPN 的不同之处在于，GlobalNet 上采用时，在每个 elem-sum 前添加了 1x1 conv 核.</p> 
<p>由下图可知，基于 ResNet backbone 的 GlobalNet 可以有效的定位简单的关键点，如 eyes，但没有精确定位置 hips 关键点的位置. 因此，需要更多的上下文信息.<br> <img src="https://images2.imgbox.com/bb/82/NptSedfO_o.png" alt="在这里插入图片描述"></p> 
<p>[2] - RefineNet</p> 
<p>基于 GlobalNet 生成的特征金字塔表示，再添加 RefineNet，定位 “hard” 关键点.</p> 
<p>RefineNet 利用了不同层的特征信息，并通过类似于 HyperNet 的上采样和链接，整合不同层的特征信息.</p> 
<p>stacked Hourglass 网络仅利用了 hourglass 模块尾部输出的上采样特征，而 RefineNet 链接了所有层的金字塔特征.</p> 
<h3><a id="_75"></a>实验</h3> 
<h4><a id="_77"></a>技巧</h4> 
<p>(1)数据增强，提升0.4map</p> 
<p>训练数据的处理上使用了随机翻转，（-45度，45度）的随机旋转，（0,7,1.35）的随机尺度变换</p> 
<p>(2)大batch的训练，主要针对检测框架，提升0.4-0.7map</p> 
<p>(3)在行人检测框架中使用soft NMS取代hard NMS，提升0.3map</p> 
<p>(4)随着检测map的提高，关键点的map提升非常有限</p> 
<p>(5)online hard keypoints mining<br> 在coco 数据集中有17个关键点需要预测，GolbalNet预测所有的17个点，并计算所有17个点的loss，RefineNet也预测所有的17个点，但是只有最难的8个点的loss 贡献给总loss。作者称这为OHEM。</p> 
<p>(6)多模型融合集成，提升1.1-1.5map在coco minval数据集上</p> 
<h4><a id="_93"></a>实验结果</h4> 
<p><img src="https://images2.imgbox.com/0c/1a/bGfY9fYA_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/9a/88/Q7CHdVuy_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/1c/8d/kmFgrEfH_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/b3/b0/BN7PbKSe_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/c3/09/qDyTYywg_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/21/24/icbSQFpc_o.png" alt="在这里插入图片描述"></p> 
<p>参考文章：<a href="https://www.aiuai.cn/aifarm446.html" rel="nofollow">论文阅读 - Cascaded Pyramid Network for Multi-Person Pose Estimation</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0f102a6dc38506822c0798ecc9f29521/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">软件构造Lab2实验要求总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/71df3a68f978d9d28112faf11aecb65f/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">二分网络上的电影推荐</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>