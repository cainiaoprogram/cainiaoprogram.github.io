<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>激活函数整理 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="激活函数整理" />
<meta property="og:description" content="sigmoid函数 import torch from d2l import torch as d2l %matplotlib inline ​ x=torch.arange(-10,10,0.1,requires_grad=True) sigmoid=torch.nn.Sigmoid() y=sigmoid(x) ​ d2l.plot(x.detach(),y.detach(),&#39;x&#39;,&#39;sigmoid(x)&#39;,figsize=(5,2.5)) sigmoid函数连续、光滑、单调递增，以 (0,0.5) 中心对称，是一个良好的阈值函数。在x超出[-6,6]的范围后，函数值基本上没有变化，值非常接近，在应用中一般不考虑。
sigmoid函数的值域范围限制在(0,1)之间，恰巧与概率值的范围相对应，这样Sigmoid函数就能与一个概率分布联系起来了。
存在等式：
当输入值为0时，sigmoid函数的导数达到最大值0.25；而输入在任一方向上越远离0点时，导数越接近0。
#清除以前的梯度 #retain_graph如果设置为False，计算图中的中间变量在计算完后就会被释放。 y.backward(torch.ones_like(x),retain_graph=True) d2l.plot(x.detach(),x.grad,&#39;x&#39;,&#39;grad of sigmoid&#39;) sigmoid函数可用作逻辑回归模型的分类器。除此之外还存在其自身的推到特性。
对于分类问题，尤其是二分类问题，都假定服从伯努利分布，
根据指数分布族的一半表现形式
伯努利分布可变形为：
故，伯努利分布也属于指数分布族，
令，可得
此为sigmoid函数形式。
tanh函数 与sigmoid类似，tanh函数也会将输入压缩至（-1,1）。
import torch from d2l import torch as d2l %matplotlib inline ​ x=torch.arange(-8.0,8.0,0.1,requires_grad=True) tanh=torch.nn.Tanh() y=tanh(x) ​ d2l.plot(x.detach(),y.detach(),&#39;x&#39;,&#39;tanh(x)&#39;,figsize=(5,2.5)) 存在等式：
tanh函数的导数如下，当输入接近0时，tanh函数的导数接近最大值1，输入在任一方向上远离0点，导数越接近0。
y.backward(torch.ones_like(x),retain_graph=True) d2l.plot(x.detach(),x.grad,&#39;x&#39;,&#39;grad of tanh&#39;,figsize=(5,2.5)) ReLU函数 ReLU函数的求导表现很好：要么让参数消失，要么让参数通过。
ReLU减轻了神经网络的梯度消失问题。ReLU函数有很多变体，如LeakyReLU，pReLU等。
#原函数 import torch from d2l import torch as d2l %matplotlib inline ​ x=torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ee4ec9e3f3b66ddf02276d1d603fa20f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T11:07:52+08:00" />
<meta property="article:modified_time" content="2024-01-10T11:07:52+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">激活函数整理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><strong>sigmoid函数</strong></h2> 
<p style="text-align:center;"><img alt="f(x)=\frac{1}{1+e^{-x}}" class="mathcode" src="https://images2.imgbox.com/7e/e6/20DcDwgr_o.png"></p> 
<p style="text-align:center;"><img alt="" height="504" src="https://images2.imgbox.com/4b/ae/zU8MGlNv_o.png" width="676"></p> 
<pre><code class="language-python">import torch
from d2l import torch as d2l
%matplotlib inline
​
x=torch.arange(-10,10,0.1,requires_grad=True)
sigmoid=torch.nn.Sigmoid()
y=sigmoid(x)
​
d2l.plot(x.detach(),y.detach(),'x','sigmoid(x)',figsize=(5,2.5))</code></pre> 
<p>sigmoid函数连续、光滑、单调递增，以 (0,0.5) 中心对称，是一个良好的阈值函数。在x超出[-6,6]的范围后，函数值基本上没有变化，值非常接近，在应用中一般不考虑。</p> 
<p>sigmoid函数的值域范围限制在(0,1)之间，恰巧与概率值的范围相对应，这样Sigmoid函数就能与一个概率分布联系起来了。</p> 
<p>存在等式：</p> 
<p style="text-align:center;"><img alt="f'(x)=f(x)(1-f(x))" class="mathcode" src="https://images2.imgbox.com/97/04/cm3Tp81Q_o.png"></p> 
<p>当输入值为0时，sigmoid函数的导数达到最大值0.25；而输入在任一方向上越远离0点时，导数越接近0。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/75/8a/zVhd9ysH_o.png"></p> 
<pre><code class="language-python">#清除以前的梯度
#retain_graph如果设置为False，计算图中的中间变量在计算完后就会被释放。
y.backward(torch.ones_like(x),retain_graph=True)
d2l.plot(x.detach(),x.grad,'x','grad of sigmoid')</code></pre> 
<p>sigmoid函数可用作逻辑回归模型的分类器。除此之外还存在其自身的推到特性。</p> 
<p>对于分类问题，尤其是二分类问题，都假定服从伯努利分布，</p> 
<p style="text-align:center;"><img alt="f(x|p)=p^x(1-p)^{1-x}" class="mathcode" src="https://images2.imgbox.com/a1/b5/zie2NgFU_o.png"></p> 
<p>根据指数分布族的一半表现形式</p> 
<p style="text-align:center;"><img alt="f(x\theta )=h(x)e^{\eta(\theta) T(x)-A(\theta )}" class="mathcode" src="https://images2.imgbox.com/60/85/ZOAfVG4f_o.png"></p> 
<p>伯努利分布可变形为：</p> 
<p style="text-align:center;"><img alt="f(x|p)=e^{ln(\frac{p}{1-p})x+ln(1-p)}" class="mathcode" src="https://images2.imgbox.com/6b/b1/RbDmabsA_o.png"></p> 
<p>故，伯努利分布也属于指数分布族，<br> 令<img alt="\eta(p) =ln\frac{p}{1-p}" class="mathcode" src="https://images2.imgbox.com/93/13/7ITnB3KV_o.png">，可得<img alt="p=\frac{1}{1+e^{-\eta (p)}}" class="mathcode" src="https://images2.imgbox.com/c9/1c/mn2f9FWx_o.png"></p> 
<p>此为sigmoid函数形式。</p> 
<h2><strong>tanh函数</strong></h2> 
<p>与sigmoid类似，tanh函数也会将输入压缩至（-1,1）。</p> 
<p style="text-align:center;"><img alt="tanh=\frac{1-e^{-2x}}{1+e^{-2x}}" class="mathcode" src="https://images2.imgbox.com/04/13/xKATmGav_o.png"></p> 
<p style="text-align:center;"><br><img alt="" src="https://images2.imgbox.com/8f/33/w7gVr9jm_o.png"></p> 
<pre><code class="language-python">import torch
from d2l import torch as d2l
%matplotlib inline
​
x=torch.arange(-8.0,8.0,0.1,requires_grad=True)
tanh=torch.nn.Tanh()
y=tanh(x)
​
d2l.plot(x.detach(),y.detach(),'x','tanh(x)',figsize=(5,2.5))</code></pre> 
<p>存在等式：</p> 
<p style="text-align:center;"><img alt="f'(x)=1-f^2(x)" class="mathcode" src="https://images2.imgbox.com/b0/50/TnuMKsEZ_o.png"></p> 
<p>tanh函数的导数如下，当输入接近0时，tanh函数的导数接近最大值1，输入在任一方向上远离0点，导数越接近0。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/6c/49/XvcaNsQ8_o.png"></p> 
<pre><code class="language-python">y.backward(torch.ones_like(x),retain_graph=True)
d2l.plot(x.detach(),x.grad,'x','grad of tanh',figsize=(5,2.5))</code></pre> 
<h2><strong>ReLU函数</strong></h2> 
<p style="text-align:center;"><img alt="ReLU(x)=max(x,0)" class="mathcode" src="https://images2.imgbox.com/77/08/nHNKva6D_o.png"><br><img alt="" src="https://images2.imgbox.com/9e/16/tK3nxlwj_o.png"></p> 
<p> </p> 
<p>ReLU函数的求导表现很好：要么让参数消失，要么让参数通过。</p> 
<p>ReLU减轻了神经网络的梯度消失问题。ReLU函数有很多变体，如LeakyReLU，pReLU等。</p> 
<pre><code class="language-python">#原函数
import torch
from d2l import torch as d2l
%matplotlib inline
​
x=torch.arange(-8.0,8.0,0.1,requires_grad=True)
relu=torch.nn.ReLU()
y=relu(x)
​
d2l.plot(x.detach(),y.detach(),'x','relu',figsize=(5,2.5))
​
#导数
#retain_graph如果设置为False，计算图中的中间变量在计算完后就会被释放。
y.backward(torch.ones_like(x),retain_graph=True)
d2l.plot(x.detach(),x.grad,'x','grad of relu',figsize=(5,2.5))</code></pre> 
<p>变种：<strong>Leaky Relu</strong>函数</p> 
<p>负区间值非0，为一个斜率相较小的线性函数</p> 
<h2><strong>softmax函数</strong></h2> 
<p>在二分类任务时，经常使用sigmoid激活函数。而在处理多分类问题的时候，需要使用softmax函数。它的输出有两条规则。</p> 
<ul><li> <p>每一项的区间范围的(0,1)</p> </li><li> <p>所有项相加的和为1</p> </li></ul> 
<p>假设有一个数组 V，Vi代表 V 中的第i个元素，那么这个元素的softmax值的计算公式为：</p> 
<p style="text-align:center;"><img alt="S_i=\frac{e^i}{\sum^i_{j=1}e^j}" class="mathcode" src="https://images2.imgbox.com/99/5b/kHlp6rRY_o.png"></p> 
<pre><code class="language-python">x=torch.Tensor([3.,1.,-3.]) softmax=torch.nn.Softmax(dim=0) y=softmax(x) print(y)</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7e418aee4be52874d9d08aef5e2d5883/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GE IC695CPU315集成IO步进电机控制器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e8affb03cb7a5a7ddab0585c19d9e8b2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Gitlab-ci:从零开始的前端自动化部署</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>