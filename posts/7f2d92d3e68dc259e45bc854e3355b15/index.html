<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>tensorflow2.X和pytorch实现polyloss - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="tensorflow2.X和pytorch实现polyloss" />
<meta property="og:description" content="polyloss介绍 polyloss是Cross-entropy loss和Focal loss的优化版本，PolyLoss在二维图像分类、实例分割、目标检测和三维目标检测任务上都明显优于Cross-entropy loss和Focal loss。
作者认为可以将常用的分类损失函数，如Cross-entropy loss和Focal loss，分解为一系列加权多项式基。
它们可以被分解为 ∑ j = 1 n α j ( 1 − P t ) j \sum_{j=1}^n\alpha_j(1-P_t)^j ∑j=1n​αj​(1−Pt​)j的形式，其中 α j ∈ R &#43; \alpha_j∈R^&#43; αj​∈R&#43;为多项式系数， P t P_t Pt​为目标类标签的预测概率。每个多项式基 ( 1 − P t ) j (1-P_t)^j (1−Pt​)j由相应的多项式系数 α j ∈ R &#43; \alpha_j∈R^&#43; αj​∈R&#43;进行加权，这使PolyLoss能够很容易地调整不同的多项式基。
当 α j = 1 / j \alpha_j=1/j αj​=1/j时，PolyLoss等价于常用的Cross-entropy loss，但这个系数分配可能不是最优的。 tensorflow2.X实现 注意：在图像分类训练时该polyloss已经对网络预测结果进行softmax缩放，在网络的最后一层可以不加softmax激活函数。但是预测图片时记得添加！
import tensorflow as tf def poly1_cross_entropy(epsilon=1." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7f2d92d3e68dc259e45bc854e3355b15/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-22T17:08:29+08:00" />
<meta property="article:modified_time" content="2022-12-22T17:08:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">tensorflow2.X和pytorch实现polyloss</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="polyloss_0"></a>polyloss介绍</h2> 
<p>polyloss是Cross-entropy loss和Focal loss的优化版本，PolyLoss在二维图像分类、实例分割、目标检测和三维目标检测任务上都明显优于Cross-entropy loss和Focal loss。</p> 
<p>作者认为可以将常用的分类损失函数，如Cross-entropy loss和Focal loss，分解为一系列加权多项式基。</p> 
<p>它们可以被分解为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ∑ 
         
         
         
           j 
          
         
           = 
          
         
           1 
          
         
        
          n 
         
        
        
        
          α 
         
        
          j 
         
        
       
         ( 
        
       
         1 
        
       
         − 
        
        
        
          P 
         
        
          t 
         
        
        
        
          ) 
         
        
          j 
         
        
       
      
        \sum_{j=1}^n\alpha_j(1-P_t)^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.2401em; vertical-align: -0.4358em;"></span><span class="mop"><span class="mop op-symbol small-op" style="position: relative; top: 0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8043em;"><span class="" style="top: -2.4003em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.2029em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.4358em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0747em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span></span></span></span></span>的形式，其中<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          α 
         
        
          j 
         
        
       
         ∈ 
        
        
        
          R 
         
        
          + 
         
        
       
      
        \alpha_j∈R^+ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8252em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span>为多项式系数，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          P 
         
        
          t 
         
        
       
      
        P_t 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>为目标类标签的预测概率。每个多项式基<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         1 
        
       
         − 
        
        
        
          P 
         
        
          t 
         
        
        
        
          ) 
         
        
          j 
         
        
       
      
        (1-P_t)^j 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.0747em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8247em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span></span></span></span></span></span></span></span></span>由相应的多项式系数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          α 
         
        
          j 
         
        
       
         ∈ 
        
        
        
          R 
         
        
          + 
         
        
       
      
        \alpha_j∈R^+ 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8252em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.7713em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0077em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.7713em;"><span class="" style="top: -3.063em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span></span></span></span></span>进行加权，这使PolyLoss能够很容易地调整不同的多项式基。</p> 
<ul><li>当<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           α 
          
         
           j 
          
         
        
          = 
         
        
          1 
         
        
          / 
         
        
          j 
         
        
       
         \alpha_j=1/j 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7167em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.0572em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">1/</span><span class="mord mathnormal" style="margin-right: 0.0572em;">j</span></span></span></span></span>时，PolyLoss等价于常用的Cross-entropy loss，但这个系数分配可能不是最优的。</li></ul> 
<h2><a id="tensorflow2X_8"></a>tensorflow2.X实现</h2> 
<p>注意：在图像分类训练时该polyloss已经对网络预测结果进行softmax缩放，在网络的最后一层可以不加softmax激活函数。但是预测图片时记得添加！</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf


<span class="token keyword">def</span> <span class="token function">poly1_cross_entropy</span><span class="token punctuation">(</span>epsilon<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">_poly1_cross_entropy</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># pt, CE, and Poly1 have shape [batch].</span>
        pt <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_sum<span class="token punctuation">(</span>y_true <span class="token operator">*</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        CE <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>softmax_cross_entropy_with_logits<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
        Poly1 <span class="token operator">=</span> CE <span class="token operator">+</span> epsilon <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>Poly1<span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss
    <span class="token keyword">return</span> _poly1_cross_entropy


<span class="token keyword">def</span> <span class="token function">poly1_focal_loss</span><span class="token punctuation">(</span>gamma<span class="token operator">=</span><span class="token number">2.0</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.25</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">_poly1_focal_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
        p <span class="token operator">=</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
        ce_loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sigmoid_cross_entropy_with_logits<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>
        pt <span class="token operator">=</span> y_true <span class="token operator">*</span> p <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_true<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> p<span class="token punctuation">)</span>
        FL <span class="token operator">=</span> ce_loss <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">)</span> <span class="token operator">**</span> gamma<span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> alpha <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            alpha_t <span class="token operator">=</span> alpha <span class="token operator">*</span> y_true <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> alpha<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> y_true<span class="token punctuation">)</span>
            FL <span class="token operator">=</span> alpha_t <span class="token operator">*</span> FL
        Poly1 <span class="token operator">=</span> FL <span class="token operator">+</span> epsilon <span class="token operator">*</span> tf<span class="token punctuation">.</span>math<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">,</span> gamma <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>Poly1<span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss
    <span class="token keyword">return</span> _poly1_focal_loss


</code></pre> 
<h2><a id="pytorch_43"></a>pytorch实现</h2> 
<p>注意：在图像分类训练时该polyloss已经对网络预测结果进行softmax缩放，在网络的最后一层可以不加softmax激活函数。但是预测图片时记得添加！</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">from</span> torch <span class="token keyword">import</span> Tensor


<span class="token keyword">class</span> <span class="token class-name">Poly1CrossEntropyLoss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 num_classes<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 epsilon<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
                 reduction<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"mean"</span><span class="token punctuation">,</span>
                 weight<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Create instance of Poly1CrossEntropyLoss
        :param num_classes:
        :param epsilon:
        :param reduction: one of none|sum|mean, apply reduction to final loss tensor
        :param weight: manual rescaling weight for each class, passed to Cross-Entropy loss
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Poly1CrossEntropyLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> reduction
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> weight
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Forward pass
        :param logits: tensor of shape [N, num_classes]
        :param labels: tensor of shape [N]
        :return: poly cross-entropy loss
        """</span>
        labels_onehot <span class="token operator">=</span> F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> num_classes<span class="token operator">=</span>self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>logits<span class="token punctuation">.</span>device<span class="token punctuation">,</span>
                                                                           dtype<span class="token operator">=</span>logits<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>
        pt <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>labels_onehot <span class="token operator">*</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        CE <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>logits<span class="token punctuation">,</span>
                             target<span class="token operator">=</span>labels<span class="token punctuation">,</span>
                             reduction<span class="token operator">=</span><span class="token string">'none'</span><span class="token punctuation">,</span>
                             weight<span class="token operator">=</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
        poly1 <span class="token operator">=</span> CE <span class="token operator">+</span> self<span class="token punctuation">.</span>epsilon <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">"mean"</span><span class="token punctuation">:</span>
            poly1 <span class="token operator">=</span> poly1<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">"sum"</span><span class="token punctuation">:</span>
            poly1 <span class="token operator">=</span> poly1<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> poly1


<span class="token keyword">class</span> <span class="token class-name">Poly1FocalLoss</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
                 num_classes<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">,</span>
                 epsilon<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
                 alpha<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">0.25</span><span class="token punctuation">,</span>
                 gamma<span class="token punctuation">:</span> <span class="token builtin">float</span> <span class="token operator">=</span> <span class="token number">2.0</span><span class="token punctuation">,</span>
                 reduction<span class="token punctuation">:</span> <span class="token builtin">str</span> <span class="token operator">=</span> <span class="token string">"mean"</span><span class="token punctuation">,</span>
                 weight<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
                 pos_weight<span class="token punctuation">:</span> Tensor <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
                 label_is_onehot<span class="token punctuation">:</span> <span class="token builtin">bool</span> <span class="token operator">=</span> <span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Create instance of Poly1FocalLoss
        :param num_classes: number of classes
        :param epsilon: poly loss epsilon
        :param alpha: focal loss alpha
        :param gamma: focal loss gamma
        :param reduction: one of none|sum|mean, apply reduction to final loss tensor
        :param weight: manual rescaling weight for each class, passed to binary Cross-Entropy loss
        :param label_is_onehot: set to True if labels are one-hot encoded
        """</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Poly1FocalLoss<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        self<span class="token punctuation">.</span>epsilon <span class="token operator">=</span> epsilon
        self<span class="token punctuation">.</span>alpha <span class="token operator">=</span> alpha
        self<span class="token punctuation">.</span>gamma <span class="token operator">=</span> gamma
        self<span class="token punctuation">.</span>reduction <span class="token operator">=</span> reduction
        self<span class="token punctuation">.</span>weight <span class="token operator">=</span> weight
        self<span class="token punctuation">.</span>pos_weight <span class="token operator">=</span> pos_weight
        self<span class="token punctuation">.</span>label_is_onehot <span class="token operator">=</span> label_is_onehot
        <span class="token keyword">return</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> logits<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""
        Forward pass
        :param logits: output of neural netwrok of shape [N, num_classes] or [N, num_classes, ...]
        :param labels: ground truth tensor of shape [N] or [N, ...] with class ids if label_is_onehot was set to False, otherwise 
            one-hot encoded tensor of same shape as logits
        :return: poly focal loss
        """</span>
        <span class="token comment"># focal loss implementation taken from</span>
        <span class="token comment"># https://github.com/facebookresearch/fvcore/blob/main/fvcore/nn/focal_loss.py</span>

        p <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>logits<span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> self<span class="token punctuation">.</span>label_is_onehot<span class="token punctuation">:</span>
            <span class="token comment"># if labels are of shape [N]</span>
            <span class="token comment"># convert to one-hot tensor of shape [N, num_classes]</span>
            <span class="token keyword">if</span> labels<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                labels <span class="token operator">=</span> F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>labels<span class="token punctuation">,</span> num_classes<span class="token operator">=</span>self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

            <span class="token comment"># if labels are of shape [N, ...] e.g. segmentation task</span>
            <span class="token comment"># convert to one-hot tensor of shape [N, num_classes, ...]</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                labels <span class="token operator">=</span> F<span class="token punctuation">.</span>one_hot<span class="token punctuation">(</span>labels<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze_<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        labels <span class="token operator">=</span> labels<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token operator">=</span>logits<span class="token punctuation">.</span>device<span class="token punctuation">,</span>
                           dtype<span class="token operator">=</span>logits<span class="token punctuation">.</span>dtype<span class="token punctuation">)</span>

        ce_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>logits<span class="token punctuation">,</span>
                                                     target<span class="token operator">=</span>labels<span class="token punctuation">,</span>
                                                     reduction<span class="token operator">=</span><span class="token string">"none"</span><span class="token punctuation">,</span>
                                                     weight<span class="token operator">=</span>self<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>
                                                     pos_weight<span class="token operator">=</span>self<span class="token punctuation">.</span>pos_weight<span class="token punctuation">)</span>
        pt <span class="token operator">=</span> labels <span class="token operator">*</span> p <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> labels<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> p<span class="token punctuation">)</span>
        FL <span class="token operator">=</span> ce_loss <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">)</span> <span class="token operator">**</span> self<span class="token punctuation">.</span>gamma<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>alpha <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            alpha_t <span class="token operator">=</span> self<span class="token punctuation">.</span>alpha <span class="token operator">*</span> labels <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> self<span class="token punctuation">.</span>alpha<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> labels<span class="token punctuation">)</span>
            FL <span class="token operator">=</span> alpha_t <span class="token operator">*</span> FL

        poly1 <span class="token operator">=</span> FL <span class="token operator">+</span> self<span class="token punctuation">.</span>epsilon <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> pt<span class="token punctuation">,</span> self<span class="token punctuation">.</span>gamma <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">"mean"</span><span class="token punctuation">:</span>
            poly1 <span class="token operator">=</span> poly1<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">elif</span> self<span class="token punctuation">.</span>reduction <span class="token operator">==</span> <span class="token string">"sum"</span><span class="token punctuation">:</span>
            poly1 <span class="token operator">=</span> poly1<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> poly1
</code></pre> 
<h2><a id="_173"></a>总结</h2> 
<p>以resnet18为例，训练过程loss图被删了，所以只能在花朵识别在验证集中识别一下，结果正确率上升了6%左右，数据集如下：<br> 链接：https://pan.baidu.com/s/1zs9U76OmGAIwbYr91KQxgg<br> 提取码：bhjx<br> 有兴趣的小伙伴可以自己尝试一下。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e2f5d60e938e261bfdb360e60548c30b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">解决vue代码不规范而出现的问题：Eslint修复</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/be62e00f32a8f58e1db7811698821cd2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">jenkins构建触发器设置（定时任务）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>