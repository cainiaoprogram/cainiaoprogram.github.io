<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>ORB&#43;GMS、FREAK&#43;GMS、BRISK&#43;GMS、AKAZE&#43;GMS特征点结合使用方法 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="ORB&#43;GMS、FREAK&#43;GMS、BRISK&#43;GMS、AKAZE&#43;GMS特征点结合使用方法" />
<meta property="og:description" content="关于ORB、FREAK、BRISK、AKAZE的具体原理参考原文，最近没时间翻译，后续会花时间把原文翻译放在博客里面。这些特征点提取方法都可以在opencv里面调用函数实现。
特征点提取与匹配原文论文下载_nudt一枚研究生-CSDN博客
feature_extraction.cpp #include &lt;iostream&gt; #include &lt;opencv2/core/core.hpp&gt; #include &lt;opencv2/features2d/features2d.hpp&gt; #include &lt;opencv2/highgui/highgui.hpp&gt; #include &lt;chrono&gt; #include &lt;opencv2/imgproc.hpp&gt; #include &lt;opencv2/flann.hpp&gt; #include &lt;opencv2/xfeatures2d.hpp&gt; using namespace std; using namespace cv; using namespace cv::xfeatures2d; // FAST特征提取 void FAST_feature(const Mat&amp; img, std::vector&lt;KeyPoint&gt;&amp; keypoints); //orb特征提取与匹配 void ORB_feature_matches ( const Mat&amp; img_1, const Mat&amp; img_2, std::vector&lt;KeyPoint&gt;&amp; keypoints_1, std::vector&lt;KeyPoint&gt;&amp; keypoints_2, std::vector&lt; DMatch &gt;&amp; matches ); //BRISK 特征提取与匹配 void BRISK_feature_matches ( const Mat&amp; img_1, const Mat&amp; img_2, std::vector&lt;KeyPoint&gt;&amp; keypoints_1, std::vector&lt;KeyPoint&gt;&amp; keypoints_2, std::vector&lt; DMatch &gt;&amp; matches ); //AKAZE 特征提取与匹配 void AKAZE_feature_matches ( const Mat&amp; img_1, const Mat&amp; img_2, std::vector&lt;KeyPoint&gt;&amp; keypoints_1, std::vector&lt;KeyPoint&gt;&amp; keypoints_2, std::vector&lt; DMatch &gt;&amp; matches ); //FREAK 特征提取与匹配 void FREAK_feature_matches ( const Mat&amp; img_1, const Mat&amp; img_2, std::vector&lt;KeyPoint&gt;&amp; keypoints_1, std::vector&lt;KeyPoint&gt;&amp; keypoints_2, std::vector&lt; DMatch &gt;&amp; matches ); int main ( int argc, char** argv ) { if ( argc !" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/283163acf2930b5f51e7fbaa1e8b0486/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-12-21T22:34:36+08:00" />
<meta property="article:modified_time" content="2021-12-21T22:34:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">ORB&#43;GMS、FREAK&#43;GMS、BRISK&#43;GMS、AKAZE&#43;GMS特征点结合使用方法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><span style="color:#e6b223;"><strong>关于ORB、FREAK、BRISK、AKAZE的具体原理参考原文，最近没时间翻译，后续会花时间把原文翻译放在博客里面。这些特征点提取方法都可以在opencv里面调用函数实现。</strong></span></p> 
<p><a href="https://blog.csdn.net/weixin_53660567/article/details/121625268" title="特征点提取与匹配原文论文下载_nudt一枚研究生-CSDN博客">特征点提取与匹配原文论文下载_nudt一枚研究生-CSDN博客</a></p> 
<h2><strong>feature_extraction.cpp</strong></h2> 
<pre><code>#include &lt;iostream&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/features2d/features2d.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;chrono&gt;
#include &lt;opencv2/imgproc.hpp&gt;
#include &lt;opencv2/flann.hpp&gt;
#include &lt;opencv2/xfeatures2d.hpp&gt;


using namespace std;
using namespace cv;
using namespace cv::xfeatures2d;

// FAST特征提取
void FAST_feature(const Mat&amp; img, std::vector&lt;KeyPoint&gt;&amp; keypoints);

//orb特征提取与匹配
void ORB_feature_matches (
    const Mat&amp; img_1, const Mat&amp; img_2,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_1,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_2,
    std::vector&lt; DMatch &gt;&amp; matches );


//BRISK 特征提取与匹配
void BRISK_feature_matches (
    const Mat&amp; img_1, const Mat&amp; img_2,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_1,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_2,
    std::vector&lt; DMatch &gt;&amp; matches );

//AKAZE 特征提取与匹配
void AKAZE_feature_matches (
    const Mat&amp; img_1, const Mat&amp; img_2,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_1,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_2,
    std::vector&lt; DMatch &gt;&amp; matches );
//FREAK 特征提取与匹配
void FREAK_feature_matches (
    const Mat&amp; img_1, const Mat&amp; img_2,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_1,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_2,
    std::vector&lt; DMatch &gt;&amp; matches );


int main ( int argc, char** argv )
{
    if ( argc != 3 )
    {
        cout&lt;&lt;"usage: inpute img1 img2"&lt;&lt;endl;
        return 1;
    }
    //-- 读取图像
    Mat img_1 = imread ( argv[1], CV_LOAD_IMAGE_COLOR );
    Mat img_2 = imread ( argv[2], CV_LOAD_IMAGE_COLOR );

// FAST -FEATURE
    vector&lt;KeyPoint&gt; fast_keypoints;
    FAST_feature(img_1, fast_keypoints);
    cout&lt;&lt;"use FAST_feature_matches found "&lt;&lt;fast_keypoints.size() &lt;&lt;"keypoints"&lt;&lt;endl;
    Mat fast_feature_image;
    drawKeypoints(img_1, fast_keypoints, fast_feature_image, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
    imshow("FAST_feature_image", fast_feature_image);
    cout &lt;&lt; "\r\n" &lt;&lt; endl;

// ORB-FEATURE
    vector&lt;KeyPoint&gt; orb_keypoints_1, orb_keypoints_2;
    vector&lt;DMatch&gt; orb_matches;
    ORB_feature_matches ( img_1, img_2, orb_keypoints_1, orb_keypoints_2, orb_matches );
    cout&lt;&lt;"use ORB_feature_matches found"&lt;&lt;orb_keypoints_1.size() &lt;&lt;"keypoints"&lt;&lt;endl;
    // 绘制orb特征点与特征匹配
    Mat orb_feature_image, orb_matches_image;
    drawKeypoints(img_1, orb_keypoints_1, orb_feature_image, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
    imshow("ORB_feature_image", orb_feature_image);
    drawMatches ( img_1, orb_keypoints_1, img_2, orb_keypoints_2, orb_matches, orb_matches_image );
    imshow("ORB_matches_image", orb_matches_image);
    imwrite("ORB_matches_image.jpg", orb_matches_image);
    cout &lt;&lt; "\r\n" &lt;&lt; endl;

// BRISK-FEATURE
    vector&lt;KeyPoint&gt; brisk_keypoint_1, brisk_keypoint_2;
    vector&lt;DMatch&gt; brisk_matches;
    BRISK_feature_matches(img_1, img_2, brisk_keypoint_1, brisk_keypoint_2, brisk_matches);
    cout &lt;&lt; "use BRISK_feature_matches found " &lt;&lt; brisk_keypoint_1.size() &lt;&lt; "keypoints" &lt;&lt; endl;

    Mat brisk_feature_image, brisk_matches_image;
    drawKeypoints(img_1, brisk_keypoint_1, brisk_feature_image, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
    imshow("BRISK feature image", brisk_feature_image);
    drawMatches(img_1, brisk_keypoint_1, img_2 ,brisk_keypoint_2, brisk_matches, brisk_matches_image);
    imshow("BRISK matches image", brisk_matches_image);
    imwrite("BRISK_matches_image.jpg", brisk_matches_image);
    cout &lt;&lt; "\r\n" &lt;&lt; endl;

// AKAZE-FEATURE
    vector&lt;KeyPoint&gt; akaze_keypoint_1, akaze_keypoint_2;
    vector&lt;DMatch&gt; akaze_matches;
    Mat descriptors_1,descriptors_2;
    AKAZE_feature_matches(img_1, img_2, akaze_keypoint_1, akaze_keypoint_2, akaze_matches);
    cout &lt;&lt; "use akaze_feature_matches found " &lt;&lt; akaze_keypoint_1.size() &lt;&lt; "keypoints" &lt;&lt; endl;

    Mat akaze_feature_image, akaze_matches_image;
    drawKeypoints(img_1, akaze_keypoint_1, akaze_feature_image, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
    imshow("akaze feature image", akaze_feature_image);
    drawMatches(img_1, akaze_keypoint_1, img_2 ,akaze_keypoint_2, akaze_matches, akaze_matches_image);
    imshow("akaze matches image", akaze_matches_image);
    imwrite("akaze matches image.jpg", akaze_matches_image);

    // FREAK-FEATURE
    vector&lt;KeyPoint&gt; freak_keypoint_1, freak_keypoint_2;
    vector&lt;DMatch&gt; freak_matches;
    //Mat descriptors_1,descriptors_2;
    FREAK_feature_matches(img_1, img_2, freak_keypoint_1, freak_keypoint_2, freak_matches);
    cout &lt;&lt; "use freak_feature_matches found " &lt;&lt; freak_keypoint_1.size() &lt;&lt; "keypoints" &lt;&lt; endl;

    Mat freak_feature_image, freak_matches_image;
    drawKeypoints(img_1, freak_keypoint_1, freak_feature_image, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
    imshow("freak feature image", freak_feature_image);
    drawMatches(img_1, freak_keypoint_1, img_2 ,freak_keypoint_2, freak_matches, freak_matches_image);
    imshow("freak matches image", freak_matches_image);
    imwrite("freak matches image.jpg", freak_matches_image);


    cvWaitKey(0);
    return 0;
}


void FAST_feature(const Mat&amp; img, std::vector&lt;KeyPoint&gt;&amp; keypoints)
{
    const int threshold = 50;
    const bool nonmaxSuppression = true;
    const int type = FastFeatureDetector::TYPE_7_12;

    Ptr&lt;FeatureDetector&gt; fast_feature = FastFeatureDetector::create(threshold,  nonmaxSuppression, type);
    // Ptr&lt;FeatureDetector&gt; fast_feature = FastFeatureDetector::create();
    fast_feature-&gt;detect(img, keypoints);
    
    
}

void ORB_feature_matches ( const Mat&amp; img_1, const Mat&amp; img_2,
                            std::vector&lt;KeyPoint&gt;&amp; keypoints_1,
                            std::vector&lt;KeyPoint&gt;&amp; keypoints_2,
                            std::vector&lt; DMatch &gt;&amp; matches )
{
    //-- 初始化
    Mat descriptors_1, descriptors_2;
    // used in OpenCV3 
    chrono::steady_clock::time_point t0 = chrono::steady_clock::now();
    Ptr&lt;FeatureDetector&gt; detector = ORB::create(2000);
    Ptr&lt;DescriptorExtractor&gt; descriptor = ORB::create();
    // Ptr&lt;cv::xfeatures2d::SurfFeatureDetector&gt; detector;
    // detector = cv::xfeatures2d::SurfFeatureDetector::create(15);
    
    // use this if you are in OpenCV2 
    // Ptr&lt;FeatureDetector&gt; detector = FeatureDetector::create ( "ORB" );
    // Ptr&lt;DescriptorExtractor&gt; descriptor = DescriptorExtractor::create ( "ORB" );
    Ptr&lt;DescriptorMatcher&gt; matcher  = DescriptorMatcher::create ( "BruteForce-Hamming" );
    //-- 第一步:检测 Oriented FAST 角点位置
    chrono::steady_clock::time_point t1 = chrono::steady_clock::now();
    detector-&gt;detect ( img_1,keypoints_1 );
    detector-&gt;detect ( img_2,keypoints_2 );
    chrono::steady_clock::time_point t2 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used1 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t2-t1 );
    cout &lt;&lt; "ORB Feature detector time: " &lt;&lt; time_used1.count() &lt;&lt; "seconds" &lt;&lt;endl;

    //-- 第二步:根据角点位置计算 BRIEF 描述子
    chrono::steady_clock::time_point t3 = chrono::steady_clock::now();
    descriptor-&gt;compute ( img_1, keypoints_1, descriptors_1 );
    descriptor-&gt;compute ( img_2, keypoints_2, descriptors_2 );
    chrono::steady_clock::time_point t4 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used2 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t4-t3 );
    cout &lt;&lt; "ORB Descriptor Extractor time: " &lt;&lt; time_used2.count() &lt;&lt; "seconds" &lt;&lt;endl;    

    //-- 第三步:对两幅图像中的BRIEF描述子进行匹配，使用 Hamming 距离
    vector&lt;DMatch&gt; match;
    chrono::steady_clock::time_point t5 = chrono::steady_clock::now();
    //BFMatcher matcher ( NORM_HAMMING );
    matcher-&gt;match ( descriptors_1, descriptors_2, match );
    chrono::steady_clock::time_point t6 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used3 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t6-t5 );
    cout &lt;&lt; "ORB Descriptor match time: " &lt;&lt; time_used3.count() &lt;&lt; "seconds" &lt;&lt;endl;      

    //-- 第四步:匹配点对筛选
    double min_dist=10000, max_dist=0;

    //找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离
    for ( int i = 0; i &lt; descriptors_1.rows; i++ )
    {
        double dist = match[i].distance;
        if ( dist &lt; min_dist ) min_dist = dist;
        if ( dist &gt; max_dist ) max_dist = dist;
    }

    printf ( "-- Max dist : %f \n", max_dist );
    printf ( "-- Min dist : %f \n", min_dist );

    //当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限
    for ( int i = 0; i &lt; descriptors_1.rows; i++ )
    {
        if ( match[i].distance &lt;= max ( 2.6*min_dist, 0.2 ) )//增加特征点数或减少特征点数再这里调整
        {
            matches.push_back ( match[i] );
        }
    }
    printf ( "ORB-- All matches : %d \n", (int)match.size() );
    printf ( "ORB-- filter match : %d \n", (int)matches.size() ); 
     
}

//BRISK 特征提取与匹配
void BRISK_feature_matches (  const Mat&amp; img_1, const Mat&amp; img_2,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_1, std::vector&lt;KeyPoint&gt;&amp; keypoints_2,    std::vector&lt; DMatch &gt;&amp; matches )
{
    // BRISK 初始化 关键点和描述子
    chrono::steady_clock::time_point t0 = chrono::steady_clock::now();
    Ptr&lt;FeatureDetector&gt;  brisk_feature = BRISK::create();
    Ptr&lt;DescriptorExtractor&gt; descriptor = BRISK::create();
    Ptr&lt;DescriptorMatcher&gt; matche = DescriptorMatcher::create( "BruteForce-Hamming" );


    //提取关键点 计算描述子
    chrono::steady_clock::time_point t7 = chrono::steady_clock::now();
    brisk_feature-&gt;detect(img_1,  keypoints_1);
    brisk_feature-&gt;detect(img_2,  keypoints_2);
    chrono::steady_clock::time_point t8 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used4 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t8-t7 );
    cout &lt;&lt; "BRISK Feature detector time: " &lt;&lt; time_used4.count() &lt;&lt; "seconds" &lt;&lt;endl;    


    Mat descriptors_1, descriptors_2;
    chrono::steady_clock::time_point t3 = chrono::steady_clock::now();
    descriptor-&gt;compute(img_1, keypoints_1, descriptors_1);
    descriptor-&gt;compute(img_2, keypoints_2, descriptors_2);
    chrono::steady_clock::time_point t4 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used2 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t4-t3 );
    cout &lt;&lt; "BRISK Descriptor Extractor time: " &lt;&lt; time_used2.count() &lt;&lt; "seconds" &lt;&lt;endl;    

    //匹配描述子 以及滤除误匹配
    vector&lt;DMatch&gt; match;
    chrono::steady_clock::time_point t5 = chrono::steady_clock::now();
    matche-&gt;match(descriptors_1, descriptors_2,  match);
    chrono::steady_clock::time_point t6 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used3 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t6-t5 );
    cout &lt;&lt; "BRISK Descriptor match time: " &lt;&lt; time_used3.count() &lt;&lt; "seconds" &lt;&lt;endl;    

    double min_dist = 10000, max_dist =100;
    for(int i=0; i&lt; descriptors_1.rows; i++)
    {
        double dist = match[i].distance;
        if(dist &lt; min_dist) min_dist = dist;
        if(dist &gt; max_dist) max_dist = dist;
    }
    printf ( "BRISK-- Max dist : %f \n", max_dist );
    printf ( "BRISK-- Min dist : %f \n", min_dist );

    for(int j=0; j&lt; descriptors_1.rows; j++)    
    {
        if(match[j].distance &lt; max (2*min_dist, 5.0))//增加特征点数或减少特征点数再这里调整
            matches.push_back(match[j]);
    }
    printf ( "BRISK-- All matches : %d \n", (int)match.size() );
    printf ( "BRISK-- filter match : %d \n", (int)matches.size() );   

}



//AKAZE 特征提取与匹配
void AKAZE_feature_matches (  const Mat&amp; img_1, const Mat&amp; img_2,
    std::vector&lt;KeyPoint&gt;&amp; keypoints_1, std::vector&lt;KeyPoint&gt;&amp; keypoints_2,    std::vector&lt; DMatch &gt;&amp; matches )
{
    // FREAK 初始化 关键点和描述子
    chrono::steady_clock::time_point t0 = chrono::steady_clock::now();
    Ptr&lt;FeatureDetector&gt;  akaze_feature = AKAZE::create();
    Ptr&lt;DescriptorExtractor&gt; descriptor = AKAZE::create();
    Ptr&lt;DescriptorMatcher&gt; matche = DescriptorMatcher::create( "BruteForce-Hamming" );


    //提取关键点 计算描述子
    chrono::steady_clock::time_point t7 = chrono::steady_clock::now();
    akaze_feature-&gt;detect(img_1,  keypoints_1);
    akaze_feature-&gt;detect(img_2,  keypoints_2);
    chrono::steady_clock::time_point t8 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used4 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t8-t7 );
    cout &lt;&lt; "AKAZE Feature detector time: " &lt;&lt; time_used4.count() &lt;&lt; "seconds" &lt;&lt;endl;    


    Mat descriptors_1, descriptors_2;
    chrono::steady_clock::time_point t3 = chrono::steady_clock::now();
    descriptor-&gt;compute(img_1, keypoints_1, descriptors_1);
    descriptor-&gt;compute(img_2, keypoints_2, descriptors_2);
    chrono::steady_clock::time_point t4 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used2 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t4-t3 );
    cout &lt;&lt; "AKAZE Descriptor Extractor time: " &lt;&lt; time_used2.count() &lt;&lt; "seconds" &lt;&lt;endl;    

    //匹配描述子 以及滤除误匹配
    vector&lt;DMatch&gt; match;
    chrono::steady_clock::time_point t5 = chrono::steady_clock::now();
    matche-&gt;match(descriptors_1, descriptors_2,  match);
    chrono::steady_clock::time_point t6 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used3 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t6-t5 );
    cout &lt;&lt; "AKAZE Descriptor match time: " &lt;&lt; time_used3.count() &lt;&lt; "seconds" &lt;&lt;endl;   

 

    double min_dist = 10000, max_dist =100;
    for(int i=0; i&lt; descriptors_1.rows; i++)
    {
        double dist = match[i].distance;
        if(dist &lt; min_dist) min_dist = dist;
        if(dist &gt; max_dist) max_dist = dist;
    }
    printf ( "AKAZE-- Max dist : %f \n", max_dist );
    printf ( "AKAZE-- Min dist : %f \n", min_dist );

    for(int j=0; j&lt; descriptors_1.rows; j++)    
    {
        if(match[j].distance &lt; max (2*min_dist, 30.0))//增加特征点数或减少特征点数再这里调整
            matches.push_back(match[j]);
    }
    printf ( "AKAZE-- All matches : %d \n", (int)match.size() );
    printf ( "AKAZE-- filter match : %d \n", (int)matches.size() );   

}

//FREAK 特征提取与匹配
void FREAK_feature_matches ( const Mat&amp; img_1, const Mat&amp; img_2,
                            std::vector&lt;KeyPoint&gt;&amp; keypoints_1,
                            std::vector&lt;KeyPoint&gt;&amp; keypoints_2,
                            std::vector&lt; DMatch &gt;&amp; matches )
{
    //-- 初始化
    Mat descriptors_1, descriptors_2;
    // used in OpenCV3 
    chrono::steady_clock::time_point t0 = chrono::steady_clock::now();
    //Ptr&lt;FeatureDetector&gt; detector = ORB::create(2000);
    //Ptr&lt;DescriptorExtractor&gt; descriptor = ORB::create();
    Ptr&lt;cv::xfeatures2d::SurfFeatureDetector&gt; detector;
    detector = cv::xfeatures2d::SurfFeatureDetector::create(15);
    // DESCRIPTOR
    Ptr&lt;FREAK&gt; extractor = FREAK::create();
    Ptr&lt;DescriptorExtractor&gt; descriptor = FREAK::create();
   
    Ptr&lt;DescriptorMatcher&gt; matcher  = DescriptorMatcher::create ( "BruteForce-Hamming" );
    //BFMatcher matcher(NORM_HAMMING);        // 使用Hamming距离测试
    //-- 第一步:检测 Oriented FAST 角点位置
    chrono::steady_clock::time_point t1 = chrono::steady_clock::now();
    detector-&gt;detect ( img_1,keypoints_1 );
    detector-&gt;detect ( img_2,keypoints_2 );
    chrono::steady_clock::time_point t2 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used1 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t2-t1 );
    cout &lt;&lt; "FREAK Feature detector time: " &lt;&lt; time_used1.count() &lt;&lt; "seconds" &lt;&lt;endl;

    //-- 第二步:根据角点位置计算 BRIEF 描述子
    chrono::steady_clock::time_point t3 = chrono::steady_clock::now();
    descriptor-&gt;compute ( img_1, keypoints_1, descriptors_1 );
    descriptor-&gt;compute ( img_2, keypoints_2, descriptors_2 );
    chrono::steady_clock::time_point t4 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used2 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t4-t3 );
    cout &lt;&lt; "FREAK Descriptor Extractor time: " &lt;&lt; time_used2.count() &lt;&lt; "seconds" &lt;&lt;endl;    

    //-- 第三步:对两幅图像中的BRIEF描述子进行匹配，使用 Hamming 距离
    vector&lt;DMatch&gt; match;
    chrono::steady_clock::time_point t5 = chrono::steady_clock::now();
    //BFMatcher matcher ( NORM_HAMMING );
    matcher-&gt;match ( descriptors_1, descriptors_2, match );
    chrono::steady_clock::time_point t6 = chrono::steady_clock::now();
    chrono::duration&lt;double&gt; time_used3 = chrono::duration_cast&lt;chrono::duration&lt;double&gt;&gt;( t6-t5 );
    cout &lt;&lt; "FREAK Descriptor match time: " &lt;&lt; time_used3.count() &lt;&lt; "seconds" &lt;&lt;endl;      

    //-- 第四步:匹配点对筛选
    double min_dist=10000, max_dist=100;

    //找出所有匹配之间的最小距离和最大距离, 即是最相似的和最不相似的两组点之间的距离
    for ( int i = 0; i &lt; descriptors_1.rows; i++ )
    {
        double dist = match[i].distance;
        if ( dist &lt; min_dist ) min_dist = dist;
        if ( dist &gt; max_dist ) max_dist = dist;
    }

    printf ( "-- Max dist : %f \n", max_dist );
    printf ( "-- Min dist : %f \n", min_dist );

    //当描述子之间的距离大于两倍的最小距离时,即认为匹配有误.但有时候最小距离会非常小,设置一个经验值30作为下限.
    for ( int i = 0; i &lt; descriptors_1.rows; i++ )
    {
        if ( match[i].distance &lt;= max ( 2*min_dist, 0.5 ) )//增加特征点数或减少特征点数再这里调整
        {
            matches.push_back ( match[i] );
        }
    }
    printf ( "FREAK-- All matches : %d \n", (int)match.size() );
    printf ( "FREAK-- filter match : %d \n", (int)matches.size() ); 
}
</code></pre> 
<h2></h2> 
<h2><strong>CMakeLists.txt</strong></h2> 
<pre><code>cmake_minimum_required( VERSION 2.8 )
project( vo1_1 )

set( CMAKE_BUILD_TYPE "Release" )
set( CMAKE_CXX_FLAGS "-std=c++14 -O3" )

find_package( OpenCV 3.4 REQUIRED )
include_directories( 
    ${OpenCV_INCLUDE_DIRS} 
)

add_executable( feature_extraction feature_extraction.cpp  )
target_link_libraries( feature_extraction ${OpenCV_LIBS} )
</code></pre> 
<h2>执行效果：</h2> 
<h3>（1）1.png 2.png</h3> 
<pre><code>./feature_extraction ../1.png ../2.png 
</code></pre> 
<pre><code>use FAST_feature_matches found 231keypoints


ORB Feature detector time: 0.00899468seconds
ORB Descriptor Extractor time: 0.0149223seconds
ORB Descriptor match time: 0.0055109seconds
-- Max dist : 92.000000 
-- Min dist : 4.000000 
ORB-- All matches : 2000 
ORB-- filter match : 14 
use ORB_feature_matches found2000keypoints


BRISK Feature detector time: 0.0313001seconds
BRISK Descriptor Extractor time: 0.0209471seconds
BRISK Descriptor match time: 0.00422422seconds
BRISK-- Max dist : 175.000000 
BRISK-- Min dist : 14.000000 
BRISK-- All matches : 1677 
BRISK-- filter match : 39 
use BRISK_feature_matches found 1677keypoints


AKAZE Feature detector time: 0.0428866seconds
AKAZE Descriptor Extractor time: 0.0362389seconds
AKAZE Descriptor match time: 0.00130731seconds
AKAZE-- Max dist : 174.000000 
AKAZE-- Min dist : 9.000000 
AKAZE-- All matches : 773 
AKAZE-- filter match : 73 
use akaze_feature_matches found 773keypoints


FREAK Feature detector time: 0.0338685seconds
FREAK Descriptor Extractor time: 0.041976seconds
FREAK Descriptor match time: 0.0047295seconds
-- Max dist : 185.000000 
-- Min dist : 2.000000 
FREAK-- All matches : 1668 
FREAK-- filter match : 2 
use freak_feature_matches found 1668keypoints
</code></pre> 
<p><img alt="" height="530" src="https://images2.imgbox.com/20/e5/AwyjaEE1_o.png" width="669"></p> 
<h4> ORB</h4> 
<p><img alt="" height="540" src="https://images2.imgbox.com/47/bd/nTEDbtuF_o.png" width="680"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/05/0e/ONCeG9y4_o.png" width="1200"></p> 
<h4>BRISK</h4> 
<p> <img alt="" height="527" src="https://images2.imgbox.com/28/82/SJPCgaaT_o.png" width="665"></p> 
<p> <img alt="" height="479" src="https://images2.imgbox.com/46/65/icIec7PN_o.png" width="1200"></p> 
<h4>AKAZE</h4> 
<p><img alt="" height="549" src="https://images2.imgbox.com/0c/55/iolSTboE_o.png" width="688"></p> 
<h4> FREAK<img alt="" height="479" src="https://images2.imgbox.com/49/ca/fwT83klR_o.png" width="1200"></h4> 
<p> <img alt="" height="538" src="https://images2.imgbox.com/b6/6f/fkLgo8O5_o.png" width="678"></p> 
<p><img alt="" height="498" src="https://images2.imgbox.com/a5/29/LPRwTiOM_o.png" width="1200"></p> 
<h3> （2）8.png 9.png</h3> 
<p><img alt="" height="539" src="https://images2.imgbox.com/99/5d/XgFbbxx8_o.png" width="681"></p> 
<p></p> 
<h4>ORB</h4> 
<p><img alt="" height="528" src="https://images2.imgbox.com/0d/f6/NMYZJWoJ_o.png" width="673"></p> 
<p> <img alt="" height="481" src="https://images2.imgbox.com/13/96/GR5Iovnq_o.png" width="1199"></p> 
<h4>BRISK</h4> 
<p><img alt="" height="527" src="https://images2.imgbox.com/f1/3d/JRXsNNWb_o.png" width="660"></p> 
<p> <img alt="" height="476" src="https://images2.imgbox.com/98/4d/pqniePNr_o.png" width="1200"></p> 
<h4>AKAZE</h4> 
<p><img alt="" height="529" src="https://images2.imgbox.com/64/da/mKLRbRGv_o.png" width="669"></p> 
<p><img alt="" height="476" src="https://images2.imgbox.com/83/61/iT9nEd6L_o.png" width="1200"></p> 
<h4>FREAK</h4> 
<p><img alt="" height="530" src="https://images2.imgbox.com/de/de/ASMf19OM_o.png" width="673"></p> 
<p><img alt="" height="476" src="https://images2.imgbox.com/55/76/L3WILlSn_o.png" width="1200"></p> 
<p><strong><span style="color:#ff9900;">总结： 从上面的结果来看，尽管对提取的特征点很多，但是匹配后正确的对数却很少，有的方法甚至只有寥寥无几的正确匹配点数。</span></strong></p> 
<h2>解决办法</h2> 
<p><strong><span style="color:#b95514;">将上述特征点方法结合GMS方法使用，这样能够较大程度的提高匹配点数，关于GMS的具体原理和实践我已经在前面的两篇博客里详细写过，大家如果没有实践过的参考我之前写的帖子。</span></strong></p> 
<p><a href="https://blog.csdn.net/weixin_53660567/article/details/121692374" title="GMS: Grid-based Motion Statistics forFast, Ultra-robust Feature Correspondence论文翻译_nudt一枚研究生-CSDN博客_gms评估">GMS: Grid-based Motion Statistics forFast, Ultra-robust Feature Correspondence论文翻译_nudt一枚研究生-CSDN博客_gms评估</a></p> 
<p><a href="https://blog.csdn.net/weixin_53660567/article/details/121707150" title="GMS特征点代码实践_nudt一枚研究生-CSDN博客">GMS特征点代码实践_nudt一枚研究生-CSDN博客</a></p> 
<p><strong><span style="color:#956fe7;">下面直接上ORB+GMS、FREAK+GMS、BRISK+GMS、AKAZE+GMS特征点结合使用后得到的效果图：</span></strong></p> 
<pre><code>use FAST_feature_matches found 231keypoints


ORB Feature detector time: 0.0092361seconds
ORB Descriptor Extractor time: 0.0149115seconds
ORB Descriptor match time: 0.0055028seconds
-- Max dist : 92.000000 
-- Min dist : 4.000000 
ORB-- All matches : 2000 
ORB-- filter match : 14 
matchesAll: 2000
matches ORB+GMS: 1187
ORB+GMS match time: 0.0495641seconds
use ORB_feature_matches found2000keypoints


BRISK Feature detector time: 0.0315025seconds
BRISK Descriptor Extractor time: 0.021117seconds
BRISK Descriptor match time: 0.00421157seconds
BRISK-- Max dist : 175.000000 
BRISK-- Min dist : 14.000000 
BRISK-- All matches : 1677 
BRISK-- filter match : 39 
matchesAll: 1677
matches BRISK+GMS: 805
BRISK+GMS match time: 0.105189seconds
use BRISK_feature_matches found 1677keypoints


AKAZE Feature detector time: 0.0463033seconds
AKAZE Descriptor Extractor time: 0.0407786seconds
AKAZE Descriptor match time: 0.00116544seconds
AKAZE-- Max dist : 174.000000 
AKAZE-- Min dist : 9.000000 
AKAZE-- All matches : 773 
AKAZE-- filter match : 73 
matchesAll: 773
matches AKAZE+GMS: 439
AKAZE+GMS match time: 0.0955873seconds
use akaze_feature_matches found 773keypoints


FREAK Feature detector time: 0.0320268seconds
FREAK Descriptor Extractor time: 0.0440346seconds
FREAK Descriptor match time: 0.00467602seconds
-- Max dist : 185.000000 
-- Min dist : 2.000000 
FREAK-- All matches : 1668 
FREAK-- filter match : 2 
matchesAll: 1668
matches FREAK+GMS: 680
FREAK+GMS match time: 0.09467seconds
use freak_feature_matches found 1668keypoints
</code></pre> 
<p><strong><span style="color:#511b78;">具体的正确匹配点数增加如代码段里的数据可知</span></strong></p> 
<h2>执行效果：</h2> 
<h3>（1）1.png 2.png</h3> 
<h4>ORB</h4> 
<p><img alt="" height="477" src="https://images2.imgbox.com/67/33/RODpeQdR_o.png" width="1199"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/a4/1a/woCBjPEE_o.png" width="1200"></p> 
<p></p> 
<h4>BRISK</h4> 
<p><img alt="" height="468" src="https://images2.imgbox.com/aa/d3/1NVSGQSh_o.png" width="1200"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/38/41/6xO9ITxS_o.png" width="1200"></p> 
<h4>AKAZE</h4> 
<p><img alt="" height="475" src="https://images2.imgbox.com/fb/8f/DTf8EsCu_o.png" width="1200"></p> 
<p><img alt="" height="478" src="https://images2.imgbox.com/f0/61/qUb9WZng_o.png" width="1200"></p> 
<h4>FREAK</h4> 
<p><img alt="" height="480" src="https://images2.imgbox.com/22/5a/T6cuaOfv_o.png" width="1200"></p> 
<p><img alt="" height="476" src="https://images2.imgbox.com/bc/c6/rGUZRAAK_o.png" width="1200"></p> 
<h3>（2）8.png 9.png</h3> 
<h4>ORB</h4> 
<p><img alt="" height="506" src="https://images2.imgbox.com/5b/8b/tvfrkeS2_o.png" width="1200"></p> 
<p><img alt="" height="479" src="https://images2.imgbox.com/a0/7e/Y56zvqEW_o.png" width="1200"></p> 
<p></p> 
<h4>BRISK</h4> 
<p><img alt="" height="506" src="https://images2.imgbox.com/00/99/jJeG9qqY_o.png" width="1200"></p> 
<p><img alt="" height="503" src="https://images2.imgbox.com/ce/ed/G9ErElfU_o.png" width="1200"></p> 
<h4>AKAZE</h4> 
<p><img alt="" height="506" src="https://images2.imgbox.com/9a/b6/gm80I5Az_o.png" width="1200"></p> 
<p> <img alt="" height="505" src="https://images2.imgbox.com/6b/7f/E5npSvPO_o.png" width="1200"></p> 
<h4>FREAK</h4> 
<p><img alt="" height="508" src="https://images2.imgbox.com/54/64/bwLmJoxz_o.png" width="1200"></p> 
<p><img alt="" height="505" src="https://images2.imgbox.com/6b/d8/6JeLteUJ_o.png" width="1200"><span style="color:#38d8f0;"><strong>结论：通过将特征点方法结合使用从而能够让匹配点数在很大程度上得到提高，而且能够降低一些误匹配点。 </strong></span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bf3ed6956859c4c3f1f01c2ced593561/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">去除 element-ui 中 Dialog 对话框遮罩层的方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0dbecdb5844d23bafcc93e1137dbe847/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">.NET EFCore之增删改查</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>