<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch实现多层lstm - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch实现多层lstm" />
<meta property="og:description" content="P y t o r c h 实现多层 l s t m Pytorch实现多层lstm Pytorch实现多层lstm 推荐一下：深度学习AI-计算机视觉（CV）-整体解决方案课件（Yolo&#43;Flask&#43;Vue&#43;Waitress&#43;Nginx） 视频教程：https://www.bilibili.com/video/BV19h4y1874T/?spm_id_from=333.999.0.0 # 10：输入数据维度大小 20 ：隐状态的特征维度 2：层数，表示用来两层lstm lstm = nn.LSTM(10, 20, 2) # 5：序列长度 3：单个训练数据长度 10：单个序列维度 举个例子：每次运行时取3个含有5个字的句子（且句子中每个字的维度为10） input = Variable(torch.randn(5, 3, 10)) # 2个LSTM层，batch_size=3, 隐藏层的特征维度20 h0 = Variable(torch.randn(2, 3, 20)) # 2个LSTM层，batch_size=3, 隐藏层的特征维度20 # 这里有2层lstm，output是最后一层lstm的每个词向量对应隐藏层的输出,其与层数无关，只与序列长度相关 c0 = Variable(torch.randn(2, 3, 20)) # output, hn = lstm(input, (h0, c0)) class RNN(nn.Module): def __init__(self, input_size, hidden_size, num_layers, num_classes): super(RNN, self)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7b6d113dfb972b3fd3b436c14f2c8fdb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-08T21:41:32+08:00" />
<meta property="article:modified_time" content="2023-10-08T21:41:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch实现多层lstm</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h3><a id="Pytorchlstm_0"></a><span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          P 
         
        
          y 
         
        
          t 
         
        
          o 
         
        
          r 
         
        
          c 
         
        
          h 
         
        
          实现多层 
         
        
          l 
         
        
          s 
         
        
          t 
         
        
          m 
         
        
       
         Pytorch实现多层lstm 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.1389em;">P</span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">orc</span><span class="mord mathnormal">h</span><span class="mord cjk_fallback">实现多层</span><span class="mord mathnormal" style="margin-right: 0.0197em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">m</span></span></span></span></span></span></h3> 
<h3><a id="AICVYoloFlaskVueWaitressNginxhttpsblogcsdnnetJumy_Sarticledetails133238782csdn_share_tail7B22type2222blog2222rType2222article2222rId22221332387822222source2222Jumy_S227D_1"></a>推荐一下：<a href="https://blog.csdn.net/Jumy_S/article/details/133238782?csdn_share_tail=%7B%22type%22:%22blog%22,%22rType%22:%22article%22,%22rId%22:%22133238782%22,%22source%22:%22Jumy_S%22%7D">深度学习AI-计算机视觉（CV）-整体解决方案课件（Yolo+Flask+Vue+Waitress+Nginx）</a></h3> 
<h3><a id="httpswwwbilibilicomvideoBV19h4y1874Tspm_id_from33399900httpswwwbilibilicomvideoBV19h4y1874Tspm_id_from33399900_3"></a><a href="https://www.bilibili.com/video/BV19h4y1874T/?spm_id_from=333.999.0.0" rel="nofollow">视频教程：https://www.bilibili.com/video/BV19h4y1874T/?spm_id_from=333.999.0.0</a></h3> 
<pre><code class="prism language-python"><span class="token comment"># 10：输入数据维度大小  20 ：隐状态的特征维度  2：层数，表示用来两层lstm</span>
lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># 5：序列长度 3：单个训练数据长度  10：单个序列维度  举个例子：每次运行时取3个含有5个字的句子（且句子中每个字的维度为10）</span>
<span class="token builtin">input</span> <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 2个LSTM层，batch_size=3, 隐藏层的特征维度20</span>
h0 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 2个LSTM层，batch_size=3, 隐藏层的特征维度20</span>
<span class="token comment"># 这里有2层lstm，output是最后一层lstm的每个词向量对应隐藏层的输出,其与层数无关，只与序列长度相关</span>

c0 <span class="token operator">=</span> Variable<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># </span>
output<span class="token punctuation">,</span> hn <span class="token operator">=</span> lstm<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>h0<span class="token punctuation">,</span> c0<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-c">class <span class="token function">RNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token operator">:</span>
    def <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span><span class="token operator">:</span>
        <span class="token function">super</span><span class="token punctuation">(</span>RNN<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">__init__</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>hidden_size <span class="token operator">=</span> hidden_size
        self<span class="token punctuation">.</span>num_layers <span class="token operator">=</span> num_layers
        self<span class="token punctuation">.</span>lstm <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">LSTM</span><span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> 
                            batch_first<span class="token operator">=</span>True<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span><span class="token function">Linear</span><span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>  # <span class="token number">2</span> <span class="token keyword">for</span> bidirection 

    def <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token operator">:</span>

        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Forward propagate RNN</span></span>
        out<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">lstm</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token macro property"><span class="token directive-hash">#</span> <span class="token expression">Decode hidden state of last time step</span></span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span><span class="token function">fc</span><span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token operator">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token operator">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> out

rnn <span class="token operator">=</span> <span class="token function">RNN</span><span class="token punctuation">(</span>input_size<span class="token punctuation">,</span> hidden_size<span class="token punctuation">,</span> num_layers<span class="token punctuation">,</span> num_classes<span class="token punctuation">)</span>
rnn<span class="token punctuation">.</span><span class="token function">cuda</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>class torch.nn.LSTM( args, * kwargs)[source]<br> 将一个多层的 (LSTM) 应用到输入序列。</p> 
<p>参数说明:</p> 
<ul><li>input_size – 输入的特征维度</li><li>hidden_size – 隐状态的特征维度</li><li>num_layers – 层数（和时序展开要区分开）</li><li>bias – 如果为False，那么LSTM将不会使用<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
          
          
            i 
           
          
            h 
           
          
         
        
          , 
         
         
         
           b 
          
          
          
            h 
           
          
            h 
           
          
         
        
       
         b_{ih},b_{hh} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ih</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hh</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>，默认为True。</li><li>batch_first – 如果为True，那么输入和输出Tensor的形状为(batch, seq, feature)</li><li>dropout – 如果非零的话，将会在RNN的输出上加个dropout，最后一层除外。</li><li>bidirectional – 如果为True，将会变成一个双向RNN，默认为False。</li></ul> 
<p>LSTM输入: input, (h_0, c_0)</p> 
<ul><li>input (seq_len, batch, input_size): 包含输入序列特征的Tensor。也可以是packed<br> variable ，详见<br> [pack_padded_sequence](#torch.nn.utils.rnn.pack_padded_sequence(input,<br> lengths, batch_first=False[source])</li><li>h_0 (num_layers * num_directions, batch,<br> hidden_size):保存着batch中每个元素的初始化隐状态的Tensor</li><li>c_0 (num_layers * num_directions, batch, hidden_size):<br> 保存着batch中每个元素的初始化细胞状态的Tensor</li></ul> 
<p>LSTM输出 output, (h_n, c_n)</p> 
<ul><li>output (seq_len, batch, hidden_size * num_directions):<br> 保存RNN最后一层的输出的Tensor。<br> 如果输入是torch.nn.utils.rnn.PackedSequence，那么输出也是torch.nn.utils.rnn.PackedSequence。</li><li>h_n (num_layers * num_directions, batch, hidden_size):<br> Tensor，保存着RNN最后一个时间步的隐状态。</li><li>c_n (num_layers * num_directions, batch, hidden_size):<br> Tensor，保存着RNN最后一个时间步的细胞状态。</li></ul> 
<p>LSTM模型参数:</p> 
<ul><li>weight_ih_l[k] – 第k层可学习的input-hidden权重(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           W 
          
          
          
            i 
           
          
            i 
           
          
         
        
          ∣ 
         
         
         
           W 
          
          
          
            i 
           
          
            f 
           
          
         
        
          ∣ 
         
         
         
           W 
          
          
          
            i 
           
          
            g 
           
          
         
        
          ∣ 
         
         
         
           W 
          
          
          
            i 
           
          
            o 
           
          
         
        
       
         W_{ii}|W_{if}|W_{ig}|W_{io} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ii</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)，形状为(input_size x4*hidden_size)</li><li>weight_hh_l[k] –第k层可学习的hidden-hidden权重(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           W 
          
          
          
            h 
           
          
            i 
           
          
         
        
          ∣ 
         
         
         
           W 
          
          
          
            h 
           
          
            f 
           
          
         
        
          ∣ 
         
         
         
           W 
          
          
          
            h 
           
          
            g 
           
          
         
        
          ∣ 
         
         
         
           W 
          
          
          
            h 
           
          
            o 
           
          
         
        
       
         W_{hi}|W_{hf}|W_{hg}|W_{ho} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hi</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.1389em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: -0.1389em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)，形状为(hidden_size x 4*hidden_size)。</li><li>bias_ih_l[k] – 第k层可学习的input-hidden偏置(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
          
          
            i 
           
          
            i 
           
          
         
        
          ∣ 
         
         
         
           b 
          
          
          
            i 
           
          
            f 
           
          
         
        
          ∣ 
         
         
         
           b 
          
          
          
            i 
           
          
            g 
           
          
         
        
          ∣ 
         
         
         
           b 
          
          
          
            i 
           
          
            o 
           
          
         
        
       
         b_{ii}|b_{if}|b_{ig}|b_{io} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ii</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)，形状为(4*hidden_size)</li><li>bias_hh_l[k] –第k层可学习的hidden-hidden偏置(<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           b 
          
          
          
            h 
           
          
            i 
           
          
         
        
          ∣ 
         
         
         
           b 
          
          
          
            h 
           
          
            f 
           
          
         
        
          ∣ 
         
         
         
           b 
          
          
          
            h 
           
          
            g 
           
          
         
        
          ∣ 
         
         
         
           b 
          
          
          
            h 
           
          
            o 
           
          
         
        
       
         b_{hi}|b_{hf}|b_{hg}|b_{ho} 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.0361em; vertical-align: -0.2861em;"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">hi</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right: 0.1076em;">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight" style="margin-right: 0.0359em;">g</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2861em;"><span class=""></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3361em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mord mathnormal mtight">o</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span>)，形状为( 4*hidden_size)。 示例:</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4bb19882dce6c6ffed7cde957868e84b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python编写小游戏详细教程,用python做简单的小游戏</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bdb3abe68fa3223e91d8b9108e1d529e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java代码hello word</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>