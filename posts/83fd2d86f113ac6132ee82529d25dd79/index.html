<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Faster RCNN详解（个人理解） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Faster RCNN详解（个人理解）" />
<meta property="og:description" content="1. Faster RCNN的四个主要内容 图1 Faster-RCNN基本结构
如上图所示，整个Faster RCNN模型可以分为四个模块：
1） Conv layers，特征提取网络 输入为一张图片，输出为一张图片的特征，即feature map。通过一组conv&#43;relu&#43;pooling层提取图像的feature map，用于后续的RPN网络和全连接层。
2） Region proposal Network，区域候选网络 输入为第一步中的feature map，输出为多个兴趣区域（ROI）。输出的每个兴趣区域具体表示为一个概率值（用于判断anchor是前景还是背景）和四个坐标值，概率值表示该兴趣区域有物体的概率，这个概率是通过softmax对每个区域进行二分类得到的；坐标值是预测的物体的位置，在进行训练时会用这个坐标与真实的坐标进行回归使在测试时预测的物体位置更加准确。
3） ROI pooling，兴趣域池化 这一层以RPN网络输出的兴趣区域和Conv layers输出的feature map为输入，将两者进行综合后得到固定大小的区域特征图（proposal feature map）并输出到后面的全连接网络中进行分类。
4） Classification and Regression，分类和回归 输入为上一层得到proposal feature map，输出为兴趣区域中物体所属的类别以及物体在图像中精确的位置。这一层通过softmax对图像进行分类，并通过边框回归修正物体的精确位置。
2. Faster RCNN四个模块详解 如下图所示，这是Faster R-CNN模型的具体网络结构
图2 Faster RCNN网络结构
2.1 Conv layers 图3 Conv layers网络结构
这部分的作用是提取输入图像的特征得到特征图。Conv layers中共包含了conv、pooling、relu三种层。本项目中是采用python中的VGG16模型作为特征提取网络。如上面的网络结构图所示，Conv layers部分共包含了13个conv层，13个relu层，4个pooling层。并且：
1）所有的conv层都是：kernel_size=3，pad=1，stride=1
2）所有的pooling层都是：kernel_size=2，pad=0，stride=2
因此一个MxN大小的图像经过Conv layers固定变为(M/16)x(N/16)，这样Conv layers生成的feature maps都可以和原图对应起来。
2.2 Region proposal Network 这一部分的作用是生成较好的建议框（Proposal），RPN包含五个子模块：
2.2.1 Anchor生成
RPN对输入的feature map上每一个点都生成了9个anchor（3种尺度(128, 256, 512)和3种宽高比(1:2, 1:1, 2:1)），这些不同大小、宽高的anchor对应到原图可以覆盖所有可能出现的物体。因此共生成了(M/16)x(N/16)x9个anchor。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/83fd2d86f113ac6132ee82529d25dd79/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-17T17:30:26+08:00" />
<meta property="article:modified_time" content="2023-04-17T17:30:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Faster RCNN详解（个人理解）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3><strong>1. </strong>Faster RCNN的四个主要内容</h3> 
<p class="img-center"><img alt="" height="280" src="https://images2.imgbox.com/d8/d3/m0VwJh61_o.png" width="330"></p> 
<p style="text-align:center;"> 图1  Faster-RCNN基本结构</p> 
<p style="margin-left:0;text-align:left;">        如上图所示，整个Faster RCNN模型可以分为四个模块：</p> 
<h4 style="text-align:left;"><strong>1） Conv layers</strong><strong>，特征提取网络</strong></h4> 
<p style="margin-left:0;text-align:left;">        输入为一张图片，输出为一张图片的特征，即feature map。通过一组conv+relu+pooling层提取图像的feature map，用于后续的RPN网络和全连接层。</p> 
<h4 style="text-align:left;"><strong>2） Region proposal Network</strong><strong>，区域候选网络</strong></h4> 
<p style="margin-left:0;text-align:left;">        输入为第一步中的feature map，输出为多个兴趣区域（ROI）。输出的每个兴趣区域具体表示为一个概率值（用于判断anchor是前景还是背景）和四个坐标值，概率值表示该兴趣区域有物体的概率，这个概率是通过softmax对每个区域进行二分类得到的；坐标值是预测的物体的位置，在进行训练时会用这个坐标与真实的坐标进行回归使在测试时预测的物体位置更加准确。</p> 
<h4 style="text-align:left;"><strong>3） ROI pooling</strong><strong>，兴趣域池化</strong></h4> 
<p style="margin-left:0;text-align:left;">        这一层以RPN网络输出的兴趣区域和Conv layers输出的feature map为输入，将两者进行综合后得到固定大小的区域特征图（proposal feature map）并输出到后面的全连接网络中进行分类。</p> 
<h4 style="margin-left:0px;text-align:left;"><strong>4） Classification and Regression，分类和回归</strong></h4> 
<p style="margin-left:0;text-align:left;">        输入为上一层得到proposal feature map，输出为兴趣区域中物体所属的类别以及物体在图像中精确的位置。这一层通过softmax对图像进行分类，并通过边框回归修正物体的精确位置。</p> 
<h3 style="margin-left:0px;text-align:left;">2. Faster RCNN四个模块详解</h3> 
<p>        如下图所示，这是Faster R-CNN模型的具体网络结构</p> 
<p class="img-center"><img alt="" height="243" src="https://images2.imgbox.com/20/e4/g2bMmFKD_o.png" width="478"></p> 
<p style="margin-left:0;text-align:center;">图2  Faster RCNN网络结构</p> 
<h4>2.1  Conv layers</h4> 
<p></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="81" src="https://images2.imgbox.com/85/5e/4sgVTLc8_o.png" width="400"></p> 
<p style="margin-left:0;text-align:center;">图3  Conv layers网络结构</p> 
<p style="margin-left:0;text-align:justify;">        这部分的作用是提取输入图像的特征得到特征图。Conv layers中共包含了conv、pooling、relu三种层。本项目中是采用python中的VGG16模型作为特征提取网络。如上面的网络结构图所示，Conv layers部分共包含了13个conv层，13个relu层，4个pooling层。并且：</p> 
<p style="text-align:justify;">    1）所有的conv层都是：kernel_size=3，pad=1，stride=1</p> 
<p style="text-align:justify;">    2）所有的pooling层都是：kernel_size=2，pad=0，stride=2</p> 
<p>        因此一个MxN大小的图像经过Conv layers固定变为(M/16)x(N/16)，这样Conv layers生成的feature maps都可以和原图对应起来。</p> 
<h4> 2.2 Region proposal Network</h4> 
<p style="margin-left:0;text-align:left;"> 这一部分的作用是生成较好的建议框（Proposal），RPN包含五个子模块：</p> 
<p style="margin-left:0;text-align:left;"><strong>2.2.1 Anchor生成</strong></p> 
<p style="margin-left:0;text-align:left;">        RPN对输入的feature map上每一个点都生成了9个anchor（3种尺度(128, 256, 512)和3种宽高比(1:2, 1:1, 2:1)），这些不同大小、宽高的anchor对应到原图可以覆盖所有可能出现的物体。因此共生成了(M/16)x(N/16)x9个anchor。</p> 
<p style="text-align:left;"><strong>2.2.2 RPN</strong><strong>卷积网络</strong></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="143" src="https://images2.imgbox.com/55/15/5CspXiQr_o.png" width="496"></p> 
<p style="margin-left:0;text-align:center;">图4  RPN网络结构</p> 
<p style="margin-left:0;text-align:justify;">        有物体的位置通常称为前景，没有物体的位置通常称为背景。为了实现对anchor前景和背景的预测以及anchor与真实边框偏移值的预测，搭建了如上图所示的网络结构。在feature map上首先用3x3卷积进行更深的特征提取，然后利用1x1卷积分别实现分类和回归。</p> 
<p style="margin-left:0;text-align:justify;">        如上图第一条分支，这是分类分支。首先使用1x1卷积输出(M/16)x(N/16)x18的特征，这里通道数为18是因为feature map中每个点有9个anchor并且每个anchor只预测其是前景还是背景。因为我们后面需要使用softmax函数计算每个anchor属于前景和背景的概率，所以需要先将(M/16)x(N/16)x18 维度变换为 (3xM/16)x(3xN/16)x2，将第三维变换为仅仅是前景背景的得分。得到概率后再将维度变换回来，然后输出每个anchor属于前景与背景的概率。</p> 
<p style="margin-left:0;text-align:justify;">        图中第二条分支是回归分支。这个分支中，利用1x1卷积输出(M/16)x(N/16)x36的特征，这个36包含每个点上9个anchor的偏移值预测，每个anchor的偏移值有四个数据，分别是中心点的横纵坐标以及宽高。这四个数据都是相对于真值的偏移量。</p> 
<p style="text-align:left;"><strong>2.2.3 计算</strong><strong>RPN loss</strong></p> 
<p style="margin-left:0;text-align:left;">        这一步只在训练中，将第一步中生成的所有anchor与标签进行匹配，匹配程度较好的赋予正样本，较差的赋予负样本，然后得到anchor的分类与位置偏移的真值，与第二步中的预测得分与预测偏移值进行loss的计算。</p> 
<p style="margin-left:0;text-align:left;">        具体地说，上一步中得到的只是预测值，为了计算预测的损失，我们还需要得到分类与偏移的真值，即每一个anchor是否对应着真实物体以及每一个anchor对应真实物体的偏移值。具体流程如下：</p> 
<blockquote> 
 <ul><li style="text-align:left;">anchor生成。这个与1）中的过程相同，共生成(M/16)x(N/16)x9个anchor。因为这种方式会产生一些边界在图像外的边框，所以还需要把这部分超过图像边框的anchor去掉。</li><li style="text-align:left;">anchor与标签匹配。为了计算anchor的损失，我们需要知道每个anchor的真实类别，因为RPN只负责建议框的生成而不负责具体类别，所以这个真实类别指的是是否包含物体。我们通过计算每一个anchor与每一个标签的IOU来判断是正样本还是负样本，具体规则如下：</li></ul> 
 <p style="text-align:left;">                1）对于任何一个anchor，与所有标签的最大IOU小于0.3，则视为负样本。</p> 
 <p style="text-align:left;">                2）对于任何一个标签，与其有最大IOU的anchor视为正样本。</p> 
 <p style="text-align:left;">                3）对于任何一个anchor，与所有标签的最大IOU大于0.7，视为正样本。</p> 
 <ul><li style="text-align:left;">anchor筛选。因为生成的anchor太多，并且包含背景的anchor较多，如果都计算损失就会使正负样本失衡从而不利于网络收敛。所以RPN默认选择256个anchor进行损失计算，其中包含128个正样本和128个负样本。</li><li style="text-align:left;">求解回归偏移真值。上一步赋予的正负样本代表了预测的类别的真值，接下来我们还需要计算预测的偏移值的真值。这个要利用anchor与对应的标签求解得到。具体计算方法如下公式：</li></ul> 
 <p style="margin-left:0;text-align:center;"><img alt="" height="153" src="https://images2.imgbox.com/fd/4c/CkMnQ77V_o.png" width="395"></p> 
 <p style="margin-left:0;text-align:center;">图5  偏移值计算公式</p> 
</blockquote> 
<p style="text-align:left;"><strong>2.2.4 生成</strong><strong>Proposal</strong></p> 
<p style="margin-left:0;text-align:center;"><img alt="" height="107" src="https://images2.imgbox.com/32/a2/GymN0PHg_o.png" width="528"></p> 
<p style="margin-left:0;text-align:center;">图6  proposal生成流程</p> 
<p style="margin-left:0;text-align:left;">        Proposal的生成过程如上流程图所示，首先生成全部的anchor，然后利用3）中得到的回归偏移值对这些anchor做回归使anchor更加贴近于真值，并且修剪掉超出图像尺寸的proposal得到最初的proposal；接着按照RPN网络中softmax计算得到的概率对所有的anchor进行排序，提取前12000个概率高的anchor；由于一个物体可能会有多个anchor重叠对应，所以应用非极大值抑制（NMS）将重叠的框去掉；最后在剩余的proposal中再次根据RPN的预测得分选择前2000个作为最终的proposal输出到下一个阶段。</p> 
<p style="text-align:left;"><strong>2.2.5 筛选</strong><strong>Proposal</strong><strong>得到</strong><strong>ROI</strong></p> 
<p style="margin-left:0;text-align:left;">        上一步生成的proposal数量为2000个，其中仍有很多的背景框，因此需要针对proposal进行进一步的筛选，过程与上面的一个筛选过程相同，也是通过利用标签与proposal构建IOU矩阵，通过与标签的重合成都选出256个正负样本。</p> 
<h4 style="margin-left:0px;text-align:left;">2.3 ROI pooling</h4> 
<p style="margin-left:0;text-align:justify;">        由于下一模块的全连接网络要求特征的维度固定，而RPN输出的ROI各自的特征大小又不相同，因此需要先将这些ROI的特征池化到固定的维度然后再输入到全连接网络中。ROI pooling的具体原理如下:</p> 
<p style="text-align:justify;">        1) 由于RPN输出的ROI是对应MxN尺度的，所以首先将其映射回(M/16)x(N/16)大小的feature map尺度(坐标除以下采样率即可)；</p> 
<p style="text-align:justify;">        2) 再将每个ROI对应的feature map区域水平分为的网格；</p> 
<p style="text-align:justify;">        3) 对网格的每一份都进行max pooling处理。</p> 
<p></p> 
<p class="img-center"><img alt="" height="245" src="https://images2.imgbox.com/dd/3e/RU6MqyAA_o.png" width="371"></p> 
<p style="text-align:center;"> 图7  ROI pooling原理</p> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:justify;">这样处理后，即使大小不同的ROI，输出结果都是固定大小，实现了固定长度输出</p> 
<h4 style="margin-left:0px;text-align:justify;">2.4 classification and regression</h4> 
<p></p> 
<p class="img-center"><img alt="" height="160" src="https://images2.imgbox.com/8b/56/OFo0IsOR_o.png" width="206"></p> 
<p style="margin-left:0;text-align:center;"></p> 
<p style="margin-left:0;text-align:center;">图8  全连接网络</p> 
<p>        这一部分利用已经获得的proposal feature maps，通过全连接层与softmax计算每个proposal具体属于那个类别（如车、盒子、塑料瓶等），输出cls_prob概率向量；同时再次利用bounding box regression获得每个proposal的位置更加精确的偏移量bbox_pred，用于回归更加精确的目标检测框。网络结构如上图所示。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a631bd0e71cd3650eaf95e736da628bd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">零基础小白怎么入门网络安全（黑客）？看这篇就够啦</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/bbdcb7792512d185ae1002f82eb069c8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">try-catch处理异常</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>