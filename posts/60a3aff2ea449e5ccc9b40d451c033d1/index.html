<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>瑞芯微rk3588部署yolov5模型实战 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="瑞芯微rk3588部署yolov5模型实战" />
<meta property="og:description" content="瑞芯微rk3588部署yolov5模型实战 模型转换通过pt模型转换为onnx模型通过onnx模型转换为rknn模型 模型部署编译推送执行文件到板子运行(单图测试)多图测试 模型转换 ​使用此yolov5 仓库获取yolov5代码以及模型
通过pt模型转换为onnx模型 python export.py --rknpu rk3588 --weight yolov5s.pt ​rk_platform 支持 rk1808、rv1109、rv1126、rk3399pro、rk3566、rk3562、rk3568、rk3588、rv1103、rv1106。（实际上，无论平台如何，导出的模型都是相同的）
​’yolov5s.pt’ 可以替换为您的模型路径
​将生成一个文件名“RK_anchors.txt”，可以在外部执行 post_process 时使用它。
​注意：请使用–rknpu参数调用，不要更改export.py中的默认rknpu值。​
通过onnx模型转换为rknn模型 ​使用此模型转换库
打开yolo_ppyolo.yml文件
#support yolo[v5,v6,v7,v8], ppyoloe_plus model_framework: onnx model_file_path: best_3588B.onnx RK_device_platform: RK3588 dataset: coco_dataset_20.txt quantize: True pre_compile: online graph: in_0: shape: 3,640,640 mean_values: 0 std_values: 255 img_type: RGB configs: quantized_dtype: asymmetric_quantized-8 quantized_algorithm: normal optimization_level: 3 ​根据模型修改 yml 配置文件参数
必填项
​model_framework 参数，指定模型来源框架，如 onnx / pytorch.
​model_file_path 参数，指定模型路径
​RK_device_platform 参数，指定RKNN平台" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/60a3aff2ea449e5ccc9b40d451c033d1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-17T17:01:39+08:00" />
<meta property="article:modified_time" content="2023-11-17T17:01:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">瑞芯微rk3588部署yolov5模型实战</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>瑞芯微rk3588部署yolov5模型实战</h4> 
 <ul><li><a href="#_1" rel="nofollow">模型转换</a></li><li><ul><li><a href="#ptonnx_3" rel="nofollow">通过pt模型转换为onnx模型</a></li><li><a href="#onnxrknn_12" rel="nofollow">通过onnx模型转换为rknn模型</a></li></ul> 
  </li><li><a href="#_99" rel="nofollow">模型部署</a></li><li><ul><li><a href="#_102" rel="nofollow">编译</a></li><li><a href="#_114" rel="nofollow">推送执行文件到板子</a></li><li><a href="#_119" rel="nofollow">运行(单图测试)</a></li><li><a href="#_130" rel="nofollow">多图测试</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>模型转换</h2> 
<p>  ​使用此<a href="https://github.com/airockchip/yolov5">yolov5</a> 仓库获取yolov5代码以及模型</p> 
<h3><a id="ptonnx_3"></a>通过pt模型转换为onnx模型</h3> 
<pre><code>python export.py --rknpu rk3588 --weight yolov5s.pt
</code></pre> 
<p>  ​rk_platform 支持 rk1808、rv1109、rv1126、rk3399pro、rk3566、rk3562、rk3568、rk3588、rv1103、rv1106。（实际上，无论平台如何，导出的模型都是相同的）<br>   ​’yolov5s.pt’ 可以替换为您的模型路径<br>   ​将生成一个文件名“RK_anchors.txt”，可以在外部执行 post_process 时使用它。<br>   ​注意：请使用–rknpu参数调用，不要更改export.py中的默认rknpu值。​<br> <img src="https://images2.imgbox.com/66/60/nktH0SUw_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="onnxrknn_12"></a>通过onnx模型转换为rknn模型</h3> 
<p>  ​使用此<a href="https://github.com/airockchip/rknn_model_zoo/tree/main/models/CV/object_detection/yolo/RKNN_model_convert">模型转换库</a><br> 打开yolo_ppyolo.yml文件</p> 
<pre><code>#support yolo[v5,v6,v7,v8], ppyoloe_plus
model_framework: onnx
model_file_path: best_3588B.onnx
RK_device_platform: RK3588

dataset: coco_dataset_20.txt
quantize: True
pre_compile: online

graph:
  in_0:
    shape: 3,640,640
    mean_values: 0
    std_values: 255
    img_type: RGB

configs:
  quantized_dtype: asymmetric_quantized-8
  quantized_algorithm: normal
  optimization_level: 3
</code></pre> 
<p>​根据模型修改 yml 配置文件参数<br> <img src="https://images2.imgbox.com/94/b9/oqYiyCHw_o.png" alt="在这里插入图片描述"></p> 
<p>必填项<br>   ​model_framework 参数，指定模型来源框架，如 onnx / pytorch.<br>   ​model_file_path 参数，指定模型路径<br>   ​RK_device_platform 参数，指定RKNN平台<br> 执行参数说明</p> 
<table><thead><tr><th>参数名</th><th>作用</th></tr></thead><tbody><tr><td>–yml_path(必填)</td><td>指定yml配置文件路径</td></tr><tr><td>–eval_perf</td><td>评估性能(基于rknn.eval_perf)</td></tr><tr><td>–eval_memory</td><td>评估内存(基于rknn.eval_memory)</td></tr><tr><td>–python_api_test</td><td>测试 rknn-toolkit.run 与 framework.run 结果的余弦值</td></tr><tr><td>–capi_test</td><td>设定 CPU/DDR/NPU 频率，测试 capi 与 framework.run结果余弦值，记录 input_set, run, output_get 耗时</td></tr><tr><td>–capi_zero_copy_test</td><td>设定 CPU/DDR/NPU 频率，测试 capi 与 framework.run结果余弦值，记录耗时（目前可能有bug）</td></tr><tr><td>–report</td><td>生成报告</td></tr></tbody></table> 
<p>可选项<br>   ​默认使用量化。请注意先准备好COCO测试数据集（下载可参考工程目录下datasets内容）。如不使用量化功能，请将 quantize 参数设为 False<br>   ​默认不启用预编译功能。如需启用请将 pre_compile 参数设为 online，并通过usb口连接npu设备（此功能仅在 RKNN-Toolkit1 上有效，usb口需要能adb连上npu设备，RKNN-Toolkit2 没有此配置）<br>   ​如需使用模拟器，请将 RK_device_id 设为 simulator<br>   ​如果是自己训练的模型及数据，请将 dataset 路径指定到对应的训练/测试数据上，model_file_path指定到对应的pt模型路径，模型输入尺寸由 3,640,640 改为 3,h,w，如 3,736,1280<br>   ​测试 coco benchmark 时，建议使用 200 - 500 张图片进行量化。</p> 
<table><thead><tr><th>参数名</th><th>填写内容</th></tr></thead><tbody><tr><td>model_name(选填)</td><td>导出 rknn 模型的名称</td></tr><tr><td>model_platform(必填)</td><td>原模型的框架名（如caffe, darknet, keras, mxnet, onnx, pytorch, tensorflow, tflite）</td></tr><tr><td>model_file_path(必填)</td><td>原模型路径（可填相对路径）</td></tr><tr><td>RK_device_platform(必填)</td><td>目标npu设备平台，可填 [rk3399pro/rk1808/rv1109/rv1126/rk3566/rk3568/rk3588]</td></tr><tr><td>RK_device_id</td><td>npu设备id(可以通过abd devices获取)，仅连接单个npu设备的时候可不填，默认为None</td></tr><tr><td>dataset</td><td>量化数据集，具体填写格式参考demo或user_guide手册。</td></tr><tr><td>quantize</td><td>是否量化，填 [True/False]</td></tr><tr><td>pre_compile</td><td>预编译模型，填写 [off\online] <br>（仅RKNN_toolkit1生效）</td></tr><tr><td></td><td></td></tr><tr><td>graph</td><td></td></tr><tr><td>- in_0(必填)</td><td>对于多输入的，请依次命名为 in_0,in_1,…,in_n</td></tr><tr><td>- name(tensorflow模型必填)</td><td>输入节点名</td></tr><tr><td>- shape(必填)</td><td>输入的尺寸，nchw/nhwc的格式取决于原框架的形式，如pytorch模型的 3,224,224</td></tr><tr><td>- mean_values</td><td>输入的均值归一数，如 123.675,116.28,103.53。对于各通道归一化数字相等的，允许填写单值，如 0,0,0 =&gt; 0</td></tr><tr><td>- std_values</td><td>输入的方差归一数，如 58.395,58.295,58.391。对于各通道归一化数字相等的，允许填写单值，如 255,255,255 =&gt; 255</td></tr><tr><td>- img_type</td><td>根据原模型输入类型，填写 RGB 或者 BGR，如果是非图片的数据，请勿填写</td></tr><tr><td>- out_0(tensorflow模型必填)</td><td>对于多输出的，请依次命名为 out_0,out_1,…,out_n</td></tr><tr><td>- name(tensorflow模型必填)</td><td>输出节点名</td></tr><tr><td></td><td></td></tr><tr><td>config</td><td>对应 rknn.config 的参数配置</td></tr><tr><td>- quantized_dtype</td><td>量化类型<br>RKNN_toolkit1: 可填写 [asymmetric_affine-u8, dynamic_fixed_point-i8, dynamic_fixed_point-i16]<br>RKNN_toolkit2: 可填写 [asymmetric_quantized-8]</td></tr><tr><td>- quantized_algorithm</td><td>量化方法：可选[‘normal’, ‘mmse’]，默认为 normal</td></tr><tr><td>- optimization_level</td><td>优化等级，默认为3</td></tr><tr><td>- mmse_epoch</td><td>mmse迭代次数，默认为3<br>（仅RKNN_toolkit1生效）</td></tr><tr><td>- do_sparse_network</td><td>使用稀疏化优化量化模型，默认为True，如果量化模型掉精度，可考虑设为 False<br>（仅RKNN_toolkit1生效）</td></tr><tr><td>- quantize_input_node</td><td>单独量化输入节点<br>（仅RKNN_toolkit1生效）</td></tr><tr><td>- merge_dequant_layer_and_output_node</td><td>合并输出节点与反量化层<br>（仅RKNN_toolkit1生效）</td></tr><tr><td>- force_builtin_perm</td><td>为输入添加transpose layer使 nhwc -&gt; nchw<br>（仅RKNN_toolkit1生效）</td></tr></tbody></table> 
<p>使用以下语句转换</p> 
<pre><code>./convert_yolo_ppyolo.sh
</code></pre> 
<p><img src="https://images2.imgbox.com/a4/57/DUdhSVuA_o.png" alt="请添加图片描述"><br> 出现Exprot RKNN model即为转换成功</p> 
<h2><a id="_99"></a>模型部署</h2> 
<p>使用<a href="https://github.com/airockchip/rknn_model_zoo/tree/main/models/CV/object_detection/yolo/RKNN_C_demo/RKNN_toolkit_2/rknn_yolo_demo">rknn部署库</a>进行部署<br> 以linux平台为例</p> 
<h3><a id="_102"></a>编译</h3> 
<p>根据指定平台修改 <code>build-linux_&lt;TARGET_PLATFORM&gt;.sh</code>中的交叉编译器所在目录的路径 <code>TOOL_CHAIN</code>，例如修改成</p> 
<pre><code class="prism language-sh"><span class="token builtin class-name">export</span> <span class="token assign-left variable">TOOL_CHAIN</span><span class="token operator">=~</span>/opt/tool_chain/gcc-9.3.0-x86_64_aarch64-linux-gnu/host
</code></pre> 
<p>然后执行：</p> 
<pre><code class="prism language-sh">./build-linux_<span class="token operator">&lt;</span>TARGET_PLATFORM<span class="token operator">&gt;</span>.sh
</code></pre> 
<h3><a id="_114"></a>推送执行文件到板子</h3> 
<p>将 install/rknn_yolo_demo_Linux 拷贝到板子的/data/目录.</p> 
<pre><code>adb push install/rknn_yolo_demo_Linux /data/
</code></pre> 
<h3><a id="_119"></a>运行(单图测试)</h3> 
<pre><code class="prism language-sh">adb shell
<span class="token builtin class-name">cd</span> /data/rknn_yolo_demo_Linux/

<span class="token builtin class-name">export</span> <span class="token assign-left variable">LD_LIBRARY_PATH</span><span class="token operator">=</span>./lib

./rknn_yolo_demo yolov5 q8 single_img ./yolov5s_u8.rknn ./model/RK_anchors_yolov5.txt ./model/dog.jpg 
</code></pre> 
<h3><a id="_130"></a>多图测试</h3> 
<pre><code>cd $(pwd | sed 's/\(rknn_model_zoo\).*/\1/g')
adb push rknn_model_zoo/datasets/COCO/val2017 /userdata/

adb shell
cd /userdata/rknn_yolo_demo/
./rknn_yolo_demo yolov5 q8 multi_imgs ./yolov5s_u8.rknn ./model/RK_anchors_yolov5.txt ./model/coco_dataset_path.txt
</code></pre> 
<p>群内交流更多技术<br> 130856474</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a40cc2920a50d94ba29f02953843b602/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Gradio构建AI算法网页界面显示教程（附实战代码）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6732d4d40fe3213af52eb6ac676a8803/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SSH使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>