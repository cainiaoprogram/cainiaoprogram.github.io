<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Focal and Global Knowledge Distillation for Detectors(CVPR2022) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Focal and Global Knowledge Distillation for Detectors(CVPR2022)" />
<meta property="og:description" content="Focal and Global Knowledge Distillation for Detectors(CVPR2022) 目标检测中的全局与局部的知识蒸馏
原文链接:https://arxiv.org/abs/2111.11837
代码github:github.com/yzd-v/FGD
文章目录 **Focal and Global Knowledge Distillation for Detectors**(CVPR2022)前要知识：KD(Knowlege Distillation)目标检测(Object Detection) 主要的贡献和方法：Global DistillationFocal Distillation 前要知识： KD(Knowlege Distillation) 目前最流行的模型压缩技术之一，能够满足大模型轻量化部署的要求，并且将大模型的训练效果同步到小模型中，类似于迁移学习，又与迁移学习的迁移内容和流程都不同。数据蒸馏的目前主流的两个方向:模型压缩和模型增强。下图是Hinton知识蒸馏论文中提出的经典教师-学生模型。这里原理不做赘述，可以参考论文原文Distilling the Knowledge in a Neural Network
目前的知识蒸馏集中在Feature-based Distillation,大致意思是将教师模型中的某一层的特征信息提取出来去训练学生模型，那么蒸馏的层怎么进行选取，并且提取出的迁移信息怎么处理都是知识蒸馏目前发展的痛点。
目标检测(Object Detection) 目标检测作为CV最重要的下游任务之一，就将分类和定位集为一体的CV技术，目标检测的模型分为one-stage,two-stage,one stage anchor-based,one stage anchor-free。典型的模型YOLO,FasterRcnn,MaskRcnn等等。特别地，现在很多的目标检测模型都会发布多个参数量的版本号，Large模型自然能识别出更好的效果，但自然而然也带来了硬件上的成本开销和部署的困难，所以目标检测领域也需要将模型压缩放在应用部署的首要位置考虑，因为往往深度学习特别是CV领域，训练和预测是分两步走的，所以训练和预测的硬件差异让更多地轻量化需求得以体现。虽然目标检测的模型的预测头部和模型结构不都相同，但是input都是特征图，每个层进行处理的也是特征图的信息进行输入，所以可以形成一个统一的基于特征的蒸馏方法来实现模型压缩
主要的贡献和方法： ​ 就像题目所说的那样，作者提出了两种不同的蒸馏方式，作者认为在目标检测领域，全局的特征联系关联特征和局部的细节特征感知信息一样重要，所以不仅要关注前景图也要关注背景图。
Global Distillation ​ 借鉴了GCnet中的GCBlock模块来获取全局的上下文关联信息，将教师模型中学习到的关联信息传递给学生模型进行学习
​ transform模块代码：
##transform模块(学生和教师) ##①1x1conv，通道数/2 ②LN&#43;Relu ③1*1conv，通道数还原 self.channel_add_conv_s = nn.Sequential( nn.Conv2d(teacher_channels, teacher_channels//2, kernel_size=1), nn.LayerNorm([teacher_channels//2, 1, 1]), nn.ReLU(inplace=True), # yapf: disable nn.Conv2d(teacher_channels//2, teacher_channels, kernel_size=1)) self." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f9b163883370bc95bbf54f12d2e648be/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-28T10:07:39+08:00" />
<meta property="article:modified_time" content="2023-03-28T10:07:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Focal and Global Knowledge Distillation for Detectors(CVPR2022)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Focal_and_Global_Knowledge_Distillation_for_DetectorsCVPR2022_0"></a><strong>Focal and Global Knowledge Distillation for Detectors</strong>(CVPR2022)</h2> 
<p>目标检测中的全局与局部的知识蒸馏</p> 
<blockquote> 
 <p>原文链接:https://arxiv.org/abs/2111.11837</p> 
 <p>代码github:<a href="https://link.zhihu.com/?target=http%3A//github.com/yzd-v/FGD" rel="nofollow">github.com/yzd-v/FGD</a></p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Focal_and_Global_Knowledge_Distillation_for_DetectorsCVPR2022_0" rel="nofollow">**Focal and Global Knowledge Distillation for Detectors**(CVPR2022)</a></li><li><ul><li><a href="#_9" rel="nofollow">前要知识：</a></li><li><ul><li><a href="#KDKnowlege_Distillation_11" rel="nofollow">KD(Knowlege Distillation)</a></li><li><a href="#Object_Detection_20" rel="nofollow">目标检测(Object Detection)</a></li></ul> 
   </li><li><a href="#_26" rel="nofollow">主要的贡献和方法：</a></li><li><ul><li><a href="#Global_Distillation_32" rel="nofollow">Global Distillation</a></li><li><a href="#Focal_Distillation_121" rel="nofollow">Focal Distillation</a></li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_9"></a>前要知识：</h3> 
<h4><a id="KDKnowlege_Distillation_11"></a>KD(Knowlege Distillation)</h4> 
<p>目前最流行的模型压缩技术之一，能够满足大模型轻量化部署的要求，并且将大模型的训练效果同步到小模型中，类似于迁移学习，又与迁移学习的迁移内容和流程都不同。数据蒸馏的目前主流的两个方向:模型压缩和模型增强。下图是Hinton知识蒸馏论文中提出的经典教师-学生模型。这里原理不做赘述，可以参考论文原文<a href="https://arxiv.org/abs/1503.02531" rel="nofollow">Distilling the Knowledge in a Neural Network</a></p> 
<p><img src="https://images2.imgbox.com/00/37/reja0Aeb_o.png" alt="在这里插入图片描述"></p> 
<p>目前的知识蒸馏集中在Feature-based Distillation,大致意思是将教师模型中的某一层的特征信息提取出来去训练学生模型，那么蒸馏的层怎么进行选取，并且提取出的迁移信息怎么处理都是知识蒸馏目前发展的痛点。</p> 
<h4><a id="Object_Detection_20"></a>目标检测(Object Detection)</h4> 
<p>目标检测作为CV最重要的下游任务之一，就将分类和定位集为一体的CV技术，目标检测的模型分为one-stage,two-stage,one stage anchor-based,one stage anchor-free。典型的模型YOLO,FasterRcnn,MaskRcnn等等。特别地，现在很多的目标检测模型都会发布多个参数量的版本号，Large模型自然能识别出更好的效果，但自然而然也带来了硬件上的成本开销和部署的困难，所以目标检测领域也需要将模型压缩放在应用部署的首要位置考虑，因为往往深度学习特别是CV领域，训练和预测是分两步走的，所以训练和预测的硬件差异让更多地轻量化需求得以体现。<strong>虽然目标检测的模型的预测头部和模型结构不都相同，但是input都是特征图，每个层进行处理的也是特征图的信息进行输入，所以可以形成一个统一的基于特征的蒸馏方法来实现模型压缩</strong></p> 
<h3><a id="_26"></a>主要的贡献和方法：</h3> 
<p><img src="https://images2.imgbox.com/6c/59/9HZpN8Ka_o.png" alt="在这里插入图片描述"></p> 
<p>​ 就像题目所说的那样，作者提出了两种不同的蒸馏方式，作者认为在目标检测领域，全局的特征联系关联特征和局部的细节特征感知信息一样重要，所以不仅要关注前景图也要关注背景图。</p> 
<h4><a id="Global_Distillation_32"></a>Global Distillation</h4> 
<p>​ 借鉴了<a href="https://arxiv.org/pdf/1904.11492.pdf" rel="nofollow">GCnet</a>中的GCBlock模块来获取全局的上下文关联信息，将教师模型中学习到的关联信息传递给学生模型进行学习</p> 
<p><img src="https://images2.imgbox.com/6a/c9/UwBcXo79_o.png" alt="在这里插入图片描述"></p> 
<p>​ transform模块代码：</p> 
<pre><code class="prism language-python"><span class="token comment">##transform模块(学生和教师)</span>
<span class="token comment">##①1x1conv，通道数/2   ②LN+Relu   ③1*1conv，通道数还原</span>
self<span class="token punctuation">.</span>channel_add_conv_s <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>teacher_channels<span class="token punctuation">,</span> teacher_channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token punctuation">[</span>teacher_channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># yapf: disable</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>teacher_channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> teacher_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
self<span class="token punctuation">.</span>channel_add_conv_t <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>teacher_channels<span class="token punctuation">,</span> teacher_channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>LayerNorm<span class="token punctuation">(</span><span class="token punctuation">[</span>teacher_channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span>inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># yapf: disable</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>teacher_channels<span class="token operator">//</span><span class="token number">2</span><span class="token punctuation">,</span> teacher_channels<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>​ Context Modeling代码：</p> 
<pre><code class="prism language-python"><span class="token comment">##GC Block</span>
<span class="token keyword">def</span> <span class="token function">spatial_pool</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">,</span> in_type<span class="token punctuation">)</span><span class="token punctuation">:</span>
    batch<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> width<span class="token punctuation">,</span> height <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span>
    input_x <span class="token operator">=</span> x
    <span class="token comment"># [N, C, H * W]</span>
    input_x <span class="token operator">=</span> input_x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> height <span class="token operator">*</span> width<span class="token punctuation">)</span>
    <span class="token comment"># [N, 1, C, H * W]</span>
    input_x <span class="token operator">=</span> input_x<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>    <span class="token comment">##在第二个维度上增加一个维度为1</span>
    <span class="token comment"># [N, 1, H, W]</span>
    <span class="token keyword">if</span> in_type <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        context_mask <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_mask_s<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        context_mask <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_mask_t<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    <span class="token comment"># [N, 1, H * W]</span>
    context_mask <span class="token operator">=</span> context_mask<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> height <span class="token operator">*</span> width<span class="token punctuation">)</span>
    <span class="token comment"># [N, 1, H * W]</span>
    context_mask <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>context_mask<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token comment"># [N, 1, H * W, 1]</span>
    context_mask <span class="token operator">=</span> context_mask<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment">##在最后一个维度上增加一个维度为1</span>
    <span class="token comment"># [N, 1, C, H*W] matmul [N, 1, H*W, 1]=  [N, 1, C, 1]</span>
    context <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_x<span class="token punctuation">,</span> context_mask<span class="token punctuation">)</span>
    <span class="token comment"># [N, C, 1, 1]</span>
    context <span class="token operator">=</span> context<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batch<span class="token punctuation">,</span> channel<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> context
</code></pre> 
<p>​ GCBlock的loss公式和代码如下：<br> <img src="https://images2.imgbox.com/c1/86/OvzMW6MR_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment">##Global Loss</span>
<span class="token keyword">def</span> <span class="token function">get_rela_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> preds_S<span class="token punctuation">,</span> preds_T<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">##loss的整体采用MSE均方误差的方法计算，即sum((Teacher-Student)^2)</span>
    loss_mse <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span> 
    
	<span class="token comment">##各自训练出自己的全局上下文特征信息，第二个参数表示0表示student，1表示teacher</span>
    context_s <span class="token operator">=</span> self<span class="token punctuation">.</span>spatial_pool<span class="token punctuation">(</span>preds_S<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    context_t <span class="token operator">=</span> self<span class="token punctuation">.</span>spatial_pool<span class="token punctuation">(</span>preds_T<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

    out_s <span class="token operator">=</span> preds_S
    out_t <span class="token operator">=</span> preds_T
	
    <span class="token comment">##将结果transform模块的特征信息与原来的输入特征信息进行相加</span>
    channel_add_s <span class="token operator">=</span> self<span class="token punctuation">.</span>channel_add_conv_s<span class="token punctuation">(</span>context_s<span class="token punctuation">)</span>
    out_s <span class="token operator">=</span> out_s <span class="token operator">+</span> channel_add_s

    channel_add_t <span class="token operator">=</span> self<span class="token punctuation">.</span>channel_add_conv_t<span class="token punctuation">(</span>context_t<span class="token punctuation">)</span>
    out_t <span class="token operator">=</span> out_t <span class="token operator">+</span> channel_add_t
	
    <span class="token comment">##均方误差，最后的sum除以长度</span>
    rela_loss <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>out_s<span class="token punctuation">,</span> out_t<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>out_s<span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> rela_loss
</code></pre> 
<h4><a id="Focal_Distillation_121"></a>Focal Distillation</h4> 
<p>​ 使用局部蒸馏来提升学生模型对教师模型的关键的像素点以及关键通道的特征信息的学习.通过空间与维度两个注意力掩码值来让学生模型能够更加注重权重较大的pixel和channel。这里的温度的可控制变量为temp，和传统的KD方法一样用在softmax中加入温度来控制分数曲线。</p> 
<pre><code class="prism language-python"><span class="token comment">##注意力掩码</span>
<span class="token keyword">def</span> <span class="token function">get_attention</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> preds<span class="token punctuation">,</span> temp<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" preds: Bs*C*W*H """</span>
    N<span class="token punctuation">,</span> C<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token operator">=</span> preds<span class="token punctuation">.</span>shape

    value <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>preds<span class="token punctuation">)</span>
    <span class="token comment"># Bs*W*H</span>
    <span class="token comment">## 空间注意力map 以第二个参数C为基准算均值</span>
    fea_map <span class="token operator">=</span> value<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment">##A_S</span>
    S_attention <span class="token operator">=</span> <span class="token punctuation">(</span>H <span class="token operator">*</span> W <span class="token operator">*</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span><span class="token punctuation">(</span>fea_map<span class="token operator">/</span>temp<span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>N<span class="token punctuation">,</span> H<span class="token punctuation">,</span> W<span class="token punctuation">)</span> <span class="token comment"># Bs*W*H</span>

    <span class="token comment"># Bs*C</span>
    <span class="token comment">##通道注意力map，以第3，4个参数HW为基准算均值</span>
    channel_map <span class="token operator">=</span> value<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment">#A_C</span>
    C_attention <span class="token operator">=</span> C <span class="token operator">*</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>channel_map<span class="token operator">/</span>temp<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>     <span class="token comment"># Bs*C</span>

    <span class="token keyword">return</span> S_attention<span class="token punctuation">,</span> C_attention
</code></pre> 
<p>​ focal loss计算公式及其代码：</p> 
<p>​ 首先是featureloss，其中的M是区分前背景的，S是掩码来抑制前后景占比过大和大目标占据像素太大的问题提出的掩码规则。所以下图中的上半部分就是前景图的loss，下半部分是背景图的loss。</p> 
<p><img src="https://images2.imgbox.com/7b/f7/jIJDMwCI_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python">    <span class="token comment">##feature loss  ,这里只用到了teacher的C和S注意力，因为学生也是用教师的注意力，用学生的注意力没有学习和比较意义</span>
    <span class="token keyword">def</span> <span class="token function">get_fea_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> preds_S<span class="token punctuation">,</span> preds_T<span class="token punctuation">,</span> Mask_fg<span class="token punctuation">,</span> Mask_bg<span class="token punctuation">,</span> C_s<span class="token punctuation">,</span> C_t<span class="token punctuation">,</span> S_s<span class="token punctuation">,</span> S_t<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">""" preds_S(Tensor): Bs*C*H*W, student's feature map
            preds_T(Tensor): Bs*C*H*W, teacher's feature map
            C_s,C_t :BS*C
            S_s,S_t :BS*H*W"""</span>
        loss_mse <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span>reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>

        <span class="token comment">##补齐C维度</span>
        Mask_fg <span class="token operator">=</span> Mask_fg<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        Mask_bg <span class="token operator">=</span> Mask_bg<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment">##补齐H,W两个维度</span>
        C_t <span class="token operator">=</span> C_t<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        C_t <span class="token operator">=</span> C_t<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment">##补齐C的维度</span>
        S_t <span class="token operator">=</span> S_t<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment">##教师的feature融入自己的注意力掩码后，运用到前背景分离图中</span>
        fea_t<span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>preds_T<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>S_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
        fea_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>fea_t<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>C_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
        fg_fea_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>fea_t<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>Mask_fg<span class="token punctuation">)</span><span class="token punctuation">)</span>
        bg_fea_t <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>fea_t<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>Mask_bg<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment">##学生利用了教师模型中的注意力后，运用到前背景分离图中</span>
        fea_s <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>preds_S<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>S_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
        fea_s <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>fea_s<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>C_t<span class="token punctuation">)</span><span class="token punctuation">)</span>
        fg_fea_s <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>fea_s<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>Mask_fg<span class="token punctuation">)</span><span class="token punctuation">)</span>
        bg_fea_s <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>fea_s<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>Mask_bg<span class="token punctuation">)</span><span class="token punctuation">)</span>

        fg_loss <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>fg_fea_s<span class="token punctuation">,</span> fg_fea_t<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>Mask_fg<span class="token punctuation">)</span>
        bg_loss <span class="token operator">=</span> loss_mse<span class="token punctuation">(</span>bg_fea_s<span class="token punctuation">,</span> bg_fea_t<span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>Mask_bg<span class="token punctuation">)</span>

        <span class="token keyword">return</span> fg_loss<span class="token punctuation">,</span> bg_loss
</code></pre> 
<p>​ 其次是衡量student模型模仿教师得出的注意力与teacher自己的注意力的相似程度，这里的loss函数采用了L1 loss。</p> 
<p><img src="https://images2.imgbox.com/58/b4/OpMSCoyB_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-python"><span class="token comment">##L1 loss来衡量学生模型模仿教师的注意力的程度</span>
<span class="token keyword">def</span> <span class="token function">get_mask_loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> C_s<span class="token punctuation">,</span> C_t<span class="token punctuation">,</span> S_s<span class="token punctuation">,</span> S_t<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment">##L1:sum(|A-B|)/len</span>
    mask_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">(</span>C_s<span class="token operator">-</span>C_t<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>C_s<span class="token punctuation">)</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">(</span>S_s<span class="token operator">-</span>S_t<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>S_s<span class="token punctuation">)</span>

    <span class="token keyword">return</span> mask_loss
</code></pre> 
<p><img src="https://images2.imgbox.com/80/ee/L9fp7r3i_o.png" alt="在这里插入图片描述"></p> 
<p>​ 总的loss代码：</p> 
<pre><code class="prism language-python">loss <span class="token operator">=</span> self<span class="token punctuation">.</span>alpha_fgd <span class="token operator">*</span> fg_loss <span class="token operator">+</span> self<span class="token punctuation">.</span>beta_fgd <span class="token operator">*</span> bg_loss \
       <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma_fgd <span class="token operator">*</span> mask_loss <span class="token operator">+</span> self<span class="token punctuation">.</span>lambda_fgd <span class="token operator">*</span> rela_loss
</code></pre> 
<p>​ 总的loss代码：</p> 
<pre><code class="prism language-python">loss <span class="token operator">=</span> self<span class="token punctuation">.</span>alpha_fgd <span class="token operator">*</span> fg_loss <span class="token operator">+</span> self<span class="token punctuation">.</span>beta_fgd <span class="token operator">*</span> bg_loss \
       <span class="token operator">+</span> self<span class="token punctuation">.</span>gamma_fgd <span class="token operator">*</span> mask_loss <span class="token operator">+</span> self<span class="token punctuation">.</span>lambda_fgd <span class="token operator">*</span> rela_loss
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2a364aba6a5580cb248f882a41ebcf60/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【爬虫】使用requests爬取英雄联盟英雄皮肤</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f079cac907f63799d51bb03b7a9d69b0/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Eclipse SWT 对话框（四）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>