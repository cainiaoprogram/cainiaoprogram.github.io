<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLOv8æ”¹è¿› | æ£€æµ‹å¤´ç¯‡ | åˆ©ç”¨DySnakeConvæ”¹è¿›æ£€æµ‹å¤´ä¸“ç”¨äºåˆ†å‰²çš„æ£€æµ‹å¤´ï¼ˆå…¨ç½‘ç‹¬å®¶é¦–å‘ï¼ŒSegï¼‰ - èœé¸Ÿç¨‹åºå‘˜åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YOLOv8æ”¹è¿› | æ£€æµ‹å¤´ç¯‡ | åˆ©ç”¨DySnakeConvæ”¹è¿›æ£€æµ‹å¤´ä¸“ç”¨äºåˆ†å‰²çš„æ£€æµ‹å¤´ï¼ˆå…¨ç½‘ç‹¬å®¶é¦–å‘ï¼ŒSegï¼‰" />
<meta property="og:description" content="ä¸€ã€æœ¬æ–‡æ”¹è¿› æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯ä¸€ç§æˆ‘è¿›è¡Œä¼˜åŒ–çš„ä¸“ç”¨äºåˆ†å‰²çš„æ£€æµ‹å¤´ï¼Œåœ¨åˆ†å‰²çš„è¿‡ç¨‹ä¸­ï¼Œæœ€å›°éš¾çš„æ— éå°±æ˜¯è¾¹ç¼˜çš„æ£€æµ‹ï¼ŒåŠ¨æ€è›‡å½¢å·ç§¯ï¼ˆDynamic Snake Convolutionï¼‰é€šè¿‡è‡ªé€‚åº”åœ°èšç„¦äºç»†é•¿å’Œè¿‚å›çš„å±€éƒ¨ç»“æ„ï¼Œå‡†ç¡®åœ°æ•æ‰ç®¡çŠ¶ç»“æ„çš„ç‰¹å¾ã€‚è¿™ç§å·ç§¯æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œé€šè¿‡åŠ¨æ€å½¢çŠ¶çš„å·ç§¯æ ¸æ¥å¢å¼ºæ„ŸçŸ¥èƒ½åŠ›ï¼Œé’ˆå¯¹ç®¡çŠ¶ç»“æ„çš„ç‰¹å¾æå–è¿›è¡Œä¼˜åŒ–ï¼Œæ‰€ä»¥å°†è¿™ä¸ªå·ç§¯é’ˆå¯¹äºYOLOv8çš„åˆ†å‰²å¤´è¿›è¡Œèåˆæ˜¯éå¸¸åˆé€‚çš„ï¼Œå½“ç„¶æœ¬æ–‡çš„æ£€æµ‹å¤´ä¹Ÿæ”¯æŒç”¨äºç›®æ ‡æ£€æµ‹ï¼Œä½†æ˜¯æˆ‘å°†å…¶è®¾è®¡å‡ºæ¥æ˜¯ä¸»è¦ä¸ºäº†åˆ†å‰²çš„è¯»è€…ä½¿ç”¨çš„ã€‚
æ¬¢è¿å¤§å®¶è®¢é˜…æˆ‘çš„ä¸“æ ä¸€èµ·å­¦ä¹ YOLOï¼Â ä¸“æ å›é¡¾ï¼šYOLOv8æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡Â ç›®å½•
ä¸€ã€æœ¬æ–‡æ”¹è¿›
äºŒã€DySnakeConvçš„æ¡†æ¶åŸç†
ä¸‰ã€DySnakerConvçš„æ ¸å¿ƒä»£ç Â å››ã€åˆ†å‰²æ£€æµ‹å¤´ä¿®æ”¹æ•™ç¨‹Â 4.1 ä¿®æ”¹ä¸€
4.2 ä¿®æ”¹äºŒÂ 4.3 ä¿®æ”¹ä¸‰Â 4.4 ä¿®æ”¹å››Â 4.5 ä¿®æ”¹äº”
4.6 ä¿®æ”¹å…­Â 4.7 ä¿®æ”¹ä¸ƒÂ 4.8 ä¿®æ”¹å…«Â 4.9 ä¿®æ”¹ä¹Â 4.10 ä¿®æ”¹10Â äº”ã€ åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹çš„yamlæ–‡ä»¶
5.1 åˆ†å‰²çš„yamlæ–‡ä»¶
5.2 ç›®æ ‡æ£€æµ‹çš„yamlæ–‡ä»¶Â å…­ã€æœ¬æ–‡æ€»ç»“
äºŒã€DySnakeConvçš„æ¡†æ¶åŸç† è®ºæ–‡ä»£ç åœ°å€ï¼šåŠ¨æ€è›‡å½¢å·ç§¯å®˜æ–¹ä»£ç ä¸‹è½½åœ°å€
è®ºæ–‡åœ°å€ï¼šã€å…è´¹ã€‘åŠ¨æ€è›‡å½¢å·ç§¯(DynamicSnakeConvolution)èµ„æº-CSDNæ–‡åº“
èƒŒæ™¯-&gt;åŠ¨æ€è›‡å½¢å·ç§¯(Dynamic Snake Convolution)æ¥æºäºä¸´åºŠåŒ»å­¦ï¼Œæ¸…æ™°å‹¾ç”»è¡€ç®¡æ˜¯è®¡ç®—æµä½“åŠ›å­¦ç ”ç©¶çš„å…³é”®å‰æï¼Œå¹¶èƒ½ååŠ©æ”¾å°„ç§‘åŒ»å¸ˆè¿›è¡Œè¯Šæ–­å’Œå®šä½ç—…å˜ã€‚åœ¨é¥æ„Ÿåº”ç”¨ä¸­ï¼Œå®Œæ•´çš„é“è·¯åˆ†å‰²ä¸ºè·¯å¾„è§„åˆ’æä¾›äº†åšå®çš„åŸºç¡€ã€‚æ— è®ºæ˜¯å“ªä¸ªé¢†åŸŸï¼Œè¿™äº›ç»“æ„éƒ½å…·æœ‰ç»†é•¿å’Œæ›²æŠ˜çš„å…±åŒç‰¹å¾ï¼Œä½¿å¾—å®ƒä»¬å¾ˆéš¾åœ¨å›¾åƒä¸­æ•æ‰åˆ°ï¼Œå› ä¸ºå®ƒä»¬åœ¨å›¾åƒä¸­çš„æ¯”ä¾‹å¾ˆå°ã€‚å› æ­¤ï¼Œè¿«åˆ‡éœ€è¦æå‡å¯¹ç»†é•¿ç®¡çŠ¶ç»“æ„çš„æ„ŸçŸ¥èƒ½åŠ›ï¼Œæ‰€ä»¥åœ¨è¿™ä¸€èƒŒæ™¯ä¸‹ä½œè€…æå‡ºäº†åŠ¨æ€è›‡å½¢å·ç§¯(Dynamic Snake Convolution)ã€‚
åŸç†-&gt;ä¸Šå›¾å±•ç¤ºäº†ä¸€ä¸ªä¸‰ç»´å¿ƒè„è¡€ç®¡æ•°æ®é›†å’Œä¸€ä¸ªäºŒç»´è¿œç¨‹é“è·¯æ•°æ®é›†ã€‚è¿™ä¸¤ä¸ªæ•°æ®é›†æ—¨åœ¨æå–ç®¡çŠ¶ç»“æ„ï¼Œä½†ç”±äºè„†å¼±çš„å±€éƒ¨ç»“æ„å’Œå¤æ‚çš„æ•´ä½“å½¢æ€ï¼Œè¿™ä¸ªä»»åŠ¡é¢ä¸´ç€æŒ‘æˆ˜ã€‚æ ‡å‡†çš„å·ç§¯æ ¸æ—¨åœ¨æå–å±€éƒ¨ç‰¹å¾ã€‚åŸºäºæ­¤ï¼Œè®¾è®¡äº†å¯å˜å½¢å·ç§¯æ ¸ä»¥ä¸°å¯Œå®ƒä»¬çš„åº”ç”¨ï¼Œå¹¶é€‚åº”ä¸åŒç›®æ ‡çš„å‡ ä½•å˜å½¢ã€‚ç„¶è€Œï¼Œç”±äºå‰é¢æåˆ°çš„æŒ‘æˆ˜ï¼Œæœ‰æ•ˆåœ°èšç„¦äºç»†å°çš„ç®¡çŠ¶ç»“æ„æ˜¯å›°éš¾çš„ã€‚
ç”±äºä»¥ä¸‹å›°éš¾ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼š
ç»†å°è€Œè„†å¼±çš„å±€éƒ¨ç»“æ„ï¼šå¦‚ä¸Šé¢çš„å›¾æ‰€ç¤ºï¼Œç»†å°çš„ç»“æ„ä»…å æ•´ä½“å›¾åƒçš„ä¸€å°éƒ¨åˆ†ï¼Œå¹¶ä¸”ç”±äºåƒç´ ç»„æˆæœ‰é™ï¼Œè¿™äº›ç»“æ„å®¹æ˜“å—åˆ°å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œä½¿æ¨¡å‹éš¾ä»¥ç²¾ç¡®åœ°åŒºåˆ†ç›®æ ‡çš„ç»†å¾®å˜åŒ–ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯èƒ½éš¾ä»¥åŒºåˆ†è¿™äº›ç»“æ„ï¼Œå¯¼è‡´åˆ†å‰²ç»“æœå‡ºç°æ–­è£‚ã€‚
å¤æ‚è€Œå¤šå˜çš„æ•´ä½“å½¢æ€ï¼šä¸Šé¢çš„å›¾ç‰‡å±•ç¤ºäº†ç»†å°ç®¡çŠ¶ç»“æ„çš„å¤æ‚å’Œå¤šå˜å½¢æ€ï¼Œå³ä½¿åœ¨åŒä¸€å›¾åƒä¸­ä¹Ÿå¦‚æ­¤ã€‚ä¸åŒåŒºåŸŸä¸­çš„ç›®æ ‡å‘ˆç°å‡ºå½¢æ€ä¸Šçš„å˜åŒ–ï¼ŒåŒ…æ‹¬åˆ†æ”¯æ•°é‡ã€åˆ†å‰ä½ç½®å’Œè·¯å¾„é•¿åº¦ç­‰ã€‚å½“æ•°æ®å‘ˆç°å‡ºå‰æ‰€æœªè§çš„å½¢æ€ç»“æ„æ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¿‡åº¦æ‹Ÿåˆå·²ç»è§è¿‡çš„ç‰¹å¾ï¼Œå¯¼è‡´åœ¨æ–°çš„å½¢æ€ç»“æ„ä¸‹æ³›åŒ–èƒ½åŠ›è¾ƒå¼±ã€‚
ä¸ºäº†åº”å¯¹ä¸Šè¿°éšœç¢ï¼Œæå‡ºäº†å¦‚ä¸‹è§£å†³æ–¹æ¡ˆï¼Œå…¶ä¸­åŒ…æ‹¬ç®¡çŠ¶æ„ŸçŸ¥å·ç§¯æ ¸ã€å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥å’Œæ‹“æ‰‘è¿ç»­æ€§çº¦æŸæŸå¤±å‡½æ•°ã€‚å…·ä½“å¦‚ä¸‹ï¼š
1. é’ˆå¯¹ç»†å°ä¸”è„†å¼±çš„å±€éƒ¨ç»“æ„æ‰€å æ¯”ä¾‹å°ä¸”éš¾ä»¥èšç„¦çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†åŠ¨æ€è›‡å½¢å·ç§¯ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°èšç„¦äºç®¡çŠ¶ç»“æ„çš„ç»†é•¿æ›²çº¿å±€éƒ¨ç‰¹å¾ï¼Œå¢å¼ºå¯¹å‡ ä½•ç»“æ„çš„æ„ŸçŸ¥ã€‚ä¸å¯å˜å½¢å·ç§¯ä¸åŒï¼ŒDSConvè€ƒè™‘åˆ°ç®¡çŠ¶ç»“æ„çš„è›‡å½¢å½¢æ€ï¼Œå¹¶é€šè¿‡çº¦æŸè¡¥å……è‡ªç”±å­¦ä¹ è¿‡ç¨‹ï¼Œæœ‰é’ˆå¯¹æ€§åœ°å¢å¼ºå¯¹ç®¡çŠ¶ç»“æ„çš„æ„ŸçŸ¥ã€‚
2. é’ˆå¯¹å¤æ‚å’Œå¤šå˜çš„æ•´ä½“å½¢æ€çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼ŒåŸºäºDSConvç”Ÿæˆå¤šä¸ªå½¢æ€å­¦å·ç§¯æ ¸æ¨¡æ¿ï¼Œä»ä¸åŒè§’åº¦è§‚å¯Ÿç›®æ ‡çš„ç»“æ„ç‰¹å¾ï¼Œå¹¶é€šè¿‡æ€»ç»“å…¸å‹çš„é‡è¦ç‰¹å¾å®ç°é«˜æ•ˆçš„ç‰¹å¾èåˆã€‚
3. é’ˆå¯¹ç®¡çŠ¶ç»“æ„åˆ†å‰²å®¹æ˜“å‡ºç°æ–­è£‚çš„é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæŒä¹…åŒè°ƒï¼ˆPersistent Homologyï¼ŒPHï¼‰çš„æ‹“æ‰‘è¿ç»­æ€§çº¦æŸæŸå¤±å‡½æ•°ï¼ˆTCLossï¼‰ã€‚PHæ˜¯ä¸€ç§ä»å‡ºç°åˆ°æ¶ˆå¤±çš„æ‹“æ‰‘ç‰¹å¾å“åº”è¿‡ç¨‹ï¼Œèƒ½å¤Ÿä»å˜ˆæ‚çš„é«˜ç»´æ•°æ®ä¸­è·å–è¶³å¤Ÿçš„æ‹“æ‰‘ä¿¡æ¯ã€‚ç›¸å…³çš„è´è’‚æ•°æ˜¯æè¿°æ‹“æ‰‘ç©ºé—´è¿é€šæ€§çš„ä¸€ç§æ–¹å¼ã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼ŒTCLosså°†PHä¸ç‚¹é›†ç›¸ä¼¼æ€§ç›¸ç»“åˆï¼Œå¼•å¯¼ç½‘ç»œå…³æ³¨å…·æœ‰å¼‚å¸¸åƒç´ /ä½“ç´ åˆ†å¸ƒçš„æ–­è£‚åŒºåŸŸï¼Œä»æ‹“æ‰‘è§’åº¦å®ç°è¿ç»­æ€§çº¦æŸã€‚
æ€»ç»“:ä¸ºäº†å…‹æœæŒ‘æˆ˜ï¼Œæå‡ºäº†DSCNetæ¡†æ¶ï¼ŒåŒ…æ‹¬ç®¡çŠ¶æ„ŸçŸ¥å·ç§¯æ ¸ã€å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥å’Œæ‹“æ‰‘è¿ç»­æ€§çº¦æŸæŸå¤±å‡½æ•°ã€‚DSConvå¢å¼ºäº†å¯¹ç»†é•¿æ›²çº¿ç‰¹å¾çš„æ„ŸçŸ¥ï¼Œå¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥æé«˜äº†å¯¹å¤æ‚æ•´ä½“å½¢æ€çš„å¤„ç†èƒ½åŠ›ï¼Œè€ŒTCLossåŸºäºæŒä¹…åŒè°ƒå®ç°äº†ä»æ‹“æ‰‘è§’åº¦çš„è¿ç»­æ€§çº¦æŸã€‚
ä¸‰ã€DySnakerConvçš„æ ¸å¿ƒä»£ç Â ä¸‹é¢çš„æ£€æµ‹å¤´å¯ä»¥ç”¨äºåˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ï¼Œä½†æ˜¯å…¶ä¿®æ”¹æ•™ç¨‹æœ‰å·®åˆ«ã€‚ç›®æ ‡æ£€æµ‹çš„æ£€æµ‹å¤´æˆ‘å°±ä¸è®²äº†ï¼Œå¤§å®¶çœ‹æˆ‘ä¹‹å‰çš„æ£€æµ‹å¤´å¦‚ä½•æ·»åŠ çš„å°±å¯ä»¥ï¼Œéƒ½æ˜¯ä¸€æ ·çš„åªæ˜¯æ¢ä¸€ä¸ªåå­—ï¼Œæœ¬æ–‡ä¸»è¦é’ˆå¯¹äºåˆ†å‰²çš„è¯»è€…ã€‚
import torch import torch.nn as nn import math from ultralytics." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/66dc24e4507bbac494e60bbba10d2f6f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-12T05:43:20+08:00" />
<meta property="article:modified_time" content="2024-01-12T05:43:20+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="èœé¸Ÿç¨‹åºå‘˜åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">èœé¸Ÿç¨‹åºå‘˜åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLOv8æ”¹è¿› | æ£€æµ‹å¤´ç¯‡ | åˆ©ç”¨DySnakeConvæ”¹è¿›æ£€æµ‹å¤´ä¸“ç”¨äºåˆ†å‰²çš„æ£€æµ‹å¤´ï¼ˆå…¨ç½‘ç‹¬å®¶é¦–å‘ï¼ŒSegï¼‰</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2 id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E6%94%B9%E8%BF%9B">ä¸€ã€æœ¬æ–‡æ”¹è¿›</h2> 
<p>æœ¬æ–‡ç»™å¤§å®¶å¸¦æ¥çš„æ”¹è¿›æœºåˆ¶æ˜¯ä¸€ç§æˆ‘è¿›è¡Œä¼˜åŒ–çš„ä¸“ç”¨äºåˆ†å‰²çš„æ£€æµ‹å¤´ï¼Œåœ¨åˆ†å‰²çš„è¿‡ç¨‹ä¸­ï¼Œæœ€å›°éš¾çš„æ— éå°±æ˜¯è¾¹ç¼˜çš„æ£€æµ‹ï¼Œ<span style="color:#ed7976;"><strong>åŠ¨æ€è›‡å½¢å·ç§¯</strong></span>ï¼ˆDynamic Snake Convolutionï¼‰é€šè¿‡è‡ªé€‚åº”åœ°èšç„¦äºç»†é•¿å’Œè¿‚å›çš„å±€éƒ¨ç»“æ„ï¼Œå‡†ç¡®åœ°æ•æ‰ç®¡çŠ¶ç»“æ„çš„ç‰¹å¾ã€‚è¿™ç§å·ç§¯æ–¹æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼Œ<strong>é€šè¿‡åŠ¨æ€å½¢çŠ¶çš„å·ç§¯æ ¸æ¥å¢å¼ºæ„ŸçŸ¥èƒ½åŠ›ï¼Œé’ˆå¯¹ç®¡çŠ¶ç»“æ„çš„ç‰¹å¾æå–è¿›è¡Œä¼˜åŒ–ï¼Œæ‰€ä»¥å°†è¿™ä¸ªå·ç§¯é’ˆå¯¹äºYOLOv8çš„åˆ†å‰²å¤´è¿›è¡Œèåˆæ˜¯éå¸¸åˆé€‚çš„ï¼Œ<span style="color:#956fe7;">å½“ç„¶æœ¬æ–‡çš„æ£€æµ‹å¤´ä¹Ÿæ”¯æŒç”¨äºç›®æ ‡æ£€æµ‹ï¼Œä½†æ˜¯æˆ‘å°†å…¶è®¾è®¡å‡ºæ¥æ˜¯ä¸»è¦ä¸ºäº†åˆ†å‰²çš„è¯»è€…ä½¿ç”¨çš„ã€‚</span></strong></p> 
<p style="text-align:center;"><span style="color:#fe2c24;"><strong>æ¬¢è¿å¤§å®¶è®¢é˜…æˆ‘çš„ä¸“æ ä¸€èµ·å­¦ä¹ YOLOï¼</strong>Â </span></p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">ä¸“æ å›é¡¾ï¼š</span><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><a href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡">YOLOv8æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡</a></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>Â Â Â Â </strong></p> 
</blockquote> 
<p id="main-toc"><strong>ç›®å½•</strong></p> 
<p id="%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E6%94%B9%E8%BF%9B-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%80%E3%80%81%E6%9C%AC%E6%96%87%E6%94%B9%E8%BF%9B" rel="nofollow">ä¸€ã€æœ¬æ–‡æ”¹è¿›</a></strong></p> 
<p id="%E4%BA%8C%E3%80%81DySnakeConv%E7%9A%84%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86-toc" style="margin-left:0px;"><strong><a href="#%E4%BA%8C%E3%80%81DySnakeConv%E7%9A%84%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86" rel="nofollow">äºŒã€DySnakeConvçš„æ¡†æ¶åŸç†</a></strong></p> 
<p id="%E4%B8%89%E3%80%81DySnakerConv%E7%9A%84%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81%C2%A0-toc" style="margin-left:0px;"><strong><a href="#%E4%B8%89%E3%80%81DySnakerConv%E7%9A%84%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81%C2%A0" rel="nofollow">ä¸‰ã€DySnakerConvçš„æ ¸å¿ƒä»£ç Â </a></strong></p> 
<p id="%E5%9B%9B%E3%80%81%E5%88%86%E5%89%B2%E6%A3%80%E6%B5%8B%E5%A4%B4%E4%BF%AE%E6%94%B9%E6%95%99%E7%A8%8B%C2%A0-toc" style="margin-left:0px;"><strong><a href="#%E5%9B%9B%E3%80%81%E5%88%86%E5%89%B2%E6%A3%80%E6%B5%8B%E5%A4%B4%E4%BF%AE%E6%94%B9%E6%95%99%E7%A8%8B%C2%A0" rel="nofollow">å››ã€åˆ†å‰²æ£€æµ‹å¤´ä¿®æ”¹æ•™ç¨‹Â </a></strong></p> 
<p id="4.1%20%E4%BF%AE%E6%94%B9%E4%B8%80-toc" style="margin-left:40px;"><strong><a href="#4.1%20%E4%BF%AE%E6%94%B9%E4%B8%80" rel="nofollow">4.1 ä¿®æ”¹ä¸€</a></strong></p> 
<p id="4.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C%C2%A0" rel="nofollow">4.2 ä¿®æ”¹äºŒÂ </a></strong></p> 
<p id="4.3%20%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.3%20%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0" rel="nofollow">4.3 ä¿®æ”¹ä¸‰Â </a></strong></p> 
<p id="4.4%20%E4%BF%AE%E6%94%B9%E5%9B%9B%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.4%20%E4%BF%AE%E6%94%B9%E5%9B%9B%C2%A0" rel="nofollow">4.4 ä¿®æ”¹å››Â </a></strong></p> 
<p id="4.5%20%E4%BF%AE%E6%94%B9%E4%BA%94-toc" style="margin-left:40px;"><strong><a href="#4.5%20%E4%BF%AE%E6%94%B9%E4%BA%94" rel="nofollow">4.5 ä¿®æ”¹äº”</a></strong></p> 
<p id="4.6%20%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.6%20%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0" rel="nofollow">4.6 ä¿®æ”¹å…­Â </a></strong></p> 
<p id="4.7%20%E4%BF%AE%E6%94%B9%E4%B8%83%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.7%20%E4%BF%AE%E6%94%B9%E4%B8%83%C2%A0" rel="nofollow">4.7 ä¿®æ”¹ä¸ƒÂ </a></strong></p> 
<p id="4.8%20%E4%BF%AE%E6%94%B9%E5%85%AB%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.8%20%E4%BF%AE%E6%94%B9%E5%85%AB%C2%A0" rel="nofollow">4.8 ä¿®æ”¹å…«Â </a></strong></p> 
<p id="4.9%20%E4%BF%AE%E6%94%B9%E4%B9%9D%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.9%20%E4%BF%AE%E6%94%B9%E4%B9%9D%C2%A0" rel="nofollow">4.9 ä¿®æ”¹ä¹Â </a></strong></p> 
<p id="4.10%20%E4%BF%AE%E6%94%B910%C2%A0-toc" style="margin-left:40px;"><strong><a href="#4.10%20%E4%BF%AE%E6%94%B910%C2%A0" rel="nofollow">4.10 ä¿®æ”¹10Â </a></strong></p> 
<p id="%E4%BA%94%E3%80%81%20%E5%88%86%E5%89%B2%E5%92%8C%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84yaml%E6%96%87%E4%BB%B6-toc" style="margin-left:0px;"><strong><a href="#%E4%BA%94%E3%80%81%20%E5%88%86%E5%89%B2%E5%92%8C%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84yaml%E6%96%87%E4%BB%B6" rel="nofollow">äº”ã€ åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹çš„yamlæ–‡ä»¶</a></strong></p> 
<p id="5.1%20%E5%88%86%E5%89%B2%E7%9A%84yaml%E6%96%87%E4%BB%B6-toc" style="margin-left:40px;"><strong><a href="#5.1%20%E5%88%86%E5%89%B2%E7%9A%84yaml%E6%96%87%E4%BB%B6" rel="nofollow">5.1 åˆ†å‰²çš„yamlæ–‡ä»¶</a></strong></p> 
<p id="5.2%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84yaml%E6%96%87%E4%BB%B6%C2%A0-toc" style="margin-left:40px;"><strong><a href="#5.2%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84yaml%E6%96%87%E4%BB%B6%C2%A0" rel="nofollow">5.2 ç›®æ ‡æ£€æµ‹çš„yamlæ–‡ä»¶Â </a></strong></p> 
<p id="%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><strong><a href="#%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93" rel="nofollow">å…­ã€æœ¬æ–‡æ€»ç»“</a></strong></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="%E4%BA%8C%E3%80%81DySnakeConv%E7%9A%84%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86"><strong>äºŒã€DySnakeConvçš„æ¡†æ¶åŸç†</strong></h2> 
<p class="img-center"><img alt="" height="393" src="https://images2.imgbox.com/23/67/SeT7GLHX_o.png" width="1200"></p> 
<p></p> 
<p><strong><span style="color:#fe2c24;">è®ºæ–‡ä»£ç åœ°å€ï¼š</span><strong><a href="https://github.com/YaoleiQi/DSCNet" title="åŠ¨æ€è›‡å½¢å·ç§¯å®˜æ–¹ä»£ç ä¸‹è½½åœ°å€">åŠ¨æ€è›‡å½¢å·ç§¯å®˜æ–¹ä»£ç ä¸‹è½½åœ°å€</a></strong><br><span style="color:#fe2c24;">è®ºæ–‡åœ°å€ï¼š</span><strong><a href="https://download.csdn.net/download/java1314777/88489535" title="ã€å…è´¹ã€‘åŠ¨æ€è›‡å½¢å·ç§¯(DynamicSnakeConvolution)èµ„æº-CSDNæ–‡åº“">ã€å…è´¹ã€‘åŠ¨æ€è›‡å½¢å·ç§¯(DynamicSnakeConvolution)èµ„æº-CSDNæ–‡åº“</a></strong></strong></p> 
<p class="img-center"><img alt="" height="259" src="https://images2.imgbox.com/79/39/Z9gSZCwl_o.png" width="943"></p> 
<p><strong>èƒŒæ™¯-&gt;</strong>åŠ¨æ€è›‡å½¢å·ç§¯(Dynamic Snake Convolution)æ¥æºäºä¸´åºŠåŒ»å­¦ï¼Œæ¸…æ™°å‹¾ç”»è¡€ç®¡æ˜¯è®¡ç®—æµä½“åŠ›å­¦ç ”ç©¶çš„å…³é”®å‰æï¼Œå¹¶èƒ½ååŠ©æ”¾å°„ç§‘åŒ»å¸ˆè¿›è¡Œè¯Šæ–­å’Œå®šä½ç—…å˜ã€‚åœ¨é¥æ„Ÿåº”ç”¨ä¸­ï¼Œå®Œæ•´çš„é“è·¯åˆ†å‰²ä¸ºè·¯å¾„è§„åˆ’æä¾›äº†åšå®çš„åŸºç¡€ã€‚æ— è®ºæ˜¯å“ªä¸ªé¢†åŸŸï¼Œè¿™äº›ç»“æ„éƒ½å…·æœ‰ç»†é•¿å’Œæ›²æŠ˜çš„å…±åŒç‰¹å¾ï¼Œä½¿å¾—å®ƒä»¬å¾ˆéš¾åœ¨å›¾åƒä¸­æ•æ‰åˆ°ï¼Œå› ä¸ºå®ƒä»¬åœ¨å›¾åƒä¸­çš„æ¯”ä¾‹å¾ˆå°ã€‚å› æ­¤ï¼Œ<strong>è¿«åˆ‡éœ€è¦æå‡å¯¹ç»†é•¿ç®¡çŠ¶ç»“æ„çš„æ„ŸçŸ¥èƒ½åŠ›</strong>ï¼Œæ‰€ä»¥åœ¨è¿™ä¸€èƒŒæ™¯ä¸‹ä½œè€…æå‡ºäº†åŠ¨æ€è›‡å½¢å·ç§¯(Dynamic Snake Convolution)ã€‚</p> 
<p class="img-center"><img alt="" height="745" src="https://images2.imgbox.com/c1/26/GcUhrVIo_o.png" width="992"></p> 
<p><strong>åŸç†-&gt;</strong>ä¸Šå›¾å±•ç¤ºäº†ä¸€ä¸ª<strong>ä¸‰ç»´å¿ƒè„è¡€ç®¡æ•°æ®é›†</strong>å’Œä¸€ä¸ª<strong>äºŒç»´è¿œç¨‹é“è·¯æ•°æ®é›†</strong>ã€‚è¿™ä¸¤ä¸ªæ•°æ®é›†æ—¨åœ¨æå–ç®¡çŠ¶ç»“æ„ï¼Œä½†ç”±äº<strong>è„†å¼±çš„å±€éƒ¨ç»“æ„å’Œå¤æ‚çš„æ•´ä½“å½¢æ€</strong>ï¼Œè¿™ä¸ªä»»åŠ¡é¢ä¸´ç€æŒ‘æˆ˜ã€‚æ ‡å‡†çš„å·ç§¯æ ¸æ—¨åœ¨æå–å±€éƒ¨ç‰¹å¾ã€‚åŸºäºæ­¤ï¼Œè®¾è®¡äº†å¯å˜å½¢å·ç§¯æ ¸ä»¥ä¸°å¯Œå®ƒä»¬çš„åº”ç”¨ï¼Œå¹¶é€‚åº”ä¸åŒç›®æ ‡çš„å‡ ä½•å˜å½¢ã€‚ç„¶è€Œï¼Œç”±äºå‰é¢æåˆ°çš„æŒ‘æˆ˜ï¼Œæœ‰æ•ˆåœ°èšç„¦äºç»†å°çš„ç®¡çŠ¶ç»“æ„æ˜¯å›°éš¾çš„ã€‚</p> 
<p>ç”±äºä»¥ä¸‹å›°éš¾ï¼Œè¿™ä»ç„¶æ˜¯ä¸€ä¸ªå…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼š</p> 
<ol><li> <p><strong>ç»†å°è€Œè„†å¼±çš„å±€éƒ¨ç»“æ„ï¼š</strong>å¦‚ä¸Šé¢çš„å›¾æ‰€ç¤ºï¼Œç»†å°çš„ç»“æ„ä»…å æ•´ä½“å›¾åƒçš„ä¸€å°éƒ¨åˆ†ï¼Œå¹¶ä¸”ç”±äºåƒç´ ç»„æˆæœ‰é™ï¼Œè¿™äº›ç»“æ„å®¹æ˜“å—åˆ°å¤æ‚èƒŒæ™¯çš„å¹²æ‰°ï¼Œä½¿æ¨¡å‹éš¾ä»¥ç²¾ç¡®åœ°åŒºåˆ†ç›®æ ‡çš„ç»†å¾®å˜åŒ–ã€‚å› æ­¤ï¼Œæ¨¡å‹å¯èƒ½éš¾ä»¥åŒºåˆ†è¿™äº›ç»“æ„ï¼Œå¯¼è‡´åˆ†å‰²ç»“æœå‡ºç°æ–­è£‚ã€‚</p> </li><li> <p><strong>å¤æ‚è€Œå¤šå˜çš„æ•´ä½“å½¢æ€ï¼š</strong>ä¸Šé¢çš„å›¾ç‰‡å±•ç¤ºäº†ç»†å°ç®¡çŠ¶ç»“æ„çš„å¤æ‚å’Œå¤šå˜å½¢æ€ï¼Œå³ä½¿åœ¨åŒä¸€å›¾åƒä¸­ä¹Ÿå¦‚æ­¤ã€‚ä¸åŒåŒºåŸŸä¸­çš„ç›®æ ‡å‘ˆç°å‡ºå½¢æ€ä¸Šçš„å˜åŒ–ï¼ŒåŒ…æ‹¬åˆ†æ”¯æ•°é‡ã€åˆ†å‰ä½ç½®å’Œè·¯å¾„é•¿åº¦ç­‰ã€‚å½“æ•°æ®å‘ˆç°å‡ºå‰æ‰€æœªè§çš„å½¢æ€ç»“æ„æ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¿‡åº¦æ‹Ÿåˆå·²ç»è§è¿‡çš„ç‰¹å¾ï¼Œå¯¼è‡´åœ¨æ–°çš„å½¢æ€ç»“æ„ä¸‹æ³›åŒ–èƒ½åŠ›è¾ƒå¼±ã€‚</p> </li></ol> 
<p>ä¸ºäº†åº”å¯¹ä¸Šè¿°éšœç¢ï¼Œæå‡ºäº†å¦‚ä¸‹è§£å†³æ–¹æ¡ˆï¼Œ<strong>å…¶ä¸­åŒ…æ‹¬ç®¡çŠ¶æ„ŸçŸ¥å·ç§¯æ ¸ã€å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥å’Œæ‹“æ‰‘è¿ç»­æ€§çº¦æŸæŸå¤±å‡½æ•°</strong>ã€‚å…·ä½“å¦‚ä¸‹ï¼š</p> 
<p>Â Â Â Â Â Â Â Â 1.<strong> é’ˆå¯¹ç»†å°ä¸”è„†å¼±çš„å±€éƒ¨ç»“æ„æ‰€å æ¯”ä¾‹å°ä¸”éš¾ä»¥èšç„¦çš„æŒ‘æˆ˜</strong>ï¼Œæå‡ºäº†åŠ¨æ€è›‡å½¢å·ç§¯ï¼Œé€šè¿‡è‡ªé€‚åº”åœ°èšç„¦äºç®¡çŠ¶ç»“æ„çš„ç»†é•¿æ›²çº¿å±€éƒ¨ç‰¹å¾ï¼Œå¢å¼ºå¯¹å‡ ä½•ç»“æ„çš„æ„ŸçŸ¥ã€‚ä¸å¯å˜å½¢å·ç§¯ä¸åŒï¼ŒDSConvè€ƒè™‘åˆ°ç®¡çŠ¶ç»“æ„çš„è›‡å½¢å½¢æ€ï¼Œå¹¶é€šè¿‡çº¦æŸè¡¥å……è‡ªç”±å­¦ä¹ è¿‡ç¨‹ï¼Œæœ‰é’ˆå¯¹æ€§åœ°å¢å¼ºå¯¹ç®¡çŠ¶ç»“æ„çš„æ„ŸçŸ¥ã€‚</p> 
<p>Â Â Â Â Â Â Â Â 2. <strong>é’ˆå¯¹å¤æ‚å’Œå¤šå˜çš„æ•´ä½“å½¢æ€çš„æŒ‘æˆ˜</strong>ï¼Œæå‡ºäº†ä¸€ç§å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥ã€‚åœ¨è¯¥æ–¹æ³•ä¸­ï¼ŒåŸºäºDSConvç”Ÿæˆå¤šä¸ªå½¢æ€å­¦å·ç§¯æ ¸æ¨¡æ¿ï¼Œä»ä¸åŒè§’åº¦è§‚å¯Ÿç›®æ ‡çš„ç»“æ„ç‰¹å¾ï¼Œå¹¶é€šè¿‡æ€»ç»“å…¸å‹çš„é‡è¦ç‰¹å¾å®ç°é«˜æ•ˆçš„ç‰¹å¾èåˆã€‚</p> 
<p>Â Â Â Â Â Â Â Â 3. <strong>é’ˆå¯¹ç®¡çŠ¶ç»“æ„åˆ†å‰²å®¹æ˜“å‡ºç°æ–­è£‚çš„é—®é¢˜</strong>ï¼Œæå‡ºäº†åŸºäºæŒä¹…åŒè°ƒï¼ˆPersistent Homologyï¼ŒPHï¼‰çš„æ‹“æ‰‘è¿ç»­æ€§çº¦æŸæŸå¤±å‡½æ•°ï¼ˆTCLossï¼‰ã€‚PHæ˜¯ä¸€ç§ä»å‡ºç°åˆ°æ¶ˆå¤±çš„æ‹“æ‰‘ç‰¹å¾å“åº”è¿‡ç¨‹ï¼Œèƒ½å¤Ÿä»å˜ˆæ‚çš„é«˜ç»´æ•°æ®ä¸­è·å–è¶³å¤Ÿçš„æ‹“æ‰‘ä¿¡æ¯ã€‚ç›¸å…³çš„è´è’‚æ•°æ˜¯æè¿°æ‹“æ‰‘ç©ºé—´è¿é€šæ€§çš„ä¸€ç§æ–¹å¼ã€‚ä¸å…¶ä»–æ–¹æ³•ä¸åŒï¼Œ<strong>TCLosså°†PHä¸ç‚¹é›†ç›¸ä¼¼æ€§ç›¸ç»“åˆ</strong>ï¼Œå¼•å¯¼ç½‘ç»œå…³æ³¨å…·æœ‰å¼‚å¸¸åƒç´ /ä½“ç´ åˆ†å¸ƒçš„æ–­è£‚åŒºåŸŸï¼Œä»æ‹“æ‰‘è§’åº¦å®ç°è¿ç»­æ€§çº¦æŸã€‚</p> 
<blockquote> 
 <p>æ€»ç»“:ä¸ºäº†å…‹æœæŒ‘æˆ˜ï¼Œæå‡ºäº†DSCNetæ¡†æ¶ï¼ŒåŒ…æ‹¬ç®¡çŠ¶æ„ŸçŸ¥å·ç§¯æ ¸ã€å¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥å’Œæ‹“æ‰‘è¿ç»­æ€§çº¦æŸæŸå¤±å‡½æ•°ã€‚DSConvå¢å¼ºäº†å¯¹ç»†é•¿æ›²çº¿ç‰¹å¾çš„æ„ŸçŸ¥ï¼Œå¤šè§†è§’ç‰¹å¾èåˆç­–ç•¥æé«˜äº†å¯¹å¤æ‚æ•´ä½“å½¢æ€çš„å¤„ç†èƒ½åŠ›ï¼Œè€ŒTCLossåŸºäºæŒä¹…åŒè°ƒå®ç°äº†ä»æ‹“æ‰‘è§’åº¦çš„è¿ç»­æ€§çº¦æŸã€‚</p> 
</blockquote> 
<p></p> 
<h2 id="%E4%B8%89%E3%80%81DySnakerConv%E7%9A%84%E6%A0%B8%E5%BF%83%E4%BB%A3%E7%A0%81%C2%A0">ä¸‰ã€DySnakerConvçš„æ ¸å¿ƒä»£ç Â </h2> 
<p>ä¸‹é¢çš„æ£€æµ‹å¤´å¯ä»¥ç”¨äºåˆ†å‰²å’Œç›®æ ‡æ£€æµ‹ï¼Œä½†æ˜¯å…¶ä¿®æ”¹æ•™ç¨‹æœ‰å·®åˆ«ã€‚ç›®æ ‡æ£€æµ‹çš„æ£€æµ‹å¤´æˆ‘å°±ä¸è®²äº†ï¼Œå¤§å®¶çœ‹æˆ‘ä¹‹å‰çš„æ£€æµ‹å¤´å¦‚ä½•æ·»åŠ çš„å°±å¯ä»¥ï¼Œéƒ½æ˜¯ä¸€æ ·çš„åªæ˜¯æ¢ä¸€ä¸ªåå­—ï¼Œæœ¬æ–‡ä¸»è¦é’ˆå¯¹äºåˆ†å‰²çš„è¯»è€…ã€‚</p> 
<pre><code>import torch
import torch.nn as nn
import math
from ultralytics.utils.checks import check_version

__all__ = ['Detect_DySnakeConv', 'Segment_DySnakeConv']

TORCH_1_10 = check_version(torch.__version__, '1.10.0')



def make_anchors(feats, strides, grid_cell_offset=0.5):
    """Generate anchors from features."""
    anchor_points, stride_tensor = [], []
    assert feats is not None
    dtype, device = feats[0].dtype, feats[0].device
    for i, stride in enumerate(strides):
        _, _, h, w = feats[i].shape
        sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x
        sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y
        sy, sx = torch.meshgrid(sy, sx, indexing='ij') if TORCH_1_10 else torch.meshgrid(sy, sx)
        anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))
        stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))
    return torch.cat(anchor_points), torch.cat(stride_tensor)


def dist2bbox(distance, anchor_points, xywh=True, dim=-1):
    """Transform distance(ltrb) to box(xywh or xyxy)."""
    lt, rb = distance.chunk(2, dim)
    x1y1 = anchor_points - lt
    x2y2 = anchor_points + rb
    if xywh:
        c_xy = (x1y1 + x2y2) / 2
        wh = x2y2 - x1y1
        return torch.cat((c_xy, wh), dim)  # xywh bbox
    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox



class DFL(nn.Module):
    """
    Integral module of Distribution Focal Loss (DFL).

    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391
    """

    def __init__(self, c1=16):
        """Initialize a convolutional layer with a given number of input channels."""
        super().__init__()
        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False)
        x = torch.arange(c1, dtype=torch.float)
        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))
        self.c1 = c1

    def forward(self, x):
        """Applies a transformer layer on input tensor 'x' and returns a tensor."""
        b, c, a = x.shape  # batch, channels, anchors
        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)
        # return self.conv(x.view(b, self.c1, 4, a).softmax(1)).view(b, 4, a)


class Proto(nn.Module):
    """YOLOv8 mask Proto module for segmentation models."""

    def __init__(self, c1, c_=256, c2=32):
        """
        Initializes the YOLOv8 mask Proto module with specified number of protos and masks.

        Input arguments are ch_in, number of protos, number of masks.
        """
        super().__init__()
        self.cv1 = Conv(c1, c_, k=3)
        self.upsample = nn.ConvTranspose2d(c_, c_, 2, 2, 0, bias=True)  # nn.Upsample(scale_factor=2, mode='nearest')
        self.cv2 = Conv(c_, c_, k=3)
        self.cv3 = Conv(c_, c2)

    def forward(self, x):
        """Performs a forward pass through layers using an upsampled input image."""
        return self.cv3(self.cv2(self.upsample(self.cv1(x))))


def autopad(k, p=None, d=1):  # kernel, padding, dilation
    """Pad to 'same' shape outputs."""
    if d &gt; 1:
        k = d * (k - 1) + 1 if isinstance(k, int) else [d * (x - 1) + 1 for x in k]  # actual kernel-size
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p


class Conv(nn.Module):
    """Standard convolution with args(ch_in, ch_out, kernel, stride, padding, groups, dilation, activation)."""
    default_act = nn.SiLU()  # default activation

    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):
        """Initialize Conv layer with given arguments including activation."""
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()

    def forward(self, x):
        """Apply convolution, batch normalization and activation to input tensor."""
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        """Perform transposed convolution of 2D data."""
        return self.act(self.conv(x))



class DSConv(nn.Module):
    def __init__(self, in_ch, out_ch, morph, kernel_size=3, if_offset=True, extend_scope=1):
        """
        The Dynamic Snake Convolution
        :param in_ch: input channel
        :param out_ch: output channel
        :param kernel_size: the size of kernel
        :param extend_scope: the range to expand (default 1 for this method)
        :param morph: the morphology of the convolution kernel is mainly divided into two types
                        along the x-axis (0) and the y-axis (1) (see the paper for details)
        :param if_offset: whether deformation is required, if it is False, it is the standard convolution kernel
        """
        super(DSConv, self).__init__()
        # use the &lt;offset_conv&gt; to learn the deformable offset
        self.offset_conv = nn.Conv2d(in_ch, 2 * kernel_size, 3, padding=1)
        self.bn = nn.BatchNorm2d(2 * kernel_size)
        self.kernel_size = kernel_size

        # two types of the DSConv (along x-axis and y-axis)
        self.dsc_conv_x = nn.Conv2d(
            in_ch,
            out_ch,
            kernel_size=(kernel_size, 1),
            stride=(kernel_size, 1),
            padding=0,
        )
        self.dsc_conv_y = nn.Conv2d(
            in_ch,
            out_ch,
            kernel_size=(1, kernel_size),
            stride=(1, kernel_size),
            padding=0,
        )

        self.gn = nn.GroupNorm(out_ch // 4, out_ch)
        self.act = Conv.default_act

        self.extend_scope = extend_scope
        self.morph = morph
        self.if_offset = if_offset

    def forward(self, f):
        offset = self.offset_conv(f)
        offset = self.bn(offset)
        # We need a range of deformation between -1 and 1 to mimic the snake's swing
        offset = torch.tanh(offset)
        input_shape = f.shape
        dsc = DSC(input_shape, self.kernel_size, self.extend_scope, self.morph)
        deformed_feature = dsc.deform_conv(f, offset, self.if_offset)
        if self.morph == 0:
            x = self.dsc_conv_x(deformed_feature.type(f.dtype))
            x = self.gn(x)
            x = self.act(x)
            return x
        else:
            x = self.dsc_conv_y(deformed_feature.type(f.dtype))
            x = self.gn(x)
            x = self.act(x)
            return x


# Core code, for ease of understanding, we mark the dimensions of input and output next to the code
class DSC(object):
    def __init__(self, input_shape, kernel_size, extend_scope, morph):
        self.num_points = kernel_size
        self.width = input_shape[2]
        self.height = input_shape[3]
        self.morph = morph
        self.extend_scope = extend_scope  # offset (-1 ~ 1) * extend_scope

        # define feature map shape
        """
        B: Batch size  C: Channel  W: Width  H: Height
        """
        self.num_batch = input_shape[0]
        self.num_channels = input_shape[1]

    """
    input: offset [B,2*K,W,H]  K: Kernel size (2*K: 2D image, deformation contains &lt;x_offset&gt; and &lt;y_offset&gt;)
    output_x: [B,1,W,K*H]   coordinate map
    output_y: [B,1,K*W,H]   coordinate map
    """

    def _coordinate_map_3D(self, offset, if_offset):
        device = offset.device
        # offset
        y_offset, x_offset = torch.split(offset, self.num_points, dim=1)

        y_center = torch.arange(0, self.width).repeat([self.height])
        y_center = y_center.reshape(self.height, self.width)
        y_center = y_center.permute(1, 0)
        y_center = y_center.reshape([-1, self.width, self.height])
        y_center = y_center.repeat([self.num_points, 1, 1]).float()
        y_center = y_center.unsqueeze(0)

        x_center = torch.arange(0, self.height).repeat([self.width])
        x_center = x_center.reshape(self.width, self.height)
        x_center = x_center.permute(0, 1)
        x_center = x_center.reshape([-1, self.width, self.height])
        x_center = x_center.repeat([self.num_points, 1, 1]).float()
        x_center = x_center.unsqueeze(0)

        if self.morph == 0:
            """
            Initialize the kernel and flatten the kernel
                y: only need 0
                x: -num_points//2 ~ num_points//2 (Determined by the kernel size)
                !!! The related PPT will be submitted later, and the PPT will contain the whole changes of each step
            """
            y = torch.linspace(0, 0, 1)
            x = torch.linspace(
                -int(self.num_points // 2),
                int(self.num_points // 2),
                int(self.num_points),
            )

            y, x = torch.meshgrid(y, x)
            y_spread = y.reshape(-1, 1)
            x_spread = x.reshape(-1, 1)

            y_grid = y_spread.repeat([1, self.width * self.height])
            y_grid = y_grid.reshape([self.num_points, self.width, self.height])
            y_grid = y_grid.unsqueeze(0)  # [B*K*K, W,H]

            x_grid = x_spread.repeat([1, self.width * self.height])
            x_grid = x_grid.reshape([self.num_points, self.width, self.height])
            x_grid = x_grid.unsqueeze(0)  # [B*K*K, W,H]

            y_new = y_center + y_grid
            x_new = x_center + x_grid

            y_new = y_new.repeat(self.num_batch, 1, 1, 1).to(device)
            x_new = x_new.repeat(self.num_batch, 1, 1, 1).to(device)

            y_offset_new = y_offset.detach().clone()

            if if_offset:
                y_offset = y_offset.permute(1, 0, 2, 3)
                y_offset_new = y_offset_new.permute(1, 0, 2, 3)
                center = int(self.num_points // 2)

                # The center position remains unchanged and the rest of the positions begin to swing
                # This part is quite simple. The main idea is that "offset is an iterative process"
                y_offset_new[center] = 0
                for index in range(1, center):
                    y_offset_new[center + index] = (y_offset_new[center + index - 1] + y_offset[center + index])
                    y_offset_new[center - index] = (y_offset_new[center - index + 1] + y_offset[center - index])
                y_offset_new = y_offset_new.permute(1, 0, 2, 3).to(device)
                y_new = y_new.add(y_offset_new.mul(self.extend_scope))

            y_new = y_new.reshape(
                [self.num_batch, self.num_points, 1, self.width, self.height])
            y_new = y_new.permute(0, 3, 1, 4, 2)
            y_new = y_new.reshape([
                self.num_batch, self.num_points * self.width, 1 * self.height
            ])
            x_new = x_new.reshape(
                [self.num_batch, self.num_points, 1, self.width, self.height])
            x_new = x_new.permute(0, 3, 1, 4, 2)
            x_new = x_new.reshape([
                self.num_batch, self.num_points * self.width, 1 * self.height
            ])
            return y_new, x_new

        else:
            """
            Initialize the kernel and flatten the kernel
                y: -num_points//2 ~ num_points//2 (Determined by the kernel size)
                x: only need 0
            """
            y = torch.linspace(
                -int(self.num_points // 2),
                int(self.num_points // 2),
                int(self.num_points),
            )
            x = torch.linspace(0, 0, 1)

            y, x = torch.meshgrid(y, x)
            y_spread = y.reshape(-1, 1)
            x_spread = x.reshape(-1, 1)

            y_grid = y_spread.repeat([1, self.width * self.height])
            y_grid = y_grid.reshape([self.num_points, self.width, self.height])
            y_grid = y_grid.unsqueeze(0)

            x_grid = x_spread.repeat([1, self.width * self.height])
            x_grid = x_grid.reshape([self.num_points, self.width, self.height])
            x_grid = x_grid.unsqueeze(0)

            y_new = y_center + y_grid
            x_new = x_center + x_grid

            y_new = y_new.repeat(self.num_batch, 1, 1, 1)
            x_new = x_new.repeat(self.num_batch, 1, 1, 1)

            y_new = y_new.to(device)
            x_new = x_new.to(device)
            x_offset_new = x_offset.detach().clone()

            if if_offset:
                x_offset = x_offset.permute(1, 0, 2, 3)
                x_offset_new = x_offset_new.permute(1, 0, 2, 3)
                center = int(self.num_points // 2)
                x_offset_new[center] = 0
                for index in range(1, center):
                    x_offset_new[center + index] = (x_offset_new[center + index - 1] + x_offset[center + index])
                    x_offset_new[center - index] = (x_offset_new[center - index + 1] + x_offset[center - index])
                x_offset_new = x_offset_new.permute(1, 0, 2, 3).to(device)
                x_new = x_new.add(x_offset_new.mul(self.extend_scope))

            y_new = y_new.reshape(
                [self.num_batch, 1, self.num_points, self.width, self.height])
            y_new = y_new.permute(0, 3, 1, 4, 2)
            y_new = y_new.reshape([
                self.num_batch, 1 * self.width, self.num_points * self.height
            ])
            x_new = x_new.reshape(
                [self.num_batch, 1, self.num_points, self.width, self.height])
            x_new = x_new.permute(0, 3, 1, 4, 2)
            x_new = x_new.reshape([
                self.num_batch, 1 * self.width, self.num_points * self.height
            ])
            return y_new, x_new

    """
    input: input feature map [N,C,D,W,H]ï¼›coordinate map [N,K*D,K*W,K*H] 
    output: [N,1,K*D,K*W,K*H]  deformed feature map
    """

    def _bilinear_interpolate_3D(self, input_feature, y, x):
        device = input_feature.device
        y = y.reshape([-1]).float()
        x = x.reshape([-1]).float()

        zero = torch.zeros([]).int()
        max_y = self.width - 1
        max_x = self.height - 1

        # find 8 grid locations
        y0 = torch.floor(y).int()
        y1 = y0 + 1
        x0 = torch.floor(x).int()
        x1 = x0 + 1

        # clip out coordinates exceeding feature map volume
        y0 = torch.clamp(y0, zero, max_y)
        y1 = torch.clamp(y1, zero, max_y)
        x0 = torch.clamp(x0, zero, max_x)
        x1 = torch.clamp(x1, zero, max_x)

        input_feature_flat = input_feature.flatten()
        input_feature_flat = input_feature_flat.reshape(
            self.num_batch, self.num_channels, self.width, self.height)
        input_feature_flat = input_feature_flat.permute(0, 2, 3, 1)
        input_feature_flat = input_feature_flat.reshape(-1, self.num_channels)
        dimension = self.height * self.width

        base = torch.arange(self.num_batch) * dimension
        base = base.reshape([-1, 1]).float()

        repeat = torch.ones([self.num_points * self.width * self.height
                             ]).unsqueeze(0)
        repeat = repeat.float()

        base = torch.matmul(base, repeat)
        base = base.reshape([-1])

        base = base.to(device)

        base_y0 = base + y0 * self.height
        base_y1 = base + y1 * self.height

        # top rectangle of the neighbourhood volume
        index_a0 = base_y0 - base + x0
        index_c0 = base_y0 - base + x1

        # bottom rectangle of the neighbourhood volume
        index_a1 = base_y1 - base + x0
        index_c1 = base_y1 - base + x1

        # get 8 grid values
        value_a0 = input_feature_flat[index_a0.type(torch.int64)].to(device)
        value_c0 = input_feature_flat[index_c0.type(torch.int64)].to(device)
        value_a1 = input_feature_flat[index_a1.type(torch.int64)].to(device)
        value_c1 = input_feature_flat[index_c1.type(torch.int64)].to(device)

        # find 8 grid locations
        y0 = torch.floor(y).int()
        y1 = y0 + 1
        x0 = torch.floor(x).int()
        x1 = x0 + 1

        # clip out coordinates exceeding feature map volume
        y0 = torch.clamp(y0, zero, max_y + 1)
        y1 = torch.clamp(y1, zero, max_y + 1)
        x0 = torch.clamp(x0, zero, max_x + 1)
        x1 = torch.clamp(x1, zero, max_x + 1)

        x0_float = x0.float()
        x1_float = x1.float()
        y0_float = y0.float()
        y1_float = y1.float()

        vol_a0 = ((y1_float - y) * (x1_float - x)).unsqueeze(-1).to(device)
        vol_c0 = ((y1_float - y) * (x - x0_float)).unsqueeze(-1).to(device)
        vol_a1 = ((y - y0_float) * (x1_float - x)).unsqueeze(-1).to(device)
        vol_c1 = ((y - y0_float) * (x - x0_float)).unsqueeze(-1).to(device)

        outputs = (value_a0 * vol_a0 + value_c0 * vol_c0 + value_a1 * vol_a1 +
                   value_c1 * vol_c1)

        if self.morph == 0:
            outputs = outputs.reshape([
                self.num_batch,
                self.num_points * self.width,
                1 * self.height,
                self.num_channels,
            ])
            outputs = outputs.permute(0, 3, 1, 2)
        else:
            outputs = outputs.reshape([
                self.num_batch,
                1 * self.width,
                self.num_points * self.height,
                self.num_channels,
            ])
            outputs = outputs.permute(0, 3, 1, 2)
        return outputs

    def deform_conv(self, input, offset, if_offset):
        y, x = self._coordinate_map_3D(offset, if_offset)
        deformed_feature = self._bilinear_interpolate_3D(input, y, x)
        return deformed_feature



class Detect_DySnakeConv(nn.Module):
    """YOLOv8 Detect Efficient head for detection models."""
    dynamic = False  # force grid reconstruction
    export = False  # export mode
    shape = None
    anchors = torch.empty(0)  # init
    strides = torch.empty(0)  # init

    def __init__(self, nc=80, ch=()):  # detection layer
        super().__init__()
        self.nc = nc  # number of classes
        self.nl = len(ch)  # number of detection layers
        self.reg_max = 16  # DFL channels (ch[0] // 16 to scale 4/8/12/16/20 for n/s/m/l/x)
        self.no = nc + self.reg_max * 4  # number of outputs per anchor
        self.stride = torch.zeros(self.nl)  # strides computed during build
        self.DySnakeConv = nn.ModuleList(nn.Sequential(DSConv(x, x, 0), DSConv(x, x, 0)) for x in ch) # DySnakeConv
        self.cv2 = nn.ModuleList(nn.Conv2d(x, 4 * self.reg_max, 1) for x in ch)
        self.cv3 = nn.ModuleList(nn.Conv2d(x, self.nc, 1) for x in ch)
        self.dfl = DFL(self.reg_max) if self.reg_max &gt; 1 else nn.Identity()

    def forward(self, x):
        """Concatenates and returns predicted bounding boxes and class probabilities."""
        shape = x[0].shape  # BCHW
        for i in range(self.nl):
            x[i] = self.DySnakeConv[i](x[i])
            x[i] = torch.cat((self.cv2[i](x[i]), self.cv3[i](x[i])), 1)
        if self.training:
            return x
        elif self.dynamic or self.shape != shape:
            self.anchors, self.strides = (x.transpose(0, 1) for x in make_anchors(x, self.stride, 0.5))
            self.shape = shape

        x_cat = torch.cat([xi.view(shape[0], self.no, -1) for xi in x], 2)
        if self.export and self.format in ('saved_model', 'pb', 'tflite', 'edgetpu', 'tfjs'):  # avoid TF FlexSplitV ops
            box = x_cat[:, :self.reg_max * 4]
            cls = x_cat[:, self.reg_max * 4:]
        else:
            box, cls = x_cat.split((self.reg_max * 4, self.nc), 1)
        dbox = dist2bbox(self.dfl(box), self.anchors.unsqueeze(0), xywh=True, dim=1) * self.strides
        y = torch.cat((dbox, cls.sigmoid()), 1)
        return y if self.export else (y, x)

    def bias_init(self):
        """Initialize Detect() biases, WARNING: requires stride availability."""
        m = self  # self.model[-1]  # Detect() module
        # cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1
        # ncf = math.log(0.6 / (m.nc - 0.999999)) if cf is None else torch.log(cf / cf.sum())  # nominal class frequency
        for a, b, s in zip(m.cv2, m.cv3, m.stride):  # from
            a.bias.data[:] = 1.0  # box
            b.bias.data[:m.nc] = math.log(5 / m.nc / (640 / s) ** 2)  # cls (.01 objects, 80 classes, 640 img)



class Segment_DySnakeConv(Detect_DySnakeConv):
    """YOLOv8 Segment head for segmentation models."""

    def __init__(self, nc=80, nm=32, npr=256, ch=()):
        """Initialize the YOLO model attributes such as the number of masks, prototypes, and the convolution layers."""
        super().__init__(nc, ch)
        self.nm = nm  # number of masks
        self.npr = npr  # number of protos
        self.proto = Proto(ch[0], self.npr, self.nm)  # protos
        self.detect = Detect_DySnakeConv.forward

        c4 = max(ch[0] // 4, self.nm)
        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nm, 1)) for x in ch)

    def forward(self, x):
        """Return model outputs and mask coefficients if training, otherwise return outputs and mask coefficients."""
        p = self.proto(x[0])  # mask protos
        bs = p.shape[0]  # batch size

        mc = torch.cat([self.cv4[i](x[i]).view(bs, self.nm, -1) for i in range(self.nl)], 2)  # mask coefficients
        x = self.detect(self, x)
        if self.training:
            return x, mc, p
        return (torch.cat([x, mc], 1), p) if self.export else (torch.cat([x[0], mc], 1), (x[1], mc, p))



</code></pre> 
<p></p> 
<h2 id="%E5%9B%9B%E3%80%81%E5%88%86%E5%89%B2%E6%A3%80%E6%B5%8B%E5%A4%B4%E4%BF%AE%E6%94%B9%E6%95%99%E7%A8%8B%C2%A0">å››ã€åˆ†å‰²æ£€æµ‹å¤´ä¿®æ”¹æ•™ç¨‹Â </h2> 
<p>ä¸‹é¢æˆ‘ä»¬æ¥æ•™å¤§å®¶ä¿®æ”¹åˆ†å‰²çš„æ£€æµ‹å¤´ï¼Œè¯æ˜æˆ‘æ²¡æœ‰æŠŠåˆ†å‰²çš„è¯»è€…å¿˜è®°äº†ï¼</p> 
<p></p> 
<hr> 
<h3 id="4.1%20%E4%BF%AE%E6%94%B9%E4%B8%80">4.1 ä¿®æ”¹ä¸€</h3> 
<p>ç¬¬ä¸€è¿˜æ˜¯å»ºç«‹æ–‡ä»¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°å¦‚ä¸‹ultralytics/nn/modulesæ–‡ä»¶å¤¹ä¸‹å»ºç«‹ä¸€ä¸ªç›®å½•åå­—å‘¢å°±æ˜¯'Addmodules'æ–‡ä»¶å¤¹ï¼ç„¶ååœ¨å…¶å†…éƒ¨å»ºç«‹ä¸€ä¸ªæ–°çš„pyæ–‡ä»¶å°†æ ¸å¿ƒä»£ç å¤åˆ¶ç²˜è´´è¿›å»å³å¯ã€‚</p> 
<p class="img-center"><img alt="" height="627" src="https://images2.imgbox.com/f8/e4/8QYaVtMK_o.png" width="411"></p> 
<p></p> 
<hr> 
<h3 id="4.2%20%E4%BF%AE%E6%94%B9%E4%BA%8C%C2%A0">4.2 ä¿®æ”¹äºŒÂ </h3> 
<p>ç¬¬äºŒæ­¥æˆ‘ä»¬åœ¨è¯¥ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–°çš„pyæ–‡ä»¶åå­—ä¸º'__init__.py'ï¼Œç„¶ååœ¨å…¶å†…éƒ¨å¯¼å…¥æˆ‘ä»¬çš„æ£€æµ‹å¤´å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚</p> 
<p><img alt="" height="522" src="https://images2.imgbox.com/e2/7a/cp83BZhi_o.png" width="926"></p> 
<p></p> 
<hr> 
<h3 id="4.3%20%E4%BF%AE%E6%94%B9%E4%B8%89%C2%A0">4.3 ä¿®æ”¹ä¸‰Â </h3> 
<p>ç¬¬ä¸‰æ­¥æˆ‘é—¨ä¸­åˆ°å¦‚ä¸‹æ–‡ä»¶'ultralytics/nn/tasks.py'è¿›è¡Œå¯¼å…¥å’Œæ³¨å†Œæˆ‘ä»¬çš„æ¨¡å—ï¼</p> 
<p><span style="color:#fe2c24;"><strong>ä»ä»Šå¤©å¼€å§‹ä»¥åçš„æ•™ç¨‹å°±éƒ½ç»Ÿä¸€æˆè¿™ä¸ªæ ·å­äº†ï¼Œå› ä¸ºæˆ‘é»˜è®¤å¤§å®¶ç”¨äº†æˆ‘ç¾¤å†…çš„æ–‡ä»¶æ¥è¿›è¡Œä¿®æ”¹ï¼ï¼</strong></span></p> 
<p><img alt="" height="459" src="https://images2.imgbox.com/8a/57/1BLzCoxP_o.png" width="1190"></p> 
<p></p> 
<hr> 
<h3 id="4.4%20%E4%BF%AE%E6%94%B9%E5%9B%9B%C2%A0">4.4 ä¿®æ”¹å››Â </h3> 
<p>æŒ‰ç…§æˆ‘çš„è¿›è¡Œæ·»åŠ å³å¯ï¼Œå½“ç„¶å…¶ä¸­æœ‰äº›æ£€æµ‹å¤´ä½ ä»¬çš„æ–‡ä»¶ä¸­å¯èƒ½æ²¡æœ‰ï¼Œæ— éœ€ç†ä¼šï¼Œä¸»è¦çœ‹å…¶å‘¨å›´çš„ä»£ç ä¸€ç›´æ¥å¯»æ‰¾å³å¯ï¼</p> 
<p><img alt="" height="751" src="https://images2.imgbox.com/b0/ae/flEU4xnp_o.png" width="1200"></p> 
<p></p> 
<hr> 
<h3 id="4.5%20%E4%BF%AE%E6%94%B9%E4%BA%94">4.5 ä¿®æ”¹äº”</h3> 
<p>æŒ‰ç…§æˆ‘ä¸‹é¢çš„æ·»åŠ ï¼Œåˆ†å‰²çš„æ£€æµ‹å¤´æ­¤å¤„æ·»åŠ ä¸¤ä¸ªè¯·æ³¨æ„ï¼</p> 
<p><img alt="" height="695" src="https://images2.imgbox.com/70/17/dSiaPJj9_o.png" width="1200"></p> 
<p></p> 
<hr> 
<h3 id="4.6%20%E4%BF%AE%E6%94%B9%E5%85%AD%C2%A0">4.6 ä¿®æ”¹å…­Â </h3> 
<p>åŒç†ï¼</p> 
<p><img alt="" height="674" src="https://images2.imgbox.com/19/65/X53iYqjG_o.png" width="1180"></p> 
<p></p> 
<hr> 
<h3 id="4.7%20%E4%BF%AE%E6%94%B9%E4%B8%83%C2%A0">4.7 ä¿®æ”¹ä¸ƒÂ </h3> 
<p>åŒç†ï¼ï¼</p> 
<p><img alt="" height="717" src="https://images2.imgbox.com/cc/40/BkbQ7OIp_o.png" width="1200"></p> 
<p></p> 
<hr> 
<h3 id="4.8%20%E4%BF%AE%E6%94%B9%E5%85%AB%C2%A0">4.8 ä¿®æ”¹å…«Â </h3> 
<p>åŒç†</p> 
<p><img alt="" height="406" src="https://images2.imgbox.com/82/ce/Yaphf9Wm_o.png" width="1200"></p> 
<p></p> 
<hr> 
<h3 id="4.9%20%E4%BF%AE%E6%94%B9%E4%B9%9D%C2%A0">4.9 ä¿®æ”¹ä¹Â </h3> 
<p>æ­¤å¤„è¯·æ³¨æ„åŸå…ˆæ˜¯ä¸€ä¸ª==å·ï¼Œç„¶åç°åœ¨å˜æˆin ç„¶åéœ€è¦é¢å¤–æ³¨æ„çš„æ˜¯æ­¤å¤„çš„mç³»ç»Ÿä¼šç»™è½¬åŒ–æˆå…¨å°å†™ï¼Œæ‰€ä»¥æˆ‘ä»¬çš„åå­—ä¹Ÿè¦å˜æˆå…¨æ˜¯å°å†™çš„ï¼ï¼ï¼ä»£ç æˆ‘å¤åˆ¶åˆ°ä¸‹é¢äº†å¤§å®¶å¤åˆ¶ç²˜è´´å³å¯ã€‚</p> 
<pre><code>    def cfg2task(cfg):
        """Guess from YAML dictionary."""
        m = cfg['head'][-1][-2].lower()  # output module name
        if m in ('classify', 'classifier', 'cls', 'fc'):
            return 'classify'
        if m == 'detect':
            return 'detect'
        if m in ('segment', 'segment_dysnakeconv'):
            return 'segment'
        if m == 'pose':
            return 'pose'
        else:
            return 'detect'
</code></pre> 
<p></p> 
<p><img alt="" height="705" src="https://images2.imgbox.com/44/57/vLJz6uTT_o.png" width="1046"></p> 
<p></p> 
<hr> 
<h3 id="4.10%20%E4%BF%AE%E6%94%B910%C2%A0">4.10 ä¿®æ”¹10Â </h3> 
<p>æŒ‰ç…§æˆ‘çš„ä¿®æ”¹ï¼Œæ­¤å¤„ä¸ºæœ€åä¸€æ­¥åé¢å¤åˆ¶yamlæ–‡ä»¶è¿è¡Œå³å¯ï¼ï¼ï¼</p> 
<p><img alt="" height="645" src="https://images2.imgbox.com/33/70/txaPQ04y_o.png" width="992"></p> 
<p></p> 
<hr> 
<h2 id="%E4%BA%94%E3%80%81%20%E5%88%86%E5%89%B2%E5%92%8C%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84yaml%E6%96%87%E4%BB%B6">äº”ã€ åˆ†å‰²å’Œç›®æ ‡æ£€æµ‹çš„yamlæ–‡ä»¶</h2> 
<h3 id="5.1%20%E5%88%86%E5%89%B2%E7%9A%84yaml%E6%96%87%E4%BB%B6">5.1 åˆ†å‰²çš„yamlæ–‡ä»¶</h3> 
<p>æ³¨æ„ä¸è¦å¤åˆ¶é”™äº†æŠ¥é”™ï¼ï¼æ­¤å¤„æ˜¯Segçš„yamlæ–‡ä»¶ã€‚</p> 
<pre><code># Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)

  - [[15, 18, 21], 1, Segment_DySnakeConv, [nc, 32, 256]]  # Detect(P3, P4, P5)
</code></pre> 
<p></p> 
<hr> 
<h3 id="5.2%20%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84yaml%E6%96%87%E4%BB%B6%C2%A0">5.2 ç›®æ ‡æ£€æµ‹çš„yamlæ–‡ä»¶Â </h3> 
<p>ç›®æ ‡æ£€æµ‹çš„æˆ‘ä¸Šé¢æ²¡æœ‰æä¾›æ•™ç¨‹ï¼Œä¹‹å‰çš„æ£€æµ‹å¤´æä¾›è¿‡å¾ˆå¤šäº†ï¼Œå¤§å®¶ç›´æ¥éšä¾¿æ‰¾ä¸€ä¸ªå°±è¡Œå°±æ˜¯åå­—ä¸ä¸€æ ·äº†ã€‚</p> 
<pre><code># Ultralytics YOLO ğŸš€, AGPL-3.0 license
# YOLOv8 object detection model with P3-P5 outputs. For Usage examples see https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80  # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov8n.yaml' will call yolov8.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.33, 0.25, 1024]  # YOLOv8n summary: 225 layers,  3157200 parameters,  3157184 gradients,   8.9 GFLOPs
  s: [0.33, 0.50, 1024]  # YOLOv8s summary: 225 layers, 11166560 parameters, 11166544 gradients,  28.8 GFLOPs
  m: [0.67, 0.75, 768]   # YOLOv8m summary: 295 layers, 25902640 parameters, 25902624 gradients,  79.3 GFLOPs
  l: [1.00, 1.00, 512]   # YOLOv8l summary: 365 layers, 43691520 parameters, 43691504 gradients, 165.7 GFLOPs
  x: [1.00, 1.25, 512]   # YOLOv8x summary: 365 layers, 68229648 parameters, 68229632 gradients, 258.5 GFLOPs

# YOLOv8.0n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]  # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]]  # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]]  # 3-P3/8
  - [-1, 6, C2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]]  # 5-P4/16
  - [-1, 6, C2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]]  # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]]  # 9

# YOLOv8.0n head
head:
  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 6], 1, Concat, [1]]  # cat backbone P4
  - [-1, 3, C2f, [512]]  # 12

  - [-1, 1, nn.Upsample, [None, 2, 'nearest']]
  - [[-1, 4], 1, Concat, [1]]  # cat backbone P3
  - [-1, 3, C2f, [256]]  # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]]  # cat head P4
  - [-1, 3, C2f, [512]]  # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]]  # cat head P5
  - [-1, 3, C2f, [1024]]  # 21 (P5/32-large)

  - [[15, 18, 21], 1, Detect_DySnakeConv, [nc]]  # Detect(P3, P4, P5)
</code></pre> 
<p></p> 
<hr> 
<h2 id="%E5%85%AD%E3%80%81%E6%9C%AC%E6%96%87%E6%80%BB%E7%BB%93">å…­ã€æœ¬æ–‡æ€»ç»“</h2> 
<p>åˆ°æ­¤æœ¬æ–‡çš„æ­£å¼åˆ†äº«å†…å®¹å°±ç»“æŸäº†ï¼Œåœ¨è¿™é‡Œç»™å¤§å®¶æ¨èæˆ‘çš„YOLOv8æ”¹è¿›æœ‰æ•ˆæ¶¨ç‚¹ä¸“æ ï¼Œæœ¬ä¸“æ ç›®å‰ä¸ºæ–°å¼€çš„å¹³å‡è´¨é‡åˆ†98åˆ†ï¼ŒåæœŸæˆ‘ä¼šæ ¹æ®å„ç§æœ€æ–°çš„å‰æ²¿é¡¶ä¼šè¿›è¡Œè®ºæ–‡å¤ç°ï¼Œä¹Ÿä¼šå¯¹ä¸€äº›è€çš„æ”¹è¿›æœºåˆ¶è¿›è¡Œè¡¥å……ï¼Œå¦‚æœå¤§å®¶è§‰å¾—æœ¬æ–‡å¸®åŠ©åˆ°ä½ äº†ï¼Œè®¢é˜…æœ¬ä¸“æ ï¼Œå…³æ³¨åç»­æ›´å¤šçš„æ›´æ–°~</p> 
<blockquote> 
 <p><strong><span style="color:#fe2c24;">ä¸“æ å›é¡¾ï¼š</span><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><a href="https://blog.csdn.net/java1314777/category_12483754.html" title="YOLOv8æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡">YOLOv8æ”¹è¿›ç³»åˆ—ä¸“æ â€”â€”æœ¬ä¸“æ æŒç»­å¤ä¹ å„ç§é¡¶ä¼šå†…å®¹â€”â€”ç§‘ç ”å¿…å¤‡</a></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p> 
</blockquote> 
<p><img alt="" height="396" src="https://images2.imgbox.com/22/a3/4queP3rt_o.gif" width="1200">â€‹</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2015154cd13031bb16f0f71c927975f5/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">ã€RT-DETRæœ‰æ•ˆæ”¹è¿›ã€‘å¸¦ä½ åˆ†æå¦‚ä½•ç¡®å®šæ”¹è¿›çš„åŸºç¡€æ¨¡å‹ï¼Œè§£å†³æ¨¡å‹æ— æ³•æ”¶æ•›ç²¾åº¦å¾ˆå·®çš„é—®é¢˜(ResNetå®˜æ–¹ä¸€æ¯”ä¸€å¤ç°)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f5be8481826532942e21383bfb8493d3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">å°†Github Copilotè½¬æ¢ä¸ºå…è´¹ä½¿ç”¨GPT-4</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 èœé¸Ÿç¨‹åºå‘˜åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>