<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PyTorch教程（六）：算数运算 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PyTorch教程（六）：算数运算" />
<meta property="og:description" content="import torch a = torch.rand(3,4) # tensor([[0.0422, 0.9152, 0.5486, 0.8753], # [0.3918, 0.6056, 0.0634, 0.9498], # [0.4444, 0.2209, 0.8165, 0.1533]]) b = torch.rand(4) # tensor([0.4145, 0.2913, 0.1655, 0.3705]) a &#43; b # tensor([[0.4567, 1.2065, 0.7141, 1.2458], # [0.8064, 0.8969, 0.2289, 1.3203], # [0.8589, 0.5122, 0.9819, 0.5238]]) torch.add(a,b) # tensor([[0.4567, 1.2065, 0.7141, 1.2458], # [0.8064, 0.8969, 0.2289, 1.3203], # [0.8589, 0.5122, 0.9819, 0.5238]]) torch.all(torch.eq(a&#43;b,torch.add(a,b))) # 判断是不是每一个位置对应的值都形同 tensor(True) torch.all(torch.eq(a-b,torch.sub(a,b))) tensor(True) torch.all(torch.eq(a*b,torch.mul(a,b))) tensor(True) torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/cf3eaca82ef60e495275f37d2d0b9ee0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-02-19T23:14:07+08:00" />
<meta property="article:modified_time" content="2021-02-19T23:14:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PyTorch教程（六）：算数运算</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <pre><code class="prism language-python"><span class="token keyword">import</span> torch

a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.0422, 0.9152, 0.5486, 0.8753],</span>
<span class="token comment">#        [0.3918, 0.6056, 0.0634, 0.9498],</span>
<span class="token comment">#        [0.4444, 0.2209, 0.8165, 0.1533]])</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([0.4145, 0.2913, 0.1655, 0.3705])</span>


a <span class="token operator">+</span> b
<span class="token comment"># tensor([[0.4567, 1.2065, 0.7141, 1.2458],</span>
<span class="token comment">#        [0.8064, 0.8969, 0.2289, 1.3203],</span>
<span class="token comment">#        [0.8589, 0.5122, 0.9819, 0.5238]])</span>
torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span>
<span class="token comment"># tensor([[0.4567, 1.2065, 0.7141, 1.2458],</span>
<span class="token comment">#        [0.8064, 0.8969, 0.2289, 1.3203],</span>
<span class="token comment">#        [0.8589, 0.5122, 0.9819, 0.5238]])</span>
torch<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token operator">+</span>b<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>add<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 判断是不是每一个位置对应的值都形同</span>
tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>

torch<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token operator">-</span>b<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>sub<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>

torch<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token operator">*</span>b<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>

torch<span class="token punctuation">.</span><span class="token builtin">all</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>eq<span class="token punctuation">(</span>a<span class="token operator">/</span>b<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>div<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
tensor<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<h2><a id="matmul_32"></a>矩阵相乘matmul</h2> 
<blockquote> 
 <p>注意： * 表示element-wise，相同位置的相乘，<br> 而matmul表示矩阵相乘</p> 
</blockquote> 
<pre><code class="prism language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[3., 3.],</span>
<span class="token comment">#        [3., 3.]])</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[1., 1.],</span>
<span class="token comment">#        [1., 1.]])</span>
torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment"># 矩阵相乘</span>
<span class="token comment">#tensor([[6., 6.],</span>
<span class="token comment">#        [6., 6.]])</span>
torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span> <span class="token comment"># 矩阵相乘</span>
<span class="token comment">#tensor([[6., 6.],</span>
<span class="token comment">#        [6., 6.]])</span>
a@b <span class="token comment"># 矩阵相乘</span>
<span class="token comment">#tensor([[6., 6.],</span>
<span class="token comment">#        [6., 6.]])</span>
</code></pre> 
<p>上面三种方式表示矩阵相乘，<code>torch.mm</code>只能支持2D的矩阵相乘，一般使用<code>torch.matmul</code>或者<code>a@b</code>来表示。</p> 
<pre><code class="prism language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">26</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">.</span>shape  <span class="token comment"># 4维矩阵相乘</span>
torch<span class="token punctuation">.</span>Size<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">26</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

b <span class="token operator">=</span> torch<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">64</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">)</span> <span class="token comment"># 自动进行Broadcasting</span>
</code></pre> 
<p>对于上面的4维矩阵相乘，前面的两维保持不变，后面的两维进行相乘。</p> 
<h2><a id="_65"></a>指数与平方根</h2> 
<pre><code class="prism language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>full<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>
<span class="token comment"># tensor([[3, 3],</span>
<span class="token comment">#        [3, 3]])</span>
a<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># 平方</span>
<span class="token comment"># tensor([[9, 9],</span>
<span class="token comment">#        [9, 9]])</span>
b <span class="token operator">=</span> a <span class="token operator">**</span> <span class="token number">2</span> <span class="token comment"># 平方</span>
<span class="token comment"># tensor([[9, 9],</span>
<span class="token comment">#        [9, 9]])</span>

b <span class="token operator">**</span> <span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span> <span class="token comment"># 开根号</span>
<span class="token comment"># tensor([[3., 3.],</span>
<span class="token comment">#        [3., 3.]])</span>

torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>double<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 开根号</span>
<span class="token comment"># tensor([[3., 3.],</span>
<span class="token comment">#        [3., 3.]], dtype=torch.float64)</span>

torch<span class="token punctuation">.</span>rsqrt<span class="token punctuation">(</span>b<span class="token punctuation">.</span>to<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>double<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 开根号之后求倒数</span>
<span class="token comment"># tensor([[0.3333, 0.3333],</span>
<span class="token comment">#        [0.3333, 0.3333]], dtype=torch.float64)</span>
</code></pre> 
<p>这里求平方根的时候为什么不能直接使用<code>b.sqrt()</code>?如果使用<code>b.sqrt()</code>会报如下错误：<code>RuntimeError: sqrt_vml_cpu not implemented for 'Long'</code>。原因是Long类型的数据不支持log对数运算, 为什么Tensor是Long类型? 因为创建List数组时默认使用的是int, 所以从List转成torch.Tensor后, 数据类型变成了Long。</p> 
<h2><a id="e_91"></a>以e为底的指数函数</h2> 
<pre><code class="prism language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 
<span class="token comment"># tensor([[2.7183, 2.7183],</span>
<span class="token comment">#        [2.7183, 2.7183]])</span>
torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>a<span class="token punctuation">)</span> <span class="token comment"># 默认以e为底</span>
<span class="token comment"># tensor([[1., 1.],</span>
<span class="token comment">#        [1., 1.]])</span>
</code></pre> 
<h2><a id="floorceiltruncfrac_101"></a>floor、ceil、trunc、frac</h2> 
<pre><code class="prism language-python">a<span class="token punctuation">.</span>floor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>ceil<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>trunc<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>a<span class="token punctuation">.</span>frac<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">.</span><span class="token punctuation">)</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token number">0.1400</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<ul><li>floor:向下取整</li><li>ceil：向上取整</li><li>trunc：裁剪整数部分</li><li>frac：裁剪小数部分</li></ul> 
<h2><a id="_111"></a>四舍五入</h2> 
<pre><code class="prism language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.499</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(3.)</span>
a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">3.50</span><span class="token punctuation">)</span>
a<span class="token punctuation">.</span><span class="token builtin">round</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(4.)</span>
</code></pre> 
<h2><a id="clamp_120"></a>clamp</h2>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/57fd5676d53bfdb46da2ee6797c85b8a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【机器学习】Ｋ折交叉验证StratifiedKFold的解析与使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/95ecebb9e070b227f49bed5cd52b7895/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">python中的除数_python中的除法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>