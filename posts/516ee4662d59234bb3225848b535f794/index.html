<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch学习笔记——timm库 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch学习笔记——timm库" />
<meta property="og:description" content="当使用ChatGPT帮我们工作的时候，确实很大一部分人就会失业，当然也有很大一部分人收益其中。我今天继续使用其帮我了解新的内容，也就是timm库。毫不夸张的说，Chat GPT比百分之80的博客讲的更清楚更好，仅次于源码。
当提到计算机视觉的深度学习框架时，PyTorch无疑是最受欢迎的选择之一。PyTorch拥有强大的自动求导功能、易于使用的API和广泛的社区支持。而针对计算机视觉任务，timm库则是一个值得推荐的PyTorch扩展库。timm（Timm is a model repository for PyTorch）库提供了预训练模型、模型构建块和模型训练的实用工具。timm库可以帮助开发者快速构建和训练深度学习模型，同时支持多种图像分类、分割和检测任务，特别是结合torch和torchvision的使用，对你训练模型，事半功倍。
本文将介绍timm库的基本用法，并使用timm库训练一个图像分类模型作为示例。本文将假设读者已经对PyTorch和计算机视觉的基本概念有一定的了解，下面详细说一下。
首先简单梳理一下timm的用途：
图像分类（Image Classification）：Timm库包含了许多用于图像分类的预训练模型，如ResNet、VGG、EfficientNet等。你可以使用这些模型进行图像分类任务，如图像分类、图像回归等。
使用EfficientNet模型进行图像分类：
model = timm.create_model(&#39;efficientnet_b0&#39;, pretrained=True) 使用ResNet模型进行图像分类：
model = timm.create_model(&#39;resnet50&#39;, pretrained=True) 目标检测（Object Detection）：Timm库提供了一系列在目标检测和物体识别任务上表现优秀的模型，如EfficientDet、YOLO、RetinaNet等。你可以使用这些模型进行目标检测和物体识别任务。
使用EfficientDet模型进行目标检测：
model = timm.create_model(&#39;efficientdet_d0&#39;, pretrained=True) 使用YOLOv5模型进行目标检测：
model = timm.create_model(&#39;yolov5s&#39;, pretrained=True) 图像分割（Image Segmentation）：Timm库支持各种图像分割模型，如DeepLab、U-Net、PSPNet等。你可以使用这些模型进行图像分割任务，例如语义分割、实例分割等。
使用DeepLabV3模型进行语义分割：
model = timm.create_model(&#39;deeplabv3_resnet50&#39;, pretrained=True) 使用PSPNet模型进行图像分割：
model = timm.create_model(&#39;pspnet_resnet50&#39;, pretrained=True) 模型微调和迁移学习：Timm库提供了方便的函数和工具，使你能够轻松地微调和迁移学习预训练模型。你可以使用Timm库中的模型作为基础模型，并在自己的数据集上进行微调。
使用预训练的ResNet模型进行微调： model = timm.create_model(&#39;resnet50&#39;, pretrained=True) # 在新数据集上进行微调 # ... 模型评估和验证：Timm库提供了各种评估指标和工具，用于模型的性能评估和验证。你可以使用这些工具来评估模型在不同任务上的性能，并进行模型选择和比较。
使用Timm库提供的评估工具进行模型性能评估 总之，Timm库是一个功能齐全的模型库，涵盖了图像分类、目标检测、图像分割等多个计算机视觉任务，并提供了方便的接口和实用工具，简化了模型开发和实验过程。你可以根据具体的需求使用Timm库中的不同模型和功能来完成相应的任务。
下面来简单学习一下。
1，安装timm库 timm库可以通过pip命令进行安装：
1
pip install timm
安装完成后，我们在Python脚本或者Jupyter Notebook中导入timm库。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/516ee4662d59234bb3225848b535f794/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-24T00:29:45+08:00" />
<meta property="article:modified_time" content="2023-05-24T00:29:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch学习笔记——timm库</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>当使用ChatGPT帮我们工作的时候，确实很大一部分人就会失业，当然也有很大一部分人收益其中。我今天继续使用其帮我了解新的内容，也就是timm库。毫不夸张的说，Chat GPT比百分之80的博客讲的更清楚更好，仅次于源码。</p> 
<p>　　当提到计算机视觉的深度学习框架时，PyTorch无疑是最受欢迎的选择之一。PyTorch拥有强大的自动求导功能、易于使用的API和广泛的社区支持。而针对计算机视觉任务，timm库则是一个值得推荐的PyTorch扩展库。timm（<strong>Timm is a model repository for PyTorch</strong>）库提供了预训练模型、模型构建块和模型训练的实用工具。timm库可以帮助开发者快速构建和训练深度学习模型，同时支持多种图像分类、分割和检测任务，特别是结合torch和torchvision的使用，对你训练模型，事半功倍。</p> 
<p>　　本文将介绍timm库的基本用法，并使用timm库训练一个图像分类模型作为示例。本文将假设读者已经对PyTorch和计算机视觉的基本概念有一定的了解，下面详细说一下。</p> 
<p>　　首先简单梳理一下timm的用途：</p> 
<ol><li> <p>图像分类（Image Classification）：Timm库包含了许多用于图像分类的预训练模型，如ResNet、VGG、EfficientNet等。你可以使用这些模型进行图像分类任务，如图像分类、图像回归等。</p> 
  <ul><li> <p>使用EfficientNet模型进行图像分类：</p> <p><code>model = timm.create_model('efficientnet_b0', pretrained=True) </code></p> </li><li> <p>使用ResNet模型进行图像分类：</p> <p><code>model = timm.create_model('resnet50', pretrained=True) </code></p> </li></ul></li><li> <p>目标检测（Object Detection）：Timm库提供了一系列在目标检测和物体识别任务上表现优秀的模型，如EfficientDet、YOLO、RetinaNet等。你可以使用这些模型进行目标检测和物体识别任务。</p> 
  <ul><li> <p>使用EfficientDet模型进行目标检测：</p> <p><code>model = timm.create_model('efficientdet_d0', pretrained=True) </code></p> </li><li> <p>使用YOLOv5模型进行目标检测：</p> <p><code>model = timm.create_model('yolov5s', pretrained=True) </code></p> </li></ul></li><li> <p>图像分割（Image Segmentation）：Timm库支持各种图像分割模型，如DeepLab、U-Net、PSPNet等。你可以使用这些模型进行图像分割任务，例如语义分割、实例分割等。</p> 
  <ul><li> <p>使用DeepLabV3模型进行语义分割：</p> <p><code>model = timm.create_model('deeplabv3_resnet50', pretrained=True) </code></p> </li><li> <p>使用PSPNet模型进行图像分割：</p> <p><code>model = timm.create_model('pspnet_resnet50', pretrained=True) </code></p> </li></ul></li><li> <p>模型微调和迁移学习：Timm库提供了方便的函数和工具，使你能够轻松地微调和迁移学习预训练模型。你可以使用Timm库中的模型作为基础模型，并在自己的数据集上进行微调。</p> 
  <ul><li>使用预训练的ResNet模型进行微调： <p><code>model = timm.create_model('resnet50', pretrained=True) # 在新数据集上进行微调 # ... </code></p> </li></ul></li><li> <p>模型评估和验证：Timm库提供了各种评估指标和工具，用于模型的性能评估和验证。你可以使用这些工具来评估模型在不同任务上的性能，并进行模型选择和比较。</p> 
  <ul><li>使用Timm库提供的评估工具进行模型性能评估</li></ul></li></ol> 
<p>　　总之，Timm库是一个功能齐全的模型库，涵盖了图像分类、目标检测、图像分割等多个计算机视觉任务，并提供了方便的接口和实用工具，简化了模型开发和实验过程。你可以根据具体的需求使用Timm库中的不同模型和功能来完成相应的任务。</p> 
<p>　　下面来简单学习一下。</p> 
<h4>1，安装timm库</h4> 
<p>　　timm库可以通过pip命令进行安装：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> </td><td> <p><code>pip install timm</code></p> </td></tr></tbody></table> 
<p>　　安装完成后，我们在Python脚本或者Jupyter Notebook中导入timm库。</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> </td><td> <p><code>import timm</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<h4>2，加载预训练模型</h4> 
<p>　　timm库提供了多个预训练模型，这些模型可以在ImageNet等数据集上进行预训练，也可以在其他数据集上进行微调。</p> 
<p>　　加载预训练模型的代码非常简单，下面我们加载需要的预训练模型权重：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> </td><td> <p><code>import timm</code></p> <p></p> <p><code>m = timm.create_model(</code><code>'vgg16'</code><code>, pretrained=True)</code></p> <p><code>m.eval()</code></p> </td></tr></tbody></table> 
<p>　　上面代码就会创建一个VGG-16的预训练模型，我们可以通过修改模型名称来加载其他预训练模型，例如：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> </td><td> <p><code>model = timm.create_model(</code><code>'efficientnet_b0'</code><code>, pretrained=True)</code></p> </td></tr></tbody></table> 
<p>　　上面代码就会创建一个EfficientNet-B0的预训练模型。</p> 
<p>　　加载所有的预训练模型列表（pprint是美化打印的标准库）：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> </td><td> <p><code>import timm</code></p> <p><code>from</code> <code>pprint import pprint</code></p> <p><code>model_names = timm.list_models(pretrained=True)</code></p> <p><code>pprint(model_names)</code></p> <p><code>&gt;&gt;&gt; [</code><code>'adv_inception_v3'</code><code>,</code></p> <p><code> </code><code>'cspdarknet53'</code><code>,</code></p> <p><code> </code><code>'cspresnext50'</code><code>,</code></p> <p><code> </code><code>'densenet121'</code><code>,</code></p> <p><code> </code><code>'densenet161'</code><code>,</code></p> <p><code> </code><code>'densenet169'</code><code>,</code></p> <p><code> </code><code>'densenet201'</code><code>,</code></p> <p><code> </code><code>'densenetblur121d'</code><code>,</code></p> <p><code> </code><code>'dla34'</code><code>,</code></p> <p><code> </code><code>'dla46_c'</code><code>,</code></p> <p><code>...</code></p> <p><code>]</code></p> </td></tr></tbody></table> 
<p>　　利用通配符加载所有的预训练模型列表：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> </td><td> <p><code>import timm</code></p> <p><code>from</code> <code>pprint import pprint</code></p> <p><code>model_names = timm.list_models(</code><code>'*resne*t*'</code><code>)</code></p> <p><code>pprint(model_names)</code></p> <p><code>&gt;&gt;&gt; [</code><code>'cspresnet50'</code><code>,</code></p> <p><code> </code><code>'cspresnet50d'</code><code>,</code></p> <p><code> </code><code>'cspresnet50w'</code><code>,</code></p> <p><code> </code><code>'cspresnext50'</code><code>,</code></p> <p><code>...</code></p> <p><code>]</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<h4>3，构建自定义模型</h4> 
<p>　　如果需要自定义模型，我们可以使用timm库提供的模型构建块。模型构建块是模型的组成部分，可以灵活的组合和定制。例如我们可以使用timm库提供的ConvBnAct模块来定义一个卷积-BatchNorm-ReLU的模型构建块：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> </td><td> <p><code>import torch.nn </code><code>as</code> <code>nn</code></p> <p><code>from</code> <code>timm.models.layers import ConvBnAct</code></p> <p></p> <p><code>block = ConvBnAct(in_channels=3, out_channels=64, kernel_size=3, stride=1, act_layer=nn.ReLU)</code></p> <p><code>print(block)</code></p> </td></tr></tbody></table> 
<p>　　这个代码会创建一个输入通道为3、输出通道为64、卷积核大小为3、步长为1、激活函数为ReLU的卷积-BatchNorm-ReLU模块。</p> 
<p>　　我们打印一下，可以清晰的看到结果：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> </td><td> <p><code>ConvNormAct(</code></p> <p><code>  </code><code>(conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)</code></p> <p><code>  </code><code>(bn): BatchNormAct2d(</code></p> <p><code>    </code><code>64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True</code></p> <p><code>    </code><code>(drop): Identity()</code></p> <p><code>    </code><code>(act): ReLU(inplace=True)</code></p> <p><code>  </code><code>)</code></p> <p><code>)</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<p>　　再来一个示例：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> </td><td> <p><code>import timm</code></p> <p></p> <p><code>class</code> <code>CustomModel(timm.models.VisionTransformer):</code></p> <p><code>    </code><code>def __init__(self, **kwargs):</code></p> <p><code>        </code><code>super().__init__(**kwargs)</code></p> <p><code>        </code><code>self.head = torch.nn.Linear(self.head.in_features, num_classes)</code></p> <p></p> <p><code>model = CustomModel(img_size=224, patch_size=16, embed_dim=768, depth=12, num_heads=12, num_classes=100)</code></p> </td></tr></tbody></table> 
<p>　　在上面的代码中，我们创建了一个继承自timm库中VisionTransformer的自定义模型，并修改了模型的输出层以适应我们的任务。</p> 
<h4>4，训练图像分类模型</h4> 
<p>　　下面我们将介绍如何使用timm库训练和测试图像分类模型。timm库是一个用于计算机视觉任务的PyTorch库，它提供了许多预训练模型和常用的计算机视觉工具。我们将使用CIFAR-10数据集作为示例。</p> 
<p>1，准备数据集</p> 
<p>　　首先，我们需要准备CIFAR-10数据集。我们可以使用torchvision库来下载和加载数据集：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> </td><td> <p><code>import torch</code></p> <p><code>import torchvision</code></p> <p><code>import torchvision.transforms </code><code>as</code> <code>transforms</code></p> <p></p> <p><code># 数据预处理</code></p> <p><code>transform = transforms.Compose([</code></p> <p><code>    </code><code>transforms.RandomHorizontalFlip(),</code></p> <p><code>    </code><code>transforms.RandomCrop(32, padding=4),</code></p> <p><code>    </code><code>transforms.ToTensor(),</code></p> <p><code>    </code><code>transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</code></p> <p><code>])</code></p> <p></p> <p><code># 加载CIFAR-10数据集</code></p> <p><code>trainset = torchvision.datasets.CIFAR10(root=</code><code>'./data'</code><code>, train=True, download=True, transform=transform)</code></p> <p><code>trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)</code></p> <p></p> <p><code>testset = torchvision.datasets.CIFAR10(root=</code><code>'./data'</code><code>, train=False, download=True, transform=transform)</code></p> <p><code>testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<p>2，创建模型</p> 
<p>　　接下来，我们将使用timm库创建一个预训练的ResNet50模型，并修改输出层以适应CIFAR-10数据集：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> </td><td> <p><code>import timm</code></p> <p></p> <p><code>model = timm.create_model(</code><code>'resnet50'</code><code>, pretrained=True, num_classes=10)</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<p>3，训练模型</p> 
<p>　　现在我们可以开始训练模型。我们将使用交叉熵损失函数和Adam优化器：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> <p>19</p> <p>20</p> <p>21</p> <p>22</p> <p>23</p> <p>24</p> <p>25</p> <p>26</p> </td><td> <p><code>import torch.optim </code><code>as</code> <code>optim</code></p> <p></p> <p><code>criterion = torch.nn.CrossEntropyLoss()</code></p> <p><code>optimizer = optim.Adam(model.parameters(), lr=0.001)</code></p> <p></p> <p><code># 训练模型</code></p> <p><code>num_epochs = 10</code></p> <p><code>device = torch.device(</code><code>"cuda:0"</code> <code>if</code> <code>torch.cuda.is_available() </code><code>else</code> <code>"cpu"</code><code>)</code></p> <p><code>model.to(device)</code></p> <p></p> <p><code>for</code> <code>epoch </code><code>in</code> <code>range(num_epochs):</code></p> <p><code>    </code><code>running_loss = 0.0</code></p> <p><code>    </code><code>for</code> <code>i, data </code><code>in</code> <code>enumerate(trainloader, 0):</code></p> <p><code>        </code><code>inputs, labels = data</code></p> <p><code>        </code><code>inputs, labels = inputs.to(device), labels.to(device)</code></p> <p></p> <p><code>        </code><code>optimizer.zero_grad()</code></p> <p></p> <p><code>        </code><code>outputs = model(inputs)</code></p> <p><code>        </code><code>loss = criterion(outputs, labels)</code></p> <p><code>        </code><code>loss.backward()</code></p> <p><code>        </code><code>optimizer.step()</code></p> <p></p> <p><code>        </code><code>running_loss += loss.item()</code></p> <p></p> <p><code>    </code><code>print(f</code><code>"Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}"</code><code>)</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<p>4，测试模型</p> 
<p>　　训练完成后，我们可以使用测试数据集评估模型的性能：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> </td><td> <p><code>correct = 0</code></p> <p><code>total = 0</code></p> <p><code>model.eval()</code></p> <p></p> <p><code>with torch.no_grad():</code></p> <p><code>    </code><code>for</code> <code>data </code><code>in</code> <code>testloader:</code></p> <p><code>        </code><code>images, labels = data</code></p> <p><code>        </code><code>images, labels = images.to(device), labels.to(device)</code></p> <p></p> <p><code>        </code><code>outputs = model(images)</code></p> <p><code>        </code><code>_, predicted = torch.max(outputs.data, 1)</code></p> <p><code>        </code><code>total += labels.size(0)</code></p> <p><code>        </code><code>correct += (predicted == labels).sum().item()</code></p> <p></p> <p><code>print(f</code><code>"Accuracy on test set: {100 * correct / total}%"</code><code>)</code></p> </td></tr></tbody></table> 
<p>5，整体图像分类模型代码</p> 
<p>　　下面是一个简单的图像分类示例，使用timm库中的ResNet50模型：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> <p>19</p> <p>20</p> <p>21</p> <p>22</p> <p>23</p> <p>24</p> <p>25</p> <p>26</p> <p>27</p> <p>28</p> <p>29</p> <p>30</p> <p>31</p> <p>32</p> <p>33</p> <p>34</p> <p>35</p> <p>36</p> <p>37</p> <p>38</p> <p>39</p> <p>40</p> <p>41</p> <p>42</p> <p>43</p> <p>44</p> <p>45</p> <p>46</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p><code>from</code> <code>PIL import Image</code></p> <p><code>import torchvision.transforms </code><code>as</code> <code>transforms</code></p> <p></p> <p><code># 加载ResNet50模型</code></p> <p><code>model = timm.create_model(</code><code>'vgg16'</code><code>, pretrained=True)</code></p> <p></p> <p><code># 将模型设置为评估模式</code></p> <p><code>model.eval()</code></p> <p></p> <p><code># 加载图像并进行预处理</code></p> <p><code>image = Image.open(r</code><code>"D:\Desktop\workdata\data\segmentation_dataset\images\Abyssinian_24.jpg"</code><code>)</code></p> <p><code># 定义图像预处理转换</code></p> <p><code>preprocess = transforms.Compose([</code></p> <p><code>    </code><code>transforms.Resize((256, 256)),  # 调整图像大小为256x256</code></p> <p><code>    </code><code>transforms.ToTensor(),  # 转换为Tensor类型</code></p> <p><code>    </code><code>transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # 归一化</code></p> <p><code>])</code></p> <p></p> <p><code># 应用预处理转换</code></p> <p><code>processed_image = preprocess(image)</code></p> <p></p> <p><code># 查看处理后的图像形状和数值范围</code></p> <p><code>print(</code><code>"Processed image shape:"</code><code>, processed_image.shape)</code></p> <p><code>print(</code><code>"Processed image range:"</code><code>, processed_image.min(), </code><code>"-"</code><code>, processed_image.max())</code></p> <p></p> <p><code># 5. 可选：将处理后的图像转换回PIL图像对象</code></p> <p><code>processed_pil_image = transforms.ToPILImage()(processed_image)</code></p> <p></p> <p><code># 6. 可选：显示处理后的图像</code></p> <p><code>processed_pil_image.show()</code></p> <p></p> <p></p> <p><code># 将输入张量转换为批处理张量</code></p> <p><code>input_batch = processed_image.unsqueeze(0)</code></p> <p></p> <p><code># 将输入张量传递给模型并获取输出</code></p> <p><code>with torch.no_grad():</code></p> <p><code>    </code><code>output = model(input_batch)</code></p> <p></p> <p><code># 获取预测结果</code></p> <p><code>_, predicted = torch.max(output.data, 1)</code></p> <p></p> <p><code># 打印预测结果</code></p> <p><code>print(predicted.item())</code></p> </td></tr></tbody></table> 
<p>　　</p> 
<p>　　在上面的代码中，我们首先加载了ResNet50模型，并将其设置为评估模式。然后，我们加载了一个图像，并使用timm库中的预处理函数对其进行预处理。接下来，我们将输入张量转换为批处理张量，并将其传递给模型以获取输出。最后，我们使用torch.max函数获取预测结果，并将其打印出来。</p> 
<h4>5，特征提取</h4> 
<p>　　timm中所有模型都可以从模型中获取各种类型的特征，用于除分类之外的任务。</p> 
<p>1，获取Penultimate Layer Features:</p> 
<p>　　Penultimate Layer Features的中文含义是 "倒数第2层的特征"，即 classifier 之前的特征。timm 库可以通过多种方式获得倒数第二个模型层的特征，而无需进行模型的手术。</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p><code>m = timm.create_model(</code><code>'resnet50'</code><code>, pretrained=True, num_classes=1000)</code></p> <p><code>o = m(torch.randn(2, 3, 224, 224))</code></p> <p><code>print(f</code><code>'Pooled shape: {o.shape}'</code><code>)</code></p> <p><code># Pooled shape: torch.Size([2, 2048])</code></p> </td></tr></tbody></table> 
<p>　　获取分类器之后的特征：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p><code>m = timm.create_model(</code><code>'ese_vovnet19b_dw'</code><code>, pretrained=True)</code></p> <p><code>o = m(torch.randn(2, 3, 224, 224))</code></p> <p><code>print(f</code><code>'Original shape: {o.shape}'</code><code>)</code></p> <p><code>m.reset_classifier(0)</code></p> <p><code>o = m(torch.randn(2, 3, 224, 224))</code></p> <p><code>print(f</code><code>'Pooled shape: {o.shape}'</code><code>)</code></p> <p><code># Pooled shape: torch.Size([2, 1024])</code></p> </td></tr></tbody></table> 
<p>　　输出多尺度特征：默认情况下，大多数模型将输出5个stride（并非所有模型都有那么多），第一个从 stride=2开始（有些从1，4开始）。</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p><code>m = timm.create_model(</code><code>'resnest26d'</code><code>, features_only=True, pretrained=True)</code></p> <p><code>o = m(torch.randn(2, 3, 224, 224))</code></p> <p><code>for</code> <code>x </code><code>in</code> <code>o:</code></p> <p><code>  </code><code>print(x.shape)</code></p> <p></p> <p><code># output</code></p> <p><code>torch.Size([2, 64, 112, 112])</code></p> <p><code>torch.Size([2, 256, 56, 56])</code></p> <p><code>torch.Size([2, 512, 28, 28])</code></p> <p><code>torch.Size([2, 1024, 14, 14])</code></p> <p><code>torch.Size([2, 2048, 7, 7])</code></p> </td></tr></tbody></table> 
<p>　　当你在使用timm库进行特征提取时，可以选择使用<code>create_model</code>函数的<code>features_only</code>参数来直接返回模型的特征提取部分，而不包括分类器部分。这可以帮助简化代码，避免手动移除最后一层分类器。</p> 
<p>　　也可以手动去除，代码如下：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> <p>19</p> <p>20</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p></p> <p><code># 1. 加载预训练模型</code></p> <p><code>model = timm.create_model(</code><code>'resnet50'</code><code>, pretrained=True)</code></p> <p></p> <p><code># 2. 移除最后一层分类器</code></p> <p><code>model = torch.nn.Sequential(*list(model.children())[:-1])</code></p> <p></p> <p><code># 3. 设置模型为评估模式</code></p> <p><code>model.eval()</code></p> <p></p> <p><code># 4. 加载图像</code></p> <p><code>input = torch.randn(1, 3, 224, 224)  # 假设输入为224x224的RGB图像</code></p> <p></p> <p><code># 5. 特征提取</code></p> <p><code>features = model(input)</code></p> <p></p> <p><code># 6. 打印提取到的特征</code></p> <p><code>print(</code><code>"Features shape:"</code><code>, features.shape)</code></p> </td></tr></tbody></table> 
<p>　　　　在上述示例中，我们使用timm库加载了一个预训练的ResNet-50模型，并通过移除最后一层分类器来获得特征提取模型。然后，我们将模型设置为评估模式（<code>model.eval()</code>）以确保不进行训练。接下来，我们加载输入图像，并将其传递给模型以获取特征表示。最后，我们打印出提取到的特征的形状。</p> 
<h4>6，模型融合</h4> 
<p>　　模型融合是一种提高模型性能的有效方法。当涉及到更复杂的模型融合时，以下是一些深层次的技巧和注意事项：</p> 
<ol><li> <p><strong>模型选择和组合</strong>：选择具有不同架构和特性的模型进行融合，例如卷积神经网络（CNN）、循环神经网络（RNN）和注意力机制（Attention）。确保选择的模型能够相互补充，以提高整体性能。</p> </li><li> <p><strong>特征融合</strong>：除了融合模型输出，还可以考虑融合模型的中间层特征。通过提取和融合模型的不同层级特征，可以获得更丰富和多样化的信息。</p> </li><li> <p><strong>加权融合</strong>：为每个模型分配适当的权重，以平衡其贡献。权重可以基于预训练模型的性能、验证集表现等进行选择，也可以通过训练得到。</p> </li><li> <p><strong>模型蒸馏</strong>：使用一个更大、更复杂的模型（教师模型）来指导训练一个较小、更轻量级的模型（学生模型）。学生模型可以通过蒸馏教师模型的知识，从而提高模型的泛化能力。</p> </li><li> <p><strong>集成学习</strong>：除了简单的模型融合，可以尝试集成学习方法，如投票、堆叠（stacking）、混合（blending）等。这些方法通过结合多个模型的预测结果，提高模型的鲁棒性和准确性。</p> </li><li> <p><strong>数据增强</strong>：对训练数据进行多样化的增强操作，如随机裁剪、旋转、翻转等，以增加数据的多样性和模型的鲁棒性。确保在融合模型中使用相同的数据增强方式，以保持一致性。</p> </li><li> <p><strong>模型选择和调优</strong>：通过交叉验证等方法，选择最佳的模型组合并进行超参数调优。可以使用网格搜索、随机搜索等技术来搜索最佳超参数组合。</p> </li></ol> 
<p>　　总之，模型融合是一个灵活且有挑战性的任务，需要结合具体问题和数据集来进行调整和优化。不同的技巧和策略适用于不同的场景，因此需要不断实验和调整以找到最佳的模型融合方法。</p> 
<p>　　以下是一个使用timm库进行模型融合的示例：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> <p>19</p> <p>20</p> <p>21</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p></p> <p><code>class</code> <code>ModelEnsemble(torch.nn.Module):</code></p> <p><code>    </code><code>def __init__(self, models):</code></p> <p><code>        </code><code>super().__init__()</code></p> <p><code>        </code><code>self.models = torch.nn.ModuleList(models)</code></p> <p></p> <p><code>    </code><code>def forward(self, x):</code></p> <p><code>        </code><code>outputs = [model(x) </code><code>for</code> <code>model </code><code>in</code> <code>self.models]</code></p> <p><code>        </code><code>return</code> <code>torch.mean(torch.stack(outputs), dim=0)</code></p> <p></p> <p><code># 加载多个预训练模型</code></p> <p><code>model1 = timm.create_model(</code><code>'resnet18'</code><code>, pretrained=True, num_classes=100)</code></p> <p><code>model2 = timm.create_model(</code><code>'vgg16'</code><code>, pretrained=True, num_classes=100)</code></p> <p></p> <p><code># 创建模型融合</code></p> <p><code>ensemble = ModelEnsemble([model1, model2])</code></p> <p></p> <p><code># 使用融合模型进行预测</code></p> <p><code>output = ensemble(input_tensor)</code></p> </td></tr></tbody></table> 
<p>　　在上面的代码中，我们首先加载了两个预训练模型。然后，我们创建了一个模型融合类，该类将多个模型的输出进行平均。最后，我们使用融合模型进行预测。</p> 
<p>　　我们打印一下模型结构，我省略一些代码，只show关键点：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> <p>19</p> <p>20</p> <p>21</p> <p>22</p> <p>23</p> <p>24</p> <p>25</p> <p>26</p> <p>27</p> <p>28</p> <p>29</p> <p>30</p> <p>31</p> <p>32</p> <p>33</p> <p>34</p> <p>35</p> <p>36</p> <p>37</p> </td><td> <p><code>ModelEnsemble(</code></p> <p><code>  </code><code>(models): ModuleList(</code></p> <p><code>    </code><code>(0): ResNet(</code></p> <p><code>      </code><code>(conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)</code></p> <p><code>      </code><code>(bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)</code></p> <p><code>      </code><code>(act1): ReLU(inplace=True)</code></p> <p><code>      </code><code>(maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)</code></p> <p><code>      </code><code>(layer1): Sequential(</code></p> <p><code>      </code><code>........ （这里省略了ResNet的网络结构）</code></p> <p><code>      </code><code>)</code></p> <p><code>      </code><code>(global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))</code></p> <p><code>      </code><code>(fc): Linear(in_features=512, out_features=100, bias=True)</code></p> <p><code>    </code><code>)</code></p> <p><code>    </code><code>(1): VGG(</code></p> <p><code>      </code><code>(features): Sequential(</code></p> <p><code>        </code><code>(0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</code></p> <p><code>        </code><code>(1): ReLU(inplace=True)</code></p> <p><code>        </code><code>(2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))</code></p> <p><code>        </code><code>(3): ReLU(inplace=True)</code></p> <p><code>        </code><code>(4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</code></p> <p><code>        </code><code>.......(这里省略了VGG16的模型结构)</code></p> <p><code>      </code><code>)</code></p> <p><code>      </code><code>(pre_logits): ConvMlp(</code></p> <p><code>        </code><code>(fc1): Conv2d(512, 4096, kernel_size=(7, 7), stride=(1, 1))</code></p> <p><code>        </code><code>(act1): ReLU(inplace=True)</code></p> <p><code>        </code><code>(drop): Dropout(p=0.0, inplace=False)</code></p> <p><code>        </code><code>(fc2): Conv2d(4096, 4096, kernel_size=(1, 1), stride=(1, 1))</code></p> <p><code>        </code><code>(act2): ReLU(inplace=True)</code></p> <p><code>      </code><code>)</code></p> <p><code>      </code><code>(head): ClassifierHead(</code></p> <p><code>        </code><code>(global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))</code></p> <p><code>        </code><code>(fc): Linear(in_features=4096, out_features=100, bias=True)</code></p> <p><code>        </code><code>(flatten): Identity()</code></p> <p><code>      </code><code>)</code></p> <p><code>    </code><code>)</code></p> <p><code>  </code><code>)</code></p> <p><code>)</code></p> </td></tr></tbody></table> 
<p>　　在上面模型融合过程中，首先将输入图像传递给第一个模型，获取其输出特征。然后，将这些特征作为输入传递给第二个模型，以获得最终的分类结果。通过对两个模型的输出进行融合，可以综合利用它们的优势，提高整体性能或泛化能力。</p> 
<p>　　需要注意的是，这只是一个简单的示例，实际的模型融合可能涉及更复杂的策略和技巧。具体的模型融合方法取决于任务的需求和数据集的特点。可以根据实际情况进行调整和改进，以获得更好的结果 。</p> 
<p>　　当涉及更复杂的模型融合时，常见的技术包括集成学习方法，如堆叠集成和投票集成。下面是一个更复杂的模型融合示例，使用堆叠集成的方法：</p> 
<table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td> <p>1</p> <p>2</p> <p>3</p> <p>4</p> <p>5</p> <p>6</p> <p>7</p> <p>8</p> <p>9</p> <p>10</p> <p>11</p> <p>12</p> <p>13</p> <p>14</p> <p>15</p> <p>16</p> <p>17</p> <p>18</p> <p>19</p> <p>20</p> <p>21</p> <p>22</p> <p>23</p> <p>24</p> <p>25</p> <p>26</p> <p>27</p> <p>28</p> <p>29</p> <p>30</p> <p>31</p> <p>32</p> <p>33</p> <p>34</p> </td><td> <p><code>import torch</code></p> <p><code>import timm</code></p> <p></p> <p><code># 1. 加载并初始化要融合的模型</code></p> <p><code>model1 = timm.create_model(</code><code>'resnet50'</code><code>, pretrained=True)</code></p> <p><code>model2 = timm.create_model(</code><code>'efficientnet_b0'</code><code>, pretrained=True)</code></p> <p><code>model3 = timm.create_model(</code><code>'densenet121'</code><code>, pretrained=True)</code></p> <p></p> <p><code># 2. 定义融合模型</code></p> <p><code>class</code> <code>FusionModel(torch.nn.Module):</code></p> <p><code>    </code><code>def __init__(self, model1, model2, model3):</code></p> <p><code>        </code><code>super(FusionModel, self).__init__()</code></p> <p><code>        </code><code>self.model1 = model1</code></p> <p><code>        </code><code>self.model2 = model2</code></p> <p><code>        </code><code>self.model3 = model3</code></p> <p><code>        </code><code>self.fc = torch.nn.Linear(3, 1)  # 假设最终输出为单个值</code></p> <p></p> <p><code>    </code><code>def forward(self, x):</code></p> <p><code>        </code><code>output1 = self.model1(x)</code></p> <p><code>        </code><code>output2 = self.model2(x)</code></p> <p><code>        </code><code>output3 = self.model3(x)</code></p> <p><code>        </code><code>fused_output = torch.cat([output1, output2, output3], dim=1)</code></p> <p><code>        </code><code>fused_output = self.fc(fused_output)</code></p> <p><code>        </code><code>return</code> <code>fused_output</code></p> <p></p> <p><code># 3. 创建融合模型实例</code></p> <p><code>fusion_model = FusionModel(model1, model2, model3)</code></p> <p></p> <p><code># 4. 使用融合模型进行推理</code></p> <p><code>input = torch.randn(1, 3, 224, 224)  # 假设输入为224x224的RGB图像</code></p> <p><code>output = fusion_model(input)</code></p> <p></p> <p><code># 5. 打印输出结果</code></p> <p><code>print(</code><code>"Fused output shape:"</code><code>, output.shape)</code></p> </td></tr></tbody></table> 
<p>　　在上述示例中，我们加载了三个预训练模型，并使用堆叠集成的方法将它们的输出连接在一起。连接后的输出经过一个全连接层进行进一步处理，最终得到融合模型的输出。</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0db5a230f54a86e679c6fd70d341ab66/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">C&#43;&#43;去除数组中的重复元素</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4688f9d87c489e22b9371256d186bbf9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java导出Excel的核心代码</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>