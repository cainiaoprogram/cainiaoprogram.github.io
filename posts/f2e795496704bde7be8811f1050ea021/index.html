<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>《RT-DETR魔术师》专栏介绍 &amp; CSDN独家改进创新实战 &amp; 专栏目录 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="《RT-DETR魔术师》专栏介绍 &amp; CSDN独家改进创新实战 &amp; 专栏目录" />
<meta property="og:description" content="RT-DETR魔术师专栏介绍：
https://blog.csdn.net/m0_63774211/category_12497375.html
✨✨✨魔改创新RT-DETR
🚀🚀🚀引入前沿顶会创新（CVPR2023，ICCV2023等），助力RT-DETR
🍉🍉🍉基于ultralytics优化，与YOLO完美结合
💡💡💡重点：通过本专栏的阅读，后续你也可以自己魔改网络，在网络不同位置（Backbone、head、detect、loss等）进行魔改，实现创新！！！
目录
1.Backbone改进
2.注意力机制改进
3.卷积变体改进
4.IOU&amp;LOSS改进 5. Neck优化
6.手把手入门教程
🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀
1.Backbone改进 1.1 HGBlock完美结合PPHGNetV2 GhostConv
RT-DETR算法优化改进：Backbone改进 | HGBlock完美结合PPHGNetV2 GhostConv-CSDN博客
1.2 HGBlock完美结合PPHGNetV2 RepConv
RT-DETR算法优化改进：Backbone改进 | HGBlock完美结合PPHGNetV2 RepConv-CSDN博客
1.3 VanillaNet一种新视觉Backbone，极简且强大！华为诺亚2023
RT-DETR算法优化改进：Backbone改进 | VanillaNet一种新视觉Backbone，极简且强大！华为诺亚2023-CSDN博客
1.4 EfficientViT，基于级联分组注意力模块的全新实时网络架构，better speed and accuracy | CVPR2023
RT-DETR算法优化改进：Backbone改进 | EfficientViT，基于级联分组注意力模块的全新实时网络架构，better speed and accuracy | CVPR2023-CSDN博客
1.5 EMO，结合 CNN 和 Transformer 的现代倒残差移动模块设计 | ICCV2023
RT-DETR算法优化改进：Backbone改进 | EMO，结合 CNN 和 Transformer 的现代倒残差移动模块设计 | ICCV2023-CSDN博客
1.6 LSKNet：遥感旋转目标检测新SOTA | ICCV 2023" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f2e795496704bde7be8811f1050ea021/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-12T16:46:36+08:00" />
<meta property="article:modified_time" content="2023-12-12T16:46:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">《RT-DETR魔术师》专栏介绍 &amp; CSDN独家改进创新实战 &amp; 专栏目录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p><span style="color:#fe2c24;"><strong>RT-DETR魔术师专栏介绍：</strong></span></p> 
<p>https://blog.csdn.net/m0_63774211/category_12497375.html</p> 
<p>✨✨✨<strong>魔改创新RT-DETR</strong></p> 
<p>🚀🚀🚀<strong>引入前沿顶会创新（CVPR2023，ICCV2023等），助力RT-DETR</strong></p> 
<p>🍉🍉🍉<strong>基于ultralytics优化，与YOLO完美结合</strong></p> 
<p>💡💡💡<span style="color:#ff9900;"><strong>重点：通过本专栏的阅读，后续你也可以自己魔改网络，在网络不同位置（Backbone、head、detect、loss等）进行魔改，实现创新！！！</strong></span></p> 
<p><br><img alt="" src="https://images2.imgbox.com/22/ff/xOB7BUk9_o.jpg"></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E6%89%8B%E6%8A%8A%E6%89%8B%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-toc" style="margin-left:40px;"><a href="#1.%E6%89%8B%E6%8A%8A%E6%89%8B%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B" rel="nofollow">1.Backbone改进</a></p> 
<p id="2.%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%94%B9%E8%BF%9B-toc" style="margin-left:40px;"><a href="#2.%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%94%B9%E8%BF%9B" rel="nofollow">2.注意力机制改进</a></p> 
<p id="3.%E5%8D%B7%E7%A7%AF%E5%8F%98%E4%BD%93%E6%94%B9%E8%BF%9B-toc" style="margin-left:40px;"><a href="#3.%E5%8D%B7%E7%A7%AF%E5%8F%98%E4%BD%93%E6%94%B9%E8%BF%9B" rel="nofollow">3.卷积变体改进</a></p> 
<p id="4.IOU%26LOSS%E6%94%B9%E8%BF%9B%C2%A0-toc" style="margin-left:40px;"><a href="#4.IOU%26LOSS%E6%94%B9%E8%BF%9B%C2%A0" rel="nofollow">4.IOU&amp;LOSS改进 </a></p> 
<p id="5.%20Neck%E4%BC%98%E5%8C%96-toc" style="margin-left:40px;"><a href="#5.%20Neck%E4%BC%98%E5%8C%96" rel="nofollow">5. Neck优化</a></p> 
<p id="6.%E6%89%8B%E6%8A%8A%E6%89%8B%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B-toc" style="margin-left:40px;"><a href="#6.%E6%89%8B%E6%8A%8A%E6%89%8B%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B" rel="nofollow">6.手把手入门教程</a></p> 
<hr id="hr-toc"> 
<p></p> 
<p id="main-toc"></p> 
<p>🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀🚀</p> 
<h3 id="1.%E6%89%8B%E6%8A%8A%E6%89%8B%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B"><a name="t0"></a><span style="color:#fe2c24;"><strong>1.Backbone改进</strong></span></h3> 
<p>1.1 HGBlock完美结合PPHGNetV2 GhostConv</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134374948" title="RT-DETR算法优化改进：Backbone改进 | HGBlock完美结合PPHGNetV2 GhostConv-CSDN博客">RT-DETR算法优化改进：Backbone改进 | HGBlock完美结合PPHGNetV2 GhostConv-CSDN博客</a></p> 
<p>1.2 HGBlock完美结合PPHGNetV2 RepConv</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134375155" title="RT-DETR算法优化改进：Backbone改进 | HGBlock完美结合PPHGNetV2 RepConv-CSDN博客">RT-DETR算法优化改进：Backbone改进 | HGBlock完美结合PPHGNetV2 RepConv-CSDN博客</a></p> 
<p>1.3 VanillaNet一种新视觉Backbone，极简且强大！<span style="color:#ff9900;"><strong>华为诺亚2023</strong></span></p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134401243" title="RT-DETR算法优化改进：Backbone改进 | VanillaNet一种新视觉Backbone，极简且强大！华为诺亚2023-CSDN博客">RT-DETR算法优化改进：Backbone改进 | VanillaNet一种新视觉Backbone，极简且强大！华为诺亚2023-CSDN博客</a></p> 
<p>1.4 EfficientViT，基于级联分组注意力模块的全新实时网络架构，better speed and accuracy | <span style="color:#ff9900;"><strong>CVPR2023</strong></span></p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134401653" title="RT-DETR算法优化改进：Backbone改进 | EfficientViT，基于级联分组注意力模块的全新实时网络架构，better speed and accuracy | CVPR2023-CSDN博客">RT-DETR算法优化改进：Backbone改进 | EfficientViT，基于级联分组注意力模块的全新实时网络架构，better speed and accuracy | CVPR2023-CSDN博客</a></p> 
<p>1.5  EMO，结合 CNN 和 Transformer 的现代倒残差移动模块设计 |<span style="color:#ff9900;"><strong> ICCV2023</strong></span></p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134402167" title="RT-DETR算法优化改进：Backbone改进 | EMO，结合 CNN 和 Transformer 的现代倒残差移动模块设计 | ICCV2023-CSDN博客">RT-DETR算法优化改进：Backbone改进 | EMO，结合 CNN 和 Transformer 的现代倒残差移动模块设计 | ICCV2023-CSDN博客</a></p> 
<p> 1.6 LSKNet：遥感旋转目标检测新SOTA |<span style="color:#ff9900;"><strong> ICCV 2023</strong></span></p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134402474" title="RT-DETR算法优化改进：Backbone改进 | LSKNet：遥感旋转目标检测新SOTA | ICCV 2023-CSDN博客">RT-DETR算法优化改进：Backbone改进 | LSKNet：遥感旋转目标检测新SOTA | ICCV 2023-CSDN博客</a></p> 
<p>1.7 Next-vit，用于现实工业场景的下一代视觉 Transformer</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134402719" title="RT-DETR算法优化改进：Backbone改进 | Next-vit，用于现实工业场景的下一代视觉 Transformer-CSDN博客">RT-DETR算法优化改进：Backbone改进 | Next-vit，用于现实工业场景的下一代视觉 Transformer-CSDN博客</a></p> 
<p>1.8 RIFormer：无需TokenMixer也能达成SOTA性能的极简ViT架构 | <span style="color:#ff9900;"><strong>CVPR2023</strong></span> <a href="https://blog.csdn.net/m0_63774211/article/details/134404756" title="RT-DETR算法优化改进：Backbone改进｜RIFormer：无需TokenMixer也能达成SOTA性能的极简ViT架构 | CVPR2023-CSDN博客">RT-DETR算法优化改进：Backbone改进｜RIFormer：无需TokenMixer也能达成SOTA性能的极简ViT架构 | CVPR2023-CSDN博客</a></p> 
<p>1.9 支持Paddle轻量级 rtdetr-r18、rtdetr-r34、rtdetr-r50、rtdetr-r101等版本</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134369278" title="RT-DETR算法优化改进：轻量级Backbone改进 | 支持Paddle轻量级 rtdetr-r18、rtdetr-r34、rtdetr-r50、rtdetr-r101等版本-CSDN博客">RT-DETR算法优化改进：轻量级Backbone改进 | 支持Paddle轻量级 rtdetr-r18、rtdetr-r34、rtdetr-r50、rtdetr-r101等版本-CSDN博客</a></p> 
<p>20 SENet v2，Squeeze-Excitation模块融合Dense Layer，效果秒杀SENet</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134728146" title="RT-DETR算法优化改进：SENet v2，Squeeze-Excitation模块融合Dense Layer，效果秒杀SENet-CSDN博客">RT-DETR算法优化改进：SENet v2，Squeeze-Excitation模块融合Dense Layer，效果秒杀SENet-CSDN博客</a></p> 
<h3 id="2.%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E6%94%B9%E8%BF%9B"><span style="color:#1c7331;">2.注意力机制改进</span></h3> 
<p>2.1  一种新颖的动态稀疏注意力(BiLevelRoutingAttention) |<span style="color:#956fe7;"><strong> CVPR2023</strong></span></p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134376982" title="RT-DETR算法优化改进：一种新颖的动态稀疏注意力(BiLevelRoutingAttention) | CVPR2023-CSDN博客">RT-DETR算法优化改进：一种新颖的动态稀疏注意力(BiLevelRoutingAttention) | CVPR2023-CSDN博客</a></p> 
<p>2.2 新颖的多尺度卷积注意力（MSCA），即插即用，助力小目标检测 | NeurIPS2022 </p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134380740" title="RT-DETR算法优化改进：新颖的多尺度卷积注意力（MSCA），即插即用，助力小目标检测 | NeurIPS2022-CSDN博客">RT-DETR算法优化改进：新颖的多尺度卷积注意力（MSCA），即插即用，助力小目标检测 | NeurIPS2022-CSDN博客</a></p> 
<p>2.3  多维协作注意模块MCA，暴力涨点，效果秒杀ECA、SRM、CBAM等 | 即插即用系列</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134381194" title="RT-DETR算法优化改进：多维协作注意模块MCA，暴力涨点，效果秒杀ECA、SRM、CBAM等 | 即插即用系列-CSDN博客">RT-DETR算法优化改进：多维协作注意模块MCA，暴力涨点，效果秒杀ECA、SRM、CBAM等 | 即插即用系列-CSDN博客</a></p> 
<p>2.4  一种新颖的可扩张残差（DWR）注意力模块，加强不同尺度特征提取能力</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134375834" title="RT-DETR算法优化改进： 一种新颖的可扩张残差（DWR）注意力模块，加强不同尺度特征提取能力-CSDN博客">RT-DETR算法优化改进： 一种新颖的可扩张残差（DWR）注意力模块，加强不同尺度特征提取能力-CSDN博客</a></p> 
<p>2.5 轻量级上采样CARAFE算子 </p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134434803" title="RT-DETR算法优化改进：轻量级上采样CARAFE算子 | 注意力机制大作战-CSDN博客">RT-DETR算法优化改进：轻量级上采样CARAFE算子 | 注意力机制大作战-CSDN博客</a></p> 
<p>2.6  自研独家创新BSAM注意力 ，基于CBAM升级</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134441910" title="RT-DETR算法优化改进：自研独家创新BSAM注意力 ，基于CBAM升级 | 注意力机制大作战-CSDN博客">RT-DETR算法优化改进：自研独家创新BSAM注意力 ，基于CBAM升级 | 注意力机制大作战-CSDN博客</a></p> 
<p></p> 
<h3 id="3.%E5%8D%B7%E7%A7%AF%E5%8F%98%E4%BD%93%E6%94%B9%E8%BF%9B"><span style="color:#1a439c;">3.卷积变体改进</span></h3> 
<p>3.1 可变形大核注意力（D-LKA Attention），超越自注意力，实现暴力涨点 | <span style="color:#38d8f0;">2023.8月最新发表 </span><a href="https://blog.csdn.net/m0_63774211/article/details/134382838" title="RT-DETR算法优化改进：可变形大核注意力（D-LKA Attention），超越自注意力，实现暴力涨点 | 2023.8月最新发表-CSDN博客">RT-DETR算法优化改进：可变形大核注意力（D-LKA Attention），超越自注意力，实现暴力涨点 | 2023.8月最新发表-CSDN博客</a></p> 
<p>3.2 大型分离卷积注意力模块（ Large Separable Kernel Attention），实现暴力涨点同时显著减少计算复杂性和内存 | 2023.8月最新发表 <a href="https://blog.csdn.net/m0_63774211/article/details/134383048" title="RT-DETR算法优化改进：大型分离卷积注意力模块（ Large Separable Kernel Attention），实现暴力涨点同时显著减少计算复杂性和内存 | 2023.8月最新发表-CSDN博客">RT-DETR算法优化改进：大型分离卷积注意力模块（ Large Separable Kernel Attention），实现暴力涨点同时显著减少计算复杂性和内存 | 2023.8月最新发表-CSDN博客</a></p> 
<p>3.3 SCConv，空间和通道重建卷积 | CVPR2023 </p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134443187" title="RT-DETR算法优化改进：SCConv，空间和通道重建卷积 | CVPR2023 | 卷积变体大作战-CSDN博客">RT-DETR算法优化改进：SCConv，空间和通道重建卷积 | CVPR2023 | 卷积变体大作战-CSDN博客</a></p> 
<p>3.4 SPD-Conv，低分辨率图像和小物体涨点明显 <a href="https://blog.csdn.net/m0_63774211/article/details/134444324" title="RT-DETR算法优化改进：SPD-Conv，低分辨率图像和小物体涨点明显，涨点神器，无脑直接使用！！！-CSDN博客">RT-DETR算法优化改进：SPD-Conv，低分辨率图像和小物体涨点明显，涨点神器，无脑直接使用！！！-CSDN博客</a></p> 
<p>3.5 一种新的partial卷积（PConv） | CVPR2023 FasterNet</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134448028" title="RT-DETR算法优化改进：一种新的partial卷积（PConv） |CVPR2023 FasterNet | 卷积变体大作战-CSDN博客">RT-DETR算法优化改进：一种新的partial卷积（PConv） |CVPR2023 FasterNet | 卷积变体大作战-CSDN博客</a></p> 
<p>3.6 AKConv（可改变核卷积），即插即用的卷积，效果秒杀DSConv | 2023年11月最新发表</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134643783" title="RT-DETR算法优化改进：AKConv（可改变核卷积），即插即用的卷积，效果秒杀DSConv | 2023年11月最新发表-CSDN博客">RT-DETR算法优化改进：AKConv（可改变核卷积），即插即用的卷积，效果秒杀DSConv | 2023年11月最新发表-CSDN博客</a> 3.7 轻量化自研设计双卷积重新设计backbone和neck，完成涨点且计算量和参数量显著下降</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134920023" title="RT-DETR算法优化改进：轻量化自研设计双卷积重新设计backbone和neck，完成涨点且计算量和参数量显著下降-CSDN博客">RT-DETR算法优化改进：轻量化自研设计双卷积重新设计backbone和neck，完成涨点且计算量和参数量显著下降-CSDN博客</a></p> 
<p></p> 
<h3 id="4.IOU%26LOSS%E6%94%B9%E8%BF%9B%C2%A0">4.IOU&amp;LOSS改进 </h3> 
<p>4.1 MPDIoU新型边界框相似度度量，效果秒杀GIoU 、 DIoU 、CIoU 、 EIoU等</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134424315" title="RT-DETR算法优化改进：Loss改进 | MPDIoU新型边界框相似度度量，效果秒杀GIoU 、 DIoU 、CIoU 、 EIoU等 | ELSEVIER 2023-CSDN博客">RT-DETR算法优化改进：Loss改进 | MPDIoU新型边界框相似度度量，效果秒杀GIoU 、 DIoU 、CIoU 、 EIoU等 | ELSEVIER 2023-CSDN博客</a></p> 
<p> 4.2 Inner-MPDIoU | Inner-IoU基于辅助边框的IoU损失，高效结合新型边界框相似度度量（MPDIoU） | 2023.11</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134425372" title="RT-DETR算法优化改进：Loss改进 | Inner-MPDIoU | Inner-IoU基于辅助边框的IoU损失，高效结合新型边界框相似度度量（MPDIoU） | 2023.11-CSDN博客">RT-DETR算法优化改进：Loss改进 | Inner-MPDIoU | Inner-IoU基于辅助边框的IoU损失，高效结合新型边界框相似度度量（MPDIoU） | 2023.11-CSDN博客</a></p> 
<p>4.3  Inner-IoU基于辅助边框的IoU损失，高效结合 GIoU, DIoU, CIoU，SIoU 等 | 2023.11</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134462481" title="RT-DETR算法优化改进：Inner-IoU基于辅助边框的IoU损失，高效结合 GIoU, DIoU, CIoU，SIoU 等 | 2023.11-CSDN博客">RT-DETR算法优化改进：Inner-IoU基于辅助边框的IoU损失，高效结合 GIoU, DIoU, CIoU，SIoU 等 | 2023.11-CSDN博客</a></p> 
<h3 id="5.%20Neck%E4%BC%98%E5%8C%96">5. Neck优化</h3> 
<p>5.1 新的设计范式Slim Neck助力RT-DETR </p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134440920" title="RT-DETR算法优化改进：新的设计范式Slim Neck助力RT-DETR | Neck改进-CSDN博客">RT-DETR算法优化改进：新的设计范式Slim Neck助力RT-DETR | Neck改进-CSDN博客</a></p> 
<p></p> 
<h3 id="6.%E6%89%8B%E6%8A%8A%E6%89%8B%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B">6.手把手入门教程</h3> 
<p>6.1 注意力机制如何添加在网络的不同位置进行创新优化</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134529590" title="RT-DETR手把手教程，注意力机制如何添加在网络的不同位置进行创新优化，EMA注意力为案列-CSDN博客">RT-DETR手把手教程，注意力机制如何添加在网络的不同位置进行创新优化，EMA注意力为案列-CSDN博客</a></p> 
<p>6.1 NEU-DET钢材表面缺陷检测任务 | 不同网络位置加入EMA注意力进行魔改</p> 
<p><a href="https://blog.csdn.net/m0_63774211/article/details/134845893" title="RT-DETR手把手教程：NEU-DET钢材表面缺陷检测任务 | 不同网络位置加入EMA注意力进行魔改-CSDN博客">RT-DETR手把手教程：NEU-DET钢材表面缺陷检测任务 | 不同网络位置加入EMA注意力进行魔改-CSDN博客</a></p> 
<p><span style="color:#fe2c24;"><strong>持续更新中</strong></span></p> 
<p><span style="color:#fe2c24;"><strong>重点，新开专栏优惠力度史无前例，后期恢复到299！！！</strong></span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/860be0b62c4297cfbb0c457f4c91b373/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">卷积神经网络（CNN）中感受野的计算问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/79103311f9fb5170d221d7c07c9f6d08/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">NVMe SSD是个啥？5张图保你弄明白SSD那些事</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>