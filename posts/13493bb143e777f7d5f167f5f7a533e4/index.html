<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python中用SpeechRecognition库和 vosk模型来识别语音 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python中用SpeechRecognition库和 vosk模型来识别语音" />
<meta property="og:description" content="Python中的SpeechRecognition库是一个比较好用的语音识别模块，提供了将语音识别成文字的方法，支持中文识别。
一、SpeechRecognition库的安装
使用pip命令安装即可：
​pip install SpeechRecognition 当安装不成功时，可以强制：
​pip install --force- SpeechRecognition 二、SpeechRecognition库的导入：
import speech_recognition as sr r = sr.Recognizer() 注意：导入库的名称与安装名称的略有不同。
三、识别麦克风输入的语音：
# 麦克风录音 mic = sr.Microphone() with mic as source: print(&#34;请说话...&#34;) r.adjust_for_ambient_noise(source) audioData = r.listen(source) # print(type(audioData)) 四、或者直接识别语音文件：
# 识别语音文件 audioFile = sr.AudioFile(&#34;渔父.mp3&#34;) with audioFile as source: audioData = r.record(source) 注意语音文件“渔父.mp3”放在主程序同一文件夹中，故没有指明路径。
不管你是要识别通过麦克风现场输入的语音，还是识别现有的语音文件，最后都是通过
audioData = r.record(source)语句读取到audioData对象中，再通过语音识别模型来识别成文本。 语音识别的模型有很多，如Google Speech API，CMU Sphinx，Vosk等。我们以能线下使用的Vosk模型为例来说明使用方法。
五、安装vosk库
pip install vosk speechrecognition提供了方便的使用vosk的函数
Recognizer.recognize_vosk(audioData) 虽然我们安装了Vosk的库，但好像其中没有包含Vosk语音模型，还需要单独下载。打开VOSK Models链接，可以看到各种语言的语音模型：
我们要识别中文，当然要下载中文语音模型：
下载各个模型到主程序文件夹下，解压，将想要使用的语音模型文件名改为“model”" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/13493bb143e777f7d5f167f5f7a533e4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-08T12:34:01+08:00" />
<meta property="article:modified_time" content="2024-01-08T12:34:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python中用SpeechRecognition库和 vosk模型来识别语音</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>Python中的SpeechRecognition库是一个比较好用的<a href="https://so.csdn.net/so/search?q=%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB&amp;spm=1001.2101.3001.7020" title="语音识别">语音识别</a>模块，提供了将语音识别成文字的方法，支持中文识别。</p> 
<p>一、SpeechRecognition库的安装</p> 
<p>使用pip命令安装即可：</p> 
<pre><code>​pip install SpeechRecognition</code></pre> 
<p>当安装不成功时，可以强制：</p> 
<pre><code>​pip install --force- SpeechRecognition</code></pre> 
<p>二、SpeechRecognition库的导入：</p> 
<pre><code>import speech_recognition as sr
r = sr.Recognizer()</code></pre> 
<p>注意：导入库的名称与安装名称的略有不同。</p> 
<p>三、识别麦克风输入的语音：</p> 
<pre><code># 麦克风录音
mic = sr.Microphone()
with mic as source:
    print("请说话...")
    r.adjust_for_ambient_noise(source)
    audioData = r.listen(source)
    # print(type(audioData))</code></pre> 
<p>四、或者直接识别语音文件：</p> 
<pre><code># 识别语音文件
audioFile = sr.AudioFile("渔父.mp3")
with audioFile as source:
   audioData = r.record(source)</code></pre> 
<p>注意语音文件“渔父.mp3”放在主程序同一文件夹中，故没有指明路径。</p> 
<p>不管你是要识别通过麦克风现场输入的语音，还是识别现有的语音文件，最后都是通过</p> 
<pre>audioData = r.record(source)语句读取到audioData对象中，再通过语音识别模型来识别成文本。
</pre> 
<p>语音识别的模型有很多，如Google Speech API，CMU Sphinx，Vosk等。我们以能线下使用的Vosk模型为例来说明使用方法。</p> 
<p>五、安装vosk库</p> 
<pre><code>pip install vosk</code></pre> 
<p>speechrecognition提供了方便的使用vosk的函数</p> 
<pre>Recognizer.recognize_vosk(audioData)</pre> 
<p>虽然我们安装了Vosk的库，但好像其中没有包含Vosk语音模型，还需要单独下载。打开<a href="https://alphacephei.com/vosk/models" rel="nofollow" title="VOSK Models">VOSK Models</a>链接，可以看到各种语言的语音模型：</p> 
<p><img alt="" height="474" src="https://images2.imgbox.com/2b/aa/hjtU4xmO_o.png" width="1200"></p> 
<p>我们要识别中文，当然要下载中文语音模型：</p> 
<p><img alt="" height="326" src="https://images2.imgbox.com/10/13/10z7fTqj_o.png" width="1200"></p> 
<p>下载各个模型到主程序文件夹下，解压，将想要使用的语音模型文件名改为“model”</p> 
<p>我试了42M和1.3G两个语音模型，好像识别效果差不多，唯一的区别是大的语音模型加载时间长。也许是我识别的古文的原因？</p> 
<p>六、语音识别</p> 
<pre><code>said = r.recognize_vosk(audioData) # 下载的语音模型解压后须改文件夹名为“model”
print("you said:", formulateResult(said))</code></pre> 
<p>七、运行结果：</p> 
<p><img alt="" height="322" src="https://images2.imgbox.com/fb/dd/z4px1lZ0_o.png" width="1189"></p> 
<p>我是用现成的语音文件“渔父.mp3”来识别的。根据程序运行顺序，应是先读取“渔父.mp3”到audioData中，再加载同一文件夹下“model”中的Vosk语音模型，然后识别并显示出识别结果。</p> 
<p>为了测试识别效果，我又用一段现代文“考场须知.mp3”来测试，识别效果还是好很多：</p> 
<p><img alt="" height="364" src="https://images2.imgbox.com/23/83/CpeLBy0a_o.png" width="1200"></p> 
<p>全文代码：</p> 
<pre><code>import speech_recognition as sr
import vosk
import pyaudio
r = sr.Recognizer()

# model = vosk.Model("model") # 在录音后自动加载，前期加载无效
# pip install SpeechRecognition

'''
# 直接录音
mic = sr.Microphone()
with mic as source:
    print("请说话...")
    r.adjust_for_ambient_noise(source)
    audioData = r.listen(source)
    # print(type(audioData))

'''
# 使用语音文件
audioFile = sr.AudioFile("考场须知.mp3")
with audioFile as source:
   audioData = r.record(source)


def formulateResult(resu):
    start = resu.index('"', resu.index('"', resu.index('"') + 1) + 1) + 1
    end = resu.index('"', start)
    return resu[start:end]

# pip install vosk；模型网站 https://alphacephei.com/vosk/models,两个模型一大一小，大的也不见得就识别准确
# said = r.recognizer_instance.recognize_vosk(audioData)
said = r.recognize_vosk(audioData) # 下载的语音模型解压后须改文件夹名为“model”
# said = r.rec(audioData)
print("you said:", formulateResult(said))</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/24521413f3c7f5dbb219596d46f4ee8c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">损坏硬盘中的数据恢复</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/265745724a7bebfa9740d26e4c00c02d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">智能运维：实现网络设备巡检与值班管理的高效与精准</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>