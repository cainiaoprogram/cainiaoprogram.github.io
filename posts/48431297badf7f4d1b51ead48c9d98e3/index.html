<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>姿态估计之CPN(Cascaded Pyramid Network) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="姿态估计之CPN(Cascaded Pyramid Network)" />
<meta property="og:description" content="这篇是face&#43;&#43;2017年coco keypoint benchmark 数据集冠军的文章。主要提出了基于CPN(Cascaded PyramidNetwork)结构的人体关键点检测框架。
Top-down pipeline：
整体框架采用Top-down自上而下的检测策略。首先使用行人检测框架，先检测出行人候选框。然后使用本文的CPN网络对每一个检测出来的行人候选框进行人体关键点的回归，进而输出最终结果。最终实现coco tes-dev 73 map，coco test-challengedataset 72.1map。
Motivation:
首先对于可以看见的easy 关键点直接预测得到，对于不可见的关键点，使用增大感受野来获得关键点位置，对于还未检测出的点，使用上下文context进行预测。
整体网络结构：
网络整体结构采用CPN(CascadedPyramid Network)结构，Cascaded指的是级联的意思，代表了网络级联了2个类似的模块（GolbalNet和RefineNet），Pyramid指的是类似于FPN的金字塔网络结构。
其中，GolbalNet负责网络所有关键点的检测，重点是对比较容易检测的眼睛，胳膊等部位的关键点预测效果较好，采用的损失函数为L2 loss。其中在每一个elem-sum操作之前，都对featuremap使用了1*1的卷积操作。
RefineNet指的是对GolbalNet预测的结果进行修正的网络。GolbalNet对身体部位的那些遮挡，看不见，或者有复杂背景的关键点预测误差较大，RefineNet则专门修正这些点。主要还是基于shortcut的思想。在该阶段的训练中，还使用了类似OHEM的online hard keypoints mining难例挖掘策略。
主要训练trick:
(1)数据增强，提升0.4map
训练数据的处理上使用了随机翻转，（-45度，45度）的随机旋转，（0,7,1.35）的随机尺度变换。
(2)大batch的训练，主要针对检测框架，提升0.4-0.7map
(3)在行人检测框架中使用soft NMS取代hard NMS，提升0.3map
soft NMS指的是将重叠较大的框中分数较小的那个框的分数拉到很低，但是不会去除到这个框，这样召回率相对较高。
hard NMS就是传统的NMS，直接将IOU大于一定阈值的框中得分较低的框直接去掉，相对召回率较低。
在人体关键点检测中，使用soft NMS会因为人体框召回率的提高而得到较高的分数。
(4)随着检测map的提高，关键点的map提升非常有限
(5)online hard keypoints mining
在coco数据集中有17个关键点需要预测，GolbalNet预测所有的17个点，并计算所有17个点的loss，RefineNet也预测所有的17个点，但是只计算其中最难的8个点的loss。在训练中还使用了类似OHEM的OHKM策略。
(6)多模型融合集成，提升1.1-1.5map在coco minval数据集上
References:
Cascaded Pyramid Network for Multi-Person Pose Estimation" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/48431297badf7f4d1b51ead48c9d98e3/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-01T00:15:48+08:00" />
<meta property="article:modified_time" content="2018-07-01T00:15:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">姿态估计之CPN(Cascaded Pyramid Network)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>这篇是face++2017年coco keypoint benchmark 数据集冠军的文章。主要提出了基于CPN(Cascaded PyramidNetwork)结构的人体关键点检测框架。</p> 
<p><br></p> 
<p><span style="color:#FF0000;">Top-down pipeline</span><span style="color:#FF0000;">：</span></p> 
<p style="text-align:center;"><span style="color:#FF0000;"><img src="https://images2.imgbox.com/0b/2f/iUplSlyZ_o.png" alt=""><br></span></p> 
<p><span style="color:#FF0000;"></span></p> 
<p>整体框架采用Top-down自上而下的检测策略。首先使用行人检测框架，先检测出行人候选框。然后使用本文的CPN网络对每一个检测出来的行人候选框进行人体关键点的回归，进而输出最终结果。最终实现coco tes-dev 73 map，coco test-challengedataset 72.1map。</p> 
<p> </p> 
<p><span style="color:#FF0000;">Motivation:</span></p> 
<p style="text-align:center;"><span style="color:#FF0000;"><img src="https://images2.imgbox.com/ab/3d/Z2VVOxTh_o.png" alt=""></span></p> 
<p><span style="color:#FF0000;"></span></p> 
<p>首先对于可以看见的easy 关键点直接预测得到，对于不可见的关键点，使用增大感受野来获得关键点位置，对于还未检测出的点，使用上下文context进行预测。</p> 
<p> </p> 
<p><span style="color:#FF0000;">整体网络结构：</span></p> 
<p style="text-align:center;"><span style="color:#FF0000;"><img src="https://images2.imgbox.com/39/a3/0nTqPYz8_o.png" alt=""></span></p> 
<p><span style="color:#FF0000;"></span></p> 
<p>网络整体结构采用CPN(CascadedPyramid Network)结构，Cascaded指的是级联的意思，代表了网络级联了2个类似的模块（GolbalNet和RefineNet），Pyramid指的是类似于FPN的金字塔网络结构。</p> 
<p>其中，GolbalNet负责网络所有关键点的检测，重点是对比较容易检测的眼睛，胳膊等部位的关键点预测效果较好，采用的损失函数为L2 loss。其中在每一个elem-sum操作之前，都对featuremap使用了1*1的卷积操作。</p> 
<p>RefineNet指的是对GolbalNet预测的结果进行修正的网络。GolbalNet对身体部位的那些遮挡，看不见，或者有复杂背景的关键点预测误差较大，RefineNet则专门修正这些点。主要还是基于shortcut的思想。在该阶段的训练中，还使用了类似OHEM的online hard keypoints mining难例挖掘策略。</p> 
<p> </p> 
<p><span style="color:#FF0000;">主要训练</span><span style="color:#FF0000;">trick:</span></p> 
<p>(1)数据增强，提升0.4map</p> 
<p>训练数据的处理上使用了随机翻转，（-45度，45度）的随机旋转，（0,7,1.35）的随机尺度变换。</p> 
<p>(2)大batch的训练，主要针对检测框架，提升0.4-0.7map</p> 
<p>(3)在行人检测框架中使用soft NMS取代hard NMS，提升0.3map</p> 
<p style="text-align:center;"><span style="color:#FF0000;"><img src="https://images2.imgbox.com/ed/ad/eOEQ6sZ0_o.png" width="400" alt=""></span></p> 
<p><span style="color:#000000;">soft NMS指的是将重叠较大的框中分数较小的那个框的分数拉到很低，但是不会去除到这个框，这样召回率相对较高。<br>hard NMS就是传统的NMS，直接将IOU大于一定阈值的框中得分较低的框直接去掉，相对召回率较低。<br></span></p> 
<p><span style="color:#000000;">在人体关键点检测中，使用soft NMS会因为人体框召回率的提高而得到较高的分数。</span></p> 
<p style="text-align:center;"><span style="color:#000000;"><img src="https://images2.imgbox.com/53/af/DgiG5GeN_o.png" alt=""><br></span></p> 
<p><span style="color:#000000;"></span></p> 
<p>(4)随着检测map的提高，关键点的map提升非常有限</p> 
<p style="text-align:center;"><span style="color:#000000;"><img src="https://images2.imgbox.com/60/9f/GCdqUGwF_o.png" alt=""></span></p> 
<p><span style="color:#000000;">(5)online hard keypoints mining<br>在coco数据集中有17个关键点需要预测，GolbalNet预测所有的17个点，并计算所有17个点的loss，RefineNet也预测所有的17个点，但是只计算其中最难的8个点的loss。在训练中还使用了类似OHEM的OHKM策略。<br><br><br>(6)多模型融合集成，提升1.1-1.5map在coco minval数据集上<br><br><br>References:<br><a href="https://arxiv.org/abs/1711.07319" rel="nofollow">Cascaded Pyramid Network for Multi-Person Pose Estimation</a><br></span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7fe976802a49a6596c1b1745072a1d9a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">类和对象</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/541c33605039cfbdc13c37ab6e805e08/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">刷脸更安全 人脸识别门禁开启安防新思路</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>