<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习笔记---多尺度网络结构归类总结 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习笔记---多尺度网络结构归类总结" />
<meta property="og:description" content="目录
1.什么是图像金字塔
1.1 高斯金字塔 ( Gaussian pyramid):
1.2 拉普拉斯金字塔（Laplacian pyramid）
1.3 DOG金字塔
2. 多尺度网络（MTCNN）
2.1 多尺度输入网络
2.2 多尺度特征融合网络
2.2.1 并行多分支网络
2.2.2 串行的跳层连接网络
3，多尺度特征预测融合网络
3.1 SSD 网络
3.2 SSH 网络
4，多尺度特征和预测融合网络 4.1 不同多尺度特征及预测方式的对比
4.1 FPN（Feature Pyramid Networks）的结构
4.2 FPN训练过程
1.什么是图像金字塔 图像金字塔是图像中多尺度表达的一种，最主要用于图像的分割，是一种以多分辨率来解释图像的有效但概念简单的结构。图像金字塔最初用于机器视觉和图像压缩，一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低，且来源于同一张原始图的图像集合。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似。我们将一层一层的图像比喻成金字塔，层级越高，则图像越小，分辨率越低。
获得图像金字塔一般包括二个步骤：
1. 利用低通滤波器平滑图像 2. 对平滑图像进行抽样（采样）
有两种采样方式——上采样（分辨率逐级升高）和下采样（分辨率逐级降低）
上采样：
下采样：
常见两类图像金字塔
1.1 高斯金字塔 ( Gaussian pyramid): 用来向下/降采样，主要的图像金字塔， 高斯金字塔是通过高斯平滑和亚采样获得一系列下采样图像，也就是说第K层高斯金字塔通过平滑、亚采样就可以获得K&#43;1层高斯图像，高斯金字塔包含了一系列低通滤波器，其截至频率从上一层到下一层是以因子2逐渐增加，所以高斯金字塔可以跨越很大的频率范围。金字塔的图像如下：
上图中最下层是原始的图像，越靠上的层图像尺寸越小，这一组图像就被称为高斯金字塔（在某些资料中，下采样之前需要首先进行高斯滤波 可以看出，随着下采样的进行，图像的分辨率不断降低，视觉效果也越来越模糊。
对图像的向下取样操作，即缩小图像。
为了获取层级为 G_i&#43;1 的金字塔图像，方法步骤如下：
&lt;1&gt; 对图像G_i进行高斯内核卷积，进行高斯模糊；
&lt;2&gt; 将所有偶数行和列去除。
得到的图像即为G_i&#43;1的图像，显而易见，结果图像只有原图的四分之一。通过对输入图像G_i(原始图像)不停迭代以上步骤就会得到整个金字塔。同时我们也可以看到，向下取样会逐渐丢失图像的信息。以上就是对图像的向下取样操作，即缩小图像。
对图像的向上取样，即放大图像
方法步骤如下：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7b10ff50ad0fb26a1bcb41080fbd17ff/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-09T17:48:59+08:00" />
<meta property="article:modified_time" content="2021-11-09T17:48:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习笔记---多尺度网络结构归类总结</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94-toc" style="margin-left:0px;"><a href="#1.%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94" rel="nofollow" title="1.什么是图像金字塔">1.什么是图像金字塔</a></p> 
<p id="1.1%20%E9%AB%98%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94%20(%20Gaussian%20pyramid)%3A-toc" style="margin-left:40px;"><a href="#1.1%20%E9%AB%98%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94%20%28%20Gaussian%20pyramid%29%3A" rel="nofollow" title="1.1 高斯金字塔 ( Gaussian pyramid):">1.1 高斯金字塔 ( Gaussian pyramid):</a></p> 
<p id="1.2%20%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94%EF%BC%88Laplacian%20pyramid%EF%BC%89-toc" style="margin-left:40px;"><a href="#1.2%20%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94%EF%BC%88Laplacian%20pyramid%EF%BC%89" rel="nofollow" title="1.2 拉普拉斯金字塔（Laplacian pyramid）">1.2 拉普拉斯金字塔（Laplacian pyramid）</a></p> 
<p id="1.3%20DOG%E9%87%91%E5%AD%97%E5%A1%94-toc" style="margin-left:40px;"><a href="#1.3%20DOG%E9%87%91%E5%AD%97%E5%A1%94" rel="nofollow" title="1.3 DOG金字塔">1.3 DOG金字塔</a></p> 
<p id="%C2%A02.%20%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%BD%91%E7%BB%9C-toc" style="margin-left:0px;"><a href="#%C2%A02.%20%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%BD%91%E7%BB%9C" rel="nofollow" title=" 2. 多尺度网络（MTCNN）"> 2. 多尺度网络（MTCNN）</a></p> 
<p id="2.1%20%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px;"><a href="#2.1%20%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C" rel="nofollow" title="2.1 多尺度输入网络">2.1 多尺度输入网络</a></p> 
<p id="%C2%A02.2%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px;"><a href="#%C2%A02.2%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C" rel="nofollow" title=" 2.2 多尺度特征融合网络"> 2.2 多尺度特征融合网络</a></p> 
<p id="2.2.1%C2%A0%E5%B9%B6%E8%A1%8C%E5%A4%9A%E5%88%86%E6%94%AF%E7%BD%91%E7%BB%9C-toc" style="margin-left:80px;"><a href="#2.2.1%C2%A0%E5%B9%B6%E8%A1%8C%E5%A4%9A%E5%88%86%E6%94%AF%E7%BD%91%E7%BB%9C" rel="nofollow" title="2.2.1 并行多分支网络">2.2.1 并行多分支网络</a></p> 
<p id="%C2%A02.2.2%C2%A0%E4%B8%B2%E8%A1%8C%E7%9A%84%E8%B7%B3%E5%B1%82%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C-toc" style="margin-left:80px;"><a href="#%C2%A02.2.2%C2%A0%E4%B8%B2%E8%A1%8C%E7%9A%84%E8%B7%B3%E5%B1%82%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C" rel="nofollow" title=" 2.2.2 串行的跳层连接网络"> 2.2.2 串行的跳层连接网络</a></p> 
<p id="3%EF%BC%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E9%A2%84%E6%B5%8B%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C-toc" style="margin-left:0px;"><a href="#3%EF%BC%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E9%A2%84%E6%B5%8B%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C" rel="nofollow" title="3，多尺度特征预测融合网络">3，多尺度特征预测融合网络</a></p> 
<p id="3.1%20SSD%20%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px;"><a href="#3.1%20SSD%20%E7%BD%91%E7%BB%9C" rel="nofollow" title="3.1 SSD 网络">3.1 SSD 网络</a></p> 
<p id="3.2%C2%A0SSH%C2%A0%E7%BD%91%E7%BB%9C-toc" style="margin-left:40px;"><a href="#3.2%C2%A0SSH%C2%A0%E7%BD%91%E7%BB%9C" rel="nofollow" title="3.2 SSH 网络">3.2 SSH 网络</a></p> 
<p id="4%EF%BC%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E5%92%8C%E9%A2%84%E6%B5%8B%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C%C2%A0-toc" style="margin-left:0px;"><a href="#4%EF%BC%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E5%92%8C%E9%A2%84%E6%B5%8B%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C%C2%A0" rel="nofollow" title="4，多尺度特征和预测融合网络 ">4，多尺度特征和预测融合网络 </a></p> 
<p id="4.1%20%E4%B8%8D%E5%90%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E5%8F%8A%E9%A2%84%E6%B5%8B%E6%96%B9%E5%BC%8F%E7%9A%84%E5%AF%B9%E6%AF%94-toc" style="margin-left:40px;"><a href="#4.1%20%E4%B8%8D%E5%90%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E5%8F%8A%E9%A2%84%E6%B5%8B%E6%96%B9%E5%BC%8F%E7%9A%84%E5%AF%B9%E6%AF%94" rel="nofollow" title="4.1 不同多尺度特征及预测方式的对比">4.1 不同多尺度特征及预测方式的对比</a></p> 
<p id="4.1%20FPN%EF%BC%88Feature%20Pyramid%20Networks%EF%BC%89%E7%9A%84%E7%BB%93%E6%9E%84-toc" style="margin-left:40px;"><a href="#4.1%20FPN%EF%BC%88Feature%20Pyramid%20Networks%EF%BC%89%E7%9A%84%E7%BB%93%E6%9E%84" rel="nofollow" title="4.1 FPN（Feature Pyramid Networks）的结构">4.1 FPN（Feature Pyramid Networks）的结构</a></p> 
<p id="%C2%A04.2%20FPN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B-toc" style="margin-left:40px;"><a href="#%C2%A04.2%20FPN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B" rel="nofollow" title=" 4.2 FPN训练过程"> 4.2 FPN训练过程</a></p> 
<hr id="hr-toc"> 
<h2 id="1.%E4%BB%80%E4%B9%88%E6%98%AF%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94">1.什么是图像金字塔</h2> 
<p>        图像金字塔是图像中多尺度表达的一种，最主要用于图像的分割，是<strong>一种以多分辨率来解释图像</strong>的有效但概念简单的结构。图像金字塔最初用于机器视觉和图像压缩，一幅图像的金字塔是一系列以金字塔形状排列的分辨率逐步降低，且来源于同一张原始图的图像集合。其通过梯次向下采样获得，直到达到某个终止条件才停止采样。金字塔的底部是待处理图像的高分辨率表示，而顶部是低分辨率的近似。我们将一层一层的图像比喻成金字塔，层级越高，则图像越小，分辨率越低。<br>  </p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/b7/17/Vrv35QDp_o.png"></p> 
<p></p> 
<p>获得图像金字塔一般包括二个步骤：</p> 
<p>1. 利用低通滤波器平滑图像 </p> 
<p>2. 对平滑图像进行抽样（采样）</p> 
<p>有两种采样方式——上采样（分辨率逐级升高）和下采样（分辨率逐级降低）</p> 
<p>上采样：</p> 
<p><img alt="" src="https://images2.imgbox.com/ce/d9/gPslK0C9_o.jpg"></p> 
<p> 下采样：</p> 
<p><img alt="" src="https://images2.imgbox.com/96/82/t1577Q00_o.jpg"></p> 
<p><strong>常见两类图像金字塔</strong></p> 
<h3 id="1.1%20%E9%AB%98%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94%20(%20Gaussian%20pyramid)%3A"><strong>1.1 高斯金字塔 ( Gaussian pyramid): </strong></h3> 
<p><strong>      </strong>用来向下/降采样，主要的图像金字塔， <strong>高斯金字塔</strong>是通过高斯平滑和亚采样获得一系列下采样图像，也就是说第K层高斯金字塔通过平滑、亚采样就可以获得K+1层高斯图像，高斯金字塔包含了一系列低通滤波器，其截至频率从上一层到下一层是以因子2逐渐增加，所以高斯金字塔可以跨越很大的频率范围。金字塔的图像如下：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/e7/5a/dp0fu2qw_o.png"></p> 
<p>      上图中最下层是原始的图像，<strong>越靠上的层图像尺寸越小</strong>，这一组图像就被称为高斯金字塔（在某些资料中，下采样之前需要<strong>首先进行高斯滤波</strong> </p> 
<p style="text-align:center;"><img alt="preview" src="https://images2.imgbox.com/0e/29/Vcvd8gwb_o.png"></p> 
<p></p> 
<p>可以看出，随着下采样的进行，图像的分辨率不断降低，视觉效果也越来越模糊。</p> 
<p><strong>对图像的向下取样操作，即缩小图像。</strong><br> 为了获取层级为 G_i+1 的金字塔图像，方法步骤如下：</p> 
<p>&lt;1&gt; 对图像G_i进行高斯内核卷积，进行高斯模糊；</p> 
<p>&lt;2&gt; 将所有偶数行和列去除。</p> 
<p>       得到的图像即为G_i+1的图像，显而易见，结果图像只有原图的四分之一。通过对输入图像G_i(原始图像)不停迭代以上步骤就会得到整个金字塔。同时我们也可以看到，向下取样会逐渐丢失图像的信息。以上就是对图像的向下取样操作，即缩小图像。</p> 
<p><strong>对图像的向上取样，即放大图像</strong><br> 方法步骤如下：</p> 
<p>&lt;1&gt; 将图像在每个方向扩大为原来的两倍，新增的行和列以0填充</p> 
<p>&lt;2&gt; 使用先前同样的内核(乘以4)与放大后的图像卷积，获得 “新增像素”的近似值</p> 
<p>       得到的图像即为放大后的图像，但是与原来的图像相比会发觉比较模糊，因为在缩放的过程中已经丢失了一些信息，<strong>如果想在缩小和放大整个过程中减少信息的丢失，这些数据形成了拉普拉斯金字塔。上述的上采样和下采样的过程是一个非逆向过程。</strong></p> 
<p>     如果高斯金字塔中任意一张图Gi（比如G0为最初的高分辨率图像）先进行下采样得到图Down(Gi)，再进行上采样得到图Up(Down(Gi))，得到的Up(Down(Gi))与Gi是存在差异的，<strong>因为下采样过程丢失的信息不能通过上采样来完全恢复</strong>，也就是说下采样是不可逆的。</p> 
<p> 下面展示了一张图先进行下采样，再进行上采样的过程：</p> 
<p style="text-align:center;"><img alt="preview" src="https://images2.imgbox.com/09/b2/wBQzzYlw_o.png"></p> 
<p>     可以看出，原始图片下采样后得到的小尺寸图片虽然保留了视觉效果，但是将该小尺寸图像再次上采样也不能完整的恢复出原始图像。</p> 
<h3 id="1.2%20%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94%EF%BC%88Laplacian%20pyramid%EF%BC%89"><strong>1.2 拉普拉斯金字塔（Laplacian pyramid）</strong></h3> 
<p><strong>     如果想在缩小和放大整个过程中减少信息的丢失，这些数据形成了拉普拉斯金字塔。</strong>拉普拉斯金字塔是通过源图像减去先缩小后再放大的图像的一系列图像构成的。保留的是残差！为图像还原做准备！因此拉普拉斯金字塔可以认为是残差金字塔，<strong>用来存储下采样后图片与原始图片的差异！</strong></p> 
<p>      下面展示了一张图先进行下采样，再进行上采样的过程：</p> 
<p style="text-align:center;"><img alt="preview" src="https://images2.imgbox.com/82/59/ODA8X17d_o.png"></p> 
<p> 可以看出，原始图片下采样后得到的小尺寸图片虽然保留了视觉效果，但是将该小尺寸图像再次上采样也不能完整的恢复出原始图像。为了能够从下采样图像Down(Gi)中还原原始图像Gi，我们需要记<strong>录再次上采样得到Up(Down(Gi))与原始图片Gi之间的差异</strong>，这就是拉普拉斯金字塔的核心思想，下面最右边的图展示了这种差异（为了效果明显我进行了伽马矫正）：</p> 
<p style="text-align:center;"><img alt="preview" src="https://images2.imgbox.com/a8/9a/R0RBIy7N_o.png"></p> 
<p>拉普拉斯金字塔就是<strong>记录高斯金字塔每一级下采样后再上采样与下采样前的差异</strong>，目的是为了能够完整的恢复出每一层级的下采样前图像。下面的公式就是前面的差异记录过程：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/68/b7/DsnSvrsf_o.png"></p> 
<p style="text-align:center;"><img alt="preview" src="https://images2.imgbox.com/b9/ec/1q6HhOWO_o.png"></p> 
<p><br><strong>      因此</strong>高斯金字塔用来向下降采样图像，注意降采样其实是由金字塔底部向上采样，分辨率降低，它和我们理解的金字塔概念相反（注意）；而拉普拉斯金字塔则用来从金字塔底层图像中向上采样重建一个图像。</p> 
<h3 id="1.3%20DOG%E9%87%91%E5%AD%97%E5%A1%94">1.3 DOG金字塔</h3> 
<p>差分金字塔，DOG（Difference of Gaussian）金字塔是在高斯金字塔的基础上构建起来的，其实生成高斯金字塔的目的就是为了构建DOG金字塔。</p> 
<p>DOG金字塔的第1组第1层是由高斯金字塔的第1组第2层减第1组第1层得到的。以此类推，逐组逐层生成每一个差分图像，所有差分图像构成差分金字塔。概括为DOG金字塔的第o组第l层图像是有高斯金字塔的第o组第l+1层减第o组第l层得到的。</p> 
<p>DOG金字塔的构建可以用下图描述：</p> 
<p> <img alt="" src="https://images2.imgbox.com/31/f9/xHQULmDm_o.jpg"></p> 
<p>下边<strong>对这些DOG图像进行归一化，可有很明显的看到差分图像所蕴含的特征</strong>，并且有一些特征是在不同模糊程度、不同尺度下都存在的，这些特征正是Sift所要提取的“稳定”特征：</p> 
<p> <img alt="" src="https://images2.imgbox.com/54/89/wfavuXnq_o.jpg"></p> 
<h2></h2> 
<h2 id="%C2%A02.%20%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%BD%91%E7%BB%9C"> 2. 多尺度网络（MTCNN）</h2> 
<p>卷积神经网络通过逐层抽象的方式来提取目标的特征，其中一个重要的概念是感受野，如果感受野太小，只能观察到局部的特征，如果感受野太大，则获得过多无效的特征。因此研究员一直都在设计各种各样的尺度模型架构。用于综合不同感受野和粒度下的特征。通常采用的是图像金字塔和特征金字塔这两种方案。具体的网络结构可以分成一下几种：</p> 
<h3 id="2.1%20%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%BE%93%E5%85%A5%E7%BD%91%E7%BB%9C">2.1 多尺度输入网络</h3> 
<p>     多尺度输入网络就是使用多个尺度的图像（图像金字塔）作为输入，如下图所示，然后对其结果进行融合，传统的人脸检测算法V-J框架采用的就是这样的思路。深度学习网络模型MTCNN人脸检测算法也是使用的这样的思路。</p> 
<p style="text-align:center;"><img alt="" height="247" src="https://images2.imgbox.com/90/2b/DGB5yRAQ_o.png" width="488"></p> 
<p></p> 
<p>      下面详细介绍一下MTCNN神经网络。<strong>MTCNN</strong>，Multi-task convolutional neural network（多任务卷积神经网络），将人脸区域检测与人脸关键点检测放在了一起，它的主题框架类似于cascade。总体可分为P-Net、R-Net、和O-Net三层网络结构。</p> 
<p>     它是2016年中国科学院深圳研究院提出的用于人脸检测任务的多任务神经网络模型，该模型主要采用了<strong>三个级联的网络</strong>，采用<strong>候选框加分类器</strong>的思想，进行快速高效的人脸检测。这三个级联的网络分别是快速生成<strong>候选窗口的P-Ne</strong>t、进行<strong>高精度候选窗口过滤选择的R-Net</strong>和<strong>生成最终边界框</strong>与<strong>人脸关键点的O-Net</strong>。和很多处理图像问题的卷积神经网络模型，该模型也用到了图像金字塔、边框回归、非最大值抑制等技术。<strong> 具体的实现过程为：</strong></p> 
<p><strong>构建图像金字塔</strong></p> 
<blockquote> 
 <p>首先将图像进行不同尺度的变换，构建图像金字塔，以适应不同大小的人脸的进行检测。</p> 
</blockquote> 
<p><strong>P-Net </strong></p> 
<p>     全称为Proposal Network，其基本的构造是一个全卷积网络。对上一步构建完成的图像金字塔，通过一个<em>FCN</em>进行初步特征提取与标定边框，并进行<em>Bounding-Box Regression</em>调整窗口与<em>NMS</em>进行大部分窗口的过滤。</p> 
<p>     P-Net是一个人脸区域的区域建议网络，该网络的将特征输入结果三个卷积层之后，通过一个人脸分类器判断该区域是否是人脸，同时使用边框回归和一个面部关键点的定位器来进行人脸区域的初步提议，该部分最终将输出很多张可能存在人脸的人脸区域，并将这些区域输入R-Net进行进一步处理。</p> 
<p><strong>这一部分的基本思想是使用较为浅层、较为简单的CNN快速生成人脸候选窗口。</strong></p> 
<p><img alt="" src="https://images2.imgbox.com/f8/5b/fBwpGAtk_o.jpg"></p> 
<p><strong>R-Net </strong></p> 
<p>      全称为Refine Network，其基本的构造是一个卷积神经网络，相对于第一层的P-Net来说，增加了一个全连接层，因此对于输入数据的筛选会更加严格。在图片经过P-Net后，会留下许多预测窗口，我们将所有的预测窗口送入R-Net，这个网络会滤除大量效果比较差的候选框，最后对选定的候选框进行Bounding-Box Regression和NMS进一步优化预测结果。</p> 
<p><strong>    R-Net的思想是使用一个相对于P-Net更复杂的网络结构来对<em>P-Net</em>生成的可能是人脸区域区域窗口进行进一步选择和调整，从而达到高精度过滤和人脸区域优化的效果。</strong></p> 
<p><img alt="" src="https://images2.imgbox.com/9c/cc/tveUrXV4_o.png"></p> 
<p><strong>O-Net</strong></p> 
<p><strong>O-Net的思想和R-Net类似，使用更复杂的网络对模型性能进行优化</strong> </p> 
<p><img alt="" src="https://images2.imgbox.com/60/5a/VDxFWtFl_o.png"></p> 
<p><strong> 下面是整个系统的工作流图</strong></p> 
<p><img alt="" src="https://images2.imgbox.com/e4/f8/hJB797IJ_o.png"></p> 
<h3 id="%C2%A02.2%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C"> 2.2 多尺度特征融合网络</h3> 
<p>多尺度特征融合网络常见的是两种结构，一种是并行多分支网络（图1），一种是串行的跳层连接网络图2。</p> 
<p><img alt="" height="322" src="https://images2.imgbox.com/67/56/FPZjVOdU_o.png" width="753"></p> 
<p style="text-align:center;"> 图 1  并行多分支网络</p> 
<p style="text-align:center;"><img alt="" height="323" src="https://images2.imgbox.com/95/0f/KmJrJTva_o.png" width="347"></p> 
<p></p> 
<p style="text-align:center;">  图 2 串行的跳层连接网络</p> 
<p>       </p> 
<h4 id="2.2.1%C2%A0%E5%B9%B6%E8%A1%8C%E5%A4%9A%E5%88%86%E6%94%AF%E7%BD%91%E7%BB%9C">2.2.1 并行多分支网络</h4> 
<p><strong>1)Inception结构</strong></p> 
<p>      并行多分支网络通常包含感受野不同的卷积核，最为典型的结构为Inception结构，如图所示分别使用1*1 的卷积，3*3的卷积，5*5的卷积和3*3的最大池化。该结构将这四个分支对输入分别提取特征后进行融合，然后作为下一层的特征输入。</p> 
<p style="text-align:center;"><img alt="" height="241" src="https://images2.imgbox.com/9c/07/FyCBbE6a_o.png" width="447"></p> 
<p style="text-align:center;"> Inception结构</p> 
<p><strong>2) PSPNet 结构（图像分割中使用）</strong></p> 
<p>     <strong>PSPNet </strong> 直接使用不同大小的池化操作，核心模块是金字塔池化模块( pyramid pooling module)，它能够聚合不同区域的上下文信息,从而提高获取全局信息的能力。实验表明这样的先验表示(即指代PSP这个结构)是有效的，在多个数据集上展现了优良的效果。</p> 
<p>PSPNet的整体架构如下：</p> 
<p><img alt="" src="https://images2.imgbox.com/ad/7d/MfVBNIkp_o.jpg"></p> 
<p>   <strong>  该模块融合了4种不同金字塔尺度的特征</strong>，第一行红色是最粗糙的特征–全局池化生成单个bin输出，后面三行是不同尺度的池化特征。为了保证全局特征的权重，如果金字塔共有N个级别，则在每个级别后使用1×1的卷积将对于级别通道降为原本的1/N。再通过双线性插值获得未池化前的大小，最终concat到一起。<br>       金字塔等级的池化核大小是可以设定的，这与送到金字塔的输入有关。论文中使用的4个等级，核大小分别为1×1，2×2，3×3，6×6；</p> 
<p><strong>3）DeeplabV3结构（图像分割中使用）</strong></p> 
<p><strong>和</strong> Inception结构不同的地方主要是使用空洞卷积控制感受野，DeepLab v3+将特征提取阶段最后几个layer的conv（图片中黄色部分）变成了<strong>dilated conv，</strong>使分辨率不再降低，但增大感受野。也就是说这样在保留位置信息的同时，语义信息保持不变。<br><img alt="" src="https://images2.imgbox.com/f6/5e/vPW0TI0w_o.png"></p> 
<p><strong> 4）Trident Network(目标检测模型)</strong></p> 
<p>    Trident network的网络结构如下，显然，叫做“三叉戟网络”就名副其实了。由图中可以看出，三个分支从上到下对应的<strong>Dilation系数</strong>逐渐增大，因此对应的目标尺寸也逐渐增大。即第一个分支用来检测小目标，第二个分支用来检测中等目标，第三个分支用来检测大目标，其和<strong>DeeplabV3网络一样，也是通过dilated conv（空洞卷积），</strong>使分辨率不再降低，但增大感受野。</p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/3c/8f/6qiWeiE3_o.png"></p> 
<h4 id="%C2%A02.2.2%C2%A0%E4%B8%B2%E8%A1%8C%E7%9A%84%E8%B7%B3%E5%B1%82%E8%BF%9E%E6%8E%A5%E7%BD%91%E7%BB%9C"> 2.2.2 串行的跳层连接网络</h4> 
<p>串行的跳层连接网络以FCN为代表，FCN的运行原理：将一张任意尺寸的图片输入到FCN中，首先经过卷积得到特征图（因为该特征图非常小，故可以称为热图），然后<strong>运用反卷积和跳级的方法</strong>，还原出与输入图片尺寸相同的特征图，将该特征图与原始图像对比，实现了每个像素的预测，保留了原始输入图像中的空间信息。<br> 整体的运行流程如下所示：</p> 
<p><img alt="" src="https://images2.imgbox.com/de/74/WwQ43YCM_o.jpg"></p> 
<p id="%E8%B7%B3%E7%BA%A7%E7%9A%84%E6%80%9D%E6%83%B3"><strong>跳级的思想：</strong></p> 
<p>       前面提到了“放大”、“缩小”的两个卷积过程，可是根据实际操作发现，<strong>一步直接将“缩小”后特征图放大效果非常不好</strong>，有很多图片的细节没有办法体现。于是作者提出了跳级的思想。</p> 
<p> <img alt="" src="https://images2.imgbox.com/d6/d6/xBjF1oAV_o.jpg"></p> 
<p>      所谓跳级，也就是<strong>分步将特征图“放大”</strong>。可以看到图中有三种“放大”的策略，它们分别是FCN-32s，FCN-16s，FCN-8s。而且FCN中对特征图的放大一共是32倍（原因是2的8次方）。<br>        我们以FCN-8s为例讲解跳级思想，首先将1 × 1特征图上采样2倍，然后与之前特征图尺寸相同的相加，得到新的上采样2倍特征图。<br>        新的上采样2倍的特征图继续上采样2倍，然后与之前特征图尺寸相同的相加，得到新的上采样4倍的特征图。<br>        之后，特征图不再与之前的特征图相加，以2倍的上采样不断进行，直到采样的总倍数为32倍。所以跳级的精华在于与之前的特征图相融合，可以更好的利用底层位置信息和高层语义信息。</p> 
<p>下图详细的介绍了网路的连接结构</p> 
<p><img alt="" height="448" src="https://images2.imgbox.com/dc/23/KPwQ9hcF_o.png" width="685"></p> 
<p></p> 
<p>       图中，image是原图像，conv1,conv2..,conv5为卷积操作，pool1,pool2,..pool5为pool操作（pool就是使得图片变为原图的1/2），注意con6-7是最后的卷积层，最右边一列是upsample后的end to end结果。必须说明的是图中nx是指对应的特征图上采样n倍（即变大n倍），并不是指有n个特征图，如32x upsampled 中的32x是图像只变大32倍，不是有32个上采样图像，又如2x conv7是指conv7的特征图变大2倍。</p> 
<h2 id="3%EF%BC%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E9%A2%84%E6%B5%8B%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C">3，多尺度特征预测融合网络</h2> 
<p>     多尺度特征预测融合网络即在不同的特征尺度进行预测，最后将结果进行融合如下图所示，目标检测SSD为其主要的代表网络。</p> 
<p style="text-align:center;"><img alt="" height="332" src="https://images2.imgbox.com/aa/99/zbmZEGxk_o.png" width="515"></p> 
<p> 单层feature map预测和特征金字塔预测对比</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/1b/a8/dcxqMfs7_o.png"></p> 
<p></p> 
<h3 id="3.1%20SSD%20%E7%BD%91%E7%BB%9C">3.1 SSD 网络</h3> 
<p>       最基础的SSD网络是以Vgg16作为backbone（主干网）, 输入图片尺寸为300x300，SSD(Single Shot MultiBox Detector)检测网络可概括为三个特征：one-stage检测器，多个尺度的特征图检测(MultiBox)，大量的先验框(Prior Boxes)。相比于YoLo和Faster-RCNN，在准确度和速度上进行了折衷。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/1e/88/LlXE5gUe_o.png"></p> 
<p></p> 
<p><strong>模型计算流程：</strong></p> 
<ul><li> <p>模型通过Base部分得到两个特征图(1, 512, 38, 38)和(1, 1024, 19, 19)</p> </li><li> <p>通过extra部分得到四个特征图(1, 512, 10, 10)，(1, 256, 5, 5)，(1, 256, 3, 3)和(1, 256, 1, 1)</p> </li><li> <p>这6个特征图再通过class_predictors和box_predictors分别得到置信度和坐标：</p> </li><li> 
  <blockquote> 
   <p>(1, 512, 38, 38) =》 (1, 4x4, 38, 38) 和 (1, 4x21, 38, 38)</p> 
   <p>(1, 1024, 19, 19) =》 (1, 6x4, 19, 19) 和 (1, 6x21, 19, 19) </p> 
   <p>(1, 512, 10, 10) =》 (1, 6x4, 10, 10) 和 (1, 6x21, 10, 10) </p> 
   <p>(1, 256, 5, 5) =》 (1, 6x4, 5, 5) 和 (1, 6x21, 5, 5)</p> 
   <p> (1, 256, 3, 3) =》 (1, 4x4, 3, 3) 和 (1, 4x21, 3, 3)</p> 
   <p>(1, 256, 1, 1) =》 (1, 4x4,1, 1) 和 (1, 4x21, 1, 1)</p> 
  </blockquote> </li><li> <p>最终得到所有预测框的loc：(1, 8732, 4)和conf：(1, 8732, 21)</p> </li></ul> 
<p><strong>训练阶段</strong></p> 
<ul><li> <p>输出所有预测框的loc_p：(1, 8732, 4)，con_p：(1, 8732, 21)和先验框anchors：(8732, 4)；结合gt_box, gt_id计算loss</p> </li></ul> 
<p><strong>测试阶段</strong></p> 
<ul><li> <p>根据先验框anchors和预测box偏移值，计算真实box坐标值和类别置信度，经过NMS，最后输出预测的box坐标值和置信度</p> </li></ul> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/aa/19/p5XdrFvt_o.png"></p> 
<h3 id="3.2%C2%A0SSH%C2%A0%E7%BD%91%E7%BB%9C">3.2 SSH 网络</h3> 
<p>骨干网络：<code>VGG-16</code></p> 
<p><code>工作原理如下图所示：</code></p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/75/8b/WesbBrPn_o.png"></p> 
<p> <img alt="" height="243" src="https://images2.imgbox.com/0a/7e/ZwxENBh0_o.png" width="879"></p> 
<h2 id="4%EF%BC%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E5%92%8C%E9%A2%84%E6%B5%8B%E8%9E%8D%E5%90%88%E7%BD%91%E7%BB%9C%C2%A0">4，多尺度特征和预测融合网络 </h2> 
<p> 这种机制就是将第2章还有第三章的两种方法的融合，将两种机制融合在一起，特征提取可以多尺度同时预测也可以多尺度。该网络较为经典的网络是FPN（目标检测网络），该网络将高层特征添加到相邻的低层组成新的特征，然后进行预测。</p> 
<h3 id="4.1%20%E4%B8%8D%E5%90%8C%E5%A4%9A%E5%B0%BA%E5%BA%A6%E7%89%B9%E5%BE%81%E5%8F%8A%E9%A2%84%E6%B5%8B%E6%96%B9%E5%BC%8F%E7%9A%84%E5%AF%B9%E6%AF%94">4.1 不同多尺度特征及预测方式的对比</h3> 
<p>下图FIg1展示了4种利用特征的形式：<br> （a）图像金字塔，即将图像做成不同的scale，然后不同scale的图像生成对应的不同scale的特征。这种方法的缺点在于增加了时间成本。有些算法会在测试时候采用图像金字塔。<br> （b）像SPP net，Fast RCNN，Faster RCNN是采用这种方式，即仅采用网络最后一层的特征。<br> （c）像SSD（Single Shot Detector）采用这种多尺度特征融合的方式，没有上采样过程，即从网络不同层抽取不同尺度的特征做预测，这种方式不会增加额外的计算量。作者认为SSD算法中没有用到足够低层的特征（在SSD中，最低层的特征是VGG网络的conv4_3），而在作者看来足够低层的特征对于检测小物体是很有帮助的。<br> （d）FPN采用顶层特征通过上采样和低层特征做融合，而且每层都是独立预测的。</p> 
<p><img alt="这里写图片描述" src="https://images2.imgbox.com/0b/83/uFm9M8zb_o.jpg"></p> 
<p></p> 
<h3 id="4.1%20FPN%EF%BC%88Feature%20Pyramid%20Networks%EF%BC%89%E7%9A%84%E7%BB%93%E6%9E%84">4.1 FPN（Feature Pyramid Networks）的结构</h3> 
<p>      通过图像金字塔来构建不同尺度的特征金字塔。主要解决的问题是目标检测在处理多尺度变化问题是的不足，现在的很多网络都使用了利用单个高层特征(比如说Faster R-CNN利用下采样四倍的卷积层——Conv4，进行后续的物体的分类和bounding box的回归)，但是这样做有一个明显的缺陷，即小物体本身具有的像素信息较少，在下采样的过程中极易被丢失，为了处理这种物体大小差异十分明显的检测问题，经典的方法是利用图像金字塔的方式进行多尺度变化增强，但这样会带来极大的计算量。所以这篇论文提出了特征金字塔的网络结构，能在增加极小的计算量的情况下，处理好物体检测中的多尺度变化问题。FPN是一种具有侧向连接（lateral connections）的自上而下的网络结构，用来构建不同尺寸的具有高级语义信息的特征图。</p> 
<p>      FPN主网络采用ResNet,算法大致结构如下图：<strong>一个自底向上的线路，一个自顶向下的线路，横向连接（lateral connection）</strong>。图中放大的区域就是横向连接，这里1*1的卷积核的主要作用是减少卷积核的个数，也就是减少了feature map的个数，并不改变feature map的尺寸大小。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/28/bb/tyubQ2Ls_o.png"></p> 
<p>      <strong>自底向上</strong>其实就是网络的前向过程。在前向过程中，feature map的大小在经过某些层后会改变，而在经过其他一些层的时候不会改变，作者将不改变feature map大小的层归为一个stage，因此每次抽取的特征都是每个stage的最后一个层输出，这样就能构成特征金字塔。<br><strong>      自顶向下</strong>的过程采用上采样（upsampling）进行，而横向连接则是将上采样的结果和自底向上生成的相同大小的feature map进行融合（merge）。在融合之后还会再采用3*3的卷积核对每个融合结果进行卷积，目的是消除上采样的混叠效应（aliasing effect）。并假设生成的feature map结果是P2，P3，P4，P5，和原来自底向上的卷积结果C2，C3，C4，C5一一对应。</p> 
<p>贴一个<strong>ResNet的结构图</strong>：这里作者采用Conv2，CONV3，CONV4和CONV5的输出。因此类似Conv2就可以看做一个stage。</p> 
<p><img alt="这里写图片描述" src="https://images2.imgbox.com/95/20/S5cepXAD_o.jpg"></p> 
<p></p> 
<h3 id="%C2%A04.2%20FPN%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"> 4.2 FPN训练过程</h3> 
<p><strong>作者一方面将FPN放在RPN网络中用于生成proposal</strong>，原来的RPN网络是以主网络的某个卷积层输出的feature map作为输入，简单讲就是只用这一个尺度的feature map。但是现在要将FPN嵌在RPN网络中，生成不同尺度特征并融合作为RPN网络的输入。在每一个scale层，都定义了不同大小的anchor，对于P2，P3，P4，P5，P6这些层，定义anchor的大小为32^2,64^2,128^2,256^2，512^2，另外每个scale层都有3个长宽对比度：1:2，1:1，2:1。所以整个特征金字塔有15种anchor。</p> 
<p><strong>正负样本的界定和Faster RCNN差不多</strong>：如果某个anchor和一个给定的ground truth有最高的IOU或者和任意一个Ground truth的IOU都大于0.7，则是正样本。如果一个anchor和任意一个ground truth的IOU都小于0.3，则为负样本。</p> 
<p>看看<strong>加入FPN的RPN网络的有效性</strong>，如下表Table1。网络这些结果都是基于ResNet-50。评价标准采用AR，AR表示Average Recall，AR右上角的100表示每张图像有100个anchor，AR的右下角s，m，l表示COCO数据集中object的大小分别是小，中，大。feature列的大括号{}表示每层独立预测。</p> 
<p><img alt="" src="https://images2.imgbox.com/bb/b5/vqJq55Ae_o.jpg"></p> 
<p><a href="https://blog.csdn.net/baidu_30594023/article/details/82623623" title="FPN参考博文：FPN全解-最全最详细_baidu_30594023的博客-CSDN博客_fpn">FPN参考博文：FPN全解-最全最详细_baidu_30594023的博客-CSDN博客_fpn</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/78e1f382e24277f48cecc21101af58fa/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">小猫爪：S32K3学习笔记06-S32K3之BCTU</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3f36725715be0cfac40b65d0eb8e7657/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">day4homework</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>