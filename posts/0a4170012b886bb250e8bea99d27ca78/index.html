<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>MR实战：词频统计 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="MR实战：词频统计" />
<meta property="og:description" content="文章目录 一、实战概述二、提出任务三、完成任务（一）准备数据1、在虚拟机上创建文本文件2、上传文件到HDFS指定目录 （二）实现步骤1、创建Maven项目2、添加相关依赖3、创建日志属性文件4、创建词频统计映射器类5、创建词频统计归并器类6、创建词频统计驱动器类7、启动应用，查看结果 四、实战总结 一、实战概述 本实战演练旨在利用Hadoop MapReduce框架在虚拟环境中执行一个简单的词频统计任务。首先，在master节点上创建了一个包含多个单词行的文本文件words.txt，并将该文件上传至HDFS中的指定目录/wordcount/input。
在集成开发环境IntelliJ IDEA中，我们创建了一个名为MRWordCount的Maven项目，并引入了Apache Hadoop 3.3.4版本的客户端依赖和JUnit测试框架。为了便于日志管理，添加了log4j.properties配置文件来定义日志输出格式及位置。
接下来，实现了两个关键类：WordCountMapper和WordCountReducer。WordCountMapper继承自Mapper接口，负责读取输入文本文件中的每一行内容，将每行按空格分割成单词，并为每个单词生成一个键值对（&lt;单词, 1&gt;），以便后续计数处理。而WordCountReducer则继承自Reducer接口，它接收Mapper阶段产生的所有相同单词的键及其对应的次数，进行合并统计并输出格式化的&#34;(单词, 出现次数)&#34;键值对。
最后，通过WordCountDriver驱动类完成整个MapReduce作业的设置与执行。此类初始化Hadoop Configuration对象、设置Job参数（包括Mapper和Reducer类、键值类型等）、指定了HDFS上的输入输出路径，并最终提交作业至集群执行。作业完成后，WordCountDriver还会从HDFS上读取结果并显示到控制台。
经过上述步骤，当运行WordCountDriver主类时，程序将会读取HDFS上的输入文件，运用MapReduce模型进行分布式计算，最终得到期望的词频统计结果，并在控制台展示出来。这个实例展示了如何使用Hadoop MapReduce进行大规模数据处理的实际操作流程。
二、提出任务 单词文件 - words.txt hello hadoop world hello hive world hello hbase world hadoop hive hbase I love hadoop and hive 使用MR框架，进行词频统计，输出如下结果
三、完成任务 （一）准备数据 1、在虚拟机上创建文本文件 在master虚拟机上创建words.txt文件
2、上传文件到HDFS指定目录 创建/wordcount/input目录，执行命令：hdfs dfs -mkdir -p /wordcount/input
将文本文件words.txt，上传到HDFS的/wordcount/input目录
（二）实现步骤 说明：集成开发环境IntelliJ IDEA版本 - 2022.3 1、创建Maven项目 Maven项目 - MRWordCount，设置了JDK版本 - 1.8，组标识 - net.huawei.mr
单击【Create】按钮，得到初始化项目
2、添加相关依赖 在pom.xml文件里添加hadoop-client和junit依赖
&lt;dependencies&gt; &lt;!--hadoop客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;org." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0a4170012b886bb250e8bea99d27ca78/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-05T18:55:02+08:00" />
<meta property="article:modified_time" content="2024-01-05T18:55:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">MR实战：词频统计</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_1" rel="nofollow">一、实战概述</a></li><li><a href="#_11" rel="nofollow">二、提出任务</a></li><li><a href="#_23" rel="nofollow">三、完成任务</a></li><li><ul><li><a href="#_24" rel="nofollow">（一）准备数据</a></li><li><ul><li><a href="#1_25" rel="nofollow">1、在虚拟机上创建文本文件</a></li><li><a href="#2HDFS_28" rel="nofollow">2、上传文件到HDFS指定目录</a></li></ul> 
   </li><li><a href="#_35" rel="nofollow">（二）实现步骤</a></li><li><ul><li><a href="#1Maven_37" rel="nofollow">1、创建Maven项目</a></li><li><a href="#2_44" rel="nofollow">2、添加相关依赖</a></li><li><a href="#3_66" rel="nofollow">3、创建日志属性文件</a></li><li><a href="#4_82" rel="nofollow">4、创建词频统计映射器类</a></li><li><a href="#5_120" rel="nofollow">5、创建词频统计归并器类</a></li><li><a href="#6_159" rel="nofollow">6、创建词频统计驱动器类</a></li><li><a href="#7_264" rel="nofollow">7、启动应用，查看结果</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_267" rel="nofollow">四、实战总结</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>一、实战概述</h2> 
<ul><li> <p>本实战演练旨在利用Hadoop MapReduce框架在虚拟环境中执行一个简单的词频统计任务。首先，在master节点上创建了一个包含多个单词行的文本文件<code>words.txt</code>，并将该文件上传至HDFS中的指定目录<code>/wordcount/input</code>。</p> </li><li> <p>在集成开发环境IntelliJ IDEA中，我们创建了一个名为<code>MRWordCount</code>的Maven项目，并引入了Apache Hadoop 3.3.4版本的客户端依赖和JUnit测试框架。为了便于日志管理，添加了log4j.properties配置文件来定义日志输出格式及位置。</p> </li><li> <p>接下来，实现了两个关键类：<code>WordCountMapper</code>和<code>WordCountReducer</code>。<code>WordCountMapper</code>继承自Mapper接口，负责读取输入文本文件中的每一行内容，将每行按空格分割成单词，并为每个单词生成一个键值对（&lt;单词, 1&gt;），以便后续计数处理。而<code>WordCountReducer</code>则继承自Reducer接口，它接收Mapper阶段产生的所有相同单词的键及其对应的次数，进行合并统计并输出格式化的"(单词, 出现次数)"键值对。</p> </li><li> <p>最后，通过<code>WordCountDriver</code>驱动类完成整个MapReduce作业的设置与执行。此类初始化Hadoop Configuration对象、设置Job参数（包括Mapper和Reducer类、键值类型等）、指定了HDFS上的输入输出路径，并最终提交作业至集群执行。作业完成后，<code>WordCountDriver</code>还会从HDFS上读取结果并显示到控制台。</p> </li><li> <p>经过上述步骤，当运行<code>WordCountDriver</code>主类时，程序将会读取HDFS上的输入文件，运用MapReduce模型进行分布式计算，最终得到期望的词频统计结果，并在控制台展示出来。这个实例展示了如何使用Hadoop MapReduce进行大规模数据处理的实际操作流程。</p> </li></ul> 
<h2><a id="_11"></a>二、提出任务</h2> 
<ul><li>单词文件 - <code>words.txt</code></li></ul> 
<pre><code>hello hadoop world
hello hive world
hello hbase world
hadoop hive hbase
I love hadoop and hive
</code></pre> 
<ul><li>使用MR框架，进行词频统计，输出如下结果<br> <img src="https://images2.imgbox.com/e5/ae/LdwBo2CE_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_23"></a>三、完成任务</h2> 
<h3><a id="_24"></a>（一）准备数据</h3> 
<h4><a id="1_25"></a>1、在虚拟机上创建文本文件</h4> 
<ul><li>在master虚拟机上创建<code>words.txt</code>文件<br> <img src="https://images2.imgbox.com/b0/c2/3qnlzztT_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="2HDFS_28"></a>2、上传文件到HDFS指定目录</h4> 
<ul><li> <p>创建<code>/wordcount/input</code>目录，执行命令：<code>hdfs dfs -mkdir -p /wordcount/input</code><br> <img src="https://images2.imgbox.com/ed/f5/9hxg3qlg_o.png" alt="在这里插入图片描述"></p> </li><li> <p>将文本文件<code>words.txt</code>，上传到HDFS的<code>/wordcount/input</code>目录<br> <img src="https://images2.imgbox.com/90/43/X8o9mNpW_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<h3><a id="_35"></a>（二）实现步骤</h3> 
<ul><li>说明：集成开发环境IntelliJ IDEA版本 - <code>2022.3</code></li></ul> 
<h4><a id="1Maven_37"></a>1、创建Maven项目</h4> 
<ul><li> <p>Maven项目 - <code>MRWordCount</code>，设置了JDK版本 - <code>1.8</code>，组标识 - <code>net.huawei.mr</code><br> <img src="https://images2.imgbox.com/95/36/yodADop4_o.png" alt="在这里插入图片描述"></p> </li><li> <p>单击【Create】按钮，得到初始化项目<br> <img src="https://images2.imgbox.com/b6/97/NP0XbP15_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<h4><a id="2_44"></a>2、添加相关依赖</h4> 
<ul><li>在<code>pom.xml</code>文件里添加<code>hadoop-client</code>和<code>junit</code>依赖<br> <img src="https://images2.imgbox.com/37/db/zBvXhFvi_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>                                   
    <span class="token comment">&lt;!--hadoop客户端--&gt;</span>                             
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>                                 
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.hadoop<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>     
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>hadoop-client<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>   
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.3.4<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>                 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>                                
    <span class="token comment">&lt;!--单元测试框架--&gt;</span>                                
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>                                 
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>                 
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>junit<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>           
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>4.13.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>                
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>                                
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>                                                  
</code></pre> 
<ul><li>刷新项目依赖<br> <img src="https://images2.imgbox.com/9e/f6/cvoPRPji_o.png" alt="在这里插入图片描述"></li></ul> 
<h4><a id="3_66"></a>3、创建日志属性文件</h4> 
<ul><li>在<code>resources</code>目录里创建<code>log4j.properties</code>文件<br> <img src="https://images2.imgbox.com/8c/12/46848TOb_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code class="prism language-shell"><span class="token assign-left variable">log4j.rootLogger</span><span class="token operator">=</span>ERROR, stdout, logfile
<span class="token assign-left variable">log4j.appender.stdout</span><span class="token operator">=</span>org.apache.log4j.ConsoleAppender
<span class="token assign-left variable">log4j.appender.stdout.layout</span><span class="token operator">=</span>org.apache.log4j.PatternLayout
<span class="token assign-left variable">log4j.appender.stdout.layout.ConversionPattern</span><span class="token operator">=</span>%d %p <span class="token punctuation">[</span>%c<span class="token punctuation">]</span> - %m%n
<span class="token assign-left variable">log4j.appender.logfile</span><span class="token operator">=</span>org.apache.log4j.FileAppender
<span class="token assign-left variable">log4j.appender.logfile.File</span><span class="token operator">=</span>target/wordcount.log
<span class="token assign-left variable">log4j.appender.logfile.layout</span><span class="token operator">=</span>org.apache.log4j.PatternLayout
<span class="token assign-left variable">log4j.appender.logfile.layout.ConversionPattern</span><span class="token operator">=</span>%d %p <span class="token punctuation">[</span>%c<span class="token punctuation">]</span> - %m%n
</code></pre> 
<h4><a id="4_82"></a>4、创建词频统计映射器类</h4> 
<ul><li>创建<code>net.huawei.mr</code>包，在包里创建<code>WordCountMapper</code>类<br> <img src="https://images2.imgbox.com/8c/c9/0NLAvHd8_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">net<span class="token punctuation">.</span>huawei<span class="token punctuation">.</span>mr</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IntWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">LongWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Mapper</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span></span><span class="token punctuation">;</span>

<span class="token comment">/**
 * 功能：词频统计映射器类
 * 作者：华卫
 * 日期：2024年01月05日
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordCountMapper</span> <span class="token keyword">extends</span> <span class="token class-name">Mapper</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">LongWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">IntWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">map</span><span class="token punctuation">(</span><span class="token class-name">LongWritable</span> key<span class="token punctuation">,</span> <span class="token class-name">Text</span> value<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span>
            <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 获取行内容</span>
        <span class="token class-name">String</span> line <span class="token operator">=</span> value<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 按空格拆分成单词数组</span>
        <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> words <span class="token operator">=</span> line<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span><span class="token string">" "</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 遍历单词数组，生成输出键值对</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> word <span class="token operator">:</span> words<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token keyword">new</span> <span class="token class-name">IntWritable</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<ul><li> <p>该代码定义了一个Hadoop MapReduce作业中的词频统计Mapper类（WordCountMapper），继承自Mapper&lt;LongWritable, Text, Text, IntWritable&gt;。它接收输入键值对（LongWritable行偏移量，Text行内容），按空格分割每行文本为单词，并为每个单词输出一个键值对到上下文（&lt;Text: 单词, IntWritable: 1&gt;），用于后续Reducer进行计数汇总。</p> </li><li> <p>映射任务与归并任务示意图<br> <img src="https://images2.imgbox.com/41/97/u9gTOeRP_o.png" alt="在这里插入图片描述"></p> </li></ul> 
<h4><a id="5_120"></a>5、创建词频统计归并器类</h4> 
<ul><li>在<code>net.huawei.mr</code>包里创建<code>WordCountReducer</code><br> <img src="https://images2.imgbox.com/60/67/EULZjKfG_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">net<span class="token punctuation">.</span>huawei<span class="token punctuation">.</span>mr</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IntWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Reducer</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOException</span></span><span class="token punctuation">;</span>

<span class="token comment">/**
 * 功能：词频统计归并类
 * 作者：华卫
 * 日期：2024年01月05日
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordCountReducer</span> <span class="token keyword">extends</span> <span class="token class-name">Reducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">IntWritable</span><span class="token punctuation">,</span> <span class="token class-name">Text</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">&gt;</span></span> <span class="token punctuation">{<!-- --></span>
    <span class="token annotation punctuation">@Override</span>
    <span class="token keyword">protected</span> <span class="token keyword">void</span> <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token class-name">Text</span> key<span class="token punctuation">,</span> <span class="token class-name">Iterable</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">IntWritable</span><span class="token punctuation">&gt;</span></span> values<span class="token punctuation">,</span> <span class="token class-name">Context</span> context<span class="token punctuation">)</span>
            <span class="token keyword">throws</span> <span class="token class-name">IOException</span><span class="token punctuation">,</span> <span class="token class-name">InterruptedException</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 定义键（单词）出现次数</span>
        <span class="token keyword">int</span> count <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
        <span class="token comment">// 遍历输入值迭代器</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">IntWritable</span> value <span class="token operator">:</span> values<span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            count <span class="token operator">=</span> count <span class="token operator">+</span> value<span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 针对此案例，可以写为count++;</span>
        <span class="token punctuation">}</span>

        <span class="token comment">// 生成新的键，格式为(word,count)</span>
        <span class="token class-name">String</span> newKey <span class="token operator">=</span> <span class="token string">"("</span> <span class="token operator">+</span> key<span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">","</span> <span class="token operator">+</span> count <span class="token operator">+</span> <span class="token string">")"</span><span class="token punctuation">;</span>

        <span class="token comment">// 输出新的键值对</span>
        context<span class="token punctuation">.</span><span class="token function">write</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">Text</span><span class="token punctuation">(</span>newKey<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<ul><li>该WordCountReducer类是Hadoop MapReduce中用于词频统计的归约器，继承自Reducer&lt;Text, IntWritable, Text, NullWritable&gt;。在reduce方法中，它接收一个单词键（Text类型）及其对应的出现次数迭代器（IntWritable类型）。通过遍历所有次数并将它们累加到变量count上，然后将单词与统计结果拼接成"(word,count)"格式的新键，并使用NullWritable作为值输出，从而实现单词及其词频的合并统计。</li></ul> 
<h4><a id="6_159"></a>6、创建词频统计驱动器类</h4> 
<ul><li>在<code>net.huawei.mr</code>包里，创建<code>WordCountDriver</code>类<br> <img src="https://images2.imgbox.com/de/0f/IBS8xMhK_o.png" alt="在这里插入图片描述"></li></ul> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">net<span class="token punctuation">.</span>huawei<span class="token punctuation">.</span>mr</span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>conf<span class="token punctuation">.</span></span><span class="token class-name">Configuration</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">FSDataInputStream</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">FileStatus</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">FileSystem</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>fs<span class="token punctuation">.</span></span><span class="token class-name">Path</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IOUtils</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">IntWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">NullWritable</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>io<span class="token punctuation">.</span></span><span class="token class-name">Text</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span></span><span class="token class-name">Job</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>input<span class="token punctuation">.</span></span><span class="token class-name">FileInputFormat</span></span><span class="token punctuation">;</span>
<span class="token keyword">import</span> <span class="token import"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>mapreduce<span class="token punctuation">.</span>lib<span class="token punctuation">.</span>output<span class="token punctuation">.</span></span><span class="token class-name">FileOutputFormat</span></span><span class="token punctuation">;</span>

<span class="token keyword">import</span> <span class="token import"><span class="token namespace">java<span class="token punctuation">.</span>net<span class="token punctuation">.</span></span><span class="token class-name">URI</span></span><span class="token punctuation">;</span>

<span class="token comment">/**
 * 功能：词频统计驱动器类
 * 作者：华卫
 * 日期：2024年01月05日
 */</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">WordCountDriver</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 创建配置对象</span>
        <span class="token class-name">Configuration</span> conf <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Configuration</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置客户端使用数据节点主机名属性</span>
        conf<span class="token punctuation">.</span><span class="token function">set</span><span class="token punctuation">(</span><span class="token string">"dfs.client.use.datanode.hostname"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 获取作业实例</span>
        <span class="token class-name">Job</span> job <span class="token operator">=</span> <span class="token class-name">Job</span><span class="token punctuation">.</span><span class="token function">getInstance</span><span class="token punctuation">(</span>conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置作业启动类</span>
        job<span class="token punctuation">.</span><span class="token function">setJarByClass</span><span class="token punctuation">(</span><span class="token class-name">WordCountDriver</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 设置Mapper类</span>
        job<span class="token punctuation">.</span><span class="token function">setMapperClass</span><span class="token punctuation">(</span><span class="token class-name">WordCountMapper</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置map任务输出键类型</span>
        job<span class="token punctuation">.</span><span class="token function">setMapOutputKeyClass</span><span class="token punctuation">(</span><span class="token class-name">Text</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置map任务输出值类型</span>
        job<span class="token punctuation">.</span><span class="token function">setMapOutputValueClass</span><span class="token punctuation">(</span><span class="token class-name">IntWritable</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 设置Reducer类</span>
        job<span class="token punctuation">.</span><span class="token function">setReducerClass</span><span class="token punctuation">(</span><span class="token class-name">WordCountReducer</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置reduce任务输出键类型</span>
        job<span class="token punctuation">.</span><span class="token function">setOutputKeyClass</span><span class="token punctuation">(</span><span class="token class-name">Text</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 设置reduce任务输出值类型</span>
        job<span class="token punctuation">.</span><span class="token function">setOutputValueClass</span><span class="token punctuation">(</span><span class="token class-name">NullWritable</span><span class="token punctuation">.</span><span class="token keyword">class</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 定义uri字符串</span>
        <span class="token class-name">String</span> uri <span class="token operator">=</span> <span class="token string">"hdfs://master:9000"</span><span class="token punctuation">;</span>

        <span class="token comment">// 创建输入目录</span>
        <span class="token class-name">Path</span> inputPath <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>uri <span class="token operator">+</span> <span class="token string">"/wordcount/input"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 创建输出目录</span>
        <span class="token class-name">Path</span> outputPath <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Path</span><span class="token punctuation">(</span>uri <span class="token operator">+</span> <span class="token string">"/wordcount/output"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 获取文件系统</span>
        <span class="token class-name">FileSystem</span> fs <span class="token operator">=</span> <span class="token class-name">FileSystem</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token keyword">new</span> <span class="token class-name">URI</span><span class="token punctuation">(</span>uri<span class="token punctuation">)</span><span class="token punctuation">,</span> conf<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 删除输出目录（第二个参数设置是否递归）</span>
        fs<span class="token punctuation">.</span><span class="token function">delete</span><span class="token punctuation">(</span>outputPath<span class="token punctuation">,</span> <span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 给作业添加输入目录（允许多个）</span>
        <span class="token class-name">FileInputFormat</span><span class="token punctuation">.</span><span class="token function">addInputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> inputPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 给作业设置输出目录（只能一个）</span>
        <span class="token class-name">FileOutputFormat</span><span class="token punctuation">.</span><span class="token function">setOutputPath</span><span class="token punctuation">(</span>job<span class="token punctuation">,</span> outputPath<span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 等待作业完成</span>
        job<span class="token punctuation">.</span><span class="token function">waitForCompletion</span><span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token comment">// 输出统计结果</span>
        <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">"======统计结果======"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token class-name">FileStatus</span><span class="token punctuation">[</span><span class="token punctuation">]</span> fileStatuses <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token function">listStatus</span><span class="token punctuation">(</span>outputPath<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> fileStatuses<span class="token punctuation">.</span>length<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{<!-- --></span>
            <span class="token comment">// 输出结果文件路径</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span>fileStatuses<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 获取文件系统数据字节输入流</span>
            <span class="token class-name">FSDataInputStream</span> in <span class="token operator">=</span> fs<span class="token punctuation">.</span><span class="token keyword">open</span><span class="token punctuation">(</span>fileStatuses<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">getPath</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token comment">// 将结果文件显示在控制台</span>
            <span class="token class-name">IOUtils</span><span class="token punctuation">.</span><span class="token function">copyBytes</span><span class="token punctuation">(</span>in<span class="token punctuation">,</span> <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">,</span> <span class="token boolean">false</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<ul><li>该WordCountDriver类是Hadoop MapReduce框架中用于执行词频统计任务的驱动类。</li></ul> 
<ol><li> <p><strong>初始化配置</strong>：首先创建一个<code>Configuration</code>对象，设置客户端使用数据节点主机名属性以便正确解析路径。</p> </li><li> <p><strong>构建作业实例</strong>：通过<code>Job.getInstance(conf)</code>获取一个MapReduce作业实例，并将当前类（WordCountDriver）作为作业启动类，这样Hadoop在运行时能识别到主程序入口。</p> </li><li> <p><strong>配置Mapper和Reducer</strong>：分别指定Map阶段使用的类为<code>WordCountMapper</code>，Reduce阶段使用的类为<code>WordCountReducer</code>。同时设定Map阶段输出键值对类型为<code>Text</code>和<code>IntWritable</code>，Reduce阶段输出键值对类型也为<code>Text</code>和<code>NullWritable</code>。</p> </li><li> <p><strong>定义文件系统URI</strong>：设置HDFS地址为<code>hdfs://master:9000</code>，并基于此URI创建输入目录（/wordcount/input）和输出目录（/wordcount/output）。</p> </li><li> <p><strong>文件系统操作</strong>：连接到HDFS文件系统，删除已存在的输出目录以准备新的计算结果，然后向作业添加输入目录和设置输出目录。</p> </li><li> <p><strong>提交并监控作业</strong>：调用<code>job.waitForCompletion(true)</code>方法提交作业并等待其完成。当作业完成后，会返回一个布尔值表示作业是否成功执行。</p> </li><li> <p><strong>读取并显示结果</strong>：作业结束后，列出输出目录下的所有文件，遍历这些文件并打开每个文件进行读取。利用<code>IOUtils.copyBytes</code>方法将结果文件的内容复制到控制台输出，展示词频统计的结果。</p> </li></ol> 
<ul><li>总之，WordCountDriver类负责整个词频统计任务的初始化、配置、执行以及结果展示工作，它将Hadoop MapReduce的各个组件如Mapper、Reducer与实际的输入输出路径关联起来，形成了一个完整的词频统计应用。</li></ul> 
<h4><a id="7_264"></a>7、启动应用，查看结果</h4> 
<ul><li>运行<code>WordCountDriver</code>类，查看结果<br> <img src="https://images2.imgbox.com/49/89/HA28z4ox_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_267"></a>四、实战总结</h2> 
<ul><li>本实战通过Hadoop MapReduce框架，在虚拟环境中对<code>words.txt</code>文件进行了词频统计。首先，将数据上传至HDFS，并在IntelliJ IDEA中创建Maven项目配置相关依赖。实现的WordCountMapper负责按空格拆分单词并初始化词频为1，WordCountReducer则对相同单词的计数进行合并。最后，WordCountDriver类配置作业参数、指定输入输出路径并在集群上执行任务，完成后从HDFS读取并展示统计结果。整个过程演示了MapReduce模式处理文本数据进行词频统计的完整流程。</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/97d2584fe1327230d59adffe6166855c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">使用国内镜像源来安装 Golang 包：</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a2b5f1756a2b38e514a6eb732f95ddeb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">P60 生成式对抗网络GAN -生成器效能评估与条件式生成</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>