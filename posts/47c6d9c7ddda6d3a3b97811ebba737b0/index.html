<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Improved Denoising Diffusion Probabilistic Models 论文阅读 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Improved Denoising Diffusion Probabilistic Models 论文阅读" />
<meta property="og:description" content="前言 DDPM模型虽然在生成任务上达到了不错的效果，但是也同样存在一些问题，例如采样时间过长、对数似然不高等。对数似然是生成模型中广泛使用的指标，优化对数似然迫使生成模型学习各个数据分布，使得模型的多样性大大提高。此外，对数似然性的微小改进可以对样本质量和学习的特征表示产生巨大影响。论文在此基础上进行改进，①DDPM原来的方差系数是固定的，现在采用学习的方式；②对损失函数进行改进，在原来的MSE损失加入了混合损失；③对比改进后的DDPM和DDIM采样速度和质量，以及和GAN模型的采样质量、参数大小进行对比。
Improving the Log-likelihood 为了进行改进前后的模型对比，实验分别在CIFAR-10和ImgaNet两个数据集进行（CIFAR10是人脸专用的数据集），在ImageNet也进行实验的原因是这样的数据集的分布更加多样，不用担心过拟合的问题。将步数从T=1000到T=4000，可以将对数似然提升至3.77。
Learning Σθ (xt, t)（可学习方差） 在DDPM中，原始推理过程的方差是下式的，后来作者实验发现直接用来代替对采样结果的影响不大，两者都是固定方差（这个固定是相对可学习的参数来说的），在下图的实验结果中也同样发现这个，两者的比值随着步数t的增加不断趋近于相同，在大步数的实验中更加明显。在下面第三幅图中显示了采样过程和NLL（采样指标）的关系，最开始的步骤对采样过程的变化比较明显。
所以，提出了一种可学习的方差方法，将方差参数化为和之间log函数的内插。于是有了下面这个方差，模型输出一个向量v，每个维度包含一个分量，将该输出转换为方差，如下所示。
经过这个改进后，逆扩散过程的均值和方差都有一部分是可学习的参数，于是，为了引导方差参数的学习，在损失函数上也进行改进，变成了混合损失，是引导均值参数的学习，是引导方差参数的学习。λ的权重为0.001，去避免过度影响，如下所示。
Improving the Noise Schedule 在原来DDPM中的前向扩散过程中的噪声参数表，即都是通过在一定范围内线性插值得到的，下面上图实验结果说明在前向扩散过程中，最后一些步的加噪过程对采样质量的影响不大。下图说明的是在当线性噪声表跳过一部分逆扩散过程的步骤时，FID采样质量并没有下降得非常快。
上述想表达的是线性噪声表有时候的扩散或者逆扩散过程的步数对采样质量的贡献不大，也就是说有些步骤是浪费的。所以，论文提出了新的一种cosine噪声表，计算方式如下，是一种更加高效的取值方式。s=0.008.
下图展示的就是两种方法的比较，在扩散过程的末期，cosine比线性的方法取得的参数降到0速度更加快，也就是说减少了扩散过程末期那些对采样质量没有必要的步骤，从而更加高效。
Reducing Gradient Noise 这一段主要是对比实验，比较和的效果。下图所示在整个学习过程中，在相同的训练时间时，混合损失可以达到更大的对数似然值。
下图所示是另外一组实验，通过证明了是要比噪声梯度更加大，因而可以通过继续优化来获得更大的对数似然值。
于是，提出了新的方法，如下图所示，当计算某一步的损失时，会保留前面十个记录进行平方和来计算。Figure 6 就显示出了重新采样的的优势，确实噪声梯度会更小并且更加稳定。但是，最后得到的结论是这种方法对方法的效果并不明显。
Results and Ablations 基于以上改进作者进行了消融实验，对比是否真的有效果。可以看到对比原来的DDPM中的方法，包括和来说，和确实在NLL和FID上有一定的提升。
另外，论文也和其他基于对数似然估计的生成模型进行了实验对比，如下图所示，虽然没有同时达到最好的效果，但是证明改进之后的DDPM确实是有提升，并且和其他模型相比是有一定竞争力的。
逆扩散(采样)过程速度改进 前面使用的已经证明了比原来是损失函数更加高效，因而可以加速逆扩散过程。
其次是新的一个噪声取值方式，和一个序列s使得将对参数采样时不仅和t有关，还和方差连接起来。
下图为实验对比，可以看到对比DDPM来说，在同样的逆扩散推理步骤时，改进的方法采样的质量更加好。
和GAN对比 GAN虽然生成更加准确，但是图像的细节质量不够好，主要表现在FID这项指标上。另外就是召回率也更低，意味着改进后的DDPM更能概括模型的数据分布。
计算量 下图所展示的就是改进后的DDPM模型计算量和NLL和FID指标的关系，基本上是呈现一个幂函数的规律。说明伴随着计算量越大，模型更加复杂，结果也会更加好，取决于具体应该怎么去权衡。论文没有给出具体的原因和解释。
总结 改进的DDPM主要由两方面，第一个是损失函数，另外就是噪声表的取值方式，论文通过实验证明了这一点，不仅仅可以改进采样质量，也可以改进采样速度。其次就是和其他生成模型的对比以及和DDIM的对比，改进后的DDPM在采样质量和速度上都有一定的竞争性。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/47c6d9c7ddda6d3a3b97811ebba737b0/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-27T20:49:14+08:00" />
<meta property="article:modified_time" content="2023-02-27T20:49:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Improved Denoising Diffusion Probabilistic Models 论文阅读</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>前言</h2> 
<p>DDPM模型虽然在生成任务上达到了不错的效果，但是也同样存在一些问题，例如采样时间过长、对数似然不高等。对数似然是生成模型中广泛使用的指标，优化对数似然迫使生成模型学习各个数据分布，使得模型的多样性大大提高。此外，对数似然性的微小改进可以对样本质量和学习的特征表示产生巨大影响。论文在此基础上进行改进，①DDPM原来的方差系数是固定的，现在采用学习的方式；②对损失函数进行改进，在原来的MSE损失加入了混合损失；③对比改进后的DDPM和DDIM采样速度和质量，以及和GAN模型的采样质量、参数大小进行对比。</p> 
<h2>Improving the Log-likelihood</h2> 
<p>为了进行改进前后的模型对比，实验分别在CIFAR-10和ImgaNet两个数据集进行（CIFAR10是人脸专用的数据集），在ImageNet也进行实验的原因是这样的数据集的分布更加多样，不用担心过拟合的问题。将步数从T=1000到T=4000，可以将对数似然提升至3.77。</p> 
<h4>Learning Σθ (xt, t)（可学习方差）</h4> 
<p>在DDPM中，原始推理过程的方差是下式的<img alt="\tilde{\beta t}" class="mathcode" src="https://images2.imgbox.com/16/3c/EGrVwP93_o.png">，后来作者实验发现直接用<img alt="\beta t" class="mathcode" src="https://images2.imgbox.com/df/a5/oGbG4fja_o.png">来代替对采样结果的影响不大，两者都是固定方差（这个固定是相对可学习的参数来说的），在下图的实验结果中也同样发现这个，两者的比值随着步数t的增加不断趋近于相同，在大步数的实验中更加明显。在下面第三幅图中显示了采样过程和NLL（采样指标）的关系，最开始的步骤对采样过程的变化比较明显。</p> 
<p class="img-center"><img alt="" height="95" src="https://images2.imgbox.com/09/2f/VbbVh3m5_o.png" width="264"></p> 
<p class="img-center"><img alt="" height="290" src="https://images2.imgbox.com/40/1a/djxqh0n6_o.png" width="464"></p> 
<p class="img-center"><img alt="" height="296" src="https://images2.imgbox.com/d4/b0/BdO4dQH5_o.png" width="432"></p> 
<p> 所以，提出了一种可学习的方差方法，将方差参数化为<img alt="\beta t" class="mathcode" src="https://images2.imgbox.com/cf/7e/7wvxPaCm_o.png">和<img alt="\tilde{\beta t}" class="mathcode" src="https://images2.imgbox.com/96/3e/OwUJrrA6_o.png">之间log函数的内插。于是有了下面这个方差，模型输出一个向量v，每个维度包含一个分量，将该输出转换为方差，如下所示。</p> 
<p class="img-center"><img alt="" height="93" src="https://images2.imgbox.com/87/85/AoHyOtSj_o.png" width="569"></p> 
<p> 经过这个改进后，逆扩散过程的均值和方差都有一部分是可学习的参数，于是，为了引导方差参数的学习，在损失函数上也进行改进，变成了混合损失，<img alt="Lsimple" class="mathcode" src="https://images2.imgbox.com/cd/20/6R6yTHlK_o.png">是引导均值参数的学习，<img alt="Lvlb" class="mathcode" src="https://images2.imgbox.com/81/1a/iUSBSFvz_o.png">是引导方差参数的学习。λ的权重为0.001，去避免过度影响<img alt="Lsimple" class="mathcode" src="https://images2.imgbox.com/ea/7d/Fn38PXgQ_o.png">，如下所示。</p> 
<p class="img-center"><img alt="" height="82" src="https://images2.imgbox.com/6d/09/RUww9Ncz_o.png" width="368"></p> 
<h4>Improving the Noise Schedule</h4> 
<p>在原来DDPM中的前向扩散过程中的噪声参数表，即<img alt="\alpha t\beta t" class="mathcode" src="https://images2.imgbox.com/99/d7/L7SYEQpo_o.png">都是通过在一定范围内线性插值得到的，下面上图实验结果说明在前向扩散过程中，最后一些步的加噪过程对采样质量的影响不大。下图说明的是在当线性噪声表跳过一部分逆扩散过程的步骤时，FID采样质量并没有下降得非常快。</p> 
<p class="img-center"><img alt="" height="314" src="https://images2.imgbox.com/ac/a7/6m2nMVjL_o.png" width="460"></p> 
<p class="img-center"><img alt="" height="153" src="https://images2.imgbox.com/c2/04/bveIXwPw_o.png" width="354"></p> 
<p>上述想表达的是<strong>线性噪声表有时候的扩散或者逆扩散过程的步数对采样质量的贡献不大，也就是说有些步骤是浪费的</strong>。所以，论文提出了新的一种cosine噪声表，计算方式如下，是一种更加高效的取值方式。s=0.008.</p> 
<p class="img-center"><img alt="" height="114" src="https://images2.imgbox.com/3a/01/lAj9ryF2_o.png" width="542"></p> 
<p> 下图展示的就是两种方法的比较，在扩散过程的末期，cosine比线性的方法取得的参数降到0速度更加快，也就是说减少了扩散过程末期那些对采样质量没有必要的步骤，从而更加高效。</p> 
<p class="img-center"><img alt="" height="330" src="https://images2.imgbox.com/71/4d/1xsIeMCw_o.png" width="461"></p> 
<h4> Reducing Gradient Noise</h4> 
<p>这一段主要是对比实验，比较<img alt="Lsimple" class="mathcode" src="https://images2.imgbox.com/0d/0e/4hy4aIYV_o.png">和<img alt="Lhybrid" class="mathcode" src="https://images2.imgbox.com/35/e5/ja07Qizc_o.png">的效果。下图所示在整个学习过程中，在相同的训练时间时，混合损失可以达到更大的对数似然值。</p> 
<p class="img-center"><img alt="" height="312" src="https://images2.imgbox.com/bc/43/Xh5o6rxl_o.png" width="473"></p> 
<p> 下图所示是另外一组实验，通过证明了<img alt="Lvlb" class="mathcode" src="https://images2.imgbox.com/d9/3c/2pMkQIWj_o.png">是要比<img alt="Lhybrid" class="mathcode" src="https://images2.imgbox.com/51/16/aJl9qmiT_o.png">噪声梯度更加大，因而可以通过继续优化<img alt="Lvlb" class="mathcode" src="https://images2.imgbox.com/d0/f6/uJNOIQN4_o.png">来获得更大的对数似然值。</p> 
<p class="img-center"><img alt="" height="289" src="https://images2.imgbox.com/9e/73/fPCIq3tO_o.png" width="426"></p> 
<p> 于是，提出了新的方法，如下图所示，当计算某一步的损失时，会保留前面十个记录进行平方和来计算。Figure 6 就显示出了重新采样的<img alt="Lvlb(resample)" class="mathcode" src="https://images2.imgbox.com/33/ae/axnuBw05_o.png">的优势，确实噪声梯度会更小并且更加稳定。<strong>但是，最后得到的结论是这种方法对<img alt="Lhybrid" class="mathcode" src="https://images2.imgbox.com/52/3a/CIpqACfJ_o.png">方法的效果并不明显。</strong></p> 
<p class="img-center"><img alt="" height="112" src="https://images2.imgbox.com/90/80/zZ8U2dJq_o.png" width="610"></p> 
<h4> Results and Ablations</h4> 
<p>基于以上改进作者进行了消融实验，对比是否真的有效果。可以看到对比原来的DDPM中的方法，包括<img alt="Linear" class="mathcode" src="https://images2.imgbox.com/5e/e8/WEGxmqrh_o.png">和<img alt="Lsimple" class="mathcode" src="https://images2.imgbox.com/8f/bc/6FjfjLAu_o.png">来说，<img alt="cosine" class="mathcode" src="https://images2.imgbox.com/fa/e5/mRx9zK8u_o.png">和<img alt="Lhybrid" class="mathcode" src="https://images2.imgbox.com/23/9b/UYXn0WEV_o.png">确实在NLL和FID上有一定的提升。</p> 
<p class="img-center"><img alt="" height="532" src="https://images2.imgbox.com/30/41/hSrDuGNg_o.png" width="487"></p> 
<p> 另外，论文也和其他基于对数似然估计的生成模型进行了实验对比，如下图所示，虽然没有同时达到最好的效果，但是证明改进之后的DDPM确实是有提升，并且和其他模型相比是有一定竞争力的。</p> 
<p class="img-center"><img alt="" height="484" src="https://images2.imgbox.com/51/10/jGOT12U8_o.png" width="528"></p> 
<h2> 逆扩散(采样)过程速度改进</h2> 
<p>前面使用的<img alt="Lhybrid" class="mathcode" src="https://images2.imgbox.com/fd/17/f6BtTT4M_o.png">已经证明了比原来是损失函数更加高效，因而可以加速逆扩散过程。</p> 
<p>其次是新的一个噪声取值方式，和一个序列s使得将对参数采样时不仅和t有关，还和方差连接起来。</p> 
<p class="img-center"><img alt="" height="69" src="https://images2.imgbox.com/86/6e/wA8xih77_o.png" width="332"></p> 
<p> 下图为实验对比，可以看到对比DDPM来说，在同样的逆扩散推理步骤时，改进的方法采样的质量更加好。</p> 
<p class="img-center"><img alt="" height="626" src="https://images2.imgbox.com/44/90/NPOYsmhb_o.png" width="450"></p> 
<h2> 和GAN对比</h2> 
<p class="img-center"><img alt="" height="183" src="https://images2.imgbox.com/29/c1/CEB75R4R_o.png" width="733"></p> 
<p>GAN虽然生成更加准确，但是图像的细节质量不够好，主要表现在FID这项指标上。另外就是召回率也更低，意味着改进后的DDPM更能概括模型的数据分布。</p> 
<h2>计算量</h2> 
<p>下图所展示的就是改进后的DDPM模型计算量和NLL和FID指标的关系，基本上是呈现一个幂函数的规律。说明伴随着计算量越大，模型更加复杂，结果也会更加好，取决于具体应该怎么去权衡。论文没有给出具体的原因和解释。</p> 
<p class="img-center"><img alt="" height="514" src="https://images2.imgbox.com/de/16/TPK4LwJD_o.png" width="381"></p> 
<h2> 总结</h2> 
<p>改进的DDPM主要由两方面，第一个是损失函数，另外就是噪声表的取值方式，论文通过实验证明了这一点，不仅仅可以改进采样质量，也可以改进采样速度。其次就是和其他生成模型的对比以及和DDIM的对比，改进后的DDPM在采样质量和速度上都有一定的竞争性。</p> 
<p></p> 
<p> </p> 
<p> </p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9dc6e10013413aa0382aded931f5e157/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux基础--权限介绍&amp;chmod&amp;chown</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/6c3096c5c30615e6aa0372698962101b/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">DLL 注入的三种方法详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>