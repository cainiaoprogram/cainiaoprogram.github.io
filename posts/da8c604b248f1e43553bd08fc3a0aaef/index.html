<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>姿态估计之2D人体姿态估计 - CPN(Cascaded Pyramid Network for Multi-Person Pose Estimation) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="姿态估计之2D人体姿态估计 - CPN(Cascaded Pyramid Network for Multi-Person Pose Estimation)" />
<meta property="og:description" content="该论文发表在2018年CVPR上，用于多人姿态估计的级联金字塔网络
arxiv论文地址：https://arxiv.org/abs/1711.07319
github代码：https://github.com/GengDavid/pytorch-cpn，https://github.com/chenyilun95/tf-cpn
文档编辑参考：
1、论文笔记（CPN）：Cascaded Pyramid Network for Multi-Person Pose Estimation
2、2018-CPN：Cascaded Pyramid Network for Multi-Person Pose Estimation - 知乎
一、背景 目前多人姿态估计中仍然存在的问题(hard” keypoints)（遮挡点，不可见点和拥挤的背景，是的人体关键点检测存在的问题），其原因归纳为两点：
1）只通过表层特征不能识别这些“难点”，例如：躯干点；
2）在训练过程中没有明确解决这些“难点”的检测问题；
因此，作者提出了一种新的网络结构，称为Cascaded Pyramid Network（CPN）级联金字塔网络，该网络可以有效缓解“hard” keypoints的检测问题，CPN网络分为两个阶段：GlobalNet和RefineNet。GlobalNet网络是一个特征金字塔网络，该网络用于定位简单的关键点，如眼睛和手等，但是对于遮挡点和不可见的点可能缺乏精确的定位；RefinNet网络该网络通过集合来自GolbalNet网络的多级别特征来明确解决“难点”的检测问题。
三大创新点：
提出了一个新的有效的网络：CPN，该网络由GlobalNet和RefineNet网络构成； 分析了在top-down结构中问题对于多人姿态估计产生影响的不同因素； 算法实现了在challenging COCO multi-persion keypoint benchmark数据集上的最好的结果，在test-dev dataset上达到73.0AP，在test challenge dataset 上达到72.1AP。 采用了top-down的路线：先在image上使用一个human detector得到人的bounding-boxes，然后再使用cpn网络进行关键点的检测；重点在cpn网络实现的关键点检测。
二、 Human Detector 类似于 Mask R-CNN，CPN pipeline 也是自顶而下的：首先通过人体检测器根据图像生成一个边界框集合bounding-boxes；然后使用bounding-boxes对原图进行裁剪，并将裁剪后的结果用于CPN网络,接着通过单人关键点估计器预测每个人关键点的详细定位。采用基于 FPN 的当前最优物体检测器作为人体检测器，并用 Mask R-CNN ROIAlign 替代 FPN ROIPooling。
2.1 FPN 目标检测算法FPN(Feature Pyramid Networks)简介
FPN使用不同分辨率的特征图感知不同大小的物体，并通过连续上采样和跨层融合机制使输出特征兼具底层视觉信息和高层语义信息。低层次的特征图语义不够丰富，不能直接用于分类，而深层的特征更值得信赖。将侧向连接与自上而下的连接组合起来，就可以得到不同分辨率的特征图，而它们都包含了原来最深层特征图的语义信息。
2.2 Mask R-CNN 回顾 R-CNN" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/da8c604b248f1e43553bd08fc3a0aaef/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-27T09:39:22+08:00" />
<meta property="article:modified_time" content="2022-05-27T09:39:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">姿态估计之2D人体姿态估计 - CPN(Cascaded Pyramid Network for Multi-Person Pose Estimation)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>该论文发表在2018年CVPR上，用于多人姿态估计的级联金字塔网络</p> 
<p>arxiv论文地址：<a class="link-info" href="https://arxiv.org/abs/1711.07319" rel="nofollow" title="https://arxiv.org/abs/1711.07319">https://arxiv.org/abs/1711.07319</a></p> 
<p>github代码：<a class="link-info" href="https://github.com/GengDavid/pytorch-cpn" title="https://github.com/GengDavid/pytorch-cpn">https://github.com/GengDavid/pytorch-cpn</a>，<a class="link-info" href="https://github.com/chenyilun95/tf-cpn" title="https://github.com/chenyilun95/tf-cpn">https://github.com/chenyilun95/tf-cpn</a></p> 
<p>文档编辑参考：</p> 
<p><a href="https://blog.csdn.net/yangzhengzheng95/article/details/85288347" title="1、论文笔记（CPN）：Cascaded Pyramid Network for Multi-Person Pose Estimation">1、论文笔记（CPN）：Cascaded Pyramid Network for Multi-Person Pose Estimation</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/444595586" title="2、2018-CPN：Cascaded Pyramid Network for Multi-Person Pose Estimation - 知乎">2、2018-CPN：Cascaded Pyramid Network for Multi-Person Pose Estimation - 知乎</a></p> 
<h2>一、背景</h2> 
<p>目前多人姿态估计中仍然存在的问题(hard” keypoints)（遮挡点，不可见点和拥挤的背景，是的人体关键点检测存在的问题），其原因归纳为两点：</p> 
<p>1）只通过表层特征不能识别这些“难点”，例如：躯干点；</p> 
<p>2）在训练过程中没有明确解决这些“难点”的检测问题；</p> 
<p>因此，作者提出了一种新的网络结构，称为<strong>Cascaded Pyramid Network（CPN）级联金字塔网络</strong>，该网络可以有效缓解<strong>“hard” keypoints</strong>的检测问题，CPN网络分为两个阶段：<strong>GlobalNet</strong>和<strong>RefineNet</strong>。GlobalNet网络是一个<strong>特征金字塔网络</strong>，该网络用于定位简单的关键点，如眼睛和手等，但是对于遮挡点和不可见的点可能缺乏精确的定位；RefinNet网络该网络通过集合来自GolbalNet网络的多级别特征来明确解决“<strong>难点</strong>”的检测问题。</p> 
<p><img alt="" height="489" src="https://images2.imgbox.com/e9/ae/iSr5tlUJ_o.png" width="1066"></p> 
<p></p> 
<p><strong>三大创新点</strong>：</p> 
<ol><li>    提出了一个新的有效的网络：CPN，该网络由GlobalNet和RefineNet网络构成；</li><li>    分析了在top-down结构中问题对于多人姿态估计产生影响的不同因素；</li><li>    算法实现了在challenging COCO multi-persion keypoint benchmark数据集上的最好的结果，在test-dev dataset上达到73.0AP，在test challenge dataset 上达到72.1AP。</li></ol> 
<p>采用了top-down的路线：先在image上使用一个human detector得到人的bounding-boxes，然后再使用cpn网络进行关键点的检测；重点在cpn网络实现的关键点检测。</p> 
<h2><strong>二、 Human Detector</strong></h2> 
<p>类似于 Mask R-CNN，CPN pipeline 也是自顶而下的：首先通过人体检测器根据图像生成一个边界框集合bounding-boxes；然后使用bounding-boxes对原图进行裁剪，并将裁剪后的结果用于CPN网络,接着通过单人关键点估计器预测每个人关键点的详细定位。采用基于 FPN 的当前最优物体检测器作为人体检测器，并用 Mask R-CNN ROIAlign 替代 FPN ROIPooling。</p> 
<h3>2.1 FPN</h3> 
<p><a href="https://blog.csdn.net/fengbingchun/article/details/87359191" title="目标检测算法FPN(Feature Pyramid Networks)简介">目标检测算法FPN(Feature Pyramid Networks)简介</a></p> 
<p>FPN使用不同分辨率的特征图感知不同大小的物体，并通过连续上采样和跨层融合机制使输出特征兼具底层视觉信息和高层语义信息。低层次的特征图语义不够丰富，不能直接用于分类，而深层的特征更值得信赖。将侧向连接与自上而下的连接组合起来，就可以得到不同分辨率的特征图，而它们都包含了原来最深层特征图的语义信息。<br><img alt="" height="393" src="https://images2.imgbox.com/a2/08/tZ4sWnes_o.png" width="603"></p> 
<h3> 2.2 Mask R-CNN 回顾</h3> 
<p style="text-align:center;"><img alt="" height="163" src="https://images2.imgbox.com/4a/28/I7ifA08S_o.png" width="468"></p> 
<p style="text-align:center;"><strong>R-CNN</strong></p> 
<p style="text-align:center;"><img alt="" height="170" src="https://images2.imgbox.com/20/63/CE6EGIxf_o.png" width="434"></p> 
<p style="text-align:center;"><img alt="" height="289" src="https://images2.imgbox.com/f3/95/voy2S5Sk_o.png" width="750"></p> 
<p style="text-align:center;"><strong>  Fast R-CNN</strong></p> 
<p></p> 
<p style="text-align:center;"><img alt="" height="484" src="https://images2.imgbox.com/9e/b0/pz2fJhSw_o.png" width="477"></p> 
<p style="text-align:center;"><strong>Faster R-CNN</strong></p> 
<p style="text-align:center;">实现了与特征提取器网络共享卷积层的区域提案网络(RPN)</p> 
<p></p> 
<p style="text-align:center;"><img alt="" height="199" src="https://images2.imgbox.com/0d/db/fDZB4ooA_o.png" width="519"></p> 
<p style="text-align:center;"></p> 
<p style="text-align:center;"><strong>Mask R-CNN = Backbone+RPN+RoIAlign+（分类+回归+mask）</strong></p> 
<p>RoIAlign与RoIPooling参见 <a href="https://www.cnblogs.com/wangyong/p/8523814.html" rel="nofollow" title="RoIPooling、RoIAlign笔记">RoIPooling、RoIAlign笔记</a></p> 
<p> <img alt="" height="225" src="https://images2.imgbox.com/f8/86/b64JGMuD_o.png" width="559"></p> 
<p>RoIPooling量化取整为最大值。</p> 
<p><img alt="" height="223" src="https://images2.imgbox.com/b8/70/DFKvF1O4_o.png" width="546"></p> 
<p></p> 
<p>RoiAlign量化不取整，保持浮点数。</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/61/41/BGnea7VN_o.png"></p> 
<p>      上图中，四个红色叉叉‘×’的像素值是通过双线性插值算法计算得到的</p> 
<h2>三、 <strong>cascaded Pyramid Network(CPN)</strong></h2> 
<p><img alt="" height="525" src="https://images2.imgbox.com/c3/94/UAVPHzE7_o.png" width="1200"></p> 
<p></p> 
<ul><li>网络整体结构采用CPN(Cascaded Pyramid Network)结构，Cascaded指的是级联的意思，代表了网络级联了2个类似的模块（GolbalNet和RefineNet），Pyramid指的是类似于FPN的金字塔网络结构。</li><li>其中，GolbalNet负责<strong>网络所有关键点的检测</strong>，重点是对比较容易检测的眼睛，胳膊等部位的关键点预测效果较好，采用的损失函数为L2 loss。其中在每一个elem-sum操作之前，都对feature map使用了1*1的卷积操作。</li><li>RefineNet指的是对GolbalNet预测的结果进行修正的网络。GolbalNet对身体部位的那些遮挡，看不见，或者有复杂背景的关键点预测误差较大，RefineNet则专门修正这些点。主要还是基于shortcut的思想。在该阶段的训练中，还使用了类似OHEM的online hard keypoints mining难例挖掘策略。</li></ul> 
<h3>3.1  GolbalNet</h3> 
<p><img alt="" height="380" src="https://images2.imgbox.com/b7/b4/KkEoaxY7_o.png" width="1200"></p> 
<ul><li>CPN 的网络架构基于 ResNet。把不同卷积特征 conv2∼5 的最后残差块分别表示为 C_2 , C_3 , ..., C_5，并在其上应用 3 × 3 卷积滤波器生成关键点的热力图。如图所示，浅层特征比如C_2 , C_3 在定位上有着较高的空间分辨率，但是在识别上语义信息较少。另一方面，由于卷积（和池化），深度特征层比如 C_4，C_5 语义信息较多，但空间分辨率较低。因此经常引入 U 型结构同时保留特征层的空间分辨率和语义信息。</li><li>本文的关键点估计应用了特征金字塔结构。稍微不同于 FPN，在上采样的过程中，在逐像素加和之前使用 1 × 1 卷积核，而这一结构正是 GlobalNet。</li><li>如图所示，基于 ResNet backbone，GlobalNet 可有效定位简单的可见关键点（比如眼睛），却无法精确定位困难的隐藏关键点（臀部）。对臀部这类关键点的定位通常需要更多的语境信息和处理，而不是相邻的外观特征。很多情况下，单一 GlobalNet 无法直接识别这些“困难”点。</li></ul> 
<p><img alt="" height="560" src="https://images2.imgbox.com/38/cf/ChsBVhn3_o.png" width="720"> 在GlobalNet中，得到了四层特征图，作者通过给每一层特征图设计了不同的数量的botleneck块，再分别经过不同倍率的上采样，然后经过concat操作后，达到了对不同尺度特征的结合，最后经过一个bottlenet块，再经过简单的变换，得到网络的最终的输出。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/1c/fc/DqItfxDc_o.png"></p> 
<p></p> 
<h3><strong>3.2 RefineNet</strong></h3> 
<p style="text-align:center;"><strong><img alt="" src="https://images2.imgbox.com/58/9d/sl1RlEvG_o.png"></strong></p> 
<p></p> 
<ul><li>GlobalNet 生成特征金字塔表征来识别“容易”点，RefineNet 则显式处理“困难”关键点。为提升信息传输的效率，保证信息完整性，RefineNet 在不同层之间传输信息，并通过像 HyperNet 一样的上采样和连接把这些信息整合起来。不同于 Stacked hourglass 的优化策略，RefineNet 接收了来自所有金字塔层的特征信息，而不是类似 hourglass 模块之间仅通过最后一个上采样特征进行信息传递。此外还把更多的 bottleneck 模块来处理更深的特征，其较小的空间尺度可实现效率和性能的良好权衡。</li><li>随着训练的进行，网络会倾向于关注占比较多的“简单”点，其重要性不及“困难”点，比如遮挡等情况，因此网络对两者的关注应该取得一个平衡。为此，RefineNet 根据训练损失在线地显式选择困难关键点（称之为在线困难关键点挖掘/ OHKM），并只从已选择的关键点反向传播梯度。</li></ul> 
<p style="text-align:center;"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7db41c0887c1e145de13748edc5a69db/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Keil基础项目创建</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8e879741849fde54905dc4b694d2fc02/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Unity-解决打包报错</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>