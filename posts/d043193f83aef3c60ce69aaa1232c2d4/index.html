<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python(Opencv)的特征点提取和画线匹配 - 代码 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python(Opencv)的特征点提取和画线匹配 - 代码" />
<meta property="og:description" content="本博客属于赋值内容，原文请看以下连接（亲测有用）：
【OpenCV-Python】29.OpenCV的特征检测——特征匹配_opencv 特征匹配 python_机器视觉小学徒的博客-CSDN博客
一、关键点获取并画图 # -*- coding: utf-8 -* import cv2 import matplotlib.pyplot as plt # 1.读取灰度图像 image1 = cv2.imread(&#34;p1.png&#34;) image2 = cv2.imread(&#34;p2.png&#34;) gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY) gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY) # 2.SIFT实例化 orb = cv2.ORB_create() #可以选择不同特征点，见后者 # 3.检测关键点 kq1, dst1 = orb.detectAndCompute(gray1, None) kq2, dst2 = orb.detectAndCompute(gray2, None) # 4.绘制关键点 cv2.drawKeypoints(image1, kq1, image1, (0, 0, 255),flags=1) # flags=1 决定特征点的大小 cv2.drawKeypoints(image2, kq2, image2, (0, 0, 255),flags=1) # flags=1 决定特征点的大小 # 绘制图像 fig, axes = plt." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d043193f83aef3c60ce69aaa1232c2d4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-19T12:42:09+08:00" />
<meta property="article:modified_time" content="2023-03-19T12:42:09+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python(Opencv)的特征点提取和画线匹配 - 代码</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p> 本博客属于赋值内容，原文请看以下连接（<span style="color:#fe2c24;"><strong>亲测有用</strong></span>）：</p> 
 <p><a class="link-info" href="https://blog.csdn.net/weixin_43843069/article/details/122243866" title="【OpenCV-Python】29.OpenCV的特征检测——特征匹配_opencv 特征匹配 python_机器视觉小学徒的博客-CSDN博客">【OpenCV-Python】29.OpenCV的特征检测——特征匹配_opencv 特征匹配 python_机器视觉小学徒的博客-CSDN博客</a></p> 
</blockquote> 
<p></p> 
<h2><span style="color:#fe2c24;">一、关键点获取并画图</span></h2> 
<blockquote> 
 <pre><code class="language-python"># -*- coding: utf-8 -*
import cv2
import matplotlib.pyplot as plt
 
# 1.读取灰度图像
image1 = cv2.imread("p1.png")
image2 = cv2.imread("p2.png")

gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)

# 2.SIFT实例化
orb = cv2.ORB_create() #可以选择不同特征点，见后者
# 3.检测关键点
kq1, dst1 = orb.detectAndCompute(gray1, None)
kq2, dst2 = orb.detectAndCompute(gray2, None)

# 4.绘制关键点
cv2.drawKeypoints(image1, kq1, image1, (0, 0, 255),flags=1)  # flags=1 决定特征点的大小
cv2.drawKeypoints(image2, kq2, image2, (0, 0, 255),flags=1)  # flags=1 决定特征点的大小
# 绘制图像
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 16))  # nrows=1, ncols=2, 1行 两列
axes[0, 0].set_title("SIFT_feature_detect image1")            # [0, 0], [0, 1] 注意区别
axes[0, 0].imshow(image1[:, :, ::-1])
axes[1, 1].set_title("SIFT_feature_detect image2")
axes[1, 1].imshow(image2[:, :, ::-1])
plt.show()
cv2.waitKey(0)</code></pre> 
 <p><span style="color:#1a439c;"><strong>结果如下：</strong></span></p> 
 <p><img alt="" height="281" src="https://images2.imgbox.com/7c/65/Gv2kBFia_o.png" width="947"></p> 
 <p></p> 
 <p></p> 
</blockquote> 
<p><span style="color:#1a439c;"><strong>光流法特征点匹配</strong></span></p> 
<pre><code class="language-python">import cv2
import numpy as np

# 读取图片
img1 = cv2.imread('image1.jpg')
img2 = cv2.imread('image2.jpg')

# 转为灰度图像
gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

# Shi-Tomasi角点检测
corners1 = cv2.goodFeaturesToTrack(gray1, maxCorners=100, qualityLevel=0.3, minDistance=7)
corners2, status, err = cv2.calcOpticalFlowPyrLK(gray1, gray2, corners1, None)

# 用cv2.drawKeypoints绘制特征点
img1_keypoints = cv2.drawKeypoints(img1, corners1, None, color=(0, 255, 0), flags=0)
img2_keypoints = cv2.drawKeypoints(img2, corners2, None, color=(0, 255, 0), flags=0)

# 特征点描述符提取和匹配
orb = cv2.ORB_create()
keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)
keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)

bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
matches = bf.match(descriptors1, descriptors2)

# 绘制匹配图
matches_img = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# 显示图片
cv2.imshow('Image 1 Keypoints', img1_keypoints)
cv2.imshow('Image 2 Keypoints', img2_keypoints)
cv2.imshow('Matches', matches_img)
cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<p></p> 
<p></p> 
<blockquote> 
 <p><span style="color:#000000;">  获得图像的关键点后，可通过计算得到关键点的描述符。关键点描述符可用于图像的特征匹配。通常，在计算图A是否包含图B的特征区域时，将图A称做训练图像，将图B称为查询图像。图A的关键点描述符称为训练描述符，图B的关键点描述符称为查询描述符。</span></p> 
</blockquote> 
<h2><span style="color:#fe2c24;">二、暴力匹配器</span></h2> 
<p>暴力匹配器使用描述符进行特征比较。在比较时，暴力匹配器首先在查询描述符中取一个关键点的描述符，将其与训练描述符中的所有关键点描述符进行比较，每次比较后会给出一个距离值，距离最小的值对应最佳匹配结果。所有描述符比较完后，匹配器返回匹配结果列表。<br> OpenCV的cv2.BFMatcher_create()函数用于创建暴力匹配器，其基本格式如下：</p> 
<pre><code class="language-python">bf = cv2.BFMatcher_create([normType[, crossCheck]])

bf为返回的暴力匹配器对象
normType为距离测量类型, 默认为cv2.NORM_L2, 通常, SIFT描述符使用cv2.NORM_L1或cv2.NORM_L2, ORB描述符使用cv2.NORM_HAMMING
crossCheck默认为False, 匹配器为每个查询描述符找到k个距离最近的匹配描述符, 为True时, 只返回满足交叉验证条件的匹配结果
</code></pre> 
<p><span style="color:#000000;"> 暴力匹配器对象的match()方法返回每个关键点的最佳匹配结果，其基本格式如下：</span></p> 
<pre><code class="language-python">ms = bf.match(des1, des2)

ms为返回的结果, 它是一个DMatch对象列表, 每个DMatch对象表示关键点的一个匹配结果, 其dintance属性表示距离, 距离值越小匹配度越高
des1为查询描述符
des2为训练描述符
</code></pre> 
<p><span style="color:#000000;"> 获得匹配结果后，可调用cv2.drawMatches()函数或cv2.drawMatchesKnn()函数绘制匹配结果图像，其基本格式如下：</span></p> 
<pre><code class="language-python">outImg = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches1to2[, matchColor[, singlePointColor[, matchesMask[, flags]]]])

outImg = cv2.drawMatches(img1, keypoints1, img2, keypoints2, matches1to2[, matchColor[, singlePointColor[, matchesMask[, flags]]]])

outImg为返回的绘制结果图像, 图像中查询图像与训练图像中匹配的关键点个两点之间的连线为彩色
img1为查询图像
keypoints1为img1的关键点
img2为训练图像
keypoints2为img2的关键点
matches1to2为img1与img2的匹配结果
matchColor为关键点和链接线的颜色, 默认使用随机颜色
singlePointColor为单个关键点的颜色, 默认使用随机颜色
matchesMask为掩膜, 用于决定绘制哪些匹配结果, 默认为空, 表示绘制所有匹配结果
flags为标志, 可设置为下列参数值:
cv2.DrawMatchesFlags_DEFAUL:默认方式, 绘制两个源图像、匹配项和单个关键点, 没有围绕关键点的圆以及关键点的大小和方向
cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS:不会绘制单个关键点
cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS:在关键点周围绘制具有关键点大小和方向的圆圈
</code></pre> 
<p><strong>具体代码如下：</strong></p> 
<pre><code class="language-python"># -*- coding: utf-8 -*
import cv2 # 暴力匹配器、ORB描述符和match()方法

img1 = cv2.imread("xhu1.jpg", cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread("xhu2.jpg", cv2.IMREAD_GRAYSCALE)

orb = cv2.ORB_create()
kp1, des1 = orb.detectAndCompute(img1, None)
kp2, des2 = orb.detectAndCompute(img2, None)

bf = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck = False)
ms = bf.match(des1, des2)
ms = sorted(ms, key = lambda x:x.distance)
img3 = cv2.drawMatches(img1, kp1, img2, kp2, ms[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

cv2.imshow("Xhu1", img1)
cv2.imshow("Xhu2", img2)
img3 = cv2.resize(img3,None,fx=0.5,fy=0.6) #  改变图像大小
cv2.imshow("Matches", img3)

cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<p><img alt="" height="528" src="https://images2.imgbox.com/da/9a/ui4ev1Xs_o.png" width="1200"><br>  <br>  </p> 
<pre><code class="language-python"># 暴力匹配器、SIFT描述符和match()方法
# -*- coding: utf-8 -*
import cv2

img1 = cv2.imread("xhu1.jpg", cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread("xhu2.jpg", cv2.IMREAD_GRAYSCALE)

sift=cv2.SIFT_create()
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)

bf = cv2.BFMatcher_create(cv2.NORM_L1, crossCheck = False)
ms = bf.match(des1, des2)
ms = sorted(ms, key = lambda x:x.distance)
img3 = cv2.drawMatches(img1, kp1, img2, kp2, ms[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# ms = np.expand_dims(ms,1)
# img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, ms[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

cv2.imshow("Xhu1", img1)
cv2.imshow("Xhu2", img2)
cv2.imshow("Matches", img3)

cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<p> <img alt="" height="525" src="https://images2.imgbox.com/95/46/kPKLjMhw_o.png" width="1200"></p> 
<p></p> 
<blockquote> 
 <p><span style="color:#000000;">暴力匹配器对象的knnMatch()方法可返回指定数量的最佳匹配结果，其基本格式如下：</span></p> 
 <pre><code class="language-python">ms = knnMatch(des1, des2, k=n)

ms为返回的匹配结果, 每个列表元素是一个子列表, 它包含了由参数k指定个数的DMatch对象
des1为查询描述符
des2为训练描述符
k为返回的最佳匹配个数
</code></pre> 
 <pre><code class="language-python"># 暴力匹配器、ORB描述符和knnMatch()方法
  # -*- coding: utf-8 -*
import cv2

img1 = cv2.imread("xhu1.jpg", cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread("xhu2.jpg", cv2.IMREAD_GRAYSCALE)

orb = cv2.ORB_create()
kp1, des1 = orb.detectAndCompute(img1, None)
kp2, des2 = orb.detectAndCompute(img2, None)

bf = cv2.BFMatcher_create(cv2.NORM_HAMMING, crossCheck = False)
ms = bf.knnMatch(des1, des2, k=2)

# 应用比例测试选择要使用的匹配结果
good = []
for m, n in ms:
    if m.distance &lt; 0.75 * n.distance:
		good.append(m)

img3 = cv2.drawMatches(img1, kp1, img2, kp2, good[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)
# good = np.expand_dims(good,1)
#img3 = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good[:20], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

cv2.imshow("Xhu1", img1)
cv2.imshow("Xhu2", img2)
cv2.imshow("Matches", img3)


cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
 <p></p> 
</blockquote> 
<h2><span style="color:#fe2c24;">三、FLANN匹配器</span></h2> 
<p>FLANN(Fast Library for Approximate Nearest Neignbors)为近似最近邻的快速库，FLANN特征匹配算法比其它的最近邻算法更快。<br> 在创建FLANN匹配器时，需要传递两参数：index_params和search_params。<br> index_params用来指定索引树的算法类型和数量。SIFT算法可以使用下面的代码来设置。<br>  </p> 
<pre><code class="language-cpp">FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE,
                    trees= 5)
</code></pre> 
<p><span style="color:#000000;">ORB算法可以使用下面的代码来设置。</span></p> 
<pre><code class="language-cpp">FLANN_INDEX_LSH = 6
index_params = dict(algorithm = FLANN_INDEX_LSH,
                    table_number = 6,
                    key_size = 12,
                    multi_probe_level = 1)
</code></pre> 
<p><span style="color:#000000;">  search_params用于指定索引树的遍历次数，遍历次数越多，匹配结果越精细，通常设置为50即可，如下所示：</span></p> 
<pre><code class="language-python">search_params = dict(check = 50)
</code></pre> 
<pre><code class="language-python"># FLANN匹配器、ORB描述符
# -*- coding: utf-8 -*
import cv2

img1 = cv2.imread("xhu1.jpg", cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread("xhu2.jpg", cv2.IMREAD_GRAYSCALE)

orb = cv2.ORB_create()
kp1, des1 = orb.detectAndCompute(img1, None)
kp2, des2 = orb.detectAndCompute(img2, None)

# 定义FLANN参数
FLANN_INDEX_LSH = 6
index_params = dict(algorithm = FLANN_INDEX_LSH,
                    table_number = 6,
                    key_size = 12,
                    multi_probe_level = 1)
search_params = dict(check = 50)

flann = cv2.FlannBasedMatcher(index_params, search_params)
matches = flann.match(des1, des2)
draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = None,
                   flags = cv2.DrawMatchesFlags_DEFAULT)

img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:20], None, **draw_params)

cv2.imshow("Xhu1", img1)
cv2.imshow("Xhu2", img2)
cv2.imshow("Matches", img3)


cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<p><img alt="" height="521" src="https://images2.imgbox.com/fe/41/EULUIKdu_o.png" width="1200"></p> 
<p></p> 
<pre><code class="language-python"># FLANN匹配器、SIFT描述符
# -*- coding: utf-8 -*
import cv2

img1 = cv2.imread("xhu1.jpg", cv2.IMREAD_GRAYSCALE)
img2 = cv2.imread("xhu2.jpg", cv2.IMREAD_GRAYSCALE)

sift = cv2.SIFT_create()
kp1, des1 = sift.detectAndCompute(img1, None)
kp2, des2 = sift.detectAndCompute(img2, None)

# 定义FLANN参数
FLANN_INDEX_KDTREE = 1
index_params = dict(algorithm = FLANN_INDEX_KDTREE,
                    trees = 5)
search_params = dict(check = 50)

flann = cv2.FlannBasedMatcher(index_params, search_params)
matches = flann.match(des1, des2)
draw_params = dict(matchColor = (0,255,0),
                   singlePointColor = (255,0,0),
                   matchesMask = None,
                   flags = cv2.DrawMatchesFlags_DEFAULT)

img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:20], None, **draw_params)

cv2.imshow("Xhu1", img1)
cv2.imshow("Xhu2", img2)
cv2.imshow("Matches", img3)


cv2.waitKey(0)
cv2.destroyAllWindows()
</code></pre> 
<p><img alt="" height="525" src="https://images2.imgbox.com/76/d5/DYktrs9u_o.png" width="1200"></p> 
<p></p> 
<h2><span style="color:#fe2c24;">四、<a href="https://so.csdn.net/so/search?q=OpenCV&amp;spm=1001.2101.3001.7020" title="OpenCV">OpenCV</a>-Python资源下载</span></h2> 
<p><a href="https://download.csdn.net/download/weixin_43843069/57802303" title="OpenCV-Python测试用图片、中文官方文档、opencv-4.5.4源码">OpenCV-Python测试用图片、中文官方文档、opencv-4.5.4源码</a></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/25770e0a404aab365a7a8e8fffb18d78/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">多层多输入的CNN-LSTM时间序列回归预测（卷积神经网络-长短期记忆网络）——附代码</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0ab19131b43a0c94453a280c8e2637a6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">随机生存森林变量选择超参数调优</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>