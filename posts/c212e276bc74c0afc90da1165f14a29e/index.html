<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>centos7中kubeadmin搭建k8s-1-22 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="centos7中kubeadmin搭建k8s-1-22" />
<meta property="og:description" content="原文连接：http://www.duozhi.online/2023/10/20/centos7%e4%b8%adkubeadmin%e6%90%ad%e5%bb%bak8s-1-22/
etcd安装参考：http://www.duozhi.online/2023/10/19/centos7%e4%b8%adetcd%e5%8d%95%e6%9c%ba%e5%ae%89%e8%a3%85/
ansible安装参考：http://www.duozhi.online/2023/10/19/centos7%e4%b8%adansible%e5%ae%89%e8%a3%85/
1.节点信息 192.168.0.203 192.168.0.204 ansible配置 [root@MES-203 etcd]# cat /etc/ansible/hosts [k8s] 192.168.0.203 ansible_ssh_user=root ansible_ssh_pass=adm129 192.168.0.204 ansible_ssh_user=root ansible_ssh_pass=adm129 2.防火墙关闭下 [root@MES-203 lib]# ansible k8s -m shell -a &#34;systemctl disable firewalld&amp;&amp;systemctl stop firewalld&amp;&amp;systemctl daemon-reload&#34; 3.时间同步 [root@MES-203 yum.repos.d]# ansible k8s -m shell -a &#34; yum install chrony -y&#34; [root@MES-203 yum.repos.d]# ansible k8s -m shell -a &#34;systemctl enable chronyd&#34; [root@MES-203 yum.repos.d]# ansible k8s -m shell -a &#34;systemctl start chronyd&#34; [root@MES-203 yum.repos.d]# ansible k8s -m shell -a &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/c212e276bc74c0afc90da1165f14a29e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-21T06:43:27+08:00" />
<meta property="article:modified_time" content="2023-10-21T06:43:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">centos7中kubeadmin搭建k8s-1-22</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>原文连接：http://www.duozhi.online/2023/10/20/centos7%e4%b8%adkubeadmin%e6%90%ad%e5%bb%bak8s-1-22/</p> 
<p>etcd安装参考：http://www.duozhi.online/2023/10/19/centos7%e4%b8%adetcd%e5%8d%95%e6%9c%ba%e5%ae%89%e8%a3%85/</p> 
<p>ansible安装参考：http://www.duozhi.online/2023/10/19/centos7%e4%b8%adansible%e5%ae%89%e8%a3%85/</p> 
<h3><a id="1_6"></a>1.节点信息</h3> 
<pre><code>192.168.0.203  
192.168.0.204

ansible配置
[root@MES-203 etcd]# cat /etc/ansible/hosts 
[k8s]
192.168.0.203 ansible_ssh_user=root ansible_ssh_pass=adm129
192.168.0.204 ansible_ssh_user=root ansible_ssh_pass=adm129
</code></pre> 
<h3><a id="2_19"></a>2.防火墙关闭下</h3> 
<pre><code>[root@MES-203 lib]# ansible k8s -m shell -a "systemctl disable firewalld&amp;&amp;systemctl stop firewalld&amp;&amp;systemctl daemon-reload"
</code></pre> 
<h3><a id="3_25"></a>3.时间同步</h3> 
<pre><code>[root@MES-203 yum.repos.d]# ansible k8s -m shell -a " yum install chrony -y"
[root@MES-203 yum.repos.d]# ansible k8s -m shell -a "systemctl enable chronyd"
[root@MES-203 yum.repos.d]# ansible k8s -m shell -a "systemctl start chronyd"
[root@MES-203 yum.repos.d]# ansible k8s -m shell -a "chronyc sources"
</code></pre> 
<h3><a id="4k8s_34"></a>4.<strong>配置k8s源,两个节点分别做如下操作</strong></h3> 
<pre><code>cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF
[kubernetes]
name=Kubernetes Repo
baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
enable=1
EOF
</code></pre> 
<h3><a id="5dockeransible_47"></a><strong>5.安装docker,通过ansible操作两个节点</strong></h3> 
<pre><code>下载docker源
[root@MES-203 k8s]# ansible k8s -m shell -a " cd /etc/yum.repos.d &amp;&amp;wget http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo"

安装docker
[root@MES-203 k8s]# ansible k8s -m shell -a " yum install docker-ce docker-ce-cli containerd.io -y"

配置cgroup驱动,因为kubelet的驱动是systemd
[root@MES-203 k8s]# ansible k8s -m shell -a "echo '{"exec-opts": ["native.cgroupdriver=systemd"]}'  sudo tee /etc/docker/daemon.json"

启动并设置开机启动
[root@MES-203 k8s]# ansible k8s -m shell -a "systemctl start docker&amp;&amp;systemctl enable docker&amp;&amp;systemctl daemon-reload"
</code></pre> 
<h3><a id="6kubelet_kubectlkubeadmansible_63"></a><strong>6.安装kubelet &amp;kubectl&amp;kubeadm，通过ansible操作两个节点</strong></h3> 
<pre><code>安装
[root@MES-203 etcd]# ansible k8s -m shell -a "yum install -y kubelet-1.22.3 kubectl-1.22.3 kubeadm-1.22.3"

设置kubelet开机启动
[root@MES-203 etcd]# ansible k8s -m shell -a "systemctl enable kubelet &amp;&amp; systemctl daemon-reload"
</code></pre> 
<h3><a id="7swap_73"></a><strong>7.swap处理–两台机器都操作</strong></h3> 
<p>最好关掉swap</p> 
<p><strong>我在操作的时候没有关掉swap操作的</strong></p> 
<p>由于虚拟机启用了swap，所以需要进行相关的配置，否则会报错,有下面的内容就说明有swap</p> 
<p>没有swap就不需要下面的操作</p> 
<p><img src="https://images2.imgbox.com/8f/5d/GP7GYlAI_o.jpg" alt=""></p> 
<pre><code>kubelet配置文件内容如下
[root@MES-203 yum.repos.d]# cat /etc/sysconfig/kubelet
KUBELET_EXTRA_ARGS="--fail-swap-on=false"
</code></pre> 
<h3><a id="8master1921680203_91"></a><strong>8.master节点操作如下-192.168.0.203</strong></h3> 
<h4><a id="81kubelet_93"></a>8.1<strong>启动kubelet</strong></h4> 
<pre><code>systemctl start kubelet
报错的话，可以 执行这个命令查看详细报错。journalctl -fu kubelet 
</code></pre> 
<h4><a id="82kubeadm_init_100"></a>8.2<strong>kubeadm init</strong></h4> 
<pre><code>[root@MES-203 yum.repos.d]# cd /home/k8s/
生成配置文件
kubeadm config print init-defaults --kubeconfig ClusterConfiguration &gt; kubeadm.yml


配置文件内容如下：
apiVersion: kubeadm.k8s.io/v1beta3
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.0.203
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  imagePullPolicy: IfNotPresent
  name: node
  taints: null
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta3
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controllerManager: {}
dns: {}
etcd:
  external:
    endpoints: 
    - http://192.168.0.203:2379
imageRepository: registry.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: 1.22.0
networking:
  dnsDomain: cluster.local
  serviceSubnet: 10.96.0.0/12
  podSubnet: 172.18.0.0/16
scheduler: {}
</code></pre> 
<h4><a id="83master_149"></a>8.3<strong>初始化master</strong></h4> 
<pre><code>--ignore-preflight-errors=Swap 由于有swap的问题，所以加了这个参数
 kubeadm init --config=kubeadm.yml --upload-certs --ignore-preflight-errors=Swap
</code></pre> 
<p><img src="https://images2.imgbox.com/bf/1b/uk3984xS_o.jpg" alt=""></p> 
<h4><a id="84kubeconfigkubeconfig_158"></a>8.4<strong>执行如下命令，复制kubeconfig，使用kubeconfig链接集群</strong></h4> 
<pre><code>[root@MES-203 k8s]# mkdir -p $HOME/.kube
[root@MES-203 k8s]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
[root@MES-203 k8s]# chown $(id -u):$(id -g) $HOME/.kube/config

查看下集群节点啦
[root@MES-203 k8s]# kubectl get node
NAME   STATUS     ROLES                  AGE     VERSION
node   NotReady   control-plane,master   3m42s   v1.22.3
</code></pre> 
<h4><a id="85_171"></a>8.5<strong>获取加入集群的命令</strong></h4> 
<pre><code>[root@MES-203 ~]# kubeadm token create --print-join-command
'kubeadm join 192.168.0.203:6443 --token xw0vxh.jp141g090tznbzgc --discovery-token-ca-cert-hash sha256:75c9e7bd11ca4362734be70ad20948ca5131a5d6dbaf8dee36f0d2f6ce4d6ba9 
[root@MES-203 ~]# '
</code></pre> 
<h3><a id="9slave1921680204_179"></a>9.<strong>slave节点-192.168.0.204</strong></h3> 
<p>不需要手动启动kubelet,jion的时候能够自动启动kubelet</p> 
<p>没有swap问题不用加–ignore-preflight-errors=Swap参数</p> 
<pre><code>[root@MES-204 yum.repos.d]# kubeadm join 192.168.0.203:6443 --token zmxoys.nycxhezjd2zkcgxi --discovery-token-ca-cert-hash sha256:75c9e7bd11ca4362734be70ad20948ca5131a5d6dbaf8dee36f0d2f6ce4d6ba9  --ignore-preflight-errors=Swap
</code></pre> 
<p><img src="https://images2.imgbox.com/40/e1/v8JfTIHu_o.jpg" alt=""></p> 
<h3><a id="10master_191"></a>10.<strong>再到master节点查看下集群情况</strong></h3> 
<p>coredns起不来，节点状态也是NotReady，不要急，后面安装好网络插件就好了</p> 
<p><img src="https://images2.imgbox.com/f5/5b/J5o7O1qZ_o.jpg" alt=""></p> 
<h3><a id="11slave_197"></a>11.<strong>后面再新加slave节点的操作步骤</strong></h3> 
<p>依次执行2.6、2.7、2.9</p> 
<h3><a id="12coreDns_pod_pending_201"></a><strong>12解决coreDns pod pending问题</strong></h3> 
<h4><a id="121masterpod_203"></a>12.1<strong>查看master节点有哪些污点（有污点的节点pod就调度不上去）</strong></h4> 
<pre><code>[root@MES-203 k8s]# kubectl describe node node
Name:               node
Roles:              control-plane,master
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=node
                    kubernetes.io/os=linux
                    node-role.kubernetes.io/control-plane=
                    node-role.kubernetes.io/master=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Thu, 20 Oct 2022 17:00:00 +0800
Taints:             node-role.kubernetes.io/master:NoSchedule
                    node.kubernetes.io/not-ready:NoSchedule
</code></pre> 
<h4><a id="122_225"></a>12.2<strong>删除污点</strong></h4> 
<pre><code>[root@MES-203 k8s]# kubectl taint node node node-role.kubernetes.io/master:NoSchedule-
node/node untainted
[root@MES-203 k8s]# kubectl taint node node node.kubernetes.io/not-ready:NoSchedule-
node/node untainted
</code></pre> 
<h4><a id="123_234"></a>12.3<strong>查看</strong></h4> 
<p>由于没有安装网络组件，还起不来</p> 
<p><img src="https://images2.imgbox.com/97/3c/kEDFpZwq_o.jpg" alt=""></p> 
<p><img src="https://images2.imgbox.com/e8/3b/bnhiMXNQ_o.jpg" alt=""></p> 
<h3><a id="13flannel_242"></a>13.<strong>安装网络插件flannel</strong></h3> 
<h4><a id="131yaml_244"></a>13.1<strong>下载yaml</strong></h4> 
<pre><code>[root@MES-203 k8s]# wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre> 
<p>修改该yaml中红框处，要和kubeadm.yml中的 podSubnet: 172.18.0.0/16 处配置相同</p> 
<p><img src="https://images2.imgbox.com/37/1c/YaeUU3ei_o.jpg" alt=""></p> 
<h4><a id="132_254"></a>13.2安装</h4> 
<pre><code>[root@MES-203 k8s]# pwd
/home/k8s
[root@MES-203 k8s]# kubectl apply -f kube-flannel.yml
</code></pre> 
<h4><a id="133_262"></a>13.3查看</h4> 
<p>全部都是running啦，就好了</p> 
<p><img src="https://images2.imgbox.com/7d/3a/wgCIFF7Z_o.jpg" alt=""></p> 
<p>节点状态也是ready啦</p> 
<p><img src="https://images2.imgbox.com/cb/47/zgbmjTKs_o.jpg" alt=""></p> 
<h3><a id="14nginxingressv111_272"></a>14.<strong>nginx-ingress-v1.1.1</strong></h3> 
<p>参考：https://kubernetes.github.io/ingress-nginx/deploy/</p> 
<h4><a id="141_276"></a>14.1下载</h4> 
<pre><code>wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.1.1/deploy/static/provider/cloud/deploy.yaml
</code></pre> 
<h4><a id="142_282"></a>14.2修改</h4> 
<p><img src="https://images2.imgbox.com/55/91/IVWC9tBk_o.jpg" alt=""></p> 
<p>下面把deployment和job的镜像修改为国内的了</p> 
<p>service改为了node-port类型</p> 
<p><img src="https://images2.imgbox.com/87/b8/XTrZSp2n_o.jpg" alt=""></p> 
<pre><code>apiVersion: v1
kind: Namespace
metadata:
  name: ingress-nginx
  labels:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx

---
# Source: ingress-nginx/templates/controller-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx
  namespace: ingress-nginx
automountServiceAccountToken: true
---
# Source: ingress-nginx/templates/controller-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller
  namespace: ingress-nginx
data:
  allow-snippet-annotations: 'true'
---
# Source: ingress-nginx/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
  name: ingress-nginx
rules:
  - apiGroups:
      - ''
    resources:
      - configmaps
      - endpoints
      - nodes
      - pods
      - secrets
      - namespaces
    verbs:
      - list
      - watch
  - apiGroups:
     - ''
    resources:
      - nodes
    verbs:
      - get
  - apiGroups:
      - ''
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ''
    resources:
      - events
    verbs:
      - create
      - patch
 - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
---
# Source: ingress-nginx/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
  name: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx
subjects:
  - kind: ServiceAccount
    name: ingress-nginx
    namespace: ingress-nginx
---
# Source: ingress-nginx/templates/controller-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx
  namespace: ingress-nginx
rules:
  - apiGroups:
      - ''
    resources:
      - namespaces
    verbs:
      - get
  - apiGroups:
    - ''
    resources:
      - configmaps
      - pods
      - secrets
      - endpoints
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ''
    resources:
      - services
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - networking.k8s.io
   resources:
      - ingresses/status
    verbs:
      - update
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingressclasses
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - ''
    resources:
      - configmaps
    resourceNames:
      - ingress-controller-leader
    verbs:
      - get
      - update
  - apiGroups:
      - ''
    resources:
      - configmaps
    verbs:
      - create
  - apiGroups:
     - ''
    resources:
      - events
    verbs:
      - create
      - patch
---
# Source: ingress-nginx/templates/controller-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx
  namespace: ingress-nginx
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx
subjects:
  - kind: ServiceAccount
    name: ingress-nginx
    namespace: ingress-nginx
---
# Source: ingress-nginx/templates/controller-service-webhook.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller-admission
  namespace: ingress-nginx
spec:
  type: ClusterIP
  ports:
    - name: https-webhook
      port: 443
      targetPort: webhook
      appProtocol: https
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
---
# Source: ingress-nginx/templates/controller-service.yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  type: NodePort
  externalTrafficPolicy: Local
  ipFamilyPolicy: SingleStack
  ipFamilies:
    - IPv4
  ports:
    - name: http
      port: 80
      protocol: TCP
      targetPort: http
      appProtocol: http
      nodePort: 31086
    - name: https
      port: 443
      protocol: TCP
     targetPort: https
      appProtocol: https
      nodePort: 31087
  selector:
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/component: controller
---
# Source: ingress-nginx/templates/controller-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: ingress-nginx-controller
  namespace: ingress-nginx
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: ingress-nginx
      app.kubernetes.io/instance: ingress-nginx
      app.kubernetes.io/component: controller
  revisionHistoryLimit: 10
 minReadySeconds: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/component: controller
    spec:
      dnsPolicy: ClusterFirst
      containers:
        - name: controller
          image: anjia0532/google-containers.ingress-nginx.controller:v1.1.1
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command:
                  - /wait-shutdown
          args:
            - /nginx-ingress-controller
            - --publish-service=$(POD_NAMESPACE)/ingress-nginx-controller
            - --election-id=ingress-controller-leader
            - --controller-class=k8s.io/ingress-nginx
            - --configmap=$(POD_NAMESPACE)/ingress-nginx-controller
            - --validating-webhook=:8443
            - --validating-webhook-certificate=/usr/local/certificates/cert
            - --validating-webhook-key=/usr/local/certificates/key
        securityContext:
            capabilities:
              drop:
                - ALL
              add:
                - NET_BIND_SERVICE
            runAsUser: 101
            allowPrivilegeEscalation: true
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LD_PRELOAD
              value: /usr/local/lib/libmimalloc.so
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
          timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /healthz
              port: 10254
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
            - name: https
              containerPort: 443
              protocol: TCP
            - name: webhook
              containerPort: 8443
              protocol: TCP
          volumeMounts:
            - name: webhook-cert
              mountPath: /usr/local/certificates/
              readOnly: true
          resources:
            requests:
              cpu: 100m
             memory: 90Mi
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: ingress-nginx
      terminationGracePeriodSeconds: 300
      volumes:
        - name: webhook-cert
          secret:
            secretName: ingress-nginx-admission
---
# Source: ingress-nginx/templates/controller-ingressclass.yaml
# We don't support namespaced ingressClass yet
# So a ClusterRole and a ClusterRoleBinding is required
apiVersion: networking.k8s.io/v1
kind: IngressClass
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: controller
  name: nginx
  namespace: ingress-nginx
spec:
  controller: k8s.io/ingress-nginx
---
# Source: ingress-nginx/templates/admission-webhooks/validating-webhook.yaml
# before changing this value, check the required kubernetes version
# https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/#prerequisites
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
  name: ingress-nginx-admission
webhooks:
  - name: validate.nginx.ingress.kubernetes.io
    matchPolicy: Equivalent
    rules:
      - apiGroups:
          - networking.k8s.io
        apiVersions:
          - v1
        operations:
          - CREATE
          - UPDATE
        resources:
        - ingresses
    failurePolicy: Fail
    sideEffects: None
    admissionReviewVersions:
      - v1
    clientConfig:
      service:
        namespace: ingress-nginx
        name: ingress-nginx-controller-admission
        path: /networking/v1/ingresses
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ingress-nginx-admission
  namespace: ingress-nginx
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: ingress-nginx-admission
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - validatingwebhookconfigurations
    verbs:
      - get
      - update
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ingress-nginx-admission
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-nginx-admission
subjects:
  - kind: ServiceAccount
    name: ingress-nginx-admission
    namespace: ingress-nginx
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ingress-nginx-admission
  namespace: ingress-nginx
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
rules:
  - apiGroups:
      - ''
    resources:
      - secrets
    verbs:
      - get
      - create
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ingress-nginx-admission
  namespace: ingress-nginx
  annotations:
    helm.sh/hook: pre-install,pre-upgrade,post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: ingress-nginx-admission
subjects:
  - kind: ServiceAccount
    name: ingress-nginx-admission
    namespace: ingress-nginx
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/job-createSecret.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: ingress-nginx-admission-create
  namespace: ingress-nginx
  annotations:
    helm.sh/hook: pre-install,pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
spec:
  template:
    metadata:
      name: ingress-nginx-admission-create
      labels:
        helm.sh/chart: ingress-nginx-4.0.15
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/version: 1.1.1
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: admission-webhook
    spec:
      containers:
        - name: create
          image: anjia0532/google-containers.ingress-nginx.kube-webhook-certgen:v1.1.1
          imagePullPolicy: Always
          args:
            - create
            - --host=ingress-nginx-controller-admission,ingress-nginx-controller-admission.$(POD_NAMESPACE).svc
            - --namespace=$(POD_NAMESPACE)
            - --secret-name=ingress-nginx-admission
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          securityContext:
            allowPrivilegeEscalation: false
      restartPolicy: OnFailure
      serviceAccountName: ingress-nginx-admission
      nodeSelector:
        kubernetes.io/os: linux
      securityContext:
        runAsNonRoot: true
        runAsUser: 2000
---
# Source: ingress-nginx/templates/admission-webhooks/job-patch/job-patchWebhook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: ingress-nginx-admission-patch
  namespace: ingress-nginx
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded
  labels:
    helm.sh/chart: ingress-nginx-4.0.15
    app.kubernetes.io/name: ingress-nginx
    app.kubernetes.io/instance: ingress-nginx
    app.kubernetes.io/version: 1.1.1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: admission-webhook
spec:
  template:
    metadata:
      name: ingress-nginx-admission-patch
      labels:
        helm.sh/chart: ingress-nginx-4.0.15
        app.kubernetes.io/name: ingress-nginx
        app.kubernetes.io/instance: ingress-nginx
        app.kubernetes.io/version: 1.1.1
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: admission-webhook
    spec:
      containers:
        - name: patch
          image: anjia0532/google-containers.ingress-nginx.kube-webhook-certgen:v1.1.1
          imagePullPolicy: Always
          args:
            - patch
            - --webhook-name=ingress-nginx-admission
            - --namespace=$(POD_NAMESPACE)
            - --patch-mutating=false
            - --secret-name=ingress-nginx-admission
            - --patch-failure-policy=Fail
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          securityContext:
            allowPrivilegeEscalation: false
      restartPolicy: OnFailure
      serviceAccountName: ingress-nginx-admission
      nodeSelector:
        kubernetes.io/os: linux
      securityContext:
        runAsNonRoot: true
        runAsUser: 2000
</code></pre> 
<h4><a id="143_980"></a>14.3安装</h4> 
<pre><code>kubectl apply -f deploy.yaml
</code></pre> 
<h3><a id="15_986"></a>15.关键目录</h3> 
<p>这里是kubeadm默认存放的路径</p> 
<p>kubeconfig就是admin.conf,可以放到自己电脑的$HOME/.kube下进行远程操作哦</p> 
<p><img src="https://images2.imgbox.com/09/b9/mIOo9hVr_o.jpg" alt=""></p> 
<p>这里是我操作的相关内容存放的路径</p> 
<p><img src="https://images2.imgbox.com/0c/2a/pjS4uDab_o.jpg" alt=""></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/221b175898636fd161c2d0cf8ceae4b0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Siren’s Song in the AI Ocean: A Survey on Hallucination in Large Language Models翻译</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a32397f4f5fe828fad9be47f46562675/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">ubuntu16-04安装minio</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>