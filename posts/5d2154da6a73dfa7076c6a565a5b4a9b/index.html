<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>PyTorch学习笔记07——模型的保存和加载 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="PyTorch学习笔记07——模型的保存和加载" />
<meta property="og:description" content="模型的保存和加载 序列化与反序列化断点续训练举个栗子理解 序列化与反序列化 模型的保存与加载也称序列化与反序列化
模型在内存中是以对象的形式存储的，而在硬盘中是以二进制序列保存的
序列化：是指将内存当中的某一个对象以二进制序列的形式存储到硬盘中，就可以长久的存储。
反序列化：将硬盘中的二进制数反序列化的放到内存中，得到对象，这样就可以使用模型了。
对应pytorch中的函数：
torch.save
主要参数： obj：对象（模型、张量、parameters、dict 等等）f：输出路径（指定一个硬盘中的路径去保存） 模型保存有两种方法：
法1：保存整个Module
torch.save(net, path) 法2：保存模型参数
state_dict = net.state_dict() torch.save(state_dict, path) 比如：
net = LeNet2(classes=2019) # &#34;训练&#34; print(&#34;训练前: &#34;, net.features[0].weight[0, ...]) net.initialize() print(&#34;训练后: &#34;, net.features[0].weight[0, ...]) path_model = &#34;./model.pkl&#34; path_state_dict = &#34;./model_state_dict.pkl&#34; # 保存整个模型 torch.save(net, path_model) # 保存模型参数 net_state_dict = net.state_dict() torch.save(net_state_dict, path_state_dict) torch.load
主要参数： f：文件路径（对应save中的f）map_location：指定存放位置，cpu or gpu（主要针对用gpu的时候） torch.load(path) 比如：
# ================================== load net =========================== # flag = 1 flag = 0 if flag: path_model = &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/5d2154da6a73dfa7076c6a565a5b4a9b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-18T09:37:08+08:00" />
<meta property="article:modified_time" content="2023-04-18T09:37:08+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">PyTorch学习笔记07——模型的保存和加载</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>模型的保存和加载</h4> 
 <ul><li><a href="#_1" rel="nofollow">序列化与反序列化</a></li><li><a href="#_89" rel="nofollow">断点续训练</a></li><li><a href="#_137" rel="nofollow">举个栗子理解</a></li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>序列化与反序列化</h2> 
<p>模型的保存与加载也称序列化与反序列化<br> 模型在内存中是以对象的形式存储的，而在硬盘中是以二进制序列保存的<br> 序列化：是指将内存当中的某一个对象以二进制序列的形式存储到硬盘中，就可以长久的存储。<br> 反序列化：将硬盘中的二进制数反序列化的放到内存中，得到对象，这样就可以使用模型了。</p> 
<p>对应pytorch中的函数：</p> 
<ol><li>torch.save<br> 主要参数：</li></ol> 
<ul><li>obj：对象（模型、张量、parameters、dict 等等）</li><li>f：输出路径（指定一个硬盘中的路径去保存）</li></ul> 
<p>模型保存有两种方法：<br> 法1：保存整个Module</p> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">,</span> path<span class="token punctuation">)</span>
</code></pre> 
<p>法2：保存模型参数</p> 
<pre><code class="prism language-python">state_dict <span class="token operator">=</span> net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>state_dict<span class="token punctuation">,</span> path<span class="token punctuation">)</span>
</code></pre> 
<p>比如：</p> 
<pre><code class="prism language-python">net <span class="token operator">=</span> LeNet2<span class="token punctuation">(</span>classes<span class="token operator">=</span><span class="token number">2019</span><span class="token punctuation">)</span>

<span class="token comment"># "训练"</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练前: "</span><span class="token punctuation">,</span> net<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
net<span class="token punctuation">.</span>initialize<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"训练后: "</span><span class="token punctuation">,</span> net<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

path_model <span class="token operator">=</span> <span class="token string">"./model.pkl"</span>
path_state_dict <span class="token operator">=</span> <span class="token string">"./model_state_dict.pkl"</span>

<span class="token comment"># 保存整个模型</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net<span class="token punctuation">,</span> path_model<span class="token punctuation">)</span>

<span class="token comment"># 保存模型参数</span>
net_state_dict <span class="token operator">=</span> net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>net_state_dict<span class="token punctuation">,</span> path_state_dict<span class="token punctuation">)</span>
</code></pre> 
<ol start="2"><li>torch.load<br> 主要参数：</li></ol> 
<ul><li>f：文件路径（对应save中的f）</li><li>map_location：指定存放位置，cpu or gpu（主要针对用gpu的时候）</li></ul> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path<span class="token punctuation">)</span>
</code></pre> 
<p>比如：</p> 
<pre><code class="prism language-python"><span class="token comment"># ================================== load net ===========================</span>
<span class="token comment"># flag = 1</span>
flag <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">if</span> flag<span class="token punctuation">:</span>

    path_model <span class="token operator">=</span> <span class="token string">"./model.pkl"</span>
    net_load <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path_model<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>net_load<span class="token punctuation">)</span>

<span class="token comment"># ================================== load state_dict ===========================</span>

flag <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment"># flag = 0</span>
<span class="token keyword">if</span> flag<span class="token punctuation">:</span>

    path_state_dict <span class="token operator">=</span> <span class="token string">"./model_state_dict.pkl"</span>
    state_dict_load <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path_state_dict<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>state_dict_load<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># ================================== update state_dict ===========================</span>
flag <span class="token operator">=</span> <span class="token number">1</span>
<span class="token comment"># flag = 0</span>
<span class="token keyword">if</span> flag<span class="token punctuation">:</span>

    net_new <span class="token operator">=</span> LeNet2<span class="token punctuation">(</span>classes<span class="token operator">=</span><span class="token number">2019</span><span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"加载前: "</span><span class="token punctuation">,</span> net_new<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    net_new<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>state_dict_load<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"加载后: "</span><span class="token punctuation">,</span> net_new<span class="token punctuation">.</span>features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre> 
<h2><a id="_89"></a>断点续训练</h2> 
<p>模型需要保存的最基本的数据：</p> 
<pre><code class="prism language-python">checkpoint <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
			<span class="token string">"model_state_dict"</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			<span class="token string">"optimizer_state_dict"</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
			<span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch
<span class="token punctuation">}</span>
</code></pre> 
<p>断点保存：</p> 
<pre><code class="prism language-python">checkpoint_interval <span class="token operator">=</span> <span class="token number">5</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>start_epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> MAX_EPOCH<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
	<span class="token comment"># 训练代码</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> checkpoint_interval <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>

        checkpoint <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">"model_state_dict"</span><span class="token punctuation">:</span> net<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                      <span class="token string">"optimizer_state_dict"</span><span class="token punctuation">:</span> optimizer<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                      <span class="token string">"epoch"</span><span class="token punctuation">:</span> epoch<span class="token punctuation">}</span>
        path_checkpoint <span class="token operator">=</span> <span class="token string">"./checkpoint_{}_epoch.pkl"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span>
        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>checkpoint<span class="token punctuation">,</span> path_checkpoint<span class="token punctuation">)</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    <span class="token comment"># 验证代码</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<p>续训练：<br> 前面的数据、模型、损失函数、优化器不变，在训练之前添加断点恢复</p> 
<pre><code class="prism language-python"><span class="token comment"># ============================ step 5+/5 断点恢复 ============================</span>
<span class="token comment"># 加载checkpoint</span>
path_checkpoint <span class="token operator">=</span> <span class="token string">"./checkpoint_4_epoch.pkl"</span>
checkpoint <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>path_checkpoint<span class="token punctuation">)</span>
<span class="token comment"># 更新模型数据</span>
net<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'model_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 更新优化器</span>
optimizer<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>checkpoint<span class="token punctuation">[</span><span class="token string">'optimizer_state_dict'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 设置起始epoch</span>
start_epoch <span class="token operator">=</span> checkpoint<span class="token punctuation">[</span><span class="token string">'epoch'</span><span class="token punctuation">]</span>
<span class="token comment"># 学习率也需要更改last_epoch（上一次迭代次数）</span>
scheduler<span class="token punctuation">.</span>last_epoch <span class="token operator">=</span> start_epoch

<span class="token comment"># ============================ step 5/5 训练 ============================</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre> 
<h2><a id="_137"></a>举个栗子理解</h2> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models
</code></pre> 
<p>PyTorch 模型将学习到的参数存储在一个内部状态字典，称为<code>state_dict</code>。可以通过<code>torch.save</code>方法持久保存这些参数：</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'model_weights.pth'</span><span class="token punctuation">)</span>
</code></pre> 
<p>要加载模型权重，需要先创建同一模型的实例，然后使用<code>load_state_dict()</code>方法加载参数。</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># we do not specify pretrained=True, i.e. do not load default weights</span>
model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model_weights.pth'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>注意：请确保inferencing前调用<code>model.eval()</code>方法，以将 dropout 和 batch normalization 层设置为评估模式。否则将产生不一致的推理结果。</p> 
<p>加载模型权重时，需要先实例化模型类，因为该类定义网络的结构。我们想保存这个类的结构连同模型，在这种情况下，我们可以传递<code>model</code>（而不是<code>model.state_dict()</code>）给保存的函数：</p> 
<pre><code class="prism language-python">torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">,</span> <span class="token string">'model.pth'</span><span class="token punctuation">)</span>
</code></pre> 
<p>加载模型：</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'model.pth'</span><span class="token punctuation">)</span>
</code></pre> 
<p>注意：此方法在序列化模型时使用 Python <a href="https://docs.python.org/3/library/pickle.html" rel="nofollow">pickle</a> 模块，因此加载模型时它依赖于可用的实际类定义。</p> 
<p>更细致的内容参见官方文档<a href="https://pytorch.org/tutorials/recipes/recipes/saving_and_loading_a_general_checkpoint.html" rel="nofollow">Saving and Loading a General Checkpoint in PyTorch</a>。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4c2dda3ccdf9456cebeab5bd5f4f71fc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">思科、华为路由协议优先级——管理距离AD值</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ee7a4f1c1227d0d20da0349bfe3bc633/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">零基础读懂Stable Diffusion（II）：怎么训练</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>