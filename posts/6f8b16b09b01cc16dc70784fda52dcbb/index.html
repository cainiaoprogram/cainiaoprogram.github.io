<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>多种LLM的API使用及开发流程 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="多种LLM的API使用及开发流程" />
<meta property="og:description" content="ChatGPT 调用 OpenAI API 是付费服务，需要先获取 OpenAI API Key，之后才能在应用中访问 ChatGPT。首先需要在OpenAI注册账号(登录注册需要科学的上网手段，有可靠方法可留言)，如果能成功注册就可以获得一个 OpenAI API KEY，将这个 key 保存到一个.env文件中，将这个文件放到项目根目录下。
读取.env 文件代码：
import os import openai from dotenv import load_dotenv, find_dotenv # 读取本地/项目的环境变量。 # find_dotenv()寻找并定位.env文件的路径 # load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中 # 如果你设置的是全局的环境变量，这行代码则没有任何作用。 _ = load_dotenv(find_dotenv()) # 如果你需要通过代理端口访问，你需要如下配置 os.environ[&#39;HTTPS_PROXY&#39;] = &#39;http://127.0.0.1:7890&#39; os.environ[&#34;HTTP_PROXY&#34;] = &#39;http://127.0.0.1:7890&#39; # 获取环境变量 OPENAI_API_KEY openai.api_key = os.environ[&#39;OPENAI_API_KEY&#39;] 使用OpenAI原生接口调用 # 获取环境变量 OPENAI_API_KEY openai.api_key = os.environ[&#39;OPENAI_API_KEY&#39;] # 创建ChatCompletion completion = openai.ChatCompletion.create( model=&#34;gpt-3.5-turbo&#34;, # 调用ChatGPT3.5 messages=[ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/6f8b16b09b01cc16dc70784fda52dcbb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-19T17:06:26+08:00" />
<meta property="article:modified_time" content="2023-11-19T17:06:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">多种LLM的API使用及开发流程</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>ChatGPT</h2> 
<p>        调用 OpenAI API 是付费服务，需要先获取 OpenAI API Key，之后才能在应用中访问 ChatGPT。首先需要在<a href="https://openai.com/" rel="nofollow" title="OpenAI">OpenAI</a>注册账号(登录注册需要科学的上网手段，有可靠方法可留言)，如果能成功注册就可以获得一个 OpenAI API KEY，将这个 key 保存到一个.env文件中，将这个文件放到项目根目录下。</p> 
<p>读取.env 文件代码：</p> 
<pre>import os
import openai
from dotenv import load_dotenv, find_dotenv

# 读取本地/项目的环境变量。
# find_dotenv()寻找并定位.env文件的路径
# load_dotenv()读取该.env文件，并将其中的环境变量加载到当前的运行环境中
# 如果你设置的是全局的环境变量，这行代码则没有任何作用。
_ = load_dotenv(find_dotenv())

# 如果你需要通过代理端口访问，你需要如下配置
os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'
os.environ["HTTP_PROXY"] = 'http://127.0.0.1:7890'

# 获取环境变量 OPENAI_API_KEY
openai.api_key = os.environ['OPENAI_API_KEY']</pre> 
<h3>使用OpenAI原生接口调用</h3> 
<pre># 获取环境变量 OPENAI_API_KEY
openai.api_key = os.environ['OPENAI_API_KEY']

# 创建ChatCompletion
completion = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",  # 调用ChatGPT3.5
    messages=[
        {"role": "system", "content": "You are an assistant."},
        {"role": "user", "content": "Hello, GPT!"}
    ]
)</pre> 
<p>参数解释：</p> 
<p>model：调用的模型，取值：“gpt-3.5-turbo”（ChatGPT-3.5）、“gpt-3.5-16k-0613”（ChatGPT-3.5 16K 版本）、“gpt-4”（ChatGPT-4）。</p> 
<p>message：提示词，ChatCompletion 的 message 需要传入一个列表，列表中包括多个不同角色的 提示词。system：即system prompt；user：用户输入的 prompt；assitance：助手，一般是模型历史回复，作为给模型参考的示例。(一般不需要使用到 system 与 assistance)</p> 
<p>temperature：Temperature 系数，控制模型返回的稳定性。</p> 
<p>max_tokens：模型输出的最大 token 数。OpenAI 计算 token 数是合并计算 Prompt 和 Completion 的总 token 数，要求总 token 数不能超过模型上限(如默认模型 token 上限为 4096)，如果输入的 prompt 较长，需要设置较小的 max_token 值，<strong>否则会报错超出限制长度</strong>。</p> 
<h3>使用LangChain调用OpenAI</h3> 
<p>LangChain 有多种大模型的封装，可以调用 ChatGPT 搭建个人应用。</p> 
<pre>from langchain.chat_models import ChatOpenAI
chat = ChatOpenAI(temperature=0.0)</pre> 
<p>ChatOpenAI 常用参数：</p> 
<p>model_name：模型名称，默认为 ‘gpt-3.5-turbo’。</p> 
<p>temperature：温度系数。 openai_api_key：OpenAI API key，</p> 
<p>openai_proxy：设置代理。max_tokens：模型输出的最大 token 数。</p> 
<p>streaming：是否使用流式传输，即逐字输出模型回答，默认为 False。</p> 
<p>LangChain 提供了 Template 模块设置 Prompt。可以直接调用 Template 填充个性化任务。Template 是包括 Python 字符串范式的字符，可以使用 format 方法进行填充。</p> 
<pre>from langchain.prompts import ChatPromptTemplate

template_str = """Translate the text that is delimited 
by triple backticks into a Chinses. text: ```{text}```"""
chat_template = ChatPromptTemplate.from_template(template_str)

text = "Today is Saturday."
# 接着调用 format_messages 将 template 转化为 message 格式
message = chat_template.format_messages(text=text)
response = chat(message)</pre> 
<h2>文心一言</h2> 
<p>        调用文心一言API同样需要key才可以使用。其有两层秘钥认证，第一层，拥有调用权限的账户可获取 API_Key 和 Secret_Key，每一个账户可以创建若干个应用，每个应用会对应一个 API_Key 和 Secret_Key，基于这两个 Key 可获取 access_token 值。使用 access_token 调用百度文心大模型。</p> 
<p>        进入<a href="https://console.bce.baidu.com/qianfan/overview" rel="nofollow" title="文心千帆服务平台">文心千帆服务平台</a>，选择应用接入，创建文心大模型的应用，创建成功后就可以看到AppID、API Key、Secret Key，使用API Key、Secret Key获取access_token需要通过post请求。</p> 
<pre>import requests
import json


def get_access_token():
    """
    使用 API Key，Secret Key 获取access_token，替换下列示例中的应用API Key、应用Secret Key
    """
    # 指定网址
    url = "https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&amp;client_id=" \
          "{api_key}&amp;client_secret={secret_key}"
    # 设置 POST 访问
    payload = json.dumps("")
    headers = {
        'Content-Type': 'application/json',
        'Accept': 'application/json'
    }
    # 通过 POST 访问获取账户对应的 access_token
    response = requests.request("POST", url, headers=headers, data=payload)
    
    return response.json().get("access_token")</pre> 
<h3>使用百度原生接口调用</h3> 
<pre>def get_res(prompt):
    # 调用接口
    url = "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/" \
          "eb-instant?access_token={access_token}"
    # 配置 POST 参数
    payload = json.dumps({
        "messages": [
            {
                "role": "user",  # user prompt
                "content": "{}".format(prompt)  # 输入的 prompt
            }
        ]
    })
    headers = {'Content-Type': 'application/json'}
    # 发起请求
    response = requests.request("POST", url, headers=headers, data=payload)
    # 返回的是一个 Json 字符串
    js = json.loads(response.text)
    
    return js["result"]</pre> 
<p>常用参数：</p> 
<p>messages：提示词，不支持 max_token 参数，由模型自行控制最大 token 数，content 总长度不能超过11200字符，超出时模型自动遗忘前文。 </p> 
<p>temperature：温度系数，默认0.95，不能设置为0。stream：是否使用流式传输。</p> 
<h3>使用LangChain调用文心模型</h3> 
<p>        原生的 LangChain 不支持调用文心模型，需要自定义LLM后才可使用。</p> 
<h2 style="background-color:transparent;">ChatGLM</h2> 
<p>       ChatGLM 包括 ChatGLM-130B 和 ChatGLM-6B 模型，支持复杂的自然语言指令，可解决推理类问题。初次使用的用户有18元token的免费使用额度。ChatGLM 有 SDK 和 HTTP 两种方式实现模型 API 的调用，建议使用 SDK 进行调用以获得更好的编程体验。注：需要安装zhupuai库。</p> 
<pre>import zhipuai

zhipuai.api_key = "api key"  # 填写控制台中获取的 APIKey 信息
model = "chatglm_std"  # 用于配置大模型版本

def get_prompt(role, content, ms=[]):
    # role 是指定角色，content 是 prompt 内容
    d = dict()
    d["role"] = role
    d["content"] = content
    ms.append(d)
    
    return ms

p = get_prompt("user", "Hello!")

# 请求模型, 调用glm的SDK
response = zhipuai.model_api.invoke(
    model=model,
    prompt=p
)
print(response)</pre> 
<p><span style="color:#0d0016;">常用参数：</span></p> 
<p><span style="color:#0d0016;"><code>prompt：</code>列表， 按照 {"role": "user", "content": "Hello！"} 的键值对形式进行传参，超过模型输入长度限制会自动截断。</span></p> 
<p><span style="color:#0d0016;"><font face="monospace"><strong>temperature</strong>：</font>控制输出的随机性，(0.0,1.0]，不能等于 0，默认值 0.95 。</span></p> 
<p><span style="color:#0d0016;"><code><strong>top_p</strong>：</code>核取样，(0.0, 1.0) ，默认值 0.7，0.7表示从前 70% 的结果中取 tokens。</span></p> 
<p><span style="color:#0d0016;"><code><strong>request_id：字符串</strong>，</code>每次请求的唯一标识，用户端传参要保证唯一，为空则默认生成。</span></p> 
<p><span style="color:#0d0016;"><code><strong>return_type：字符串</strong>，</code>返回内容的类型，默认返回json_string，<code>text</code> 表示返回文本内容。</span></p> 
<p><span style="color:#0d0016;"><strong>注</strong>：可根据需要调整top_p或temperature，但不要同时调整。</span></p> 
<p>使用LangChain调用ChatGLM时同样需要先自定义LLM才可使用。</p> 
<h2>LLM开发流程</h2> 
<p>        调用 LLM 的 API 实现核心的理解与生成，使用 Prompt 控制大语言模型。LLM的两个核心功能：指令理解和文本生成。相比之前，使用小模型解决业务问题，需要将业务分解成子问题，对每个子问题划分训练集和验证集，训练模型，最后在将模型链接在一起。在 LLM 的帮助下，可使用通用模型 + 不同业务的提示词来解决业务问题。在这种情况下，对效果的评估也不同于之前，由于不需要构建训练集、验证集、测试集，而是直接使用业务数据作为验证集以调整提示词，并结果不好的数据作为测试集修改提高提示词。</p> 
<h3>开发过程分解</h3> 
<p>        应用目的：开发模型的核心目的。</p> 
<p>        应用功能：应用需实现的功能及业务逻辑拆解。</p> 
<p>        应用架构：业务数据 + 提示词 + 通用大模型</p> 
<p>        数据处理：对业务数据预处理，做向量化并存在数据库中。</p> 
<p>        提示工程：使用业务数据构建验证集并以此设计提示词。</p> 
<p>        优化迭代：根据上一步构建的提示词效果，选出效果不佳的case优化提示词。</p> 
<p>        </p> 
<p>     </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5cd01f9c745aed688b105b74894e24e4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【c&#43;&#43;】左值和右值</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/287159c4c7c0425acaa5b374c265bc88/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">抖音点赞取消点赞</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>