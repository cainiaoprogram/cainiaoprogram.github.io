<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>图像分割之Unet原理简介与代码简析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="图像分割之Unet原理简介与代码简析" />
<meta property="og:description" content="Unet论文地址：
A Nested U-Net Architecture for Medical Image Segmentation
Unet是比较早的基于深度学习的分割算法了，优点是速度真的快（P100上基于VGG的backbone能跑到50帧），同时不是太开放的场景下可以做到令人满意的分割效果，在对实时性要求较高的场合下是比较适用的（不是所有的场合都能上MaskRCNN的，Backbone大一点，如果显卡差点就容易爆显存了。。），同时相比大分割网络的模型动辄几百Mb，Unet用小backbone模型就可以做到10Mb内，Conv层通道减少一点再把网络模型参数分开，模型大小可以做到很小，用CPU跑速度都挺快的，关键是分割精度在较为简单场景下还可以，load速度快太多了，简单，效果好，速度快，这也就是Unet为什么这么受欢迎的原因，下面是Unet原理介绍：
下图就是Unet网络结构：
Unet结构可以说是相对比较简单的图像分割算法了，通过四个下采样提取目标特征，再通过四个上采样，最后逐个对其像素点进行分类，那么这实际上是一个基于编码器（encode）-解码器（decode）思想，选用四个block做下采样的原因论文作者好像并没有说明，个人理解是因为是更适合测试数据集？
既然说到编码器-解码器，我的个人理解是编码器实际上相当于backbone对输入图片进行特征提取，提取出合适的feature-map，再通过解码器恢复至原尺寸，进行逐个像素点分类。
例如输入1281283的图片，输入网络后的输出为1281281的mask，
以下是一个最简单的下采样block:
x = Conv2D(64, (3, 3), padding=&#39;same&#39;, name=&#39;block1_conv1&#39;)(input) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = Conv2D(64, (3, 3), padding=&#39;same&#39;, name=&#39;block1_conv2&#39;)(x) x = BatchNormalization()(x) b1 = Activation(&#39;relu&#39;)(x) x = MaxPooling2D()(b1) 下采样过程其实没有什么特别值得说明的，就是简单的卷积层特征提取。
上采样：
输入图像经过前面下采样进行特征提取之后，需要把图像恢复至原来的尺寸以便进一步对像素进行分类（所谓的语义分割），那么这个过程也就是上采样。
一般来说上采样方法常见的有：双线性差值（bilinear）,反卷积（Transposed Convolution），还有就是反池化（Unpooling），Unet的上采样就是通过反卷积实现的。
反卷积实质上来说是转置卷积，早在2011年被Zeiler提出，这里简单介绍一下反卷积，详细介绍请看这里
卷积的前向计算可以看做是参数矩阵和输入矩阵相乘，Y是输出，C是参数矩阵，X是输入矩阵
那么反卷积其实类似该前向的逆运算写成：
这里注意的是，反卷积只是为了恢复图像shape，而不是为了恢复图像像素，所以并不是完全的逆运算，反卷积实质还是一种卷积。
Unet中一个标准的上采样block，注意这里运用了一个跳连接把前面的特征图和上采样后的特征图concat到一起（类似resnet的思想），目的是使得上采样后的特征图具有更多的浅层语义信息，增强分割精度，这里注意，最后一层直接一个sigmoid二分类把mask分为前景和背景。
x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=&#39;same&#39;)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = concatenate([x, b3]) x = Conv2D(256, (3, 3), padding=&#39;same&#39;)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) x = Conv2D(256, (3, 3), padding=&#39;same&#39;)(x) x = BatchNormalization()(x) x = Activation(&#39;relu&#39;)(x) 分类：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d73c49a901380528d4c305b5dc154457/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-05-05T21:47:28+08:00" />
<meta property="article:modified_time" content="2020-05-05T21:47:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">图像分割之Unet原理简介与代码简析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>Unet论文地址：</p> 
<p>A Nested U-Net Architecture for Medical Image Segmentation</p> 
<p>Unet是比较早的基于深度学习的分割算法了，优点是速度真的快（P100上基于VGG的backbone能跑到50帧），同时不是太开放的场景下可以做到令人满意的分割效果，在对实时性要求较高的场合下是比较适用的（不是所有的场合都能上MaskRCNN的，Backbone大一点，如果显卡差点就容易爆显存了。。），同时相比大分割网络的模型动辄几百Mb，Unet用小backbone模型就可以做到10Mb内，Conv层通道减少一点再把网络模型参数分开，模型大小可以做到很小，用CPU跑速度都挺快的，关键是分割精度在较为简单场景下还可以，load速度快太多了，简单，效果好，速度快，这也就是Unet为什么这么受欢迎的原因，下面是Unet原理介绍：</p> 
<p>下图就是Unet网络结构：<br> <img src="https://images2.imgbox.com/f4/de/yPYJQGaW_o.png" alt="在这里插入图片描述"></p> 
<p>Unet结构可以说是相对比较简单的图像分割算法了，通过四个下采样提取目标特征，再通过四个上采样，最后逐个对其像素点进行分类，那么这实际上是一个基于编码器（encode）-解码器（decode）思想，选用四个block做下采样的原因论文作者好像并没有说明，个人理解是因为是更适合测试数据集？</p> 
<p>既然说到编码器-解码器，我的个人理解是编码器实际上相当于backbone对输入图片进行特征提取，提取出合适的feature-map，再通过解码器恢复至原尺寸，进行逐个像素点分类。</p> 
<p>例如输入128<em>128</em>3的图片，输入网络后的输出为128<em>128</em>1的mask，</p> 
<p>以下是一个最简单的下采样block:</p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'block1_conv1'</span><span class="token punctuation">)</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'block1_conv2'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
b1 <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

x <span class="token operator">=</span> MaxPooling2D<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>b1<span class="token punctuation">)</span>
</code></pre> 
<p>下采样过程其实没有什么特别值得说明的，就是简单的卷积层特征提取。</p> 
<p>上采样：</p> 
<p>输入图像经过前面下采样进行特征提取之后，需要把图像恢复至原来的尺寸以便进一步对像素进行分类（所谓的语义分割），那么这个过程也就是上采样。</p> 
<p>一般来说上采样方法常见的有：双线性差值（bilinear）,反卷积（Transposed Convolution），还有就是反池化（Unpooling），Unet的上采样就是通过反卷积实现的。</p> 
<p>反卷积实质上来说是转置卷积，早在2011年被Zeiler提出，这里简单介绍一下反卷积，详细介绍请看<a href="https://www.zhihu.com/question/48279880" rel="nofollow">这里</a></p> 
<p>卷积的前向计算可以看做是参数矩阵和输入矩阵相乘，Y是输出，C是参数矩阵，X是输入矩阵</p> 
<p><img src="https://images2.imgbox.com/b6/18/MjChj6mL_o.png" alt="在这里插入图片描述"><br> 那么反卷积其实类似该前向的逆运算写成：</p> 
<p><img src="https://images2.imgbox.com/05/dc/j7CNfVb4_o.png" alt="在这里插入图片描述"></p> 
<p>这里注意的是，反卷积只是为了恢复图像shape，而不是为了恢复图像像素，所以并不是完全的逆运算，反卷积实质还是一种卷积。</p> 
<p>Unet中一个标准的上采样block，注意这里运用了一个跳连接把前面的特征图和上采样后的特征图concat到一起（类似resnet的思想），目的是使得上采样后的特征图具有更多的浅层语义信息，增强分割精度，这里注意，最后一层直接一个sigmoid二分类把mask分为前景和背景。</p> 
<pre><code class="prism language-python">x <span class="token operator">=</span> Conv2DTranspose<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

x <span class="token operator">=</span> concatenate<span class="token punctuation">(</span><span class="token punctuation">[</span>x<span class="token punctuation">,</span> b3<span class="token punctuation">]</span><span class="token punctuation">)</span>
x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>

x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
x <span class="token operator">=</span> Activation<span class="token punctuation">(</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<p>分类：</p> 
<h2><a id="sigmoid_88"></a>最后一层，通过sigmoid完成前景和背景分类</h2> 
<pre><code class="prism language-python">x <span class="token operator">=</span> Conv2D<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'sigmoid'</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'same'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span>
</code></pre> 
<p>损失函数：</p> 
<p>简单说明一下图像分割中的损失函数：</p> 
<p>Unet的损失函数其实就是一般的图像分割损失函数</p> 
<p>常见的图像分割损失函数有，Binary crossentropy，dice coefficient，focal loss（解决类别不平衡），这里以dice_loss举例</p> 
<p>一般为：</p> 
<p><img src="https://images2.imgbox.com/da/eb/wP1NDjgo_o.png" alt="在这里插入图片描述"><br> A为先验mask，B为预测mask。</p> 
<p>具体代码实现：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> keras <span class="token keyword">import</span> backend <span class="token keyword">as</span> K
smooth <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">.</span>
<span class="token keyword">def</span> <span class="token function">dice_coef</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    y_true_f <span class="token operator">=</span> K<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>y_true<span class="token punctuation">)</span>
    y_pred_f <span class="token operator">=</span> K<span class="token punctuation">.</span>flatten<span class="token punctuation">(</span>y_pred<span class="token punctuation">)</span>
    intersection <span class="token operator">=</span> K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_true_f <span class="token operator">*</span> y_pred_f<span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">.</span> <span class="token operator">*</span> intersection <span class="token operator">+</span> smooth<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_true_f <span class="token operator">*</span> y_true_f<span class="token punctuation">)</span> <span class="token operator">+</span> K<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y_pred_f <span class="token operator">*</span> y_pred_f<span class="token punctuation">)</span> <span class="token operator">+</span> smooth<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">dice_coef_loss</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">1</span><span class="token punctuation">.</span> <span class="token operator">-</span> dice_coef<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>

</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6456dbbf83a2bd6a3c05df1668b15729/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SpringBoot项目启动自动执行sql脚本</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/04bcfe6929ad91c4d3a466dfa2ceeb79/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Redis-- key最大是多少 ，单个实例最多支持多少个key</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>