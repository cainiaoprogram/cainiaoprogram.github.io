<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>论文解读：Large Language Models as Analogical Reasoners - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="论文解读：Large Language Models as Analogical Reasoners" />
<meta property="og:description" content="一、动机 大模型在各种类型的NLP任务上均展现出惊艳的表现。基于CoT propmt能够更好地激发大模型解决复杂推理问题的能力，例如解决数学解题，可以让模型生成reasoning path。现有的经典的CoT方法有few-shot cot、zero-shot cot等。然后现有的cot面临两个核心挑战： 需要提供相关的exemplars作为指导；需要尽可能减少人工标注的成本； Zero-shot CoT避免了人工标注来引导推理，但是对于一些复杂的任务难以完成推理，例如code generation；而few-shot CoT则可以通过引入task相关的exemplar来让大模型生成相应的推理，但是此时则需要人工标注或挑选exemplar因此引发一个研究问题：如何能够同时兼顾两者的优势？本文提出一种“归纳学习”的提示方法。首先设计instruction让大模型生成出与当前问题比较相关的exemplars，并补全exemplars，最后让模型recall relevant problem and aolutions来解决当前的问题。 二、方法 本文关注problem-solving task。
给定一个问题 x x x，首先通过一个prompt method将问题映射到文本输入 ϕ ( x ) \phi(x) ϕ(x)，任务目标是调用LLM解决这个问题并生成目标答案 y y y，生成的目标答案可以包含reasoning path r r r和答案 a a a。
本文则是关注在设计 ϕ \phi ϕ。
Self-Generated Exemplars **归纳提示学习（analogical prompting）**旨在模型在解决一个新的问题时，能够自发性地寻找相似的已有的知识。因此提出Self-Generated Exemplars方法，即让模型从在训练阶段掌握的problem-solving knowledge中生成出相关的问题和解决方法。
设计指令来达到这个目的：
基于这个instruction的一个实例如下所示：
大模型能够根据给定的instruciton，在对于一个新的问题 x x x时候，能够先生成出3个相关的且互不相同的problem并给出相应的解决方案，然后再对目标问题进行解决。
self-generated instruction的三个核心部分：
需要明确地让模型生成relevant切diverse exemplars。因为打磨学会偏向于重复地生成一些经典的问题，误导模型生成。 generate problems that are distinct from each other.
single-pass &amp; independent exemplar generation。实验发现single-pass效果最好： single-pass：本文提出的方法，一个instruction让模型生成3个exemplar；independent exemplar generation：让模型分别生成若干exemplar，然后采样3个exemplar之后再重新设计prompt让大模型进行生成。 exemplar number K K K：发现3～5最佳。 Self-generated Knowledge &#43; Exemplars 对于像code-generation等复杂的任务，low-level exemplar generation不一定能过让模型很好地解决此类问题，因此本文提出一种high-level generation方法。通过设计如下指令来实现：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/fa8b073a7207dd106f141a599cd5963f/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-10-24T00:46:49+08:00" />
<meta property="article:modified_time" content="2023-10-24T00:46:49+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">论文解读：Large Language Models as Analogical Reasoners</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://images2.imgbox.com/00/69/NXWzSehn_o.png" alt="image.png"></p> 
<h3><a id="_1"></a>一、动机</h3> 
<ul><li>大模型在各种类型的NLP任务上均展现出惊艳的表现。基于CoT propmt能够更好地激发大模型解决复杂推理问题的能力，例如解决数学解题，可以让模型生成reasoning path。现有的经典的CoT方法有few-shot cot、zero-shot cot等。</li><li>然后现有的cot面临两个核心挑战： 
  <ul><li>需要提供相关的exemplars作为指导；</li><li>需要尽可能减少人工标注的成本；</li></ul> </li><li>Zero-shot CoT避免了人工标注来引导推理，但是对于一些复杂的任务难以完成推理，例如code generation；而few-shot CoT则可以通过引入task相关的exemplar来让大模型生成相应的推理，但是此时则需要人工标注或挑选exemplar</li><li>因此引发一个研究问题：如何能够同时兼顾两者的优势？</li><li>本文提出一种“归纳学习”的提示方法。首先设计instruction让大模型生成出与当前问题比较相关的exemplars，并补全exemplars，最后让模型recall relevant problem and aolutions来解决当前的问题。</li></ul> 
<h3><a id="_11"></a>二、方法</h3> 
<p>本文关注problem-solving task。<br> 给定一个问题<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         x 
        
       
      
        x 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>，首先通过一个prompt method将问题映射到文本输入<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ϕ 
        
       
         ( 
        
       
         x 
        
       
         ) 
        
       
      
        \phi(x) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span></span>，任务目标是调用LLM解决这个问题并生成目标答案<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         y 
        
       
      
        y 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.625em; vertical-align: -0.1944em;"></span><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span></span></span></span></span>，生成的目标答案可以包含reasoning path <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         r 
        
       
      
        r 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">r</span></span></span></span></span>和答案<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         a 
        
       
      
        a 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span></span>。<br> <img src="https://images2.imgbox.com/ac/5a/nJx0ddZw_o.png" alt="image.png"><br> 本文则是关注在设计<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ϕ 
        
       
      
        \phi 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.8889em; vertical-align: -0.1944em;"></span><span class="mord mathnormal">ϕ</span></span></span></span></span>。</p> 
<p><img src="https://images2.imgbox.com/62/f5/EDuEYDlu_o.png" alt="image.png"></p> 
<h4><a id="SelfGenerated_Exemplars_18"></a>Self-Generated Exemplars</h4> 
<p>**归纳提示学习（analogical prompting）**旨在模型在解决一个新的问题时，能够自发性地寻找相似的已有的知识。因此提出Self-Generated Exemplars方法，即让模型从在训练阶段掌握的problem-solving knowledge中生成出相关的问题和解决方法。<br> 设计指令来达到这个目的：<br> <img src="https://images2.imgbox.com/86/8e/zQDIrNSv_o.png" alt="image.png"><br> 基于这个instruction的一个实例如下所示：<br> <img src="https://images2.imgbox.com/fe/82/QbjhWHkX_o.png" alt="image.png"><br> 大模型能够根据给定的instruciton，在对于一个新的问题<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         x 
        
       
      
        x 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">x</span></span></span></span></span>时候，能够先生成出3个相关的且互不相同的problem并给出相应的解决方案，然后再对目标问题进行解决。</p> 
<p>self-generated instruction的三个核心部分：</p> 
<ul><li>需要明确地让模型生成relevant切diverse exemplars。因为打磨学会偏向于重复地生成一些经典的问题，误导模型生成。</li></ul> 
<blockquote> 
 <p>generate problems that are distinct from each other.</p> 
</blockquote> 
<ul><li>single-pass &amp; independent exemplar generation。实验发现single-pass效果最好： 
  <ul><li>single-pass：本文提出的方法，一个instruction让模型生成3个exemplar；</li><li>independent exemplar generation：让模型分别生成若干exemplar，然后采样3个exemplar之后再重新设计prompt让大模型进行生成。</li></ul> </li><li>exemplar number <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          K 
         
        
       
         K 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6833em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">K</span></span></span></span></span>：发现3～5最佳。</li></ul> 
<h4><a id="Selfgenerated_Knowledge__Exemplars_36"></a>Self-generated Knowledge + Exemplars</h4> 
<p>对于像code-generation等复杂的任务，low-level exemplar generation不一定能过让模型很好地解决此类问题，因此本文提出一种high-level generation方法。通过设计如下指令来实现：<br> <img src="https://images2.imgbox.com/e6/78/ZR4IM4Qd_o.png" alt="image.png"><br> 对应的具体的例子如下所示：<br> <img src="https://images2.imgbox.com/d3/a4/8Dpi6h5W_o.png" alt="image.png"><br> 本质来说，就是在self-generated exemplar prompt的基础上，添加新的任务，<strong>即让模型生成核心知识</strong>。例如代码生成中，需要让模型先思考选择什么algorithm，以及algorithm对应的tutorial。<br> Knowledge的优势主要体现在两个方面：</p> 
<ul><li>knowledge act as high-level takeaways that complement low-level exemplars, which prevents LLMs from overly relying on specific exemplars and helps to generalize to new problems;</li><li>LLMs identify the core concepts of the problem and produce exemplars that align more closely in fundamental problem-solving approaches</li></ul> 
<h3><a id="_46"></a>三、实验</h3> 
<h4><a id="_47"></a>实验数据任务：</h4> 
<ul><li>mathematical problem solving：GSM8K、MATH等；</li><li>code generation：动态规划、图算法等复杂的编程题，例如codeforces；</li><li>Big-Bench</li></ul> 
<h4><a id="_52"></a>模型：</h4> 
<ul><li>GPT3.5-turbo、GPT-4、PaLM2-L</li></ul> 
<h4><a id="_55"></a>实验结果：</h4> 
<p>发现本文提出的方达到了SOTA。<br> <img src="https://images2.imgbox.com/5b/ab/eGztokYj_o.png" alt="image.png"></p> 
<h4><a id="Selfgeneration_exemplarretrieve_relevant_exemplar_58"></a>探索：Self-generation exemplar与retrieve relevant exemplar的对比</h4> 
<ul><li>retrieve方法的优势在于准确可靠，即采样得到的exemplar一定是准确的，但是缺点在于需要额外的标注成本，且搜索空间往往有限</li><li>self-generation方法的优势在于简单且自适应，能够根据具体的task量身定制对应的exemplar，且搜索空间可以是整个模型训练的语料。 v</li></ul> 
<p><img src="https://images2.imgbox.com/80/c0/1aHONOL5_o.png" alt="image.png"></p> 
<h4><a id="Scale_of_LLM_64"></a>探索：Scale of LLM</h4> 
<p>上图中展示出，当模型规模越大时，解题的准确性也越高，同时我们提出的self-generation方法与baseline的提升幅度也越大。</p> 
<ul><li>当使用小模型时候，LLM本身的知识有限，因此更需要retrieve exemplar；</li><li>当使用大模型的时候，此时LLM本身的知识很丰富，选择self-generation更容易得到与目标问题相近的exemplar。</li></ul> 
<h4><a id="exemplar_70"></a>探索：exemplar数量分析</h4> 
<p><img src="https://images2.imgbox.com/f5/80/CwUx0VXx_o.png" alt="image.png"><br> 发现当<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         K 
        
       
         ∈ 
        
       
         { 
        
       
         3 
        
       
         , 
        
       
         4 
        
       
         , 
        
       
         5 
        
       
         } 
        
       
      
        K\in\{3, 4, 5\} 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.7224em; vertical-align: -0.0391em;"></span><span class="mord mathnormal" style="margin-right: 0.0715em;">K</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">{<!-- --></span><span class="mord">3</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">4</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord">5</span><span class="mclose">}</span></span></span></span></span>时候更合适。</p> 
<hr>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/32d415e67e0d295fdcc1e7e654fb257b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【C语言】斐波那契数列细讲</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a7241fa551f85ea14642cd90d8d6578e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【通览一百个大模型】Baize（UCSD）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>