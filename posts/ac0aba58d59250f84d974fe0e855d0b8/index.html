<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>R实战 | 聚类分析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="R实战 | 聚类分析" />
<meta property="og:description" content="聚类分析 R中有各种各样的聚类分析函数。本文主要介绍其中的三种方法:层次聚集、划分聚类、基于模型的聚类。
数据准备 聚类分析之前，可以对数据进行预处理，如包括缺失值的处理和数据的标准化。以鸢尾花数据集（iris）为例。
# 数据预处理 mydata &lt;- iris[,1:4] mydata &lt;- na.omit(mydata) # 删除缺失值 mydata &lt;- scale(mydata) # 数据标准化 Partitioning(划分) K-means 是我们最常用的基于欧式距离的聚类算法，其认为两个目标的距离越近，相似度越大。需要分析者先确定要将这组数据分成多少类，也即聚类的个数。根据所提取的簇数绘制出组内的平方和，可以帮助确定合适的簇数。
# 探索最佳聚类个数 # 计算不同个数聚类内部的距离平方和 wss &lt;- (nrow(mydata)-1)*sum(apply(mydata,2,var)) for (i in 2:15) wss[i] &lt;- sum(kmeans(mydata,centers=i)$withinss) plot(1:15, wss, type=&#34;b&#34;, xlab=&#34;Number of Clusters&#34;, ylab=&#34;Within groups sum of squares&#34;) WSS WSS下降趋于稳定的聚类数即为我们的最佳聚类。如图，聚类个数为4时满足要求。(3-5都差不多，并没有唯一聚类数)
# K-Means 聚类分析 fit &lt;- kmeans(mydata, 4) # 聚类数为4 # 每个聚类的均值 aggregate(mydata,by=list(fit$cluster),FUN=mean) # 添加聚类列 mydata_result &lt;- data.frame(mydata, fit$cluster) 层次聚类 R语言提供了丰富的层次聚类函数，这里简单介绍一下用Ward方法进行的层次聚类分析。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ac0aba58d59250f84d974fe0e855d0b8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-25T10:30:00+08:00" />
<meta property="article:modified_time" content="2022-04-25T10:30:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">R实战 | 聚类分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:left;"><img src="https://images2.imgbox.com/e1/ed/LfKeecDK_o.png" alt="c72286fd32c732e9193dcd53285e699f.png"></p> 
 <figcaption>
   聚类分析 
 </figcaption> 
 <p><code>R</code>中有各种各样的聚类分析函数。本文主要介绍其中的三种方法:<code>层次聚集</code>、<code>划分聚类</code>、<code>基于模型的聚类</code>。</p> 
 <h3>数据准备</h3> 
 <p>聚类分析之前，可以对数据进行预处理，如包括缺失值的处理和数据的标准化。以鸢尾花数据集（iris）为例。</p> 
 <pre class="has"><code class="language-go"># 数据预处理
mydata &lt;- iris[,1:4]
mydata &lt;- na.omit(mydata) # 删除缺失值
mydata &lt;- scale(mydata) # 数据标准化</code></pre> 
 <h3>Partitioning(划分)</h3> 
 <p><code>K-means</code> 是我们最常用的基于<code>欧式距离</code>的聚类算法，其认为两个目标的距离越近，相似度越大。需要分析者先确定要将这组数据分成多少类，也即聚类的个数。根据所提取的簇数绘制出组内的平方和，可以帮助确定合适的簇数。</p> 
 <pre class="has"><code class="language-go"># 探索最佳聚类个数
# 计算不同个数聚类内部的距离平方和
wss &lt;- (nrow(mydata)-1)*sum(apply(mydata,2,var))
for (i in 2:15) wss[i] &lt;- sum(kmeans(mydata,centers=i)$withinss)
plot(1:15, wss, type="b", 
     xlab="Number of Clusters",
     ylab="Within groups sum of squares")</code></pre> 
 <img src="https://images2.imgbox.com/3b/f7/gkUnZz9a_o.png" alt="777c468b401e66e5b69c3eed46c55367.png"> 
 <figcaption>
   WSS 
 </figcaption> 
 <p><code>WSS</code>下降趋于稳定的聚类数即为我们的最佳聚类。如图，聚类个数为4时满足要求。(3-5都差不多，并没有唯一聚类数)</p> 
 <pre class="has"><code class="language-go"># K-Means 聚类分析
fit &lt;- kmeans(mydata, 4) # 聚类数为4
# 每个聚类的均值
aggregate(mydata,by=list(fit$cluster),FUN=mean)
# 添加聚类列
mydata_result &lt;- data.frame(mydata, fit$cluster)</code></pre> 
 <h3>层次聚类</h3> 
 <p>R语言提供了丰富的层次聚类函数，这里简单介绍一下用<code>Ward</code>方法进行的层次聚类分析。</p> 
 <p>层次的聚类方法（Hierarchical Clustering），从字面上理解，其是层次化的聚类，最终得出来的是树形结构。专业一点来说，层次聚类通过 <strong>计算不同类别数据点间的相似度</strong> 来创建一棵有层次的嵌套聚类树。</p> 
 <p><strong>层次聚类的好处是不需要指定具体类别数目的</strong>，其得到的是一颗树，聚类完成之后，可在任意层次横切一刀，得到指定数目的簇。</p> 
 <img src="https://images2.imgbox.com/4e/09/bNRH63mo_o.png" alt="ecd121859dc2a4bd2c8592af48cc6044.png"> 
 <figcaption>
   聚类数示例 
 </figcaption> 
 <pre class="has"><code class="language-go"># Ward 层次聚类
d &lt;- dist(mydata, method = "euclidean") #距离矩阵
fit &lt;- hclust(d, method="ward")
plot(fit) # 聚类树</code></pre> 
 <img src="https://images2.imgbox.com/9e/eb/AckxrpkQ_o.png" alt="a22698608a9c94c32f282757eee652f1.png"> 
 <figcaption> 
  <br> 
 </figcaption> 
 <pre class="has"><code class="language-go">groups &lt;- cutree(fit, k=3) # 将聚类树切成3个聚类
rect.hclust(fit, k=3, border="red")</code></pre> 
 <img src="https://images2.imgbox.com/85/58/yj7yBgtt_o.png" alt="fff7c63d2c56a4b30dbc3bd18901f670.png"> 
 <figcaption> 
  <br> 
 </figcaption> 
 <p><code>pvclust</code>包中的<code>pvclust()</code>函数提供了基于多尺度<code>bootstrap</code>重采样的分层聚类的<code>p</code>值。得到数据高度支持的聚类将具有较大的<code>p</code>值。</p> 
 <pre class="has"><code class="language-go"># Ward Hierarchical Clustering with Bootstrapped p values
library(pvclust)
fit &lt;- pvclust(mydata, method.hclust="ward",
   method.dist="euclidean")
plot(fit) # dendogram with p values
# add rectangles around groups highly supported by the data
pvrect(fit, alpha=.95)</code></pre> 
 <img src="https://images2.imgbox.com/f0/93/Tt3NDGji_o.png" alt="eae783b53250f8fff9217cd1cfd971f0.png"> 
 <figcaption>
   pvclust 
 </figcaption> 
 <h3>基于模型聚类</h3> 
 <p>基于模型的聚类方法利用极大似然估计法和贝叶斯准则在大量假定的模型中去选择最佳的聚类模型并确定最佳聚类个数。其中，对于参数化高斯混合模型，<code>Mclust</code>包中的<code>Mclust()</code>函数根据分层聚类初始化EM的BIC选择最优模型。</p> 
 <pre class="has"><code class="language-go"># Model Based Clustering
library(mclust)
fit &lt;- Mclust(mydata)
plot(fit) # plot results
summary(fit) # display the best model</code></pre> 
 <img src="https://images2.imgbox.com/09/de/fpy5cFfY_o.png" alt="7e139493413fe120c91a10aa07bbe37d.png"> 
 <figcaption>
   Mclust 
 </figcaption> 
 <pre class="has"><code class="language-go">&gt; summary(fit) # display the best model
---------------------------------------------------- 
Gaussian finite mixture model fitted by EM algorithm 
---------------------------------------------------- 

Mclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 2 components: 

 log-likelihood   n df       BIC       ICL
      -322.6936 150 29 -790.6956 -790.6969

Clustering table:
  1   2 
 50 100</code></pre> 
 <p>从上面的结果来看，分为两个聚类效果更好。</p> 
 <h3>聚类可视化</h3> 
 <pre class="has"><code class="language-go"># K-Means Clustering with 5 clusters
fit &lt;- kmeans(mydata, 3)

# vary parameters for most readable graph
library(cluster)
clusplot(mydata, fit$cluster, color=TRUE, shade=TRUE,
   labels=2, lines=0)</code></pre> 
 <img src="https://images2.imgbox.com/35/36/yTq1kYZk_o.png" alt="9847341ddd5c0dfb98a78be1ec79cb54.png"> 
 <figcaption>
   clusplot 
 </figcaption> 
 <pre class="has"><code class="language-go"># Centroid Plot against 1st 2 discriminant functions
install.packages('fpc')
library(fpc)
plotcluster(mydata, fit$cluster)</code></pre> 
 <img src="https://images2.imgbox.com/b4/c6/gUCA7IhQ_o.png" alt="bbfb5b8eaacb91177da34810f2e36072.png"> 
 <figcaption>
   fpc 
 </figcaption> 
 <h3>参考</h3> 
 <ul><li><p><strong>Quick-R: Cluster Analysis (statmethods.net)</strong>(https://www.statmethods.net/advstats/cluster.html)</p></li></ul> 
 <h3>木舟笔记2022年度VIP企划</h3> 
 <p>权益：</p> 
 <ol><li><p><strong>2022</strong>年度木舟笔记<strong>所有推文示例数据及代码(在VIP群里实时更新)</strong>。</p><img src="https://images2.imgbox.com/e0/39/UiBYwgug_o.png" alt="1e1590316c7c77e56ce5f9a7019124a9.png"></li><li><p>木舟笔记<strong>科研交流群</strong>。</p></li><li><p>半价购买<code>跟着Cell学作图系列合集</code><a href="" rel="nofollow">(免费教程+代码领取)|跟着Cell学作图系列合集</a>。</p></li></ol> 
 <p>收费：</p> 
 <p> <strong>99￥/人</strong>。可添加微信：<code>mzbj0002</code> 转账，或直接在文末打赏。</p> 
 <img src="https://images2.imgbox.com/fa/fe/tdnJ6IJa_o.png" alt="eb15739cc43d1b96ebf2b7a7fd86ed2e.png"> 
 <figcaption>
   扫描二维码添加微信 
 </figcaption> 
 <hr> 
 <img src="https://images2.imgbox.com/58/13/JcHqOA5n_o.png" alt="e4a18c6b167e23129b196bc5d271165f.png"> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0a5f17302104ec749ac7bd4f0319cddc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">docker镜像文件分层的原理</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/fad99dd116773b30493137cc17b8b7d6/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">计算机网络_02_应用层(个人总结)</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>