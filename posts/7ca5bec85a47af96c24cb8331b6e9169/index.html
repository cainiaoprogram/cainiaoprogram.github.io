<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【人脸】人脸矫正相关知识 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【人脸】人脸矫正相关知识" />
<meta property="og:description" content="目录
人脸矫正相关知识
一、人脸矫正的简要流程
二、Python代码中人脸矫正实现方式
三、C&#43;&#43;代码中人脸矫正实现方式
人脸矫正相关知识 一、人脸矫正的简要流程 Step1、使用人脸检测结果的5个特征点和人脸标准的5个参考特征点坐标求出仿射变换矩阵。
Step2、通过上一步求得的放射变换矩阵对人脸进行旋转平移矫正，得到矫正好的人脸。
补充1.人脸标准的5个参考特征点坐标如下(人脸尺寸为112 * 112)：
src = np.array([ [30.2946&#43;8.0, 51.6963], [65.5318&#43;8.0, 51.5014], [48.0252&#43;8.0, 71.7366], [33.5493&#43;8.0, 92.3655], [62.7299&#43;8.0, 92.2041] ], dtype=np.float32 ) #该特征点坐标是基于112*112尺寸人脸的 二、Python代码中人脸矫正实现方式 备注：该方法使用skimage库的transform.SimilarityTransform()，先计算仿射变换矩阵，再使用opencv中的warpAffine()函数矫正人脸图片。
src = np.array([ [30.2946, 51.6963], [65.5318, 51.5014], [48.0252, 71.7366], [33.5493, 92.3655], [62.7299, 92.2041] ], dtype=np.float32 ) if image_size[1]==112: src[:,0] &#43;= 8.0 #每一行的第0个数据 dst = landmark.astype(np.float32) #astype:数据类型转换 # step1.计算仿射变换举证 tform = trans.SimilarityTransform() #创建一个相似变换对象(这是用到python的skimage库) tform.estimate(dst, src) # estimate():通过一组对应点估计出变换矩阵 M = tform." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/7ca5bec85a47af96c24cb8331b6e9169/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-05-07T21:33:12+08:00" />
<meta property="article:modified_time" content="2021-05-07T21:33:12+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【人脸】人脸矫正相关知识</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86-toc" style="margin-left:0px;"><a href="#%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86" rel="nofollow">人脸矫正相关知识</a></p> 
<p id="%E4%B8%80%E3%80%81%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E7%9A%84%E7%AE%80%E8%A6%81%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#%E4%B8%80%E3%80%81%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E7%9A%84%E7%AE%80%E8%A6%81%E6%B5%81%E7%A8%8B" rel="nofollow">一、人脸矫正的简要流程</a></p> 
<p id="%E4%BA%8C%E3%80%81Python%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F-toc" style="margin-left:40px;"><a href="#%E4%BA%8C%E3%80%81Python%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F" rel="nofollow">二、Python代码中人脸矫正实现方式</a></p> 
<p id="%E4%B8%89%E3%80%81C%2B%2B%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F-toc" style="margin-left:40px;"><a href="#%E4%B8%89%E3%80%81C%2B%2B%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F" rel="nofollow">三、C++代码中人脸矫正实现方式</a></p> 
<hr id="hr-toc"> 
<h2 id="%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86">人脸矫正相关知识</h2> 
<h3 id="%E4%B8%80%E3%80%81%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E7%9A%84%E7%AE%80%E8%A6%81%E6%B5%81%E7%A8%8B">一、人脸矫正的简要流程</h3> 
<p>Step1、使用<span style="color:#3399ea;">人脸检测结果的5个特征点</span>和<span style="color:#3399ea;">人脸标准的5个参考特征点</span>坐标<strong><span style="color:#f33b45;">求出仿射变换矩阵</span></strong>。</p> 
<p>Step2、通过上一步求得的放射变换矩阵对人脸进行旋转平移矫正，得到矫正好的人脸。</p> 
<p><strong>补充1.</strong><span style="color:#3399ea;">人脸标准的5个参考特征点坐标如下(<strong>人脸尺寸为112 * 112</strong>)：</span></p> 
<pre><code class="language-python">    src = np.array([
      [30.2946+8.0, 51.6963],
      [65.5318+8.0, 51.5014],
      [48.0252+8.0, 71.7366],
      [33.5493+8.0, 92.3655],
      [62.7299+8.0, 92.2041] ], dtype=np.float32 )
#该特征点坐标是基于112*112尺寸人脸的</code></pre> 
<h3 id="%E4%BA%8C%E3%80%81Python%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F">二、Python代码中人脸矫正实现方式</h3> 
<p>备注：该方法使用skimage库的transform.SimilarityTransform()，先计算仿射变换矩阵，再使用opencv中的warpAffine()函数矫正人脸图片。</p> 
<pre><code class="language-python">src = np.array([
      [30.2946, 51.6963],
      [65.5318, 51.5014],
      [48.0252, 71.7366],
      [33.5493, 92.3655],
      [62.7299, 92.2041] ], dtype=np.float32 )
    if image_size[1]==112:
      src[:,0] += 8.0 #每一行的第0个数据
    dst = landmark.astype(np.float32) #astype:数据类型转换
    
    # step1.计算仿射变换举证
    tform = trans.SimilarityTransform() #创建一个相似变换对象(这是用到python的skimage库)
    tform.estimate(dst, src)  # estimate():通过一组对应点估计出变换矩阵
    M = tform.params[0:2,:]
    # M = trorm.params
    
    # step2.通过仿射变换矩阵对人脸进行矫正
    warped = cv2.warpAffine(img,M,(image_size[1],image_size[0]), borderValue = 0.0)
</code></pre> 
<pre><code class="language-python">    ### 这里还看到有一个投影变换的操作方法,不过并未使用该方法
    tform3 = trans.ProjectiveTransform()
    tform3.estimate(src, dst)
    warped = trans.warp(img, tform3, output_shape=_shape)</code></pre> 
<h3 id="%E4%B8%89%E3%80%81C%2B%2B%E4%BB%A3%E7%A0%81%E4%B8%AD%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F">三、C++代码中人脸矫正实现方式</h3> 
<p>备注：C++中直接使用opencv库函数实现人脸矫正功能。</p> 
<pre><code class="language-cpp">//pts为人脸检测结果的特征点坐标,anchors是标准参考特征点坐标
///===step1.计算仿射变换矩阵
cv::Mat warp_mat = cv::estimateRigidTransform(pts, anchors, false);    //求特征点的仿射变换矩阵

///===step2.通过仿射变换矩阵矫正人脸
cv::warpAffine(imgc, rectifiedImg, warp_mat, cv::Size(112, 112));//对图像的旋转和平移都是通过仿射变换函数cv::warpAffine()来实现的
</code></pre> 
<p><strong>备注：<em>cvEstimateRigidTransform</em></strong>是opencv中求取仿射变换的函数，该函数会用到<span style="color:#3399ea;"><strong>ransac算法</strong></span>（从所有特征点中通过迭代的方式选取若干数量的"有效"特征点），然后利用icvGetRTMatrix函数求取仿射变换系数。</p> 
<p><strong>ransac算法简要介绍：</strong></p> 
<p><strong>ransac算法</strong>能够解决全部的数据中存在错误数据的情况，现实中我们的数据可能会存在错误的数据(标注错误等等)，这些数据会影响模型拟合，ransac算法随机选取数据中的一部分进行迭代，有较大概率能够避开错误数据的干扰。</p> 
<p><img alt="" height="236" src="https://images2.imgbox.com/84/82/qrtvaJoF_o.png" width="411"><br> RANSAC算法通过反复选择数据中的一组随机子集来达成目标。被选取的子集被假设为局内点，并用下述方法进行验证：<br> 1.首先我们先随机假设一小组局内点为初始值。然后用此局内点拟合一个模型。(此模型适应于假设的局内点，所有的未知参数都能从假设的局内点计算得出)。<br> 2.用1中得到的模型去测试所有的其它数据，如果某个点适用于估计的模型，认为它也是局内点，将局内点扩充。<br> 3.如果有足够多的点被归类为假设的局内点，那么估计的模型就足够合理。<br> 4.然后，用所有假设的局内点去重新估计模型，因为此模型仅仅是在初始的假设的局内点估计的，后续有扩充后，需要更新。<br> 5.最后，通过估计局内点与模型的错误率来评估模型。<br> 整个这个过程为迭代一次，此过程被重复执行固定的次数，每次产生的模型有两个结局：<br> 1、要么因为局内点太少，还不如上一次的模型，而被舍弃，<br> 2、要么因为比现有的模型更好而被选用。<br> 参考链接：https://blog.csdn.net/robinhjwy/article/details/79174914</p> 
<p> </p> 
<p><strong>下面还有一个第三方实现的仿射变换矩阵计算方法</strong>：(来源:<a href="https://blog.csdn.net/u011956147/article/details/90294249">https://blog.csdn.net/u011956147/article/details/90294249</a>)</p> 
<pre><code class="language-cpp">float default[5][2] = {  
            {30.2946f+8.0f, 51.6963f},
            {65.5318f+8.0f, 51.5014f},
            {48.0252f+8.0f, 71.7366f},
            {33.5493f+8.0f, 92.3655f},
            {62.7299f+8.0f, 92.2041f}
        };  // +8.0f for 112*112
float detect[5][2] = {  
            {30.2946f, 51.6963f},
            {65.5318f, 51.5014f},
            {48.0252f, 71.7366f},
            {33.5493f, 92.3655f},
            {62.7299f, 92.2041f}
        };  // 
cv::Mat src(5,2,CV_32FC1, default); 
memcpy(src.data, default, 2 * 5 * sizeof(float));
cv::Mat dst(5,2,CV_32FC1, detect);
memcpy(dst.data, detect, 2 * 5 * sizeof(float));

cv::Mat M = FacePreprocess::similarTransform(dst, src);  // skimage.transform.SimilarityTransform
cv::Mat warpImg;
//cv::warpAffine(input, warpImg, M, cv::Size(112, 112));
cv::warpPerspective(inpu, croppedMat, M, cv::Size(112, 112));
</code></pre> 
<pre><code class="language-cpp">namespace FacePreprocess {

    cv::Mat meanAxis0(const cv::Mat &amp;src)
    {
        int num = src.rows;
        int dim = src.cols;

        // x1 y1
        // x2 y2

        cv::Mat output(1,dim,CV_32F);
        for(int i = 0 ; i &lt;  dim; i ++)
        {
            float sum = 0 ;
            for(int j = 0 ; j &lt; num ; j++)
            {
                sum+=src.at&lt;float&gt;(j,i);
            }
            output.at&lt;float&gt;(0,i) = sum/num;
        }

        return output;
    }

    cv::Mat elementwiseMinus(const cv::Mat &amp;A,const cv::Mat &amp;B)
    {
        cv::Mat output(A.rows,A.cols,A.type());

        assert(B.cols == A.cols);
        if(B.cols == A.cols)
        {
            for(int i = 0 ; i &lt;  A.rows; i ++)
            {
                for(int j = 0 ; j &lt; B.cols; j++)
                {
                    output.at&lt;float&gt;(i,j) = A.at&lt;float&gt;(i,j) - B.at&lt;float&gt;(0,j);
                }
            }
        }
        return output;
    }


    cv::Mat varAxis0(const cv::Mat &amp;src)
    {
	cv::Mat temp_ = elementwiseMinus(src,meanAxis0(src));
        cv::multiply(temp_ ,temp_ ,temp_ );
        return meanAxis0(temp_);

    }



    int MatrixRank(cv::Mat M)
    {
	cv::Mat w, u, vt;
	cv::SVD::compute(M, w, u, vt);
	cv::Mat1b nonZeroSingularValues = w &gt; 0.0001;
        int rank = countNonZero(nonZeroSingularValues);
        return rank;

    }

//    References
//    ----------
//    .. [1] "Least-squares estimation of transformation parameters between two
//    point patterns", Shinji Umeyama, PAMI 1991, DOI: 10.1109/34.88573
//
//    """
//
//    Anthor:Jack Yu
    cv::Mat similarTransform(cv::Mat src,cv::Mat dst) {
        int num = src.rows;
        int dim = src.cols;
        cv::Mat src_mean = meanAxis0(src);
        cv::Mat dst_mean = meanAxis0(dst);
        cv::Mat src_demean = elementwiseMinus(src, src_mean);
        cv::Mat dst_demean = elementwiseMinus(dst, dst_mean);
        cv::Mat A = (dst_demean.t() * src_demean) / static_cast&lt;float&gt;(num);
        cv::Mat d(dim, 1, CV_32F);
        d.setTo(1.0f);
        if (cv::determinant(A) &lt; 0) {
            d.at&lt;float&gt;(dim - 1, 0) = -1;

        }
	cv::Mat T = cv::Mat::eye(dim + 1, dim + 1, CV_32F);
        cv::Mat U, S, V;
	cv::SVD::compute(A, S,U, V);

        // the SVD function in opencv differ from scipy .


        int rank = MatrixRank(A);
        if (rank == 0) {
            assert(rank == 0);

        } else if (rank == dim - 1) {
            if (cv::determinant(U) * cv::determinant(V) &gt; 0) {
                T.rowRange(0, dim).colRange(0, dim) = U * V;
            } else {
//            s = d[dim - 1]
//            d[dim - 1] = -1
//            T[:dim, :dim] = np.dot(U, np.dot(np.diag(d), V))
//            d[dim - 1] = s
                int s = d.at&lt;float&gt;(dim - 1, 0) = -1;
                d.at&lt;float&gt;(dim - 1, 0) = -1;

                T.rowRange(0, dim).colRange(0, dim) = U * V;
                cv::Mat diag_ = cv::Mat::diag(d);
                cv::Mat twp = diag_*V; //np.dot(np.diag(d), V.T)
		cv::Mat B = cv::Mat::zeros(3, 3, CV_8UC1);
		cv::Mat C = B.diag(0);
                T.rowRange(0, dim).colRange(0, dim) = U* twp;
                d.at&lt;float&gt;(dim - 1, 0) = s;
            }
        }
        else{
            cv::Mat diag_ = cv::Mat::diag(d);
            cv::Mat twp = diag_*V.t(); //np.dot(np.diag(d), V.T)
            cv::Mat res = U* twp; // U
            T.rowRange(0, dim).colRange(0, dim) = -U.t()* twp;
        }
        cv::Mat var_ = varAxis0(src_demean);
        float val = cv::sum(var_).val[0];
        cv::Mat res;
        cv::multiply(d,S,res);
        float scale =  1.0/val*cv::sum(res).val[0];
        T.rowRange(0, dim).colRange(0, dim) = - T.rowRange(0, dim).colRange(0, dim).t();
        cv::Mat  temp1 = T.rowRange(0, dim).colRange(0, dim); // T[:dim, :dim]
        cv::Mat  temp2 = src_mean.t(); //src_mean.T
        cv::Mat  temp3 = temp1*temp2; // np.dot(T[:dim, :dim], src_mean.T)
        cv::Mat temp4 = scale*temp3;
        T.rowRange(0, dim).colRange(dim, dim+1)=  -(temp4 - dst_mean.t()) ;
        T.rowRange(0, dim).colRange(0, dim) *= scale;
        return T;
    }
}
</code></pre> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f5af213391e1fcd5d1f2fc92574c2ac8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">xp系统中提示文件WINDOWS\SYSTEM32\CONFIG\SYSTEM缺失问题的解决方法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/dff736bb82ec7887ef4a9e84544f32bd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android Studio / IDEA 编辑器显示代码路径目录层级</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>