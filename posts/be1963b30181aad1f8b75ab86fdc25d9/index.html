<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>82.é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰ä»¥åŠä»£ç å®ç° - èœé¸Ÿç¨‹åºå‘˜åšå®¢</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="82.é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰ä»¥åŠä»£ç å®ç°" />
<meta property="og:description" content="1. é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ å¿˜è®°é—¨ï¼šå°†å€¼æœ0å‡å°‘è¾“å…¥é—¨ï¼šå†³å®šä¸æ˜¯å¿½ç•¥æ‰è¾“å…¥æ•°æ®è¾“å‡ºé—¨ï¼šå†³å®šæ˜¯ä¸æ˜¯ä½¿ç”¨éšçŠ¶æ€ 2. é—¨ 3. å€™é€‰è®°å¿†å•å…ƒ 4. è®°å¿†å•å…ƒ 5. éšçŠ¶æ€ 6. æ€»ç»“ 7. ä»é›¶å®ç°çš„ä»£ç  æˆ‘ä»¬é¦–å…ˆåŠ è½½æ—¶å…‰æœºå™¨æ•°æ®é›†ã€‚
import torch from torch import nn from d2l import torch as d2l batch_size, num_steps = 32, 35 train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps) 7.1 åˆå§‹åŒ–æ¨¡å‹å‚æ•° æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å’Œåˆå§‹åŒ–æ¨¡å‹å‚æ•°ã€‚ å¦‚å‰æ‰€è¿°ï¼Œè¶…å‚æ•°num_hiddenså®šä¹‰éšè—å•å…ƒçš„æ•°é‡ã€‚ æˆ‘ä»¬æŒ‰ç…§æ ‡å‡†å·® 0.01 çš„é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–æƒé‡ï¼Œå¹¶å°†åç½®é¡¹è®¾ä¸º 0 ã€‚
def get_lstm_params(vocab_size, num_hiddens, device): num_inputs = num_outputs = vocab_size def normal(shape): return torch.randn(size=shape, device=device)*0.01 def three(): return (normal((num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)), torch.zeros(num_hiddens, device=device)) W_xi, W_hi, b_i = three() # è¾“å…¥é—¨å‚æ•° W_xf, W_hf, b_f = three() # é—å¿˜é—¨å‚æ•° W_xo, W_ho, b_o = three() # è¾“å‡ºé—¨å‚æ•° W_xc, W_hc, b_c = three() # å€™é€‰è®°å¿†å…ƒå‚æ•° # è¾“å‡ºå±‚å‚æ•° W_hq = normal((num_hiddens, num_outputs)) b_q = torch." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/be1963b30181aad1f8b75ab86fdc25d9/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-18T14:57:05+08:00" />
<meta property="article:modified_time" content="2023-01-18T14:57:05+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="èœé¸Ÿç¨‹åºå‘˜åšå®¢" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">èœé¸Ÿç¨‹åºå‘˜åšå®¢</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">82.é•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼ˆLSTMï¼‰ä»¥åŠä»£ç å®ç°</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="1__0"></a>1. é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ</h2> 
<ul><li>å¿˜è®°é—¨ï¼šå°†å€¼æœ0å‡å°‘</li><li>è¾“å…¥é—¨ï¼šå†³å®šä¸æ˜¯å¿½ç•¥æ‰è¾“å…¥æ•°æ®</li><li>è¾“å‡ºé—¨ï¼šå†³å®šæ˜¯ä¸æ˜¯ä½¿ç”¨éšçŠ¶æ€</li></ul> 
<h2><a id="2__7"></a>2. é—¨</h2> 
<p><img src="https://images2.imgbox.com/bc/a5/Zui5KsK7_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="3__10"></a>3. å€™é€‰è®°å¿†å•å…ƒ</h2> 
<p><img src="https://images2.imgbox.com/ad/d6/pINTRBDt_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="4__15"></a>4. è®°å¿†å•å…ƒ</h2> 
<p><img src="https://images2.imgbox.com/9a/a4/MvNVCtVN_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="5__19"></a>5. éšçŠ¶æ€</h2> 
<p><img src="https://images2.imgbox.com/cb/c9/hJfqYEGJ_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="6__23"></a>6. æ€»ç»“</h2> 
<p><img src="https://images2.imgbox.com/f8/54/1xj9pvhY_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="7__26"></a>7. ä»é›¶å®ç°çš„ä»£ç </h2> 
<p>æˆ‘ä»¬é¦–å…ˆåŠ è½½æ—¶å…‰æœºå™¨æ•°æ®é›†ã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> d2l <span class="token keyword">import</span> torch <span class="token keyword">as</span> d2l

batch_size<span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">35</span>
train_iter<span class="token punctuation">,</span> vocab <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_time_machine<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_steps<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="71__39"></a>7.1 åˆå§‹åŒ–æ¨¡å‹å‚æ•°</h2> 
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰å’Œåˆå§‹åŒ–æ¨¡å‹å‚æ•°ã€‚ å¦‚å‰æ‰€è¿°ï¼Œè¶…å‚æ•°<code>num_hiddens</code>å®šä¹‰éšè—å•å…ƒçš„æ•°é‡ã€‚ æˆ‘ä»¬æŒ‰ç…§æ ‡å‡†å·® 0.01 çš„é«˜æ–¯åˆ†å¸ƒåˆå§‹åŒ–æƒé‡ï¼Œå¹¶å°†åç½®é¡¹è®¾ä¸º 0 ã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_lstm_params</span><span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_inputs <span class="token operator">=</span> num_outputs <span class="token operator">=</span> vocab_size

    <span class="token keyword">def</span> <span class="token function">normal</span><span class="token punctuation">(</span>shape<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span>shape<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span>

    <span class="token keyword">def</span> <span class="token function">three</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span>normal<span class="token punctuation">(</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                normal<span class="token punctuation">(</span><span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>

    W_xi<span class="token punctuation">,</span> W_hi<span class="token punctuation">,</span> b_i <span class="token operator">=</span> three<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># è¾“å…¥é—¨å‚æ•°</span>
    W_xf<span class="token punctuation">,</span> W_hf<span class="token punctuation">,</span> b_f <span class="token operator">=</span> three<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># é—å¿˜é—¨å‚æ•°</span>
    W_xo<span class="token punctuation">,</span> W_ho<span class="token punctuation">,</span> b_o <span class="token operator">=</span> three<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># è¾“å‡ºé—¨å‚æ•°</span>
    W_xc<span class="token punctuation">,</span> W_hc<span class="token punctuation">,</span> b_c <span class="token operator">=</span> three<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># å€™é€‰è®°å¿†å…ƒå‚æ•°</span>
    <span class="token comment"># è¾“å‡ºå±‚å‚æ•°</span>
    W_hq <span class="token operator">=</span> normal<span class="token punctuation">(</span><span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span> num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    b_q <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span>
    <span class="token comment"># é™„åŠ æ¢¯åº¦</span>
    params <span class="token operator">=</span> <span class="token punctuation">[</span>W_xi<span class="token punctuation">,</span> W_hi<span class="token punctuation">,</span> b_i<span class="token punctuation">,</span> W_xf<span class="token punctuation">,</span> W_hf<span class="token punctuation">,</span> b_f<span class="token punctuation">,</span> W_xo<span class="token punctuation">,</span> W_ho<span class="token punctuation">,</span> b_o<span class="token punctuation">,</span> W_xc<span class="token punctuation">,</span> W_hc<span class="token punctuation">,</span>
              b_c<span class="token punctuation">,</span> W_hq<span class="token punctuation">,</span> b_q<span class="token punctuation">]</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
        param<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> params
</code></pre> 
<h2><a id="72__70"></a>7.2 å®šä¹‰æ¨¡å‹</h2> 
<p>åœ¨<strong>åˆå§‹åŒ–å‡½æ•°</strong>ä¸­ï¼Œ é•¿çŸ­æœŸè®°å¿†ç½‘ç»œçš„éšçŠ¶æ€éœ€è¦è¿”å›ä¸€ä¸ªé¢å¤–çš„<strong>è®°å¿†å…ƒ</strong>ï¼Œ å•å…ƒçš„å€¼ä¸º0ï¼Œå½¢çŠ¶ä¸ºï¼ˆæ‰¹é‡å¤§å°ï¼Œéšè—å•å…ƒæ•°ï¼‰ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°ä»¥ä¸‹çš„çŠ¶æ€åˆå§‹åŒ–ã€‚</p> 
<pre><code class="prism language-python"><span class="token comment"># Cå’ŒHéƒ½è¦åˆå§‹åŒ–</span>
<span class="token keyword">def</span> <span class="token function">init_lstm_state</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span>
            torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span><span class="token punctuation">,</span> device<span class="token operator">=</span>device<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>å®é™…æ¨¡å‹çš„å®šä¹‰ä¸æˆ‘ä»¬å‰é¢è®¨è®ºçš„ä¸€æ ·ï¼š <strong>æä¾›ä¸‰ä¸ªé—¨å’Œä¸€ä¸ªé¢å¤–çš„è®°å¿†å…ƒ</strong>ã€‚ è¯·æ³¨æ„ï¼Œ<code>åªæœ‰éšçŠ¶æ€æ‰ä¼šä¼ é€’åˆ°è¾“å‡ºå±‚ï¼Œ è€Œè®°å¿†å…ƒ ğ‚ğ‘¡ ä¸ç›´æ¥å‚ä¸è¾“å‡ºè®¡ç®—</code>ã€‚</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">lstm</span><span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> state<span class="token punctuation">,</span> params<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token punctuation">[</span>W_xi<span class="token punctuation">,</span> W_hi<span class="token punctuation">,</span> b_i<span class="token punctuation">,</span> W_xf<span class="token punctuation">,</span> W_hf<span class="token punctuation">,</span> b_f<span class="token punctuation">,</span> W_xo<span class="token punctuation">,</span> W_ho<span class="token punctuation">,</span> b_o<span class="token punctuation">,</span> W_xc<span class="token punctuation">,</span> W_hc<span class="token punctuation">,</span> b_c<span class="token punctuation">,</span>
     W_hq<span class="token punctuation">,</span> b_q<span class="token punctuation">]</span> <span class="token operator">=</span> params
    <span class="token punctuation">(</span>H<span class="token punctuation">,</span> C<span class="token punctuation">)</span> <span class="token operator">=</span> state
    outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> X <span class="token keyword">in</span> inputs<span class="token punctuation">:</span>
        I <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xi<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hi<span class="token punctuation">)</span> <span class="token operator">+</span> b_i<span class="token punctuation">)</span>
        F <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xf<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hf<span class="token punctuation">)</span> <span class="token operator">+</span> b_f<span class="token punctuation">)</span>
        O <span class="token operator">=</span> torch<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xo<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_ho<span class="token punctuation">)</span> <span class="token operator">+</span> b_o<span class="token punctuation">)</span>
        C_tilda <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">(</span>X @ W_xc<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token punctuation">(</span>H @ W_hc<span class="token punctuation">)</span> <span class="token operator">+</span> b_c<span class="token punctuation">)</span>
        C <span class="token operator">=</span> F <span class="token operator">*</span> C <span class="token operator">+</span> I <span class="token operator">*</span> C_tilda
        H <span class="token operator">=</span> O <span class="token operator">*</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>C<span class="token punctuation">)</span>
        Y <span class="token operator">=</span> <span class="token punctuation">(</span>H @ W_hq<span class="token punctuation">)</span> <span class="token operator">+</span> b_q
        outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>H<span class="token punctuation">,</span> C<span class="token punctuation">)</span>
</code></pre> 
<h2><a id="73__101"></a>7.3 è®­ç»ƒå’Œé¢„æµ‹</h2> 
<p>è®©æˆ‘ä»¬é€šè¿‡å®ä¾‹åŒ–rnn_scratchä¸­ å¼•å…¥çš„<code>RNNModelScratchç±»</code>æ¥è®­ç»ƒä¸€ä¸ªé•¿çŸ­æœŸè®°å¿†ç½‘ç»œï¼Œ å°±å¦‚æˆ‘ä»¬åœ¨gruä¸­æ‰€åšçš„ä¸€æ ·ã€‚</p> 
<pre><code class="prism language-python">vocab_size<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> device <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> d2l<span class="token punctuation">.</span>try_gpu<span class="token punctuation">(</span><span class="token punctuation">)</span>
num_epochs<span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">500</span><span class="token punctuation">,</span> <span class="token number">1</span>
model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModelScratch<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> num_hiddens<span class="token punctuation">,</span> device<span class="token punctuation">,</span> get_lstm_params<span class="token punctuation">,</span>
                            init_lstm_state<span class="token punctuation">,</span> lstm<span class="token punctuation">)</span>
d2l<span class="token punctuation">.</span>train_ch8<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
</code></pre> 
<p>è¿è¡Œç»“æœï¼š</p> 
<p><img src="https://images2.imgbox.com/2b/f4/BDTidF0I_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<h2><a id="8__119"></a>8. ç®€æ´å®ç°</h2> 
<p>ä½¿ç”¨é«˜çº§APIï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å®ä¾‹åŒ–<code>LSTMæ¨¡å‹</code>ã€‚ é«˜çº§APIå°è£…äº†å‰æ–‡ä»‹ç»çš„æ‰€æœ‰é…ç½®ç»†èŠ‚ã€‚ è¿™æ®µä»£ç çš„è¿è¡Œé€Ÿåº¦è¦å¿«å¾—å¤šï¼Œ å› ä¸ºå®ƒä½¿ç”¨çš„æ˜¯ç¼–è¯‘å¥½çš„è¿ç®—ç¬¦è€Œä¸æ˜¯Pythonæ¥å¤„ç†ä¹‹å‰é˜è¿°çš„è®¸å¤šç»†èŠ‚ã€‚</p> 
<pre><code class="prism language-python">num_inputs <span class="token operator">=</span> vocab_size
lstm_layer <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span> num_hiddens<span class="token punctuation">)</span>
model <span class="token operator">=</span> d2l<span class="token punctuation">.</span>RNNModel<span class="token punctuation">(</span>lstm_layer<span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
d2l<span class="token punctuation">.</span>train_ch8<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_iter<span class="token punctuation">,</span> vocab<span class="token punctuation">,</span> lr<span class="token punctuation">,</span> num_epochs<span class="token punctuation">,</span> device<span class="token punctuation">)</span>
</code></pre> 
<p>è¿è¡Œç»“æœï¼š</p> 
<p><img src="https://images2.imgbox.com/02/17/zYlHhbhY_o.png" alt="åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°"></p> 
<p>å®é™…æƒ…å†µä¸‹ï¼ŒLSTMå’ŒGRUç”¨å“ªä¸ªéƒ½å¯ä»¥ï¼Œæ€§èƒ½å·®ä¸å¤šã€‚</p> 
<blockquote> 
 <p>é•¿çŸ­æœŸè®°å¿†ç½‘ç»œæ˜¯å…¸å‹çš„å…·æœ‰é‡è¦çŠ¶æ€æ§åˆ¶çš„<strong>éšå˜é‡è‡ªå›å½’æ¨¡å‹</strong>ã€‚ å¤šå¹´æ¥å·²ç»æå‡ºäº†å…¶è®¸å¤šå˜ä½“ï¼Œä¾‹å¦‚ï¼Œå¤šå±‚ã€æ®‹å·®è¿æ¥ã€ä¸åŒç±»å‹çš„æ­£åˆ™åŒ–ã€‚ ç„¶è€Œï¼Œç”±äºåºåˆ—çš„<code>é•¿è·ç¦»ä¾èµ–æ€§</code>ï¼Œè®­ç»ƒé•¿çŸ­æœŸè®°å¿†ç½‘ç»œ å’Œå…¶ä»–åºåˆ—æ¨¡å‹ï¼ˆä¾‹å¦‚é—¨æ§å¾ªç¯å•å…ƒï¼‰çš„æˆæœ¬æ˜¯ç›¸å½“é«˜çš„ã€‚ åœ¨åé¢çš„å†…å®¹ä¸­ï¼Œæˆ‘ä»¬å°†è®²è¿°æ›´é«˜çº§çš„æ›¿ä»£æ¨¡å‹ï¼Œå¦‚<strong>Transformer</strong>ã€‚</p> 
</blockquote> 
<h2><a id="9_QA_144"></a>9. Q&amp;A</h2>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1521d200c0420e20f5460d4b6f5bbab9/" rel="prev">
			<span class="pager__subtitle">Â«&thinsp;Previous</span>
			<p class="pager__title">super-jacocoç¯å¢ƒéƒ¨ç½²å’Œä½¿ç”¨--æ”¯æŒç¯å¢ƒå…¨é‡</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/70100fdcb118470cd1fb74674a2202dc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;Â»</span>
			<p class="pager__title">ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒåŠéªŒè¯å¥—è·¯</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 èœé¸Ÿç¨‹åºå‘˜åšå®¢.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>