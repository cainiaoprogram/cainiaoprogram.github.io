<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Object Detection(目标检测神文) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Object Detection(目标检测神文)" />
<meta property="og:description" content="目标检测神文，非常全而且持续在更新。转发自：https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html，如有侵权联系删除。
更新时间：
20190226 暂时停更
不再更新，最新检测文章请移步：https://blog.csdn.net/hw5226349/article/details/88733364
我会跟进原作者博客持续更新，加入自己对目标检测领域的一些新研究及论文解读。博客根据需求直接进行关键字搜索，例如2018，可找到最新论文。
文章目录 Papers损失函数[CVPR2019] Generalized Intersection over Union: A Metric and A Loss for Bounding Box RegressionDeep Neural Networks for Object DetectionOverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks R-CNNRich feature hierarchies for accurate object detection and semantic segmentation Fast R-CNNFast R-CNNA-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection Faster R-CNNFaster R-CNN: Towards Real-Time Object Detection with Region Proposal NetworksR-CNN minus RFaster R-CNN in MXNet with distributed implementation and data parallelizationContextual Priming and Feedback for Faster R-CNNAn Implementation of Faster RCNN with Study for Region SamplingInterpretable R-CNN[AAAI2019]Object Detection based on Region Decomposition and Assembly Light-Head R-CNNLight-Head R-CNN: In Defense of Two-Stage Object DetectorCascade R-CNN: Delving into High Quality Object Detection MultiBoxScalable Object Detection using Deep Neural NetworksScalable, High-Quality Object Detection SPP-NetSpatial Pyramid Pooling in Deep Convolutional Networks for Visual RecognitionDeepID-Net: Deformable Deep Convolutional Neural Networks for Object DetectionObject Detectors Emerge in Deep Scene CNNssegDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object DetectionObject Detection Networks on Convolutional Feature MapsImproving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured PredictionDeepBox: Learning Objectness with Convolutional Networks MR-CNNObject detection via a multi-region &amp; semantic segmentation-aware CNN model YOLOYou Only Look Once: Unified, Real-Time Object Detectiondarkflow - translate darknet to tensorflow." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ebffb91d0bbb54cba2d03c5ddd8152b5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-08-21T14:25:28+08:00" />
<meta property="article:modified_time" content="2018-08-21T14:25:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Object Detection(目标检测神文)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>目标检测神文，非常全而且持续在更新。转发自：<a href="https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html" rel="nofollow">https://handong1587.github.io/deep_learning/2015/10/09/object-detection.html</a>，如有侵权联系删除。<br> 更新时间：<br> 20190226 暂时停更<br> 不再更新，最新检测文章请移步：https://blog.csdn.net/hw5226349/article/details/88733364<br> 我会跟进原作者博客持续更新，加入自己对目标检测领域的一些新研究及论文解读。博客根据需求直接进行关键字搜索，例如2018，可找到最新论文。</p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Papers_55" rel="nofollow">Papers</a></li><li><ul><li><a href="#_60" rel="nofollow">损失函数</a></li><li><ul><li><a href="#CVPR2019_Generalized_Intersection_over_Union_A_Metric_and_A_Loss_for_Bounding_Box_Regression_61" rel="nofollow">[CVPR2019] Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression</a></li><li><a href="#Deep_Neural_Networks_for_Object_Detection_66" rel="nofollow">Deep Neural Networks for Object Detection</a></li><li><a href="#OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks_69" rel="nofollow">OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</a></li></ul> 
   </li><li><a href="#RCNN_76" rel="nofollow">R-CNN</a></li><li><ul><li><a href="#Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation_77" rel="nofollow">Rich feature hierarchies for accurate object detection and semantic segmentation</a></li></ul> 
   </li><li><a href="#Fast_RCNN_91" rel="nofollow">Fast R-CNN</a></li><li><ul><li><a href="#Fast_RCNN_92" rel="nofollow">Fast R-CNN</a></li><li><a href="#AFastRCNN_Hard_Positive_Generation_via_Adversary_for_Object_Detection_105" rel="nofollow">A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</a></li></ul> 
   </li><li><a href="#Faster_RCNN_112" rel="nofollow">Faster R-CNN</a></li><li><ul><li><a href="#Faster_RCNN_Towards_RealTime_Object_Detection_with_Region_Proposal_Networks_113" rel="nofollow">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a></li><li><a href="#RCNN_minus_R_132" rel="nofollow">R-CNN minus R</a></li><li><a href="#Faster_RCNN_in_MXNet_with_distributed_implementation_and_data_parallelization_137" rel="nofollow">Faster R-CNN in MXNet with distributed implementation and data parallelization</a></li><li><a href="#Contextual_Priming_and_Feedback_for_Faster_RCNN_141" rel="nofollow">Contextual Priming and Feedback for Faster R-CNN</a></li><li><a href="#An_Implementation_of_Faster_RCNN_with_Study_for_Region_Sampling_147" rel="nofollow">An Implementation of Faster RCNN with Study for Region Sampling</a></li><li><a href="#Interpretable_RCNN_153" rel="nofollow">Interpretable R-CNN</a></li><li><a href="#AAAI2019Object_Detection_based_on_Region_Decomposition_and_Assembly_159" rel="nofollow">[AAAI2019]Object Detection based on Region Decomposition and Assembly</a></li></ul> 
   </li><li><a href="#LightHead_RCNN_167" rel="nofollow">Light-Head R-CNN</a></li><li><ul><li><a href="#LightHead_RCNN_In_Defense_of_TwoStage_Object_Detector_168" rel="nofollow">Light-Head R-CNN: In Defense of Two-Stage Object Detector</a></li><li><a href="#Cascade_RCNN_Delving_into_High_Quality_Object_Detection_176" rel="nofollow">Cascade R-CNN: Delving into High Quality Object Detection</a></li></ul> 
   </li><li><a href="#MultiBox_184" rel="nofollow">MultiBox</a></li><li><ul><li><a href="#Scalable_Object_Detection_using_Deep_Neural_Networks_185" rel="nofollow">Scalable Object Detection using Deep Neural Networks</a></li><li><a href="#Scalable_HighQuality_Object_Detection_192" rel="nofollow">Scalable, High-Quality Object Detection</a></li></ul> 
   </li><li><a href="#SPPNet_200" rel="nofollow">SPP-Net</a></li><li><ul><li><a href="#Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition_201" rel="nofollow">Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</a></li><li><a href="#DeepIDNet_Deformable_Deep_Convolutional_Neural_Networks_for_Object_Detection_208" rel="nofollow">DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection</a></li><li><a href="#Object_Detectors_Emerge_in_Deep_Scene_CNNs_215" rel="nofollow">Object Detectors Emerge in Deep Scene CNNs</a></li><li><a href="#segDeepM_Exploiting_Segmentation_and_Context_in_Deep_Neural_Networks_for_Object_Detection_223" rel="nofollow">segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection</a></li><li><a href="#Object_Detection_Networks_on_Convolutional_Feature_Maps_230" rel="nofollow">Object Detection Networks on Convolutional Feature Maps</a></li><li><a href="#Improving_Object_Detection_with_Deep_Convolutional_Networks_via_Bayesian_Optimization_and_Structured_Prediction_236" rel="nofollow">Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction</a></li><li><a href="#DeepBox_Learning_Objectness_with_Convolutional_Networks_242" rel="nofollow">DeepBox: Learning Objectness with Convolutional Networks</a></li></ul> 
   </li><li><a href="#MRCNN_250" rel="nofollow">MR-CNN</a></li><li><ul><li><a href="#Object_detection_via_a_multiregion__semantic_segmentationaware_CNN_model_251" rel="nofollow">Object detection via a multi-region &amp; semantic segmentation-aware CNN model</a></li></ul> 
   </li><li><a href="#YOLO_261" rel="nofollow">YOLO</a></li><li><ul><li><a href="#You_Only_Look_Once_Unified_RealTime_Object_Detection_262" rel="nofollow">You Only Look Once: Unified, Real-Time Object Detection</a></li><li><a href="#darkflow__translate_darknet_to_tensorflow_Load_trained_weights_retrainfinetune_them_using_tensorflow_export_constant_graph_def_to_C_279" rel="nofollow">darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++</a></li><li><a href="#Start_Training_YOLO_with_Our_Own_Data_284" rel="nofollow">Start Training YOLO with Our Own Data</a></li><li><a href="#YOLO_Core_ML_versus_MPSNNGraph_290" rel="nofollow">YOLO: Core ML versus MPSNNGraph</a></li><li><a href="#TensorFlow_YOLO_object_detection_on_Android_296" rel="nofollow">TensorFlow YOLO object detection on Android</a></li><li><a href="#Computer_Vision_in_iOS__Object_Detection_301" rel="nofollow">Computer Vision in iOS – Object Detection</a></li></ul> 
   </li><li><a href="#YOLOv2_307" rel="nofollow">YOLOv2</a></li><li><ul><li><a href="#YOLO9000_Better_Faster_Stronger_308" rel="nofollow">YOLO9000: Better, Faster, Stronger</a></li><li><a href="#darknet_scripts_320" rel="nofollow">darknet_scripts</a></li><li><a href="#Yolo_mark_GUI_for_marking_bounded_boxes_of_objects_in_images_for_training_Yolo_v2_325" rel="nofollow">Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2</a></li><li><a href="#LightNet_Bringing_pjreddies_DarkNet_out_of_the_shadows_329" rel="nofollow">LightNet: Bringing pjreddie’s DarkNet out of the shadows</a></li><li><a href="#YOLO_v2_Bounding_Box_Tool_333" rel="nofollow">YOLO v2 Bounding Box Tool</a></li></ul> 
   </li><li><a href="#YOLOv3_339" rel="nofollow">YOLOv3</a></li><li><ul><li><a href="#YOLOv3_An_Incremental_Improvement_340" rel="nofollow">YOLOv3: An Incremental Improvement</a></li><li><a href="#YOLOLITE_A_RealTime_Object_Detection_Algorithm_Optimized_for_NonGPU_Computers_347" rel="nofollow">YOLO-LITE: A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers</a></li><li><a href="#AttentionNet_Aggregating_Weak_Directions_for_Accurate_Object_Detection_352" rel="nofollow">AttentionNet: Aggregating Weak Directions for Accurate Object Detection</a></li></ul> 
   </li><li><a href="#DenseBox_362" rel="nofollow">DenseBox</a></li><li><ul><li><a href="#DenseBox_Unifying_Landmark_Localization_with_End_to_End_Object_Detection_363" rel="nofollow">DenseBox: Unifying Landmark Localization with End to End Object Detection</a></li></ul> 
   </li><li><a href="#SSD_370" rel="nofollow">SSD</a></li><li><ul><li><a href="#SSD_Single_Shot_MultiBox_Detector_371" rel="nofollow">SSD: Single Shot MultiBox Detector</a></li></ul> 
   </li><li><a href="#DSSD_389" rel="nofollow">DSSD</a></li><li><ul><li><a href="#DSSD__Deconvolutional_Single_Shot_Detector_390" rel="nofollow">DSSD : Deconvolutional Single Shot Detector</a></li><li><a href="#Enhancement_of_SSD_by_concatenating_feature_maps_for_object_detection_398" rel="nofollow">Enhancement of SSD by concatenating feature maps for object detection</a></li><li><a href="#Contextaware_SingleShot_Detector_403" rel="nofollow">Context-aware Single-Shot Detector</a></li><li><a href="#FeatureFused_SSD_Fast_Detection_for_Small_Objects_408" rel="nofollow">Feature-Fused SSD: Fast Detection for Small Objects</a></li></ul> 
   </li><li><a href="#FSSD_413" rel="nofollow">FSSD</a></li><li><ul><li><a href="#FSSD_Feature_Fusion_Single_Shot_Multibox_Detector_414" rel="nofollow">FSSD: Feature Fusion Single Shot Multibox Detector</a></li><li><a href="#Weaving_Multiscale_Context_for_Single_Shot_Detector_418" rel="nofollow">Weaving Multi-scale Context for Single Shot Detector</a></li></ul> 
   </li><li><a href="#ESSD_425" rel="nofollow">ESSD</a></li><li><ul><li><a href="#Extend_the_shallow_part_of_Single_Shot_MultiBox_Detector_via_Convolutional_Neural_Network_426" rel="nofollow">Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network</a></li><li><a href="#Tiny_SSD_A_Tiny_Singleshot_Detection_Deep_Convolutional_Neural_Network_for_Realtime_Embedded_Object_Detection_430" rel="nofollow">Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection</a></li><li><a href="#MDSSD_Multiscale_Deconvolutional_Single_Shot_Detector_for_small_objects_434" rel="nofollow">MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects</a></li></ul> 
   </li><li><a href="#InsideOutside_Net_ION_440" rel="nofollow">Inside-Outside Net (ION)</a></li><li><ul><li><a href="#InsideOutside_Net_Detecting_Objects_in_Context_with_Skip_Pooling_and_Recurrent_Neural_Networks_441" rel="nofollow">Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks</a></li><li><a href="#Adaptive_Object_Detection_Using_Adjacency_and_Zoom_Prediction_448" rel="nofollow">Adaptive Object Detection Using Adjacency and Zoom Prediction</a></li><li><a href="#GCNN_an_Iterative_Grid_Based_Object_Detector_455" rel="nofollow">G-CNN: an Iterative Grid Based Object Detector</a></li></ul> 
   </li><li><a href="#Factors_in_Finetuning_Deep_Model_for_object_detection_460" rel="nofollow">Factors in Finetuning Deep Model for object detection</a></li><li><ul><li><a href="#Factors_in_Finetuning_Deep_Model_for_Object_Detection_with_Longtail_Distribution_461" rel="nofollow">Factors in Finetuning Deep Model for Object Detection with Long-tail Distribution</a></li><li><a href="#We_dont_need_no_boundingboxes_Training_object_class_detectors_using_only_human_verification_467" rel="nofollow">We don’t need no bounding-boxes: Training object class detectors using only human verification</a></li><li><a href="#HyperNet_Towards_Accurate_Region_Proposal_Generation_and_Joint_Object_Detection_472" rel="nofollow">HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</a></li><li><a href="#A_MultiPath_Network_for_Object_Detection_477" rel="nofollow">A MultiPath Network for Object Detection</a></li></ul> 
   </li><li><a href="#CRAFT_484" rel="nofollow">CRAFT</a></li><li><ul><li><a href="#CRAFT_Objects_from_Images_485" rel="nofollow">CRAFT Objects from Images</a></li></ul> 
   </li><li><a href="#OHEM_494" rel="nofollow">OHEM</a></li><li><ul><li><a href="#Training_Regionbased_Object_Detectors_with_Online_Hard_Example_Mining_495" rel="nofollow">Training Region-based Object Detectors with Online Hard Example Mining</a></li><li><a href="#SOHEM_Stratified_Online_Hard_Example_Mining_for_Object_Detection_503" rel="nofollow">S-OHEM: Stratified Online Hard Example Mining for Object Detection</a></li><li><a href="#Exploit_All_the_Layers_Fast_and_Accurate_CNN_Object_Detector_with_Scale_Dependent_Pooling_and_Cascaded_Rejection_Classifiers_507" rel="nofollow">Exploit All the Layers: Fast and Accurate CNN Object Detector with Scale Dependent Pooling and Cascaded Rejection Classifiers</a></li></ul> 
   </li><li><a href="#RFCN_514" rel="nofollow">R-FCN</a></li><li><ul><li><a href="#RFCN_Object_Detection_via_Regionbased_Fully_Convolutional_Networks_515" rel="nofollow">R-FCN: Object Detection via Region-based Fully Convolutional Networks</a></li><li><a href="#RFCN3000_at_30fps_Decoupling_Detection_and_Classification_524" rel="nofollow">R-FCN-3000 at 30fps: Decoupling Detection and Classification</a></li><li><a href="#Recycle_deep_features_for_better_object_detection_528" rel="nofollow">Recycle deep features for better object detection</a></li></ul> 
   </li><li><a href="#MSCNN_533" rel="nofollow">MS-CNN</a></li><li><ul><li><a href="#A_Unified_Multiscale_Deep_Convolutional_Neural_Network_for_Fast_Object_Detection_534" rel="nofollow">A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection</a></li><li><a href="#Multistage_Object_Detection_with_Group_Recursive_Learning_542" rel="nofollow">Multi-stage Object Detection with Group Recursive Learning</a></li><li><a href="#Subcategoryaware_Convolutional_Neural_Networks_for_Object_Proposals_and_Detection_547" rel="nofollow">Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection</a></li></ul> 
   </li><li><a href="#PVANET_554" rel="nofollow">PVANET</a></li><li><ul><li><a href="#PVANet_Lightweight_Deep_Neural_Networks_for_Realtime_Object_Detection_555" rel="nofollow">PVANet: Lightweight Deep Neural Networks for Real-time Object Detection</a></li></ul> 
   </li><li><a href="#GBDNet_563" rel="nofollow">GBD-Net</a></li><li><ul><li><a href="#Gated_Bidirectional_CNN_for_Object_Detection_564" rel="nofollow">Gated Bi-directional CNN for Object Detection</a></li><li><a href="#Crafting_GBDNet_for_Object_Detection_570" rel="nofollow">Crafting GBD-Net for Object Detection</a></li><li><a href="#StuffNet_Using_Stuff_to_Improve_Object_Detection_578" rel="nofollow">StuffNet: Using ‘Stuff’ to Improve Object Detection</a></li><li><a href="#Generalized_Haar_Filter_based_Deep_Networks_for_RealTime_Object_Detection_in_Traffic_Scene_583" rel="nofollow">Generalized Haar Filter based Deep Networks for Real-Time Object Detection in Traffic Scene</a></li><li><a href="#Hierarchical_Object_Detection_with_Deep_Reinforcement_Learning_588" rel="nofollow">Hierarchical Object Detection with Deep Reinforcement Learning</a></li><li><a href="#Learning_to_detect_and_localize_many_objects_from_few_examples_598" rel="nofollow">Learning to detect and localize many objects from few examples</a></li><li><a href="#Speedaccuracy_tradeoffs_for_modern_convolutional_object_detectors_603" rel="nofollow">Speed/accuracy trade-offs for modern convolutional object detectors</a></li><li><a href="#SqueezeDet_Unified_Small_Low_Power_Fully_Convolutional_Neural_Networks_for_RealTime_Object_Detection_for_Autonomous_Driving_609" rel="nofollow">SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving</a></li></ul> 
   </li><li><a href="#Feature_Pyramid_Network_FPN_616" rel="nofollow">Feature Pyramid Network (FPN)</a></li><li><ul><li><a href="#Feature_Pyramid_Networks_for_Object_Detection_617" rel="nofollow">Feature Pyramid Networks for Object Detection</a></li><li><a href="#ActionDriven_Object_Detection_with_TopDown_Visual_Attentions_623" rel="nofollow">Action-Driven Object Detection with Top-Down Visual Attentions</a></li><li><a href="#Beyond_Skip_Connections_TopDown_Modulation_for_Object_Detection_627" rel="nofollow">Beyond Skip Connections: Top-Down Modulation for Object Detection</a></li><li><a href="#WideResidualInception_Networks_for_Realtime_Object_Detection_632" rel="nofollow">Wide-Residual-Inception Networks for Real-time Object Detection</a></li><li><a href="#Attentional_Network_for_Visual_Object_Detection_637" rel="nofollow">Attentional Network for Visual Object Detection</a></li><li><a href="#Learning_Chained_Deep_Features_and_Classifiers_for_Cascade_in_Object_Detection_642" rel="nofollow">Learning Chained Deep Features and Classifiers for Cascade in Object Detection</a></li><li><a href="#DeNet_Scalable_Realtime_Object_Detection_with_Directed_Sparse_Sampling_649" rel="nofollow">DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling</a></li><li><a href="#Discriminative_Bimodal_Networks_for_Visual_Localization_and_Detection_with_Natural_Language_Queries_655" rel="nofollow">Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries</a></li><li><a href="#Spatial_Memory_for_Context_Reasoning_in_Object_Detection_661" rel="nofollow">Spatial Memory for Context Reasoning in Object Detection</a></li><li><a href="#Accurate_Single_Stage_Detector_Using_Recurrent_Rolling_Convolution_666" rel="nofollow">Accurate Single Stage Detector Using Recurrent Rolling Convolution</a></li><li><a href="#Deep_Occlusion_Reasoning_for_MultiCamera_MultiTarget_Detection_674" rel="nofollow">Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection</a></li><li><a href="#LCDet_LowComplexity_FullyConvolutional_Neural_Networks_for_Object_Detection_in_Embedded_Systems_678" rel="nofollow">LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems</a></li><li><a href="#Point_Linking_Network_for_Object_Detection_684" rel="nofollow">Point Linking Network for Object Detection</a></li><li><a href="#Perceptual_Generative_Adversarial_Networks_for_Small_Object_Detection_690" rel="nofollow">Perceptual Generative Adversarial Networks for Small Object Detection</a></li><li><a href="#Fewshot_Object_Detection_694" rel="nofollow">Few-shot Object Detection</a></li><li><a href="#YesNet_An_effective_Detector_Based_on_Global_Information_698" rel="nofollow">Yes-Net: An effective Detector Based on Global Information</a></li><li><a href="#SMC_Faster_RCNN_Toward_a_scenespecialized_multiobject_detector_702" rel="nofollow">SMC Faster R-CNN: Toward a scene-specialized multi-object detector</a></li><li><a href="#Towards_lightweight_convolutional_neural_networks_for_object_detection_706" rel="nofollow">Towards lightweight convolutional neural networks for object detection</a></li><li><a href="#RON_Reverse_Connection_with_Objectness_Prior_Networks_for_Object_Detection_710" rel="nofollow">RON: Reverse Connection with Objectness Prior Networks for Object Detection</a></li><li><a href="#Mimicking_Very_Efficient_Network_for_Object_Detection_717" rel="nofollow">Mimicking Very Efficient Network for Object Detection</a></li><li><a href="#Residual_Features_and_Unified_Prediction_Network_for_Single_Stage_Detection_722" rel="nofollow">Residual Features and Unified Prediction Network for Single Stage Detection</a></li><li><a href="#Deformable_Partbased_Fully_Convolutional_Network_for_Object_Detection_726" rel="nofollow">Deformable Part-based Fully Convolutional Network for Object Detection</a></li><li><a href="#Adaptive_Feeding_Achieving_Fast_and_Accurate_Detections_by_Adaptively_Combining_Object_Detectors_731" rel="nofollow">Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</a></li><li><a href="#Recurrent_Scale_Approximation_for_Object_Detection_in_CNN_736" rel="nofollow">Recurrent Scale Approximation for Object Detection in CNN</a></li></ul> 
   </li><li><a href="#DSOD_744" rel="nofollow">DSOD</a></li><li><ul><li><a href="#DSOD_Learning_Deeply_Supervised_Object_Detectors_from_Scratch_745" rel="nofollow">DSOD: Learning Deeply Supervised Object Detectors from Scratch</a></li><li><a href="#Object_Detection_from_Scratch_with_Deep_Supervision_751" rel="nofollow">Object Detection from Scratch with Deep Supervision</a></li><li><a href="#Focal_Loss_for_Dense_Object_Detection_756" rel="nofollow">Focal Loss for Dense Object Detection</a></li><li><a href="#Focal_Loss_Dense_Detector_for_Vehicle_Surveillance_762" rel="nofollow">Focal Loss Dense Detector for Vehicle Surveillance</a></li><li><a href="#CoupleNet_Coupling_Global_Structure_with_Local_Parts_for_Object_Detection_766" rel="nofollow">CoupleNet: Coupling Global Structure with Local Parts for Object Detection</a></li><li><a href="#Incremental_Learning_of_Object_Detectors_without_Catastrophic_Forgetting_771" rel="nofollow">Incremental Learning of Object Detectors without Catastrophic Forgetting</a></li><li><a href="#Zoom_OutandIn_Network_with_Map_Attention_Decision_for_Region_Proposal_and_Object_Detection_776" rel="nofollow">Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection</a></li><li><a href="#StairNet_TopDown_Semantic_Aggregation_for_Accurate_One_Shot_Detection_780" rel="nofollow">StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection</a></li><li><a href="#Dynamic_Zoomin_Network_for_Fast_Object_Detection_in_Large_Images_784" rel="nofollow">Dynamic Zoom-in Network for Fast Object Detection in Large Images</a></li><li><a href="#ZeroAnnotation_Object_Detection_with_Web_Knowledge_Transfer_788" rel="nofollow">Zero-Annotation Object Detection with Web Knowledge Transfer</a></li></ul> 
   </li><li><a href="#MegDet_796" rel="nofollow">MegDet</a></li><li><ul><li><a href="#MegDet_A_Large_MiniBatch_Object_Detector_797" rel="nofollow">MegDet: A Large Mini-Batch Object Detector</a></li><li><a href="#SingleShot_Refinement_Neural_Network_for_Object_Detection_802" rel="nofollow">Single-Shot Refinement Neural Network for Object Detection</a></li><li><a href="#Receptive_Field_Block_Net_for_Accurate_and_Fast_Object_Detection_808" rel="nofollow">Receptive Field Block Net for Accurate and Fast Object Detection</a></li><li><a href="#An_Analysis_of_Scale_Invariance_in_Object_Detection__SNIP_814" rel="nofollow">An Analysis of Scale Invariance in Object Detection - SNIP</a></li><li><a href="#Feature_Selective_Networks_for_Object_Detection_820" rel="nofollow">Feature Selective Networks for Object Detection</a></li><li><a href="#Learning_a_Rotation_Invariant_Detector_with_Rotatable_Bounding_Box_824" rel="nofollow">Learning a Rotation Invariant Detector with Rotatable Bounding Box</a></li><li><a href="#Scalable_Object_Detection_for_Stylized_Objects_829" rel="nofollow">Scalable Object Detection for Stylized Objects</a></li><li><a href="#Learning_Object_Detectors_from_Scratch_with_Gated_Recurrent_Feature_Pyramids_834" rel="nofollow">Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</a></li><li><a href="#Deep_Regionlets_for_Object_Detection_839" rel="nofollow">Deep Regionlets for Object Detection</a></li><li><a href="#Training_and_Testing_Object_Detectors_with_Virtual_Images_844" rel="nofollow">Training and Testing Object Detectors with Virtual Images</a></li><li><a href="#LargeScale_Object_Discovery_and_Detector_Adaptation_from_Unlabeled_Video_850" rel="nofollow">Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video</a></li><li><a href="#Spot_the_Difference_by_Object_Detection_856" rel="nofollow">Spot the Difference by Object Detection</a></li><li><a href="#LocalizationAware_Active_Learning_for_Object_Detection_861" rel="nofollow">Localization-Aware Active Learning for Object Detection</a></li><li><a href="#Object_Detection_with_Maskbased_Feature_Encoding_866" rel="nofollow">Object Detection with Mask-based Feature Encoding</a></li><li><a href="#LSTD_A_LowShot_Transfer_Detector_for_Object_Detection_870" rel="nofollow">LSTD: A Low-Shot Transfer Detector for Object Detection</a></li><li><a href="#Domain_Adaptive_Faster_RCNN_for_Object_Detection_in_the_Wild_875" rel="nofollow">Domain Adaptive Faster R-CNN for Object Detection in the Wild</a></li><li><a href="#Pseudo_Mask_Augmented_Object_Detection_881" rel="nofollow">Pseudo Mask Augmented Object Detection</a></li><li><a href="#Revisiting_RCNN_On_Awakening_the_Classification_Power_of_Faster_RCNN_885" rel="nofollow">Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</a></li><li><a href="#Decoupled_Classification_Refinement_Hard_False_Positive_Suppression_for_Object_Detection_891" rel="nofollow">Decoupled Classification Refinement: Hard False Positive Suppression for Object Detection</a></li><li><a href="#Learning_Region_Features_for_Object_Detection_896" rel="nofollow">Learning Region Features for Object Detection</a></li><li><a href="#SingleShot_Bidirectional_Pyramid_Networks_for_HighQuality_Object_Detection_901" rel="nofollow">Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection</a></li><li><a href="#Object_Detection_for_Comics_using_Manga109_Annotations_906" rel="nofollow">Object Detection for Comics using Manga109 Annotations</a></li><li><a href="#TaskDriven_Super_Resolution_Object_Detection_in_Lowresolution_Images_911" rel="nofollow">Task-Driven Super Resolution: Object Detection in Low-resolution Images</a></li><li><a href="#Transferring_CommonSense_Knowledge_for_Object_Detection_915" rel="nofollow">Transferring Common-Sense Knowledge for Object Detection</a></li><li><a href="#Multiscale_Locationaware_Kernel_Representation_for_Object_Detection_919" rel="nofollow">Multi-scale Location-aware Kernel Representation for Object Detection</a></li><li><a href="#Loss_Rank_Mining_A_General_Hard_Example_Mining_Method_for_Realtime_Detectors_925" rel="nofollow">Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors</a></li><li><a href="#DetNet_A_Backbone_network_for_Object_Detection_930" rel="nofollow">DetNet: A Backbone network for Object Detection</a></li><li><a href="#Robust_Physical_Adversarial_Attack_on_Faster_RCNN_Object_Detector_935" rel="nofollow">Robust Physical Adversarial Attack on Faster R-CNN Object Detector</a></li><li><a href="#AdvDetPatch_Attacking_Object_Detectors_with_Adversarial_Patches_939" rel="nofollow">AdvDetPatch: Attacking Object Detectors with Adversarial Patches</a></li><li><a href="#Attacking_Object_Detectors_via_Imperceptible_Patches_on_Background_943" rel="nofollow">Attacking Object Detectors via Imperceptible Patches on Background</a></li><li><a href="#Physical_Adversarial_Examples_for_Object_Detectors_947" rel="nofollow">Physical Adversarial Examples for Object Detectors</a></li><li><a href="#Quantization_Mimic_Towards_Very_Tiny_CNN_for_Object_Detection_952" rel="nofollow">Quantization Mimic: Towards Very Tiny CNN for Object Detection</a></li><li><a href="#Object_detection_at_200_Frames_Per_Second_956" rel="nofollow">Object detection at 200 Frames Per Second</a></li><li><a href="#Object_Detection_using_Domain_Randomization_and_Generative_Adversarial_Refinement_of_Synthetic_Images_961" rel="nofollow">Object Detection using Domain Randomization and Generative Adversarial Refinement of Synthetic Images</a></li><li><a href="#SNIPER_Efficient_MultiScale_Training_966" rel="nofollow">SNIPER: Efficient Multi-Scale Training</a></li><li><a href="#Soft_Sampling_for_Robust_Object_Detection_972" rel="nofollow">Soft Sampling for Robust Object Detection</a></li><li><a href="#MetaAnchor_Learning_to_Detect_Objects_with_Customized_Anchors_976" rel="nofollow">MetaAnchor: Learning to Detect Objects with Customized Anchors</a></li><li><a href="#Localization_Recall_Precision_LRP_A_New_Performance_Metric_for_Object_Detection_981" rel="nofollow">Localization Recall Precision (LRP): A New Performance Metric for Object Detection</a></li><li><a href="#AutoContext_RCNN_987" rel="nofollow">Auto-Context R-CNN</a></li><li><a href="#Pooling_Pyramid_Network_for_Object_Detection_992" rel="nofollow">Pooling Pyramid Network for Object Detection</a></li><li><a href="#Modeling_Visual_Context_is_Key_to_Augmenting_Object_Detection_Datasets_997" rel="nofollow">Modeling Visual Context is Key to Augmenting Object Detection Datasets</a></li><li><a href="#Dual_Refinement_Network_for_SingleShot_Object_Detection_1002" rel="nofollow">Dual Refinement Network for Single-Shot Object Detection</a></li><li><a href="#Acquisition_of_Localization_Confidence_for_Accurate_Object_Detection_1006" rel="nofollow">Acquisition of Localization Confidence for Accurate Object Detection</a></li><li><a href="#CornerNet_Detecting_Objects_as_Paired_Keypoints_1012" rel="nofollow">CornerNet: Detecting Objects as Paired Keypoints</a></li><li><a href="#Unsupervised_Hard_Example_Mining_from_Videos_for_Improved_Object_Detection_1019" rel="nofollow">Unsupervised Hard Example Mining from Videos for Improved Object Detection</a></li><li><a href="#SAN_Learning_Relationship_between_Convolutional_Features_for_MultiScale_Object_Detection_1025" rel="nofollow">SAN: Learning Relationship between Convolutional Features for Multi-Scale Object Detection</a></li><li><a href="#A_Survey_of_Modern_Object_Detection_Literature_using_Deep_Learning_1029" rel="nofollow">A Survey of Modern Object Detection Literature using Deep Learning</a></li><li><a href="#TinyDSOD_Lightweight_Object_Detection_for_ResourceRestricted_Usages_1033" rel="nofollow">Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages</a></li><li><a href="#Deep_Feature_Pyramid_Reconfiguration_for_Object_Detection_1038" rel="nofollow">Deep Feature Pyramid Reconfiguration for Object Detection</a></li><li><a href="#MDCN_MultiScale_Deep_Inception_Convolutional_Neural_Networks_for_Efficient_Object_Detection_1042" rel="nofollow">MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection</a></li><li><a href="#Recent_Advances_in_Object_Detection_in_the_Age_of_Deep_Convolutional_Neural_Networks_1046" rel="nofollow">Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks</a></li><li><a href="#Deep_Learning_for_Generic_Object_Detection_A_Survey_1049" rel="nofollow">Deep Learning for Generic Object Detection: A Survey</a></li><li><a href="#Training_ConfidenceCalibrated_Classifier_for_Detecting_OutofDistribution_Samples_1052" rel="nofollow">Training Confidence-Calibrated Classifier for Detecting Out-of-Distribution Samples</a></li><li><a href="#ScratchDetExploring_to_Train_SingleShot_Object_Detectors_from_Scratch_1056" rel="nofollow">ScratchDet:Exploring to Train Single-Shot Object Detectors from Scratch</a></li><li><a href="#Fast_and_accurate_object_detection_in_high_resolution_4K_and_8K_video_using_GPUs_1060" rel="nofollow">Fast and accurate object detection in high resolution 4K and 8K video using GPUs</a></li><li><a href="#Hybrid_Knowledge_Routed_Modules_for_Largescale_Object_Detection_1065" rel="nofollow">Hybrid Knowledge Routed Modules for Large-scale Object Detection</a></li><li><a href="#Gradient_Harmonized_Singlestage_Detector_1070" rel="nofollow">Gradient Harmonized Single-stage Detector</a></li><li><a href="#M2Det_A_SingleShot_Object_Detector_based_on_MultiLevel_Feature_Pyramid_Network_1074" rel="nofollow">M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</a></li><li><a href="#BAN_Focusing_on_Boundary_Context_for_Object_Detection_1079" rel="nofollow">BAN: Focusing on Boundary Context for Object Detection</a></li><li><a href="#Multilayer_Pruning_Framework_for_Compressing_Single_Shot_MultiBox_Detector_1082" rel="nofollow">Multi-layer Pruning Framework for Compressing Single Shot MultiBox Detector</a></li><li><a href="#R2CNN_MultiDimensional_Attention_Based_Rotation_Invariant_Detector_with_Robust_Anchor_Strategy_1086" rel="nofollow">R2CNN++: Multi-Dimensional Attention Based Rotation Invariant Detector with Robust Anchor Strategy</a></li><li><a href="#DeRPN_Taking_a_further_step_toward_more_general_object_detection_1090" rel="nofollow">DeRPN: Taking a further step toward more general object detection</a></li><li><a href="#Fast_Efficient_Object_Detection_Using_Selective_Attention_1096" rel="nofollow">Fast Efficient Object Detection Using Selective Attention</a></li><li><a href="#Sampling_Techniques_for_LargeScale_Object_Detection_from_Sparsely_Annotated_Objects_1100" rel="nofollow">Sampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects</a></li><li><a href="#Efficient_CoarsetoFine_NonLocal_Module_for_the_Detection_of_Small_Objects_1103" rel="nofollow">Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects</a></li><li><a href="#Deep_Regionlets_Blended_Representation_and_Deep_Learning_for_Generic_Object_Detection_1106" rel="nofollow">Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection</a></li><li><a href="#Grid_RCNN_1110" rel="nofollow">Grid R-CNN</a></li><li><a href="#Transferable_Adversarial_Attacks_for_Image_and_Video_Object_Detection_1114" rel="nofollow">Transferable Adversarial Attacks for Image and Video Object Detection</a></li><li><a href="#Anchor_Box_Optimization_for_Object_Detection_1117" rel="nofollow">Anchor Box Optimization for Object Detection</a></li><li><a href="#AutoFocus_Efficient_MultiScale_Inference_1121" rel="nofollow">AutoFocus: Efficient Multi-Scale Inference</a></li><li><a href="#Practical_Adversarial_Attack_Against_Object_Detector_1128" rel="nofollow">Practical Adversarial Attack Against Object Detector</a></li><li><a href="#Learning_Efficient_Detector_with_Semisupervised_Adaptive_Distillation_1131" rel="nofollow">Learning Efficient Detector with Semi-supervised Adaptive Distillation</a></li><li><a href="#ScaleAware_Trident_Networks_for_Object_Detection_1136" rel="nofollow">Scale-Aware Trident Networks for Object Detection</a></li><li><a href="#Region_Proposal_by_Guided_Anchoring_1141" rel="nofollow">Region Proposal by Guided Anchoring</a></li><li><a href="#Consistent_Optimization_for_SingleShot_Object_Detection_1145" rel="nofollow">Consistent Optimization for Single-Shot Object Detection</a></li><li><a href="#Bottomup_Object_Detection_by_Grouping_Extreme_and_Center_Points_1149" rel="nofollow">Bottom-up Object Detection by Grouping Extreme and Center Points</a></li><li><a href="#A_Singleshot_Object_Detector_with_Feature_Aggragation_and_Enhancement_1154" rel="nofollow">A Single-shot Object Detector with Feature Aggragation and Enhancement</a></li><li><a href="#Bag_of_Freebies_for_Training_Object_Detection_Neural_Networks_1157" rel="nofollow">Bag of Freebies for Training Object Detection Neural Networks</a></li></ul> 
   </li><li><a href="#NonMaximum_Suppression_NMS_1162" rel="nofollow">Non-Maximum Suppression (NMS)</a></li><li><ul><li><a href="#EndtoEnd_Integration_of_a_Convolutional_Network_Deformable_Parts_Model_and_NonMaximum_Suppression_1163" rel="nofollow">End-to-End Integration of a Convolutional Network, Deformable Parts Model and Non-Maximum Suppression</a></li><li><a href="#A_convnet_for_nonmaximum_suppression_1169" rel="nofollow">A convnet for non-maximum suppression</a></li><li><a href="#SoftNMS__Improving_Object_Detection_With_One_Line_of_Code_1174" rel="nofollow">Soft-NMS – Improving Object Detection With One Line of Code</a></li><li><a href="#Learning_nonmaximum_suppression_1181" rel="nofollow">Learning non-maximum suppression</a></li><li><a href="#Relation_Networks_for_Object_Detection_1189" rel="nofollow">Relation Networks for Object Detection</a></li><li><a href="#Learning_Pairwise_Relationship_for_Multiobject_Detection_in_Crowded_Scenes_1194" rel="nofollow">Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes</a></li><li><a href="#Daedalus_Breaking_NonMaximum_Suppression_in_Object_Detection_via_Adversarial_Examples_1198" rel="nofollow">Daedalus: Breaking Non-Maximum Suppression in Object Detection via Adversarial Examples</a></li></ul> 
   </li><li><a href="#Adversarial_Examples_1203" rel="nofollow">Adversarial Examples</a></li><li><ul><li><a href="#Adversarial_Examples_that_Fool_Detectors_1204" rel="nofollow">Adversarial Examples that Fool Detectors</a></li><li><a href="#Adversarial_Examples_Are_Not_Easily_Detected_Bypassing_Ten_Detection_Methods_1209" rel="nofollow">Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods</a></li></ul> 
   </li><li><a href="#Weakly_Supervised_Object_Detection_1216" rel="nofollow">Weakly Supervised Object Detection</a></li><li><ul><li><a href="#Track_and_Transfer_Watching_Videos_to_Simulate_Strong_Human_Supervision_for_WeaklySupervised_Object_Detection_1217" rel="nofollow">Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection</a></li><li><a href="#Weakly_supervised_object_detection_using_pseudostrong_labels_1222" rel="nofollow">Weakly supervised object detection using pseudo-strong labels</a></li><li><a href="#Saliency_Guided_EndtoEnd_Learning_for_Weakly_Supervised_Object_Detection_1226" rel="nofollow">Saliency Guided End-to-End Learning for Weakly Supervised Object Detection</a></li><li><a href="#Visual_and_Semantic_Knowledge_Transfer_for_Large_Scale_Semisupervised_Object_Detection_1231" rel="nofollow">Visual and Semantic Knowledge Transfer for Large Scale Semi-supervised Object Detection</a></li></ul> 
   </li><li><a href="#Video_Object_Detection_1237" rel="nofollow">Video Object Detection</a></li><li><ul><li><a href="#Learning_Object_Class_Detectors_from_Weakly_Annotated_Video_1238" rel="nofollow">Learning Object Class Detectors from Weakly Annotated Video</a></li><li><a href="#Analysing_domain_shift_factors_between_videos_and_images_for_object_detection_1243" rel="nofollow">Analysing domain shift factors between videos and images for object detection</a></li><li><a href="#Video_Object_Recognition_1247" rel="nofollow">Video Object Recognition</a></li><li><a href="#Deep_Learning_for_Saliency_Prediction_in_Natural_Video_1251" rel="nofollow">Deep Learning for Saliency Prediction in Natural Video</a></li><li><a href="#TCNN_Tubelets_with_Convolutional_Neural_Networks_for_Object_Detection_from_Videos_1257" rel="nofollow">T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos</a></li><li><a href="#Object_Detection_from_Video_Tubelets_with_Convolutional_Neural_Networks_1263" rel="nofollow">Object Detection from Video Tubelets with Convolutional Neural Networks</a></li><li><a href="#Object_Detection_in_Videos_with_Tubelets_and_Multicontext_Cues_1270" rel="nofollow">Object Detection in Videos with Tubelets and Multi-context Cues</a></li><li><a href="#Context_Matters_Refining_Object_Detection_in_Video_with_Recurrent_Neural_Networks_1276" rel="nofollow">Context Matters: Refining Object Detection in Video with Recurrent Neural Networks</a></li><li><a href="#CNN_Based_Object_Detection_in_Large_Video_Images_1283" rel="nofollow">CNN Based Object Detection in Large Video Images</a></li><li><a href="#Object_Detection_in_Videos_with_Tubelet_Proposal_Networks_1289" rel="nofollow">Object Detection in Videos with Tubelet Proposal Networks</a></li><li><a href="#FlowGuided_Feature_Aggregation_for_Video_Object_Detection_1293" rel="nofollow">Flow-Guided Feature Aggregation for Video Object Detection</a></li><li><a href="#Video_Object_Detection_using_Faster_RCNN_1298" rel="nofollow">Video Object Detection using Faster R-CNN</a></li><li><a href="#Improving_Context_Modeling_for_Video_Object_Detection_and_Tracking_1303" rel="nofollow">Improving Context Modeling for Video Object Detection and Tracking</a></li><li><a href="#Temporal_Dynamic_Graph_LSTM_for_Actiondriven_Video_Object_Detection_1307" rel="nofollow">Temporal Dynamic Graph LSTM for Action-driven Video Object Detection</a></li><li><a href="#Mobile_Video_Object_Detection_with_TemporallyAware_Feature_Maps_1312" rel="nofollow">Mobile Video Object Detection with Temporally-Aware Feature Maps</a></li><li><a href="#Towards_High_Performance_Video_Object_Detection_1316" rel="nofollow">Towards High Performance Video Object Detection</a></li><li><a href="#Impression_Network_for_Video_Object_Detection_1320" rel="nofollow">Impression Network for Video Object Detection</a></li><li><a href="#SpatialTemporal_Memory_Networks_for_Video_Object_Detection_1324" rel="nofollow">Spatial-Temporal Memory Networks for Video Object Detection</a></li><li><a href="#3DDETNet_a_Single_Stage_VideoBased_Vehicle_Detector_1328" rel="nofollow">3D-DETNet: a Single Stage Video-Based Vehicle Detector</a></li><li><a href="#Object_Detection_in_Videos_by_Short_and_Long_Range_Object_Linking_1332" rel="nofollow">Object Detection in Videos by Short and Long Range Object Linking</a></li><li><a href="#Object_Detection_in_Video_with_Spatiotemporal_Sampling_Networks_1336" rel="nofollow">Object Detection in Video with Spatiotemporal Sampling Networks</a></li><li><a href="#Towards_High_Performance_Video_Object_Detection_for_Mobiles_1341" rel="nofollow">Towards High Performance Video Object Detection for Mobiles</a></li><li><a href="#Optimizing_Video_Object_Detection_via_a_ScaleTime_Lattice_1346" rel="nofollow">Optimizing Video Object Detection via a Scale-Time Lattice</a></li><li><a href="#Pack_and_Detect_Fast_Object_Detection_in_Videos_Using_RegionofInterest_Packing_1353" rel="nofollow">Pack and Detect: Fast Object Detection in Videos Using Region-of-Interest Packing</a></li><li><a href="#Fast_Object_Detection_in_Compressed_Video_1356" rel="nofollow">Fast Object Detection in Compressed Video</a></li><li><a href="#TubeCNN_Modeling_temporal_evolution_of_appearance_for_object_detection_in_video_1359" rel="nofollow">Tube-CNN: Modeling temporal evolution of appearance for object detection in video</a></li><li><a href="#AdaScale_Towards_Realtime_Video_Object_Detection_Using_Adaptive_Scaling_1363" rel="nofollow">AdaScale: Towards Real-time Video Object Detection Using Adaptive Scaling</a></li></ul> 
   </li><li><a href="#Object_Detection_on_Mobile_Devices_1370" rel="nofollow">Object Detection on Mobile Devices</a></li><li><ul><li><a href="#Pelee_A_RealTime_Object_Detection_System_on_Mobile_Devices_1371" rel="nofollow">Pelee: A Real-Time Object Detection System on Mobile Devices</a></li></ul> 
   </li><li><a href="#Object_Detection_in_3D_1380" rel="nofollow">Object Detection in 3D</a></li><li><ul><li><a href="#Vote3Deep_Fast_Object_Detection_in_3D_Point_Clouds_Using_Efficient_Convolutional_Neural_Networks_1381" rel="nofollow">Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient Convolutional Neural Networks</a></li><li><a href="#ComplexYOLO_Realtime_3D_Object_Detection_on_Point_Clouds_1385" rel="nofollow">Complex-YOLO: Real-time 3D Object Detection on Point Clouds</a></li><li><a href="#Focal_Loss_in_3D_Object_Detection_1390" rel="nofollow">Focal Loss in 3D Object Detection</a></li><li><a href="#3D_Object_Detection_Using_Scale_Invariant_and_Feature_Reweighting_Networks_1394" rel="nofollow">3D Object Detection Using Scale Invariant and Feature Reweighting Networks</a></li><li><a href="#3D_Backbone_Network_for_3D_Object_Detection_1398" rel="nofollow">3D Backbone Network for 3D Object Detection</a></li></ul> 
   </li><li><a href="#Object_Detection_on_RGBD_1403" rel="nofollow">Object Detection on RGB-D</a></li><li><ul><li><a href="#Learning_Rich_Features_from_RGBD_Images_for_Object_Detection_and_Segmentation_1404" rel="nofollow">Learning Rich Features from RGB-D Images for Object Detection and Segmentation</a></li><li><a href="#Differential_Geometry_Boosts_Convolutional_Neural_Networks_for_Object_Detection_1408" rel="nofollow">Differential Geometry Boosts Convolutional Neural Networks for Object Detection</a></li><li><a href="#A_Selfsupervised_Learning_System_for_Object_Detection_using_Physics_Simulation_and_Multiview_Pose_Estimation_1413" rel="nofollow">A Self-supervised Learning System for Object Detection using Physics Simulation and Multi-view Pose Estimation</a></li></ul> 
   </li><li><a href="#ZeroShot_Object_Detection_1419" rel="nofollow">Zero-Shot Object Detection</a></li><li><ul><li><a href="#ZeroShot_Detection_1420" rel="nofollow">Zero-Shot Detection</a></li><li><a href="#ZeroShot_Object_Detection_1426" rel="nofollow">Zero-Shot Object Detection</a></li><li><a href="#ZeroShot_Object_Detection_Learning_to_Simultaneously_Recognize_and_Localize_Novel_Concepts_1430" rel="nofollow">Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts</a></li><li><a href="#ZeroShot_Object_Detection_by_Hybrid_Region_Embedding_1435" rel="nofollow">Zero-Shot Object Detection by Hybrid Region Embedding</a></li></ul> 
   </li><li><a href="#Salient_Object_Detection_1442" rel="nofollow">Salient Object Detection</a></li><li><ul><li><a href="#Best_Deep_Saliency_Detection_Models_CVPR_2016__2015_1445" rel="nofollow">Best Deep Saliency Detection Models (CVPR 2016 &amp; 2015)</a></li><li><a href="#Largescale_optimization_of_hierarchical_features_for_saliency_prediction_in_natural_images_1449" rel="nofollow">Large-scale optimization of hierarchical features for saliency prediction in natural images</a></li><li><a href="#Predicting_Eye_Fixations_using_Convolutional_Neural_Networks_1453" rel="nofollow">Predicting Eye Fixations using Convolutional Neural Networks</a></li><li><a href="#Saliency_Detection_by_MultiContext_Deep_Learning_1457" rel="nofollow">Saliency Detection by Multi-Context Deep Learning</a></li><li><a href="#DeepSaliency_MultiTask_Deep_Neural_Network_Model_for_Salient_Object_Detection_1461" rel="nofollow">DeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection</a></li><li><a href="#SuperCNN_A_Superpixelwise_Convolutional_Neural_Network_for_Salient_Object_Detection_1465" rel="nofollow">SuperCNN: A Superpixelwise Convolutional Neural Network for Salient Object Detection</a></li><li><a href="#Shallow_and_Deep_Convolutional_Networks_for_Saliency_Prediction_1469" rel="nofollow">Shallow and Deep Convolutional Networks for Saliency Prediction</a></li><li><a href="#Recurrent_Attentional_Networks_for_Saliency_Detection_1475" rel="nofollow">Recurrent Attentional Networks for Saliency Detection</a></li><li><a href="#TwoStream_Convolutional_Networks_for_Dynamic_Saliency_Prediction_1480" rel="nofollow">Two-Stream Convolutional Networks for Dynamic Saliency Prediction</a></li></ul> 
   </li><li><a href="#Unconstrained_Salient_Object_Detection_1486" rel="nofollow">Unconstrained Salient Object Detection</a></li><li><ul><li><a href="#Unconstrained_Salient_Object_Detection_via_Proposal_Subset_Optimization_1487" rel="nofollow">Unconstrained Salient Object Detection via Proposal Subset Optimization</a></li><li><a href="#DHSNet_Deep_Hierarchical_Saliency_Network_for_Salient_Object_Detection_1495" rel="nofollow">DHSNet: Deep Hierarchical Saliency Network for Salient Object Detection</a></li><li><a href="#Salient_Object_Subitizing_1499" rel="nofollow">Salient Object Subitizing</a></li><li><a href="#DeeplySupervised_Recurrent_Convolutional_Neural_Network_for_Saliency_Detection_1508" rel="nofollow">Deeply-Supervised Recurrent Convolutional Neural Network for Saliency Detection</a></li><li><a href="#Saliency_Detection_via_Combining_RegionLevel_and_PixelLevel_Predictions_with_CNNs_1513" rel="nofollow">Saliency Detection via Combining Region-Level and Pixel-Level Predictions with CNNs</a></li><li><a href="#Edge_Preserving_and_MultiScale_Contextual_Neural_Network_for_Salient_Object_Detection_1518" rel="nofollow">Edge Preserving and Multi-Scale Contextual Neural Network for Salient Object Detection</a></li><li><a href="#A_Deep_MultiLevel_Network_for_Saliency_Prediction_1522" rel="nofollow">A Deep Multi-Level Network for Saliency Prediction</a></li><li><a href="#Visual_Saliency_Detection_Based_on_Multiscale_Deep_CNN_Features_1526" rel="nofollow">Visual Saliency Detection Based on Multiscale Deep CNN Features</a></li><li><a href="#A_Deep_Spatial_Contextual_Longterm_Recurrent_Convolutional_Network_for_Saliency_Detection_1531" rel="nofollow">A Deep Spatial Contextual Long-term Recurrent Convolutional Network for Saliency Detection</a></li><li><a href="#Deeply_supervised_salient_object_detection_with_short_connections_1536" rel="nofollow">Deeply supervised salient object detection with short connections</a></li><li><a href="#Weakly_Supervised_Topdown_Salient_Object_Detection_1543" rel="nofollow">Weakly Supervised Top-down Salient Object Detection</a></li><li><a href="#SalGAN_Visual_Saliency_Prediction_with_Generative_Adversarial_Networks_1548" rel="nofollow">SalGAN: Visual Saliency Prediction with Generative Adversarial Networks</a></li><li><a href="#Visual_Saliency_Prediction_Using_a_Mixture_of_Deep_Neural_Networks_1553" rel="nofollow">Visual Saliency Prediction Using a Mixture of Deep Neural Networks</a></li><li><a href="#A_Fast_and_Compact_Salient_Score_Regression_Network_Based_on_Fully_Convolutional_Network_1557" rel="nofollow">A Fast and Compact Salient Score Regression Network Based on Fully Convolutional Network</a></li><li><a href="#Saliency_Detection_by_Forward_and_Backward_Cues_in_DeepCNNs_1561" rel="nofollow">Saliency Detection by Forward and Backward Cues in Deep-CNNs</a></li><li><a href="#Supervised_Adversarial_Networks_for_Image_Saliency_Detection_1565" rel="nofollow">Supervised Adversarial Networks for Image Saliency Detection</a></li><li><a href="#Groupwise_Deep_Cosaliency_Detection_1569" rel="nofollow">Group-wise Deep Co-saliency Detection</a></li><li><a href="#Towards_the_Success_Rate_of_One_Realtime_Unconstrained_Salient_Object_Detection_1573" rel="nofollow">Towards the Success Rate of One: Real-time Unconstrained Salient Object Detection</a></li><li><a href="#Amulet_Aggregating_Multilevel_Convolutional_Features_for_Salient_Object_Detection_1578" rel="nofollow">Amulet: Aggregating Multi-level Convolutional Features for Salient Object Detection</a></li><li><a href="#Learning_Uncertain_Convolutional_Features_for_Accurate_Saliency_Detection_1583" rel="nofollow">Learning Uncertain Convolutional Features for Accurate Saliency Detection</a></li><li><a href="#Deep_EdgeAware_Saliency_Detection_1588" rel="nofollow">Deep Edge-Aware Saliency Detection</a></li><li><a href="#Selfexplanatory_Deep_Salient_Object_Detection_1592" rel="nofollow">Self-explanatory Deep Salient Object Detection</a></li><li><a href="#PiCANet_Learning_Pixelwise_Contextual_Attention_in_ConvNets_and_Its_Application_in_Saliency_Detection_1597" rel="nofollow">PiCANet: Learning Pixel-wise Contextual Attention in ConvNets and Its Application in Saliency Detection</a></li><li><a href="#DeepFeat_A_Bottom_Up_and_Top_Down_Saliency_Model_Based_on_Deep_Features_of_Convolutional_Neural_Nets_1601" rel="nofollow">DeepFeat: A Bottom Up and Top Down Saliency Model Based on Deep Features of Convolutional Neural Nets</a></li><li><a href="#Recurrently_Aggregating_Deep_Features_for_Salient_Object_Detection_1605" rel="nofollow">Recurrently Aggregating Deep Features for Salient Object Detection</a></li><li><a href="#Deep_saliency_What_is_learnt_by_a_deep_network_about_saliency_1610" rel="nofollow">Deep saliency: What is learnt by a deep network about saliency?</a></li><li><a href="#ContrastOriented_Deep_Neural_Networks_for_Salient_Object_Detection_1615" rel="nofollow">Contrast-Oriented Deep Neural Networks for Salient Object Detection</a></li><li><a href="#Salient_Object_Detection_by_Lossless_Feature_Reflection_1620" rel="nofollow">Salient Object Detection by Lossless Feature Reflection</a></li><li><a href="#HyperFusionNet_Densely_Reflective_Fusion_for_Salient_Object_Detection_1625" rel="nofollow">HyperFusion-Net: Densely Reflective Fusion for Salient Object Detection</a></li></ul> 
   </li><li><a href="#Video_Saliency_Detection_1632" rel="nofollow">Video Saliency Detection</a></li><li><ul><li><a href="#Deep_Learning_For_Video_Saliency_Detection_1633" rel="nofollow">Deep Learning For Video Saliency Detection</a></li><li><a href="#Video_Salient_Object_Detection_Using_Spatiotemporal_Deep_Features_1637" rel="nofollow">Video Salient Object Detection Using Spatiotemporal Deep Features</a></li><li><a href="#Predicting_Video_Saliency_with_ObjecttoMotion_CNN_and_Twolayer_Convolutional_LSTM_1641" rel="nofollow">Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM</a></li></ul> 
   </li><li><a href="#Visual_Relationship_Detection_1648" rel="nofollow">Visual Relationship Detection</a></li><li><ul><li><a href="#Visual_Relationship_Detection_with_Language_Priors_1649" rel="nofollow">Visual Relationship Detection with Language Priors</a></li><li><a href="#ViPCNN_A_Visual_Phrase_Reasoning_Convolutional_Neural_Network_for_Visual_Relationship_Detection_1655" rel="nofollow">ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection</a></li><li><a href="#Visual_Translation_Embedding_Network_for_Visual_Relation_Detection_1660" rel="nofollow">Visual Translation Embedding Network for Visual Relation Detection</a></li><li><a href="#Deep_Variationstructured_Reinforcement_Learning_for_Visual_Relationship_and_Attribute_Detection_1664" rel="nofollow">Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection</a></li><li><a href="#Detecting_Visual_Relationships_with_Deep_Relational_Networks_1669" rel="nofollow">Detecting Visual Relationships with Deep Relational Networks</a></li><li><a href="#Identifying_Spatial_Relations_in_Images_using_Convolutional_Neural_Networks_1674" rel="nofollow">Identifying Spatial Relations in Images using Convolutional Neural Networks</a></li><li><a href="#PPRFCN_Weakly_Supervised_Visual_Relation_Detection_via_Parallel_Pairwise_RFCN_1678" rel="nofollow">PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise R-FCN</a></li><li><a href="#Natural_Language_Guided_Visual_Relationship_Detection_1683" rel="nofollow">Natural Language Guided Visual Relationship Detection</a></li><li><a href="#Detecting_Visual_Relationships_Using_Box_Attention_1687" rel="nofollow">Detecting Visual Relationships Using Box Attention</a></li><li><a href="#Google_AI_Open_Images__Visual_Relationship_Track_1692" rel="nofollow">Google AI Open Images - Visual Relationship Track</a></li><li><a href="#ContextDependent_Diffusion_Network_for_Visual_Relationship_Detection_1697" rel="nofollow">Context-Dependent Diffusion Network for Visual Relationship Detection</a></li><li><a href="#A_Problem_Reduction_Approach_for_Visual_Relationships_Detection_1701" rel="nofollow">A Problem Reduction Approach for Visual Relationships Detection</a></li></ul> 
   </li><li><a href="#Face_Deteciton_1707" rel="nofollow">Face Deteciton</a></li><li><ul><li><a href="#Multiview_Face_Detection_Using_Deep_Convolutional_Neural_Networks_1708" rel="nofollow">Multi-view Face Detection Using Deep Convolutional Neural Networks</a></li><li><a href="#From_Facial_Parts_Responses_to_Face_Detection_A_Deep_Learning_Approach_1714" rel="nofollow">From Facial Parts Responses to Face Detection: A Deep Learning Approach</a></li><li><a href="#Compact_Convolutional_Neural_Network_Cascade_for_Face_Detection_1723" rel="nofollow">Compact Convolutional Neural Network Cascade for Face Detection</a></li><li><a href="#Face_Detection_with_EndtoEnd_Integration_of_a_ConvNet_and_a_3D_Model_1729" rel="nofollow">Face Detection with End-to-End Integration of a ConvNet and a 3D Model</a></li><li><a href="#CMSRCNN_Contextual_MultiScale_Regionbased_CNN_for_Unconstrained_Face_Detection_1735" rel="nofollow">CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection</a></li><li><a href="#Towards_a_Deep_Learning_Framework_for_Unconstrained_Face_Detection_1740" rel="nofollow">Towards a Deep Learning Framework for Unconstrained Face Detection</a></li><li><a href="#Supervised_Transformer_Network_for_Efficient_Face_Detection_1745" rel="nofollow">Supervised Transformer Network for Efficient Face Detection</a></li><li><a href="#UnitBox_An_Advanced_Object_Detection_Network_1749" rel="nofollow">UnitBox: An Advanced Object Detection Network</a></li><li><a href="#Bootstrapping_Face_Detection_with_Hard_Negative_Examples_1755" rel="nofollow">Bootstrapping Face Detection with Hard Negative Examples</a></li><li><a href="#Grid_Loss_Detecting_Occluded_Faces_1761" rel="nofollow">Grid Loss: Detecting Occluded Faces</a></li><li><a href="#A_MultiScale_Cascade_Fully_Convolutional_Network_Face_Detector_1768" rel="nofollow">A Multi-Scale Cascade Fully Convolutional Network Face Detector</a></li></ul> 
   </li><li><a href="#MTCNN_1776" rel="nofollow">MTCNN</a></li><li><ul><li><a href="#Joint_Face_Detection_and_Alignment_using_Multitask_Cascaded_Convolutional_Neural_Networks_1777" rel="nofollow">Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks</a></li><li><a href="#Face_Detection_using_Deep_Learning_An_Improved_Faster_RCNN_Approach_1791" rel="nofollow">Face Detection using Deep Learning: An Improved Faster RCNN Approach</a></li><li><a href="#FacenessNet_Face_Detection_through_Deep_Facial_Part_Responses_1796" rel="nofollow">Faceness-Net: Face Detection through Deep Facial Part Responses</a></li><li><a href="#MultiPath_RegionBased_Convolutional_Neural_Network_for_Accurate_Detection_of_Unconstrained_Hard_Faces_1801" rel="nofollow">Multi-Path Region-Based Convolutional Neural Network for Accurate Detection of Unconstrained “Hard Faces”</a></li><li><a href="#EndToEnd_Face_Detection_and_Recognition_1806" rel="nofollow">End-To-End Face Detection and Recognition</a></li><li><a href="#Face_RCNN_1810" rel="nofollow">Face R-CNN</a></li><li><a href="#Face_Detection_through_ScaleFriendly_Deep_Convolutional_Networks_1814" rel="nofollow">Face Detection through Scale-Friendly Deep Convolutional Networks</a></li><li><a href="#ScaleAware_Face_Detection_1818" rel="nofollow">Scale-Aware Face Detection</a></li><li><a href="#Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN_1823" rel="nofollow">Detecting Faces Using Inside Cascaded Contextual CNN</a></li><li><a href="#MultiBranch_Fully_Convolutional_Network_for_Face_Detection_1828" rel="nofollow">Multi-Branch Fully Convolutional Network for Face Detection</a></li><li><a href="#SSH_Single_Stage_Headless_Face_Detector_1832" rel="nofollow">SSH: Single Stage Headless Face Detector</a></li><li><a href="#Dockerface_an_easy_to_install_and_use_Faster_RCNN_face_detector_in_a_Docker_container_1838" rel="nofollow">Dockerface: an easy to install and use Faster R-CNN face detector in a Docker container</a></li><li><a href="#FaceBoxes_A_CPU_Realtime_Face_Detector_with_High_Accuracy_1842" rel="nofollow">FaceBoxes: A CPU Real-time Face Detector with High Accuracy</a></li><li><a href="#S3FD_Single_Shot_Scaleinvariant_Face_Detector_1850" rel="nofollow">S3FD: Single Shot Scale-invariant Face Detector</a></li><li><a href="#Detecting_Faces_Using_Regionbased_Fully_Convolutional_Networks_1858" rel="nofollow">Detecting Faces Using Region-based Fully Convolutional Networks</a></li><li><a href="#AffordanceNet_An_EndtoEnd_Deep_Learning_Approach_for_Object_Affordance_Detection_1862" rel="nofollow">AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection</a></li><li><a href="#Face_Attention_Network_An_effective_Face_Detector_for_the_Occluded_Faces_1866" rel="nofollow">Face Attention Network: An effective Face Detector for the Occluded Faces</a></li><li><a href="#Feature_Agglomeration_Networks_for_Single_Stage_Face_Detection_1870" rel="nofollow">Feature Agglomeration Networks for Single Stage Face Detection</a></li><li><a href="#Face_Detection_Using_Improved_Faster_RCNN_1874" rel="nofollow">Face Detection Using Improved Faster RCNN</a></li><li><a href="#PyramidBox_A_Contextassisted_Single_Shot_Face_Detector_1879" rel="nofollow">PyramidBox: A Context-assisted Single Shot Face Detector</a></li><li><a href="#A_Fast_Face_Detection_Method_via_Convolutional_Neural_Network_1884" rel="nofollow">A Fast Face Detection Method via Convolutional Neural Network</a></li><li><a href="#Beyond_Tradeoff_Accelerate_FCNbased_Face_Detector_with_Higher_Accuracy_1889" rel="nofollow">Beyond Trade-off: Accelerate FCN-based Face Detector with Higher Accuracy</a></li><li><a href="#RealTime_RotationInvariant_Face_Detection_with_Progressive_Calibration_Networks_1894" rel="nofollow">Real-Time Rotation-Invariant Face Detection with Progressive Calibration Networks</a></li><li><a href="#SFace_An_Efficient_Network_for_Face_Detection_in_Large_Scale_Variations_1900" rel="nofollow">SFace: An Efficient Network for Face Detection in Large Scale Variations</a></li><li><a href="#Survey_of_Face_Detection_on_Lowquality_Images_1905" rel="nofollow">Survey of Face Detection on Low-quality Images</a></li><li><a href="#Anchor_Cascade_for_Efficient_Face_Detection_1909" rel="nofollow">Anchor Cascade for Efficient Face Detection</a></li><li><a href="#Adversarial_Attacks_on_Face_Detectors_using_Neural_Net_based_Constrained_Optimization_1914" rel="nofollow">Adversarial Attacks on Face Detectors using Neural Net based Constrained Optimization</a></li><li><a href="#Selective_Refinement_Network_for_High_Performance_Face_Detection_1919" rel="nofollow">Selective Refinement Network for High Performance Face Detection</a></li><li><a href="#DSFD_Dual_Shot_Face_Detector_1922" rel="nofollow">DSFD: Dual Shot Face Detector</a></li><li><a href="#Learning_Better_Features_for_Face_Detection_with_Feature_Fusion_and_Segmentation_Supervision_1925" rel="nofollow">Learning Better Features for Face Detection with Feature Fusion and Segmentation Supervision</a></li><li><a href="#FARPN_Floating_Region_Proposals_for_Face_Detection_1928" rel="nofollow">FA-RPN: Floating Region Proposals for Face Detection</a></li><li><a href="#Robust_and_High_Performance_Face_Detector_1931" rel="nofollow">Robust and High Performance Face Detector</a></li><li><a href="#DAFEFD_Density_Aware_Feature_Enrichment_for_Face_Detection_1934" rel="nofollow">DAFE-FD: Density Aware Feature Enrichment for Face Detection</a></li><li><a href="#Improved_Selective_Refinement_Network_for_Face_Detection_1937" rel="nofollow">Improved Selective Refinement Network for Face Detection</a></li><li><a href="#Revisiting_a_singlestage_method_for_face_detection_1941" rel="nofollow">Revisiting a single-stage method for face detection</a></li></ul> 
   </li><li><a href="#Detect_Small_Faces_1946" rel="nofollow">Detect Small Faces</a></li><li><ul><li><a href="#Finding_Tiny_Faces_1947" rel="nofollow">Finding Tiny Faces</a></li><li><a href="#Detecting_and_counting_tiny_faces_1956" rel="nofollow">Detecting and counting tiny faces</a></li><li><a href="#Seeing_Small_Faces_from_Robust_Anchors_Perspective_1963" rel="nofollow">Seeing Small Faces from Robust Anchor’s Perspective</a></li><li><a href="#FaceMagNet_Magnifying_Feature_Maps_to_Detect_Small_Faces_1968" rel="nofollow">Face-MagNet: Magnifying Feature Maps to Detect Small Faces</a></li><li><a href="#Robust_Face_Detection_via_Learning_Small_Faces_on_Hard_Images_1975" rel="nofollow">Robust Face Detection via Learning Small Faces on Hard Images</a></li><li><a href="#SFA_Small_Faces_Attention_Face_Detector_1980" rel="nofollow">SFA: Small Faces Attention Face Detector</a></li></ul> 
   </li><li><a href="#Person_Head_Detection_1985" rel="nofollow">Person Head Detection</a></li><li><ul><li><a href="#Contextaware_CNNs_for_person_head_detection_1986" rel="nofollow">Context-aware CNNs for person head detection</a></li><li><a href="#Detecting_Heads_using_Feature_Refine_Net_and_Cascaded_Multiscale_Architecture_1993" rel="nofollow">Detecting Heads using Feature Refine Net and Cascaded Multi-scale Architecture</a></li><li><a href="#A_Comparison_of_CNNbased_Face_and_Head_Detectors_for_RealTime_Video_Surveillance_Applications_1997" rel="nofollow">A Comparison of CNN-based Face and Head Detectors for Real-Time Video Surveillance Applications</a></li><li><a href="#FCHD_A_fast_and_accurate_head_detector_2000" rel="nofollow">FCHD: A fast and accurate head detector</a></li></ul> 
   </li><li><a href="#Pedestrian_Detection__People_Detection_2006" rel="nofollow">Pedestrian Detection / People Detection</a></li><li><ul><li><a href="#Pedestrian_Detection_aided_by_Deep_Learning_Semantic_Tasks_2007" rel="nofollow">Pedestrian Detection aided by Deep Learning Semantic Tasks</a></li><li><a href="#Deep_Learning_Strong_Parts_for_Pedestrian_Detection_2013" rel="nofollow">Deep Learning Strong Parts for Pedestrian Detection</a></li><li><a href="#Taking_a_Deeper_Look_at_Pedestrians_2019" rel="nofollow">Taking a Deeper Look at Pedestrians</a></li><li><a href="#Convolutional_Channel_Features_2024" rel="nofollow">Convolutional Channel Features</a></li><li><a href="#Endtoend_people_detection_in_crowded_scenes_2030" rel="nofollow">End-to-end people detection in crowded scenes</a></li><li><a href="#Learning_ComplexityAware_Cascades_for_Deep_Pedestrian_Detection_2037" rel="nofollow">Learning Complexity-Aware Cascades for Deep Pedestrian Detection</a></li><li><a href="#Deep_convolutional_neural_networks_for_pedestrian_detection_2042" rel="nofollow">Deep convolutional neural networks for pedestrian detection</a></li><li><a href="#Scaleaware_Fast_RCNN_for_Pedestrian_Detection_2047" rel="nofollow">Scale-aware Fast R-CNN for Pedestrian Detection</a></li><li><a href="#New_algorithm_improves_speed_and_accuracy_of_pedestrian_detection_2051" rel="nofollow">New algorithm improves speed and accuracy of pedestrian detection</a></li><li><a href="#Pushing_the_Limits_of_Deep_CNNs_for_Pedestrian_Detection_2055" rel="nofollow">Pushing the Limits of Deep CNNs for Pedestrian Detection</a></li><li><a href="#A_RealTime_Deep_Learning_Pedestrian_Detector_for_Robot_Navigation_2060" rel="nofollow">A Real-Time Deep Learning Pedestrian Detector for Robot Navigation</a></li><li><a href="#A_RealTime_Pedestrian_Detector_using_Deep_Learning_for_HumanAware_Navigation_2064" rel="nofollow">A Real-Time Pedestrian Detector using Deep Learning for Human-Aware Navigation</a></li><li><a href="#Is_Faster_RCNN_Doing_Well_for_Pedestrian_Detection_2068" rel="nofollow">Is Faster R-CNN Doing Well for Pedestrian Detection?</a></li><li><a href="#Unsupervised_Deep_Domain_Adaptation_for_Pedestrian_Detection_2074" rel="nofollow">Unsupervised Deep Domain Adaptation for Pedestrian Detection</a></li><li><a href="#Reduced_Memory_Region_Based_Deep_Convolutional_Neural_Network_Detection_2079" rel="nofollow">Reduced Memory Region Based Deep Convolutional Neural Network Detection</a></li><li><a href="#Fused_DNN_A_deep_neural_network_fusion_approach_to_fast_and_robust_pedestrian_detection_2084" rel="nofollow">Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection</a></li><li><a href="#Detecting_People_in_Artwork_with_CNNs_2088" rel="nofollow">Detecting People in Artwork with CNNs</a></li><li><a href="#Multispectral_Deep_Neural_Networks_for_Pedestrian_Detection_2092" rel="nofollow">Multispectral Deep Neural Networks for Pedestrian Detection</a></li><li><a href="#Boxlevel_Segmentation_Supervised_Deep_Neural_Networks_for_Accurate_and_Realtime_Multispectral_Pedestrian_Detection_2096" rel="nofollow">Box-level Segmentation Supervised Deep Neural Networks for Accurate and Real-time Multispectral Pedestrian Detection</a></li><li><a href="#Deep_Multicamera_People_Detection_2100" rel="nofollow">Deep Multi-camera People Detection</a></li><li><a href="#Expecting_the_Unexpected_Training_Detectors_for_Unusual_Pedestrians_with_Adversarial_Imposters_2104" rel="nofollow">Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters</a></li><li><a href="#What_Can_Help_Pedestrian_Detection_2111" rel="nofollow">What Can Help Pedestrian Detection?</a></li><li><a href="#Illuminating_Pedestrians_via_Simultaneous_Detection__Segmentation_2118" rel="nofollow">Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation</a></li><li><a href="#Rotational_Rectification_Network_for_Robust_Pedestrian_Detection_2122" rel="nofollow">Rotational Rectification Network for Robust Pedestrian Detection</a></li><li><a href="#STDPD_Generating_Synthetic_Training_Data_for_Pedestrian_Detection_in_Unannotated_Videos_2127" rel="nofollow">STD-PD: Generating Synthetic Training Data for Pedestrian Detection in Unannotated Videos</a></li><li><a href="#Too_Far_to_See_Not_Really__Pedestrian_Detection_with_Scaleaware_Localization_Policy_2132" rel="nofollow">Too Far to See? Not Really! — Pedestrian Detection with Scale-aware Localization Policy</a></li><li><a href="#Repulsion_Loss_Detecting_Pedestrians_in_a_Crowd_2136" rel="nofollow">Repulsion Loss: Detecting Pedestrians in a Crowd</a></li><li><a href="#Aggregated_Channels_Network_for_RealTime_Pedestrian_Detection_2140" rel="nofollow">Aggregated Channels Network for Real-Time Pedestrian Detection</a></li><li><a href="#Illuminationaware_Faster_RCNN_for_Robust_Multispectral_Pedestrian_Detection_2144" rel="nofollow">Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection</a></li><li><a href="#Exploring_MultiBranch_and_HighLevel_Semantic_Networks_for_Improving_Pedestrian_Detection_2149" rel="nofollow">Exploring Multi-Branch and High-Level Semantic Networks for Improving Pedestrian Detection</a></li><li><a href="#PedestrianSynthesisGAN_Generating_Pedestrian_Data_in_Real_Scene_and_Beyond_2153" rel="nofollow">Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond</a></li><li><a href="#PCN_Part_and_Context_Information_for_Pedestrian_Detection_with_CNNs_2157" rel="nofollow">PCN: Part and Context Information for Pedestrian Detection with CNNs</a></li><li><a href="#Smallscale_Pedestrian_Detection_Based_on_Somatic_Topology_Localization_and_Temporal_Feature_Aggregation_2162" rel="nofollow">Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation</a></li><li><a href="#Occlusionaware_RCNN_Detecting_Pedestrians_in_a_Crowd_2167" rel="nofollow">Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</a></li><li><a href="#Multispectral_Pedestrian_Detection_via_Simultaneous_Detection_and_Segmentation_2172" rel="nofollow">Multispectral Pedestrian Detection via Simultaneous Detection and Segmentation</a></li><li><a href="#Pedestrian_Detection_with_Autoregressive_Network_Phases_2177" rel="nofollow">Pedestrian Detection with Autoregressive Network Phases</a></li><li><a href="#The_CrossModality_Disparity_Problem_in_Multispectral_Pedestrian_Detection_2181" rel="nofollow">The Cross-Modality Disparity Problem in Multispectral Pedestrian Detection</a></li></ul> 
   </li><li><a href="#Vehicle_Detection_2187" rel="nofollow">Vehicle Detection</a></li><li><ul><li><a href="#DAVE_A_Unified_Framework_for_Fast_Vehicle_Detection_and_Annotation_2188" rel="nofollow">DAVE: A Unified Framework for Fast Vehicle Detection and Annotation</a></li><li><a href="#Evolving_Boxes_for_fast_Vehicle_Detection_2193" rel="nofollow">Evolving Boxes for fast Vehicle Detection</a></li><li><a href="#FineGrained_Car_Detection_for_Visual_Census_Estimation_2197" rel="nofollow">Fine-Grained Car Detection for Visual Census Estimation</a></li><li><a href="#SINet_A_Scaleinsensitive_Convolutional_Neural_Network_for_Fast_Vehicle_Detection_2202" rel="nofollow">SINet: A Scale-insensitive Convolutional Neural Network for Fast Vehicle Detection</a></li><li><a href="#Label_and_Sample_Efficient_Training_of_Vehicle_Object_Detector_from_Sparsely_Labeled_Data_2207" rel="nofollow">Label and Sample: Efficient Training of Vehicle Object Detector from Sparsely Labeled Data</a></li><li><a href="#Domain_Randomization_for_SceneSpecific_Car_Detection_and_Pose_Estimation_2211" rel="nofollow">Domain Randomization for Scene-Specific Car Detection and Pose Estimation</a></li><li><a href="#ShuffleDet_RealTime_Vehicle_Detection_Network_in_Onboard_Embedded_UAV_Imagery_2214" rel="nofollow">ShuffleDet: Real-Time Vehicle Detection Network in On-board Embedded UAV Imagery</a></li></ul> 
   </li><li><a href="#TrafficSign_Detection_2221" rel="nofollow">Traffic-Sign Detection</a></li><li><ul><li><a href="#TrafficSign_Detection_and_Classification_in_the_Wild_2222" rel="nofollow">Traffic-Sign Detection and Classification in the Wild</a></li><li><a href="#Evaluating_Stateoftheart_Object_Detector_on_Challenging_Traffic_Light_Data_2229" rel="nofollow">Evaluating State-of-the-art Object Detector on Challenging Traffic Light Data</a></li><li><a href="#Detecting_Small_Signs_from_Large_Images_2234" rel="nofollow">Detecting Small Signs from Large Images</a></li><li><a href="#Localized_Traffic_Sign_Detection_with_Multiscale_Deconvolution_Networks_2239" rel="nofollow">Localized Traffic Sign Detection with Multi-scale Deconvolution Networks</a></li><li><a href="#Detecting_Traffic_Lights_by_Single_Shot_Detection_2243" rel="nofollow">Detecting Traffic Lights by Single Shot Detection</a></li><li><a href="#A_Hierarchical_Deep_Architecture_and_MiniBatch_Selection_Method_For_Joint_Traffic_Sign_and_Light_Detection_2248" rel="nofollow">A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection</a></li></ul> 
   </li><li><a href="#Skeleton_Detection_2256" rel="nofollow">Skeleton Detection</a></li><li><ul><li><a href="#Object_Skeleton_Extraction_in_Natural_Images_by_Fusing_Scaleassociated_Deep_Side_Outputs_2257" rel="nofollow">Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs</a></li><li><a href="#DeepSkeleton_Learning_Multitask_Scaleassociated_Deep_Side_Outputs_for_Object_Skeleton_Extraction_in_Natural_Images_2262" rel="nofollow">DeepSkeleton: Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images</a></li><li><a href="#SRN_Sideoutput_Residual_Network_for_Object_Symmetry_Detection_in_the_Wild_2266" rel="nofollow">SRN: Side-output Residual Network for Object Symmetry Detection in the Wild</a></li><li><a href="#HiFi_Hierarchical_Feature_Integration_for_Skeleton_Detection_2272" rel="nofollow">Hi-Fi: Hierarchical Feature Integration for Skeleton Detection</a></li></ul> 
   </li><li><a href="#Fruit_Detection_2278" rel="nofollow">Fruit Detection</a></li><li><ul><li><a href="#Deep_Fruit_Detection_in_Orchards_2279" rel="nofollow">Deep Fruit Detection in Orchards</a></li><li><a href="#Image_Segmentation_for_Fruit_Detection_and_Yield_Estimation_in_Apple_Orchards_2283" rel="nofollow">Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards</a></li></ul> 
   </li><li><a href="#Shadow_Detection_2290" rel="nofollow">Shadow Detection</a></li><li><ul><li><a href="#Fast_Shadow_Detection_from_a_Single_Image_Using_a_Patched_Convolutional_Neural_Network_2291" rel="nofollow">Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network</a></li><li><a href="#ADNet_Shadow_Detection_with_Adversarial_Shadow_Attenuation_2295" rel="nofollow">A+D-Net: Shadow Detection with Adversarial Shadow Attenuation</a></li><li><a href="#Stacked_Conditional_Generative_Adversarial_Networks_for_Jointly_Learning_Shadow_Detection_and_Shadow_Removal_2299" rel="nofollow">Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal</a></li><li><a href="#Directionaware_Spatial_Context_Features_for_Shadow_Detection_2303" rel="nofollow">Direction-aware Spatial Context Features for Shadow Detection</a></li><li><a href="#Directionaware_Spatial_Context_Features_for_Shadow_Detection_and_Removal_2308" rel="nofollow">Direction-aware Spatial Context Features for Shadow Detection and Removal</a></li></ul> 
   </li><li><a href="#Others_Detection_2315" rel="nofollow">Others Detection</a></li><li><ul><li><a href="#Deep_Deformation_Network_for_Object_Landmark_Localization_2316" rel="nofollow">Deep Deformation Network for Object Landmark Localization</a></li><li><a href="#Fashion_Landmark_Detection_in_the_Wild_2320" rel="nofollow">Fashion Landmark Detection in the Wild</a></li><li><a href="#Deep_Learning_for_Fast_and_Accurate_Fashion_Item_Detection_2327" rel="nofollow">Deep Learning for Fast and Accurate Fashion Item Detection</a></li><li><a href="#OSMDeepOD__OSM_and_Deep_Learning_based_Object_Detection_from_Aerial_Imagery_formerly_known_as_OSMCrosswalkDetection_2333" rel="nofollow">OSMDeepOD - OSM and Deep Learning based Object Detection from Aerial Imagery (formerly known as “OSM-Crosswalk-Detection”)</a></li><li><a href="#Selfie_Detection_by_SynergyConstraint_Based_Convolutional_Neural_Network_2337" rel="nofollow">Selfie Detection by Synergy-Constraint Based Convolutional Neural Network</a></li><li><a href="#Associative_EmbeddingEndtoEnd_Learning_for_Joint_Detection_and_Grouping_2342" rel="nofollow">Associative Embedding:End-to-End Learning for Joint Detection and Grouping</a></li><li><a href="#Deep_Cuboid_Detection_Beyond_2D_Bounding_Boxes_2346" rel="nofollow">Deep Cuboid Detection: Beyond 2D Bounding Boxes</a></li><li><a href="#Automatic_Model_Based_Dataset_Generation_for_Fast_and_Accurate_Crop_and_Weeds_Detection_2351" rel="nofollow">Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection</a></li><li><a href="#Deep_Learning_Logo_Detection_with_Data_Expansion_by_Synthesising_Context_2355" rel="nofollow">Deep Learning Logo Detection with Data Expansion by Synthesising Context</a></li><li><a href="#Scalable_Deep_Learning_Logo_Detection_2359" rel="nofollow">Scalable Deep Learning Logo Detection</a></li><li><a href="#Pixelwise_Ear_Detection_with_Convolutional_EncoderDecoder_Networks_2363" rel="nofollow">Pixel-wise Ear Detection with Convolutional Encoder-Decoder Networks</a></li><li><a href="#Automatic_Handgun_Detection_Alarm_in_Videos_Using_Deep_Learning_2367" rel="nofollow">Automatic Handgun Detection Alarm in Videos Using Deep Learning</a></li><li><a href="#Objects_as_context_for_part_detection_2372" rel="nofollow">Objects as context for part detection</a></li><li><a href="#Using_Deep_Networks_for_Drone_Detection_2376" rel="nofollow">Using Deep Networks for Drone Detection</a></li><li><a href="#Cut_Paste_and_Learn_Surprisingly_Easy_Synthesis_for_Instance_Detection_2381" rel="nofollow">Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection</a></li><li><a href="#Target_Driven_Instance_Detection_2386" rel="nofollow">Target Driven Instance Detection</a></li><li><a href="#DeepVoting_An_Explainable_Framework_for_Semantic_Part_Detection_under_Partial_Occlusion_2390" rel="nofollow">DeepVoting: An Explainable Framework for Semantic Part Detection under Partial Occlusion</a></li><li><a href="#VPGNet_Vanishing_Point_Guided_Network_for_Lane_and_Road_Marking_Detection_and_Recognition_2394" rel="nofollow">VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition</a></li><li><a href="#Grab_Pay_and_Eat_Semantic_Food_Detection_for_Smart_Restaurants_2400" rel="nofollow">Grab, Pay and Eat: Semantic Food Detection for Smart Restaurants</a></li><li><a href="#ReMotENet_Efficient_Relevant_Motion_Event_Detection_for_Largescale_Home_Surveillance_Videos_2404" rel="nofollow">ReMotENet: Efficient Relevant Motion Event Detection for Large-scale Home Surveillance Videos</a></li><li><a href="#Deep_Learning_Object_Detection_Methods_for_Ecological_Camera_Trap_Data_2409" rel="nofollow">Deep Learning Object Detection Methods for Ecological Camera Trap Data</a></li><li><a href="#ELGAN_Embedding_Loss_Driven_Generative_Adversarial_Networks_for_Lane_Detection_2414" rel="nofollow">EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection</a></li><li><a href="#Towards_EndtoEnd_Lane_Detection_an_Instance_Segmentation_Approach_2418" rel="nofollow">Towards End-to-End Lane Detection: an Instance Segmentation Approach</a></li><li><a href="#iCAN_InstanceCentric_Attention_Network_for_HumanObject_Interaction_Detection_2422" rel="nofollow">iCAN: Instance-Centric Attention Network for Human-Object Interaction Detection</a></li><li><a href="#Densely_Supervised_Grasp_Detector_DSGD_2429" rel="nofollow">Densely Supervised Grasp Detector (DSGD)</a></li></ul> 
   </li><li><a href="#Object_Proposal_2433" rel="nofollow">Object Proposal</a></li><li><ul><li><a href="#DeepProposal_Hunting_Objects_by_Cascading_Deep_Convolutional_Layers_2434" rel="nofollow">DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers</a></li><li><a href="#Scaleaware_Pixelwise_Object_Proposal_Networks_2439" rel="nofollow">Scale-aware Pixel-wise Object Proposal Networks</a></li><li><a href="#Attend_Refine_Repeat_Active_Box_Proposal_Generation_via_InOut_Localization_2444" rel="nofollow">Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization</a></li><li><a href="#Learning_to_Segment_Object_Proposals_via_Recursive_Neural_Networks_2450" rel="nofollow">Learning to Segment Object Proposals via Recursive Neural Networks</a></li><li><a href="#Learning_Detection_with_Diverse_Proposals_2454" rel="nofollow">Learning Detection with Diverse Proposals</a></li><li><a href="#ScaleNet_Guiding_Object_Proposal_Generation_in_Supermarkets_and_Beyond_2460" rel="nofollow">ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond</a></li><li><a href="#Improving_Small_Object_Proposals_for_Company_Logo_Detection_2465" rel="nofollow">Improving Small Object Proposals for Company Logo Detection</a></li><li><a href="#Open_Logo_Detection_Challenge_2470" rel="nofollow">Open Logo Detection Challenge</a></li><li><a href="#AttentionMask_Attentive_Efficient_Object_Proposal_Generation_Focusing_on_Small_Objects_2478" rel="nofollow">AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects</a></li></ul> 
   </li><li><a href="#Localization_2484" rel="nofollow">Localization</a></li><li><ul><li><a href="#Beyond_Bounding_Boxes_Precise_Localization_of_Objects_in_Images_2485" rel="nofollow">Beyond Bounding Boxes: Precise Localization of Objects in Images</a></li><li><a href="#Weakly_Supervised_Object_Localization_with_Multifold_Multiple_Instance_Learning_2492" rel="nofollow">Weakly Supervised Object Localization with Multi-fold Multiple Instance Learning</a></li><li><a href="#Weakly_Supervised_Object_Localization_Using_Size_Estimates_2496" rel="nofollow">Weakly Supervised Object Localization Using Size Estimates</a></li><li><a href="#Active_Object_Localization_with_Deep_Reinforcement_Learning_2500" rel="nofollow">Active Object Localization with Deep Reinforcement Learning</a></li><li><a href="#Localizing_objects_using_referring_expressions_2506" rel="nofollow">Localizing objects using referring expressions</a></li><li><a href="#LocNet_Improving_Localization_Accuracy_for_Object_Detection_2513" rel="nofollow">LocNet: Improving Localization Accuracy for Object Detection</a></li><li><a href="#Learning_Deep_Features_for_Discriminative_Localization_2519" rel="nofollow">Learning Deep Features for Discriminative Localization</a></li><li><a href="#ContextLocNet_ContextAware_Deep_Network_Models_for_Weakly_Supervised_Localization_2527" rel="nofollow">ContextLocNet: Context-Aware Deep Network Models for Weakly Supervised Localization</a></li><li><a href="#Ensemble_of_Part_Detectors_for_Simultaneous_Classification_and_Localization_2534" rel="nofollow">Ensemble of Part Detectors for Simultaneous Classification and Localization</a></li><li><a href="#STNet_Selective_Tuning_of_Convolutional_Networks_for_Object_Localization_2538" rel="nofollow">STNet: Selective Tuning of Convolutional Networks for Object Localization</a></li><li><a href="#Soft_Proposal_Networks_for_Weakly_Supervised_Object_Localization_2542" rel="nofollow">Soft Proposal Networks for Weakly Supervised Object Localization</a></li><li><a href="#Finegrained_Discriminative_Localization_via_Saliencyguided_Faster_RCNN_2547" rel="nofollow">Fine-grained Discriminative Localization via Saliency-guided Faster R-CNN</a></li></ul> 
   </li><li><a href="#Tutorials__Talks_2554" rel="nofollow">Tutorials / Talks</a></li><li><ul><li><a href="#Convolutional_Feature_Maps_Elements_of_efficient_and_accurate_CNNbased_object_detection_2555" rel="nofollow">Convolutional Feature Maps: Elements of efficient (and accurate) CNN-based object detection</a></li><li><a href="#Towards_Good_Practices_for_Recognition__Detection_2559" rel="nofollow">Towards Good Practices for Recognition &amp; Detection</a></li><li><a href="#Work_in_progress_Improving_object_detection_and_instance_segmentation_for_small_objects_2564" rel="nofollow">Work in progress: Improving object detection and instance segmentation for small objects</a></li><li><a href="#Object_Detection_with_Deep_Learning_A_Review_2568" rel="nofollow">Object Detection with Deep Learning: A Review</a></li></ul> 
   </li><li><a href="#Projects_2574" rel="nofollow">Projects</a></li><li><ul><li><a href="#Detectron_2575" rel="nofollow">Detectron</a></li><li><a href="#TensorBox_a_simple_framework_for_training_neural_networks_to_detect_objects_in_images_2580" rel="nofollow">TensorBox: a simple framework for training neural networks to detect objects in images</a></li><li><a href="#Object_detection_in_torch_Implementation_of_some_object_detection_frameworks_in_torch_2585" rel="nofollow">Object detection in torch: Implementation of some object detection frameworks in torch</a></li><li><a href="#Using_DIGITS_to_train_an_Object_Detection_network_2589" rel="nofollow">Using DIGITS to train an Object Detection network</a></li><li><a href="#FCNMultiBox_Detector_2593" rel="nofollow">FCN-MultiBox Detector</a></li><li><a href="#KittiBox_A_car_detection_model_implemented_in_Tensorflow_2598" rel="nofollow">KittiBox: A car detection model implemented in Tensorflow.</a></li><li><a href="#Deformable_Convolutional_Networks__MST__SoftNMS_2604" rel="nofollow">Deformable Convolutional Networks + MST + Soft-NMS</a></li><li><a href="#How_to_Build_a_Realtime_HandDetector_using_Neural_Networks_SSD_on_Tensorflow_2608" rel="nofollow">How to Build a Real-time Hand-Detector using Neural Networks (SSD) on Tensorflow</a></li><li><a href="#Metrics_for_object_detection_2613" rel="nofollow">Metrics for object detection</a></li><li><a href="#MobileNetv2SSDLite_2619" rel="nofollow">MobileNetv2-SSDLite</a></li></ul> 
   </li><li><a href="#Leaderboard_2624" rel="nofollow">Leaderboard</a></li><li><ul><li><a href="#Detection_Results_VOC2012_2625" rel="nofollow">Detection Results: VOC2012</a></li></ul> 
   </li><li><a href="#Tools_2632" rel="nofollow">Tools</a></li><li><ul><li><a href="#BeaverDam_Video_annotation_tool_for_deep_learning_training_labels_2633" rel="nofollow">BeaverDam: Video annotation tool for deep learning training labels</a></li></ul> 
   </li><li><a href="#Blogs_2639" rel="nofollow">Blogs</a></li><li><ul><li><a href="#Convolutional_Neural_Networks_for_Object_Detection_2640" rel="nofollow">Convolutional Neural Networks for Object Detection</a></li><li><a href="#Introducing_automatic_object_detection_to_visual_search_Pinterest_2644" rel="nofollow">Introducing automatic object detection to visual search (Pinterest)</a></li><li><a href="#Deep_Learning_for_Object_Detection_with_DIGITS_2651" rel="nofollow">Deep Learning for Object Detection with DIGITS</a></li><li><a href="#Analyzing_The_Papers_Behind_Facebooks_Computer_Vision_Approach_2655" rel="nofollow">Analyzing The Papers Behind Facebook’s Computer Vision Approach</a></li><li><a href="#Easily_Create_High_Quality_Object_Detectors_with_Deep_Learning_2660" rel="nofollow">Easily Create High Quality Object Detectors with Deep Learning</a></li><li><a href="#How_to_Train_a_DeepLearned_Object_Detection_Model_in_the_Microsoft_Cognitive_Toolkit_2665" rel="nofollow">How to Train a Deep-Learned Object Detection Model in the Microsoft Cognitive Toolkit</a></li><li><a href="#Object_Detection_in_Satellite_Imagery_a_Low_Overhead_Approach_2670" rel="nofollow">Object Detection in Satellite Imagery, a Low Overhead Approach</a></li><li><a href="#You_Only_Look_Twice%E2%80%8A%E2%80%8AMultiScale_Object_Detection_in_Satellite_Imagery_With_Convolutional_Neural_Networks_2675" rel="nofollow">You Only Look Twice — Multi-Scale Object Detection in Satellite Imagery With Convolutional Neural Networks</a></li><li><a href="#Faster_RCNN_Pedestrian_and_Car_Detection_2680" rel="nofollow">Faster R-CNN Pedestrian and Car Detection</a></li><li><a href="#Small_UNet_for_vehicle_detection_2686" rel="nofollow">Small U-Net for vehicle detection</a></li><li><a href="#Region_of_interest_pooling_explained_2690" rel="nofollow">Region of interest pooling explained</a></li><li><a href="#Supercharge_your_Computer_Vision_models_with_the_TensorFlow_Object_Detection_API_2695" rel="nofollow">Supercharge your Computer Vision models with the TensorFlow Object Detection API</a></li><li><a href="#Understanding_SSD_MultiBox%E2%80%8A%E2%80%8ARealTime_Object_Detection_In_Deep_Learning_2700" rel="nofollow">Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning</a></li><li><a href="#Oneshot_object_detection_2703" rel="nofollow">One-shot object detection</a></li><li><a href="#An_overview_of_object_detection_onestage_methods_2706" rel="nofollow">An overview of object detection: one-stage methods</a></li></ul> 
   </li><li><a href="#deep_learning_object_detection_2709" rel="nofollow">deep learning object detection</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<table><thead><tr><th>Method</th><th align="center">backbone</th><th align="center">test size</th><th align="center">VOC2007</th><th align="center">VOC2010</th><th align="center">VOC2012</th><th align="center">ILSVRC 2013</th><th align="center">MSCOCO 2015</th><th align="center">Speed</th></tr></thead><tbody><tr><td>OverFeat</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">24.3%</td><td align="center"></td><td align="center"></td></tr><tr><td>R-CNN</td><td align="center">AlexNet</td><td align="center"></td><td align="center">58.5%</td><td align="center">53.7%</td><td align="center">53.3%</td><td align="center">31.4%</td><td align="center"></td><td align="center"></td></tr><tr><td>R-CNN</td><td align="center">VGG17</td><td align="center"></td><td align="center">66.0%</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>SPP_net</td><td align="center">ZF-5</td><td align="center"></td><td align="center">54.2%</td><td align="center"></td><td align="center"></td><td align="center">31.84%</td><td align="center"></td><td align="center"></td></tr><tr><td>DeepID-Net</td><td align="center"></td><td align="center"></td><td align="center">64.1%</td><td align="center"></td><td align="center"></td><td align="center">50.3%</td><td align="center"></td><td align="center"></td></tr><tr><td>NoC</td><td align="center"></td><td align="center"></td><td align="center">73.3%</td><td align="center"></td><td align="center">68.8%</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>Fast-RCNN</td><td align="center">VGG16</td><td align="center"></td><td align="center">70.0%</td><td align="center">68.8%</td><td align="center">68.4%</td><td align="center"></td><td align="center">19.7%(@[0.5-0.95]), 35.9%(@0.5)</td><td align="center"></td></tr><tr><td>MR-CNN</td><td align="center"></td><td align="center"></td><td align="center">78.2%</td><td align="center"></td><td align="center">73.9%</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>Faster-RCNN</td><td align="center">VGG16</td><td align="center"></td><td align="center">78.8%</td><td align="center"></td><td align="center">75.9%</td><td align="center"></td><td align="center">21.9%(@[0.5-0.95]), 42.7%(@0.5)</td><td align="center">198ms</td></tr><tr><td>Faster-RCNN</td><td align="center">ResNet101</td><td align="center"></td><td align="center">85.6%</td><td align="center"></td><td align="center">83.8%</td><td align="center"></td><td align="center">37.4%(@[0.5-0.95]), 59.0%(@0.5)</td><td align="center"></td></tr><tr><td>YOLO</td><td align="center"></td><td align="center"></td><td align="center">63.4%</td><td align="center"></td><td align="center">57.9%</td><td align="center"></td><td align="center"></td><td align="center">45 fps</td></tr><tr><td>YOLO</td><td align="center">VGG-16</td><td align="center"></td><td align="center">66.4%</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">21 fps</td></tr><tr><td>YOLOv2</td><td align="center"></td><td align="center">448x448</td><td align="center">78.6%</td><td align="center"></td><td align="center">73.4%</td><td align="center"></td><td align="center">21.6%(@[0.5-0.95]), 44.0%(@0.5)</td><td align="center">40 fps</td></tr><tr><td>SSD</td><td align="center">VGG16</td><td align="center">300x300</td><td align="center">77.2%</td><td align="center"></td><td align="center">75.8%</td><td align="center"></td><td align="center">25.1%(@[0.5-0.95]), 43.1%(@0.5)</td><td align="center">46 fps</td></tr><tr><td>SSD</td><td align="center">VGG16</td><td align="center">512x512</td><td align="center">79.8%</td><td align="center"></td><td align="center">78.5%</td><td align="center"></td><td align="center">28.8%(@[0.5-0.95]), 48.5%(@0.5)</td><td align="center">19 fps</td></tr><tr><td>SSD</td><td align="center">ResNet101</td><td align="center">300x300</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">28.0%(@[0.5-0.95])</td><td align="center">16 fps</td></tr><tr><td>SSD</td><td align="center">ResNet101</td><td align="center">512x512</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">31.2%(@[0.5-0.95])</td><td align="center">8 fps</td></tr><tr><td>DSSD</td><td align="center">ResNet101</td><td align="center">300x300</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">28.0%(@[0.5-0.95])</td><td align="center">8 fps</td></tr><tr><td>DSSD</td><td align="center">ResNet101</td><td align="center">500x500</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">33.2%(@[0.5-0.95])</td><td align="center">6 fps</td></tr><tr><td>ION</td><td align="center"></td><td align="center"></td><td align="center">79.2%</td><td align="center"></td><td align="center">76.4%</td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>CRAFT</td><td align="center"></td><td align="center"></td><td align="center">75.7%</td><td align="center"></td><td align="center">71.3%</td><td align="center">48.5%</td><td align="center"></td><td align="center"></td></tr><tr><td>OHEM</td><td align="center"></td><td align="center"></td><td align="center">78.9%</td><td align="center"></td><td align="center">76.3%</td><td align="center"></td><td align="center">25.5%(@[0.5-0.95]), 45.9%(@0.5)</td><td align="center"></td></tr><tr><td>R-FCN</td><td align="center">ResNet50</td><td align="center"></td><td align="center">77.4%</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">0.12sec(K40), 0.09sec(TitianX)</td></tr><tr><td>R-FCN</td><td align="center">ResNet101</td><td align="center"></td><td align="center">79.5%</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">0.17sec(K40), 0.12sec(TitianX)</td></tr><tr><td>R-FCN(ms train)</td><td align="center">ResNet101</td><td align="center"></td><td align="center">83.6%</td><td align="center"></td><td align="center">82.0%</td><td align="center"></td><td align="center">31.5%(@[0.5-0.95]), 53.2%(@0.5)</td><td align="center"></td></tr><tr><td>PVANet 9.0</td><td align="center"></td><td align="center"></td><td align="center">84.9%</td><td align="center"></td><td align="center">84.2%</td><td align="center"></td><td align="center"></td><td align="center">750ms(CPU), 46ms(TitianX)</td></tr><tr><td>RetinaNet</td><td align="center">ResNet101-FPN</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>Light-Head R-CNN</td><td align="center">Xception*</td><td align="center">800/1200</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">31.5%@[0.5:0.95]</td><td align="center">95 fps</td></tr><tr><td>Light-Head R-CNN</td><td align="center">Xception*</td><td align="center">700/1100</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">30.7%@[0.5:0.95]</td><td align="center">102 fps</td></tr><tr><td>STDN</td><td align="center"></td><td align="center"></td><td align="center">80.9 (07+12)</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>RefineDet</td><td align="center"></td><td align="center"></td><td align="center">83.8 (07+12)</td><td align="center"></td><td align="center">83.5 (07++12)</td><td align="center"></td><td align="center">41.8</td><td align="center"></td></tr><tr><td>SNIP</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">45.7</td><td align="center"></td></tr><tr><td>Relation-Network</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">32.5</td><td align="center"></td></tr><tr><td>Cascade R-CNN</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">42.8</td><td align="center"></td></tr><tr><td>MLKP</td><td align="center"></td><td align="center"></td><td align="center">80.6 (07+12)</td><td align="center"></td><td align="center">77.2 (07++12)</td><td align="center"></td><td align="center">28.6</td><td align="center"></td></tr><tr><td>Fitness-NMS</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">41.8</td><td align="center"></td></tr><tr><td>RFBNet</td><td align="center"></td><td align="center"></td><td align="center">82.2 (07+12)</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>CornerNet</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">42.1</td><td align="center"></td></tr><tr><td>PFPNet</td><td align="center"></td><td align="center"></td><td align="center">84.1 (07+12)</td><td align="center"></td><td align="center">83.7 (07++12)</td><td align="center"></td><td align="center">39.4</td><td align="center"></td></tr><tr><td>Pelee</td><td align="center"></td><td align="center"></td><td align="center">70.9 (07+12)</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td></tr><tr><td>HKRM</td><td align="center"></td><td align="center"></td><td align="center">78.8 (07+12)</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">37.8</td><td align="center"></td></tr><tr><td>M2Det</td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center"></td><td align="center">44.2</td><td align="center"></td></tr><tr><td>SIN</td><td align="center"></td><td align="center"></td><td align="center">76.0 (07+12)</td><td align="center"></td><td align="center">73.1 (07++12)</td><td align="center"></td><td align="center">23.2</td><td align="center"></td></tr></tbody></table> 
<h2><a id="Papers_55"></a>Papers</h2> 
<hr> 
<hr> 
<h3><a id="_60"></a>损失函数</h3> 
<h4><a id="CVPR2019_Generalized_Intersection_over_Union_A_Metric_and_A_Loss_for_Bounding_Box_Regression_61"></a>[CVPR2019] Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1902.09630</li></ul> 
<h4><a id="Deep_Neural_Networks_for_Object_Detection_66"></a>Deep Neural Networks for Object Detection</h4> 
<ul><li>paper: http://papers.nips.cc/paper/5207-deep-neural-networks-for-object-detection.pdf</li></ul> 
<h4><a id="OverFeat_Integrated_Recognition_Localization_and_Detection_using_Convolutional_Networks_69"></a>OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1312.6229</li><li>github: https://github.com/sermanet/OverFeat</li><li>code: http://cilvr.nyu.edu/doku.php?id=software:overfeat:start</li></ul> 
<hr> 
<h3><a id="RCNN_76"></a>R-CNN</h3> 
<h4><a id="Rich_feature_hierarchies_for_accurate_object_detection_and_semantic_segmentation_77"></a>Rich feature hierarchies for accurate object detection and semantic segmentation</h4> 
<ul><li>intro: R-CNN</li><li>arxiv: http://arxiv.org/abs/1311.2524</li><li>supp: http://people.eecs.berkeley.edu/~rbg/papers/r-cnn-cvpr-supp.pdf</li><li>slides: http://www.image-net.org/challenges/LSVRC/2013/slides/r-cnn-ilsvrc2013-workshop.pdf</li><li>slides: http://www.cs.berkeley.edu/~rbg/slides/rcnn-cvpr14-slides.pdf</li><li>github: https://github.com/rbgirshick/rcnn</li><li>notes: http://zhangliliang.com/2014/07/23/paper-note-rcnn/</li><li>caffe-pr(“Make R-CNN the Caffe detection example”): https://github.com/BVLC/caffe/pull/482</li></ul> 
<hr> 
<h3><a id="Fast_RCNN_91"></a>Fast R-CNN</h3> 
<h4><a id="Fast_RCNN_92"></a>Fast R-CNN</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1504.08083</li><li>slides: http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-detection.pdf</li><li>github: https://github.com/rbgirshick/fast-rcnn</li><li>github(COCO-branch): https://github.com/rbgirshick/fast-rcnn/tree/coco</li><li>webcam demo: https://github.com/rbgirshick/fast-rcnn/pull/29</li><li>notes: http://zhangliliang.com/2015/05/17/paper-note-fast-rcnn/</li><li>notes: http://blog.csdn.net/linj_m/article/details/48930179</li><li>github(“Fast R-CNN in MXNet”): https://github.com/precedenceguo/mx-rcnn</li><li>github: https://github.com/mahyarnajibi/fast-rcnn-torch</li><li>github: https://github.com/apple2373/chainer-simple-fast-rnn</li><li>github: https://github.com/zplizzi/tensorflow-fast-rcnn</li></ul> 
<h4><a id="AFastRCNN_Hard_Positive_Generation_via_Adversary_for_Object_Detection_105"></a>A-Fast-RCNN: Hard Positive Generation via Adversary for Object Detection</h4> 
<ul><li>intro: CVPR 2017</li><li>arxiv: https://arxiv.org/abs/1704.03414</li><li>paper: http://abhinavsh.info/papers/pdfs/adversarial_object_detection.pdf</li><li>github(Caffe): https://github.com/xiaolonw/adversarial-frcnn</li></ul> 
<h3><a id="Faster_RCNN_112"></a>Faster R-CNN</h3> 
<h4><a id="Faster_RCNN_Towards_RealTime_Object_Detection_with_Region_Proposal_Networks_113"></a>Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</h4> 
<ul><li>intro: NIPS 2015</li><li>arxiv: http://arxiv.org/abs/1506.01497</li><li>gitxiv: http://www.gitxiv.com/posts/8pfpcvefDYn2gSgXk/faster-r-cnn-towards-real-time-object-detection-with-region</li><li>slides: http://web.cs.hacettepe.edu.tr/~aykut/classes/spring2016/bil722/slides/w05-FasterR-CNN.pdf</li><li>github(official, Matlab): https://github.com/ShaoqingRen/faster_rcnn</li><li>github: https://github.com/rbgirshick/py-faster-rcnn</li><li>github(MXNet): https://github.com/msracver/Deformable-ConvNets/tree/master/faster_rcnn</li><li>github: https://github.com//jwyang/faster-rcnn.pytorch</li><li>github: https://github.com/mitmul/chainer-faster-rcnn</li><li>github: https://github.com/andreaskoepf/faster-rcnn.torch</li><li>github: https://github.com/ruotianluo/Faster-RCNN-Densecap-torch</li><li>github: https://github.com/smallcorgi/Faster-RCNN_TF</li><li>github: https://github.com/CharlesShang/TFFRCNN</li><li>github(C++ demo): https://github.com/YihangLou/FasterRCNN-Encapsulation-Cplusplus</li><li>github: https://github.com/yhenon/keras-frcnn</li><li>github: https://github.com/Eniac-Xie/faster-rcnn-resnet</li><li>github(C++): https://github.com/D-X-Y/caffe-faster-rcnn/tree/dev</li></ul> 
<h4><a id="RCNN_minus_R_132"></a>R-CNN minus R</h4> 
<ul><li>intro: BMVC 2015</li><li>arxiv: http://arxiv.org/abs/1506.06981</li></ul> 
<h4><a id="Faster_RCNN_in_MXNet_with_distributed_implementation_and_data_parallelization_137"></a>Faster R-CNN in MXNet with distributed implementation and data parallelization</h4> 
<ul><li>github: https://github.com/dmlc/mxnet/tree/master/example/rcnn</li></ul> 
<h4><a id="Contextual_Priming_and_Feedback_for_Faster_RCNN_141"></a>Contextual Priming and Feedback for Faster R-CNN</h4> 
<ul><li>intro: ECCV 2016. Carnegie Mellon University</li><li>paper: http://abhinavsh.info/context_priming_feedback.pdf</li><li>poster: http://www.eccv2016.org/files/posters/P-1A-20.pdf</li></ul> 
<h4><a id="An_Implementation_of_Faster_RCNN_with_Study_for_Region_Sampling_147"></a>An Implementation of Faster RCNN with Study for Region Sampling</h4> 
<ul><li>intro: Technical Report, 3 pages. CMU</li><li>arxiv: https://arxiv.org/abs/1702.02138</li><li>github: https://github.com/endernewton/tf-faster-rcnn</li></ul> 
<h4><a id="Interpretable_RCNN_153"></a>Interpretable R-CNN</h4> 
<ul><li>intro: North Carolina State University &amp; Alibaba</li><li>keywords: AND-OR Graph (AOG)</li><li>arxiv: https://arxiv.org/abs/1711.05226</li></ul> 
<h4><a id="AAAI2019Object_Detection_based_on_Region_Decomposition_and_Assembly_159"></a>[AAAI2019]Object Detection based on Region Decomposition and Assembly</h4> 
<ul><li>intro: AAAI2019,区域分解组装</li><li>arxiv: https://arxiv.org/abs/1901.08225</li><li>translate: https://zhuanlan.zhihu.com/p/58951221 论文翻译</li></ul> 
<hr> 
<h3><a id="LightHead_RCNN_167"></a>Light-Head R-CNN</h3> 
<h4><a id="LightHead_RCNN_In_Defense_of_TwoStage_Object_Detector_168"></a>Light-Head R-CNN: In Defense of Two-Stage Object Detector</h4> 
<ul><li>intro: Tsinghua University &amp; Megvii Inc</li><li>arxiv: https://arxiv.org/abs/1711.07264</li><li>github(official, Tensorflow): https://github.com/zengarden/light_head_rcnn</li><li>github: https://github.com/terrychenism/Deformable-ConvNets/blob/master/rfcn/symbols/resnet_v1_101_rfcn_light.py#L784</li></ul> 
<p>##Cascade R-CNN</p> 
<h4><a id="Cascade_RCNN_Delving_into_High_Quality_Object_Detection_176"></a>Cascade R-CNN: Delving into High Quality Object Detection</h4> 
<ul><li>intro: CVPR 2018. UC San Diego</li><li>arxiv: https://arxiv.org/abs/1712.00726</li><li>github(Caffe, official): https://github.com/zhaoweicai/cascade-rcnn</li></ul> 
<hr> 
<h3><a id="MultiBox_184"></a>MultiBox</h3> 
<h4><a id="Scalable_Object_Detection_using_Deep_Neural_Networks_185"></a>Scalable Object Detection using Deep Neural Networks</h4> 
<ul><li>intro: first MultiBox. Train a CNN to predict Region of Interest.</li><li>arxiv: http://arxiv.org/abs/1312.2249</li><li>github: https://github.com/google/multibox</li><li>blog: https://research.googleblog.com/2014/12/high-quality-object-detection-at-scale.html</li></ul> 
<h4><a id="Scalable_HighQuality_Object_Detection_192"></a>Scalable, High-Quality Object Detection</h4> 
<ul><li>intro: second MultiBox</li><li>arxiv: http://arxiv.org/abs/1412.1441</li><li>github: https://github.com/google/multibox</li></ul> 
<hr> 
<h3><a id="SPPNet_200"></a>SPP-Net</h3> 
<h4><a id="Spatial_Pyramid_Pooling_in_Deep_Convolutional_Networks_for_Visual_Recognition_201"></a>Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition</h4> 
<ul><li>intro: ECCV 2014 / TPAMI 2015</li><li>arxiv: http://arxiv.org/abs/1406.4729</li><li>github: https://github.com/ShaoqingRen/SPP_net</li><li>notes: http://zhangliliang.com/2014/09/13/paper-note-sppnet/</li></ul> 
<h4><a id="DeepIDNet_Deformable_Deep_Convolutional_Neural_Networks_for_Object_Detection_208"></a>DeepID-Net: Deformable Deep Convolutional Neural Networks for Object Detection</h4> 
<ul><li>intro: PAMI 2016</li><li>intro: an extension of R-CNN. box pre-training, cascade on region proposals, deformation layers and context representations</li><li>project page: http://www.ee.cuhk.edu.hk/%CB%9Cwlouyang/projects/imagenetDeepId/index.html</li><li>arxiv: http://arxiv.org/abs/1412.5661</li></ul> 
<h4><a id="Object_Detectors_Emerge_in_Deep_Scene_CNNs_215"></a>Object Detectors Emerge in Deep Scene CNNs</h4> 
<ul><li>intro: ICLR 2015</li><li>arxiv: http://arxiv.org/abs/1412.6856</li><li>paper: https://www.robots.ox.ac.uk/~vgg/rg/papers/zhou_iclr15.pdf</li><li>paper: https://people.csail.mit.edu/khosla/papers/iclr2015_zhou.pdf</li><li>slides: http://places.csail.mit.edu/slide_iclr2015.pdf</li></ul> 
<h4><a id="segDeepM_Exploiting_Segmentation_and_Context_in_Deep_Neural_Networks_for_Object_Detection_223"></a>segDeepM: Exploiting Segmentation and Context in Deep Neural Networks for Object Detection</h4> 
<ul><li>intro: CVPR 2015</li><li>project(code+data): https://www.cs.toronto.edu/~yukun/segdeepm.html</li><li>arxiv: https://arxiv.org/abs/1502.04275</li><li>github: https://github.com/YknZhu/segDeepM</li></ul> 
<h4><a id="Object_Detection_Networks_on_Convolutional_Feature_Maps_230"></a>Object Detection Networks on Convolutional Feature Maps</h4> 
<ul><li>intro: TPAMI 2015</li><li>keywords: NoC</li><li>arxiv: http://arxiv.org/abs/1504.06066</li></ul> 
<h4><a id="Improving_Object_Detection_with_Deep_Convolutional_Networks_via_Bayesian_Optimization_and_Structured_Prediction_236"></a>Improving Object Detection with Deep Convolutional Networks via Bayesian Optimization and Structured Prediction</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1504.03293</li><li>slides: http://www.ytzhang.net/files/publications/2015-cvpr-det-slides.pdf</li><li>github: https://github.com/YutingZhang/fgs-obj</li></ul> 
<h4><a id="DeepBox_Learning_Objectness_with_Convolutional_Networks_242"></a>DeepBox: Learning Objectness with Convolutional Networks</h4> 
<ul><li>keywords: DeepBox</li><li>arxiv: http://arxiv.org/abs/1505.02146</li><li>github: https://github.com/weichengkuo/DeepBox</li></ul> 
<hr> 
<h3><a id="MRCNN_250"></a>MR-CNN</h3> 
<h4><a id="Object_detection_via_a_multiregion__semantic_segmentationaware_CNN_model_251"></a>Object detection via a multi-region &amp; semantic segmentation-aware CNN model</h4> 
<ul><li>intro: ICCV 2015. MR-CNN</li><li>arxiv: http://arxiv.org/abs/1505.01749</li><li>github: https://github.com/gidariss/mrcnn-object-detection</li><li>notes: http://zhangliliang.com/2015/05/17/paper-note-ms-cnn/</li><li>notes: http://blog.cvmarcher.com/posts/2015/05/17/multi-region-semantic-segmentation-aware-cnn/</li></ul> 
<hr> 
<h3><a id="YOLO_261"></a>YOLO</h3> 
<h4><a id="You_Only_Look_Once_Unified_RealTime_Object_Detection_262"></a>You Only Look Once: Unified, Real-Time Object Detection</h4> 
<p><img src="https://images2.imgbox.com/d0/0b/68Fq5rP4_o.png" alt="这里写图片描述"></p> 
<ul><li>arxiv: http://arxiv.org/abs/1506.02640</li><li>code: http://pjreddie.com/darknet/yolo/</li><li>github: https://github.com/pjreddie/darknet</li><li>blog: https://pjreddie.com/publications/yolo/</li><li>slides: https://docs.google.com/presentation/d/1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA/pub?start=false&amp;loop=false&amp;delayms=3000&amp;slide=id.p</li><li>reddit: https://www.reddit.com/r/MachineLearning/comments/3a3m0o/realtime_object_detection_with_yolo/</li><li>github: https://github.com/gliese581gg/YOLO_tensorflow</li><li>github: https://github.com/xingwangsfu/caffe-yolo</li><li>github: https://github.com/frankzhangrui/Darknet-Yolo</li><li>github: https://github.com/BriSkyHekun/py-darknet-yolo</li><li>github: https://github.com/tommy-qichang/yolo.torch</li><li>github: https://github.com/frischzenger/yolo-windows</li><li>github: https://github.com/AlexeyAB/yolo-windows</li><li>github: https://github.com/nilboy/tensorflow-yolo</li></ul> 
<h4><a id="darkflow__translate_darknet_to_tensorflow_Load_trained_weights_retrainfinetune_them_using_tensorflow_export_constant_graph_def_to_C_279"></a>darkflow - translate darknet to tensorflow. Load trained weights, retrain/fine-tune them using tensorflow, export constant graph def to C++</h4> 
<ul><li>blog: https://thtrieu.github.io/notes/yolo-tensorflow-graph-buffer-cpp</li><li>github: https://github.com/thtrieu/darkflow</li></ul> 
<h4><a id="Start_Training_YOLO_with_Our_Own_Data_284"></a>Start Training YOLO with Our Own Data</h4> 
<p><img src="https://images2.imgbox.com/7a/bf/YQIAJehP_o.jpg" alt="这里写图片描述"></p> 
<ul><li>intro: train with customized data and class numbers/labels. Linux / Windows version for darknet.</li><li>blog: http://guanghan.info/blog/en/my-works/train-yolo/</li><li>github: https://github.com/Guanghan/darknet</li></ul> 
<h4><a id="YOLO_Core_ML_versus_MPSNNGraph_290"></a>YOLO: Core ML versus MPSNNGraph</h4> 
<ul><li>intro: Tiny YOLO for iOS implemented using CoreML but also using the new MPS graph API.</li><li>blog: http://machinethink.net/blog/yolo-coreml-versus-mps-graph/</li><li>github: https://github.com/hollance/YOLO-CoreML-MPSNNGraph</li></ul> 
<h4><a id="TensorFlow_YOLO_object_detection_on_Android_296"></a>TensorFlow YOLO object detection on Android</h4> 
<ul><li>intro: Real-time object detection on Android using the YOLO network with TensorFlow</li><li>github: https://github.com/natanielruiz/android-yolo</li></ul> 
<h4><a id="Computer_Vision_in_iOS__Object_Detection_301"></a>Computer Vision in iOS – Object Detection</h4> 
<ul><li>blog: https://sriraghu.com/2017/07/12/computer-vision-in-ios-object-detection/</li><li>github:https://github.com/r4ghu/iOS-CoreML-Yolo</li></ul> 
<hr> 
<h3><a id="YOLOv2_307"></a>YOLOv2</h3> 
<h4><a id="YOLO9000_Better_Faster_Stronger_308"></a>YOLO9000: Better, Faster, Stronger</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1612.08242</li><li>code: http://pjreddie.com/yolo9000/</li><li>github(Chainer): https://github.com/leetenki/YOLOv2</li><li>github(Keras): https://github.com/allanzelener/YAD2K</li><li>github(PyTorch): https://github.com/longcw/yolo2-pytorch</li><li>github(Tensorflow): https://github.com/hizhangp/yolo_tensorflow</li><li>github(Windows): https://github.com/AlexeyAB/darknet</li><li>github: https://github.com/choasUp/caffe-yolo9000</li><li>github: https://github.com/philipperemy/yolo-9000</li></ul> 
<h4><a id="darknet_scripts_320"></a>darknet_scripts</h4> 
<ul><li>intro: Auxilary scripts to work with (YOLO) darknet deep learning famework. AKA -&gt; How to generate YOLO anchors?</li><li>github: https://github.com/Jumabek/darknet_scripts</li></ul> 
<h4><a id="Yolo_mark_GUI_for_marking_bounded_boxes_of_objects_in_images_for_training_Yolo_v2_325"></a>Yolo_mark: GUI for marking bounded boxes of objects in images for training Yolo v2</h4> 
<ul><li>github: https://github.com/AlexeyAB/Yolo_mark</li></ul> 
<h4><a id="LightNet_Bringing_pjreddies_DarkNet_out_of_the_shadows_329"></a>LightNet: Bringing pjreddie’s DarkNet out of the shadows</h4> 
<ul><li>github: https://github.com//explosion/lightnet</li></ul> 
<h4><a id="YOLO_v2_Bounding_Box_Tool_333"></a>YOLO v2 Bounding Box Tool</h4> 
<ul><li>intro: Bounding box labeler tool to generate the training data in the format YOLO v2 requires.</li><li>github: https://github.com/Cartucho/yolo-boundingbox-labeler-GUI</li></ul> 
<hr> 
<h3><a id="YOLOv3_339"></a>YOLOv3</h3> 
<h4><a id="YOLOv3_An_Incremental_Improvement_340"></a>YOLOv3: An Incremental Improvement</h4> 
<ul><li>project page: https://pjreddie.com/darknet/yolo/</li><li>arxiv: https://arxiv.org/abs/1804.02767</li><li>github: https://github.com/DeNA/PyTorch_YOLOv3</li><li>github: https://github.com/eriklindernoren/PyTorch-YOLOv3</li></ul> 
<h4><a id="YOLOLITE_A_RealTime_Object_Detection_Algorithm_Optimized_for_NonGPU_Computers_347"></a>YOLO-LITE: A Real-Time Object Detection Algorithm Optimized for Non-GPU Computers</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.05588</li></ul> 
<hr> 
<h4><a id="AttentionNet_Aggregating_Weak_Directions_for_Accurate_Object_Detection_352"></a>AttentionNet: Aggregating Weak Directions for Accurate Object Detection</h4> 
<ul><li>intro: ICCV 2015</li><li>intro: state-of-the-art performance of 65% (AP) on PASCAL VOC 2007/2012 human detection task</li><li>arxiv: http://arxiv.org/abs/1506.07704</li><li>slides: https://www.robots.ox.ac.uk/~vgg/rg/slides/AttentionNet.pdf</li><li>slides: http://image-net.org/challenges/talks/lunit-kaist-slide.pdf</li></ul> 
<hr> 
<h3><a id="DenseBox_362"></a>DenseBox</h3> 
<h4><a id="DenseBox_Unifying_Landmark_Localization_with_End_to_End_Object_Detection_363"></a>DenseBox: Unifying Landmark Localization with End to End Object Detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1509.04874</li><li>demo: http://pan.baidu.com/s/1mgoWWsS</li><li>KITTI result: http://www.cvlibs.net/datasets/kitti/eval_object.php</li></ul> 
<hr> 
<h3><a id="SSD_370"></a>SSD</h3> 
<h4><a id="SSD_Single_Shot_MultiBox_Detector_371"></a>SSD: Single Shot MultiBox Detector</h4> 
<p><img src="https://images2.imgbox.com/c0/a6/knm8nu0A_o.png" alt="这里写图片描述"></p> 
<ul><li>intro: ECCV 2016 Oral</li><li>arxiv: http://arxiv.org/abs/1512.02325</li><li>paper: http://www.cs.unc.edu/~wliu/papers/ssd.pdf</li><li>slides: http://www.cs.unc.edu/%7Ewliu/papers/ssd_eccv2016_slide.pdf</li><li>github(Official): https://github.com/weiliu89/caffe/tree/ssd</li><li>video: http://weibo.com/p/2304447a2326da963254c963c97fb05dd3a973</li><li>github: https://github.com/zhreshold/mxnet-ssd</li><li>github: https://github.com/zhreshold/mxnet-ssd.cpp</li><li>github: https://github.com/rykov8/ssd_keras</li><li>github: https://github.com/balancap/SSD-Tensorflow</li><li>github: https://github.com/amdegroot/ssd.pytorch</li><li>github(Caffe): https://github.com/chuanqi305/MobileNet-SSD<br> What’s the diffience in performance between this new code you pushed and the previous code? #327<br> https://github.com/weiliu89/caffe/issues/327</li></ul> 
<hr> 
<h3><a id="DSSD_389"></a>DSSD</h3> 
<h4><a id="DSSD__Deconvolutional_Single_Shot_Detector_390"></a>DSSD : Deconvolutional Single Shot Detector</h4> 
<ul><li>intro: UNC Chapel Hill &amp; Amazon Inc</li><li>arxiv: https://arxiv.org/abs/1701.06659</li><li>github: https://github.com/chengyangfu/caffe/tree/dssd</li><li>github: https://github.com/MTCloudVision/mxnet-dssd</li><li>demo: http://120.52.72.53/www.cs.unc.edu/c3pr90ntc0td/~cyfu/dssd_lalaland.mp4</li></ul> 
<h4><a id="Enhancement_of_SSD_by_concatenating_feature_maps_for_object_detection_398"></a>Enhancement of SSD by concatenating feature maps for object detection</h4> 
<ul><li>intro: rainbow SSD (R-SSD)</li><li>arxiv: https://arxiv.org/abs/1705.09587</li></ul> 
<h4><a id="Contextaware_SingleShot_Detector_403"></a>Context-aware Single-Shot Detector</h4> 
<ul><li>keywords: CSSD, DiCSSD, DeCSSD, effective receptive fields (ERFs), theoretical receptive fields (TRFs)</li><li>arxiv: https://arxiv.org/abs/1707.08682</li></ul> 
<h4><a id="FeatureFused_SSD_Fast_Detection_for_Small_Objects_408"></a>Feature-Fused SSD: Fast Detection for Small Objects</h4> 
<p>https://arxiv.org/abs/1709.05054</p> 
<hr> 
<h3><a id="FSSD_413"></a>FSSD</h3> 
<h4><a id="FSSD_Feature_Fusion_Single_Shot_Multibox_Detector_414"></a>FSSD: Feature Fusion Single Shot Multibox Detector</h4> 
<p>https://arxiv.org/abs/1712.00960</p> 
<h4><a id="Weaving_Multiscale_Context_for_Single_Shot_Detector_418"></a>Weaving Multi-scale Context for Single Shot Detector</h4> 
<ul><li>intro: WeaveNet</li><li>keywords: fuse multi-scale information</li><li>arxiv: https://arxiv.org/abs/1712.03149</li></ul> 
<hr> 
<h3><a id="ESSD_425"></a>ESSD</h3> 
<h4><a id="Extend_the_shallow_part_of_Single_Shot_MultiBox_Detector_via_Convolutional_Neural_Network_426"></a>Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1801.05918</li></ul> 
<h4><a id="Tiny_SSD_A_Tiny_Singleshot_Detection_Deep_Convolutional_Neural_Network_for_Realtime_Embedded_Object_Detection_430"></a>Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1802.06488</li></ul> 
<h4><a id="MDSSD_Multiscale_Deconvolutional_Single_Shot_Detector_for_small_objects_434"></a>MDSSD: Multi-scale Deconvolutional Single Shot Detector for small objects</h4> 
<ul><li>intro: Zhengzhou University</li><li>arxiv: https://arxiv.org/abs/1805.07009</li></ul> 
<hr> 
<h3><a id="InsideOutside_Net_ION_440"></a>Inside-Outside Net (ION)</h3> 
<h4><a id="InsideOutside_Net_Detecting_Objects_in_Context_with_Skip_Pooling_and_Recurrent_Neural_Networks_441"></a>Inside-Outside Net: Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks</h4> 
<ul><li>intro: “0.8s per image on a Titan X GPU (excluding proposal generation) without two-stage bounding-box regression and 1.15s per image with it”.</li><li>arxiv: http://arxiv.org/abs/1512.04143</li><li>slides: http://www.seanbell.ca/tmp/ion-coco-talk-bell2015.pdf</li><li>coco-leaderboard: http://mscoco.org/dataset/#detections-leaderboard</li></ul> 
<h4><a id="Adaptive_Object_Detection_Using_Adjacency_and_Zoom_Prediction_448"></a>Adaptive Object Detection Using Adjacency and Zoom Prediction</h4> 
<ul><li>intro: CVPR 2016. AZ-Net</li><li>arxiv: http://arxiv.org/abs/1512.07711</li><li>github: https://github.com/luyongxi/az-net</li><li>youtube: https://www.youtube.com/watch?v=YmFtuNwxaNM</li></ul> 
<h4><a id="GCNN_an_Iterative_Grid_Based_Object_Detector_455"></a>G-CNN: an Iterative Grid Based Object Detector</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1512.07729</li></ul> 
<hr> 
<h3><a id="Factors_in_Finetuning_Deep_Model_for_object_detection_460"></a>Factors in Finetuning Deep Model for object detection</h3> 
<h4><a id="Factors_in_Finetuning_Deep_Model_for_Object_Detection_with_Longtail_Distribution_461"></a>Factors in Finetuning Deep Model for Object Detection with Long-tail Distribution</h4> 
<ul><li>intro: CVPR 2016.rank 3rd for provided data and 2nd for external data on ILSVRC 2015 object detection</li><li>project page: http://www.ee.cuhk.edu.hk/~wlouyang/projects/ImageNetFactors/CVPR16.html</li><li>arxiv: http://arxiv.org/abs/1601.05150</li></ul> 
<h4><a id="We_dont_need_no_boundingboxes_Training_object_class_detectors_using_only_human_verification_467"></a>We don’t need no bounding-boxes: Training object class detectors using only human verification</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1602.08405</li></ul> 
<h4><a id="HyperNet_Towards_Accurate_Region_Proposal_Generation_and_Joint_Object_Detection_472"></a>HyperNet: Towards Accurate Region Proposal Generation and Joint Object Detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1604.00600</li></ul> 
<h4><a id="A_MultiPath_Network_for_Object_Detection_477"></a>A MultiPath Network for Object Detection</h4> 
<ul><li>intro: BMVC 2016. Facebook AI Research (FAIR)</li><li>arxiv: http://arxiv.org/abs/1604.02135</li><li>github: https://github.com/facebookresearch/multipathnet</li></ul> 
<hr> 
<h3><a id="CRAFT_484"></a>CRAFT</h3> 
<h4><a id="CRAFT_Objects_from_Images_485"></a>CRAFT Objects from Images</h4> 
<ul><li>intro: CVPR 2016. Cascade Region-proposal-network And FasT-rcnn. an extension of Faster R-CNN</li><li>project page: http://byangderek.github.io/projects/craft.html</li><li>arxiv: https://arxiv.org/abs/1604.03239</li><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Yang_CRAFT_Objects_From_CVPR_2016_paper.pdf</li><li>github: https://github.com/byangderek/CRAFT</li></ul> 
<hr> 
<h3><a id="OHEM_494"></a>OHEM</h3> 
<h4><a id="Training_Regionbased_Object_Detectors_with_Online_Hard_Example_Mining_495"></a>Training Region-based Object Detectors with Online Hard Example Mining</h4> 
<ul><li>intro: CVPR 2016 Oral. Online hard example mining (OHEM)</li><li>arxiv: http://arxiv.org/abs/1604.03540</li><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Shrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf</li><li>github(Official): https://github.com/abhi2610/ohem</li><li>author page: http://abhinav-shrivastava.info/</li></ul> 
<h4><a id="SOHEM_Stratified_Online_Hard_Example_Mining_for_Object_Detection_503"></a>S-OHEM: Stratified Online Hard Example Mining for Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1705.02233</li></ul> 
<h4><a id="Exploit_All_the_Layers_Fast_and_Accurate_CNN_Object_Detector_with_Scale_Dependent_Pooling_and_Cascaded_Rejection_Classifiers_507"></a>Exploit All the Layers: Fast and Accurate CNN Object Detector with Scale Dependent Pooling and Cascaded Rejection Classifiers</h4> 
<ul><li>intro: CVPR 2016</li><li>keywords: scale-dependent pooling (SDP), cascaded rejection classifiers (CRC)</li><li>paper: http://www-personal.umich.edu/~wgchoi/SDP-CRC_camready.pdf</li></ul> 
<hr> 
<h3><a id="RFCN_514"></a>R-FCN</h3> 
<h4><a id="RFCN_Object_Detection_via_Regionbased_Fully_Convolutional_Networks_515"></a>R-FCN: Object Detection via Region-based Fully Convolutional Networks</h4> 
<p>arxiv: http://arxiv.org/abs/1605.06409<br> github: https://github.com/daijifeng001/R-FCN<br> github(MXNet): https://github.com/msracver/Deformable-ConvNets/tree/master/rfcn<br> github: https://github.com/Orpine/py-R-FCN<br> github: https://github.com/PureDiors/pytorch_RFCN<br> github: https://github.com/bharatsingh430/py-R-FCN-multiGPU<br> github: https://github.com/xdever/RFCN-tensorflow</p> 
<h4><a id="RFCN3000_at_30fps_Decoupling_Detection_and_Classification_524"></a>R-FCN-3000 at 30fps: Decoupling Detection and Classification</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.01802</li></ul> 
<h4><a id="Recycle_deep_features_for_better_object_detection_528"></a>Recycle deep features for better object detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1607.05066</li></ul> 
<hr> 
<h3><a id="MSCNN_533"></a>MS-CNN</h3> 
<h4><a id="A_Unified_Multiscale_Deep_Convolutional_Neural_Network_for_Fast_Object_Detection_534"></a>A Unified Multi-scale Deep Convolutional Neural Network for Fast Object Detection</h4> 
<ul><li>intro: ECCV 2016</li><li>intro: 640×480: 15 fps, 960×720: 8 fps</li><li>arxiv: http://arxiv.org/abs/1607.07155</li><li>github: https://github.com/zhaoweicai/mscnn</li><li>poster: http://www.eccv2016.org/files/posters/P-2B-38.pdf</li></ul> 
<h4><a id="Multistage_Object_Detection_with_Group_Recursive_Learning_542"></a>Multi-stage Object Detection with Group Recursive Learning</h4> 
<ul><li>intro: VOC2007: 78.6%, VOC2012: 74.9%</li><li>arxiv: http://arxiv.org/abs/1608.05159</li></ul> 
<h4><a id="Subcategoryaware_Convolutional_Neural_Networks_for_Object_Proposals_and_Detection_547"></a>Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection</h4> 
<ul><li>intro: WACV 2017. SubCNN</li><li>arxiv: http://arxiv.org/abs/1604.04693</li><li>github: https://github.com/tanshen/SubCNN</li></ul> 
<hr> 
<h3><a id="PVANET_554"></a>PVANET</h3> 
<h4><a id="PVANet_Lightweight_Deep_Neural_Networks_for_Realtime_Object_Detection_555"></a>PVANet: Lightweight Deep Neural Networks for Real-time Object Detection</h4> 
<ul><li>intro: Presented at NIPS 2016 Workshop on Efficient Methods for Deep Neural Networks (EMDNN). Continuation of arXiv:1608.08021</li><li>arxiv: https://arxiv.org/abs/1611.08588</li><li>github: https://github.com/sanghoon/pva-faster-rcnn</li><li>leaderboard(PVANet 9.0): http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=4</li></ul> 
<hr> 
<h3><a id="GBDNet_563"></a>GBD-Net</h3> 
<h4><a id="Gated_Bidirectional_CNN_for_Object_Detection_564"></a>Gated Bi-directional CNN for Object Detection</h4> 
<ul><li>intro: The Chinese University of Hong Kong &amp; Sensetime Group Limited</li><li>paper: http://link.springer.com/chapter/10.1007/978-3-319-46478-7_22</li><li>mirror: https://pan.baidu.com/s/1dFohO7v</li></ul> 
<h4><a id="Crafting_GBDNet_for_Object_Detection_570"></a>Crafting GBD-Net for Object Detection</h4> 
<ul><li>intro: winner of the ImageNet object detection challenge of 2016. CUImage and CUVideo</li><li>intro: gated bi-directional CNN (GBD-Net)</li><li>arxiv: https://arxiv.org/abs/1610.02579</li><li>github: https://github.com/craftGBD/craftGBD</li></ul> 
<h4><a id="StuffNet_Using_Stuff_to_Improve_Object_Detection_578"></a>StuffNet: Using ‘Stuff’ to Improve Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1610.05861</li></ul> 
<h4><a id="Generalized_Haar_Filter_based_Deep_Networks_for_RealTime_Object_Detection_in_Traffic_Scene_583"></a>Generalized Haar Filter based Deep Networks for Real-Time Object Detection in Traffic Scene</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1610.09609</li></ul> 
<h4><a id="Hierarchical_Object_Detection_with_Deep_Reinforcement_Learning_588"></a>Hierarchical Object Detection with Deep Reinforcement Learning</h4> 
<ul><li>intro: Deep Reinforcement Learning Workshop (NIPS 2016)</li><li>project page: https://imatge-upc.github.io/detection-2016-nipsws/</li><li>arxiv: https://arxiv.org/abs/1611.03718</li><li>slides: http://www.slideshare.net/xavigiro/hierarchical-object-detection-with-deep-reinforcement-learning</li><li>github: https://github.com/imatge-upc/detection-2016-nipsws</li><li>blog: http://jorditorres.org/nips/</li></ul> 
<h4><a id="Learning_to_detect_and_localize_many_objects_from_few_examples_598"></a>Learning to detect and localize many objects from few examples</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1611.05664</li></ul> 
<h4><a id="Speedaccuracy_tradeoffs_for_modern_convolutional_object_detectors_603"></a>Speed/accuracy trade-offs for modern convolutional object detectors</h4> 
<ul><li>intro: CVPR 2017. Google Research</li><li>arxiv: https://arxiv.org/abs/1611.10012</li></ul> 
<h4><a id="SqueezeDet_Unified_Small_Low_Power_Fully_Convolutional_Neural_Networks_for_RealTime_Object_Detection_for_Autonomous_Driving_609"></a>SqueezeDet: Unified, Small, Low Power Fully Convolutional Neural Networks for Real-Time Object Detection for Autonomous Driving</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1612.01051</li><li>github: https://github.com/BichenWuUCB/squeezeDet</li><li>github: https://github.com/fregu856/2D_detection</li></ul> 
<hr> 
<h3><a id="Feature_Pyramid_Network_FPN_616"></a>Feature Pyramid Network (FPN)</h3> 
<h4><a id="Feature_Pyramid_Networks_for_Object_Detection_617"></a>Feature Pyramid Networks for Object Detection</h4> 
<ul><li>intro: Facebook AI Research</li><li>arxiv: https://arxiv.org/abs/1612.03144</li></ul> 
<h4><a id="ActionDriven_Object_Detection_with_TopDown_Visual_Attentions_623"></a>Action-Driven Object Detection with Top-Down Visual Attentions</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1612.06704</li></ul> 
<h4><a id="Beyond_Skip_Connections_TopDown_Modulation_for_Object_Detection_627"></a>Beyond Skip Connections: Top-Down Modulation for Object Detection</h4> 
<ul><li>intro: CMU &amp; UC Berkeley &amp; Google Research</li><li>arxiv: https://arxiv.org/abs/1612.06851</li></ul> 
<h4><a id="WideResidualInception_Networks_for_Realtime_Object_Detection_632"></a>Wide-Residual-Inception Networks for Real-time Object Detection</h4> 
<ul><li>intro: Inha University</li><li>arxiv: https://arxiv.org/abs/1702.01243</li></ul> 
<h4><a id="Attentional_Network_for_Visual_Object_Detection_637"></a>Attentional Network for Visual Object Detection</h4> 
<ul><li>intro: University of Maryland &amp; Mitsubishi Electric Research Laboratories</li><li>arxiv: https://arxiv.org/abs/1702.01478</li></ul> 
<h4><a id="Learning_Chained_Deep_Features_and_Classifiers_for_Cascade_in_Object_Detection_642"></a>Learning Chained Deep Features and Classifiers for Cascade in Object Detection</h4> 
<ul><li>keykwords: CC-Net</li><li>intro: chained cascade network (CC-Net). 81.1% mAP on PASCAL VOC 2007</li><li>arxiv: https://arxiv.org/abs/1702.07054</li></ul> 
<h4><a id="DeNet_Scalable_Realtime_Object_Detection_with_Directed_Sparse_Sampling_649"></a>DeNet: Scalable Real-time Object Detection with Directed Sparse Sampling</h4> 
<ul><li>intro: ICCV 2017 (poster)</li><li>arxiv: https://arxiv.org/abs/1703.10295</li></ul> 
<h4><a id="Discriminative_Bimodal_Networks_for_Visual_Localization_and_Detection_with_Natural_Language_Queries_655"></a>Discriminative Bimodal Networks for Visual Localization and Detection with Natural Language Queries</h4> 
<ul><li>intro: CVPR 2017</li><li>arxiv: https://arxiv.org/abs/1704.03944</li></ul> 
<h4><a id="Spatial_Memory_for_Context_Reasoning_in_Object_Detection_661"></a>Spatial Memory for Context Reasoning in Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1704.04224</li></ul> 
<h4><a id="Accurate_Single_Stage_Detector_Using_Recurrent_Rolling_Convolution_666"></a>Accurate Single Stage Detector Using Recurrent Rolling Convolution</h4> 
<ul><li>intro: CVPR 2017. SenseTime</li><li>keywords: Recurrent Rolling Convolution (RRC)</li><li>arxiv: https://arxiv.org/abs/1704.05776</li><li>github: https://github.com/xiaohaoChen/rrc_detection</li></ul> 
<h4><a id="Deep_Occlusion_Reasoning_for_MultiCamera_MultiTarget_Detection_674"></a>Deep Occlusion Reasoning for Multi-Camera Multi-Target Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1704.05775</li></ul> 
<h4><a id="LCDet_LowComplexity_FullyConvolutional_Neural_Networks_for_Object_Detection_in_Embedded_Systems_678"></a>LCDet: Low-Complexity Fully-Convolutional Neural Networks for Object Detection in Embedded Systems</h4> 
<ul><li>intro: Embedded Vision Workshop in CVPR. UC San Diego &amp; Qualcomm Inc</li><li>arxiv: https://arxiv.org/abs/1705.05922</li></ul> 
<h4><a id="Point_Linking_Network_for_Object_Detection_684"></a>Point Linking Network for Object Detection</h4> 
<ul><li>intro: Point Linking Network (PLN)</li><li>arxiv: https://arxiv.org/abs/1706.03646</li></ul> 
<h4><a id="Perceptual_Generative_Adversarial_Networks_for_Small_Object_Detection_690"></a>Perceptual Generative Adversarial Networks for Small Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.05274</li></ul> 
<h4><a id="Fewshot_Object_Detection_694"></a>Few-shot Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.08249</li></ul> 
<h4><a id="YesNet_An_effective_Detector_Based_on_Global_Information_698"></a>Yes-Net: An effective Detector Based on Global Information</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.09180</li></ul> 
<h4><a id="SMC_Faster_RCNN_Toward_a_scenespecialized_multiobject_detector_702"></a>SMC Faster R-CNN: Toward a scene-specialized multi-object detector</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.10217</li></ul> 
<h4><a id="Towards_lightweight_convolutional_neural_networks_for_object_detection_706"></a>Towards lightweight convolutional neural networks for object detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1707.01395</li></ul> 
<h4><a id="RON_Reverse_Connection_with_Objectness_Prior_Networks_for_Object_Detection_710"></a>RON: Reverse Connection with Objectness Prior Networks for Object Detection</h4> 
<ul><li>intro: CVPR 2017</li><li>arxiv: https://arxiv.org/abs/1707.01691</li><li>github: https://github.com/taokong/RON</li></ul> 
<h4><a id="Mimicking_Very_Efficient_Network_for_Object_Detection_717"></a>Mimicking Very Efficient Network for Object Detection</h4> 
<ul><li>intro: CVPR 2017. SenseTime &amp; Beihang University</li><li>paper: http://openaccess.thecvf.com/content_cvpr_2017/papers/Li_Mimicking_Very_Efficient_CVPR_2017_paper.pdf</li></ul> 
<h4><a id="Residual_Features_and_Unified_Prediction_Network_for_Single_Stage_Detection_722"></a>Residual Features and Unified Prediction Network for Single Stage Detection</h4> 
<p>https://arxiv.org/abs/1707.05031</p> 
<h4><a id="Deformable_Partbased_Fully_Convolutional_Network_for_Object_Detection_726"></a>Deformable Part-based Fully Convolutional Network for Object Detection</h4> 
<ul><li>intro: BMVC 2017 (oral). Sorbonne Universités &amp; CEDRIC</li><li>arxiv: https://arxiv.org/abs/1707.06175</li></ul> 
<h4><a id="Adaptive_Feeding_Achieving_Fast_and_Accurate_Detections_by_Adaptively_Combining_Object_Detectors_731"></a>Adaptive Feeding: Achieving Fast and Accurate Detections by Adaptively Combining Object Detectors</h4> 
<ul><li>intro: ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1707.06399</li></ul> 
<h4><a id="Recurrent_Scale_Approximation_for_Object_Detection_in_CNN_736"></a>Recurrent Scale Approximation for Object Detection in CNN</h4> 
<ul><li>intro: ICCV 2017</li><li>keywords: Recurrent Scale Approximation (RSA)</li><li>arxiv: https://arxiv.org/abs/1707.09531</li><li>github: https://github.com/sciencefans/RSA-for-object-detection</li></ul> 
<hr> 
<h3><a id="DSOD_744"></a>DSOD</h3> 
<h4><a id="DSOD_Learning_Deeply_Supervised_Object_Detectors_from_Scratch_745"></a>DSOD: Learning Deeply Supervised Object Detectors from Scratch</h4> 
<p><img src="https://images2.imgbox.com/9f/11/PbqNWpSk_o.png" alt="这里写图片描述"></p> 
<ul><li>intro: ICCV 2017. Fudan University &amp; Tsinghua University &amp; Intel Labs China</li><li>arxiv: https://arxiv.org/abs/1708.01241</li><li>github: https://github.com/szq0214/DSOD</li></ul> 
<h4><a id="Object_Detection_from_Scratch_with_Deep_Supervision_751"></a>Object Detection from Scratch with Deep Supervision</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1809.09294</li></ul> 
<p>##RetinaNet</p> 
<h4><a id="Focal_Loss_for_Dense_Object_Detection_756"></a>Focal Loss for Dense Object Detection</h4> 
<ul><li>intro: ICCV 2017 Best student paper award. Facebook AI Research</li><li>keywords: RetinaNet</li><li>arxiv: https://arxiv.org/abs/1708.02002</li></ul> 
<h4><a id="Focal_Loss_Dense_Detector_for_Vehicle_Surveillance_762"></a>Focal Loss Dense Detector for Vehicle Surveillance</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1803.01114</li></ul> 
<h4><a id="CoupleNet_Coupling_Global_Structure_with_Local_Parts_for_Object_Detection_766"></a>CoupleNet: Coupling Global Structure with Local Parts for Object Detection</h4> 
<ul><li>intro: ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1708.02863</li></ul> 
<h4><a id="Incremental_Learning_of_Object_Detectors_without_Catastrophic_Forgetting_771"></a>Incremental Learning of Object Detectors without Catastrophic Forgetting</h4> 
<ul><li>intro: ICCV 2017. Inria</li><li>arxiv: https://arxiv.org/abs/1708.06977</li></ul> 
<h4><a id="Zoom_OutandIn_Network_with_Map_Attention_Decision_for_Region_Proposal_and_Object_Detection_776"></a>Zoom Out-and-In Network with Map Attention Decision for Region Proposal and Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.04347</li></ul> 
<h4><a id="StairNet_TopDown_Semantic_Aggregation_for_Accurate_One_Shot_Detection_780"></a>StairNet: Top-Down Semantic Aggregation for Accurate One Shot Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.05788</li></ul> 
<h4><a id="Dynamic_Zoomin_Network_for_Fast_Object_Detection_in_Large_Images_784"></a>Dynamic Zoom-in Network for Fast Object Detection in Large Images</h4> 
<p>https://arxiv.org/abs/1711.05187</p> 
<h4><a id="ZeroAnnotation_Object_Detection_with_Web_Knowledge_Transfer_788"></a>Zero-Annotation Object Detection with Web Knowledge Transfer</h4> 
<ul><li>intro: NTU, Singapore &amp; Amazon</li><li>keywords: multi-instance multi-label domain adaption learning framework</li><li>arxiv: https://arxiv.org/abs/1711.05954</li></ul> 
<hr> 
<h3><a id="MegDet_796"></a>MegDet</h3> 
<h4><a id="MegDet_A_Large_MiniBatch_Object_Detector_797"></a>MegDet: A Large Mini-Batch Object Detector</h4> 
<ul><li>intro: Peking University &amp; Tsinghua University &amp; Megvii Inc</li><li>arxiv: https://arxiv.org/abs/1711.07240</li></ul> 
<h4><a id="SingleShot_Refinement_Neural_Network_for_Object_Detection_802"></a>Single-Shot Refinement Neural Network for Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.06897</li><li>github: https://github.com/sfzhang15/RefineDet</li><li>github: https://github.com/MTCloudVision/RefineDet-Mxnet</li></ul> 
<h4><a id="Receptive_Field_Block_Net_for_Accurate_and_Fast_Object_Detection_808"></a>Receptive Field Block Net for Accurate and Fast Object Detection</h4> 
<ul><li>intro: RFBNet</li><li>arxiv: https://arxiv.org/abs/1711.07767</li><li>github: https://github.com//ruinmessi/RFBNet</li></ul> 
<h4><a id="An_Analysis_of_Scale_Invariance_in_Object_Detection__SNIP_814"></a>An Analysis of Scale Invariance in Object Detection - SNIP</h4> 
<ul><li>intro: CVPR 2018</li><li>arxiv: https://arxiv.org/abs/1711.08189</li><li>github: https://github.com/bharatsingh430/snip</li></ul> 
<h4><a id="Feature_Selective_Networks_for_Object_Detection_820"></a>Feature Selective Networks for Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.08879</li></ul> 
<h4><a id="Learning_a_Rotation_Invariant_Detector_with_Rotatable_Bounding_Box_824"></a>Learning a Rotation Invariant Detector with Rotatable Bounding Box</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.09405</li><li>github(official, Caffe): https://github.com/liulei01/DRBox</li></ul> 
<h4><a id="Scalable_Object_Detection_for_Stylized_Objects_829"></a>Scalable Object Detection for Stylized Objects</h4> 
<ul><li>intro: Microsoft AI &amp; Research Munich</li><li>arxiv: https://arxiv.org/abs/1711.09822</li></ul> 
<h4><a id="Learning_Object_Detectors_from_Scratch_with_Gated_Recurrent_Feature_Pyramids_834"></a>Learning Object Detectors from Scratch with Gated Recurrent Feature Pyramids</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.00886</li><li>github: https://github.com/szq0214/GRP-DSOD</li></ul> 
<h4><a id="Deep_Regionlets_for_Object_Detection_839"></a>Deep Regionlets for Object Detection</h4> 
<ul><li>keywords: region selection network, gating network</li><li>arxiv: https://arxiv.org/abs/1712.02408</li></ul> 
<h4><a id="Training_and_Testing_Object_Detectors_with_Virtual_Images_844"></a>Training and Testing Object Detectors with Virtual Images</h4> 
<ul><li>intro: IEEE/CAA Journal of Automatica Sinica</li><li>arxiv: https://arxiv.org/abs/1712.08470</li></ul> 
<h4><a id="LargeScale_Object_Discovery_and_Detector_Adaptation_from_Unlabeled_Video_850"></a>Large-Scale Object Discovery and Detector Adaptation from Unlabeled Video</h4> 
<ul><li>keywords: object mining, object tracking, unsupervised object discovery by appearance-based clustering, self-supervised detector adaptation</li><li>arxiv: https://arxiv.org/abs/1712.08832</li></ul> 
<h4><a id="Spot_the_Difference_by_Object_Detection_856"></a>Spot the Difference by Object Detection</h4> 
<ul><li>intro: Tsinghua University &amp; JD Group</li><li>arxiv: https://arxiv.org/abs/1801.01051</li></ul> 
<h4><a id="LocalizationAware_Active_Learning_for_Object_Detection_861"></a>Localization-Aware Active Learning for Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1801.05124</li></ul> 
<h4><a id="Object_Detection_with_Maskbased_Feature_Encoding_866"></a>Object Detection with Mask-based Feature Encoding</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1802.03934</li></ul> 
<h4><a id="LSTD_A_LowShot_Transfer_Detector_for_Object_Detection_870"></a>LSTD: A Low-Shot Transfer Detector for Object Detection</h4> 
<ul><li>intro: AAAI 2018</li><li>arxiv: https://arxiv.org/abs/1803.01529</li></ul> 
<h4><a id="Domain_Adaptive_Faster_RCNN_for_Object_Detection_in_the_Wild_875"></a>Domain Adaptive Faster R-CNN for Object Detection in the Wild</h4> 
<ul><li>intro: CVPR 2018. ETH Zurich &amp; ESAT/PSI</li><li>arxiv: https://arxiv.org/abs/1803.03243</li><li>github(official. Caffe): https://github.com/yuhuayc/da-faster-rcnn</li></ul> 
<h4><a id="Pseudo_Mask_Augmented_Object_Detection_881"></a>Pseudo Mask Augmented Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1803.05858</li></ul> 
<h4><a id="Revisiting_RCNN_On_Awakening_the_Classification_Power_of_Faster_RCNN_885"></a>Revisiting RCNN: On Awakening the Classification Power of Faster RCNN</h4> 
<ul><li>intro: ECCV 2018</li><li>keywords: DCR V1</li><li>arxiv: https://arxiv.org/abs/1803.06799</li><li>github(official, MXNet): https://github.com/bowenc0221/Decoupled-Classification-Refinement</li></ul> 
<h4><a id="Decoupled_Classification_Refinement_Hard_False_Positive_Suppression_for_Object_Detection_891"></a>Decoupled Classification Refinement: Hard False Positive Suppression for Object Detection</h4> 
<ul><li>keywords: DCR V2</li><li>arxiv: https://arxiv.org/abs/1810.04002</li><li>github(official, MXNet): https://github.com/bowenc0221/Decoupled-Classification-Refinement</li></ul> 
<h4><a id="Learning_Region_Features_for_Object_Detection_896"></a>Learning Region Features for Object Detection</h4> 
<ul><li>intro: Peking University &amp; MSRA</li><li>arxiv: https://arxiv.org/abs/1803.07066</li></ul> 
<h4><a id="SingleShot_Bidirectional_Pyramid_Networks_for_HighQuality_Object_Detection_901"></a>Single-Shot Bidirectional Pyramid Networks for High-Quality Object Detection</h4> 
<ul><li>intro: Singapore Management University &amp; Zhejiang University</li><li>arxiv: https://arxiv.org/abs/1803.08208</li></ul> 
<h4><a id="Object_Detection_for_Comics_using_Manga109_Annotations_906"></a>Object Detection for Comics using Manga109 Annotations</h4> 
<ul><li>intro: University of Tokyo &amp; National Institute of Informatics, Japan</li><li>arxiv: https://arxiv.org/abs/1803.08670</li></ul> 
<h4><a id="TaskDriven_Super_Resolution_Object_Detection_in_Lowresolution_Images_911"></a>Task-Driven Super Resolution: Object Detection in Low-resolution Images</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1803.11316</li></ul> 
<h4><a id="Transferring_CommonSense_Knowledge_for_Object_Detection_915"></a>Transferring Common-Sense Knowledge for Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.01077</li></ul> 
<h4><a id="Multiscale_Locationaware_Kernel_Representation_for_Object_Detection_919"></a>Multi-scale Location-aware Kernel Representation for Object Detection</h4> 
<ul><li>intro: CVPR 2018</li><li>arxiv: https://arxiv.org/abs/1804.00428</li><li>github: https://github.com/Hwang64/MLKP</li></ul> 
<h4><a id="Loss_Rank_Mining_A_General_Hard_Example_Mining_Method_for_Realtime_Detectors_925"></a>Loss Rank Mining: A General Hard Example Mining Method for Real-time Detectors</h4> 
<ul><li>intro: National University of Defense Technology</li><li>arxiv: https://arxiv.org/abs/1804.04606</li></ul> 
<h4><a id="DetNet_A_Backbone_network_for_Object_Detection_930"></a>DetNet: A Backbone network for Object Detection</h4> 
<ul><li>intro: Tsinghua University &amp; Megvii Inc</li><li>arxiv: https://arxiv.org/abs/1804.06215</li></ul> 
<h4><a id="Robust_Physical_Adversarial_Attack_on_Faster_RCNN_Object_Detector_935"></a>Robust Physical Adversarial Attack on Faster R-CNN Object Detector</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.05810</li></ul> 
<h4><a id="AdvDetPatch_Attacking_Object_Detectors_with_Adversarial_Patches_939"></a>AdvDetPatch: Attacking Object Detectors with Adversarial Patches</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1806.02299</li></ul> 
<h4><a id="Attacking_Object_Detectors_via_Imperceptible_Patches_on_Background_943"></a>Attacking Object Detectors via Imperceptible Patches on Background</h4> 
<ul><li>https://arxiv.org/abs/1809.05966</li></ul> 
<h4><a id="Physical_Adversarial_Examples_for_Object_Detectors_947"></a>Physical Adversarial Examples for Object Detectors</h4> 
<ul><li>intro: WOOT 2018</li><li>arxiv: https://arxiv.org/abs/1807.07769</li></ul> 
<h4><a id="Quantization_Mimic_Towards_Very_Tiny_CNN_for_Object_Detection_952"></a>Quantization Mimic: Towards Very Tiny CNN for Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1805.02152</li></ul> 
<h4><a id="Object_detection_at_200_Frames_Per_Second_956"></a>Object detection at 200 Frames Per Second</h4> 
<ul><li>intro: United Technologies Research Center-Ireland</li><li>arxiv: https://arxiv.org/abs/1805.06361</li></ul> 
<h4><a id="Object_Detection_using_Domain_Randomization_and_Generative_Adversarial_Refinement_of_Synthetic_Images_961"></a>Object Detection using Domain Randomization and Generative Adversarial Refinement of Synthetic Images</h4> 
<ul><li>intro: CVPR 2018 Deep Vision Workshop</li><li>arxiv: https://arxiv.org/abs/1805.11778</li></ul> 
<h4><a id="SNIPER_Efficient_MultiScale_Training_966"></a>SNIPER: Efficient Multi-Scale Training</h4> 
<ul><li>intro: University of Maryland</li><li>keywords: SNIPER (Scale Normalization for Image Pyramid with Efficient Resampling)</li><li>arxiv: https://arxiv.org/abs/1805.09300</li><li>github: https://github.com/mahyarnajibi/SNIPER</li></ul> 
<h4><a id="Soft_Sampling_for_Robust_Object_Detection_972"></a>Soft Sampling for Robust Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1806.06986</li></ul> 
<h4><a id="MetaAnchor_Learning_to_Detect_Objects_with_Customized_Anchors_976"></a>MetaAnchor: Learning to Detect Objects with Customized Anchors</h4> 
<ul><li>intro: Megvii Inc (Face++) &amp; Fudan University</li><li>arxiv: https://arxiv.org/abs/1807.00980</li></ul> 
<h4><a id="Localization_Recall_Precision_LRP_A_New_Performance_Metric_for_Object_Detection_981"></a>Localization Recall Precision (LRP): A New Performance Metric for Object Detection</h4> 
<ul><li>intro: ECCV 2018. Middle East Technical University</li><li>arxiv: https://arxiv.org/abs/1807.01696</li><li>github: https://github.com/cancam/LRP</li></ul> 
<h4><a id="AutoContext_RCNN_987"></a>Auto-Context R-CNN</h4> 
<ul><li>intro: Rejected by ECCV18</li><li>arxiv: https://arxiv.org/abs/1807.02842</li></ul> 
<h4><a id="Pooling_Pyramid_Network_for_Object_Detection_992"></a>Pooling Pyramid Network for Object Detection</h4> 
<ul><li>intro: Google AI Perception</li><li>arxiv: https://arxiv.org/abs/1807.03284</li></ul> 
<h4><a id="Modeling_Visual_Context_is_Key_to_Augmenting_Object_Detection_Datasets_997"></a>Modeling Visual Context is Key to Augmenting Object Detection Datasets</h4> 
<ul><li>intro: ECCV 2018</li><li>arxiv: https://arxiv.org/abs/1807.07428</li></ul> 
<h4><a id="Dual_Refinement_Network_for_SingleShot_Object_Detection_1002"></a>Dual Refinement Network for Single-Shot Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1807.08638</li></ul> 
<h4><a id="Acquisition_of_Localization_Confidence_for_Accurate_Object_Detection_1006"></a>Acquisition of Localization Confidence for Accurate Object Detection</h4> 
<ul><li>intro: ECCV 2018</li><li>arxiv: https://arxiv.org/abs/1807.11590</li><li>gihtub: https://github.com/vacancy/PreciseRoIPooling</li></ul> 
<h4><a id="CornerNet_Detecting_Objects_as_Paired_Keypoints_1012"></a>CornerNet: Detecting Objects as Paired Keypoints</h4> 
<ul><li>intro: ECCV 2018</li><li>keywords: IoU-Net, PreciseRoIPooling</li><li>arxiv: https://arxiv.org/abs/1808.01244</li><li>github: https://github.com/umich-vl/CornerNet</li></ul> 
<h4><a id="Unsupervised_Hard_Example_Mining_from_Videos_for_Improved_Object_Detection_1019"></a>Unsupervised Hard Example Mining from Videos for Improved Object Detection</h4> 
<ul><li>intro: ECCV 2018</li><li>arxiv: https://arxiv.org/abs/1808.04285</li></ul> 
<h4><a id="SAN_Learning_Relationship_between_Convolutional_Features_for_MultiScale_Object_Detection_1025"></a>SAN: Learning Relationship between Convolutional Features for Multi-Scale Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1808.04974</li></ul> 
<h4><a id="A_Survey_of_Modern_Object_Detection_Literature_using_Deep_Learning_1029"></a>A Survey of Modern Object Detection Literature using Deep Learning</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1808.07256</li></ul> 
<h4><a id="TinyDSOD_Lightweight_Object_Detection_for_ResourceRestricted_Usages_1033"></a>Tiny-DSOD: Lightweight Object Detection for Resource-Restricted Usages</h4> 
<ul><li>intro: BMVC 2018</li><li>arxiv: https://arxiv.org/abs/1807.11013</li><li>github: https://github.com/lyxok1/Tiny-DSOD</li></ul> 
<h4><a id="Deep_Feature_Pyramid_Reconfiguration_for_Object_Detection_1038"></a>Deep Feature Pyramid Reconfiguration for Object Detection</h4> 
<ul><li>intro: ECCV 2018</li><li>arxiv: https://arxiv.org/abs/1808.07993</li></ul> 
<h4><a id="MDCN_MultiScale_Deep_Inception_Convolutional_Neural_Networks_for_Efficient_Object_Detection_1042"></a>MDCN: Multi-Scale, Deep Inception Convolutional Neural Networks for Efficient Object Detection</h4> 
<ul><li>intro: ICPR 2018</li><li>arxiv: https://arxiv.org/abs/1809.01791</li></ul> 
<h4><a id="Recent_Advances_in_Object_Detection_in_the_Age_of_Deep_Convolutional_Neural_Networks_1046"></a>Recent Advances in Object Detection in the Age of Deep Convolutional Neural Networks</h4> 
<ul><li>https://arxiv.org/abs/1809.03193</li></ul> 
<h4><a id="Deep_Learning_for_Generic_Object_Detection_A_Survey_1049"></a>Deep Learning for Generic Object Detection: A Survey</h4> 
<ul><li>https://arxiv.org/abs/1809.02165</li></ul> 
<h4><a id="Training_ConfidenceCalibrated_Classifier_for_Detecting_OutofDistribution_Samples_1052"></a>Training Confidence-Calibrated Classifier for Detecting Out-of-Distribution Samples</h4> 
<ul><li>intro: ICLR 2018</li><li>arxiv: https://github.com/alinlab/Confident_classifier</li></ul> 
<h4><a id="ScratchDetExploring_to_Train_SingleShot_Object_Detectors_from_Scratch_1056"></a>ScratchDet:Exploring to Train Single-Shot Object Detectors from Scratch</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1810.08425</li><li>github: https://github.com/KimSoybean/ScratchDet</li></ul> 
<h4><a id="Fast_and_accurate_object_detection_in_high_resolution_4K_and_8K_video_using_GPUs_1060"></a>Fast and accurate object detection in high resolution 4K and 8K video using GPUs</h4> 
<ul><li>intro: Best Paper Finalist at IEEE High Performance Extreme Computing Conference (HPEC) 2018</li><li>intro: Carnegie Mellon University</li><li>arxiv: https://arxiv.org/abs/1810.10551</li></ul> 
<h4><a id="Hybrid_Knowledge_Routed_Modules_for_Largescale_Object_Detection_1065"></a>Hybrid Knowledge Routed Modules for Large-scale Object Detection</h4> 
<ul><li>intro: NIPS 2018</li><li>arxiv: https://arxiv.org/abs/1810.12681</li><li>github(official, PyTorch): https://github.com/chanyn/HKRM</li></ul> 
<h4><a id="Gradient_Harmonized_Singlestage_Detector_1070"></a>Gradient Harmonized Single-stage Detector</h4> 
<ul><li>intro: AAAI 2019</li><li>arxiv: https://arxiv.org/abs/1811.05181</li></ul> 
<h4><a id="M2Det_A_SingleShot_Object_Detector_based_on_MultiLevel_Feature_Pyramid_Network_1074"></a>M2Det: A Single-Shot Object Detector based on Multi-Level Feature Pyramid Network</h4> 
<ul><li>intro: AAAI 2019</li><li>arxiv: https://arxiv.org/abs/1811.04533</li><li>github: https://github.com/qijiezhao/M2Det</li></ul> 
<h4><a id="BAN_Focusing_on_Boundary_Context_for_Object_Detection_1079"></a>BAN: Focusing on Boundary Context for Object Detection</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.05243</li></ul> 
<h4><a id="Multilayer_Pruning_Framework_for_Compressing_Single_Shot_MultiBox_Detector_1082"></a>Multi-layer Pruning Framework for Compressing Single Shot MultiBox Detector</h4> 
<ul><li>intro: WACV 2019</li><li>arxiv: https://arxiv.org/abs/1811.08342</li></ul> 
<h4><a id="R2CNN_MultiDimensional_Attention_Based_Rotation_Invariant_Detector_with_Robust_Anchor_Strategy_1086"></a>R2CNN++: Multi-Dimensional Attention Based Rotation Invariant Detector with Robust Anchor Strategy</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1811.07126</li><li>github: https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow</li></ul> 
<h4><a id="DeRPN_Taking_a_further_step_toward_more_general_object_detection_1090"></a>DeRPN: Taking a further step toward more general object detection</h4> 
<ul><li>intro: AAAI 2019</li><li>intro: South China University of Technology</li><li>arxiv: https://arxiv.org/abs/1811.06700</li><li>github: https://github.com/HCIILAB/DeRPN</li></ul> 
<h4><a id="Fast_Efficient_Object_Detection_Using_Selective_Attention_1096"></a>Fast Efficient Object Detection Using Selective Attention</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.07502</li></ul> 
<h4><a id="Sampling_Techniques_for_LargeScale_Object_Detection_from_Sparsely_Annotated_Objects_1100"></a>Sampling Techniques for Large-Scale Object Detection from Sparsely Annotated Objects</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.10862</li></ul> 
<h4><a id="Efficient_CoarsetoFine_NonLocal_Module_for_the_Detection_of_Small_Objects_1103"></a>Efficient Coarse-to-Fine Non-Local Module for the Detection of Small Objects</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.12152</li></ul> 
<h4><a id="Deep_Regionlets_Blended_Representation_and_Deep_Learning_for_Generic_Object_Detection_1106"></a>Deep Regionlets: Blended Representation and Deep Learning for Generic Object Detection</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.11318</li></ul> 
<h4><a id="Grid_RCNN_1110"></a>Grid R-CNN</h4> 
<ul><li>intro: SenseTime</li><li>arxiv: https://arxiv.org/abs/1811.12030</li></ul> 
<h4><a id="Transferable_Adversarial_Attacks_for_Image_and_Video_Object_Detection_1114"></a>Transferable Adversarial Attacks for Image and Video Object Detection</h4> 
<p>-arxiv：https://arxiv.org/abs/1811.12641</p> 
<h4><a id="Anchor_Box_Optimization_for_Object_Detection_1117"></a>Anchor Box Optimization for Object Detection</h4> 
<ul><li>intro: University of Illinois at Urbana-Champaign &amp; Microsoft Research</li><li>arxiv: https://arxiv.org/abs/1812.00469</li></ul> 
<h4><a id="AutoFocus_Efficient_MultiScale_Inference_1121"></a>AutoFocus: Efficient Multi-Scale Inference</h4> 
<ul><li>intro: University of Maryland</li><li>arxiv: https://arxiv.org/abs/1812.01600</li></ul> 
<p>###Few-shot Object Detection via Feature Reweighting</p> 
<ul><li>arxiv：https://arxiv.org/abs/1812.01866</li></ul> 
<h4><a id="Practical_Adversarial_Attack_Against_Object_Detector_1128"></a>Practical Adversarial Attack Against Object Detector</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1812.10217</li></ul> 
<h4><a id="Learning_Efficient_Detector_with_Semisupervised_Adaptive_Distillation_1131"></a>Learning Efficient Detector with Semi-supervised Adaptive Distillation</h4> 
<ul><li>intro: SenseTime Research</li><li>arxiv: https://arxiv.org/abs/1901.00366</li><li>github: https://github.com/Tangshitao/Semi-supervised-Adaptive-Distillation</li></ul> 
<h4><a id="ScaleAware_Trident_Networks_for_Object_Detection_1136"></a>Scale-Aware Trident Networks for Object Detection</h4> 
<p>intro: University of Chinese Academy of Sciences &amp; TuSimple<br> arxiv: https://arxiv.org/abs/1901.01892<br> github: https://github.com/TuSimple/simpledet</p> 
<h4><a id="Region_Proposal_by_Guided_Anchoring_1141"></a>Region Proposal by Guided Anchoring</h4> 
<ul><li>intro: CUHK - SenseTime Joint Lab &amp; Amazon Rekognition &amp; Nanyang Technological University</li><li>arxiv: https://arxiv.org/abs/1901.03278</li></ul> 
<h4><a id="Consistent_Optimization_for_SingleShot_Object_Detection_1145"></a>Consistent Optimization for Single-Shot Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1901.06563</li><li>blog: https://zhuanlan.zhihu.com/p/55416312</li></ul> 
<h4><a id="Bottomup_Object_Detection_by_Grouping_Extreme_and_Center_Points_1149"></a>Bottom-up Object Detection by Grouping Extreme and Center Points</h4> 
<ul><li>keywords: ExtremeNet</li><li>arxiv: https://arxiv.org/abs/1901.08043</li><li>github: https://github.com/xingyizhou/ExtremeNet</li></ul> 
<h4><a id="A_Singleshot_Object_Detector_with_Feature_Aggragation_and_Enhancement_1154"></a>A Single-shot Object Detector with Feature Aggragation and Enhancement</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1902.02923</li></ul> 
<h4><a id="Bag_of_Freebies_for_Training_Object_Detection_Neural_Networks_1157"></a>Bag of Freebies for Training Object Detection Neural Networks</h4> 
<ul><li>intro: Amazon Web Services</li><li>arxiv: https://arxiv.org/abs/1902.04103</li></ul> 
<hr> 
<h3><a id="NonMaximum_Suppression_NMS_1162"></a>Non-Maximum Suppression (NMS)</h3> 
<h4><a id="EndtoEnd_Integration_of_a_Convolutional_Network_Deformable_Parts_Model_and_NonMaximum_Suppression_1163"></a>End-to-End Integration of a Convolutional Network, Deformable Parts Model and Non-Maximum Suppression</h4> 
<ul><li>intro: CVPR 2015</li><li>arxiv: http://arxiv.org/abs/1411.5309</li><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Wan_End-to-End_Integration_of_2015_CVPR_paper.pdf</li></ul> 
<h4><a id="A_convnet_for_nonmaximum_suppression_1169"></a>A convnet for non-maximum suppression</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1511.06437<br> Improving Object Detection With One Line of Code</li></ul> 
<h4><a id="SoftNMS__Improving_Object_Detection_With_One_Line_of_Code_1174"></a>Soft-NMS – Improving Object Detection With One Line of Code</h4> 
<ul><li>intro: ICCV 2017. University of Maryland</li><li>keywords: Soft-NMS</li><li>arxiv: https://arxiv.org/abs/1704.04503</li><li>github: https://github.com/bharatsingh430/soft-nms</li></ul> 
<h4><a id="Learning_nonmaximum_suppression_1181"></a>Learning non-maximum suppression</h4> 
<ul><li>intro: CVPR 2017</li><li>project page: https://www.mpi-inf.mpg.de/departments/computer-vision-and-multimodal-computing/research/object-recognition-and-scene-understanding/learning-nms/</li><li>arxiv: https://arxiv.org/abs/1705.02950</li><li>github: https://github.com/hosang/gossipnet</li></ul> 
<h4><a id="Relation_Networks_for_Object_Detection_1189"></a>Relation Networks for Object Detection</h4> 
<ul><li>intro: CVPR 2018 oral</li><li>arxiv: https://arxiv.org/abs/1711.11575</li><li>github(official, MXNet): https://github.com/msracver/Relation-Networks-for-Object-Detection</li></ul> 
<h4><a id="Learning_Pairwise_Relationship_for_Multiobject_Detection_in_Crowded_Scenes_1194"></a>Learning Pairwise Relationship for Multi-object Detection in Crowded Scenes</h4> 
<ul><li>keywords: Pairwise-NMS</li><li>arxiv: https://arxiv.org/abs/1901.03796</li></ul> 
<h4><a id="Daedalus_Breaking_NonMaximum_Suppression_in_Object_Detection_via_Adversarial_Examples_1198"></a>Daedalus: Breaking Non-Maximum Suppression in Object Detection via Adversarial Examples</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1902.02067</li></ul> 
<hr> 
<h3><a id="Adversarial_Examples_1203"></a>Adversarial Examples</h3> 
<h4><a id="Adversarial_Examples_that_Fool_Detectors_1204"></a>Adversarial Examples that Fool Detectors</h4> 
<ul><li>intro: University of Illinois</li><li>arxiv: https://arxiv.org/abs/1712.02494</li></ul> 
<h4><a id="Adversarial_Examples_Are_Not_Easily_Detected_Bypassing_Ten_Detection_Methods_1209"></a>Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods</h4> 
<ul><li>project page: http://nicholas.carlini.com/code/nn_breaking_detection/</li><li>arxiv: https://arxiv.org/abs/1705.07263</li><li>github: https://github.com/carlini/nn_breaking_detection</li></ul> 
<hr> 
<h3><a id="Weakly_Supervised_Object_Detection_1216"></a>Weakly Supervised Object Detection</h3> 
<h4><a id="Track_and_Transfer_Watching_Videos_to_Simulate_Strong_Human_Supervision_for_WeaklySupervised_Object_Detection_1217"></a>Track and Transfer: Watching Videos to Simulate Strong Human Supervision for Weakly-Supervised Object Detection</h4> 
<ul><li>intro: CVPR 2016</li><li>arxiv: http://arxiv.org/abs/1604.05766</li></ul> 
<h4><a id="Weakly_supervised_object_detection_using_pseudostrong_labels_1222"></a>Weakly supervised object detection using pseudo-strong labels</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1607.04731</li></ul> 
<h4><a id="Saliency_Guided_EndtoEnd_Learning_for_Weakly_Supervised_Object_Detection_1226"></a>Saliency Guided End-to-End Learning for Weakly Supervised Object Detection</h4> 
<ul><li>intro: IJCAI 2017</li><li>arxiv: https://arxiv.org/abs/1706.06768</li></ul> 
<h4><a id="Visual_and_Semantic_Knowledge_Transfer_for_Large_Scale_Semisupervised_Object_Detection_1231"></a>Visual and Semantic Knowledge Transfer for Large Scale Semi-supervised Object Detection</h4> 
<ul><li>intro: TPAMI 2017. National Institutes of Health (NIH) Clinical Center</li><li>arxiv: https://arxiv.org/abs/1801.03145</li></ul> 
<hr> 
<h3><a id="Video_Object_Detection_1237"></a>Video Object Detection</h3> 
<h4><a id="Learning_Object_Class_Detectors_from_Weakly_Annotated_Video_1238"></a>Learning Object Class Detectors from Weakly Annotated Video</h4> 
<ul><li>intro: CVPR 2012</li><li>paper: https://www.vision.ee.ethz.ch/publications/papers/proceedings/eth_biwi_00905.pdf</li></ul> 
<h4><a id="Analysing_domain_shift_factors_between_videos_and_images_for_object_detection_1243"></a>Analysing domain shift factors between videos and images for object detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1501.01186</li></ul> 
<h4><a id="Video_Object_Recognition_1247"></a>Video Object Recognition</h4> 
<ul><li>slides: http://vision.princeton.edu/courses/COS598/2015sp/slides/VideoRecog/Video%20Object%20Recognition.pptx</li></ul> 
<h4><a id="Deep_Learning_for_Saliency_Prediction_in_Natural_Video_1251"></a>Deep Learning for Saliency Prediction in Natural Video</h4> 
<ul><li>intro: Submitted on 12 Jan 2016</li><li>keywords: Deep learning, saliency map, optical flow, convolution network, contrast features</li><li>paper: https://hal.archives-ouvertes.fr/hal-01251614/document</li></ul> 
<h4><a id="TCNN_Tubelets_with_Convolutional_Neural_Networks_for_Object_Detection_from_Videos_1257"></a>T-CNN: Tubelets with Convolutional Neural Networks for Object Detection from Videos</h4> 
<ul><li>intro: Winning solution in ILSVRC2015 Object Detection from Video(VID) Task</li><li>arxiv: http://arxiv.org/abs/1604.02532</li><li>github: https://github.com/myfavouritekk/T-CNN</li></ul> 
<h4><a id="Object_Detection_from_Video_Tubelets_with_Convolutional_Neural_Networks_1263"></a>Object Detection from Video Tubelets with Convolutional Neural Networks</h4> 
<ul><li>intro: CVPR 2016 Spotlight paper</li><li>arxiv: https://arxiv.org/abs/1604.04053</li><li>paper: http://www.ee.cuhk.edu.hk/~wlouyang/Papers/KangVideoDet_CVPR16.pdf</li><li>gihtub: https://github.com/myfavouritekk/vdetlib</li></ul> 
<h4><a id="Object_Detection_in_Videos_with_Tubelets_and_Multicontext_Cues_1270"></a>Object Detection in Videos with Tubelets and Multi-context Cues</h4> 
<ul><li>intro: SenseTime Group</li><li>slides: http://www.ee.cuhk.edu.hk/~xgwang/CUvideo.pdf</li><li>slides: http://image-net.org/challenges/talks/Object%20Detection%20in%20Videos%20with%20Tubelets%20and%20Multi-context%20Cues%20-%20Final.pdf</li></ul> 
<h4><a id="Context_Matters_Refining_Object_Detection_in_Video_with_Recurrent_Neural_Networks_1276"></a>Context Matters: Refining Object Detection in Video with Recurrent Neural Networks</h4> 
<ul><li>intro: BMVC 2016</li><li>keywords: pseudo-labeler</li><li>arxiv: http://arxiv.org/abs/1607.04648</li><li>paper: http://vision.cornell.edu/se3/wp-content/uploads/2016/07/video_object_detection_BMVC.pdf</li></ul> 
<h4><a id="CNN_Based_Object_Detection_in_Large_Video_Images_1283"></a>CNN Based Object Detection in Large Video Images</h4> 
<ul><li>intro: WangTao @ 爱奇艺</li><li>keywords: object retrieval, object detection, scene classification</li><li>slides: http://on-demand.gputechconf.com/gtc/2016/presentation/s6362-wang-tao-cnn-based-object-detection-large-video-images.pdf</li></ul> 
<h4><a id="Object_Detection_in_Videos_with_Tubelet_Proposal_Networks_1289"></a>Object Detection in Videos with Tubelet Proposal Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.06355</li></ul> 
<h4><a id="FlowGuided_Feature_Aggregation_for_Video_Object_Detection_1293"></a>Flow-Guided Feature Aggregation for Video Object Detection</h4> 
<ul><li>intro: MSRA</li><li>arxiv: https://arxiv.org/abs/1703.10025</li></ul> 
<h4><a id="Video_Object_Detection_using_Faster_RCNN_1298"></a>Video Object Detection using Faster R-CNN</h4> 
<ul><li>blog: http://andrewliao11.github.io/object_detection/faster_rcnn/</li><li>github: https://github.com/andrewliao11/py-faster-rcnn-imagenet</li></ul> 
<h4><a id="Improving_Context_Modeling_for_Video_Object_Detection_and_Tracking_1303"></a>Improving Context Modeling for Video Object Detection and Tracking</h4> 
<p>http://image-net.org/challenges/talks_2017/ilsvrc2017_short(poster).pdf</p> 
<h4><a id="Temporal_Dynamic_Graph_LSTM_for_Actiondriven_Video_Object_Detection_1307"></a>Temporal Dynamic Graph LSTM for Action-driven Video Object Detection</h4> 
<ul><li>intro: ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1708.00666</li></ul> 
<h4><a id="Mobile_Video_Object_Detection_with_TemporallyAware_Feature_Maps_1312"></a>Mobile Video Object Detection with Temporally-Aware Feature Maps</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.06368</li></ul> 
<h4><a id="Towards_High_Performance_Video_Object_Detection_1316"></a>Towards High Performance Video Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.11577</li></ul> 
<h4><a id="Impression_Network_for_Video_Object_Detection_1320"></a>Impression Network for Video Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.05896</li></ul> 
<h4><a id="SpatialTemporal_Memory_Networks_for_Video_Object_Detection_1324"></a>Spatial-Temporal Memory Networks for Video Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.06317</li></ul> 
<h4><a id="3DDETNet_a_Single_Stage_VideoBased_Vehicle_Detector_1328"></a>3D-DETNet: a Single Stage Video-Based Vehicle Detector</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1801.01769</li></ul> 
<h4><a id="Object_Detection_in_Videos_by_Short_and_Long_Range_Object_Linking_1332"></a>Object Detection in Videos by Short and Long Range Object Linking</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1801.09823</li></ul> 
<h4><a id="Object_Detection_in_Video_with_Spatiotemporal_Sampling_Networks_1336"></a>Object Detection in Video with Spatiotemporal Sampling Networks</h4> 
<ul><li>intro: University of Pennsylvania, 2Dartmouth College</li><li>arxiv: https://arxiv.org/abs/1803.05549</li></ul> 
<h4><a id="Towards_High_Performance_Video_Object_Detection_for_Mobiles_1341"></a>Towards High Performance Video Object Detection for Mobiles</h4> 
<ul><li>intro: Microsoft Research Asia</li><li>arxiv: https://arxiv.org/abs/1804.05830</li></ul> 
<h4><a id="Optimizing_Video_Object_Detection_via_a_ScaleTime_Lattice_1346"></a>Optimizing Video Object Detection via a Scale-Time Lattice</h4> 
<ul><li>intro: CVPR 2018</li><li>project page: http://mmlab.ie.cuhk.edu.hk/projects/ST-Lattice/</li><li>arxiv: https://arxiv.org/abs/1804.05472</li><li>github: https://github.com/hellock/scale-time-lattice</li></ul> 
<h4><a id="Pack_and_Detect_Fast_Object_Detection_in_Videos_Using_RegionofInterest_Packing_1353"></a>Pack and Detect: Fast Object Detection in Videos Using Region-of-Interest Packing</h4> 
<ul><li>https://arxiv.org/abs/1809.01701</li></ul> 
<h4><a id="Fast_Object_Detection_in_Compressed_Video_1356"></a>Fast Object Detection in Compressed Video</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.11057</li></ul> 
<h4><a id="TubeCNN_Modeling_temporal_evolution_of_appearance_for_object_detection_in_video_1359"></a>Tube-CNN: Modeling temporal evolution of appearance for object detection in video</h4> 
<ul><li>intro: INRIA/ENS</li><li>arxiv: https://arxiv.org/abs/1812.02619</li></ul> 
<h4><a id="AdaScale_Towards_Realtime_Video_Object_Detection_Using_Adaptive_Scaling_1363"></a>AdaScale: Towards Real-time Video Object Detection Using Adaptive Scaling</h4> 
<ul><li>intro: SysML 2019 oral</li><li>arxiv: https://arxiv.org/abs/1902.02910</li></ul> 
<hr> 
<h3><a id="Object_Detection_on_Mobile_Devices_1370"></a>Object Detection on Mobile Devices</h3> 
<h4><a id="Pelee_A_RealTime_Object_Detection_System_on_Mobile_Devices_1371"></a>Pelee: A Real-Time Object Detection System on Mobile Devices</h4> 
<ul><li>intro: ICLR 2018 workshop track</li><li>intro: based on the SSD</li><li>arxiv: https://arxiv.org/abs/1804.06882</li><li>github: https://github.com/Robert-JunWang/Pelee</li></ul> 
<hr> 
<h3><a id="Object_Detection_in_3D_1380"></a>Object Detection in 3D</h3> 
<h4><a id="Vote3Deep_Fast_Object_Detection_in_3D_Point_Clouds_Using_Efficient_Convolutional_Neural_Networks_1381"></a>Vote3Deep: Fast Object Detection in 3D Point Clouds Using Efficient Convolutional Neural Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1609.06666</li></ul> 
<h4><a id="ComplexYOLO_Realtime_3D_Object_Detection_on_Point_Clouds_1385"></a>Complex-YOLO: Real-time 3D Object Detection on Point Clouds</h4> 
<ul><li>intro: Valeo Schalter und Sensoren GmbH &amp; Ilmenau University of Technology</li><li>arxiv: https://arxiv.org/abs/1803.06199</li></ul> 
<h4><a id="Focal_Loss_in_3D_Object_Detection_1390"></a>Focal Loss in 3D Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1809.06065</li><li>github: https://github.com/pyun-ram/FL3D</li></ul> 
<h4><a id="3D_Object_Detection_Using_Scale_Invariant_and_Feature_Reweighting_Networks_1394"></a>3D Object Detection Using Scale Invariant and Feature Reweighting Networks</h4> 
<ul><li>intro: AAAI 2019</li><li>arxiv: https://arxiv.org/abs/1901.02237</li></ul> 
<h4><a id="3D_Backbone_Network_for_3D_Object_Detection_1398"></a>3D Backbone Network for 3D Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1901.08373</li></ul> 
<hr> 
<h3><a id="Object_Detection_on_RGBD_1403"></a>Object Detection on RGB-D</h3> 
<h4><a id="Learning_Rich_Features_from_RGBD_Images_for_Object_Detection_and_Segmentation_1404"></a>Learning Rich Features from RGB-D Images for Object Detection and Segmentation</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1407.5736</li></ul> 
<h4><a id="Differential_Geometry_Boosts_Convolutional_Neural_Networks_for_Object_Detection_1408"></a>Differential Geometry Boosts Convolutional Neural Networks for Object Detection</h4> 
<ul><li>intro: CVPR 2016</li><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016_workshops/w23/html/Wang_Differential_Geometry_Boosts_CVPR_2016_paper.html</li></ul> 
<h4><a id="A_Selfsupervised_Learning_System_for_Object_Detection_using_Physics_Simulation_and_Multiview_Pose_Estimation_1413"></a>A Self-supervised Learning System for Object Detection using Physics Simulation and Multi-view Pose Estimation</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1703.03347</li></ul> 
<hr> 
<h3><a id="ZeroShot_Object_Detection_1419"></a>Zero-Shot Object Detection</h3> 
<h4><a id="ZeroShot_Detection_1420"></a>Zero-Shot Detection</h4> 
<ul><li>intro: Australian National University</li><li>keywords: YOLO</li><li>arxiv: https://arxiv.org/abs/1803.07113</li></ul> 
<h4><a id="ZeroShot_Object_Detection_1426"></a>Zero-Shot Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.04340</li></ul> 
<h4><a id="ZeroShot_Object_Detection_Learning_to_Simultaneously_Recognize_and_Localize_Novel_Concepts_1430"></a>Zero-Shot Object Detection: Learning to Simultaneously Recognize and Localize Novel Concepts</h4> 
<ul><li>intro: Australian National University</li><li>arxiv: https://arxiv.org/abs/1803.06049</li></ul> 
<h4><a id="ZeroShot_Object_Detection_by_Hybrid_Region_Embedding_1435"></a>Zero-Shot Object Detection by Hybrid Region Embedding</h4> 
<ul><li>intro: Middle East Technical University &amp; Hacettepe University</li><li>arxiv: https://arxiv.org/abs/1805.06157</li></ul> 
<hr> 
<h3><a id="Salient_Object_Detection_1442"></a>Salient Object Detection</h3> 
<p>This task involves predicting the salient regions of an image given by human eye fixations.</p> 
<h4><a id="Best_Deep_Saliency_Detection_Models_CVPR_2016__2015_1445"></a>Best Deep Saliency Detection Models (CVPR 2016 &amp; 2015)</h4> 
<ul><li>page: http://i.cs.hku.hk/~yzyu/vision.html</li></ul> 
<h4><a id="Largescale_optimization_of_hierarchical_features_for_saliency_prediction_in_natural_images_1449"></a>Large-scale optimization of hierarchical features for saliency prediction in natural images</h4> 
<ul><li>paper: http://coxlab.org/pdfs/cvpr2014_vig_saliency.pdf</li></ul> 
<h4><a id="Predicting_Eye_Fixations_using_Convolutional_Neural_Networks_1453"></a>Predicting Eye Fixations using Convolutional Neural Networks</h4> 
<ul><li>paper: http://www.escience.cn/system/file?fileId=72648</li></ul> 
<h4><a id="Saliency_Detection_by_MultiContext_Deep_Learning_1457"></a>Saliency Detection by Multi-Context Deep Learning</h4> 
<ul><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhao_Saliency_Detection_by_2015_CVPR_paper.pdf</li></ul> 
<h4><a id="DeepSaliency_MultiTask_Deep_Neural_Network_Model_for_Salient_Object_Detection_1461"></a>DeepSaliency: Multi-Task Deep Neural Network Model for Salient Object Detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1510.05484</li></ul> 
<h4><a id="SuperCNN_A_Superpixelwise_Convolutional_Neural_Network_for_Salient_Object_Detection_1465"></a>SuperCNN: A Superpixelwise Convolutional Neural Network for Salient Object Detection</h4> 
<ul><li>paper: www.shengfenghe.com/supercnn-a-superpixelwise-convolutional-neural-network-for-salient-object-detection.html</li></ul> 
<h4><a id="Shallow_and_Deep_Convolutional_Networks_for_Saliency_Prediction_1469"></a>Shallow and Deep Convolutional Networks for Saliency Prediction</h4> 
<ul><li>intro: CVPR 2016</li><li>arxiv: http://arxiv.org/abs/1603.00845</li><li>github: https://github.com/imatge-upc/saliency-2016-cvpr</li></ul> 
<h4><a id="Recurrent_Attentional_Networks_for_Saliency_Detection_1475"></a>Recurrent Attentional Networks for Saliency Detection</h4> 
<ul><li>intro: CVPR 2016. recurrent attentional convolutional-deconvolution network (RACDNN)</li><li>arxiv: http://arxiv.org/abs/1604.03227</li></ul> 
<h4><a id="TwoStream_Convolutional_Networks_for_Dynamic_Saliency_Prediction_1480"></a>Two-Stream Convolutional Networks for Dynamic Saliency Prediction</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1607.04730</li></ul> 
<hr> 
<h3><a id="Unconstrained_Salient_Object_Detection_1486"></a>Unconstrained Salient Object Detection</h3> 
<h4><a id="Unconstrained_Salient_Object_Detection_via_Proposal_Subset_Optimization_1487"></a>Unconstrained Salient Object Detection via Proposal Subset Optimization</h4> 
<p><img src="https://images2.imgbox.com/dd/02/KX0dUjV2_o.jpg" alt="这里写图片描述"></p> 
<ul><li>intro: CVPR 2016</li><li>project page: http://cs-people.bu.edu/jmzhang/sod.html</li><li>paper: http://cs-people.bu.edu/jmzhang/SOD/CVPR16SOD_camera_ready.pdf</li><li>github: https://github.com/jimmie33/SOD</li><li>caffe model zoo: https://github.com/BVLC/caffe/wiki/Model-Zoo#cnn-object-proposal-models-for-salient-object-detection</li></ul> 
<h4><a id="DHSNet_Deep_Hierarchical_Saliency_Network_for_Salient_Object_Detection_1495"></a>DHSNet: Deep Hierarchical Saliency Network for Salient Object Detection</h4> 
<ul><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DHSNet_Deep_Hierarchical_CVPR_2016_paper.pdf</li></ul> 
<h4><a id="Salient_Object_Subitizing_1499"></a>Salient Object Subitizing</h4> 
<p><img src="https://images2.imgbox.com/34/cb/MGirgOfE_o.png" alt="这里写图片描述"></p> 
<ul><li>intro: CVPR 2015</li><li>intro: predicting the existence and the number of salient objects in an image using holistic cues</li><li>project page: http://cs-people.bu.edu/jmzhang/sos.html</li><li>arxiv: http://arxiv.org/abs/1607.07525</li><li>paper: http://cs-people.bu.edu/jmzhang/SOS/SOS_preprint.pdf</li><li>caffe model zoo: https://github.com/BVLC/caffe/wiki/Model-Zoo#cnn-models-for-salient-object-subitizing</li></ul> 
<h4><a id="DeeplySupervised_Recurrent_Convolutional_Neural_Network_for_Saliency_Detection_1508"></a>Deeply-Supervised Recurrent Convolutional Neural Network for Saliency Detection</h4> 
<ul><li>intro: ACMMM 2016. deeply-supervised recurrent convolutional neural network (DSRCNN)</li><li>arxiv: http://arxiv.org/abs/1608.05177</li></ul> 
<h4><a id="Saliency_Detection_via_Combining_RegionLevel_and_PixelLevel_Predictions_with_CNNs_1513"></a>Saliency Detection via Combining Region-Level and Pixel-Level Predictions with CNNs</h4> 
<ul><li>intro: ECCV 2016</li><li>arxiv: http://arxiv.org/abs/1608.05186</li></ul> 
<h4><a id="Edge_Preserving_and_MultiScale_Contextual_Neural_Network_for_Salient_Object_Detection_1518"></a>Edge Preserving and Multi-Scale Contextual Neural Network for Salient Object Detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1608.08029</li></ul> 
<h4><a id="A_Deep_MultiLevel_Network_for_Saliency_Prediction_1522"></a>A Deep Multi-Level Network for Saliency Prediction</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1609.01064</li></ul> 
<h4><a id="Visual_Saliency_Detection_Based_on_Multiscale_Deep_CNN_Features_1526"></a>Visual Saliency Detection Based on Multiscale Deep CNN Features</h4> 
<ul><li>intro: IEEE Transactions on Image Processing</li><li>arxiv: http://arxiv.org/abs/1609.02077</li></ul> 
<h4><a id="A_Deep_Spatial_Contextual_Longterm_Recurrent_Convolutional_Network_for_Saliency_Detection_1531"></a>A Deep Spatial Contextual Long-term Recurrent Convolutional Network for Saliency Detection</h4> 
<ul><li>intro: DSCLRCN</li><li>arxiv: https://arxiv.org/abs/1610.01708</li></ul> 
<h4><a id="Deeply_supervised_salient_object_detection_with_short_connections_1536"></a>Deeply supervised salient object detection with short connections</h4> 
<ul><li>intro: IEEE TPAMI 2018 (IEEE CVPR 2017)</li><li>arxiv: https://arxiv.org/abs/1611.04849</li><li>github(official, Caffe): https://github.com/Andrew-Qibin/DSS</li><li>github(Tensorflow): https://github.com/Joker316701882/Salient-Object-Detection</li></ul> 
<h4><a id="Weakly_Supervised_Topdown_Salient_Object_Detection_1543"></a>Weakly Supervised Top-down Salient Object Detection</h4> 
<ul><li>intro: Nanyang Technological University</li><li>arxiv: https://arxiv.org/abs/1611.05345</li></ul> 
<h4><a id="SalGAN_Visual_Saliency_Prediction_with_Generative_Adversarial_Networks_1548"></a>SalGAN: Visual Saliency Prediction with Generative Adversarial Networks</h4> 
<ul><li>project page: https://imatge-upc.github.io/saliency-salgan-2017/</li><li>arxiv: https://arxiv.org/abs/1701.01081</li></ul> 
<h4><a id="Visual_Saliency_Prediction_Using_a_Mixture_of_Deep_Neural_Networks_1553"></a>Visual Saliency Prediction Using a Mixture of Deep Neural Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.00372</li></ul> 
<h4><a id="A_Fast_and_Compact_Salient_Score_Regression_Network_Based_on_Fully_Convolutional_Network_1557"></a>A Fast and Compact Salient Score Regression Network Based on Fully Convolutional Network</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.00615</li></ul> 
<h4><a id="Saliency_Detection_by_Forward_and_Backward_Cues_in_DeepCNNs_1561"></a>Saliency Detection by Forward and Backward Cues in Deep-CNNs</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1703.00152</li></ul> 
<h4><a id="Supervised_Adversarial_Networks_for_Image_Saliency_Detection_1565"></a>Supervised Adversarial Networks for Image Saliency Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1704.07242</li></ul> 
<h4><a id="Groupwise_Deep_Cosaliency_Detection_1569"></a>Group-wise Deep Co-saliency Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1707.07381</li></ul> 
<h4><a id="Towards_the_Success_Rate_of_One_Realtime_Unconstrained_Salient_Object_Detection_1573"></a>Towards the Success Rate of One: Real-time Unconstrained Salient Object Detection</h4> 
<ul><li>intro: University of Maryland College Park &amp; eBay Inc</li><li>arxiv: https://arxiv.org/abs/1708.00079</li></ul> 
<h4><a id="Amulet_Aggregating_Multilevel_Convolutional_Features_for_Salient_Object_Detection_1578"></a>Amulet: Aggregating Multi-level Convolutional Features for Salient Object Detection</h4> 
<ul><li>intro: ICCV 2017</li><li>arixv: https://arxiv.org/abs/1708.02001</li></ul> 
<h4><a id="Learning_Uncertain_Convolutional_Features_for_Accurate_Saliency_Detection_1583"></a>Learning Uncertain Convolutional Features for Accurate Saliency Detection</h4> 
<ul><li>intro: Accepted as a poster in ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1708.02031</li></ul> 
<h4><a id="Deep_EdgeAware_Saliency_Detection_1588"></a>Deep Edge-Aware Saliency Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1708.04366</li></ul> 
<h4><a id="Selfexplanatory_Deep_Salient_Object_Detection_1592"></a>Self-explanatory Deep Salient Object Detection</h4> 
<ul><li>intro: National University of Defense Technology, China &amp; National University of Singapore</li><li>arxiv: https://arxiv.org/abs/1708.05595</li></ul> 
<h4><a id="PiCANet_Learning_Pixelwise_Contextual_Attention_in_ConvNets_and_Its_Application_in_Saliency_Detection_1597"></a>PiCANet: Learning Pixel-wise Contextual Attention in ConvNets and Its Application in Saliency Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1708.06433</li></ul> 
<h4><a id="DeepFeat_A_Bottom_Up_and_Top_Down_Saliency_Model_Based_on_Deep_Features_of_Convolutional_Neural_Nets_1601"></a>DeepFeat: A Bottom Up and Top Down Saliency Model Based on Deep Features of Convolutional Neural Nets</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.02495</li></ul> 
<h4><a id="Recurrently_Aggregating_Deep_Features_for_Salient_Object_Detection_1605"></a>Recurrently Aggregating Deep Features for Salient Object Detection</h4> 
<ul><li>intro: AAAI 2018</li><li>paper: https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16775/16281</li></ul> 
<h4><a id="Deep_saliency_What_is_learnt_by_a_deep_network_about_saliency_1610"></a>Deep saliency: What is learnt by a deep network about saliency?</h4> 
<ul><li>intro: 2nd Workshop on Visualisation for Deep Learning in the 34th International Conference On Machine Learning</li><li>arxiv: https://arxiv.org/abs/1801.04261</li></ul> 
<h4><a id="ContrastOriented_Deep_Neural_Networks_for_Salient_Object_Detection_1615"></a>Contrast-Oriented Deep Neural Networks for Salient Object Detection</h4> 
<ul><li>intro: TNNLS</li><li>arxiv: https://arxiv.org/abs/1803.11395</li></ul> 
<h4><a id="Salient_Object_Detection_by_Lossless_Feature_Reflection_1620"></a>Salient Object Detection by Lossless Feature Reflection</h4> 
<ul><li>intro: IJCAI 2018</li><li>arxiv: https://arxiv.org/abs/1802.06527</li></ul> 
<h4><a id="HyperFusionNet_Densely_Reflective_Fusion_for_Salient_Object_Detection_1625"></a>HyperFusion-Net: Densely Reflective Fusion for Salient Object Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.05142</li></ul> 
<hr> 
<h3><a id="Video_Saliency_Detection_1632"></a>Video Saliency Detection</h3> 
<h4><a id="Deep_Learning_For_Video_Saliency_Detection_1633"></a>Deep Learning For Video Saliency Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.00871</li></ul> 
<h4><a id="Video_Salient_Object_Detection_Using_Spatiotemporal_Deep_Features_1637"></a>Video Salient Object Detection Using Spatiotemporal Deep Features</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1708.01447</li></ul> 
<h4><a id="Predicting_Video_Saliency_with_ObjecttoMotion_CNN_and_Twolayer_Convolutional_LSTM_1641"></a>Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.06316</li></ul> 
<hr> 
<h3><a id="Visual_Relationship_Detection_1648"></a>Visual Relationship Detection</h3> 
<h4><a id="Visual_Relationship_Detection_with_Language_Priors_1649"></a>Visual Relationship Detection with Language Priors</h4> 
<ul><li>intro: ECCV 2016 oral</li><li>paper: https://cs.stanford.edu/people/ranjaykrishna/vrd/vrd.pdf</li><li>github: https://github.com/Prof-Lu-Cewu/Visual-Relationship-Detection</li></ul> 
<h4><a id="ViPCNN_A_Visual_Phrase_Reasoning_Convolutional_Neural_Network_for_Visual_Relationship_Detection_1655"></a>ViP-CNN: A Visual Phrase Reasoning Convolutional Neural Network for Visual Relationship Detection</h4> 
<ul><li>intro: Visual Phrase reasoning Convolutional Neural Network (ViP-CNN), Visual Phrase Reasoning Structure (VPRS)</li><li>arxiv: https://arxiv.org/abs/1702.07191</li></ul> 
<h4><a id="Visual_Translation_Embedding_Network_for_Visual_Relation_Detection_1660"></a>Visual Translation Embedding Network for Visual Relation Detection</h4> 
<ul><li>arxiv: https://www.arxiv.org/abs/1702.08319</li></ul> 
<h4><a id="Deep_Variationstructured_Reinforcement_Learning_for_Visual_Relationship_and_Attribute_Detection_1664"></a>Deep Variation-structured Reinforcement Learning for Visual Relationship and Attribute Detection</h4> 
<ul><li>intro: CVPR 2017 spotlight paper</li><li>arxiv: https://arxiv.org/abs/1703.03054</li></ul> 
<h4><a id="Detecting_Visual_Relationships_with_Deep_Relational_Networks_1669"></a>Detecting Visual Relationships with Deep Relational Networks</h4> 
<ul><li>intro: CVPR 2017 oral. The Chinese University of Hong Kong</li><li>arxiv: https://arxiv.org/abs/1704.03114</li></ul> 
<h4><a id="Identifying_Spatial_Relations_in_Images_using_Convolutional_Neural_Networks_1674"></a>Identifying Spatial Relations in Images using Convolutional Neural Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.04215</li></ul> 
<h4><a id="PPRFCN_Weakly_Supervised_Visual_Relation_Detection_via_Parallel_Pairwise_RFCN_1678"></a>PPR-FCN: Weakly Supervised Visual Relation Detection via Parallel Pairwise R-FCN</h4> 
<ul><li>intro: ICCV</li><li>arxiv: https://arxiv.org/abs/1708.01956</li></ul> 
<h4><a id="Natural_Language_Guided_Visual_Relationship_Detection_1683"></a>Natural Language Guided Visual Relationship Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.06032</li></ul> 
<h4><a id="Detecting_Visual_Relationships_Using_Box_Attention_1687"></a>Detecting Visual Relationships Using Box Attention</h4> 
<ul><li>intro: Google AI &amp; IST Austria</li><li>arxiv: https://arxiv.org/abs/1807.02136</li></ul> 
<h4><a id="Google_AI_Open_Images__Visual_Relationship_Track_1692"></a>Google AI Open Images - Visual Relationship Track</h4> 
<ul><li>intro: Detect pairs of objects in particular relationships</li><li>kaggle: https://www.kaggle.com/c/google-ai-open-images-visual-relationship-track</li></ul> 
<h4><a id="ContextDependent_Diffusion_Network_for_Visual_Relationship_Detection_1697"></a>Context-Dependent Diffusion Network for Visual Relationship Detection</h4> 
<ul><li>intro: 2018 ACM Multimedia Conference</li><li>arxiv: https://arxiv.org/abs/1809.06213</li></ul> 
<h4><a id="A_Problem_Reduction_Approach_for_Visual_Relationships_Detection_1701"></a>A Problem Reduction Approach for Visual Relationships Detection</h4> 
<ul><li>intro: ECCV 2018 Workshop</li><li>arxiv: https://arxiv.org/abs/1809.09828</li></ul> 
<hr> 
<h3><a id="Face_Deteciton_1707"></a>Face Deteciton</h3> 
<h4><a id="Multiview_Face_Detection_Using_Deep_Convolutional_Neural_Networks_1708"></a>Multi-view Face Detection Using Deep Convolutional Neural Networks</h4> 
<ul><li>intro: Yahoo</li><li>arxiv: http://arxiv.org/abs/1502.02766</li><li>github: https://github.com/guoyilin/FaceDetection_CNN</li></ul> 
<h4><a id="From_Facial_Parts_Responses_to_Face_Detection_A_Deep_Learning_Approach_1714"></a>From Facial Parts Responses to Face Detection: A Deep Learning Approach</h4> 
<ul><li>intro: ICCV 2015. CUHK</li><li>project page: http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness.html</li><li>arxiv: https://arxiv.org/abs/1509.06451</li><li>paper: http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_From_Facial_Parts_ICCV_2015_paper.pdf</li></ul> 
<h4><a id="Compact_Convolutional_Neural_Network_Cascade_for_Face_Detection_1723"></a>Compact Convolutional Neural Network Cascade for Face Detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1508.01292</li><li>github: https://github.com/Bkmz21/FD-Evaluation</li><li>github: https://github.com/Bkmz21/CompactCNNCascade</li></ul> 
<h4><a id="Face_Detection_with_EndtoEnd_Integration_of_a_ConvNet_and_a_3D_Model_1729"></a>Face Detection with End-to-End Integration of a ConvNet and a 3D Model</h4> 
<ul><li>intro: ECCV 2016</li><li>arxiv: https://arxiv.org/abs/1606.00850</li><li>github(MXNet): https://github.com/tfwu/FaceDetection-ConvNet-3D</li></ul> 
<h4><a id="CMSRCNN_Contextual_MultiScale_Regionbased_CNN_for_Unconstrained_Face_Detection_1735"></a>CMS-RCNN: Contextual Multi-Scale Region-based CNN for Unconstrained Face Detection</h4> 
<ul><li>intro: CMU</li><li>arxiv: https://arxiv.org/abs/1606.05413</li></ul> 
<h4><a id="Towards_a_Deep_Learning_Framework_for_Unconstrained_Face_Detection_1740"></a>Towards a Deep Learning Framework for Unconstrained Face Detection</h4> 
<ul><li>intro: overlap with CMS-RCNN</li><li>arxiv: https://arxiv.org/abs/1612.05322</li></ul> 
<h4><a id="Supervised_Transformer_Network_for_Efficient_Face_Detection_1745"></a>Supervised Transformer Network for Efficient Face Detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1607.05477</li></ul> 
<h4><a id="UnitBox_An_Advanced_Object_Detection_Network_1749"></a>UnitBox: An Advanced Object Detection Network</h4> 
<ul><li>intro: ACM MM 2016</li><li>keywords: IOULoss</li><li>arxiv: http://arxiv.org/abs/1608.01471</li></ul> 
<h4><a id="Bootstrapping_Face_Detection_with_Hard_Negative_Examples_1755"></a>Bootstrapping Face Detection with Hard Negative Examples</h4> 
<ul><li>author: 万韶华 @ 小米.</li><li>intro: Faster R-CNN, hard negative mining. state-of-the-art on the FDDB dataset</li><li>arxiv: http://arxiv.org/abs/1608.02236</li></ul> 
<h4><a id="Grid_Loss_Detecting_Occluded_Faces_1761"></a>Grid Loss: Detecting Occluded Faces</h4> 
<ul><li>intro: ECCV 2016</li><li>arxiv: https://arxiv.org/abs/1609.00129</li><li>paper: http://lrs.icg.tugraz.at/pubs/opitz_eccv_16.pdf</li><li>poster: http://www.eccv2016.org/files/posters/P-2A-34.pdf</li></ul> 
<h4><a id="A_MultiScale_Cascade_Fully_Convolutional_Network_Face_Detector_1768"></a>A Multi-Scale Cascade Fully Convolutional Network Face Detector</h4> 
<ul><li>intro: ICPR 2016</li><li>arxiv: http://arxiv.org/abs/1609.03536</li></ul> 
<hr> 
<h3><a id="MTCNN_1776"></a>MTCNN</h3> 
<h4><a id="Joint_Face_Detection_and_Alignment_using_Multitask_Cascaded_Convolutional_Neural_Networks_1777"></a>Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Neural Networks</h4> 
<p><img src="https://images2.imgbox.com/b7/c0/ZTamH1sI_o.png" alt="这里写图片描述"></p> 
<ul><li>project page: https://kpzhang93.github.io/MTCNN_face_detection_alignment/index.html</li><li>arxiv: https://arxiv.org/abs/1604.02878</li><li>github(official, Matlab): https://github.com/kpzhang93/MTCNN_face_detection_alignment</li><li>github: https://github.com/pangyupo/mxnet_mtcnn_face_detection</li><li>github: https://github.com/DaFuCoding/MTCNN_Caffe</li><li>github(MXNet): https://github.com/Seanlinx/mtcnn</li><li>github: https://github.com/Pi-DeepLearning/RaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion</li><li>github(Caffe): https://github.com/foreverYoungGitHub/MTCNN</li><li>github: https://github.com/CongWeilin/mtcnn-caffe</li><li>github(OpenCV+OpenBlas): https://github.com/AlphaQi/MTCNN-light</li><li>github(Tensorflow+golang): https://github.com/jdeng/goface</li></ul> 
<h4><a id="Face_Detection_using_Deep_Learning_An_Improved_Faster_RCNN_Approach_1791"></a>Face Detection using Deep Learning: An Improved Faster RCNN Approach</h4> 
<ul><li>intro: DeepIR Inc</li><li>arxiv: https://arxiv.org/abs/1701.08289</li></ul> 
<h4><a id="FacenessNet_Face_Detection_through_Deep_Facial_Part_Responses_1796"></a>Faceness-Net: Face Detection through Deep Facial Part Responses</h4> 
<ul><li>intro: An extended version of ICCV 2015 paper</li><li>arxiv: https://arxiv.org/abs/1701.08393</li></ul> 
<h4><a id="MultiPath_RegionBased_Convolutional_Neural_Network_for_Accurate_Detection_of_Unconstrained_Hard_Faces_1801"></a>Multi-Path Region-Based Convolutional Neural Network for Accurate Detection of Unconstrained “Hard Faces”</h4> 
<ul><li>intro: CVPR 2017. MP-RCNN, MP-RPN</li><li>arxiv: https://arxiv.org/abs/1703.09145</li></ul> 
<h4><a id="EndToEnd_Face_Detection_and_Recognition_1806"></a>End-To-End Face Detection and Recognition</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1703.10818</li></ul> 
<h4><a id="Face_RCNN_1810"></a>Face R-CNN</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.01061</li></ul> 
<h4><a id="Face_Detection_through_ScaleFriendly_Deep_Convolutional_Networks_1814"></a>Face Detection through Scale-Friendly Deep Convolutional Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1706.02863</li></ul> 
<h4><a id="ScaleAware_Face_Detection_1818"></a>Scale-Aware Face Detection</h4> 
<ul><li>intro: CVPR 2017. SenseTime &amp; Tsinghua University</li><li>arxiv: https://arxiv.org/abs/1706.09876</li></ul> 
<h4><a id="Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN_1823"></a>Detecting Faces Using Inside Cascaded Contextual CNN</h4> 
<ul><li>intro: CVPR 2017. Tencent AI Lab &amp; SenseTime</li><li>paper: http://ai.tencent.com/ailab/media/publications/Detecting_Faces_Using_Inside_Cascaded_Contextual_CNN.pdf</li></ul> 
<h4><a id="MultiBranch_Fully_Convolutional_Network_for_Face_Detection_1828"></a>Multi-Branch Fully Convolutional Network for Face Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1707.06330</li></ul> 
<h4><a id="SSH_Single_Stage_Headless_Face_Detector_1832"></a>SSH: Single Stage Headless Face Detector</h4> 
<ul><li>intro: ICCV 2017. University of Maryland</li><li>arxiv: https://arxiv.org/abs/1708.03979</li><li>github(official, Caffe): https://github.com/mahyarnajibi/SSH</li></ul> 
<h4><a id="Dockerface_an_easy_to_install_and_use_Faster_RCNN_face_detector_in_a_Docker_container_1838"></a>Dockerface: an easy to install and use Faster R-CNN face detector in a Docker container</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1708.04370</li></ul> 
<h4><a id="FaceBoxes_A_CPU_Realtime_Face_Detector_with_High_Accuracy_1842"></a>FaceBoxes: A CPU Real-time Face Detector with High Accuracy</h4> 
<ul><li>intro: IJCB 2017</li><li>keywords: Rapidly Digested Convolutional Layers (RDCL), Multiple Scale Convolutional Layers (MSCL)</li><li>intro: the proposed detector runs at 20 FPS on a single CPU core and 125 FPS using a GPU for VGA-resolution images</li><li>arxiv: https://arxiv.org/abs/1708.05234</li><li>github(official): https://github.com/sfzhang15/FaceBoxes</li><li>github(Caffe): https://github.com/zeusees/FaceBoxes</li></ul> 
<h4><a id="S3FD_Single_Shot_Scaleinvariant_Face_Detector_1850"></a>S3FD: Single Shot Scale-invariant Face Detector</h4> 
<ul><li>intro: ICCV 2017. Chinese Academy of Sciences</li><li>intro: can run at 36 FPS on a Nvidia Titan X (Pascal) for VGA-resolution images</li><li>arxiv: https://arxiv.org/abs/1708.05237</li><li>github(Caffe, official): https://github.com/sfzhang15/SFD</li><li>github: https://github.com//clcarwin/SFD_pytorch</li></ul> 
<h4><a id="Detecting_Faces_Using_Regionbased_Fully_Convolutional_Networks_1858"></a>Detecting Faces Using Region-based Fully Convolutional Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.05256</li></ul> 
<h4><a id="AffordanceNet_An_EndtoEnd_Deep_Learning_Approach_for_Object_Affordance_Detection_1862"></a>AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.07326</li></ul> 
<h4><a id="Face_Attention_Network_An_effective_Face_Detector_for_the_Occluded_Faces_1866"></a>Face Attention Network: An effective Face Detector for the Occluded Faces</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.07246</li></ul> 
<h4><a id="Feature_Agglomeration_Networks_for_Single_Stage_Face_Detection_1870"></a>Feature Agglomeration Networks for Single Stage Face Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.00721</li></ul> 
<h4><a id="Face_Detection_Using_Improved_Faster_RCNN_1874"></a>Face Detection Using Improved Faster RCNN</h4> 
<ul><li>intro: Huawei Cloud BU</li><li>arxiv: https://arxiv.org/abs/1802.02142</li></ul> 
<h4><a id="PyramidBox_A_Contextassisted_Single_Shot_Face_Detector_1879"></a>PyramidBox: A Context-assisted Single Shot Face Detector</h4> 
<ul><li>intro: Baidu, Inc</li><li>arxiv: https://arxiv.org/abs/1803.07737</li></ul> 
<h4><a id="A_Fast_Face_Detection_Method_via_Convolutional_Neural_Network_1884"></a>A Fast Face Detection Method via Convolutional Neural Network</h4> 
<ul><li>intro: Neurocomputing</li><li>arxiv: https://arxiv.org/abs/1803.10103</li></ul> 
<h4><a id="Beyond_Tradeoff_Accelerate_FCNbased_Face_Detector_with_Higher_Accuracy_1889"></a>Beyond Trade-off: Accelerate FCN-based Face Detector with Higher Accuracy</h4> 
<ul><li>intro: CVPR 2018. Beihang University &amp; CUHK &amp; Sensetime</li><li>arxiv: https://arxiv.org/abs/1804.05197</li></ul> 
<h4><a id="RealTime_RotationInvariant_Face_Detection_with_Progressive_Calibration_Networks_1894"></a>Real-Time Rotation-Invariant Face Detection with Progressive Calibration Networks</h4> 
<ul><li>intro: CVPR 2018</li><li>arxiv: https://arxiv.org/abs/1804.06039</li><li>github: https://github.com/Jack-CV/PCN</li></ul> 
<h4><a id="SFace_An_Efficient_Network_for_Face_Detection_in_Large_Scale_Variations_1900"></a>SFace: An Efficient Network for Face Detection in Large Scale Variations</h4> 
<ul><li>intro: Beihang University &amp; Megvii Inc. (Face++)</li><li>arxiv: https://arxiv.org/abs/1804.06559</li></ul> 
<h4><a id="Survey_of_Face_Detection_on_Lowquality_Images_1905"></a>Survey of Face Detection on Low-quality Images</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.07362</li></ul> 
<h4><a id="Anchor_Cascade_for_Efficient_Face_Detection_1909"></a>Anchor Cascade for Efficient Face Detection</h4> 
<ul><li>intro: The University of Sydney</li><li>arxiv: https://arxiv.org/abs/1805.03363</li></ul> 
<h4><a id="Adversarial_Attacks_on_Face_Detectors_using_Neural_Net_based_Constrained_Optimization_1914"></a>Adversarial Attacks on Face Detectors using Neural Net based Constrained Optimization</h4> 
<ul><li>intro: IEEE MMSP</li><li>arxiv: https://arxiv.org/abs/1805.12302</li></ul> 
<h4><a id="Selective_Refinement_Network_for_High_Performance_Face_Detection_1919"></a>Selective Refinement Network for High Performance Face Detection</h4> 
<ul><li>https://arxiv.org/abs/1809.02693</li></ul> 
<h4><a id="DSFD_Dual_Shot_Face_Detector_1922"></a>DSFD: Dual Shot Face Detector</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1810.10220</li></ul> 
<h4><a id="Learning_Better_Features_for_Face_Detection_with_Feature_Fusion_and_Segmentation_Supervision_1925"></a>Learning Better Features for Face Detection with Feature Fusion and Segmentation Supervision</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.08557</li></ul> 
<h4><a id="FARPN_Floating_Region_Proposals_for_Face_Detection_1928"></a>FA-RPN: Floating Region Proposals for Face Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1812.05586</li></ul> 
<h4><a id="Robust_and_High_Performance_Face_Detector_1931"></a>Robust and High Performance Face Detector</h4> 
<p>https://arxiv.org/abs/1901.02350</p> 
<h4><a id="DAFEFD_Density_Aware_Feature_Enrichment_for_Face_Detection_1934"></a>DAFE-FD: Density Aware Feature Enrichment for Face Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1901.05375</li></ul> 
<h4><a id="Improved_Selective_Refinement_Network_for_Face_Detection_1937"></a>Improved Selective Refinement Network for Face Detection</h4> 
<ul><li>intro: Chinese Academy of Sciences &amp; JD AI Research</li><li>arxiv: https://arxiv.org/abs/1901.06651</li></ul> 
<h4><a id="Revisiting_a_singlestage_method_for_face_detection_1941"></a>Revisiting a single-stage method for face detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1902.01559</li></ul> 
<hr> 
<h3><a id="Detect_Small_Faces_1946"></a>Detect Small Faces</h3> 
<h4><a id="Finding_Tiny_Faces_1947"></a>Finding Tiny Faces</h4> 
<ul><li>intro: CVPR 2017. CMU</li><li>project page: http://www.cs.cmu.edu/~peiyunh/tiny/index.html</li><li>arxiv: https://arxiv.org/abs/1612.04402</li><li>github(official, Matlab): https://github.com/peiyunh/tiny</li><li>github(inference-only): https://github.com/chinakook/hr101_mxnet</li><li>github: https://github.com/cydonia999/Tiny_Faces_in_Tensorflow</li></ul> 
<h4><a id="Detecting_and_counting_tiny_faces_1956"></a>Detecting and counting tiny faces</h4> 
<ul><li>intro: ENS Paris-Saclay. ExtendedTinyFaces</li><li>intro: Detecting and counting small objects - Analysis, review and application to counting</li><li>arxiv: https://arxiv.org/abs/1801.06504</li><li>github: https://github.com/alexattia/ExtendedTinyFaces</li></ul> 
<h4><a id="Seeing_Small_Faces_from_Robust_Anchors_Perspective_1963"></a>Seeing Small Faces from Robust Anchor’s Perspective</h4> 
<ul><li>intro: CVPR 2018</li><li>arxiv: https://arxiv.org/abs/1802.09058</li></ul> 
<h4><a id="FaceMagNet_Magnifying_Feature_Maps_to_Detect_Small_Faces_1968"></a>Face-MagNet: Magnifying Feature Maps to Detect Small Faces</h4> 
<ul><li>intro: WACV 2018</li><li>keywords: Face Magnifier Network (Face-MageNet)</li><li>arxiv: https://arxiv.org/abs/1803.05258</li><li>github: https://github.com/po0ya/face-magnet</li></ul> 
<h4><a id="Robust_Face_Detection_via_Learning_Small_Faces_on_Hard_Images_1975"></a>Robust Face Detection via Learning Small Faces on Hard Images</h4> 
<ul><li>intro: Johns Hopkins University &amp; Stanford University</li><li>arxiv: https://arxiv.org/abs/1811.11662</li><li>github: https://github.com/bairdzhang/smallhardface</li></ul> 
<h4><a id="SFA_Small_Faces_Attention_Face_Detector_1980"></a>SFA: Small Faces Attention Face Detector</h4> 
<ul><li>intro: Jilin University</li><li>arxiv: https://arxiv.org/abs/1812.08402</li></ul> 
<hr> 
<h3><a id="Person_Head_Detection_1985"></a>Person Head Detection</h3> 
<h4><a id="Contextaware_CNNs_for_person_head_detection_1986"></a>Context-aware CNNs for person head detection</h4> 
<ul><li>intro: ICCV 2015</li><li>project page: http://www.di.ens.fr/willow/research/headdetection/</li><li>arxiv: http://arxiv.org/abs/1511.07917</li><li>github: https://github.com/aosokin/cnn_head_detection</li></ul> 
<h4><a id="Detecting_Heads_using_Feature_Refine_Net_and_Cascaded_Multiscale_Architecture_1993"></a>Detecting Heads using Feature Refine Net and Cascaded Multi-scale Architecture</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1803.09256</li></ul> 
<h4><a id="A_Comparison_of_CNNbased_Face_and_Head_Detectors_for_RealTime_Video_Surveillance_Applications_1997"></a>A Comparison of CNN-based Face and Head Detectors for Real-Time Video Surveillance Applications</h4> 
<ul><li>https://arxiv.org/abs/1809.03336</li></ul> 
<h4><a id="FCHD_A_fast_and_accurate_head_detector_2000"></a>FCHD: A fast and accurate head detector</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1809.08766</li><li>github(PyTorch, official): https://github.com/aditya-vora/FCHD-Fully-Convolutional-Head-Detector</li></ul> 
<hr> 
<h3><a id="Pedestrian_Detection__People_Detection_2006"></a>Pedestrian Detection / People Detection</h3> 
<h4><a id="Pedestrian_Detection_aided_by_Deep_Learning_Semantic_Tasks_2007"></a>Pedestrian Detection aided by Deep Learning Semantic Tasks</h4> 
<ul><li>intro: CVPR 2015</li><li>project page: http://mmlab.ie.cuhk.edu.hk/projects/TA-CNN/</li><li>arxiv: http://arxiv.org/abs/1412.0069</li></ul> 
<h4><a id="Deep_Learning_Strong_Parts_for_Pedestrian_Detection_2013"></a>Deep Learning Strong Parts for Pedestrian Detection</h4> 
<ul><li>intro: ICCV 2015. CUHK. DeepParts</li><li>intro: Achieving 11.89% average miss rate on Caltech Pedestrian Dataset</li><li>paper: http://personal.ie.cuhk.edu.hk/~pluo/pdf/tianLWTiccv15.pdf</li></ul> 
<h4><a id="Taking_a_Deeper_Look_at_Pedestrians_2019"></a>Taking a Deeper Look at Pedestrians</h4> 
<ul><li>intro: CVPR 2015</li><li>arxiv: https://arxiv.org/abs/1501.05790</li></ul> 
<h4><a id="Convolutional_Channel_Features_2024"></a>Convolutional Channel Features</h4> 
<ul><li>intro: ICCV 2015</li><li>arxiv: https://arxiv.org/abs/1504.07339</li><li>github: https://github.com/byangderek/CCF</li></ul> 
<h4><a id="Endtoend_people_detection_in_crowded_scenes_2030"></a>End-to-end people detection in crowded scenes</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1506.04878</li><li>github: https://github.com/Russell91/reinspect</li><li>ipn: http://nbviewer.ipython.org/github/Russell91/ReInspect/blob/master/evaluation_reinspect.ipynb</li><li>youtube: https://www.youtube.com/watch?v=QeWl0h3kQ24</li></ul> 
<h4><a id="Learning_ComplexityAware_Cascades_for_Deep_Pedestrian_Detection_2037"></a>Learning Complexity-Aware Cascades for Deep Pedestrian Detection</h4> 
<ul><li>intro: ICCV 2015</li><li>arxiv: https://arxiv.org/abs/1507.05348</li></ul> 
<h4><a id="Deep_convolutional_neural_networks_for_pedestrian_detection_2042"></a>Deep convolutional neural networks for pedestrian detection</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1510.03608</li><li>github: https://github.com/DenisTome/DeepPed</li></ul> 
<h4><a id="Scaleaware_Fast_RCNN_for_Pedestrian_Detection_2047"></a>Scale-aware Fast R-CNN for Pedestrian Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1510.08160</li></ul> 
<h4><a id="New_algorithm_improves_speed_and_accuracy_of_pedestrian_detection_2051"></a>New algorithm improves speed and accuracy of pedestrian detection</h4> 
<ul><li>blog: http://www.eurekalert.org/pub_releases/2016-02/uoc–nai020516.php</li></ul> 
<h4><a id="Pushing_the_Limits_of_Deep_CNNs_for_Pedestrian_Detection_2055"></a>Pushing the Limits of Deep CNNs for Pedestrian Detection</h4> 
<ul><li>intro: “set a new record on the Caltech pedestrian dataset, lowering the log-average miss rate from 11.7% to 8.9%”</li><li>arxiv: http://arxiv.org/abs/1603.04525</li></ul> 
<h4><a id="A_RealTime_Deep_Learning_Pedestrian_Detector_for_Robot_Navigation_2060"></a>A Real-Time Deep Learning Pedestrian Detector for Robot Navigation</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1607.04436</li></ul> 
<h4><a id="A_RealTime_Pedestrian_Detector_using_Deep_Learning_for_HumanAware_Navigation_2064"></a>A Real-Time Pedestrian Detector using Deep Learning for Human-Aware Navigation</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1607.04441</li></ul> 
<h4><a id="Is_Faster_RCNN_Doing_Well_for_Pedestrian_Detection_2068"></a>Is Faster R-CNN Doing Well for Pedestrian Detection?</h4> 
<ul><li>intro: ECCV 2016</li><li>arxiv: http://arxiv.org/abs/1607.07032</li><li>github: https://github.com/zhangliliang/RPN_BF/tree/RPN-pedestrian</li></ul> 
<h4><a id="Unsupervised_Deep_Domain_Adaptation_for_Pedestrian_Detection_2074"></a>Unsupervised Deep Domain Adaptation for Pedestrian Detection</h4> 
<ul><li>intro: ECCV Workshop 2016</li><li>arxiv: https://arxiv.org/abs/1802.03269</li></ul> 
<h4><a id="Reduced_Memory_Region_Based_Deep_Convolutional_Neural_Network_Detection_2079"></a>Reduced Memory Region Based Deep Convolutional Neural Network Detection</h4> 
<ul><li>intro: IEEE 2016 ICCE-Berlin</li><li>arxiv: http://arxiv.org/abs/1609.02500</li></ul> 
<h4><a id="Fused_DNN_A_deep_neural_network_fusion_approach_to_fast_and_robust_pedestrian_detection_2084"></a>Fused DNN: A deep neural network fusion approach to fast and robust pedestrian detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1610.03466</li></ul> 
<h4><a id="Detecting_People_in_Artwork_with_CNNs_2088"></a>Detecting People in Artwork with CNNs</h4> 
<ul><li>intro: ECCV 2016 Workshops</li><li>arxiv: https://arxiv.org/abs/1610.08871</li></ul> 
<h4><a id="Multispectral_Deep_Neural_Networks_for_Pedestrian_Detection_2092"></a>Multispectral Deep Neural Networks for Pedestrian Detection</h4> 
<ul><li>intro: BMVC 2016 oral</li><li>arxiv: https://arxiv.org/abs/1611.02644</li></ul> 
<h4><a id="Boxlevel_Segmentation_Supervised_Deep_Neural_Networks_for_Accurate_and_Realtime_Multispectral_Pedestrian_Detection_2096"></a>Box-level Segmentation Supervised Deep Neural Networks for Accurate and Real-time Multispectral Pedestrian Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1902.05291</li></ul> 
<h4><a id="Deep_Multicamera_People_Detection_2100"></a>Deep Multi-camera People Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.04593</li></ul> 
<h4><a id="Expecting_the_Unexpected_Training_Detectors_for_Unusual_Pedestrians_with_Adversarial_Imposters_2104"></a>Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters</h4> 
<ul><li>intro: CVPR 2017</li><li>project page: http://ml.cs.tsinghua.edu.cn:5000/publications/synunity/</li><li>arxiv: https://arxiv.org/abs/1703.06283</li><li>github(Tensorflow): https://github.com/huangshiyu13/RPNplus</li></ul> 
<h4><a id="What_Can_Help_Pedestrian_Detection_2111"></a>What Can Help Pedestrian Detection?</h4> 
<ul><li>intro: CVPR 2017. Tsinghua University &amp; Peking University &amp; Megvii Inc.</li><li>keywords: Faster R-CNN, HyperLearner</li><li>arxiv: https://arxiv.org/abs/1705.02757</li><li>paper: http://openaccess.thecvf.com/content_cvpr_2017/papers/Mao_What_Can_Help_CVPR_2017_paper.pdf</li></ul> 
<h4><a id="Illuminating_Pedestrians_via_Simultaneous_Detection__Segmentation_2118"></a>Illuminating Pedestrians via Simultaneous Detection &amp; Segmentation</h4> 
<ul><li>arxiv: <a href="https://arxiv.org/abs/1706.08564" rel="nofollow">https://arxiv.org/abs/1706.08564</a></li></ul> 
<h4><a id="Rotational_Rectification_Network_for_Robust_Pedestrian_Detection_2122"></a>Rotational Rectification Network for Robust Pedestrian Detection</h4> 
<ul><li>intro: CMU &amp; Volvo Construction</li><li>arxiv: https://arxiv.org/abs/1706.08917</li></ul> 
<h4><a id="STDPD_Generating_Synthetic_Training_Data_for_Pedestrian_Detection_in_Unannotated_Videos_2127"></a>STD-PD: Generating Synthetic Training Data for Pedestrian Detection in Unannotated Videos</h4> 
<ul><li>intro: The University of North Carolina at Chapel Hill</li><li>arxiv: https://arxiv.org/abs/1707.09100</li></ul> 
<h4><a id="Too_Far_to_See_Not_Really__Pedestrian_Detection_with_Scaleaware_Localization_Policy_2132"></a>Too Far to See? Not Really! — Pedestrian Detection with Scale-aware Localization Policy</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.00235</li></ul> 
<h4><a id="Repulsion_Loss_Detecting_Pedestrians_in_a_Crowd_2136"></a>Repulsion Loss: Detecting Pedestrians in a Crowd</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.07752</li></ul> 
<h4><a id="Aggregated_Channels_Network_for_RealTime_Pedestrian_Detection_2140"></a>Aggregated Channels Network for Real-Time Pedestrian Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1801.00476</li></ul> 
<h4><a id="Illuminationaware_Faster_RCNN_for_Robust_Multispectral_Pedestrian_Detection_2144"></a>Illumination-aware Faster R-CNN for Robust Multispectral Pedestrian Detection</h4> 
<ul><li>intro: State Key Lab of CAD&amp;CG, Zhejiang University</li><li>arxiv: https://arxiv.org/abs/1803.05347</li></ul> 
<h4><a id="Exploring_MultiBranch_and_HighLevel_Semantic_Networks_for_Improving_Pedestrian_Detection_2149"></a>Exploring Multi-Branch and High-Level Semantic Networks for Improving Pedestrian Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.00872</li></ul> 
<h4><a id="PedestrianSynthesisGAN_Generating_Pedestrian_Data_in_Real_Scene_and_Beyond_2153"></a>Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.02047</li></ul> 
<h4><a id="PCN_Part_and_Context_Information_for_Pedestrian_Detection_with_CNNs_2157"></a>PCN: Part and Context Information for Pedestrian Detection with CNNs</h4> 
<ul><li>intro: British Machine Vision Conference(BMVC) 2017</li><li>arxiv: https://arxiv.org/abs/1804.04483</li></ul> 
<h4><a id="Smallscale_Pedestrian_Detection_Based_on_Somatic_Topology_Localization_and_Temporal_Feature_Aggregation_2162"></a>Small-scale Pedestrian Detection Based on Somatic Topology Localization and Temporal Feature Aggregation</h4> 
<ul><li>intro: ECCV 2018. Hikvision Research Institute</li><li>arxiv: https://arxiv.org/abs/1807.01438</li></ul> 
<h4><a id="Occlusionaware_RCNN_Detecting_Pedestrians_in_a_Crowd_2167"></a>Occlusion-aware R-CNN: Detecting Pedestrians in a Crowd</h4> 
<ul><li>intro: ECCV 2018</li><li>arxiv: https://arxiv.org/abs/1807.08407</li></ul> 
<h4><a id="Multispectral_Pedestrian_Detection_via_Simultaneous_Detection_and_Segmentation_2172"></a>Multispectral Pedestrian Detection via Simultaneous Detection and Segmentation</h4> 
<ul><li>intro: BMVC 2018</li><li>arxiv: https://arxiv.org/abs/1808.04818</li></ul> 
<h4><a id="Pedestrian_Detection_with_Autoregressive_Network_Phases_2177"></a>Pedestrian Detection with Autoregressive Network Phases</h4> 
<ul><li>intro: Michigan State University</li><li>arxiv: https://arxiv.org/abs/1812.00440</li></ul> 
<h4><a id="The_CrossModality_Disparity_Problem_in_Multispectral_Pedestrian_Detection_2181"></a>The Cross-Modality Disparity Problem in Multispectral Pedestrian Detection</h4> 
<p>-arxiv: https://arxiv.org/abs/1901.02645</p> 
<hr> 
<h3><a id="Vehicle_Detection_2187"></a>Vehicle Detection</h3> 
<h4><a id="DAVE_A_Unified_Framework_for_Fast_Vehicle_Detection_and_Annotation_2188"></a>DAVE: A Unified Framework for Fast Vehicle Detection and Annotation</h4> 
<ul><li>intro: ECCV 2016</li><li>arxiv: http://arxiv.org/abs/1607.04564</li></ul> 
<h4><a id="Evolving_Boxes_for_fast_Vehicle_Detection_2193"></a>Evolving Boxes for fast Vehicle Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.00254</li></ul> 
<h4><a id="FineGrained_Car_Detection_for_Visual_Census_Estimation_2197"></a>Fine-Grained Car Detection for Visual Census Estimation</h4> 
<ul><li>intro: AAAI 2016</li><li>arxiv: https://arxiv.org/abs/1709.02480</li></ul> 
<h4><a id="SINet_A_Scaleinsensitive_Convolutional_Neural_Network_for_Fast_Vehicle_Detection_2202"></a>SINet: A Scale-insensitive Convolutional Neural Network for Fast Vehicle Detection</h4> 
<ul><li>intro: IEEE Transactions on Intelligent Transportation Systems (T-ITS)</li><li>arxiv: https://arxiv.org/abs/1804.00433</li></ul> 
<h4><a id="Label_and_Sample_Efficient_Training_of_Vehicle_Object_Detector_from_Sparsely_Labeled_Data_2207"></a>Label and Sample: Efficient Training of Vehicle Object Detector from Sparsely Labeled Data</h4> 
<ul><li>intro: UC Berkeley</li><li>arxiv: https://arxiv.org/abs/1808.08603</li></ul> 
<h4><a id="Domain_Randomization_for_SceneSpecific_Car_Detection_and_Pose_Estimation_2211"></a>Domain Randomization for Scene-Specific Car Detection and Pose Estimation</h4> 
<ul><li>arxiv：https://arxiv.org/abs/1811.05939</li></ul> 
<h4><a id="ShuffleDet_RealTime_Vehicle_Detection_Network_in_Onboard_Embedded_UAV_Imagery_2214"></a>ShuffleDet: Real-Time Vehicle Detection Network in On-board Embedded UAV Imagery</h4> 
<ul><li>intro: ECCV 2018, UAVision 2018</li><li>arxiv: https://arxiv.org/abs/1811.06318</li></ul> 
<hr> 
<h3><a id="TrafficSign_Detection_2221"></a>Traffic-Sign Detection</h3> 
<h4><a id="TrafficSign_Detection_and_Classification_in_the_Wild_2222"></a>Traffic-Sign Detection and Classification in the Wild</h4> 
<ul><li>intro: CVPR 2016</li><li>project page(code+dataset): http://cg.cs.tsinghua.edu.cn/traffic-sign/</li><li>paper: http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Zhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf</li><li>code &amp; model: http://cg.cs.tsinghua.edu.cn/traffic-sign/data_model_code/newdata0411.zip</li></ul> 
<h4><a id="Evaluating_Stateoftheart_Object_Detector_on_Challenging_Traffic_Light_Data_2229"></a>Evaluating State-of-the-art Object Detector on Challenging Traffic Light Data</h4> 
<ul><li>intro: CVPR 2017 workshop</li><li>paper: http://openaccess.thecvf.com/content_cvpr_2017_workshops/w9/papers/Jensen_Evaluating_State-Of-The-Art_Object_CVPR_2017_paper.pdf</li></ul> 
<h4><a id="Detecting_Small_Signs_from_Large_Images_2234"></a>Detecting Small Signs from Large Images</h4> 
<ul><li>intro: IEEE Conference on Information Reuse and Integration (IRI) 2017 oral</li><li>arxiv: https://arxiv.org/abs/1706.08574</li></ul> 
<h4><a id="Localized_Traffic_Sign_Detection_with_Multiscale_Deconvolution_Networks_2239"></a>Localized Traffic Sign Detection with Multi-scale Deconvolution Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1804.10428</li></ul> 
<h4><a id="Detecting_Traffic_Lights_by_Single_Shot_Detection_2243"></a>Detecting Traffic Lights by Single Shot Detection</h4> 
<ul><li>intro: ITSC 2018</li><li>arxiv: https://arxiv.org/abs/1805.02523</li></ul> 
<h4><a id="A_Hierarchical_Deep_Architecture_and_MiniBatch_Selection_Method_For_Joint_Traffic_Sign_and_Light_Detection_2248"></a>A Hierarchical Deep Architecture and Mini-Batch Selection Method For Joint Traffic Sign and Light Detection</h4> 
<ul><li>intro: IEEE 15th Conference on Computer and Robot Vision</li><li>arxiv: https://arxiv.org/abs/1806.07987</li><li>demo: https://www.youtube.com/watch?v=_YmogPzBXOw&amp;feature=youtu.be</li></ul> 
<hr> 
<h3><a id="Skeleton_Detection_2256"></a>Skeleton Detection</h3> 
<h4><a id="Object_Skeleton_Extraction_in_Natural_Images_by_Fusing_Scaleassociated_Deep_Side_Outputs_2257"></a>Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs</h4> 
<p><img src="https://images2.imgbox.com/e6/47/Ze3hBmzR_o.png" alt="这里写图片描述"></p> 
<ul><li>arxiv: http://arxiv.org/abs/1603.09446</li><li>github: https://github.com/zeakey/DeepSkeleton</li></ul> 
<h4><a id="DeepSkeleton_Learning_Multitask_Scaleassociated_Deep_Side_Outputs_for_Object_Skeleton_Extraction_in_Natural_Images_2262"></a>DeepSkeleton: Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1609.03659</li></ul> 
<h4><a id="SRN_Sideoutput_Residual_Network_for_Object_Symmetry_Detection_in_the_Wild_2266"></a>SRN: Side-output Residual Network for Object Symmetry Detection in the Wild</h4> 
<ul><li>intro: CVPR 2017</li><li>arxiv: https://arxiv.org/abs/1703.02243</li><li>github: https://github.com/KevinKecc/SRN</li></ul> 
<h4><a id="HiFi_Hierarchical_Feature_Integration_for_Skeleton_Detection_2272"></a>Hi-Fi: Hierarchical Feature Integration for Skeleton Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1801.01849</li></ul> 
<hr> 
<h3><a id="Fruit_Detection_2278"></a>Fruit Detection</h3> 
<h4><a id="Deep_Fruit_Detection_in_Orchards_2279"></a>Deep Fruit Detection in Orchards</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1610.03677</li></ul> 
<h4><a id="Image_Segmentation_for_Fruit_Detection_and_Yield_Estimation_in_Apple_Orchards_2283"></a>Image Segmentation for Fruit Detection and Yield Estimation in Apple Orchards</h4> 
<ul><li>intro: The Journal of Field Robotics in May 2016</li><li>project page: http://confluence.acfr.usyd.edu.au/display/AGPub/</li><li>arxiv: https://arxiv.org/abs/1610.08120</li></ul> 
<hr> 
<h3><a id="Shadow_Detection_2290"></a>Shadow Detection</h3> 
<h4><a id="Fast_Shadow_Detection_from_a_Single_Image_Using_a_Patched_Convolutional_Neural_Network_2291"></a>Fast Shadow Detection from a Single Image Using a Patched Convolutional Neural Network</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.09283</li></ul> 
<h4><a id="ADNet_Shadow_Detection_with_Adversarial_Shadow_Attenuation_2295"></a>A+D-Net: Shadow Detection with Adversarial Shadow Attenuation</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.01361</li></ul> 
<h4><a id="Stacked_Conditional_Generative_Adversarial_Networks_for_Jointly_Learning_Shadow_Detection_and_Shadow_Removal_2299"></a>Stacked Conditional Generative Adversarial Networks for Jointly Learning Shadow Detection and Shadow Removal</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1712.02478</li></ul> 
<h4><a id="Directionaware_Spatial_Context_Features_for_Shadow_Detection_2303"></a>Direction-aware Spatial Context Features for Shadow Detection</h4> 
<ul><li>intro: CVPR 2018</li><li>arxiv: https://arxiv.org/abs/1712.04142</li></ul> 
<h4><a id="Directionaware_Spatial_Context_Features_for_Shadow_Detection_and_Removal_2308"></a>Direction-aware Spatial Context Features for Shadow Detection and Removal</h4> 
<ul><li>intro: The Chinese University of Hong Kong &amp; The Hong Kong Polytechnic University</li><li>arxiv: https://arxiv.org/abs/1805.04635</li></ul> 
<hr> 
<h3><a id="Others_Detection_2315"></a>Others Detection</h3> 
<h4><a id="Deep_Deformation_Network_for_Object_Landmark_Localization_2316"></a>Deep Deformation Network for Object Landmark Localization</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1605.01014</li></ul> 
<h4><a id="Fashion_Landmark_Detection_in_the_Wild_2320"></a>Fashion Landmark Detection in the Wild</h4> 
<ul><li>intro: ECCV 2016</li><li>project page: http://personal.ie.cuhk.edu.hk/~lz013/projects/FashionLandmarks.html</li><li>arxiv: http://arxiv.org/abs/1608.03049</li><li>github(Caffe): https://github.com/liuziwei7/fashion-landmarks</li></ul> 
<h4><a id="Deep_Learning_for_Fast_and_Accurate_Fashion_Item_Detection_2327"></a>Deep Learning for Fast and Accurate Fashion Item Detection</h4> 
<ul><li>intro: Kuznech Inc.</li><li>intro: MultiBox and Fast R-CNN</li><li>paper: https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf</li></ul> 
<h4><a id="OSMDeepOD__OSM_and_Deep_Learning_based_Object_Detection_from_Aerial_Imagery_formerly_known_as_OSMCrosswalkDetection_2333"></a>OSMDeepOD - OSM and Deep Learning based Object Detection from Aerial Imagery (formerly known as “OSM-Crosswalk-Detection”)</h4> 
<p><img src="https://images2.imgbox.com/22/7c/KyRbXyEa_o.png" alt="这里写图片描述"></p> 
<ul><li>github: https://github.com/geometalab/OSMDeepOD</li></ul> 
<h4><a id="Selfie_Detection_by_SynergyConstraint_Based_Convolutional_Neural_Network_2337"></a>Selfie Detection by Synergy-Constraint Based Convolutional Neural Network</h4> 
<ul><li>intro: IEEE SITIS 2016</li><li>arxiv: https://arxiv.org/abs/1611.04357</li></ul> 
<h4><a id="Associative_EmbeddingEndtoEnd_Learning_for_Joint_Detection_and_Grouping_2342"></a>Associative Embedding:End-to-End Learning for Joint Detection and Grouping</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1611.05424</li></ul> 
<h4><a id="Deep_Cuboid_Detection_Beyond_2D_Bounding_Boxes_2346"></a>Deep Cuboid Detection: Beyond 2D Bounding Boxes</h4> 
<ul><li>intro: CMU &amp; Magic Leap</li><li>arxiv: https://arxiv.org/abs/1611.10010</li></ul> 
<h4><a id="Automatic_Model_Based_Dataset_Generation_for_Fast_and_Accurate_Crop_and_Weeds_Detection_2351"></a>Automatic Model Based Dataset Generation for Fast and Accurate Crop and Weeds Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1612.03019</li></ul> 
<h4><a id="Deep_Learning_Logo_Detection_with_Data_Expansion_by_Synthesising_Context_2355"></a>Deep Learning Logo Detection with Data Expansion by Synthesising Context</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1612.09322</li></ul> 
<h4><a id="Scalable_Deep_Learning_Logo_Detection_2359"></a>Scalable Deep Learning Logo Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1803.11417</li></ul> 
<h4><a id="Pixelwise_Ear_Detection_with_Convolutional_EncoderDecoder_Networks_2363"></a>Pixel-wise Ear Detection with Convolutional Encoder-Decoder Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.00307</li></ul> 
<h4><a id="Automatic_Handgun_Detection_Alarm_in_Videos_Using_Deep_Learning_2367"></a>Automatic Handgun Detection Alarm in Videos Using Deep Learning</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1702.05147</li><li>results: https://github.com/SihamTabik/Pistol-Detection-in-Videos</li></ul> 
<h4><a id="Objects_as_context_for_part_detection_2372"></a>Objects as context for part detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1703.09529</li></ul> 
<h4><a id="Using_Deep_Networks_for_Drone_Detection_2376"></a>Using Deep Networks for Drone Detection</h4> 
<ul><li>intro: AVSS 2017</li><li>arxiv: https://arxiv.org/abs/1706.05726</li></ul> 
<h4><a id="Cut_Paste_and_Learn_Surprisingly_Easy_Synthesis_for_Instance_Detection_2381"></a>Cut, Paste and Learn: Surprisingly Easy Synthesis for Instance Detection</h4> 
<ul><li>intro: ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1708.01642</li></ul> 
<h4><a id="Target_Driven_Instance_Detection_2386"></a>Target Driven Instance Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1803.04610</li></ul> 
<h4><a id="DeepVoting_An_Explainable_Framework_for_Semantic_Part_Detection_under_Partial_Occlusion_2390"></a>DeepVoting: An Explainable Framework for Semantic Part Detection under Partial Occlusion</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1709.04577</li></ul> 
<h4><a id="VPGNet_Vanishing_Point_Guided_Network_for_Lane_and_Road_Marking_Detection_and_Recognition_2394"></a>VPGNet: Vanishing Point Guided Network for Lane and Road Marking Detection and Recognition</h4> 
<ul><li>intro: ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1710.06288</li><li>github: https://github.com/SeokjuLee/VPGNet</li></ul> 
<h4><a id="Grab_Pay_and_Eat_Semantic_Food_Detection_for_Smart_Restaurants_2400"></a>Grab, Pay and Eat: Semantic Food Detection for Smart Restaurants</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1711.05128</li></ul> 
<h4><a id="ReMotENet_Efficient_Relevant_Motion_Event_Detection_for_Largescale_Home_Surveillance_Videos_2404"></a>ReMotENet: Efficient Relevant Motion Event Detection for Large-scale Home Surveillance Videos</h4> 
<ul><li>intro: WACV 2018</li><li>arxiv: https://arxiv.org/abs/1801.02031</li></ul> 
<h4><a id="Deep_Learning_Object_Detection_Methods_for_Ecological_Camera_Trap_Data_2409"></a>Deep Learning Object Detection Methods for Ecological Camera Trap Data</h4> 
<ul><li>intro: Conference of Computer and Robot Vision. University of Guelph</li><li>arxiv: https://arxiv.org/abs/1803.10842</li></ul> 
<h4><a id="ELGAN_Embedding_Loss_Driven_Generative_Adversarial_Networks_for_Lane_Detection_2414"></a>EL-GAN: Embedding Loss Driven Generative Adversarial Networks for Lane Detection</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1806.05525</li></ul> 
<h4><a id="Towards_EndtoEnd_Lane_Detection_an_Instance_Segmentation_Approach_2418"></a>Towards End-to-End Lane Detection: an Instance Segmentation Approach</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1802.05591</li><li>github: https://github.com/MaybeShewill-CV/lanenet-lane-detection</li></ul> 
<h4><a id="iCAN_InstanceCentric_Attention_Network_for_HumanObject_Interaction_Detection_2422"></a>iCAN: Instance-Centric Attention Network for Human-Object Interaction Detection</h4> 
<ul><li>intro: BMVC 2018</li><li>project page: https://gaochen315.github.io/iCAN/</li><li>arxiv: https://arxiv.org/abs/1808.10437</li><li>github: https://github.com/vt-vl-lab/iCAN</li></ul> 
<h4><a id="Densely_Supervised_Grasp_Detector_DSGD_2429"></a>Densely Supervised Grasp Detector (DSGD)</h4> 
<ul><li>https://arxiv.org/abs/1810.03962</li></ul> 
<hr> 
<h3><a id="Object_Proposal_2433"></a>Object Proposal</h3> 
<h4><a id="DeepProposal_Hunting_Objects_by_Cascading_Deep_Convolutional_Layers_2434"></a>DeepProposal: Hunting Objects by Cascading Deep Convolutional Layers</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1510.04445</li><li>github: https://github.com/aghodrati/deepproposal</li></ul> 
<h4><a id="Scaleaware_Pixelwise_Object_Proposal_Networks_2439"></a>Scale-aware Pixel-wise Object Proposal Networks</h4> 
<ul><li>intro: IEEE Transactions on Image Processing</li><li>arxiv: http://arxiv.org/abs/1601.04798</li></ul> 
<h4><a id="Attend_Refine_Repeat_Active_Box_Proposal_Generation_via_InOut_Localization_2444"></a>Attend Refine Repeat: Active Box Proposal Generation via In-Out Localization</h4> 
<ul><li>intro: BMVC 2016. AttractioNet</li><li>arxiv: https://arxiv.org/abs/1606.04446</li><li>github: https://github.com/gidariss/AttractioNet</li></ul> 
<h4><a id="Learning_to_Segment_Object_Proposals_via_Recursive_Neural_Networks_2450"></a>Learning to Segment Object Proposals via Recursive Neural Networks</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1612.01057</li></ul> 
<h4><a id="Learning_Detection_with_Diverse_Proposals_2454"></a>Learning Detection with Diverse Proposals</h4> 
<ul><li>intro: CVPR 2017</li><li>keywords: differentiable Determinantal Point Process (DPP) layer, Learning Detection with Diverse Proposals (LDDP)</li><li>arxiv: https://arxiv.org/abs/1704.03533</li></ul> 
<h4><a id="ScaleNet_Guiding_Object_Proposal_Generation_in_Supermarkets_and_Beyond_2460"></a>ScaleNet: Guiding Object Proposal Generation in Supermarkets and Beyond</h4> 
<ul><li>keywords: product detection</li><li>arxiv: https://arxiv.org/abs/1704.06752</li></ul> 
<h4><a id="Improving_Small_Object_Proposals_for_Company_Logo_Detection_2465"></a>Improving Small Object Proposals for Company Logo Detection</h4> 
<ul><li>intro: ICMR 2017</li><li>arxiv: https://arxiv.org/abs/1704.08881</li></ul> 
<h4><a id="Open_Logo_Detection_Challenge_2470"></a>Open Logo Detection Challenge</h4> 
<ul><li>intro: BMVC 2018</li><li>keywords: QMUL-OpenLogo</li><li>project page: https://qmul-openlogo.github.io/</li><li>arxiv: https://arxiv.org/abs/1807.01964</li></ul> 
<h4><a id="AttentionMask_Attentive_Efficient_Object_Proposal_Generation_Focusing_on_Small_Objects_2478"></a>AttentionMask: Attentive, Efficient Object Proposal Generation Focusing on Small Objects</h4> 
<ul><li>intro: ACCV 2018 oral</li><li>arxiv: https://arxiv.org/abs/1811.08728</li><li>github: https://github.com/chwilms/AttentionMask</li></ul> 
<hr> 
<h3><a id="Localization_2484"></a>Localization</h3> 
<h4><a id="Beyond_Bounding_Boxes_Precise_Localization_of_Objects_in_Images_2485"></a>Beyond Bounding Boxes: Precise Localization of Objects in Images</h4> 
<ul><li>intro: PhD Thesis</li><li>homepage: http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.html</li><li>phd-thesis: http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-193.pdf</li><li>github(“SDS using hypercolumns”): https://github.com/bharath272/sds</li></ul> 
<h4><a id="Weakly_Supervised_Object_Localization_with_Multifold_Multiple_Instance_Learning_2492"></a>Weakly Supervised Object Localization with Multi-fold Multiple Instance Learning</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1503.00949</li></ul> 
<h4><a id="Weakly_Supervised_Object_Localization_Using_Size_Estimates_2496"></a>Weakly Supervised Object Localization Using Size Estimates</h4> 
<ul><li>arxiv: http://arxiv.org/abs/1608.04314</li></ul> 
<h4><a id="Active_Object_Localization_with_Deep_Reinforcement_Learning_2500"></a>Active Object Localization with Deep Reinforcement Learning</h4> 
<ul><li>intro: ICCV 2015</li><li>keywords: Markov Decision Process</li><li>arxiv: https://arxiv.org/abs/1511.06015</li></ul> 
<h4><a id="Localizing_objects_using_referring_expressions_2506"></a>Localizing objects using referring expressions</h4> 
<ul><li>intro: ECCV 2016</li><li>keywords: LSTM, multiple instance learning (MIL)</li><li>paper: http://www.umiacs.umd.edu/~varun/files/refexp-ECCV16.pdf</li><li>github: https://github.com/varun-nagaraja/referring-expressions</li></ul> 
<h4><a id="LocNet_Improving_Localization_Accuracy_for_Object_Detection_2513"></a>LocNet: Improving Localization Accuracy for Object Detection</h4> 
<ul><li>intro: CVPR 2016 oral</li><li>arxiv: http://arxiv.org/abs/1511.07763</li><li>github: https://github.com/gidariss/LocNet</li></ul> 
<h4><a id="Learning_Deep_Features_for_Discriminative_Localization_2519"></a>Learning Deep Features for Discriminative Localization</h4> 
<p><img src="https://images2.imgbox.com/be/9b/1B3kGMST_o.jpg" alt="这里写图片描述"></p> 
<ul><li>homepage: http://cnnlocalization.csail.mit.edu/</li><li>arxiv: http://arxiv.org/abs/1512.04150</li><li>github(Tensorflow): https://github.com/jazzsaxmafia/Weakly_detector</li><li>github: https://github.com/metalbubble/CAM</li><li>github: https://github.com/tdeboissiere/VGG16CAM-keras</li></ul> 
<h4><a id="ContextLocNet_ContextAware_Deep_Network_Models_for_Weakly_Supervised_Localization_2527"></a>ContextLocNet: Context-Aware Deep Network Models for Weakly Supervised Localization</h4> 
<p><img src="https://images2.imgbox.com/d1/ef/kXMs5Iwn_o.png" alt="这里写图片描述"></p> 
<ul><li>intro: ECCV 2016</li><li>project page: http://www.di.ens.fr/willow/research/contextlocnet/</li><li>arxiv: http://arxiv.org/abs/1609.04331</li><li>github: https://github.com/vadimkantorov/contextlocnet</li></ul> 
<h4><a id="Ensemble_of_Part_Detectors_for_Simultaneous_Classification_and_Localization_2534"></a>Ensemble of Part Detectors for Simultaneous Classification and Localization</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1705.10034</li></ul> 
<h4><a id="STNet_Selective_Tuning_of_Convolutional_Networks_for_Object_Localization_2538"></a>STNet: Selective Tuning of Convolutional Networks for Object Localization</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1708.06418</li></ul> 
<h4><a id="Soft_Proposal_Networks_for_Weakly_Supervised_Object_Localization_2542"></a>Soft Proposal Networks for Weakly Supervised Object Localization</h4> 
<ul><li>intro: ICCV 2017</li><li>arxiv: https://arxiv.org/abs/1709.01829</li></ul> 
<h4><a id="Finegrained_Discriminative_Localization_via_Saliencyguided_Faster_RCNN_2547"></a>Fine-grained Discriminative Localization via Saliency-guided Faster R-CNN</h4> 
<ul><li>intro: ACM MM 2017</li><li>arxiv: https://arxiv.org/abs/1709.08295</li></ul> 
<hr> 
<h3><a id="Tutorials__Talks_2554"></a>Tutorials / Talks</h3> 
<h4><a id="Convolutional_Feature_Maps_Elements_of_efficient_and_accurate_CNNbased_object_detection_2555"></a>Convolutional Feature Maps: Elements of efficient (and accurate) CNN-based object detection</h4> 
<ul><li>slides: http://research.microsoft.com/en-us/um/people/kahe/iccv15tutorial/iccv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf</li></ul> 
<h4><a id="Towards_Good_Practices_for_Recognition__Detection_2559"></a>Towards Good Practices for Recognition &amp; Detection</h4> 
<ul><li>intro: Hikvision Research Institute. Supervised Data Augmentation (SDA)</li><li>slides: http://image-net.org/challenges/talks/2016/Hikvision_at_ImageNet_2016.pdf</li></ul> 
<h4><a id="Work_in_progress_Improving_object_detection_and_instance_segmentation_for_small_objects_2564"></a>Work in progress: Improving object detection and instance segmentation for small objects</h4> 
<p><a href="https://docs.google.com/presentation/d/1OTfGn6mLe1VWE8D0q6Tu_WwFTSoLGd4OF8WCYnOWcVo/edit#slide=id.g37418adc7a_0_229" rel="nofollow">https://docs.google.com/presentation/d/1OTfGn6mLe1VWE8D0q6Tu_WwFTSoLGd4OF8WCYnOWcVo/edit#slide=id.g37418adc7a_0_229</a></p> 
<h4><a id="Object_Detection_with_Deep_Learning_A_Review_2568"></a>Object Detection with Deep Learning: A Review</h4> 
<ul><li>arxiv: https://arxiv.org/abs/1807.05511</li></ul> 
<hr> 
<h3><a id="Projects_2574"></a>Projects</h3> 
<h4><a id="Detectron_2575"></a>Detectron</h4> 
<ul><li>intro: FAIR’s research platform for object detection research, implementing popular algorithms like Mask R-CNN and RetinaNet.</li><li>github: https://github.com/facebookresearch/Detectron</li></ul> 
<h4><a id="TensorBox_a_simple_framework_for_training_neural_networks_to_detect_objects_in_images_2580"></a>TensorBox: a simple framework for training neural networks to detect objects in images</h4> 
<ul><li>intro: “The basic model implements the simple and robust GoogLeNet-OverFeat algorithm. We additionally provide an implementation of the ReInspect algorithm”</li><li>github: https://github.com/Russell91/TensorBox</li></ul> 
<h4><a id="Object_detection_in_torch_Implementation_of_some_object_detection_frameworks_in_torch_2585"></a>Object detection in torch: Implementation of some object detection frameworks in torch</h4> 
<ul><li>github: https://github.com/fmassa/object-detection.torch</li></ul> 
<h4><a id="Using_DIGITS_to_train_an_Object_Detection_network_2589"></a>Using DIGITS to train an Object Detection network</h4> 
<ul><li>github: https://github.com/NVIDIA/DIGITS/blob/master/examples/object-detection/README.md</li></ul> 
<h4><a id="FCNMultiBox_Detector_2593"></a>FCN-MultiBox Detector</h4> 
<ul><li>intro: Full convolution MultiBox Detector (like SSD) implemented in Torch.</li><li>github: https://github.com/teaonly/FMD.torch</li></ul> 
<h4><a id="KittiBox_A_car_detection_model_implemented_in_Tensorflow_2598"></a>KittiBox: A car detection model implemented in Tensorflow.</h4> 
<ul><li>keywords: MultiNet</li><li>intro: KittiBox is a collection of scripts to train out model FastBox on the Kitti Object Detection Dataset</li><li>github: https://github.com/MarvinTeichmann/KittiBox</li></ul> 
<h4><a id="Deformable_Convolutional_Networks__MST__SoftNMS_2604"></a>Deformable Convolutional Networks + MST + Soft-NMS</h4> 
<ul><li>github: https://github.com/bharatsingh430/Deformable-ConvNets</li></ul> 
<h4><a id="How_to_Build_a_Realtime_HandDetector_using_Neural_Networks_SSD_on_Tensorflow_2608"></a>How to Build a Real-time Hand-Detector using Neural Networks (SSD) on Tensorflow</h4> 
<ul><li>blog: https://towardsdatascience.com/how-to-build-a-real-time-hand-detector-using-neural-networks-ssd-on-tensorflow-d6bac0e4b2ce</li><li>github: https://github.com//victordibia/handtracking</li></ul> 
<h4><a id="Metrics_for_object_detection_2613"></a>Metrics for object detection</h4> 
<ul><li>intro: Most popular metrics used to evaluate object detection algorithms</li><li>github: https://github.com/rafaelpadilla/Object-Detection-Metrics</li></ul> 
<h4><a id="MobileNetv2SSDLite_2619"></a>MobileNetv2-SSDLite</h4> 
<ul><li>intro: Caffe implementation of SSD and SSDLite detection on MobileNetv2, converted from tensorflow.</li><li>github: https://github.com/chuanqi305/MobileNetv2-SSDLite</li></ul> 
<hr> 
<h3><a id="Leaderboard_2624"></a>Leaderboard</h3> 
<h4><a id="Detection_Results_VOC2012_2625"></a>Detection Results: VOC2012</h4> 
<ul><li>intro: Competition “comp4” (train on additional data)</li><li>homepage: http://host.robots.ox.ac.uk:8080/leaderboard/displaylb.php?challengeid=11&amp;compid=4</li></ul> 
<hr> 
<h3><a id="Tools_2632"></a>Tools</h3> 
<h4><a id="BeaverDam_Video_annotation_tool_for_deep_learning_training_labels_2633"></a>BeaverDam: Video annotation tool for deep learning training labels</h4> 
<p>https://github.com/antingshen/BeaverDam</p> 
<hr> 
<h3><a id="Blogs_2639"></a>Blogs</h3> 
<h4><a id="Convolutional_Neural_Networks_for_Object_Detection_2640"></a>Convolutional Neural Networks for Object Detection</h4> 
<p>http://rnd.azoft.com/convolutional-neural-networks-object-detection/</p> 
<h4><a id="Introducing_automatic_object_detection_to_visual_search_Pinterest_2644"></a>Introducing automatic object detection to visual search (Pinterest)</h4> 
<ul><li>keywords: Faster R-CNN</li><li>blog: https://engineering.pinterest.com/blog/introducing-automatic-object-detection-visual-search</li><li>demo: https://engineering.pinterest.com/sites/engineering/files/Visual%20Search%20V1%20-%20Video.mp4</li><li>review: https://news.developer.nvidia.com/pinterest-introduces-the-future-of-visual-search/?mkt_tok=eyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%3D</li></ul> 
<h4><a id="Deep_Learning_for_Object_Detection_with_DIGITS_2651"></a>Deep Learning for Object Detection with DIGITS</h4> 
<ul><li>blog: https://devblogs.nvidia.com/parallelforall/deep-learning-object-detection-digits/</li></ul> 
<h4><a id="Analyzing_The_Papers_Behind_Facebooks_Computer_Vision_Approach_2655"></a>Analyzing The Papers Behind Facebook’s Computer Vision Approach</h4> 
<ul><li>keywords: DeepMask, SharpMask, MultiPathNet</li><li>blog: https://adeshpande3.github.io/adeshpande3.github.io/Analyzing-the-Papers-Behind-Facebook’s-Computer-Vision-Approach/</li></ul> 
<h4><a id="Easily_Create_High_Quality_Object_Detectors_with_Deep_Learning_2660"></a>Easily Create High Quality Object Detectors with Deep Learning</h4> 
<ul><li>intro: dlib v19.2</li><li>blog: http://blog.dlib.net/2016/10/easily-create-high-quality-object.html</li></ul> 
<h4><a id="How_to_Train_a_DeepLearned_Object_Detection_Model_in_the_Microsoft_Cognitive_Toolkit_2665"></a>How to Train a Deep-Learned Object Detection Model in the Microsoft Cognitive Toolkit</h4> 
<ul><li>blog: https://blogs.technet.microsoft.com/machinelearning/2016/10/25/how-to-train-a-deep-learned-object-detection-model-in-cntk/</li><li>github: https://github.com/Microsoft/CNTK/tree/master/Examples/Image/Detection/FastRCNN</li></ul> 
<h4><a id="Object_Detection_in_Satellite_Imagery_a_Low_Overhead_Approach_2670"></a>Object Detection in Satellite Imagery, a Low Overhead Approach</h4> 
<ul><li>part 1: https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7#.2csh4iwx9</li><li>part 2: https://medium.com/the-downlinq/object-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92#.f9b7dgf64</li></ul> 
<h4><a id="You_Only_Look_Twice%E2%80%8A%E2%80%8AMultiScale_Object_Detection_in_Satellite_Imagery_With_Convolutional_Neural_Networks_2675"></a>You Only Look Twice — Multi-Scale Object Detection in Satellite Imagery With Convolutional Neural Networks</h4> 
<ul><li>part 1: https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571#.fmmi2o3of</li><li>part 2: https://medium.com/the-downlinq/you-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588#.nwzarsz1t</li></ul> 
<h4><a id="Faster_RCNN_Pedestrian_and_Car_Detection_2680"></a>Faster R-CNN Pedestrian and Car Detection</h4> 
<ul><li>blog: https://bigsnarf.wordpress.com/2016/11/07/faster-r-cnn-pedestrian-and-car-detection/</li><li>ipn: https://gist.github.com/bigsnarfdude/2f7b2144065f6056892a98495644d3e0#file-demo_faster_rcnn_notebook-ipynb</li><li>github: https://github.com/bigsnarfdude/Faster-RCNN_TF</li></ul> 
<h4><a id="Small_UNet_for_vehicle_detection_2686"></a>Small U-Net for vehicle detection</h4> 
<ul><li>blog: https://medium.com/@vivek.yadav/small-u-net-for-vehicle-detection-9eec216f9fd6#.md4u80kad</li></ul> 
<h4><a id="Region_of_interest_pooling_explained_2690"></a>Region of interest pooling explained</h4> 
<ul><li>blog: https://deepsense.io/region-of-interest-pooling-explained/</li><li>github: https://github.com/deepsense-io/roi-pooling</li></ul> 
<h4><a id="Supercharge_your_Computer_Vision_models_with_the_TensorFlow_Object_Detection_API_2695"></a>Supercharge your Computer Vision models with the TensorFlow Object Detection API</h4> 
<ul><li>blog: https://research.googleblog.com/2017/06/supercharge-your-computer-vision-models.html</li><li>github: https://github.com/tensorflow/models/tree/master/object_detection</li></ul> 
<h4><a id="Understanding_SSD_MultiBox%E2%80%8A%E2%80%8ARealTime_Object_Detection_In_Deep_Learning_2700"></a>Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning</h4> 
<p>https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab</p> 
<h4><a id="Oneshot_object_detection_2703"></a>One-shot object detection</h4> 
<p>http://machinethink.net/blog/object-detection/</p> 
<h4><a id="An_overview_of_object_detection_onestage_methods_2706"></a>An overview of object detection: one-stage methods</h4> 
<p>https://www.jeremyjordan.me/object-detection-one-stage/</p> 
<h3><a id="deep_learning_object_detection_2709"></a>deep learning object detection</h3> 
<ul><li>intro: A paper list of object detection using deep learning.</li><li>github: https://github.com/hoya012/deep_learning_object_detection</li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/04255788e64f9b24f0b056b23906c245/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">关于set   -o   vi  的使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/158c7eb8e8eaa640c23f5c81e2445500/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">spring boot配置详情</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>