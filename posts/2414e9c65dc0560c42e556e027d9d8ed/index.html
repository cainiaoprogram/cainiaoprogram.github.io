<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>面试宝典之消息中间件面试题 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="面试宝典之消息中间件面试题" />
<meta property="og:description" content="RabbitMq: 1、RabbitMQ有啥用处？ （1）服务间异步通信
（2）顺序消费
（3）定时任务
（4）请求削峰
2、RabbitMQ有哪些常用的工作模式？ 工作模式（Work）发布订阅模式（Fanout）路由模式（Routing）主题模式（Topic） 3、如何保证RabbitMQ消息不被重复消费？ 通过消费端处理，每条消息分配唯一的id，消费端在消费的时候验证，过滤掉重复的消息。使用乐观锁实现，保证接口的幂等性。 4、如何保证RabbitMQ消息的可靠传输？ 发送端：
（1）开启Confirm模式（消息确认机制或者事务模式）。
（2）如果消息发送失败做补偿处理，记录日志重新发送等，确保消息最终发送成功。
队列：
（1）声明交换机，队列的时候设置持久化参数。
（2）发送消息的时候设置消息的持久化参数，队列消息持久化到磁盘上，即便是宕机，重启之后消息依旧还在。
接收端：
（1）接收端开启手动应答模式。
（2）确定消息处理完成，消费端再向队列确认消费，删除消息。
（3）消费端如果处理异常，记录日志，通过其他补偿机制处理，确保最终消息处理成功。
5、RabbitMQ的交换机有哪些类型？ （1）fanout：如果交换器收到消息，将会广播到所有绑定的队列上
（2）direct：如果路由键完全匹配，消息就被投递到相应的队列
（3）topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符
6、Topic模式时，Routingkey中的#号和*号有什么区别？ #号标识0个字符、1个字符、多个字符*号表示1个或者多个字符 RocketMQ: 基础
1.为什么要使用消息队列呢？
消息队列主要有三大用途，我们拿一个电商系统的下单举例：
解耦：引入消息队列之前，下单完成之后，需要订单服务去调用库存服务减库存，调用营销服务加营销数据……引入消息队列之后，可以把订单完成的消息丢进队列里，下游服务自己去调用就行了，这样就完成了订单服务和其它服务的解耦合。
异步：订单支付之后，我们要扣减库存、增加积分、发送消息等等，这样一来这个链路就长了，链路一长，响应时间就变长了。引入消息队列，除了更新订单状态，其它的都可以异步去做，这样一来就来，就能降低响应时间。
削峰：消息队列合一用来削峰，例如秒杀系统，平时流量很低，但是要做秒杀活动，秒杀的时候流量疯狂怼进来，我们的服务器，Redis，MySQL各自的承受能力都不一样，直接全部流量照单全收肯定有问题啊，严重点可能直接打挂了。
我们可以把请求扔到队列里面，只放出我们服务能处理的流量，这样就能抗住短时间的大流量了。
解耦、异步、削峰，是消息队列最主要的三大作用。
2.为什么要选择RocketMQ?
市场上几大消息队列对比如下：
RabbitMQ ActiveMQ RocketMQ Kafka
公司 Rabbit Apache 阿里 Apache
语言 Erlang Java Java Scala&amp;Java
协议支持 AMPQ OpenWire、STOMP、REST、 XMPP、AMQP 自定义 自定义协议，社区封装了http协议支持
客户端支持语言 官方支持Erlang、Java、Ruby等，社区查出多种API，几乎支持所有语言 Java、C、C&#43;&#43;、Python、PHP、Perl，.net 等 Java、C&#43;&#43;（不成熟） 官方支持Java，社区产出多种API，如PHP，Python等
单击吞吐量 3.万级 4." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2414e9c65dc0560c42e556e027d9d8ed/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-09T19:35:42+08:00" />
<meta property="article:modified_time" content="2024-01-09T19:35:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">面试宝典之消息中间件面试题</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h4>RabbitMq:</h4> 
<h5>1、RabbitMQ有啥用处？</h5> 
<p>（1）服务间异步通信<br> （2）顺序消费<br> （3）定时任务<br> （4）请求削峰</p> 
<h5>2、RabbitMQ有哪些常用的工作模式？</h5> 
<ul><li>工作模式（Work）</li><li>发布订阅模式（Fanout）</li><li>路由模式（Routing）</li><li>主题模式（Topic）</li></ul> 
<h5>3、如何保证RabbitMQ消息不被重复消费？</h5> 
<ul><li>通过消费端处理，每条消息分配唯一的id，消费端在消费的时候验证，过滤掉重复的消息。</li><li>使用乐观锁实现，保证接口的幂等性。</li></ul> 
<h5>4、如何保证RabbitMQ消息的可靠传输？</h5> 
<ul><li> <p>发送端：<br> （1）开启Confirm模式（消息确认机制或者事务模式）。<br> （2）如果消息发送失败做补偿处理，记录日志重新发送等，确保消息最终发送成功。</p> </li><li> <p>队列：<br> （1）声明交换机，队列的时候设置持久化参数。<br> （2）发送消息的时候设置消息的持久化参数，队列消息持久化到磁盘上，即便是宕机，重启之后消息依旧还在。</p> </li><li> <p>接收端：<br> （1）接收端开启手动应答模式。<br> （2）确定消息处理完成，消费端再向队列确认消费，删除消息。<br> （3）消费端如果处理异常，记录日志，通过其他补偿机制处理，确保最终消息处理成功。</p> </li></ul> 
<h5>5、RabbitMQ的交换机有哪些类型？</h5> 
<p>（1）fanout：如果交换器收到消息，将会广播到所有绑定的队列上<br> （2）direct：如果路由键完全匹配，消息就被投递到相应的队列<br> （3）topic：可以使来自不同源头的消息能够到达同一个队列。 使用 topic 交换器时，可以使用通配符</p> 
<h5>6、Topic模式时，Routingkey中的#号和*号有什么区别？</h5> 
<ul><li>#号标识0个字符、1个字符、多个字符</li><li>*号表示1个或者多个字符</li></ul> 
<p></p> 
<h4>RocketMQ:</h4> 
<h6><br> 基础<br> 1.为什么要使用消息队列呢？<br>  </h6> 
<p>消息队列主要有三大用途，我们拿一个电商系统的下单举例：</p> 
<p><strong>解耦</strong>：引入消息队列之前，下单完成之后，需要订单服务去调用库存服务减库存，调用营销服务加营销数据……引入消息队列之后，可以把订单完成的消息丢进队列里，下游服务自己去调用就行了，这样就完成了订单服务和其它服务的解耦合。</p> 
<p><br><strong>异步</strong>：订单支付之后，我们要扣减库存、增加积分、发送消息等等，这样一来这个链路就长了，链路一长，响应时间就变长了。引入消息队列，除了更新订单状态，其它的都可以异步去做，这样一来就来，就能降低响应时间。</p> 
<p><br><strong>削峰</strong>：消息队列合一用来削峰，例如秒杀系统，平时流量很低，但是要做秒杀活动，秒杀的时候流量疯狂怼进来，我们的服务器，Redis，MySQL各自的承受能力都不一样，直接全部流量照单全收肯定有问题啊，严重点可能直接打挂了。<br> 我们可以把请求扔到队列里面，只放出我们服务能处理的流量，这样就能抗住短时间的大流量了。</p> 
<p><strong>解耦、异步、削峰，是消息队列最主要的三大作用。</strong></p> 
<p><strong>2.为什么要选择RocketMQ?</strong><br> 市场上几大消息队列对比如下：</p> 
<p><strong>RabbitMQ    ActiveMQ    RocketMQ    Kafka</strong><br> 公司    Rabbit    Apache    阿里    Apache<br> 语言    Erlang    Java    Java    Scala&amp;Java<br> 协议支持    AMPQ    OpenWire、STOMP、REST、 XMPP、AMQP    自定义    自定义协议，社区封装了http协议支持<br> 客户端支持语言    官方支持Erlang、Java、Ruby等，社区查出多种API，几乎支持所有语言    Java、C、C++、Python、PHP、Perl，.net 等    Java、C++（不成熟）    官方支持Java，社区产出多种API，如PHP，Python等<br><strong>单击吞吐量    3.万级    4.万级    1.十万级    2.十万级</strong><br><strong>消息延迟    微秒级    毫秒级    毫秒级    毫秒以内</strong><br> 可用性    高，基于主从架构实现可用性    高，基于主从架构实现可用性    非常高，分布式架构    非常高，分布式架构，一个数据多副本<br> 消息可靠性    -    有较低的概率丢失数据    经过参数优化配置，可以做到零丢失    经过参数配置，消息可以做到零丢失<br> 功能支持    基于erlang开发，所以并发性能极强，性能极好，延时低    MQ领域的功能极其完备    MQ功能较为完备，分布式扩展性好    功能较为简单，主要支持加单MQ功能<br> 优势    erlang语言开发，性能极好、延时很低，吞吐量万级、MQ功能完备，管理界面非常好，社区活跃；互联网公司使用较多    非常成熟，功能强大，在业内大量公司和项目中都有应用    接口简单易用，阿里出品有保障，吞吐量大，分布式扩展方便、社区比较活跃，支持大规模的Topic、支持复杂的业务场景，可以基于源码进行定制开发    超高吞吐量，ms级的时延，极高的可用性和可靠性，分布式扩展方便<br> 劣势    吞吐量较低，erlang语音开发不容易进行定制开发，集群动态扩展麻烦    偶尔有较低概率丟失消息，社区活跃度不高    接口不是按照标准JMS规范走的，有的系统迁移要修改大量的代码，技术有被抛弃的风险    有可能进行消息的<br> 重复消费<br> 应用    都有使用    主要用于解耦和异步，较少用在大规模吞吐的场景中    用于大规模吞吐、复杂业务中    在大数据的实时计算和日志采集中被大规模使用，是业界的标准<br> 总结一下：</p> 
<p>选择中间件的可以从这些维度来考虑：可靠性，性能，功能，可运维行，可拓展性，社区活跃度。目前常用的几个中间件，ActiveMQ作为“老古董”，市面上用的已经不多，其它几种：</p> 
<p><strong>RabbitMQ：</strong></p> 
<p>优点：轻量，迅捷，容易部署和使用，拥有灵活的路由配置<br> 缺点：性能和吞吐量不太理想，不易进行二次开发<br><strong>RocketMQ：</strong></p> 
<p>优点：性能好，高吞吐量，稳定可靠，有活跃的中文社区<br> 缺点：兼容性上不是太好<br><strong>Kafka：</strong></p> 
<p>优点：拥有强大的性能及吞吐量，兼容性很好<br> 缺点：由于“攒一波再处理”导致延迟比较高<br> 我们的系统是面向用户的C端系统，具有一定的并发量，对性能也有比较高的要求，所以选择了低延迟、吞吐量比较高，可用性比较好的RocketMQ。</p> 
<p>3.RocketMQ有什么优缺点？<br><strong>RocketMQ优点：</strong></p> 
<p>单机吞吐量：十万级<br> 可用性：非常高，分布式架构<br> 消息可靠性：经过参数优化配置，消息可以做到0丢失<br> 功能支持：MQ功能较为完善，还是分布式的，扩展性好<br> 支持10亿级别的消息堆积，不会因为堆积导致性能下降<br> 源码是Java，方便结合公司自己的业务二次开发<br> 天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况<br> RoketMQ在稳定性上可能更值得信赖，这些业务场景在阿里双11已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择RocketMQ<br><strong>RocketMQ缺点：</strong></p> 
<p>支持的客户端语言不多，目前是Java及c++，其中c++不成熟<br> 没有在 MQ核心中去实现JMS等接口，有些系统要迁移需要修改大量代码<br><strong>4.消息队列有哪些消息模型？</strong><br> 消息队列有两种模型：队列模型和发布/订阅模型。</p> 
<p><strong>队列模型</strong></p> 
<p>这是最初的一种消息队列模型，对应着消息队列“发-存-收”的模型。生产者往某个队列里面发送消息，一个队列可以存储多个生产者的消息，一个队列也可以有多个消费者，但是消费者之间是竞争关系，也就是说每条消息只能被一个消费者消费。</p> 
<p><strong>发布/订阅模型</strong><br> 如果需要将一份消息数据分发给多个消费者，并且每个消费者都要求收到全量的消息。很显然，队列模型无法满足这个需求。解决的方式就是发布/订阅模型。</p> 
<p>在发布 - 订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。</p> 
<p>它和 “队列模式” 的异同：生产者就是发布者，队列就是主题，消费者就是订阅者，无本质区别。唯一的不同点在于：一份消息数据是否可以被多次消费。</p> 
<p>5.那RocketMQ的消息模型呢？<br> RocketMQ使用的消息模型是标准的发布-订阅模型，在RocketMQ的术语表中，生产者、消费者和主题，与发布-订阅模型中的概念是完全一样的。</p> 
<p>RocketMQ本身的消息是由下面几部分组成：</p> 
<p><strong>Message</strong><br> Message（消息）就是要传输的信息。</p> 
<p>一条消息必须有一个主题（Topic），主题可以看做是你的信件要邮寄的地址。</p> 
<p>一条消息也可以拥有一个可选的标签（Tag）和额处的键值对，它们可以用于设置一个业务 Key 并在 Broker 上查找此消息以便在开发期间查找问题。</p> 
<p>Topic<br> Topic（主题）可以看做消息的归类，它是消息的第一级类型。比如一个电商系统可以分为：交易消息、物流消息等，一条消息必须有一个 Topic 。</p> 
<p>Topic 与生产者和消费者的关系非常松散，一个 Topic 可以有0个、1个、多个生产者向其发送消息，一个生产者也可以同时向不同的 Topic 发送消息。</p> 
<p>一个 Topic 也可以被 0个、1个、多个消费者订阅。</p> 
<p><strong>Tag</strong><br> Tag（标签）可以看作子主题，它是消息的第二级类型，用于为用户提供额外的灵活性。使用标签，同一业务模块不同目的的消息就可以用相同 Topic 而不同的 Tag 来标识。比如交易消息又可以分为：交易创建消息、交易完成消息等，一条消息可以没有 Tag 。</p> 
<p>标签有助于保持你的代码干净和连贯，并且还可以为 RocketMQ 提供的查询系统提供帮助。</p> 
<p><strong>Group</strong><br> RocketMQ中，订阅者的概念是通过消费组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被Consumer Group1消费过，也会再给Consumer Group2消费。</p> 
<p>消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。默认情况，如果一条消息被消费者Consumer1消费了，那同组的其他消费者就不会再收到这条消息。</p> 
<p><strong>Message Queue</strong><br> Message Queue（消息队列），一个 Topic 下可以设置多个消息队列，Topic 包括多个 Message Queue ，如果一个 Consumer 需要获取 Topic下所有的消息，就要遍历所有的 Message Queue。</p> 
<p>RocketMQ还有一些其它的Queue——例如ConsumerQueue。</p> 
<p><strong>Offset</strong><br> 在Topic的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要RocketMQ为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。</p> 
<p>也可以这么说，Queue 是一个长度无限的数组，Offset 就是下标。</p> 
<p>RocketMQ的消息模型中，这些就是比较关键的概念了。画张图总结一下：</p> 
<p><strong>6.消息的消费模式了解吗？</strong><br> 消息消费模式有两种：Clustering（集群消费）和Broadcasting（广播消费）。</p> 
<p>默认情况下就是集群消费，这种模式下一个消费者组共同消费一个主题的多个队列，一个队列只会被一个消费者消费，如果某个消费者挂掉，分组内其它消费者会接替挂掉的消费者继续消费。</p> 
<p>而广播消费消息会发给消费者组中的每一个消费者进行消费。</p> 
<p><strong>7.RoctetMQ基本架构了解吗？</strong><br> 先看图，RocketMQ的基本架构：</p> 
<p>RocketMQ 一共有四个部分组成：NameServer，Broker，Producer 生产者，Consumer 消费者，它们对应了：发现、发、存、收，为了保证高可用，一般每一部分都是集群部署的。</p> 
<p><strong>8.那能介绍一下这四部分吗？</strong><br> 类比一下我们生活的邮政系统——</p> 
<p>邮政系统要正常运行，离不开下面这四个角色， 一是发信者，二 是收信者， 三是负责暂存传输的邮局， 四是负责协调各个地方邮局的管理机构。对应到 RocketMQ 中，这四个角色就是 Producer、 Consumer、 Broker 、NameServer。</p> 
<p><strong>NameServer</strong><br> NameServer 是一个无状态的服务器，角色类似于 Kafka使用的 Zookeeper，但比 Zookeeper 更轻量。<br> 特点：</p> 
<p>每个 NameServer 结点之间是相互独立，彼此没有任何信息交互。<br> Nameserver 被设计成几乎是无状态的，通过部署多个结点来标识自己是一个伪集群，Producer 在发送消息前从 NameServer 中获取 Topic 的路由信息也就是发往哪个 Broker，Consumer 也会定时从 NameServer 获取 Topic 的路由信息，Broker 在启动时会向 NameServer 注册，并定时进行心跳连接，且定时同步维护的 Topic 到 NameServer。<br> 功能主要有两个：</p> 
<p><strong>1、和Broker 结点保持长连接。<br> 2、维护 Topic 的路由信息。</strong><br> Broker<br> 消息存储和中转角色，负责存储和转发消息。</p> 
<p>Broker 内部维护着一个个 Consumer Queue，用来存储消息的索引，真正存储消息的地方是 CommitLog（日志文件）。</p> 
<p>单个 Broker 与所有的 Nameserver 保持着长连接和心跳，并会定时将 Topic 信息同步到 NameServer，和 NameServer 的通信底层是通过 Netty 实现的。</p> 
<p><strong>Producer</strong><br> 消息生产者，业务端负责发送消息，由用户自行实现和分布式部署。</p> 
<p>Producer由用户进行分布式部署，消息由Producer通过多种负载均衡模式发送到Broker集群，发送低延时，支持快速失败。</p> 
<p>RocketMQ 提供了三种方式发送消息：同步、异步和单向</p> 
<p>同步发送：同步发送指消息发送方发出数据后会在收到接收方发回响应之后才发下一个数据包。一般用于重要通知消息，例如重要通知邮件、营销短信。<br> 异步发送：异步发送指发送方发出数据后，不等接收方发回响应，接着发送下个数据包，一般用于可能链路耗时较长而对响应时间敏感的业务场景，例如用户视频上传后通知启动转码服务。<br> 单向发送：单向发送是指只负责发送消息而不等待服务器回应且没有回调函数触发，适用于某些耗时非常短但对可靠性要求并不高的场景，例如日志收集。<br><strong>Consumer</strong><br> 消息消费者，负责消费消息，一般是后台系统负责异步消费。</p> 
<p>Consumer也由用户部署，支持PUSH和PULL两种消费模式，支持集群消费和广播消费，提供实时的消息订阅机制。<br> Pull：拉取型消费者（Pull Consumer）主动从消息服务器拉取信息，只要批量拉取到消息，用户应用就会启动消费过程，所以 Pull 称为主动消费型。<br> Push：推送型消费者（Push Consumer）封装了消息的拉取、消费进度和其他的内部维护工作，将消息到达时执行的回调接口留给用户应用程序来实现。所以 Push 称为被动消费类型，但其实从实现上看还是从消息服务器中拉取消息，不同于 Pull 的是 Push 首先要注册消费监听器，当监听器处触发后才开始消费消息。<br> 进阶<br> 9.如何保证消息的可用性/可靠性/不丢失呢？<br> 消息可能在哪些阶段丢失呢？可能会在这三个阶段发生丢失：生产阶段、存储阶段、消费阶段。</p> 
<p>所以要从这三个阶段考虑：</p> 
<p><strong>生产</strong><br> 在生产阶段，主要通过请求确认机制，来保证消息的可靠传递。</p> 
<p>1、同步发送的时候，要注意处理响应结果和异常。如果返回响应OK，表示消息成功发送到了Broker，如果响应失败，或者发生其它异常，都应该重试。<br> 2、异步发送的时候，应该在回调方法里检查，如果发送失败或者异常，都应该进行重试。<br> 3、如果发生超时的情况，也可以通过查询日志的API，来检查是否在Broker存储成功。<br> 存储<br> 存储阶段，可以通过配置可靠性优先的 Broker 参数来避免因为宕机丢消息，简单说就是可靠性优先的场景都应该使用同步。</p> 
<p>1、消息只要持久化到CommitLog（日志文件）中，即使Broker宕机，未消费的消息也能重新恢复再消费。<br> 2、Broker的刷盘机制：同步刷盘和异步刷盘，不管哪种刷盘都可以保证消息一定存储在pagecache中（内存中），但是同步刷盘更可靠，它是Producer发送消息后等数据持久化到磁盘之后再返回响应给Producer。<br> 3、Broker通过主从模式来保证高可用，Broker支持Master和Slave同步复制、Master和Slave异步复制模式，生产者的消息都是发送给Master，但是消费既可以从Master消费，也可以从Slave消费。同步复制模式可以保证即使Master宕机，消息肯定在Slave中有备份，保证了消息不会丢失。</p> 
<p><br><strong>消费</strong><br> 从Consumer角度分析，如何保证消息被成功消费？</p> 
<p>Consumer保证消息成功消费的关键在于确认的时机，不要在收到消息后就立即发送消费确认，而是应该在执行完所有消费业务逻辑之后，再发送消费确认。因为消息队列维护了消费的位置，逻辑执行失败了，没有确认，再去队列拉取消息，就还是之前的一条。<br> 10.如何处理消息重复的问题呢？<br> 对分布式消息队列来说，同时做到确保一定投递和不重复投递是很难的，就是所谓的“有且仅有一次” 。RocketMQ择了确保一定投递，保证消息不丢失，但有可能造成消息重复。</p> 
<p>处理消息重复问题，主要有业务端自己保证，主要的方式有两种：业务幂等和消息去重。</p> 
<p>业务幂等：第一种是保证消费逻辑的幂等性，也就是多次调用和一次调用的效果是一样的。这样一来，不管消息消费多少次，对业务都没有影响。</p> 
<p>消息去重：第二种是业务端，对重复的消息就不再消费了。这种方法，需要保证每条消息都有一个唯一的编号，通常是业务相关的，比如订单号，消费的记录需要落库，而且需要保证和消息确认这一步的原子性。</p> 
<p>具体做法是可以建立一个消费记录表，拿到这个消息做数据库的insert操作。给这个消息做一个唯一主键（primary key）或者唯一约束，那么就算出现重复消费的情况，就会导致主键冲突，那么就不再处理这条消息。</p> 
<p><strong>11.怎么处理消息积压？</strong><br> 发生了消息积压，这时候就得想办法赶紧把积压的消息消费完，就得考虑提高消费能力，一般有两种办法：</p> 
<p>消费者扩容：如果当前Topic的Message Queue的数量大于消费者数量，就可以对消费者进行扩容，增加消费者，来提高消费能力，尽快把积压的消息消费玩。<br> 消息迁移Queue扩容：如果当前Topic的Message Queue的数量小于或者等于消费者数量，这种情况，再扩容消费者就没什么用，就得考虑扩容Message Queue。可以新建一个临时的Topic，临时的Topic多设置一些Message Queue，然后先用一些消费者把消费的数据丢到临时的Topic，因为不用业务处理，只是转发一下消息，还是很快的。接下来用扩容的消费者去消费新的Topic里的数据，消费完了之后，恢复原状。</p> 
<p><br><strong>12.顺序消息如何实现？</strong><br> 顺序消息是指消息的消费顺序和产生顺序相同，在有些业务逻辑下，必须保证顺序，比如订单的生成、付款、发货，这个消息必须按顺序处理才行。</p> 
<p>顺序消息分为全局顺序消息和部分顺序消息：</p> 
<p>全局顺序消息指某个 Topic 下的所有消息都要保证顺序；</p> 
<p>部分顺序消息只要保证每一组消息被顺序消费即可，比如订单消息，只要保证同一个订单 ID 个消息能按顺序消费即可。</p> 
<p>部分顺序消息<br> 部分顺序消息相对比较好实现，生产端需要做到把同 ID 的消息发送到同一个 Message Queue ；在消费过程中，要做到从同一个Message Queue读取的消息顺序处理——消费端不能并发处理顺序消息，这样才能达到部分有序。</p> 
<p>发送端使用 MessageQueueSelector 类来控制 把消息发往哪个 Message Queue 。</p> 
<p>消费端通过使用 MessageListenerOrderly 来解决单 Message Queue 的消息被并发处理的问题。</p> 
<p>全局顺序消息<br> RocketMQ 默认情况下不保证顺序，比如创建一个 Topic ，默认八个写队列，八个读队列，这时候一条消息可能被写入任意一个队列里；在数据的读取过程中，可能有多个 Consumer ，每个 Consumer 也可能启动多个线程并行处理，所以消息被哪个 Consumer 消费，被消费的顺序和写人的顺序是否一致是不确定的。</p> 
<p>要保证全局顺序消息， 需要先把 Topic 的读写队列数设置为 一，然后Producer Consumer 的并发设置，也要是一。简单来说，为了保证整个 Topic全局消息有序，只能消除所有的并发处理，各部分都设置成单线程处理 ，这时候就完全牺牲RocketMQ的高并发、高吞吐的特性了。</p> 
<p><strong>13.如何实现消息过滤？</strong><br> 有两种方案：</p> 
<p>一种是在 Broker 端按照 Consumer 的去重逻辑进行过滤，这样做的好处是避免了无用的消息传输到 Consumer 端，缺点是加重了 Broker 的负担，实现起来相对复杂。<br> 另一种是在 Consumer 端过滤，比如按照消息设置的 tag 去重，这样的好处是实现起来简单，缺点是有大量无用的消息到达了 Consumer 端只能丢弃不处理。<br> 一般采用Cosumer端过滤，如果希望提高吞吐量，可以采用Broker过滤。</p> 
<p>对消息的过滤有三种方式：</p> 
<p>根据Tag过滤：这是最常见的一种，用起来高效简单</p> 
<pre><code class="language-java">DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("CID_EXAMPLE");
consumer.subscribe("TOPIC", "TAGA || TAGB || TAGC");</code></pre> 
<p><br><br> SQL 表达式过滤：SQL表达式过滤更加灵活</p> 
<pre><code class="language-java">DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("please_rename_unique_group_name_4");
// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3
consumer.subscribe("TopicTest", MessageSelector.bySql("a between 0 and 3");
consumer.registerMessageListener(new MessageListenerConcurrently() {
   @Override
   public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) {
       return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
   }
});
consumer.start();
</code></pre> 
<p><br><br> Filter Server 方式：最灵活，也是最复杂的一种方式，允许用户自定义函数进行过滤<br> 14.延时消息了解吗？<br> 电商的订单超时自动取消，就是一个典型的利用延时消息的例子，用户提交了一个订单，就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。</p> 
<p>RocketMQ是支持延时消息的，只需要在生产消息的时候设置消息的延时级别：</p> 
<pre><code class="language-java">// 实例化一个生产者来产生延时消息
DefaultMQProducer producer = new DefaultMQProducer("ExampleProducerGroup");
// 启动生产者
producer.start();
int totalMessagesToSend = 100;
for (int i = 0; i &lt; totalMessagesToSend; i++) {
    Message message = new Message("TestTopic", ("Hello scheduled message " + i).getBytes());
    // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel)
    message.setDelayTimeLevel(3);
    // 发送消息
    producer.send(message);
}</code></pre> 
<p><br> 但是目前RocketMQ支持的延时级别是有限的：</p> 
<pre><code class="language-java">private String messageDelayLevel = "1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h";</code></pre> 
<p><br><strong>RocketMQ怎么实现延时消息的？</strong><br> 简单，八个字：临时存储+定时任务。</p> 
<p>Broker收到延时消息了，会先发送到主题（SCHEDULE_TOPIC_XXXX）的相应时间段的Message Queue中，然后通过一个定时任务轮询这些队列，到期后，把消息投递到目标Topic的队列中，然后消费者就可以正常消费这些消息。</p> 
<p><strong>15.怎么实现分布式消息事务的？半消息？</strong><br> 半消息：是指暂时还不能被 Consumer 消费的消息，Producer 成功发送到 Broker 端的消息，但是此消息被标记为 “暂不可投递” 状态，只有等 Producer 端执行完本地事务后经过二次确认了之后，Consumer 才能消费此条消息。</p> 
<p>依赖半消息，可以实现分布式消息事务，其中的关键在于二次确认以及消息回查：</p> 
<p>1、Producer 向 broker 发送半消息<br> 2、Producer 端收到响应，消息发送成功，此时消息是半消息，标记为 “不可投递” 状态，Consumer 消费不了。<br> 3、Producer 端执行本地事务。<br> 4、正常情况本地事务执行完成，Producer 向 Broker 发送 Commit/Rollback，如果是 Commit，Broker 端将半消息标记为正常消息，Consumer 可以消费，如果是 Rollback，Broker 丢弃此消息。<br> 5、异常情况，Broker 端迟迟等不到二次确认。在一定时间后，会查询所有的半消息，然后到 Producer 端查询半消息的执行情况。<br> 6、Producer 端查询本地事务的状态<br> 7、根据事务的状态提交 commit/rollback 到 broker 端。（5，6，7 是消息回查）<br> 8、消费者段消费到消息之后，执行本地事务，执行本地事务。<br> 16.死信队列知道吗？<br> 死信队列用于处理无法被正常消费的消息，即死信消息。</p> 
<p>当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中，该特殊队列称为死信队列。</p> 
<p>死信消息的特点：</p> 
<p>不会再被消费者正常消费。<br> 有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，需要在死信消息产生后的 3 天内及时处理。<br> 死信队列的特点：</p> 
<p>一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。<br> 如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。<br> 一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。<br> RocketMQ 控制台提供对死信消息的查询、导出和重发的功能。</p> 
<p><strong>17.如何保证RocketMQ的高可用？</strong><br> NameServer因为是无状态，且不相互通信的，所以只要集群部署就可以保证高可用。</p> 
<p>RocketMQ的高可用主要是在体现在Broker的读和写的高可用，Broker的高可用是通过集群和主从实现的。</p> 
<p>Broker可以配置两种角色：Master和Slave，Master角色的Broker支持读和写，Slave角色的Broker只支持读，Master会向Slave同步消息。</p> 
<p>也就是说Producer只能向Master角色的Broker写入消息，Cosumer可以从Master和Slave角色的Broker读取消息。</p> 
<p>Consumer 的配置文件中，并不需要设置是从 Master 读还是从 Slave读，当 Master 不可用或者繁忙的时候， Consumer 的读请求会被自动切换到从 Slave。有了自动切换 Consumer 这种机制，当一个 Master 角色的机器出现故障后，Consumer 仍然可以从 Slave 读取消息，不影响 Consumer 读取消息，这就实现了读的高可用。</p> 
<p>如何达到发送端写的高可用性呢？在创建 Topic 的时候，把 Topic 的多个Message Queue 创建在多个 Broker 组上（相同 Broker 名称，不同 brokerId机器组成 Broker 组），这样当 Broker 组的 Master 不可用后，其他组Master 仍然可用， Producer 仍然可以发送消息 RocketMQ 目前还不支持把Slave自动转成 Master ，如果机器资源不足，需要把 Slave 转成 Master ，则要手动停止 Slave 色的 Broker ，更改配置文件，用新的配置文件启动 Broker。</p> 
<p>原理<br><strong>18.说一下RocketMQ的整体工作流程？</strong><br> 简单来说，RocketMQ是一个分布式消息队列，也就是消息队列+分布式系统。</p> 
<p>作为消息队列，它是发-存-收的一个模型，对应的就是Producer、Broker、Cosumer；作为分布式系统，它要有服务端、客户端、注册中心，对应的就是Broker、Producer/Consumer、NameServer</p> 
<p>所以我们看一下它主要的工作流程：RocketMQ由NameServer注册中心集群、Producer生产者集群、Consumer消费者集群和若干Broker（RocketMQ进程）组成：</p> 
<p>Broker在启动的时候去向所有的NameServer注册，并保持长连接，每30s发送一次心跳<br> Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息<br> Conusmer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费</p> 
<p><br><strong>19.为什么RocketMQ不使用Zookeeper作为注册中心呢？</strong><br> Kafka我们都知道采用Zookeeper作为注册中心——当然也开始逐渐去Zookeeper，RocketMQ不使用Zookeeper其实主要可能从这几方面来考虑：</p> 
<p>CAP理论，指的是在一个分布式系统中，Consistency(一致性)、Availability(可用性)、Partition Tolerance(分区容错性)，不能同时成立</p> 
<p>基于可用性的考虑，根据CAP理论，同时最多只能满足两个点，而Zookeeper满足的是CP，也就是说Zookeeper并不能保证服务的可用性，Zookeeper在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状态，而这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计。<br> 基于性能的考虑，NameServer本身的实现非常轻量，而且可以通过增加机器的方式水平扩展，增加集群的抗压能力，而Zookeeper的写是不可扩展的，Zookeeper要解决这个问题只能通过划分领域，划分多个Zookeeper集群来解决，首先操作起来太复杂，其次这样还是又违反了CAP中的A的设计，导致服务之间是不连通的。<br> 持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久性，而对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。而且本身存储的数据应该是高度定制化的。<br> 消息发送应该弱依赖注册中心，而RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时候从NameServer获取到Broker地址后缓存到本地，如果NameServer整个集群不可用，短时间内对于生产者和消费者并不会产生太大影响。<br> 20.Broker是怎么保存数据的呢？<br> RocketMQ主要的存储文件包括CommitLog文件、ConsumeQueue文件、Indexfile文件。</p> 
<p>CommitLog：消息主体以及元数据的存储主体，存储Producer端写入的消息主体内容,消息内容不是定长的。单个文件大小默认1G, 文件名长度为20位，左边补零，剩余为起始偏移量，比如00000000000000000000代表了第一个文件，起始偏移量为0，文件大小为1G=1073741824；当第一个文件写满了，第二个文件为00000000001073741824，起始偏移量为1073741824，以此类推。消息主要是顺序写入日志文件，当文件满了，写入下一个文件。</p> 
<p>CommitLog文件保存于${Rocket_Home}/store/commitlog目录中，从图中我们可以明显看出来文件名的偏移量，每个文件默认1G，写满后自动生成一个新的文件。</p> 
<p>ConsumeQueue：消息消费队列，引入的目的主要是提高消息消费的性能，由于RocketMQ是基于主题topic的订阅模式，消息消费是针对主题进行的，如果要遍历commitlog文件中根据topic检索消息是非常低效的。</p> 
<p>Consumer即可根据ConsumeQueue来查找待消费的消息。其中，ConsumeQueue（逻辑消费队列）作为消费消息的索引，保存了指定Topic下的队列消息在CommitLog中的起始物理偏移量offset，消息大小size和消息Tag的HashCode值。</p> 
<p>ConsumeQueue文件可以看成是基于Topic的CommitLog索引文件，故ConsumeQueue文件夹的组织方式如下：topic/queue/file三层组织结构，具体存储路径为：$HOME/store/consumequeue/{topic}/{queueId}/{fileName}。同样ConsumeQueue文件采取定长设计，每一个条目共20个字节，分别为8字节的CommitLog物理偏移量、4字节的消息长度、8字节tag hashcode，单个文件由30W个条目组成，可以像数组一样随机访问每一个条目，每个ConsumeQueue文件大小约5.72M；</p> 
<p>IndexFile：IndexFile（索引文件）提供了一种可以通过key或时间区间来查询消息的方法。Index文件的存储位置是：{fileName}，文件名fileName是以创建时的时间戳命名的，固定的单个IndexFile文件大小约为400M，一个IndexFile可以保存 2000W个索引，IndexFile的底层存储设计为在文件系统中实现HashMap结构，故RocketMQ的索引文件其底层实现为hash索引。</p> 
<p>总结一下：RocketMQ采用的是混合型的存储结构，即为Broker单个实例下所有的队列共用一个日志数据文件（即为CommitLog）来存储。</p> 
<p>RocketMQ的混合型存储结构(多个Topic的消息实体内容都存储于一个CommitLog中)针对Producer和Consumer分别采用了数据和索引部分相分离的存储结构，Producer发送消息至Broker端，然后Broker端使用同步或者异步的方式对消息刷盘持久化，保存至CommitLog中。</p> 
<p>只要消息被刷盘持久化至磁盘文件CommitLog中，那么Producer发送的消息就不会丢失。正因为如此，Consumer也就肯定有机会去消费这条消息。当无法拉取到消息后，可以等下一次消息拉取，同时服务端也支持长轮询模式，如果一个消息拉取请求未拉取到消息，Broker允许等待30s的时间，只要这段时间内有新消息到达，将直接返回给消费端。</p> 
<p>这里，RocketMQ的具体做法是，使用Broker端的后台服务线程—ReputMessageService不停地分发请求并异步构建ConsumeQueue（逻辑消费队列）和IndexFile（索引文件）数据。</p> 
<p><strong>21.说说RocketMQ怎么对文件进行读写的？</strong><br> RocketMQ对文件的读写巧妙地利用了操作系统的一些高效文件读写方式——PageCache、顺序读写、零拷贝。</p> 
<p>PageCache、顺序读取<br> 在RocketMQ中，ConsumeQueue逻辑消费队列存储的数据较少，并且是顺序读取，在page cache机制的预读取作用下，Consume Queue文件的读性能几乎接近读内存，即使在有消息堆积情况下也不会影响性能。而对于CommitLog消息存储的日志数据文件来说，读取消息内容时候会产生较多的随机访问读取，严重影响性能。如果选择合适的系统IO调度算法，比如设置调度算法为“Deadline”（此时块存储采用SSD的话），随机读的性能也会有所提升。</p> 
<p>页缓存（PageCache)是OS对文件的缓存，用于加速对文件的读写。一般来说，程序对文件进行顺序读写的速度几乎接近于内存的读写速度，主要原因就是由于OS使用PageCache机制对读写访问操作进行了性能优化，将一部分的内存用作PageCache。对于数据的写入，OS会先写入至Cache内，随后通过异步的方式由pdflush内核线程将Cache内的数据刷盘至物理磁盘上。对于数据的读取，如果一次读取文件时出现未命中PageCache的情况，OS从物理磁盘上访问读取文件的同时，会顺序对其他相邻块的数据文件进行预读取。</p> 
<p>零拷贝<br> 另外，RocketMQ主要通过MappedByteBuffer对文件进行读写操作。其中，利用了NIO中的FileChannel模型将磁盘上的物理文件直接映射到用户态的内存地址中（这种Mmap的方式减少了传统IO，将磁盘文件数据在操作系统内核地址空间的缓冲区，和用户应用程序地址空间的缓冲区之间来回进行拷贝的性能开销），将对文件的操作转化为直接对内存地址进行操作，从而极大地提高了文件的读写效率（正因为需要使用内存映射机制，故RocketMQ的文件存储都使用定长结构来存储，方便一次将整个文件映射至内存）。</p> 
<p>说说什么是零拷贝?<br> 在操作系统中，使用传统的方式，数据需要经历几次拷贝，还要经历用户态/内核态切换。</p> 
<p>从磁盘复制数据到内核态内存；<br> 从内核态内存复制到用户态内存；<br> 然后从用户态内存复制到网络驱动的内核态内存；<br> 最后是从网络驱动的内核态内存复制到网卡中进行传输。<br> 所以，可以通过零拷贝的方式，减少用户态与内核态的上下文切换和内存拷贝的次数，用来提升I/O的性能。零拷贝比较常见的实现方式是mmap，这种机制在Java中是通过MappedByteBuffer实现的。</p> 
<p><strong>22.消息刷盘怎么实现的呢？</strong><br> RocketMQ提供了两种刷盘策略：同步刷盘和异步刷盘</p> 
<p>同步刷盘：在消息达到Broker的内存之后，必须刷到commitLog日志文件中才算成功，然后返回Producer数据已经发送成功。<br> 异步刷盘：异步刷盘是指消息达到Broker内存后就返回Producer数据已经发送成功，会唤醒一个线程去将数据持久化到CommitLog日志文件中。<br> Broker 在消息的存取时直接操作的是内存（内存映射文件），这可以提供系统的吞吐量，但是无法避免机器掉电时数据丢失，所以需要持久化到磁盘中。</p> 
<p>刷盘的最终实现都是使用NIO中的 MappedByteBuffer.force() 将映射区的数据写入到磁盘，如果是同步刷盘的话，在Broker把消息写到CommitLog映射区后，就会等待写入完成。</p> 
<p>异步而言，只是唤醒对应的线程，不保证执行的时机，流程如图所示。</p> 
<p><strong>22.能说下 RocketMQ 的负载均衡是如何实现的？</strong><br> RocketMQ中的负载均衡都在Client端完成，具体来说的话，主要可以分为Producer端发送消息时候的负载均衡和Consumer端订阅消息的负载均衡。</p> 
<p><strong>Producer的负载均衡</strong><br> Producer端在发送消息的时候，会先根据Topic找到指定的TopicPublishInfo，在获取了TopicPublishInfo路由信息后，RocketMQ的客户端在默认方式下selectOneMessageQueue()方法会从TopicPublishInfo中的messageQueueList中选择一个队列（MessageQueue）进行发送消息。具这里有一个sendLatencyFaultEnable开关变量，如果开启，在随机递增取模的基础上，再过滤掉not available的Broker代理。</p> 
<p>所谓的"latencyFaultTolerance"，是指对之前失败的，按一定的时间做退避。例如，如果上次请求的latency超过550Lms，就退避3000Lms；超过1000L，就退避60000L；如果关闭，采用随机递增取模的方式选择一个队列（MessageQueue）来发送消息，latencyFaultTolerance机制是实现消息发送高可用的核心关键所在。</p> 
<p><strong>Consumer的负载均衡</strong><br> 在RocketMQ中，Consumer端的两种消费模式（Push/Pull）都是基于拉模式来获取消息的，而在Push模式只是对pull模式的一种封装，其本质实现为消息拉取线程在从服务器拉取到一批消息后，然后提交到消息消费线程池后，又“马不停蹄”的继续向服务器再次尝试拉取消息。如果未拉取到消息，则延迟一下又继续拉取。在两种基于拉模式的消费方式（Push/Pull）中，均需要Consumer端知道从Broker端的哪一个消息队列中去获取消息。因此，有必要在Consumer端来做负载均衡，即Broker端中多个MessageQueue分配给同一个ConsumerGroup中的哪些Consumer消费。</p> 
<p><strong>Consumer端的心跳包发送</strong><br> 在Consumer启动后，它就会通过定时任务不断地向RocketMQ集群中的所有Broker实例发送心跳包（其中包含了，消息消费分组名称、订阅关系集合、消息通信模式和客户端id的值等信息）。Broker端在收到Consumer的心跳消息后，会将它维护在ConsumerManager的本地缓存变量—consumerTable，同时并将封装后的客户端网络通道信息保存在本地缓存变量—channelInfoTable中，为之后做Consumer端的负载均衡提供可以依据的元数据信息。</p> 
<p>Consumer端实现负载均衡的核心类—RebalanceImpl<br> 在Consumer实例的启动流程中的启动MQClientInstance实例部分，会完成负载均衡服务线程—RebalanceService的启动（每隔20s执行一次）。</p> 
<p>通过查看源码可以发现，RebalanceService线程的run()方法最终调用的是RebalanceImpl类的rebalanceByTopic()方法，这个方法是实现Consumer端负载均衡的核心。</p> 
<p>rebalanceByTopic()方法会根据消费者通信类型为“广播模式”还是“集群模式”做不同的逻辑处理。这里主要来看下集群模式下的主要处理流程：</p> 
<p>(1) 从rebalanceImpl实例的本地缓存变量—topicSubscribeInfoTable中，获取该Topic主题下的消息消费队列集合（mqSet）；</p> 
<p>(2) 根据topic和consumerGroup为参数调用mQClientFactory.findConsumerIdList()方法向Broker端发送通信请求，获取该消费组下消费者Id列表；</p> 
<p>(3) 先对Topic下的消息消费队列、消费者Id排序，然后用消息队列分配策略算法（默认为：消息队列的平均分配算法），计算出待拉取的消息队列。这里的平均分配算法，类似于分页的算法，将所有MessageQueue排好序类似于记录，将所有消费端Consumer排好序类似页数，并求出每一页需要包含的平均size和每个页面记录的范围range，最后遍历整个range而计算出当前Consumer端应该分配到的的MessageQueue。</p> 
<p>(4) 然后，调用updateProcessQueueTableInRebalance()方法，具体的做法是，先将分配到的消息队列集合（mqSet）与processQueueTable做一个过滤比对。</p> 
<p>上图中processQueueTable标注的红色部分，表示与分配到的消息队列集合mqSet互不包含。将这些队列设置Dropped属性为true，然后查看这些队列是否可以移除出processQueueTable缓存变量，这里具体执行removeUnnecessaryMessageQueue()方法，即每隔1s 查看是否可以获取当前消费处理队列的锁，拿到的话返回true。如果等待1s后，仍然拿不到当前消费处理队列的锁则返回false。如果返回true，则从processQueueTable缓存变量中移除对应的Entry；<br> 上图中processQueueTable的绿色部分，表示与分配到的消息队列集合mqSet的交集。判断该ProcessQueue是否已经过期了，在Pull模式的不用管，如果是Push模式的，设置Dropped属性为true，并且调用removeUnnecessaryMessageQueue()方法，像上面一样尝试移除Entry；<br> 最后，为过滤后的消息队列集合（mqSet）中的每个MessageQueue创建一个ProcessQueue对象并存入RebalanceImpl的processQueueTable队列中（其中调用RebalanceImpl实例的computePullFromWhere(MessageQueue mq)方法获取该MessageQueue对象的下一个进度消费值offset，随后填充至接下来要创建的pullRequest对象属性中），并创建拉取请求对象—pullRequest添加到拉取列表—pullRequestList中，最后执行dispatchPullRequest()方法，将Pull消息的请求对象PullRequest依次放入PullMessageService服务线程的阻塞队列pullRequestQueue中，待该服务线程取出后向Broker端发起Pull消息的请求。其中，可以重点对比下，RebalancePushImpl和RebalancePullImpl两个实现类的dispatchPullRequest()方法不同，RebalancePullImpl类里面的该方法为空。<br> 消息消费队列在同一消费组不同消费者之间的负载均衡，其核心设计理念是在一个消息消费队列在同一时间只允许被同一消费组内的一个消费者消费，一个消息消费者能同时消费多个消息队列。</p> 
<h4>Kafka</h4> 
<h5>1、kafka的消费者是pull(拉)还是push(推)模式，这种模式有什么好处？</h5> 
<p><br> Kafka 遵循了一种大部分消息系统共同的传统的设计：producer 将消息推送到 broker，consumer 从broker 拉取消息。</p> 
<p>优点：pull模式消费者自主决定是否批量从broker拉取数据，而push模式在无法知道消费者消费能力情况下，不易控制推送速度，太快可能造成消费者奔溃，太慢又可能造成浪费。</p> 
<p>缺点：如果 broker 没有可供消费的消息，将导致 consumer 不断在循环中轮询，直到新消息到到达。为了避免这点，Kafka 有个参数可以让 consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发送)。</p> 
<h5>2、kafka维护消息状态的跟踪方法</h5> 
<p><br> Kafka中的Topic 被分成了若干分区，每个分区在同一时间只被一个 consumer 消费。然后再通过offset进行消息位置标记，通过位置偏移来跟踪消费状态。相比其他一些消息队列使用“一个消息被分发到consumer 后 broker 就马上进行标记或者等待 customer 的通知后进行标记”的优点是，避免了通信消息发送后，可能出现的程序奔溃而出现消息丢失或者重复消费的情况。同时也无需维护消息的状态，不用加锁，提高了吞吐量。</p> 
<h5>3、zookeeper对于kafka的作用是什么?</h5> 
<p><br> Zookeeper 主要用于在集群中不同节点之间进行通信，在 Kafka 中，它被用于提交偏移量，因此如果节点在任何情况下都失败了，它都可以从之前提交的偏移量中获取，除此之外，它还执行其他活动，如: leader 检测、分布式同步、配置管理、识别新节点何时离开或连接、集群、节点实时状态等等。</p> 
<h5>4、kafka判断一个节点还活着的有那两个条件？</h5> 
<p><br> （1）节点必须维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接<br> （2）如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久</p> 
<h5>5、讲一讲 kafka 的 ack 的三种机制</h5> 
<p><br> request.required.acks 有三个值 0 1 -1(all)，具体如下：<br> 0：生产者不会等待 broker 的 ack，这个延迟最低但是存储的保证最弱当 server 挂掉的时候就会丢数据。<br> 1：服务端会等待 ack 值 leader 副本确认接收到消息后发送 ack 但是如果 leader挂掉后他不确保是否复制完成新 leader 也会导致数据丢失。<br> -1(all)：服务端会等所有的 follower 的副本受到数据后才会受到 leader 发出的ack，这样数据不会丢失。</p> 
<h5>6、kafka 分布式（不是单机）的情况下，如何保证消息的顺序消费?</h5> 
<p><br> Kafka 中发送 1 条消息的时候，可以指定(topic, partition, key) 3 个参数，partiton 和 key 是可选的。</p> 
<p>Kafka 分布式的单位是 partition，同一个 partition 用一个 write ahead log 组织，所以可以保证FIFO 的顺序。不同 partition 之间不能保证顺序。因此你可以指定 partition，将相应的消息发往同 1个 partition，并且在消费端，Kafka 保证1 个 partition 只能被1 个 consumer 消费，就可以实现这些消息的顺序消费。</p> 
<p>另外，你也可以指定 key（比如 order id），具有同 1 个 key 的所有消息，会发往同 1 个partition，那这样也实现了消息的顺序消息。</p> 
<h5>7、kafka 如何不消费重复数据？比如扣款，我们不能重复的扣。</h5> 
<p><br> 这个问题换种问法，就是kafka如何保证消息的幂等性。对于消息队列来说，出现重复消息的概率还是挺大的，不能完全依赖消息队列，而是应该在业务层进行数据的一致性幂等校验。</p> 
<p>比如你处理的数据要写库（mysql，redis等），你先根据主键查一下，如果这数据都有了，你就别插入了，进行一些消息登记或者update等其他操作。另外，数据库层面也可以设置唯一健，确保数据不要重复插入等 。一般这里要求生产者在发送消息的时候，携带全局的唯一id。</p> 
<h5>8、讲一下kafka集群的组成？</h5> 
<p><br> kafka的集群图如下：</p> 
<p>Broker（代理）</p> 
<p>Kafka集群通常由多个代理组成以保持负载平衡。 Kafka代理是无状态的，所以他们使用ZooKeeper来维护它们的集群状态。 一个Kafka代理实例可以每秒处理数十万次读取和写入，每个Broker可以处理TB的消息，而没有性能影响。 Kafka经纪人领导选举可以由ZooKeeper完成。</p> 
<p>ZooKeeper</p> 
<p>ZooKeeper用于管理和协调Kafka代理。 ZooKeeper服务主要用于通知生产者和消费者Kafka系统中存在任何新代理或Kafka系统中代理失败。 根据Zookeeper接收到关于代理的存在或失败的通知，然后生产者和消费者采取决定并开始与某些其他代理协调他们的任务。</p> 
<p>Producers（生产者）</p> 
<p>生产者将数据推送给经纪人。 当新代理启动时，所有生产者搜索它并自动向该新代理发送消息。 Kafka生产者不等待来自代理的确认，并且发送消息的速度与代理可以处理的一样快。</p> 
<p>Consumers（消费者）</p> 
<p>因为Kafka代理是无状态的，这意味着消费者必须通过使用分区偏移来维护已经消耗了多少消息。 如果消费者确认特定的消息偏移，则意味着消费者已经消费了所有先前的消息。 消费者向代理发出异步拉取请求，以具有准备好消耗的字节缓冲区。 消费者可以简单地通过提供偏移值来快退或跳到分区中的任何点。 消费者偏移值由ZooKeeper通知。</p> 
<h5>9、kafka是什么？</h5> 
<p><br> Kafka是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由LinkedIn公司开发，使用Scala语言编写，目前是Apache的开源项目。</p> 
<p>broker： Kafka服务器，负责消息存储和转发</p> 
<p>topic：消息类别，Kafka按照topic来分类消息</p> 
<p>partition： topic的分区，一个topic可以包含多个partition， topic 消息保存在各个partition上4. offset：消息在日志中的位置，可以理解是消息在partition上的偏移量，也是代表该消息的唯一序号</p> 
<p>Producer：消息生产者</p> 
<p>Consumer：消息消费者</p> 
<p>Consumer Group：消费者分组，每个Consumer必须属于一个group</p> 
<p>Zookeeper：保存着集群 broker、 topic、 partition等meta 数据；另外，还负责broker故障发现， partition leader选举，负载均衡等功能</p> 
<h5>10、partition的数据文件（offffset，MessageSize，data）</h5> 
<p><br> partition中的每条Message包含了以下三个属性： offset，MessageSize，data，其中offset表示Message在这个partition中的偏移量，offset不是该Message在partition数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了partition中的一条Message，可以认为offset是partition中Message的 id； MessageSize表示消息内容data的大小；data为Message的具体内容。</p> 
<h5>11、kafka如何实现数据的高效读取？（顺序读写、分段命令、二分查找）</h5> 
<p><br> Kafka为每个分段后的数据文件建立了索引文件，文件名与数据文件的名字是一样的，只是文件扩展名为index。 index文件中并没有为数据文件中的每条Message建立索引，而是采用了稀疏存储的方式，每隔一定字节的数据建立一条索引。这样避免了索引文件占用过多的空间，从而可以将索引文件保留在内存中。</p> 
<h5>12、 Kafka 消费者端的 Rebalance 操作什么时候发生？</h5> 
<p><br> 同一个 consumer 消费者组 group.id 中，新增了消费者进来，会执行 Rebalance 操作<br> 消费者离开当期所属的 consumer group组。比如宕机<br> 分区数量发生变化时(即 topic 的分区数量发生变化时)<br> 消费者主动取消订阅<br> Rebalance的过程如下：</p> 
<p>第一步：所有成员都向coordinator发送请求，请求入组。一旦所有成员都发送了请求，coordinator会从中选择一个consumer担任leader的角色，并把组成员信息以及订阅信息发给leader。</p> 
<p>第二步：leader开始分配消费方案，指明具体哪个consumer负责消费哪些topic的哪些partition。一旦完成分配，leader会将这个方案发给coordinator。coordinator接收到分配方案之后会把方案发给各个consumer，这样组内的所有成员就都知道自己应该消费哪些分区了。</p> 
<p>所以对于Rebalance来说，Coordinator起着至关重要的作用</p> 
<h5>13、Kafka 中的ISR(InSyncRepli)、OSR(OutSyncRepli)、AR(AllRepli)代表什么？</h5> 
<p><br> 答：kafka中与leader副本保持一定同步程度的副本（包括leader）组成ISR。与leader滞后太多的副本组成OSR。分区中所有的副本通称为AR。</p> 
<p>ISR : 速率和leader相差低于10秒的follower的集合<br> OSR : 速率和leader相差大于10秒的follower<br> AR : 全部分区的follower</p> 
<h5>14、Kafka 中的HW、LEO等分别代表什么？</h5> 
<p><br> 答：HW：高水位，指消费者只能拉取到这个offset之前的数据</p> 
<p>LEO：标识当前日志文件中下一条待写入的消息的offset，大小等于当前日志文件最后一条消息的offset+1.</p> 
<h5>15、Kafka的那些设计让它有如此高的性能?</h5> 
<p><br> 1.kafka是分布式的消息队列<br> 2.对log文件进行了segment,并对segment创建了索引<br> 3.(对于单节点)使用了顺序读写,速度能够达到600M/s<br> 4.引用了zero拷贝,在os系统就完成了读写操做</p> 
<h5>16、Kafka为什么不支持读写分离？</h5> 
<p><br> 1、 这其实是分布式场景下的通用问题，因为我们知道CAP理论下，我们只能保证C（一致性）和A（可用性）取其一，如果支持读写分离，那其实对于一致性的要求可能就会有一定折扣，因为通常的场景下，副本之间都是通过同步来实现副本数据一致的，那同步过程中肯定会有时间的消耗，如果支持了读写分离，就意味着可能的数据不一致，或数据滞后。</p> 
<p>2、 Leader/Follower模型并没有规定Follower副本不可以对外提供读服务。很多框架都是允许这么做的，只是 Kafka最初为了避免不一致性的问题，而采用了让Leader统一提供服务的方式。</p> 
<p>3、 不过，自Kafka 2.4之后，Kafka提供了有限度的读写分离，也就是说，Follower副本能够对外提供读服务。</p> 
<h5>17、分区Leader选举策略有几种？</h5> 
<p><br> 分区的Leader副本选举对用户是完全透明的，它是由Controller独立完成的。你需要回答的是，在哪些场景下，需要执行分区Leader选举。每一种场景对应于一种选举策略。</p> 
<p>1、 OfflinePartition Leader选举：每当有分区上线时，就需要执行Leader选举。所谓的分区上线，可能是创建了新分区，也可能是之前的下线分区重新上线。这是最常见的分区Leader选举场景。</p> 
<p>2、 ReassignPartition Leader选举：当你手动运行Kafka-reassign-partitions命令，或者是调用Admin的alterPartitionReassignments方法执行分区副本重分配时，可能触发此类选举。假设原来的AR是[1，2，3]，Leader是1，当执行副本重分配后，副本集合AR被设置成[4，5，6]，显然，Leader必须要变更，此时会发生Reassign Partition Leader选举。</p> 
<p>3、 PreferredReplicaPartition Leader选举：当你手动运行Kafka-preferred-replica-election命令，或自动触发了Preferred Leader选举时，该类策略被激活。所谓的Preferred Leader，指的是AR中的第一个副本。比如AR是[3，2，1]，那么，Preferred Leader就是3。</p> 
<p>4、 ControlledShutdownPartition Leader选举：当Broker正常关闭时，该Broker上的所有Leader副本都会下线，因此，需要为受影响的分区执行相应的Leader选举。</p> 
<p>这4类选举策略的大致思想是类似的，即从AR中挑选首个在ISR中的副本，作为新Leader。</p> 
<h5>18、请简述下你在哪些场景下会选择 Kafka？</h5> 
<p><br> •日志收集：一个公司可以用Kafka可以收集各种服务的log，通过kafka以统一接口服务的方式开放给各种consumer，例如hadoop、HBase、Solr等。<br> •消息系统：解耦和生产者和消费者、缓存消息等。<br> •用户活动跟踪：Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。<br> •运营指标：Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。<br> •流式处理：比如spark streaming和 Flink</p> 
<h5>19、请谈一谈 Kafka 数据一致性原理</h5> 
<p><br> 一致性就是说不论是老的 Leader 还是新选举的 Leader，Consumer 都能读到一样的数据。</p> 
<p><br> 假设分区的副本为3，其中副本0是 Leader，副本1和副本2是 follower，并且在 ISR 列表里面。虽然副本0已经写入了 Message4，但是 Consumer 只能读取到 Message2。因为所有的 ISR 都同步了 Message2，只有 High Water Mark 以上的消息才支持 Consumer 读取，而 High Water Mark 取决于 ISR 列表里面偏移量最小的分区，对应于上图的副本2，这个很类似于木桶原理。</p> 
<p>这样做的原因是还没有被足够多副本复制的消息被认为是“不安全”的，如果 Leader 发生崩溃，另一个副本成为新 Leader，那么这些消息很可能丢失了。如果我们允许消费者读取这些消息，可能就会破坏一致性。试想，一个消费者从当前 Leader（副本0） 读取并处理了 Message4，这个时候 Leader 挂掉了，选举了副本1为新的 Leader，这时候另一个消费者再去从新的 Leader 读取消息，发现这个消息其实并不存在，这就导致了数据不一致性问题。</p> 
<p>当然，引入了 High Water Mark 机制，会导致 Broker 间的消息复制因为某些原因变慢，那么消息到达消费者的时间也会随之变长（因为我们会先等待消息复制完毕）。延迟时间可以通过参数 replica.lag.time.max.ms 参数配置，它指定了副本在复制消息时可被允许的最大延迟时间。</p> 
<h5>20、Kafka 缺点？</h5> 
<p><br> 由于是批量发送，数据并非真正的实时；<br> •对于mqtt协议不支持；<br> •不支持物联网传感数据直接接入；<br> •仅支持统一分区内消息有序，无法实现全局消息有序；<br> •监控不完善，需要安装插件；<br> •依赖zookeeper进行元数据管理；<br>  </p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a2b06a5a3fc7e392ad57c71e1ab6ac2a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【从零开始学技术】Fiddler 抓取 https 请求大全</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/39da859f3d9447eb417c865677175b07/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">面试宝典之ElasticSearch面试题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>