<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>tensorRT踩坑日常之训练模型转ONNX转engine - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="tensorRT踩坑日常之训练模型转ONNX转engine" />
<meta property="og:description" content="tensorRT踩坑日常之训练模型转ONNX转engine tensorRT是用来干嘛的在这里就不多介绍了
在使用tensorRT提速之前需要先训练模型
在将训练好的模型转ONNX再转engine
一、将训练好的模型转ONNX这里就提供将torch转ONNX，其余的网上还是有很多教程的
import torch import torch.nn import onnx model = torch.load(&#39;best.pt&#39;) model.eval() input_names = [&#39;input&#39;] output_names = [&#39;output&#39;] x = torch.randn(1,3,32,32,requires_grad=True) torch.onnx.export(model, x, &#39;flame.onnx&#39;, input_names=input_names, output_names=output_names, verbose=&#39;True&#39;) 输出就行
二、将ONNX转engine
可以直接使用tensorrt自带的trtexec将onnx模型转engine：
进入tensorrt的安装目录下的bin文件，就能看到trtexec：输入
ubuntu下的trtexec
/usr/src/tensorrt/bin
trtexec -h 查看帮助命令
=== Model Options === --uff=&lt;file&gt; UFF model --onnx=&lt;file&gt; ONNX model --model=&lt;file&gt; Caffe model (default = no model, random weights used) --deploy=&lt;file&gt; Caffe prototxt file --output=&lt;name&gt;[,&lt;name&gt;]* Output names (it can be specified multiple times); at least one output is required for UFF and Caffe --uffInput=&lt;name&gt;,X,Y,Z Input blob name and its dimensions (X,Y,Z=C,H,W), it can be specified multiple times; at least one is required for UFF models --uffNHWC Set if inputs are in the NHWC layout instead of NCHW (use X,Y,Z=H,W,C order in --uffInput) === Build Options === --maxBatch Set max batch size and build an implicit batch engine (default = 1) --explicitBatch Use explicit batch sizes when building the engine (default = implicit) --minShapes=spec Build with dynamic shapes using a profile with the min shapes provided --optShapes=spec Build with dynamic shapes using a profile with the opt shapes provided --maxShapes=spec Build with dynamic shapes using a profile with the max shapes provided --minShapesCalib=spec Calibrate with dynamic shapes using a profile with the min shapes provided --optShapesCalib=spec Calibrate with dynamic shapes using a profile with the opt shapes provided --maxShapesCalib=spec Calibrate with dynamic shapes using a profile with the max shapes provided Note: All three of min, opt and max shapes must be supplied." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b8fe629dce7454bddebb2e325710abe4/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-21T10:47:36+08:00" />
<meta property="article:modified_time" content="2022-04-21T10:47:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">tensorRT踩坑日常之训练模型转ONNX转engine</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="tensorRTONNXengine_0"></a>tensorRT踩坑日常之训练模型转ONNX转engine</h2> 
<p>tensorRT是用来干嘛的在这里就不多介绍了<br> 在使用tensorRT提速之前需要先训练模型<br> 在将训练好的模型转ONNX再转engine</p> 
<p>一、将训练好的模型转ONNX这里就提供将torch转ONNX，其余的网上还是有很多教程的</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn
<span class="token keyword">import</span> onnx
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'best.pt'</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
input_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'input'</span><span class="token punctuation">]</span>
output_names <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'output'</span><span class="token punctuation">]</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span><span class="token number">32</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>onnx<span class="token punctuation">.</span>export<span class="token punctuation">(</span>model<span class="token punctuation">,</span> x<span class="token punctuation">,</span> <span class="token string">'flame.onnx'</span><span class="token punctuation">,</span> input_names<span class="token operator">=</span>input_names<span class="token punctuation">,</span> output_names<span class="token operator">=</span>output_names<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token string">'True'</span><span class="token punctuation">)</span>
</code></pre> 
<p>输出就行</p> 
<p>二、将ONNX转engine<br> 可以直接使用tensorrt自带的trtexec将onnx模型转engine：<br> 进入tensorrt的安装目录下的bin文件，就能看到trtexec：输入<br> ubuntu下的trtexec</p> 
<blockquote> 
 <p>/usr/src/tensorrt/bin</p> 
</blockquote> 
<blockquote> 
 <p>trtexec -h 查看帮助命令</p> 
</blockquote> 
<pre><code class="prism language-python"><span class="token operator">==</span><span class="token operator">=</span> Model Options <span class="token operator">==</span><span class="token operator">=</span>
  <span class="token operator">-</span><span class="token operator">-</span>uff<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>                UFF model
  <span class="token operator">-</span><span class="token operator">-</span>onnx<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>               ONNX model
  <span class="token operator">-</span><span class="token operator">-</span>model<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>              Caffe model <span class="token punctuation">(</span>default <span class="token operator">=</span> no model<span class="token punctuation">,</span> random weights used<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>deploy<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>             Caffe prototxt <span class="token builtin">file</span>
  <span class="token operator">-</span><span class="token operator">-</span>output<span class="token operator">=</span><span class="token operator">&lt;</span>name<span class="token operator">&gt;</span><span class="token punctuation">[</span><span class="token punctuation">,</span><span class="token operator">&lt;</span>name<span class="token operator">&gt;</span><span class="token punctuation">]</span><span class="token operator">*</span>   Output names <span class="token punctuation">(</span>it can be specified multiple times<span class="token punctuation">)</span><span class="token punctuation">;</span> at least one output <span class="token keyword">is</span> required <span class="token keyword">for</span> UFF <span class="token keyword">and</span> Caffe
  <span class="token operator">-</span><span class="token operator">-</span>uffInput<span class="token operator">=</span><span class="token operator">&lt;</span>name<span class="token operator">&gt;</span><span class="token punctuation">,</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>Z     Input blob name <span class="token keyword">and</span> its dimensions <span class="token punctuation">(</span>X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>Z<span class="token operator">=</span>C<span class="token punctuation">,</span>H<span class="token punctuation">,</span>W<span class="token punctuation">)</span><span class="token punctuation">,</span> it can be specified multiple times<span class="token punctuation">;</span> at least one <span class="token keyword">is</span> required <span class="token keyword">for</span> UFF models
  <span class="token operator">-</span><span class="token operator">-</span>uffNHWC                   Set <span class="token keyword">if</span> inputs are <span class="token keyword">in</span> the NHWC layout instead of NCHW <span class="token punctuation">(</span>use X<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>Z<span class="token operator">=</span>H<span class="token punctuation">,</span>W<span class="token punctuation">,</span>C order <span class="token keyword">in</span> <span class="token operator">-</span><span class="token operator">-</span>uffInput<span class="token punctuation">)</span>

<span class="token operator">==</span><span class="token operator">=</span> Build Options <span class="token operator">==</span><span class="token operator">=</span>
  <span class="token operator">-</span><span class="token operator">-</span>maxBatch                  Set <span class="token builtin">max</span> batch size <span class="token keyword">and</span> build an implicit batch engine <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>explicitBatch             Use explicit batch sizes when building the engine <span class="token punctuation">(</span>default <span class="token operator">=</span> implicit<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>minShapes<span class="token operator">=</span>spec            Build <span class="token keyword">with</span> dynamic shapes using a profile <span class="token keyword">with</span> the <span class="token builtin">min</span> shapes provided
  <span class="token operator">-</span><span class="token operator">-</span>optShapes<span class="token operator">=</span>spec            Build <span class="token keyword">with</span> dynamic shapes using a profile <span class="token keyword">with</span> the opt shapes provided
  <span class="token operator">-</span><span class="token operator">-</span>maxShapes<span class="token operator">=</span>spec            Build <span class="token keyword">with</span> dynamic shapes using a profile <span class="token keyword">with</span> the <span class="token builtin">max</span> shapes provided
  <span class="token operator">-</span><span class="token operator">-</span>minShapesCalib<span class="token operator">=</span>spec       Calibrate <span class="token keyword">with</span> dynamic shapes using a profile <span class="token keyword">with</span> the <span class="token builtin">min</span> shapes provided
  <span class="token operator">-</span><span class="token operator">-</span>optShapesCalib<span class="token operator">=</span>spec       Calibrate <span class="token keyword">with</span> dynamic shapes using a profile <span class="token keyword">with</span> the opt shapes provided
  <span class="token operator">-</span><span class="token operator">-</span>maxShapesCalib<span class="token operator">=</span>spec       Calibrate <span class="token keyword">with</span> dynamic shapes using a profile <span class="token keyword">with</span> the <span class="token builtin">max</span> shapes provided
                              Note<span class="token punctuation">:</span> All three of <span class="token builtin">min</span><span class="token punctuation">,</span> opt <span class="token keyword">and</span> <span class="token builtin">max</span> shapes must be supplied<span class="token punctuation">.</span>
                                    However<span class="token punctuation">,</span> <span class="token keyword">if</span> only opt shapes <span class="token keyword">is</span> supplied then it will be expanded so
                                    that <span class="token builtin">min</span> shapes <span class="token keyword">and</span> <span class="token builtin">max</span> shapes are <span class="token builtin">set</span> to the same values <span class="token keyword">as</span> opt shapes<span class="token punctuation">.</span>
                                    In addition<span class="token punctuation">,</span> use of dynamic shapes implies explicit batch<span class="token punctuation">.</span>
                                    Input names can be wrapped <span class="token keyword">with</span> escaped single quotes <span class="token punctuation">(</span>ex<span class="token punctuation">:</span> \'Input<span class="token punctuation">:</span><span class="token number">0</span>\'<span class="token punctuation">)</span><span class="token punctuation">.</span>
                              Example <span class="token builtin">input</span> shapes spec<span class="token punctuation">:</span> input0<span class="token punctuation">:</span>1x3x256x256<span class="token punctuation">,</span>input1<span class="token punctuation">:</span>1x3x128x128
                              Each <span class="token builtin">input</span> shape <span class="token keyword">is</span> supplied <span class="token keyword">as</span> a key<span class="token operator">-</span>value pair where key <span class="token keyword">is</span> the <span class="token builtin">input</span> name <span class="token keyword">and</span>
                              value <span class="token keyword">is</span> the dimensions <span class="token punctuation">(</span>including the batch dimension<span class="token punctuation">)</span> to be used <span class="token keyword">for</span> that <span class="token builtin">input</span><span class="token punctuation">.</span>
                              Each key<span class="token operator">-</span>value pair has the key <span class="token keyword">and</span> value separated using a colon <span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
                              Multiple <span class="token builtin">input</span> shapes can be provided via comma<span class="token operator">-</span>separated key<span class="token operator">-</span>value pairs<span class="token punctuation">.</span>
  <span class="token operator">-</span><span class="token operator">-</span>inputIOFormats<span class="token operator">=</span>spec       Type <span class="token keyword">and</span> <span class="token builtin">format</span> of each of the <span class="token builtin">input</span> tensors <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token builtin">all</span> inputs <span class="token keyword">in</span> fp32<span class="token punctuation">:</span>chw<span class="token punctuation">)</span>
                              See <span class="token operator">-</span><span class="token operator">-</span>outputIOFormats <span class="token builtin">help</span> <span class="token keyword">for</span> the grammar of <span class="token builtin">type</span> <span class="token keyword">and</span> <span class="token builtin">format</span> <span class="token builtin">list</span><span class="token punctuation">.</span>
                              Note<span class="token punctuation">:</span> If this option <span class="token keyword">is</span> specified<span class="token punctuation">,</span> please <span class="token builtin">set</span> comma<span class="token operator">-</span>separated types <span class="token keyword">and</span> formats <span class="token keyword">for</span> <span class="token builtin">all</span>
                                    inputs following the same order <span class="token keyword">as</span> network inputs ID <span class="token punctuation">(</span>even <span class="token keyword">if</span> only one <span class="token builtin">input</span>
                                    needs specifying IO <span class="token builtin">format</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">set</span> the <span class="token builtin">type</span> <span class="token keyword">and</span> <span class="token builtin">format</span> once <span class="token keyword">for</span> broadcasting<span class="token punctuation">.</span>
  <span class="token operator">-</span><span class="token operator">-</span>outputIOFormats<span class="token operator">=</span>spec      Type <span class="token keyword">and</span> <span class="token builtin">format</span> of each of the output tensors <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token builtin">all</span> outputs <span class="token keyword">in</span> fp32<span class="token punctuation">:</span>chw<span class="token punctuation">)</span>
                              Note<span class="token punctuation">:</span> If this option <span class="token keyword">is</span> specified<span class="token punctuation">,</span> please <span class="token builtin">set</span> comma<span class="token operator">-</span>separated types <span class="token keyword">and</span> formats <span class="token keyword">for</span> <span class="token builtin">all</span>
                                    outputs following the same order <span class="token keyword">as</span> network outputs ID <span class="token punctuation">(</span>even <span class="token keyword">if</span> only one output
                                    needs specifying IO <span class="token builtin">format</span><span class="token punctuation">)</span> <span class="token keyword">or</span> <span class="token builtin">set</span> the <span class="token builtin">type</span> <span class="token keyword">and</span> <span class="token builtin">format</span> once <span class="token keyword">for</span> broadcasting<span class="token punctuation">.</span>
                              IO Formats<span class="token punctuation">:</span> spec  <span class="token punctuation">:</span><span class="token operator">:=</span> IOfmt<span class="token punctuation">[</span><span class="token string">","</span>spec<span class="token punctuation">]</span>
                                          IOfmt <span class="token punctuation">:</span><span class="token operator">:=</span> <span class="token builtin">type</span><span class="token punctuation">:</span>fmt
                                          <span class="token builtin">type</span>  <span class="token punctuation">:</span><span class="token operator">:=</span> <span class="token string">"fp32"</span><span class="token operator">|</span><span class="token string">"fp16"</span><span class="token operator">|</span><span class="token string">"int32"</span><span class="token operator">|</span><span class="token string">"int8"</span>
                                          fmt   <span class="token punctuation">:</span><span class="token operator">:=</span> <span class="token punctuation">(</span><span class="token string">"chw"</span><span class="token operator">|</span><span class="token string">"chw2"</span><span class="token operator">|</span><span class="token string">"chw4"</span><span class="token operator">|</span><span class="token string">"hwc8"</span><span class="token operator">|</span><span class="token string">"chw16"</span><span class="token operator">|</span><span class="token string">"chw32"</span><span class="token operator">|</span><span class="token string">"dhwc8"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"+"</span>fmt<span class="token punctuation">]</span>
  <span class="token operator">-</span><span class="token operator">-</span>workspace<span class="token operator">=</span>N               Set workspace size <span class="token keyword">in</span> megabytes <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>noBuilderCache            Disable timing cache <span class="token keyword">in</span> builder <span class="token punctuation">(</span>default <span class="token keyword">is</span> to enable timing cache<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>nvtxMode<span class="token operator">=</span>mode             Specify NVTX annotation verbosity<span class="token punctuation">.</span> mode <span class="token punctuation">:</span><span class="token operator">:=</span> default<span class="token operator">|</span>verbose<span class="token operator">|</span>none
  <span class="token operator">-</span><span class="token operator">-</span>minTiming<span class="token operator">=</span>M               Set the minimum number of iterations used <span class="token keyword">in</span> kernel selection <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>avgTiming<span class="token operator">=</span>M               Set the number of times averaged <span class="token keyword">in</span> each iteration <span class="token keyword">for</span> kernel selection <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>noTF32                    Disable tf32 precision <span class="token punctuation">(</span>default <span class="token keyword">is</span> to enable tf32<span class="token punctuation">,</span> <span class="token keyword">in</span> addition to fp32<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>refit                     Mark the engine <span class="token keyword">as</span> refittable<span class="token punctuation">.</span> This will allow the inspection of refittable layers 
                              <span class="token keyword">and</span> weights within the engine<span class="token punctuation">.</span>
  <span class="token operator">-</span><span class="token operator">-</span>fp16                      Enable fp16 precision<span class="token punctuation">,</span> <span class="token keyword">in</span> addition to fp32 <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>int8                      Enable int8 precision<span class="token punctuation">,</span> <span class="token keyword">in</span> addition to fp32 <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>best                      Enable <span class="token builtin">all</span> precisions to achieve the best performance <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>calib<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>              Read INT8 calibration cache <span class="token builtin">file</span>
  <span class="token operator">-</span><span class="token operator">-</span>safe                      Only test the functionality available <span class="token keyword">in</span> safety restricted flows
  <span class="token operator">-</span><span class="token operator">-</span>saveEngine<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>         Save the serialized engine
  <span class="token operator">-</span><span class="token operator">-</span>loadEngine<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>         Load a serialized engine
  <span class="token operator">-</span><span class="token operator">-</span>tacticSources<span class="token operator">=</span>tactics     Specify the tactics to be used by adding <span class="token punctuation">(</span><span class="token operator">+</span><span class="token punctuation">)</span> <span class="token keyword">or</span> removing <span class="token punctuation">(</span><span class="token operator">-</span><span class="token punctuation">)</span> tactics <span class="token keyword">from</span> the default 
                              tactic sources <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token builtin">all</span> available tactics<span class="token punctuation">)</span><span class="token punctuation">.</span>
                              Note<span class="token punctuation">:</span> Currently only cuBLAS <span class="token keyword">and</span> cuBLAS LT are listed <span class="token keyword">as</span> optional tactics<span class="token punctuation">.</span>
                              Tactic Sources<span class="token punctuation">:</span> tactics <span class="token punctuation">:</span><span class="token operator">:=</span> <span class="token punctuation">[</span><span class="token string">","</span>tactic<span class="token punctuation">]</span>
                                              tactic  <span class="token punctuation">:</span><span class="token operator">:=</span> <span class="token punctuation">(</span><span class="token operator">+</span><span class="token operator">|</span><span class="token operator">-</span><span class="token punctuation">)</span>lib
                                              lib     <span class="token punctuation">:</span><span class="token operator">:=</span> <span class="token string">"cublas"</span><span class="token operator">|</span><span class="token string">"cublasLt"</span>

<span class="token operator">==</span><span class="token operator">=</span> Inference Options <span class="token operator">==</span><span class="token operator">=</span>
  <span class="token operator">-</span><span class="token operator">-</span>batch<span class="token operator">=</span>N                   Set batch size <span class="token keyword">for</span> implicit batch engines <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>shapes<span class="token operator">=</span>spec               Set <span class="token builtin">input</span> shapes <span class="token keyword">for</span> dynamic shapes inference inputs<span class="token punctuation">.</span>
                              Note<span class="token punctuation">:</span> Use of dynamic shapes implies explicit batch<span class="token punctuation">.</span>
                                    Input names can be wrapped <span class="token keyword">with</span> escaped single quotes <span class="token punctuation">(</span>ex<span class="token punctuation">:</span> \'Input<span class="token punctuation">:</span><span class="token number">0</span>\'<span class="token punctuation">)</span><span class="token punctuation">.</span>
                              Example <span class="token builtin">input</span> shapes spec<span class="token punctuation">:</span> input0<span class="token punctuation">:</span>1x3x256x256<span class="token punctuation">,</span> input1<span class="token punctuation">:</span>1x3x128x128
                              Each <span class="token builtin">input</span> shape <span class="token keyword">is</span> supplied <span class="token keyword">as</span> a key<span class="token operator">-</span>value pair where key <span class="token keyword">is</span> the <span class="token builtin">input</span> name <span class="token keyword">and</span>
                              value <span class="token keyword">is</span> the dimensions <span class="token punctuation">(</span>including the batch dimension<span class="token punctuation">)</span> to be used <span class="token keyword">for</span> that <span class="token builtin">input</span><span class="token punctuation">.</span>
                              Each key<span class="token operator">-</span>value pair has the key <span class="token keyword">and</span> value separated using a colon <span class="token punctuation">(</span><span class="token punctuation">:</span><span class="token punctuation">)</span><span class="token punctuation">.</span>
                              Multiple <span class="token builtin">input</span> shapes can be provided via comma<span class="token operator">-</span>separated key<span class="token operator">-</span>value pairs<span class="token punctuation">.</span>
  <span class="token operator">-</span><span class="token operator">-</span>loadInputs<span class="token operator">=</span>spec           Load <span class="token builtin">input</span> values <span class="token keyword">from</span> files <span class="token punctuation">(</span>default <span class="token operator">=</span> generate random inputs<span class="token punctuation">)</span><span class="token punctuation">.</span> Input names can be wrapped <span class="token keyword">with</span> single quotes <span class="token punctuation">(</span>ex<span class="token punctuation">:</span> <span class="token string">'Input:0'</span><span class="token punctuation">)</span>
                              Input values spec <span class="token punctuation">:</span><span class="token operator">:=</span> Ival<span class="token punctuation">[</span><span class="token string">","</span>spec<span class="token punctuation">]</span>
                                           Ival <span class="token punctuation">:</span><span class="token operator">:=</span> name<span class="token string">":"</span><span class="token builtin">file</span>
  <span class="token operator">-</span><span class="token operator">-</span>iterations<span class="token operator">=</span>N              Run at least N inference iterations <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>warmUp<span class="token operator">=</span>N                  Run <span class="token keyword">for</span> N milliseconds to warmup before measuring performance <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">200</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>duration<span class="token operator">=</span>N                Run performance measurements <span class="token keyword">for</span> at least N seconds wallclock time <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">3</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>sleepTime<span class="token operator">=</span>N               Delay inference start <span class="token keyword">with</span> a gap of N milliseconds between launch <span class="token keyword">and</span> compute <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>streams<span class="token operator">=</span>N                 Instantiate N engines to use concurrently <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>exposeDMA                 Serialize DMA transfers to <span class="token keyword">and</span> <span class="token keyword">from</span> device<span class="token punctuation">.</span> <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>noDataTransfers           Do <span class="token keyword">not</span> transfer data to <span class="token keyword">and</span> <span class="token keyword">from</span> the device during inference<span class="token punctuation">.</span> <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>useSpinWait               Actively synchronize on GPU events<span class="token punctuation">.</span> This option may decrease synchronization time but increase CPU usage <span class="token keyword">and</span> power <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>threads                   Enable multithreading to drive engines <span class="token keyword">with</span> independent threads <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>useCudaGraph              Use cuda graph to capture engine execution <span class="token keyword">and</span> then launch inference <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>separateProfileRun        Do <span class="token keyword">not</span> attach the profiler <span class="token keyword">in</span> the benchmark run<span class="token punctuation">;</span> <span class="token keyword">if</span> profiling <span class="token keyword">is</span> enabled<span class="token punctuation">,</span> a second profile run will be executed <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>buildOnly                 Skip inference perf measurement <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>

<span class="token operator">==</span><span class="token operator">=</span> Build <span class="token keyword">and</span> Inference Batch Options <span class="token operator">==</span><span class="token operator">=</span>
                              When using implicit batch<span class="token punctuation">,</span> the <span class="token builtin">max</span> batch size of the engine<span class="token punctuation">,</span> <span class="token keyword">if</span> <span class="token keyword">not</span> given<span class="token punctuation">,</span> 
                              <span class="token keyword">is</span> <span class="token builtin">set</span> to the inference batch size<span class="token punctuation">;</span>
                              when using explicit batch<span class="token punctuation">,</span> <span class="token keyword">if</span> shapes are specified only <span class="token keyword">for</span> inference<span class="token punctuation">,</span> they 
                              will be used also <span class="token keyword">as</span> <span class="token builtin">min</span><span class="token operator">/</span>opt<span class="token operator">/</span><span class="token builtin">max</span> <span class="token keyword">in</span> the build profile<span class="token punctuation">;</span> <span class="token keyword">if</span> shapes are 
                              specified only <span class="token keyword">for</span> the build<span class="token punctuation">,</span> the opt shapes will be used also <span class="token keyword">for</span> inference<span class="token punctuation">;</span>
                              <span class="token keyword">if</span> both are specified<span class="token punctuation">,</span> they must be compatible<span class="token punctuation">;</span> <span class="token keyword">and</span> <span class="token keyword">if</span> explicit batch <span class="token keyword">is</span> 
                              enabled but neither <span class="token keyword">is</span> specified<span class="token punctuation">,</span> the model must provide complete static
                              dimensions<span class="token punctuation">,</span> including batch size<span class="token punctuation">,</span> <span class="token keyword">for</span> <span class="token builtin">all</span> inputs

<span class="token operator">==</span><span class="token operator">=</span> Reporting Options <span class="token operator">==</span><span class="token operator">=</span>
  <span class="token operator">-</span><span class="token operator">-</span>verbose                   Use verbose logging <span class="token punctuation">(</span>default <span class="token operator">=</span> false<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>avgRuns<span class="token operator">=</span>N                 Report performance measurements averaged over N consecutive iterations <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>percentile<span class="token operator">=</span>P              Report performance <span class="token keyword">for</span> the P percentage <span class="token punctuation">(</span><span class="token number">0</span><span class="token operator">&lt;=</span>P<span class="token operator">&lt;=</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">0</span> representing <span class="token builtin">max</span> perf<span class="token punctuation">,</span> <span class="token keyword">and</span> <span class="token number">100</span> representing <span class="token builtin">min</span> perf<span class="token punctuation">;</span> <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">99</span><span class="token operator">%</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>dumpRefit                 Print the refittable layers <span class="token keyword">and</span> weights <span class="token keyword">from</span> a refittable engine
  <span class="token operator">-</span><span class="token operator">-</span>dumpOutput                Print the output tensor<span class="token punctuation">(</span>s<span class="token punctuation">)</span> of the last inference iteration <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>dumpProfile               Print profile information per layer <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>exportTimes<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>        Write the timing results <span class="token keyword">in</span> a json <span class="token builtin">file</span> <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>exportOutput<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>       Write the output tensors to a json <span class="token builtin">file</span> <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>exportProfile<span class="token operator">=</span><span class="token operator">&lt;</span><span class="token builtin">file</span><span class="token operator">&gt;</span>      Write the profile information per layer <span class="token keyword">in</span> a json <span class="token builtin">file</span> <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>

<span class="token operator">==</span><span class="token operator">=</span> System Options <span class="token operator">==</span><span class="token operator">=</span>
  <span class="token operator">-</span><span class="token operator">-</span>device<span class="token operator">=</span>N                  Select cuda device N <span class="token punctuation">(</span>default <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>useDLACore<span class="token operator">=</span>N              Select DLA core N <span class="token keyword">for</span> layers that support DLA <span class="token punctuation">(</span>default <span class="token operator">=</span> none<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>allowGPUFallback          When DLA <span class="token keyword">is</span> enabled<span class="token punctuation">,</span> allow GPU fallback <span class="token keyword">for</span> unsupported layers <span class="token punctuation">(</span>default <span class="token operator">=</span> disabled<span class="token punctuation">)</span>
  <span class="token operator">-</span><span class="token operator">-</span>plugins                   Plugin library <span class="token punctuation">(</span><span class="token punctuation">.</span>so<span class="token punctuation">)</span> to load <span class="token punctuation">(</span>can be specified multiple times<span class="token punctuation">)</span>

</code></pre> 
<p>运行就行</p> 
<blockquote> 
 <p>trtexec --onnx=flame_sim.onnx --saveEngine=flame_sim.engine --best --workspace=1024 --minShapes=inputx:1x3x224x224 --optShapes=inputx:1x3x2224x224 --maxShapes=inputx:1x3x224x224</p> 
</blockquote> 
<p>但是要记住设置工作区间 默认的工作区间为16，单位为MB --minShapes=inputx:1x3x224x224 --optShapes=inputx:1x3x2224x224 --maxShapes=inputx:1x3x224x22<br> 设置最小，最大和最佳的输入 注意保存engine的时候不要保存在bin下面 可能会报错的 保存引擎错误</p> 
<p>有的时候转engine的时候回报错</p> 
<blockquote> 
 <p>onnx2trt_utils.cpp:220: Your ONNX model has been generated with INT64<br> weights, while TensorRT does not natively support INT64. Attempting to<br> cast down to INT32.</p> 
</blockquote> 
<p>是因为你的onnx是INT64权重生成的，而tensorrt是支持INT32 的所有要将onnx转为更简单的模型。需要用到 onnx-simplifier 使用 <code>pip install onnx-simplifier</code>就能直接安装了<br> 安装完毕后就可以转了 <code>python -m onnxsim .\flame.onnx .\flame_sim.onnx</code></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7e95aedb61f300f207d6671ebb3f66fb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">服务器代码运行的小tips</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/071fd90562e1860f164202c61d61b862/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">c&#43;&#43; 输入文件流ifstream用法详解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>