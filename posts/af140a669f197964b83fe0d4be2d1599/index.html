<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CDH大数据平台搭建之HADOOP分布式集群搭建 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CDH大数据平台搭建之HADOOP分布式集群搭建" />
<meta property="og:description" content="CDH大数据平台搭建之HADOOP安装 一、什么是HADOOP?二、如何下载1.官网下载2.网盘下载 三、搭建集群1.虚拟机准备2.安装JDK3.安装ZOOKEEPER4.集群规划5.安装HADOOP6.修改配置文件1、进入配置文件目录：2、修改env文件3、修改core-site.xml文件4、修改hdfs-site.xml文件5、配置mapred-site.xml文件6、修改yarn-site.xml文件7、修改slaves文件8、分发文件9、配置环境变量 四、启动集群1.启动ZOOKEEPER集群2.启动JournalNode3.格式化namenode4.格式化zkfc5.启动zkfc6.启动namenode7.格式化secondarynamenode8.启动secondarynamenode9.验证是否成功10.启动datanode11.启动resourcemanager12.启动nodemanager 五、各个机器命令进程六、网页端口效果1、namenoderesourcemanager 七、高可用测试总结 一、什么是HADOOP? Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要是分布式数据存储以及计算。
二、如何下载 1.官网下载 1、apache版本：http://hadoop.apache.org/ 2、cdh版本(已收费)：http://archive.cloudera.com/cdh5/cdh/5/ 2.网盘下载 链接：https://pan.baidu.com/s/18x2lc0Z7JbJ7pW-15VtiDg 提取码：cdh5 三、搭建集群 1.虚拟机准备 请参考CHD大数据平台搭建之VMware及虚拟机安装
以及CHD大数据平台搭建之虚拟环境配置
2.安装JDK 请参考CHD大数据平台搭建之JDK安装
3.安装ZOOKEEPER 请参考CHD大数据平台搭建之ZOOKEEPER安装
4.集群规划 请参考CHD大数据平台搭建之集群规划
5.安装HADOOP tar -zxvf hadoop-2.6.0-cdh5.7.6.tar.gz -C /opt/modules/ 6.修改配置文件 1、进入配置文件目录： cd /opt/modules/hadoop-2.6.0-cdh5.7.6/etc/hadoop 2、修改env文件 配置env文件java安装目录 hadoop-env.sh mapred-env.sh yarn-env.sh 修改：export JAVA_HOME=/opt/modules/jdk1.8.0_91 3、修改core-site.xml文件 1、新建文件夹：
mkdir -p /opt/modules/hadoop-2.6.0-cdh5.7.6/data/tmp 2、添加如下内容
&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt; &lt;/property&gt; &lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/modules/hadoop-2.6.0-cdh5.7.6/datas/tmp&lt;/value&gt; &lt;/property&gt; &lt;!-- zookeeper通讯地址--&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;bigdata-training03.hpsk.com:2181,bigdata-training04.hpsk.com:2181,bigdata-training05.hpsk.com:2181&lt;/value&gt; &lt;/property&gt; 4、修改hdfs-site.xml文件 1、新建文件夹：
mkdir -p /opt/modules/hadoop-2." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/af140a669f197964b83fe0d4be2d1599/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-05-16T17:44:40+08:00" />
<meta property="article:modified_time" content="2023-05-16T17:44:40+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CDH大数据平台搭建之HADOOP分布式集群搭建</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>CDH大数据平台搭建之HADOOP安装</h4> 
 <ul><li><a href="#HADOOP_3" rel="nofollow">一、什么是HADOOP?</a></li><li><a href="#_8" rel="nofollow">二、如何下载</a></li><li><ul><li><a href="#1_9" rel="nofollow">1.官网下载</a></li><li><a href="#2_13" rel="nofollow">2.网盘下载</a></li></ul> 
  </li><li><a href="#_15" rel="nofollow">三、搭建集群</a></li><li><ul><li><a href="#1_16" rel="nofollow">1.虚拟机准备</a></li><li><a href="#2JDK_20" rel="nofollow">2.安装JDK</a></li><li><a href="#3ZOOKEEPER_23" rel="nofollow">3.安装ZOOKEEPER</a></li><li><a href="#4_26" rel="nofollow">4.集群规划</a></li><li><a href="#5HADOOP_28" rel="nofollow">5.安装HADOOP</a></li><li><a href="#6_31" rel="nofollow">6.修改配置文件</a></li><li><ul><li><a href="#1_32" rel="nofollow">1、进入配置文件目录：</a></li><li><a href="#2env_34" rel="nofollow">2、修改env文件</a></li><li><a href="#3coresitexml_40" rel="nofollow">3、修改core-site.xml文件</a></li><li><a href="#4hdfssitexml_61" rel="nofollow">4、修改hdfs-site.xml文件</a></li><li><a href="#5mapredsitexml_145" rel="nofollow">5、配置mapred-site.xml文件</a></li><li><a href="#6yarnsitexml_164" rel="nofollow">6、修改yarn-site.xml文件</a></li><li><a href="#7slaves_229" rel="nofollow">7、修改slaves文件</a></li><li><a href="#8_238" rel="nofollow">8、分发文件</a></li><li><a href="#9_243" rel="nofollow">9、配置环境变量</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_254" rel="nofollow">四、启动集群</a></li><li><ul><li><a href="#1ZOOKEEPER_255" rel="nofollow">1.启动ZOOKEEPER集群</a></li><li><a href="#2JournalNode_258" rel="nofollow">2.启动JournalNode</a></li><li><a href="#3namenode_262" rel="nofollow">3.格式化namenode</a></li><li><a href="#4zkfc_265" rel="nofollow">4.格式化zkfc</a></li><li><a href="#5zkfc_269" rel="nofollow">5.启动zkfc</a></li><li><a href="#6namenode_272" rel="nofollow">6.启动namenode</a></li><li><a href="#7secondarynamenode_275" rel="nofollow">7.格式化secondarynamenode</a></li><li><a href="#8secondarynamenode_278" rel="nofollow">8.启动secondarynamenode</a></li><li><a href="#9_282" rel="nofollow">9.验证是否成功</a></li><li><a href="#10datanode_287" rel="nofollow">10.启动datanode</a></li><li><a href="#11resourcemanager_291" rel="nofollow">11.启动resourcemanager</a></li><li><a href="#12nodemanager_295" rel="nofollow">12.启动nodemanager</a></li></ul> 
  </li><li><a href="#_299" rel="nofollow">五、各个机器命令进程</a></li><li><a href="#_313" rel="nofollow">六、网页端口效果</a></li><li><ul><li><a href="#1namenode_314" rel="nofollow">1、namenode</a></li><li><a href="#resourcemanager_320" rel="nofollow">resourcemanager</a></li></ul> 
  </li><li><a href="#_325" rel="nofollow">七、高可用测试</a></li><li><a href="#_329" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr color="#000000" size='1"'> 
<h2><a id="HADOOP_3"></a>一、什么是HADOOP?</h2> 
<p>Hadoop是一个由Apache基金会所开发的分布式系统基础架构，主要是分布式数据存储以及计算。</p> 
<h2><a id="_8"></a>二、如何下载</h2> 
<h3><a id="1_9"></a>1.官网下载</h3> 
<pre><code>1、apache版本：http://hadoop.apache.org/
2、cdh版本(已收费)：http://archive.cloudera.com/cdh5/cdh/5/
</code></pre> 
<h3><a id="2_13"></a>2.网盘下载</h3> 
<pre><code>链接：https://pan.baidu.com/s/18x2lc0Z7JbJ7pW-15VtiDg 提取码：cdh5 
</code></pre> 
<h2><a id="_15"></a>三、搭建集群</h2> 
<h3><a id="1_16"></a>1.虚拟机准备</h3> 
<p>请参考<a href="https://blog.csdn.net/qq_41924766/article/details/117464392">CHD大数据平台搭建之VMware及虚拟机安装</a><br> 以及<a href="https://blog.csdn.net/qq_41924766/article/details/117471299">CHD大数据平台搭建之虚拟环境配置</a></p> 
<h3><a id="2JDK_20"></a>2.安装JDK</h3> 
<p>请参考<a href="https://blog.csdn.net/qq_41924766/article/details/117564382">CHD大数据平台搭建之JDK安装</a></p> 
<h3><a id="3ZOOKEEPER_23"></a>3.安装ZOOKEEPER</h3> 
<p>请参考<a href="https://blog.csdn.net/qq_41924766/article/details/117669390">CHD大数据平台搭建之ZOOKEEPER安装</a></p> 
<h3><a id="4_26"></a>4.集群规划</h3> 
<p>请参考<a href="https://blog.csdn.net/qq_41924766/article/details/117561341">CHD大数据平台搭建之集群规划</a></p> 
<h3><a id="5HADOOP_28"></a>5.安装HADOOP</h3> 
<pre><code>tar -zxvf hadoop-2.6.0-cdh5.7.6.tar.gz -C /opt/modules/
</code></pre> 
<h3><a id="6_31"></a>6.修改配置文件</h3> 
<h4><a id="1_32"></a>1、进入配置文件目录：</h4> 
<pre><code>cd /opt/modules/hadoop-2.6.0-cdh5.7.6/etc/hadoop
</code></pre> 
<h4><a id="2env_34"></a>2、修改env文件</h4> 
<pre><code>配置env文件java安装目录
hadoop-env.sh
mapred-env.sh
yarn-env.sh 
修改：export JAVA_HOME=/opt/modules/jdk1.8.0_91
</code></pre> 
<h4><a id="3coresitexml_40"></a>3、修改core-site.xml文件</h4> 
<p>1、新建文件夹：</p> 
<pre><code>mkdir -p /opt/modules/hadoop-2.6.0-cdh5.7.6/data/tmp
</code></pre> 
<p>2、添加如下内容</p> 
 
<pre><code>&lt;property&gt;
	&lt;name&gt;fs.defaultFS&lt;/name&gt;
	&lt;value&gt;hdfs://mycluster&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;
&lt;property&gt;
	&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
	&lt;value&gt;/opt/modules/hadoop-2.6.0-cdh5.7.6/datas/tmp&lt;/value&gt;
&lt;/property&gt;
&lt;!-- zookeeper通讯地址--&gt;
&lt;property&gt;
	&lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;
	&lt;value&gt;bigdata-training03.hpsk.com:2181,bigdata-training04.hpsk.com:2181,bigdata-training05.hpsk.com:2181&lt;/value&gt;
&lt;/property&gt;
</code></pre> 
<h4><a id="4hdfssitexml_61"></a>4、修改hdfs-site.xml文件</h4> 
<p>1、新建文件夹：</p> 
<pre><code>mkdir -p /opt/modules/hadoop-2.6.0-cdh5.7.6/datas/jn
</code></pre> 
<p>2、添加如下内容：</p> 
<pre><code>&lt;!-- 完全分布式集群名称 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.nameservices&lt;/name&gt;
	&lt;value&gt;mycluster&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 集群中NameNode节点都有哪些 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;
	&lt;value&gt;nn1,nn2&lt;/value&gt;
&lt;/property&gt;

&lt;!-- nn1的RPC通信地址 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn1&lt;/name&gt;
	&lt;value&gt;bigdata-training01.hpsk.com:9000&lt;/value&gt;
&lt;/property&gt;

&lt;!-- nn2的RPC通信地址 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.namenode.rpc-address.mycluster.nn2&lt;/name&gt;
	&lt;value&gt;bigdata-training03.hpsk.com:9000&lt;/value&gt;
&lt;/property&gt;

&lt;!-- nn1的http通信地址 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.namenode.http-address.mycluster.nn1&lt;/name&gt;
	&lt;value&gt;bigdata-training01.hpsk.com:50070&lt;/value&gt;
&lt;/property&gt;

&lt;!-- nn2的http通信地址 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.namenode.http-address.mycluster.nn2&lt;/name&gt;
	&lt;value&gt;bigdata-training03.hpsk.com:50070&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 指定NameNode元数据在JournalNode上的存放位置 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;
	&lt;value&gt;qjournal://bigdata-training01.hpsk.com:8485;bigdata-training02.hpsk.com:8485;bigdata-training03.hpsk.com:8485;bigdata-training04.hpsk.com:8485;bigdata-training05.hpsk.com:8485/mycluster&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 配置隔离机制，即同一时刻只能有一台服务器对外响应 --&gt;
&lt;property&gt;
	&lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;
	&lt;value&gt;sshfence&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 使用隔离机制时需要ssh无秘钥登录--&gt;
&lt;property&gt;
	&lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;
	&lt;value&gt;/home/hpsk/.ssh/id_rsa&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 声明journalnode服务器存储目录--&gt;
&lt;property&gt;
	&lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;
	&lt;value&gt;/opt/modules/hadoop-2.6.0-cdh5.7.6/datas/jn&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 关闭权限检查--&gt;
&lt;property&gt;
	&lt;name&gt;dfs.permissions.enable&lt;/name&gt;
	&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 访问代理类：client，mycluster，active配置失败自动切换实现方式--&gt;
&lt;property&gt;
	&lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;
	&lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 自动切换--&gt;
&lt;property&gt;
	&lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre> 
<h4><a id="5mapredsitexml_145"></a>5、配置mapred-site.xml文件</h4> 
<p>1、修改文件名</p> 
<pre><code>mv mapred-site.xml.template mapred-site.xml
</code></pre> 
<p>2、添加如下内容：</p> 
<pre><code>&lt;!-- 指定MR运行在YARN上 --&gt;
&lt;property&gt;
	&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
	&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 历史服务器端地址 --&gt;
&lt;property&gt;
	&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
	&lt;value&gt;bigdata-training02.hpsk.com:10020&lt;/value&gt;
&lt;/property&gt;
</code></pre> 
<h4><a id="6yarnsitexml_164"></a>6、修改yarn-site.xml文件</h4> 
<p>1、添加如下内容：</p> 
<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;!--启用resourcemanager ha--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;!--声明两台resourcemanager的地址--&gt;
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;
    &lt;value&gt;cluster-yarn1&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;
    &lt;value&gt;rm1,rm2&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;
    &lt;value&gt;bigdata-training02.hpsk.com&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;
    &lt;value&gt;bigdata-training03.hpsk.com&lt;/value&gt;
&lt;/property&gt;

&lt;!--指定zookeeper集群的地址--&gt; 
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;
    &lt;value&gt;bigdata-training03.hpsk.com:2181,bigdata-training04.hpsk.com:2181,bigdata-training05.hpsk.com:2181&lt;/value&gt;
&lt;/property&gt;

&lt;!--启用自动恢复--&gt; 
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt;
    &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;!--指定resourcemanager的状态信息存储在zookeeper集群--&gt; 
&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt;     
	&lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 日志聚集功能使能 --&gt;
&lt;property&gt;
	&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
	&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 日志保留时间设置7天 --&gt;
&lt;property&gt;
	&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
	&lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;
</code></pre> 
<h4><a id="7slaves_229"></a>7、修改slaves文件</h4> 
<p>1、添加如下内容：</p> 
<pre><code>bigdata-training01.hpsk.com
bigdata-training02.hpsk.com
bigdata-training03.hpsk.com
bigdata-training04.hpsk.com
bigdata-training05.hpsk.com
</code></pre> 
<h4><a id="8_238"></a>8、分发文件</h4> 
<p>xsync参考<a href="https://blog.csdn.net/qq_41924766/article/details/117709745">CHD大数据平台搭建之xsync分发脚本</a></p> 
<pre><code>xsync hadoop-2.6.0-cdh5.7.6
</code></pre> 
<h4><a id="9_243"></a>9、配置环境变量</h4> 
<p>1、编辑配置文件</p> 
<pre><code>sudo vi /etc/profile
</code></pre> 
<p>2、添加内容</p> 
<pre><code># HADOOP_HOME
export HADOOP_HOME=/opt/modules/hadoop-2.6.0-cdh5.7.6
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
</code></pre> 
<h2><a id="_254"></a>四、启动集群</h2> 
<h3><a id="1ZOOKEEPER_255"></a>1.启动ZOOKEEPER集群</h3> 
<pre><code>在193、194、195三台机器启动ZK
zkServer.sh start
</code></pre> 
<h3><a id="2JournalNode_258"></a>2.启动JournalNode</h3> 
<pre><code>5台机器上面都执行
sbin/hadoop-daemon.sh start journalnode
</code></pre> 
<h3><a id="3namenode_262"></a>3.格式化namenode</h3> 
<pre><code>191上面格式化namenode
bin/hdfs namenode -format
</code></pre> 
<h3><a id="4zkfc_265"></a>4.格式化zkfc</h3> 
<pre><code>191上面格式化zkfc
bin/hdfs zkfc -formatZK
</code></pre> 
<h3><a id="5zkfc_269"></a>5.启动zkfc</h3> 
<pre><code>在191和193上启动zkfc
sbin/hadoop-daemon.sh start zkfc
</code></pre> 
<h3><a id="6namenode_272"></a>6.启动namenode</h3> 
<pre><code>在191上启动namenode
sbin/hadoop-daemon.sh start namenode
</code></pre> 
<h3><a id="7secondarynamenode_275"></a>7.格式化secondarynamenode</h3> 
<pre><code>在193上格式化namenode
bin/hdfs namenode -bootstrapStandby
</code></pre> 
<h3><a id="8secondarynamenode_278"></a>8.启动secondarynamenode</h3> 
<pre><code>在193上启动namenode
sbin/hadoop-daemon.sh start namenode
</code></pre> 
<h3><a id="9_282"></a>9.验证是否成功</h3> 
<pre><code>1、191和193上的命令行输入jps命令，有namenode进程
2、网页端口查看：
10.192.8.191:50070和10.192.8.193:50070
一个是standby和一个active
</code></pre> 
<h3><a id="10datanode_287"></a>10.启动datanode</h3> 
<pre><code>所有机器启动datanode
sbin/hadoop-daemon.sh start datanode
</code></pre> 
<h3><a id="11resourcemanager_291"></a>11.启动resourcemanager</h3> 
<pre><code>192和193上启动resourcemanager
sbin/yarn-daemon.sh start resourcemanager
</code></pre> 
<h3><a id="12nodemanager_295"></a>12.启动nodemanager</h3> 
<pre><code>所有机器启动nodemanager
sbin/yarn-daemon.sh start nodemanager
</code></pre> 
<h2><a id="_299"></a>五、各个机器命令进程</h2> 
<p>1、10.192.8.191进程如下：<br> <img src="https://images2.imgbox.com/5a/9f/9TWyKBcV_o.png" alt="在这里插入图片描述"><br> 2、10.192.8.192进程如下：<br> <img src="https://images2.imgbox.com/98/c5/SlfCWzN2_o.png" alt="在这里插入图片描述"></p> 
<p>3、10.192.8.193进程如下：<br> <img src="https://images2.imgbox.com/39/60/2hy4Bxzs_o.png" alt="在这里插入图片描述"></p> 
<p>4、10.192.8.194进程如下：<br> <img src="https://images2.imgbox.com/02/0a/m41FNuEp_o.png" alt="在这里插入图片描述"></p> 
<p>5、10.192.8.195进程如下：<br> <img src="https://images2.imgbox.com/ab/e6/wVFfsdnb_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_313"></a>六、网页端口效果</h2> 
<h3><a id="1namenode_314"></a>1、namenode</h3> 
<p>1、10.192.8.191网页<br> <img src="https://images2.imgbox.com/21/48/Wi8k3xqm_o.png" alt="在这里插入图片描述"></p> 
<p>2、10.192.8.193网页<br> <img src="https://images2.imgbox.com/0e/4e/0WnAsGxK_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="resourcemanager_320"></a>resourcemanager</h3> 
<p>1、10.192.8.192<br> <img src="https://images2.imgbox.com/4f/92/Jl4J92DU_o.png" alt="在这里插入图片描述"><br> 2、10.192.8.193<br> <img src="https://images2.imgbox.com/6a/54/dGSXVP7f_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_325"></a>七、高可用测试</h2> 
<pre><code>命令行kill -9 active状态的NN或者RN
查看另一个NN或者RN是否变成active
</code></pre> 
<h2><a id="_329"></a>总结</h2> 
<p>到此hadoop集群也就搭建完成了，觉得写得可以的小伙伴可以点个赞，网盘大数据所需软件，需要的找前面链接下载哦。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b5d8096e4fc74a09f5736ff2101b87c6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GX18B20温度传感器替代DS18B20，精度更高</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ccd6cf32fe9b564d5a992786058ff612/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">怎么有效地查询MySQL表中的重复数据</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>