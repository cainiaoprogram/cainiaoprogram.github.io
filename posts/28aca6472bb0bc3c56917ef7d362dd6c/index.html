<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms" />
<meta property="og:description" content=" 基于乳腺成像报告和数据系统(BI-RADS)和密度标准，先进的深度学习算法可以预测患者患乳腺癌的风险。最近的研究表明，多视角分析的结合改善了乳腺检查的整体分类。在本文中，我们提出了一种新的多视角DL方法用于BI-RADS和乳腺x线片密度评估。该方法首先在每个视图上分别部署深度卷积网络进行特征提取。然后，提取的特征被堆叠起来，并送入光梯度提升机(LightGBM)分类器来预测BI-RADS和密度分数。我们在内部乳房x线照相术数据集和公共数据集上进行了大量的实验。实验结果表明，该方法在两个基准数据集上(内部数据集&#43;5%，DDSM数据集&#43;10%)的分类性能显著优于单视图分类方法。这些结果突出了组合多视图的重要作用提高乳腺癌风险预测的信息。
方法 本文提出的BI-RADS密度分类体系结构分为两个阶段，如图1b所示。第一阶段使用cnn从乳房x线照片中学习潜在特征。然后第二阶段应用LightGBM作为分类器来预测BI-RADS和密度分数。为了验证所提出的多视图模型的有效性，我们将其与单视图方法进行了比较(图1a)。
图像预处理 大多数乳房x光片的背景都是黑色的，不显示任何信息，这对于训练来说是巨大的资源消耗。因此，我们使用YOLOv5构建了一个自动探测器，可以在原始扫描的基础上准确定位乳腺相关区域。为了训练探测器，我们手工标注了2000张乳房x光片，其中1600张用于训练，400张用于验证。经过训练的模型在验证集上的mAP为0.995，能够正确预测未见的乳房x线照片中的乳腺Bounding Box
多视图特征提取 根据特征提取过程，实现有监督的深度cnn，然后去除结构末端的全连接层，从输入图像中获得隐藏表示。隐藏表示是一个维数为H × W × C的张量，它是从原始维数下采样得到的。其中，我们使用ResNet-34和EfficientNet-B2作为特征提取步骤。为了训练ResNet-34提取器，将所有输入图像的大小调整为H × W = 512 × 512。此外，每一张乳房x光片都从原始的灰度通道复制到三个通道。经过训练的提取器后，得到维数为H × W × C = 32 × 24 × 512的特征张量。最后，将这个隐藏的表示在空间维度上进行平均池化，以得到一个512维的向量。同样，为了训练EfficientNetB2模型，输入是H× W ×C = 1024×768×3。隐张量为H × W × C = 32 × 24 × 1408，隐向量为1408维格式。
分类 这一阶段的输入是特征提取步骤的特征向量。我们在ResNet-34提供的N×512-dimensional向量和EfficientNet-B2提供的N×1408-dimensional向量上训练LightGBM分类器，其中N是训练图像的数量。LightGBM是一个基于树算法的梯度增强框架，实现更快地交付结果，减少内存使用，并提高准确性。多视图(图1b)架构背后的主要思想是使用来自四个视图的多个隐藏信息的融合来训练一个有效的分类器。特征提取步骤中的四个骨干分别为数据集的每个视图进行训练。在这种组合技术中，我们平均了L- cc和LMLO特征向量，以及R-CC和R-MLO特征向量。然后将所有的平均向量作为lighttgbm的输入，以提供BI-RADS的置信分数和密度。
数据集 我们在我们的私有数据集和DDSM数据集上评估了所提出的方法。该私人数据集是回顾性收集自2018年至2020年的河内医科大学医院。每幅图像被分配给一个由三名放射专家组成的团队，他们专门从事乳房成像的多标记标注(BI-RADS 1-5和乳腺密度A-D)。总的来说，该数据集包括来自9911项研究的36138张筛查乳房x光照片。共有8509个四视图研究，每个视图包含一个图像(L-CC, L-MLO, R-CC, R-MLO)。这些考试被多重标签分层方法分为三组:训练集(5,792项研究)、验证集(1,266项研究)和测试集(1,271项研究)。表1对私有数据集上的三个集合进行了描述。对于DDSM数据集，在培训、验证、测试集上进行多标签分层的考试数量为1822个;391;和391年,分别。每项研究都涉及两个乳房的图像，以及病理标签和密度信息。有四种类型的标签，正常-良性-癌症-良性与回调-良性没有回调。DDSM训练集包含486个正常病例，704个良性病例和632个癌症病例。正常/良性/癌症研究在验证集和测试集中的数字分别为105/147/139和104/145/142。对于这两个数据集，每个乳房的病理/BI-RADS标签是其CC和MLO图像的最大标签，而这两个视图图像的密度肯定具有相同的信息
结果 " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/28aca6472bb0bc3c56917ef7d362dd6c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-11T11:15:43+08:00" />
<meta property="article:modified_time" content="2022-03-11T11:15:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">A novel multi-view deep learning approach for BI-RADS and density assessment of mammograms</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <blockquote> 
 <p>基于乳腺成像报告和数据系统(BI-RADS)和密度标准，先进的深度学习算法可以预测患者患乳腺癌的风险。最近的研究表明，多视角分析的结合改善了乳腺检查的整体分类。在本文中，我们提出了一种新的多视角DL方法用于BI-RADS和乳腺x线片密度评估。该方法首先在每个视图上分别部署深度卷积网络进行特征提取。然后，提取的特征被堆叠起来，并送入光梯度提升机(LightGBM)分类器来预测BI-RADS和密度分数。我们在内部乳房x线照相术数据集和公共数据集上进行了大量的实验。实验结果表明，该方法在两个基准数据集上(内部数据集+5%，DDSM数据集+10%)的分类性能显著优于单视图分类方法。这些结果突出了组合多视图的重要作用提高乳腺癌风险预测的信息。</p> 
</blockquote> 
<h2>方法</h2> 
<p>本文提出的BI-RADS密度分类体系结构分为两个阶段，如图1b所示。第一阶段使用cnn从乳房x线照片中学习潜在特征。然后第二阶段应用LightGBM作为分类器来预测BI-RADS和密度分数。为了验证所提出的多视图模型的有效性，我们将其与单视图方法进行了比较(图1a)。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/b8/31/FMjmex7q_o.png"></p> 
<p> </p> 
<h4>图像预处理</h4> 
<p>大多数乳房x光片的背景都是黑色的，不显示任何信息，这对于训练来说是巨大的资源消耗。因此，我们使用YOLOv5构建了一个自动探测器，可以在原始扫描的基础上准确定位乳腺相关区域。为了训练探测器，我们手工标注了2000张乳房x光片，其中1600张用于训练，400张用于验证。经过训练的模型在验证集上的mAP为0.995，能够正确预测未见的乳房x线照片中的乳腺Bounding Box</p> 
<h4>多视图特征提取</h4> 
<p>根据特征提取过程，实现有监督的深度cnn，然后去除结构末端的全连接层，从输入图像中获得隐藏表示。隐藏表示是一个维数为H × W × C的张量，它是从原始维数下采样得到的。其中，我们使用ResNet-34和EfficientNet-B2作为特征提取步骤。为了训练ResNet-34提取器，将所有输入图像的大小调整为H × W = 512 × 512。此外，每一张乳房x光片都从原始的灰度通道复制到三个通道。经过训练的提取器后，得到维数为H × W × C = 32 × 24 × 512的特征张量。最后，将这个隐藏的表示在空间维度上进行平均池化，以得到一个512维的向量。同样，为了训练EfficientNetB2模型，输入是H× W ×C = 1024×768×3。隐张量为H × W × C = 32 × 24 × 1408，隐向量为1408维格式。</p> 
<h4>分类</h4> 
<p>这一阶段的输入是特征提取步骤的特征向量。我们在ResNet-34提供的N×512-dimensional向量和EfficientNet-B2提供的N×1408-dimensional向量上训练LightGBM分类器，其中N是训练图像的数量。LightGBM是一个基于树算法的梯度增强框架，实现更快地交付结果，减少内存使用，并提高准确性。多视图(图1b)架构背后的主要思想是使用来自四个视图的多个隐藏信息的融合来训练一个有效的分类器。特征提取步骤中的四个骨干分别为数据集的每个视图进行训练。在这种组合技术中，我们平均了L- cc和LMLO特征向量，以及R-CC和R-MLO特征向量。然后将所有的平均向量作为lighttgbm的输入，以提供BI-RADS的置信分数和密度。</p> 
<h4>数据集</h4> 
<p>我们在我们的私有数据集和DDSM数据集上评估了所提出的方法。该私人数据集是回顾性收集自2018年至2020年的河内医科大学医院。每幅图像被分配给一个由三名放射专家组成的团队，他们专门从事乳房成像的多标记标注(BI-RADS 1-5和乳腺密度A-D)。总的来说，该数据集包括来自9911项研究的36138张筛查乳房x光照片。共有8509个四视图研究，每个视图包含一个图像(L-CC, L-MLO, R-CC, R-MLO)。这些考试被多重标签分层方法分为三组:训练集(5,792项研究)、验证集(1,266项研究)和测试集(1,271项研究)。表1对私有数据集上的三个集合进行了描述。对于DDSM数据集，在培训、验证、测试集上进行多标签分层的考试数量为1822个;391;和391年,分别。每项研究都涉及两个乳房的图像，以及病理标签和密度信息。有四种类型的标签，正常-良性-癌症-良性与回调-良性没有回调。DDSM训练集包含486个正常病例，704个良性病例和632个癌症病例。正常/良性/癌症研究在验证集和测试集中的数字分别为105/147/139和104/145/142。对于这两个数据集，每个乳房的病理/BI-RADS标签是其CC和MLO图像的最大标签，而这两个视图图像的密度肯定具有相同的信息</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/8a/ac/hyjdgO9h_o.png"></p> 
<p></p> 
<h4>结果</h4> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/3e/f8/gXxTyBIu_o.png"></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f7568d65e51b24d8f58ae803d368ee06/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Windows通过计划任务定时执行bat文件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/595bddf06bb4abe985cb3c352376ed22/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">超详细的R语言热图之complexheatmap系列（1）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>