<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>YOLOv3网络结构 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="YOLOv3网络结构" />
<meta property="og:description" content="YOLOv3网络结构 文章目录 YOLOv3网络结构简介实现原理整体结构图示各结构组成及分析1. backbone部分2. neck部分3. head部分 输出解耦 简介 YOLOv3是一种基于深度学习的目标检测算法，由Joseph Redmon等人于2018年提出。YOLOv3是YOLO系列的第三个版本，相比于前两个版本，YOLOv3在速度和精度上都有了很大的提升，相较于YOLOv2的主要变化在于引入了多尺度的概念。
实现原理 YOLOv3实现的大致原理是由卷积神经网络（CNN）网络的输出把图片分成N×N个网格，然后每个网格负责去检测那些中心点落在该格子内的目标。YOLOv3设定的是每个网格单元预测3个box，所以每个box需要有 (x, y, w, h, confidence)五个基本参数，然后根据数据集的类型的不同还要有20或80个类别的概率。
整体结构图示 各结构组成及分析 1. backbone部分 YOLOv3使用了darknet-53的前面的52层（没有用于图像分类的全连接层）作为backbone部分，这部分是通用的，也可以加上全连接层拿来做图像分类等任务。
DarkNet53中大量使用残差结构的跳层连接，并且为了降低池化带来的梯度负面效果，作者直接摒弃了POOLing，用conv的stride来实现降采样。
如上图所示，蓝色方块×1，×2，×8分别表示该模块重复1次、2次和8次，橙色方块是该模块的名字，Conv Block 表示该模块是一个普通的卷积模块，Residual Block 代表该模块是一个残差网络结构（残差网络具体结构见《常用的卷积结构》）。
2. neck部分 YOLOv3的neck部分使用的是FPN，FPN是特征金字塔网络的缩写。它是一种特征提取方法，可用于目标检测任务。FPN可以从图像中提取不同尺度和分辨率的特征，然后将它们组合成一个特征金字塔。这个特征金字塔可以用于检测图像中不同大小的物体。
如上图所示，backbone部分输出的shape分别为（13，13，1024），（26，26，512），（52，52，256）。将这三个输出分别输入到FPN中，（13，13，1024）这一个输入，经过5次卷积后，输出（13，13，512），然后兵分两路，一路传入到head中，一路再经过一个卷积和上采样，得到（26，26，256），将这个输出和backbone的第2个输出也就是（26，26，512）进行堆叠操作（concat）,得到（26，26，768）。以此类推：（26，26，768）再经过5次卷积，然后兵分两路，将上采样输出和backbone的输出进行堆叠操作；最后对（52，52，256）的输出也进行相同操作。最终得到三个分支来传给head部分。
区别concat与add操作：concat操作是把两个矩阵通道堆叠到一起，里面的数据不变，通道数为两者相加；add操作是把两个矩阵数据加在一起，两者通道数相同且不变，只是单纯的数据相加。
3. head部分 YOLOv3的head部分是YOLOv3的检测头部分，用于将neck部分的输出特征图转换为检测结果。YOLOv3的head部分包括三个卷积层，其中两个卷积层使用1×1卷积核，以减少特征图的通道数，最后一个卷积层使用1×1卷积核和3×3卷积核，以生成最终的检测结果。
如上图，FPN输出的3个分支，通过两层卷积输出预测head。这里最终输出的形式为：batchSize×(4&#43;1&#43;类别总数)×特征图宽×特征图宽。其中的4为预测框的tx，ty，tw，th。这里假定采用coco数据集，有80个类别，所以输出的tensor的channel输为255。
输出解耦 YOLOv3网络在head部分输出后还要经历对输出解耦的部分。具体实现过程如下：
我们以13×13的输出为例，原本416×416大小变成13×13，相当于缩小了416/13=32倍，也就是说原图32×32个小方块对应于最后输出的1×1的像素点。
如下图，蓝色的是实际的标注框，粉红色的是对应到13×13上的先验框，先验框是固定不变的，它的中心就是落在13×13的交点上，长宽就是除以32的结果每个特征图。由于先验框是我们一开始自己确定的，显然是不正确，需要模型对它调整。
我们将初始先验框坐标记为（cx,cy,pw,ph），模型输出的4为（tx,ty,tw,th）,调整的公式如上图所示，中心点取sigmoid激活函数，sigmoid函数范围是0~1，也就是中心点的调整范围永远在右下角的框内，这也就是我们说的，物体的中心落在哪个格子里，该物体就由哪个框负责预测。
范围永远在右下角的框内，这也就是我们说的，物体的中心落在哪个格子里，该物体就由哪个框负责预测。
最后将长宽取exp后与先验框对应坐标相乘。这就得到了在13×13尺寸图上的预测框，然后再乘以32缩放回来就得到了最后的预测框。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/723123513a81a4b5328f27c99e49e084/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-05T16:30:02+08:00" />
<meta property="article:modified_time" content="2023-04-05T16:30:02+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">YOLOv3网络结构</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="YOLOv3_0"></a>YOLOv3网络结构</h2> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#YOLOv3_0" rel="nofollow">YOLOv3网络结构</a></li><li><ul><li><a href="#_3" rel="nofollow">简介</a></li><li><a href="#_7" rel="nofollow">实现原理</a></li><li><a href="#_10" rel="nofollow">整体结构图示</a></li><li><a href="#_13" rel="nofollow">各结构组成及分析</a></li><li><ul><li><a href="#1_backbone_15" rel="nofollow">1. backbone部分</a></li><li><a href="#2_neck_24" rel="nofollow">2. neck部分</a></li><li><a href="#3_head_35" rel="nofollow">3. head部分</a></li></ul> 
   </li><li><a href="#_44" rel="nofollow">输出解耦</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_3"></a>简介</h3> 
<p>YOLOv3是一种基于深度学习的目标检测算法，由Joseph Redmon等人于2018年提出。YOLOv3是YOLO系列的第三个版本，相比于前两个版本，YOLOv3在速度和精度上都有了很大的提升，相较于YOLOv2的主要变化在于引入了多尺度的概念。</p> 
<h3><a id="_7"></a>实现原理</h3> 
<p>YOLOv3实现的大致原理是由卷积神经网络（CNN）网络的输出把图片分成N×N个网格，然后每个网格负责去检测那些中心点落在该格子内的目标。YOLOv3设定的是每个网格单元预测3个box，所以每个box需要有 (x, y, w, h, confidence)五个基本参数，然后根据数据集的类型的不同还要有20或80个类别的概率。</p> 
<h3><a id="_10"></a>整体结构图示</h3> 
<p><img src="https://images2.imgbox.com/81/7c/WzTZu15y_o.jpg" alt="在这里插入图片描述"></p> 
<h3><a id="_13"></a>各结构组成及分析</h3> 
<h4><a id="1_backbone_15"></a>1. backbone部分</h4> 
<p>YOLOv3使用了darknet-53的前面的52层（没有用于图像分类的全连接层）作为backbone部分，这部分是通用的，也可以加上全连接层拿来做图像分类等任务。</p> 
<p>DarkNet53中大量使用残差结构的跳层连接，并且为了降低池化带来的梯度负面效果，作者直接摒弃了POOLing，用conv的stride来实现降采样。<img src="https://images2.imgbox.com/00/4a/rUl5kTMI_o.jpg" alt="在这里插入图片描述"></p> 
<p>如上图所示，蓝色方块×1，×2，×8分别表示该模块重复1次、2次和8次，橙色方块是该模块的名字，Conv Block 表示该模块是一个普通的卷积模块，Residual Block 代表该模块是一个残差网络结构（残差网络具体结构见《常用的卷积结构》）。</p> 
<h4><a id="2_neck_24"></a>2. neck部分</h4> 
<p>YOLOv3的neck部分使用的是FPN，FPN是特征金字塔网络的缩写。它是一种特征提取方法，可用于目标检测任务。FPN可以从图像中提取不同尺度和分辨率的特征，然后将它们组合成一个特征金字塔。这个特征金字塔可以用于检测图像中不同大小的物体。</p> 
<p><img src="https://images2.imgbox.com/4d/6f/hAbS7ieW_o.png" alt="在这里插入图片描述"></p> 
<p>如上图所示，backbone部分输出的shape分别为（13，13，1024），（26，26，512），（52，52，256）。将这三个输出分别输入到FPN中，（13，13，1024）这一个输入，经过5次卷积后，输出（13，13，512），然后兵分两路，一路传入到head中，一路再经过一个卷积和上采样，得到（26，26，256），将这个输出和backbone的第2个输出也就是（26，26，512）进行堆叠操作（concat）,得到（26，26，768）。以此类推：（26，26，768）再经过5次卷积，然后兵分两路，将上采样输出和backbone的输出进行堆叠操作；最后对（52，52，256）的输出也进行相同操作。最终得到三个分支来传给head部分。</p> 
<p>区别concat与add操作：concat操作是把两个矩阵通道堆叠到一起，里面的数据不变，通道数为两者相加；add操作是把两个矩阵数据加在一起，两者通道数相同且不变，只是单纯的数据相加。</p> 
<h4><a id="3_head_35"></a>3. head部分</h4> 
<p>YOLOv3的head部分是YOLOv3的检测头部分，用于将neck部分的输出特征图转换为检测结果。YOLOv3的head部分包括三个卷积层，其中两个卷积层使用1×1卷积核，以减少特征图的通道数，最后一个卷积层使用1×1卷积核和3×3卷积核，以生成最终的检测结果。</p> 
<p><img src="https://images2.imgbox.com/03/dc/JQ8jjr07_o.png" alt="在这里插入图片描述"></p> 
<p>如上图，FPN输出的3个分支，通过两层卷积输出预测head。这里最终输出的形式为：batchSize×(4+1+类别总数)×特征图宽×特征图宽。其中的4为预测框的tx，ty，tw，th。这里假定采用coco数据集，有80个类别，所以输出的tensor的channel输为255。</p> 
<h3><a id="_44"></a>输出解耦</h3> 
<p>YOLOv3网络在head部分输出后还要经历对输出解耦的部分。具体实现过程如下：</p> 
<p>我们以13×13的输出为例，原本416×416大小变成13×13，相当于缩小了416/13=32倍，也就是说原图32×32个小方块对应于最后输出的1×1的像素点。</p> 
<p>如下图，蓝色的是实际的标注框，粉红色的是对应到13×13上的先验框，先验框是固定不变的，它的中心就是落在13×13的交点上，长宽就是除以32的结果每个特征图。由于先验框是我们一开始自己确定的，显然是不正确，需要模型对它调整。</p> 
<p><img src="https://images2.imgbox.com/f2/96/J95xjLwK_o.png" alt="在这里插入图片描述"></p> 
<p>我们将初始先验框坐标记为（cx,cy,pw,ph），模型输出的4为（tx,ty,tw,th）,调整的公式如上图所示，中心点取sigmoid激活函数，sigmoid函数范围是0~1，也就是中心点的调整范围永远在右下角的框内，这也就是我们说的，物体的中心落在哪个格子里，该物体就由哪个框负责预测。</p> 
<p>范围永远在右下角的框内，这也就是我们说的，物体的中心落在哪个格子里，该物体就由哪个框负责预测。</p> 
<p>最后将长宽取exp后与先验框对应坐标相乘。这就得到了在13×13尺寸图上的预测框，然后再乘以32缩放回来就得到了最后的预测框。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/2effc5c6934e3495123ff0e37668b860/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Vue3解决懒加载</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8ff68dca2e47fd76b008e255e4a3ecb2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">pytorch安装和测试</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>