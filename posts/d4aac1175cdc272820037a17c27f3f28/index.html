<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>机器学习--模型评价和选择（8） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="机器学习--模型评价和选择（8）" />
<meta property="og:description" content="一、基本概念 误差（误差期望）：学习器的实际预测输出与样本真实输出之间的差异
经验误差（训练误差）：学习器在训练集上的误差
泛化误差：学习器在新样本上的误差
过拟合（过配）：学习器学习能力过强，将训练集中自身的特点当做所有潜在样本都会由的一般性质，这会导致泛化能力下降。 无法避免，只能缓解
欠拟合（欠配）：学习器对训练样本的一般性质没有学好
二、训练流程 2.1 获取测试集 测试集应该尽量与训练集互斥
当我们只有一个包含m条记录的训练集，需要对训练集进行拆分，拆分方法如下：
留出法：
① 原理： 即将训练集划分为测试集和训练集。
② 划分原则：
训练\测试集要保持均衡（和原数据集中各部分比例尽可能一致）
按比例 一般为 37 28 19
③ 注意：
使用单次留出法估计结果不太可靠，需要我们采用若干次随机划分、重复进行实验评估后采取所有结果的均值作为最终的评估结果
④ 局限：
若划分后的训练集包含大多数数据，那么训练出来的模型更接近用原数据训练出来的模型，此时测试集中数据较少，评估结果不准确；若令划分后的测试集中包含较多的数据，那么划分后训练集训练出的模型和原数据训练出的模型差距较大，从而会降低评估结果的保真性。
此问题无好的解决办法，只能选取合适的比例。
⑤ 适用范围： 数据量足够
∙ \bullet ∙ 交叉验证法：（k折交叉验证）
① 原理：
将数据集D 划分为k个子集，每个子集通过分层采样得到（为了保持数据分布的一致性），然后用k-1个子集的并集作为训练集，余下的一个子集为测试集，这样可以重复进行k次训练和测试，最后结果为这k次实验的均值。
② 注意：
评估结果的稳定性和保真性取决与k的值
同留出法一样，需要重复进行p次划分，将这p次的实验结果的均值作为最终的结果
③ 特例：留一法
数据集D有m个样本，划分为m个子集，即为留一法。
留一法训练出来的模型与D训练出来的模型及其相似，因此留一法评估结果相对准确
缺陷：
未考虑调参情况下，留一法也难以应对海量数据带来的开销，计算复杂度高
根据“没有免费午餐”定理，留一法的结果也未必永远比其他方法准确
④ 适用范围： 数据量足够大
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
∙ \bullet ∙ 自助法：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d4aac1175cdc272820037a17c27f3f28/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-25T19:40:18+08:00" />
<meta property="article:modified_time" content="2020-11-25T19:40:18+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">机器学习--模型评价和选择（8）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>一、基本概念</h2> 
<p>误差（误差期望）：学习器的实际预测输出与样本真实输出之间的差异<br> 经验误差（训练误差）：学习器在训练集上的误差<br> 泛化误差：学习器在新样本上的误差<br> 过拟合（过配）：学习器学习能力过强，将训练集中自身的特点当做所有潜在样本都会由的一般性质，这会导致泛化能力下降。 无法避免，只能缓解<br> 欠拟合（欠配）：学习器对训练样本的一般性质没有学好</p> 
<h2><a id="_7"></a>二、训练流程</h2> 
<h3><a id="21__9"></a>2.1 获取测试集</h3> 
<p>测试集应该尽量与训练集互斥</p> 
<p>当我们只有一个包含m条记录的训练集，需要对训练集进行拆分，拆分方法如下：</p> 
<p><mark>留出法：</mark></p> 
<p>① 原理： 即将训练集划分为测试集和训练集。</p> 
<p>② 划分原则：<br> 训练\测试集要保持均衡（和原数据集中各部分比例尽可能一致）<br> 按比例 一般为 37 28 19</p> 
<p>③ 注意：<br> 使用单次留出法估计结果不太可靠，需要我们采用若干次随机划分、重复进行实验评估后采取所有结果的均值作为最终的评估结果</p> 
<p>④ 局限：<br> 若划分后的训练集包含大多数数据，那么训练出来的模型更接近用原数据训练出来的模型，此时测试集中数据较少，评估结果不准确；若令划分后的测试集中包含较多的数据，那么划分后训练集训练出的模型和原数据训练出的模型差距较大，从而会降低评估结果的保真性。<br> 此问题无好的解决办法，只能选取合适的比例。</p> 
<p>⑤ 适用范围： 数据量足够</p> 
<p><mark><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ∙ 
         
        
       
         \bullet 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.44445em; vertical-align: 0em;"></span><span class="mord">∙</span></span></span></span></span> 交叉验证法：（k折交叉验证）</mark></p> 
<p>① 原理：<br> 将数据集D 划分为k个子集，每个子集通过分层采样得到（为了保持数据分布的一致性），然后用k-1个子集的并集作为训练集，余下的一个子集为测试集，这样可以重复进行k次训练和测试，最后结果为这k次实验的均值。</p> 
<p>② 注意：</p> 
<p>评估结果的稳定性和保真性取决与k的值</p> 
<p>同留出法一样，需要重复进行p次划分，将这p次的实验结果的均值作为最终的结果</p> 
<p>③ 特例：留一法</p> 
<p>数据集D有m个样本，划分为m个子集，即为留一法。</p> 
<p>留一法训练出来的模型与D训练出来的模型及其相似，因此留一法评估结果相对准确</p> 
<p>缺陷：<br> 未考虑调参情况下，留一法也难以应对海量数据带来的开销，计算复杂度高<br> 根据“没有免费午餐”定理，留一法的结果也未必永远比其他方法准确</p> 
<p>④ 适用范围： 数据量足够大</p> 
<p>from sklearn.model_selection import KFold<br> from sklearn.model_selection import cross_val_score<br> from sklearn.model_selection import GridSearchCV</p> 
<p><mark><span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ∙ 
         
        
       
         \bullet 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.44445em; vertical-align: 0em;"></span><span class="mord">∙</span></span></span></span></span> 自助法：</mark></p> 
<p>① 原理：<br> 它以自助采样法为基础（有放回采样），对于有m个记录的数据集D，对它采样才生数据集D’，:<br> 每次从D中随机取出一个样本，拷贝后放入D’，再将取出的样本放回D，重复m次上述过程，得到包含m个样本的数据集D’。<br> D中的记录有的多次出现再D’中，有的没有出现。D中样本在D’中不出现的概率为<img src="https://images2.imgbox.com/d5/3c/uTP4uA1Z_o.png" alt="在这里插入图片描述"><br> 我们用D’作为训练集，用D\D’ 作为测试集</p> 
<p>② 适用范围：</p> 
<p>数据量较小，且难以有效划分训练\测试集</p> 
<p>③：优缺点</p> 
<p>能产生多个不同的测试集，对集成学习有帮助<br> 改变了原始数据集的分布，会产生估计偏差</p> 
<h3><a id="22__78"></a>2.2 调参</h3> 
<p>参数往往是在实数范围内取值，故将所有可能的参数都训练出来模型不太现实。我们往往对每个参数选取一定的范围和步长，这是折合了性能估计和计算开销的选择</p> 
<h2><a id="_82"></a>三、性能度量</h2> 
<h3><a id="31__83"></a>3.1 错误率与精度</h3> 
<p>分类任务最常用的两种度量方式，既适用于二分类任务，也适用于多分类任务。</p> 
<p>错误率：分类错误的样本数占总样本数的比例<br> 精度：1-错误率</p> 
<h3><a id="32_F1_90"></a>3.2 查准率与查全率与F1度量</h3> 
<p>混淆矩阵：</p> 
<p>预测值为正例，记为P（Positive）<br> 预测值为反例，记为N（Negative）<br> 预测值与真实值相同，记为T（True）<br> 预测值与真实值相反，记为F（False）</p> 
<p><img src="https://images2.imgbox.com/01/f1/bVDymFsX_o.png" alt="在这里插入图片描述"></p> 
<p>TP真阳性 ：预测类别是P（正例），真实类别也是P<br> FP假阳性 ：预测类别是P，真实类别是N（反例）<br> TN真阴性 ：预测类别是N，真实类别也是N<br> FN假阴性 ：预测类别是N，真实类别是P</p> 
<p>将样例根据真实类别与学习器预测类别的组合划分为真正例TP、假正例FP、假反例FN、正反例TN。他们的和为样例总数。</p> 
<p>查准率P和查全率R为：<br> <img src="https://images2.imgbox.com/0f/c7/SsAsIjU3_o.png" alt="在这里插入图片描述"></p> 
<p>P-R曲线： 查准率为纵轴，查全率为横轴</p> 
<p>若一个学习器的PR曲线被另一个学习器的曲线完全包住，那么我们说后者的性能优于前者；若两者PR曲线交叉，我们通常采用两者曲线的交点，即平衡点（BEP，查准率=查全率的取值）来衡量两者的性能优劣</p> 
<p>F1： 两者性能优劣更常用的度量方式</p> 
<p>F1的一般形式–Fβ：<br> <img src="https://images2.imgbox.com/51/e4/KjZjFvtZ_o.png" alt="在这里插入图片描述"><br> β&gt;0，度量了查全率对查准率的相对重要性；β=1，退化为标准的F1度量；β&gt;1，查全率有更大影响；β&lt;1，查准率有更大影响</p> 
<h3><a id="33_ROCAUC_123"></a>3.3 ROC和AUC</h3> 
<p>ROC曲线： 横轴为假正例率（FPR），纵轴为真正例率(TPR)</p> 
<p><img src="https://images2.imgbox.com/ec/ee/N4m880V1_o.png" alt="在这里插入图片描述"><br> 进行学习器比较时，若一个学习器的ROC曲线被另一个学习器完全包住，那么后者性能优于前者，若发生交叉，那么我们一般采用ROC曲线下的面积，即AUC</p> 
<h3><a id="34__130"></a>3.4 代价敏感错误率和代价曲线</h3> 
<p>为权衡不同类型错误所造成的不同损失，可为错误赋予“非均等代价”</p> 
<h2><a id="_134"></a>四、练习</h2> 
<p>用ROC评价模型，绘制混淆矩阵</p> 
<pre><code>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

# 导入波士顿房价数据集
from sklearn.datasets import load_boston

# 返回样例集合和标签集合
X,y = load_boston(return_X_y=True)

# # 查看房价中位数和最大值
median = np.median(y)
max = np.max(y)

# 将y二值化
y = pd.Series(y).map(lambda x:(x&gt;median)*1)

# 拆分数据集
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=1,train_size=0.8)

# 生成模型并训练
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
lr = LogisticRegression()
gnb = GaussianNB()
lr.fit(X_train,y_train)
gnb.fit(X_train,y_train)

# 预测
lr_y_ = lr.predict(X_test)
gnb_y_ = gnb.predict(X_test)

from sklearn.metrics import confusion_matrix

# 绘制混淆矩阵   
def paint_cm(y_true,y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()
    cm = confusion_matrix(y_true,y_pred)
    sns.set_style('white')
    plt.imshow(cm,cmap=plt.cm.rainbow)
    plt.xticks([0,1])
    plt.yticks([0,1])
    plt.text(x=0-0.1,y=0,s='TP:%d'%tp)
    plt.text(x=0-0.1,y=1,s='FN:%d'%fn)
    plt.text(x=1-0.1,y=0,s='FP:%d'%fp)
    plt.text(x=1-0.1,y=1,s='TN:%d'%tn)
    plt.rcParams['font.sans-serif'] = ['SimHei']
    plt.title("混淆矩阵")

# 封装评价函数
def select_model(y_true,y_pred,score):
    tn, fp, fn, tp = confusion_matrix(y_true,y_pred).ravel()
    # 查准率 P
    P = tp/(tp+fp)
    # 查全率 R
    R = tp/(tp+fn)
    # F1
    from sklearn.metrics import f1_score,roc_curve,roc_auc_score
    F1 = f1_score(y_true,y_pred)
    # ROC曲线
    fpr,tpr,thresholds = roc_curve(y_test,score,pos_label=1)
    plt.plot(fpr,tpr,color='green')
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.plot(np.linspace(0,1,10),np.linspace(0,1,10),ls='--')
    plt.legend()
    plt.show()
    
    return P,R,F1

score1 = lr.predict_proba(X_test)[:,1]
score2 = gnb.predict_proba(X_test)[:,1]

P,R,F1 = select_model(y_test,lr_y_,score1)
</code></pre> 
<p><img src="https://images2.imgbox.com/87/65/2xUrqR11_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/1c/72/uC7axHb8_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4657c1c1cf8c5a5bac293d8970d63d69/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">23_linux笔记-ansible</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f59a7d70c4fdb328216608edc06c51f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">1370. 上升下降字符串</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>