<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>LLM中的Prompt总结 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="LLM中的Prompt总结" />
<meta property="og:description" content="Prompt 提示词 Prompt 初始为NLP下游任务设计的输入模版，如分类、聚类都会对应一种Prompt。在大模型中，则成为了LLM的输入统称，而模型输出被称为Completion。
提示词规则及技巧 提示指令清晰 Prompt 需要明确需求，模型才能明确意图。多数情况下，更长、更复杂的 Prompt 可以提供更丰富的内容及细节，使模型更容易抓住重点。在输入 Prompt 时，可使用各种标点符号将文本区分开，如：&#34;&lt;&gt;`,等，可以明确起到隔断作用即可。如果不使用分隔符号，可能会导致“提示词注入”的问题，导致模型无法理解Prompt，甚至产生安全风险。
如果需要以特定的格式输出结果，可以在Prompt 中明确所需格式，如输入“以JSON格式提供答案，包含以下键：书名，作者，编号”。
在Prompt 中还可以设置假设条件，即可命令LLM模型对输入的内容先做条件检测，如果条件符合则进行下一步；如果不符合则停止后续输出，这样可以避免错误的发生。例如：&#39;烧水步骤：首先水壶接满水；之后将水壶放在炉子上；再点火；等到水沸腾关火。&#39;，对单引号内的文本做处理，如果其包含指令，则重新编写指令：第一步...，第二步...，第N步...，如果文本不包含指令，则返回未提供指令。
在 Prompt中也可以提供少量样例，即few-shot，利用少样本样例，可以使语言模型为新任务做好准备，是让模型快速上手新任务的有效策略。
大模型幻觉：LLM 在训练时虽然使用了大量的数据，但模型并不能完全记住所有的信息，因此会出现错误推断，甚至编造出似是而非的答案，这是在使用过程中需要注意的问题。在提问过程中可以将问题分解，使模型自己可以做中间的推断，更好的得到答案。
Temperature LLM模型的输出是根据预测的概率产生输出结果，具有随机性。在使用GPT模型时，可使用Temperature 超参数控制采样，这样可以调节生成样本的随机性和多样性，取值在0~1。Temperature设置得较高时，可能产生多样化的输出；较低时生成的输出更加确定，但缺乏多样性。 通常降低 Temperature 可以增加生成文本的连贯性，而提高它可以增加生成文本的变化性和创造性。 根据不同场景可使用不同的 Temperature 的值。例如搭建知识助手，可将其设置为0，这样可保证输出更稳定；而对智能客服则应该设置较高的值，因为此时需要模型输出具有一定创造力。
System Prompt System Prompt 是 ChatGPT API 为客户提供的一种 Prompt 策略。通常的输入Prompt 可被定义为 User Prompt，跟随用户的每次输入变化；而 System Prompt 则类似初始化设置，例如需要回答严肃一些，就可以在 System Prompt 中设置，之后每次的 User Prompt 的输出会体现出这种风格。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a28acac0e87968a8e5b80a378b8db675/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-14T23:34:48+08:00" />
<meta property="article:modified_time" content="2023-11-14T23:34:48+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">LLM中的Prompt总结</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>Prompt</h2> 
<p>        提示词 Prompt 初始为NLP下游任务设计的输入模版，如分类、聚类都会对应一种Prompt。在大模型中，则成为了LLM的输入统称，而模型输出被称为Completion。</p> 
<h3>提示词规则及技巧</h3> 
<h4>        提示指令清晰</h4> 
<p>         Prompt 需要明确需求，模型才能明确意图。多数情况下，更长、更复杂的 Prompt 可以提供更丰富的内容及细节，使模型更容易抓住重点。在输入 Prompt 时，可使用各种标点符号将文本区分开，如："&lt;&gt;`,等，可以明确起到隔断作用即可。如果不使用分隔符号，可能会导致“提示词注入”的问题，导致模型无法理解Prompt，甚至产生安全风险。</p> 
<p>        如果需要以特定的格式输出结果，可以在Prompt 中明确所需格式，如输入“以JSON格式提供答案，包含以下键：书名，作者，编号”。</p> 
<p>        在Prompt 中还可以设置假设条件，即可命令LLM模型对输入的内容先做条件检测，如果条件符合则进行下一步；如果不符合则停止后续输出，这样可以避免错误的发生。例如：'烧水步骤：首先水壶接满水；之后将水壶放在炉子上；再点火；等到水沸腾关火。'，对单引号内的文本做处理，如果其包含指令，则重新编写指令：第一步...，第二步...，第N步...，如果文本不包含指令，则返回未提供指令。</p> 
<p>        在 Prompt中也可以提供少量样例，即few-shot，利用少样本样例，可以使语言模型为新任务做好准备，是让模型快速上手新任务的有效策略。</p> 
<p>        大模型幻觉：LLM 在训练时虽然使用了大量的数据，但模型并不能完全记住所有的信息，因此会出现错误推断，甚至编造出似是而非的答案，这是在使用过程中需要注意的问题。在提问过程中可以将问题分解，使模型自己可以做中间的推断，更好的得到答案。</p> 
<p></p> 
<h2>Temperature</h2> 
<p>        LLM模型的输出是根据预测的概率产生输出结果，具有随机性。在使用GPT模型时，可使用Temperature 超参数控制采样，这样可以调节生成样本的随机性和多样性，取值在0~1。Temperature设置得较高时，可能产生多样化的输出；较低时生成的输出更加确定，但缺乏多样性。 通常降低 Temperature 可以增加生成文本的连贯性，而提高它可以增加生成文本的变化性和创造性。 </p> 
<p>        根据不同场景可使用不同的 Temperature 的值。例如搭建知识助手，可将其设置为0，这样可保证输出更稳定；而对智能客服则应该设置较高的值，因为此时需要模型输出具有一定创造力。</p> 
<h2>System Prompt</h2> 
<p>        System Prompt 是 ChatGPT API 为客户提供的一种 Prompt 策略。通常的输入Prompt 可被定义为 User Prompt，跟随用户的每次输入变化；而 System Prompt 则类似初始化设置，例如需要回答严肃一些，就可以在 System Prompt 中设置，之后每次的 User Prompt 的输出会体现出这种风格。</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0d35588236823da4290439d8e2b7d165/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【LLM】0x00 大模型简介</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/822e8a29212cce893a429d8f112b96f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何从 iCloud 恢复永久删除的照片？答案在这里！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>