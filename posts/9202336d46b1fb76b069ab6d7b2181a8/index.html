<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习】音乐表示Music Representation - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【机器学习】音乐表示Music Representation" />
<meta property="og:description" content="音乐基本术语 velocity (i.e. bar or body speed)A tempo is how fast the beats go by in a particular piece of music.quality：音程性质 音乐符号化表示（Symbolic） 最基本的音乐信息（Events）：在何时起止（Onset、Offset）什么绝对音高（MIDI pitch）。元信息：该音乐数据的名称是什么，包含什么声部、使用什么音色播放。基本音乐学信息：基本的如小节线、速度、拍号、调式等，以及进一步的信息如表情记号（连线、跳音、延长音、重音、强弱）、反复、临时升降号等。高层音乐学信息：乐句、和弦、分段、情绪。 因为最基础的MIDI文件只需要起止（Onset、Offset）、绝对音高（MIDI pitch）就可以播放了（音色之类的都可以设为默认如钢琴），因此才会造成数据如此杂乱。MusicXML格式就好得多，因为其是一个面向乐谱显示或排版的格式，包含基本音乐学信息是其基础。
MIDI（Musical Instrument Digital Interface） Channel通道：是指定的0~15的一个值，因为MIDI文件给我们提供了默认的16个通道，每一个通道可以对应一种乐器，相当于midi支持一首歌曲里同时使用16种乐器进行演奏Track音轨：音轨与通道并不是一一对应，而是可以多对多的关系。音轨是逻辑上的划分，比如可以将钢琴的左手演奏放在track 1，右手演奏放在track 2。但是输出时候，都是对应输出到钢琴的通道。你也可以只设置一个track 1，并且在里面记录着不同通道的消息。另外，还经常将track 0用来存储midi的作者、版权、音轨名、乐器名等元信息Event事件：事件也叫做消息(在mido库中使用message表示)。包括三种事件 meta event元消息，midi event主消息， sysex event系统消息。元消息上文有提及是作者，版权，音乐名等信息的存在track0中，系统消息是存储midi系统不同版本的信息，主要需要留意的就是midi消息。 midi有多种信息类型： MIDI Events Piano-Roll MusicXML MusicXML文件分为两种类型：score-partwise与score-timewise，其中较为常见的是score-partwise。
score-partwise 谱子信息，XML文件信息 各声部信息 声部1全曲： 小节1： 属性 音符1 音符2 …… REMI（revamped MIDI-derived events） 基于节拍事件（Beat-based）
REMI用时值取代MIDI编码里的音符关(Note off)，用小节（Bar）和位置（Position）取代MIDI编码里的时移，并且增加了音乐速度与和弦信息。REMI编码将音乐编码成按照小节、位置、和弦、音乐速度、音高、时值、力度依次排列的离散token序列
The Bar, Position and Tempo-related events entail the use of audio domain downbeat and beat tracking algorithms 相比MIDI-like，REMI的异同：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9202336d46b1fb76b069ab6d7b2181a8/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-03-29T18:24:58+08:00" />
<meta property="article:modified_time" content="2023-03-29T18:24:58+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习】音乐表示Music Representation</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2><span style="color:#be191c;"><strong>音乐基本术语</strong></span></h2> 
<ul><li>velocity (i.e. bar or body speed)</li><li><em><em>A</em> </em><strong><em><em>tempo</em></em></strong><em> <em>is</em> <em>how</em> <em>fast</em> <em>the</em> <em>beats</em> <em>go</em> <em>by</em> <em>in</em> <em>a</em> <em>particular</em> <em>piece</em> <em>of</em> </em><strong><em><em>music</em></em></strong><em>.</em></li><li>quality：音程性质</li></ul> 
<p></p> 
<h2 id="音乐的符号化表示"><span style="color:#be191c;"><strong>音乐符号化表示（Symbolic）</strong></span> </h2> 
<ul><li>最基本的音乐信息（Events）：在何时起止（Onset、Offset）什么绝对音高（MIDI pitch）。</li><li>元信息：该音乐数据的名称是什么，包含什么声部、使用什么音色播放。</li><li>基本音乐学信息：基本的如小节线、速度、拍号、调式等，以及进一步的信息如表情记号（连线、跳音、延长音、重音、强弱）、反复、临时升降号等。</li><li>高层音乐学信息：乐句、和弦、分段、情绪。</li></ul> 
<p>因为最基础的MIDI文件只需要起止（Onset、Offset）、绝对音高（MIDI pitch）就可以播放了（音色之类的都可以设为默认如钢琴），因此才会造成数据如此杂乱。MusicXML格式就好得多，因为其是一个面向乐谱显示或排版的格式，包含基本音乐学信息是其基础。</p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>MIDI（Musical Instrument Digital Interface）</strong></span></h3> 
<ul><li><strong>Channel通道：</strong>是指定的0~15的一个值，因为MIDI文件给我们提供了默认的16个通道，每一个通道可以对应一种乐器，相当于<strong>midi支持一首歌曲里同时使用16种乐器进行演奏</strong></li><li><strong>Track音轨：</strong>音轨与通道并不是一一对应，而是可以多对多的关系。音轨是逻辑上的划分，比如可以将钢琴的左手演奏放在track 1，右手演奏放在track 2。但是输出时候，都是对应输出到钢琴的通道。你也可以只设置一个track 1，并且在里面记录着不同通道的消息。另外，还经常将track 0用来存储midi的作者、版权、音轨名、乐器名等元信息</li><li><strong>Event事件：</strong>事件也叫做<strong>消息</strong>(在mido库中使用message表示)。包括三种事件 <strong>meta event元消息，midi event主消息， sysex event系统消息</strong>。元消息上文有提及是作者，版权，音乐名等信息的存在track0中，系统消息是存储midi系统不同版本的信息，主要需要留意的就是midi消息。 midi有多种信息类型：</li></ul> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" height="452" src="https://images2.imgbox.com/61/f6/StKJAGrw_o.png" width="308"> 
  <figcaption>
    MIDI Events 
  </figcaption> 
 </figure> 
</div> 
<p></p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>Piano-Roll</strong></span></h3> 
<p><img alt="" height="277" src="https://images2.imgbox.com/98/39/YEftO8fi_o.png" width="629"></p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>MusicXML</strong></span></h3> 
<p>MusicXML文件分为两种类型：score-partwise与score-timewise，其中较为常见的是score-partwise。</p> 
<h4>score-partwise</h4> 
<pre><code>谱子信息，XML文件信息  
各声部信息
声部1全曲：
    小节1：
            属性
        音符1
        音符2
        ……</code></pre> 
<p></p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>REMI（revamped MIDI-derived events）</strong></span></h3> 
<p><span style="color:#1a439c;"><strong>基于节拍事件（Beat-based）</strong></span></p> 
<p>REMI用时值取代MIDI编码里的音符关(Note off)，用小节（Bar）和位置（Position）取代MIDI编码里的时移，并且增加了音乐速度与和弦信息。REMI编码将音乐编码成按照小节、位置、和弦、音乐速度、音高、时值、力度依次排列的离散token序列</p> 
<div class="img-center"> 
 <figure class="image"> 
  <img alt="" height="201" src="https://images2.imgbox.com/5a/22/G0FlZIRD_o.png" width="474"> 
  <figcaption>
    The Bar, Position and Tempo-related events entail the use of 
   <strong>audio domain downbeat and beat tracking algorithms</strong> 
  </figcaption> 
 </figure> 
</div> 
<p>相比MIDI-like，REMI的异同：</p> 
<ul><li><span style="color:#511b78;"><strong><code>Note-On</code> 和 <code>Note Velocity</code></strong></span></li></ul> 
<p><code>Note-On</code>事件表示某一特定音高的音的开始事件，<code>Node Velocity</code>则表示响度。这两种事件在Midi-like和REMI表示中都存在。</p> 
<ul><li><span style="color:#511b78;"><strong><code>Note-Off</code> 和 <code>Note-Duration</code></strong></span></li></ul> 
<p>在REMI中，使用<code>Note-Duration</code>取代了<code>Note-off</code>，将一个音符用三个连续的token表示：<code>Note Velocity</code>，<code>Note-On</code>，<code>Note-Duration。 </code>这样做主要有两个原因：</p> 
<ol><li>MIDI-like表示中，必须通过开始结束之间的gap推断时值，通过专门的时值事件表示更为清晰直接</li><li>MIDI-like表示中的开始事件与结束事件往往中间间隔若干其他事件，这使得成对出现关系的学习存在困难</li></ol> 
<ul><li><span style="color:#511b78;"><strong><code>Time-Shift</code> 和 <code>Position &amp; Bar</code></strong></span></li></ul> 
<p>以固定时值出现的<strong>位置&amp;小节（Position &amp; Bar）</strong>事件取代原先伴随音符的<strong>时间偏移（Time-Shift）</strong>事件，能够在音乐数据表示中加入度量结构，避免基于<code>Time-Shift</code>的模型中时间错误累积的问题。Position&amp;Bar更多优点：</p> 
<ul><li>（1）更容易学习不同小节中同一位置的音符的相关关系</li><li>（2）便于添加小节级别的约束关系</li><li>（3）在多音轨/多乐器音乐创作中，以位置&amp;小节表示作为时间参照，便于协调多个不同声部</li></ul> 
<ul><li><span style="color:#511b78;"><strong><code>Tempo</code></strong></span></li></ul> 
<p>用于考虑速度变化（比如常见的beats per minute; BPM）。这类事件在MIDI乐谱中不一定存在，但是在MIDI演奏数据中可以通过对音频进行乐曲速度估计得到。</p> 
<ul><li><span style="color:#511b78;"><strong><code>Chord</code></strong></span></li></ul> 
<p>按根音和类型定义的共60种和弦被作为额外的支持符号（supportive token）输入给模型。</p> 
<p class="img-center"><img alt="" height="281" src="https://images2.imgbox.com/7c/dd/2i14xSpa_o.png" width="450"></p> 
<h4>节拍(beat)追踪与强拍(downbeat)追踪</h4> 
<p>为了获取<strong><code>Bar</code>事件</strong>位置，本文使用RNN从音频中估计得到强拍（downbeat）位置，并用线性插值的方法得到节拍位置。这样的表示方式可以得到更规则的时间（节奏）序列。</p> 
<h4>和弦识别</h4> 
<p>使用基于规则的启发式方法进行符号域和弦识别。遍历片段中的每个音作为可能的和弦根音，并通过与其他音的音程关系计算似然得分，最终得到和弦估计。</p> 
<p><img alt="" height="158" src="https://images2.imgbox.com/a6/a6/um3uSX0e_o.png" width="472"></p> 
<p></p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>Compound Word Representation（CP）</strong></span></h3> 
<p>为了进一步缩减REMI编码的序列长度，CP提出将REMI编码的离散token序列转化为以复合词为时间单位的token序列</p> 
<h4><img alt="" height="329" src="https://images2.imgbox.com/b8/74/rftzCs7h_o.png" width="303"><img alt="" height="207" src="https://images2.imgbox.com/c8/41/IbSETMTV_o.png" width="376"></h4> 
<h4><span style="color:#511b78;"><strong>Corpus2Event</strong></span></h4> 
<pre><code class="language-python"># ---- define event ---- #
''' 8 kinds:
     tempo: 0:   IGN (ignore)    
            1:   no change
            int: tempo
     chord: 0:   IGN
            1:   no change
            str: chord types
  bar-beat: 0:   IGN     
            int: beat position (1...16)
            int: bar (bar)
      type: 0:   eos    
            1:   metrical
            2:   note
  duration: 0:   IGN
            int: length
     pitch: 0:   IGN
            int: pitch
  velocity: 0:   IGN    
            int: velocity
'''

# event template
compound_event = {
    'tempo': 0, 
    'chord': 0,
    'bar-beat': 0, 
    'type': 0,
    'pitch': 0,
    'duration': 0,
    'velocity': 0,
}


# event生成的过程 process : 每一个bar,中的每一个tick
final_sequence = []
for bar_step in range(0, global_end, BAR_RESOL):
    final_sequence.append(create_bar_event())

    # --- piano track --- #
    for timing in range(bar_step, bar_step + BAR_RESOL, TICK_RESOL):
        pos_on = False
        pos_events = []
        pos_text = 'Beat_' + str((timing-bar_step)//TICK_RESOL)

        ...metrical (tempo+chord)
        ...for note in notes
        ...

    if len(pos_events):
        final_sequence.extend(pos_events)
    
# BAR ending
final_sequence.append(create_bar_event())   

# EOS
final_sequence.append(create_eos_event())  </code></pre> 
<h4><span style="color:#511b78;"><strong>event2word</strong></span></h4> 
<pre><code class="language-python"># --- build dictionary --- #
# all files
class_keys = pickle.load(
    open(os.path.join(path_indir, eventfiles[0]), 'rb'))[0].keys()
print('class keys:', class_keys)

# define dictionary 
event2word = {}
word2event = {} 

corpus_kv = collections.defaultdict(list)
for file in eventfiles:
    for event in pickle.load(open(
        os.path.join(path_indir, file), 'rb')):
        for key in class_keys:
            corpus_kv[key].append(event[key])

for ckey in class_keys:
    class_unique_vals = sorted(
        set(corpus_kv[ckey]), key=lambda x: (not isinstance(x, int), x))
    event2word[ckey] = {key: i for i, key in enumerate(class_unique_vals)}
    word2event[ckey] = {i: key for i, key in enumerate(class_unique_vals)}</code></pre> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>OctupleMIDI</strong></span></h3> 
<p>Multi-track MIDI 编码方式被提出用于对<strong>多个音轨同时编码</strong>，具有对和声建模的优势。为了进一步缩短编码长度，并提供足够丰富的音乐信息，OctupleMIDI编码将每个音符编码成一个包含拍号、音乐速度、小节、位置、乐器、音高、时值、力度这8个元素的元组。<strong>更短的序列长度可以使模型一次性处理更长的音乐片段，从而提升模型的建模能力。</strong>用在MusicBERT中。</p> 
<p class="img-center"><img alt="" height="322" src="https://images2.imgbox.com/e7/91/0h7QO1op_o.png" width="643"></p> 
<p></p> 
<p></p> 
<p></p> 
<h2><span style="color:#be191c;"><strong>Python音乐表示库</strong></span></h2> 
<h3><span style="color:#1a439c;"><strong>Music21库</strong></span></h3> 
<p><code>music21</code>可以处理包括<strong>MusicXML，MIDI，abc</strong>等多种格式的音乐文件，并可以从零开始构建音乐文件或对音乐进行分析。它读取midi文件时，<strong>输出是一个个音符object</strong>，甚至如果多个音符同时按响，输出就是一个<strong>和弦object</strong>。而不是一个动作。</p> 
<pre><code class="language-python">import music21  
mid = music21.converter.parse("twinkle-twinkle-little-star.mid") # 读取midi文件 
for note in mid[0].flat.notes:  # 所有的音符
    print(note,  note.duration.type,   note.offset)   # 音符， 时长， 位置

#输出
&gt;&gt;&gt; &lt;music21.note.Note C&gt; quarter 0.0
&gt;&gt;&gt; &lt;music21.chord.Chord E3 C3&gt; half 0.0
&gt;&gt;&gt; &lt;music21.note.Note C&gt; quarter 1.0
&gt;&gt;&gt; &lt;music21.note.Note G&gt; quarter 2.0
&gt;&gt;&gt; &lt;music21.chord.Chord C4 C3&gt; half 2.0
&gt;&gt;&gt; &lt;music21.note.Note G&gt; quarter 3.0</code></pre> 
<h4><span style="color:#511b78;"><strong>音符</strong></span></h4> 
<pre><code class="language-python">f = note.Note("F5#")  #创建一个音高为F5#的音符
f.name  #音符的音名
f.step  #音符的音级（不包含变化音及八度信息的音名，这里成为音级严格来说并不准确）
f.pitch.pitchClassString  #音级（以C为0级的音程数）
f.octave  #八度
f.pitch  #音符的音高，返回一个音高对象
f.duration  #音符的时值，返回一个时值对象
f.duration.type  #音符的时值的类型 'quarter','half'

f.pitch.midi

#改变属性
f.duration.dots  #改变符点数量
f.duration.quarterLength  #直接改变时值，以四分音符计
f.pitch.accidental  #变化音的类型</code></pre> 
<h4><strong><span style="color:#511b78;">和弦</span></strong></h4> 
<pre><code class="language-python">cMajor = chord.Chord(["E3","C4","G4"])  #初始化和弦
cMajor.add(note.Note("E3"))  #添加和弦
cMajor.duration.quarterLength=2  #和弦也可以修改时值</code></pre> 
<h4><span style="color:#511b78;"><strong>Stream</strong></span></h4> 
<p>类似list的基本单位，它可以储存任意music21对象及其组合。</p> 
<pre><code class="language-python">stream1 = stream.Stream()  #创建
stream1.append(f)
stream1.insert(0,f)
stream1.repeatAppend(f, 4)  #重复添加

stream1.show('text')  #显示</code></pre> 
<h4>小节 (Measure)</h4> 
<p></p> 
<h4>乐谱Score</h4> 
<p></p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>MusPy库</strong></span></h3> 
<p><a class="has-card" href="https://salu133445.github.io/muspy/" rel="nofollow" title="MusPy documentation — MusPy documentation (salu133445.github.io)"><span class="link-card-box"><span class="link-title">MusPy documentation — MusPy documentation (salu133445.github.io)</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/de/c7/vmmERPGv_o.png">https://salu133445.github.io/muspy/</span></span></a></p> 
<ul><li>数据集准备，可以对接PyTorch和TensorFlow。</li><li>数据的读取和预处理，支持了常见格式，有这和其他库合作的接口。支持数种常见表示。</li><li>模型的评估算法和工具，包括音频渲染、乐谱可视化、pianoroll可视化，以及指标计算。</li></ul> 
<h4>允许的四种表示方式</h4> 
<p><img alt="" height="228" src="https://images2.imgbox.com/be/ca/J48PQ5oi_o.png" width="1200"></p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>Musicaiz库（2022）</strong></span></h3> 
<p><a class="has-card" href="https://carlosholivan.github.io/musicaiz/index.html" rel="nofollow" title="MusicAIz — Musicaiz 0.0.2 documentation"><span class="link-card-box"><span class="link-title">MusicAIz — Musicaiz 0.0.2 documentation</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/b5/83/2KHjGUZY_o.png">https://carlosholivan.github.io/musicaiz/index.html</span></span></a></p> 
<p>支持提供了音乐生成客观评价指标</p> 
<p></p> 
<p></p> 
<h2><span style="color:#be191c;"><strong>Python工具包</strong></span></h2> 
<h3><strong><span style="color:#1a439c;">Miditoolkit</span></strong></h3> 
<pre><code class="language-python">import miditoolkit
midi_obj = miditoolkit.midi.parser.MidiFile(path_midi)
print(midi_obj)

"""
Output:

ticks per beat: 480
max tick: 72002
tempo changes: 68
time sig: 2
key sig: 0
markers: 71
lyrics: False
instruments: 2

"""</code></pre> 
<h4>Tempo and Beat Resolution</h4> 
<p><img alt="" height="107" src="https://images2.imgbox.com/b9/4f/3Yku02S4_o.png" width="486"></p> 
<p><strong>Timing in MIDI files</strong> is centered around ticks and beats. A beat is the same as a quarter note. <strong>Beats are divided into ticks</strong>, the smallest unit of time in MIDI.</p> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>Madmom</strong></span></h3> 
<p><a class="has-card" href="https://madmom.readthedocs.io/en/latest/introduction.html" rel="nofollow" title="Introduction — madmom 0.17.dev0 documentation"><span class="link-card-box"><span class="link-title">Introduction — madmom 0.17.dev0 documentation</span><span class="link-link"><img alt="" class="link-link-icon" src="https://images2.imgbox.com/95/4e/Xgn9eUm2_o.png">https://madmom.readthedocs.io/en/latest/introduction.html</span></span></a></p> 
<ul><li>madmom 是一个音频信号处理库，主要用于音乐信号提取（MIR）</li><li>提取特征和使用它的HMM包来提取beat和downbeat（即音乐节拍和强拍）并计算多种评价指标得分</li></ul> 
<pre><code class="language-python">from madmom.audio.signal import SignalProcessor, FramedSignalProcessor
from madmom.audio.stft import ShortTimeFourierTransformProcessor
from madmom.audio.spectrogram import (
            FilteredSpectrogramProcessor, LogarithmicSpectrogramProcessor,
            SpectrogramDifferenceProcessor)
from madmom.processors import ParallelProcessor, Processor, SequentialProcessor</code></pre> 
<p>多线程提取频谱特征以及频谱的一阶差分</p> 
<pre><code class="language-python">def madmom_feature(wav):
    sig = SignalProcessor(num_channels=1, sample_rate=44100)
    multi = ParallelProcessor([])
    frame_sizes = [1024, 2048, 4096]
    num_bands = [3, 6, 12]

    for frame_size, num_bands in zip(frame_sizes, num_bands):
        frames = FramedSignalProcessor(frame_size=frame_size, fps=100)
        stft = ShortTimeFourierTransformProcessor()  # caching FFT window
        filt = FilteredSpectrogramProcessor(
            num_bands=num_bands, fmin=30, fmax=17000, norm_filters=True)
        spec = LogarithmicSpectrogramProcessor(mul=1, add=1)
        diff = SpectrogramDifferenceProcessor(
            diff_ratio=0.5, positive_diffs=True, stack_diffs=np.hstack)

        # process each frame size with spec and diff sequentially
        multi.append(SequentialProcessor((frames, stft, filt, spec, diff)))

    # stack the features and processes everything sequentially
    pre_processor = SequentialProcessor((sig, multi, np.hstack))
    feature = pre_processor.process( wav)
    return feature</code></pre> 
<p>用madmom自带的HMM模块处理beat和downbeat联合检测算法生成的激活值</p> 
<pre><code class="language-python">from madmom.features.downbeats import DBNDownBeatTrackingProcessor as DownBproc
hmm_proc = DownBproc(beats_per_bar = [3,4], num_tempi = 80, 
          transition_lambda = 180, 
          observation_lambda = 21, 
          threshold = 0.5, fps = 100)
#act是用神经网络等音频节拍检测算法处理得到的激活值
beat_fuser_est = hmm_proc(act)
beat_pred = beat_fuser_est[:,0]
downbeat_pred = beat_pred[beat_fuser_est[:,1]==1]</code></pre> 
<p>对节拍检测结果和节拍标注值计算多种评估指标：</p> 
<pre><code class="language-python">from madmom.evaluation.beats import BeatEvaluation
scr = BeatEvaluation(beat_pred,beat_true)
print(scr.fmeasure,scr.pscore,scr.cemgil,scr.cmlc,scr.cmlt,
                      scr.amlc,scr.amlt)</code></pre> 
<p></p> 
<h3><span style="color:#1a439c;"><strong>liborsa</strong></span></h3> 
<blockquote> 
 <ul><li>librosa.beat:用于检测速度和节拍</li><li>librosa.core:用于从磁盘加载音频和计算各种频谱图</li><li>librosa.decompose:实现矩阵分解进行谐波和冲击源分离通用频谱图分解</li><li>librosa.display:音频特征的显示</li><li>librosa.effects:时域音频处理，音高变换和时间拉伸，时域包装器。</li><li>librosa.feature:特征提取和操作：色度图，伪常数Q（对数频率）变换，Mel频谱图，MFCC和调谐估计</li><li>librosa.filters:滤波器生成色度。伪CQT、CQT等</li><li>librosa.onset:其实检测和起始强度计算。</li><li>librosa.segment:用于结构分段的函数</li><li>librosa.swquence:顺序建模功能</li><li>librosa.util:辅助工具（规范化。填充、居中）</li></ul> 
</blockquote> 
<p></p> 
<p></p> 
<p></p> 
<h2><span style="color:#be191c;"><strong>References</strong></span></h2> 
<p><a href="https://zhuanlan.zhihu.com/p/543411221" rel="nofollow" title="Pop Music Transformer：基于节拍事件表示的流行钢琴作品的建模与生成 - 知乎">Pop Music Transformer：基于节拍事件表示的流行钢琴作品的建模与生成 - 知乎</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/555557792" rel="nofollow" title="AI之歌，旋律动人 - 知乎">AI之歌，旋律动人 - 知乎</a></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/e8d9f9c1e20f630d901c84d9a7c49318/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">GPU使用问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/accd58f857447cd9ce8138f5e280d3c5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">数据库:Redis数据库</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>