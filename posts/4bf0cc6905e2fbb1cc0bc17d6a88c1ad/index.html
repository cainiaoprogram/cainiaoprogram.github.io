<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>三步完成ChatGLM3-6B在英特尔CPU上的INT4量化和部署 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="三步完成ChatGLM3-6B在英特尔CPU上的INT4量化和部署" />
<meta property="og:description" content="作者: 英特尔边缘计算创新大使 刘力
1.1 ChatGLM3-6B简介 ChatGLM3 是智谱AI和清华大学 KEG 实验室联合发布的新一代对话预训练模型。ChatGLM3-6B 是 ChatGLM3 系列中的开源模型，在填写问卷进行登记后亦允许免费商业使用。
引用自：https://github.com/THUDM/ChatGLM3
请使用命令，将ChatGLM3-6B模型下载到本地：
git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git 1.2 BigDL-LLM简介 BigDL-LLM是开源，遵循Apache 2.0许可证，专门用于在英特尔的硬件平台上加速大语言模型（Large Language Model, LLM）推理计算的软件工具包。它是在原有的BigDL框架基础上，为了应对大语言模型在推理过程中对性能和资源的高要求而设计的。BigDL-LLM旨在通过优化和硬件加速技术来提高大语言模型的运行效率，减少推理延迟，并降低资源消耗。
BigDL-LLM的主要特点包括：
1.低精度优化：通过支持INT4/INT5/INT8等低精度格式，减少模型的大小和推理时的计算量，同时保持较高的推理精度。
2.硬件加速：利用英特尔CPU集成的硬件加速技术，如AVX（Advanced Vector Extensions）、VNNI（Vector Neural Network Instructions）和AMX（Advanced Matrix Extensions）等，来加速模型的推理计算。
3.使用方便：对于基于Hugging Face Transformers API的模型，只需修改少量代码即可实现加速，使得开发者可以轻松地在其现有模型上应用BigDL-LLM。
4.性能提升：BigDL-LLM可以显著提高大语言模型在英特尔平台上的运行速度，减少推理时间，特别是在处理大规模模型和复杂任务时。
5.资源友好：通过优化模型运行时的资源使用，BigDL-LLM使得大语言模型可以在资源受限的环境中也能高效运行，如普通的笔记本电脑或服务器。
1.3 使用BigDL-LLM量化并部署ChatGLM3-6B 1.3.1 第一步，创建虚拟环境 请安装Anaconda，然后用下面的命令创建名为llm的虚拟环境
conda create -n llm python=3.9 conda activate llm 1.3.2 第二步，安装BigDL-LLM 执行命令：
​pip install --pre --upgrade bigdl-llm[all] -i Simple Index ​ 1.3.3 第三步：运行范例程序 范例程序下载地址：https://gitee.com/Pauntech/chat-glm3/blob/master/chatglm3_infer.py
import time from bigdl." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4bf0cc6905e2fbb1cc0bc17d6a88c1ad/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-09T15:58:00+08:00" />
<meta property="article:modified_time" content="2024-01-09T15:58:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">三步完成ChatGLM3-6B在英特尔CPU上的INT4量化和部署</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="margin-left:0;text-align:justify;">作者: 英特尔边缘计算创新大使  刘力</p> 
<h2>1.1 <a name="_Toc931"> ChatGLM3-6B</a>简介</h2> 
<p style="margin-left:0;text-align:justify;"><span style="background-color:#FFFFFF;"><span style="color:#1f2328;">ChatGLM3 </span></span><span style="background-color:#FFFFFF;"><span style="color:#1f2328;">是智谱AI和清华大学 KEG 实验室联合发布的新一代对话预训练模型。<strong>ChatGLM3-6B</strong> 是 ChatGLM3 系列中的<strong>开源模型</strong>，在填写</span></span><a href="https://open.bigmodel.cn/mla/form" rel="nofollow" title="问卷">问卷</a><span style="background-color:#FFFFFF;"><span style="color:#1f2328;">进行登记后<strong>亦允许免费商业使用</strong></span></span>。</p> 
<p class="img-center"><img alt="" height="524" src="https://images2.imgbox.com/2a/a1/sWgpp3GN_o.png" width="610"></p> 
<p style="margin-left:0;text-align:center;">引用自：https://github.com/THUDM/ChatGLM3</p> 
<p style="margin-left:0;text-align:justify;">请使用命令，将ChatGLM3-6B模型下载到本地：</p> 
<pre><code class="language-bash">git clone https://www.modelscope.cn/ZhipuAI/chatglm3-6b.git</code></pre> 
<h2 style="margin-left:0px;text-align:justify;">1.2 <a name="_Toc14467"> BigDL-LLM</a>简介</h2> 
<p></p> 
<p style="margin-left:0;text-align:justify;">BigDL-LLM是开源，遵循Apache 2.0许可证，专门用于在英特尔的硬件平台上加速大语言模型（Large Language Model, LLM）推理计算的软件工具包。它是在原有的BigDL框架基础上，为了应对大语言模型在推理过程中对性能和资源的高要求而设计的。BigDL-LLM旨在通过优化和硬件加速技术来提高大语言模型的运行效率，减少推理延迟，并降低资源消耗。</p> 
<p style="margin-left:0;text-align:justify;">BigDL-LLM的主要特点包括：</p> 
<p style="margin-left:0;text-align:justify;"><strong>1.</strong><strong>低精度优化</strong>：通过支持INT4/INT5/INT8等低精度格式，减少模型的大小和推理时的计算量，同时保持较高的推理精度。</p> 
<p style="margin-left:0;text-align:justify;"><strong>2.</strong><strong>硬件加速</strong>：利用英特尔CPU集成的硬件加速技术，如AVX（Advanced Vector Extensions）、VNNI（Vector Neural Network Instructions）和AMX（Advanced Matrix Extensions）等，来加速模型的推理计算。</p> 
<p style="margin-left:0;text-align:justify;"><strong>3.</strong><strong>使用方便</strong>：对于基于Hugging Face Transformers API的模型，只需修改少量代码即可实现加速，使得开发者可以轻松地在其现有模型上应用BigDL-LLM。</p> 
<p style="margin-left:0;text-align:justify;"><strong>4.</strong><strong>性能提升</strong>：BigDL-LLM可以显著提高大语言模型在英特尔平台上的运行速度，减少推理时间，特别是在处理大规模模型和复杂任务时。</p> 
<p style="margin-left:0;text-align:justify;"><strong>5.</strong><strong>资源友好</strong>：通过优化模型运行时的资源使用，BigDL-LLM使得大语言模型可以在资源受限的环境中也能高效运行，如普通的笔记本电脑或服务器。</p> 
<h2>1.3 <a name="_Toc26602"> 使用BigDL-LLM</a>量化并部署ChatGLM3-6B</h2> 
<h3 style="text-align:justify;"><a name="_Toc10001">1.3.1 第一步，创建虚拟环境</a></h3> 
<p style="margin-left:0;text-align:justify;">请安装Anaconda，然后用下面的命令创建名为llm的虚拟环境</p> 
<pre><code class="language-bash">conda create -n llm python=3.9

conda activate llm</code></pre> 
<h3>1.3.2 <a name="_Toc6970"> 第二步，安装BigDL-LLM</a></h3> 
<p></p> 
<p style="margin-left:0;text-align:justify;">执行命令：</p> 
<pre><code class="language-bash">​pip install --pre --upgrade bigdl-llm[all] -i Simple Index
​</code></pre> 
<h3>1.3.3 <a name="_Toc7375"> 第三步：运行范例程序</a></h3> 
<p></p> 
<p style="margin-left:0;text-align:justify;">范例程序下载地址：https://gitee.com/Pauntech/chat-glm3/blob/master/chatglm3_infer.py</p> 
<pre><code class="language-python">import time

from bigdl.llm.transformers import AutoModel

from transformers import AutoTokenizer



CHATGLM_V3_PROMPT_FORMAT = "&lt;|user|&gt;\n{prompt}\n&lt;|assistant|&gt;"

# 请指定chatglm3-6b的本地路径

model_path = "d:/chatglm3-6b"

# 载入ChatGLM3-6B模型并实现INT4量化

model = AutoModel.from_pretrained(model_path,

                                  load_in_4bit=True,

                                  trust_remote_code=True)

# 载入tokenizer

tokenizer = AutoTokenizer.from_pretrained(model_path,

                                          trust_remote_code=True)

# 制作ChatGLM3格式提示词    

prompt = CHATGLM_V3_PROMPT_FORMAT.format(prompt="What is Intel?")

# 对提示词编码

input_ids = tokenizer.encode(prompt, return_tensors="pt")

st = time.time()

# 执行推理计算，生成Tokens

output = model.generate(input_ids,max_new_tokens=32)

end = time.time()

# 对生成Tokens解码并显示

output_str = tokenizer.decode(output[0], skip_special_tokens=True)

print(f'Inference time: {end-st} s')

print('-'*20, 'Prompt', '-'*20)

print(prompt)

print('-'*20, 'Output', '-'*20)

print(output_str)</code></pre> 
<p style="margin-left:0;text-align:justify;">运行结果，如下所示：</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="328" src="https://images2.imgbox.com/64/af/cQJRJ31V_o.png" width="866"></p> 
<h3>1.3.4 <a name="_Toc25874"> ChatGLM3-6B WebUI demo</a></h3> 
<p></p> 
<p style="margin-left:0;text-align:justify;">请先安装依赖软件包：</p> 
<pre><code class="language-bash">​pip install gradio mdtex2html streamlit -i https://mirrors.aliyun.com/pypi/simple/
​</code></pre> 
<p style="margin-left:0;text-align:justify;">下载范例程序：https://gitee.com/Pauntech/chat-glm3/blob/master/chatglm3_web_demo.py</p> 
<p style="margin-left:0;text-align:justify;">然后运行：</p> 
<pre><code class="language-bash">streamlit run chatglm3_web_demo.py</code></pre> 
<p style="margin-left:0;text-align:justify;">运行结果如下：</p> 
<p style="margin-left:0px;"><img alt="" src="https://images2.imgbox.com/73/68/hrSOiLf8_o.jpg"></p> 
<p style="margin-left:0px;"><a name="_Toc19718"></a><a class="link-info" href="https://pan.baidu.com/s/1ZxoV5_LFXAYzG-o40u2q3w?pwd=4uyg%C2%A0" rel="nofollow" title="三步完成ChatGLM3-6B在CPU上的INT4量化和部署视频">三步完成ChatGLM3-6B在CPU上的INT4量化和部署视频</a></p> 
<h2 style="margin-left:0px;text-align:justify;">1.4 <a name="_Toc12216"> 总结</a></h2> 
<p style="margin-left:0;text-align:justify;">BigDL-LLM工具包简单易用，仅需三步即可完成虚拟环境创建、BigDLL-LLM安装以及ChatGLM3-6B模型的INT4量化以及在英特尔CPU上的部署。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;">作者简介：</p> 
<p style="margin-left:0;text-align:justify;">刘力，深圳市铂盛科技有限公司的创始人，英特尔边缘计算创新大使。带领团队成功设计了多种计算机系统，并申请了多项专利和软件著作，铂盛科技为国家高新技术企业，深圳市专精特新企业。铂盛通过整合算力和算法，打造软硬件一体化的AIPC解决方案，目前产品已在工业控制、智能机器人、教育、医疗、金融等多个边缘计算领域得到广泛应用。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;">联系方式</p> 
<p style="margin-left:0;text-align:justify;">电话：13537819699</p> 
<p style="margin-left:0;text-align:justify;">Email：leo.liu@pasuntech.com</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/797f97ba6171691cc8cc46fd0603c86a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Vue3-watch的用法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f5cf061e8fc99124c780a08b6a5454fd/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">MySQL运维实战(3.2) 常见数据库连接失败问题排查</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>