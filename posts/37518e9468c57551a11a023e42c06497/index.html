<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>AIGC论文串烧！从GAN和Diffusion讲起 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="AIGC论文串烧！从GAN和Diffusion讲起" />
<meta property="og:description" content="来源：夕小瑶科技说
刚刚过去的几个月，无疑是生成式AI爆发的奇点。
说到生成式AI，就不得不提到AIGC。AIGC全称为AI-Generated Content，指基于预训练大模型、生成式对抗网络（GAN）等人工智能技术，通过已有数据寻找规律，并通过释放泛化能力生成相关技术的内容。
AIGC 在图像生成中的示例
虽然在文生图领域，扩散模型似乎已经一统天下，但GAN 依然存在不可磨灭的优势。这使得一些研究者在这一方向上持续努力，并取得了非常实用的成果，相关的论文已被 CVPR 2023 接收。
这次我整理了46篇【CVPR 2023的AIGC应用汇总】图像转换、翻译/可控文生图/图像恢复/语义布局可控生成/医学图像/face相关的基于diffusion扩散模型/GAN生成对抗方法论文合集&#43;部分代码，我特地选了6篇具有代表性的文章为大家叙述，希望对在该领域想发论文的同学带来一些新思路！
“
01
GAN的反击！朱俊彦新作GigaGAN，出图速度秒杀Stable Diffusion
题目：
最近，文字-图像生成技术的成功已经席卷全球，激发了大众的想象力。从技术的角度来看，它也标志着设计生成图像模型所青睐的架构的巨大变化。GANs曾经是事实上的选择，有StyleGAN这样的优秀技术。随着DALL·e2的出现，自回归和扩散模型似乎一夜之间成为大规模生成模型的新标准。
CycleGAN 的主要作者、曾获 2018 年 ACM SIGGRAPH 最佳博士论文奖的朱俊彦是这篇 CVPR 论文的第二作者。
该研究首先使用 StyleGAN2 进行实验，并观察到简单地扩展主干网络会导致训练不稳定。基于此，研究者确定了几个关键问题，并提出了一种在增加模型容量的同时稳定训练的技术。
“
02
基于示例的图像转换的屏蔽和自适应变压器
题目：
该论文提出了一个基于样本的图像转换新方法。用于此任务的先进方法主要集中在建立跨域语义对应上，但跨域语义匹配具有挑战性，匹配错误最终会降低生成图像的质量。
为了克服这一挑战，该论文提出了一种掩码和自适应变换器 (MAT)，用于学习准确的跨域对应关系，并执行上下文感知特征增强。为了实现后者，使用样本的输入源特征和全局样式代码作为补充信息来解码图像。
此外，设计了一种新的对比风格学习方法，用于获取质量区分风格表示，这反过来有利于高质量图像的生成。实验结果表明在各种图像转换任务中表现更好。
“
03
具有列行纠缠像素合成的高效尺度不变生成器
题目：
该论文说明任意尺寸图像生成（Any-scale image synthesis）提供了一种高效和可扩展的解决方案，可以在任何比例下合成逼真的图像，甚至超过2K分辨率。
这项工作提出了列行耦合的像素生成（Column-Row Entangled Pixel Synthesis，CREPS），一种既高效又具有尺度等变性的新型生成模型，而不使用任何空间卷积或粗到细的设计。在各种数据集上的实验，包括FFHQ、LSUNChurch、MetFaces和Flickr-Scenery，证实了CREPS具有在任意任意分辨率下合成尺度一致图像的能力。
“
04
图像恢复，基于GAN生成对抗/diffusion扩散模型方法
题目：
该论文研究JPEG图像恢复问题，即加密比特流中的比特错误。比特错误会导致解码后的图像内容出现不可预测的色偏和块位移，这些问题无法通过现有的主要依赖于像素域中预定义退化模型的图像恢复方法来解决。该论文提出了一个强健的JPEG解码器，并采用两阶段补偿和对齐框架来恢复受比特流损坏的JPEG图像。
具体而言，JPEG解码器采用了一种具有容错机制的方法来解码受损的JPEG比特流。两阶段框架由自补偿和对齐（SCA）阶段和引导补偿和对齐（GCA）阶段组成。在三个不同比特错误率的基准测试上进行了实验。实验结果和消融研究表明了我们所提出的方法的优越性。
“
05
PosterLayout：内容感知视觉文本演示布局的新基准和方法
题目：
该论文提出了设计序列形成（DSF）方法，以模拟人类设计师的设计过程重新组织布局中的元素，并提出了一种基于CNN-LSTM的条件生成对抗网络（GAN）来生成适当的布局。具体来说，鉴别器是设计序列感知的，将监督生成器的“设计”过程。
实验结果验证了新基准的有用性和所提出方法的有效性，该方法通过为不同的画布生成适当的布局实现了最佳性能。
“
06
使用人脑活动的潜在扩散模型进行高分辨率图像重建
题目：
本文提出一种基于扩散模型（DM）的新方法，通过功能性磁共振成像（functional magnetic resonance imaging，fMRI）从人脑活动来重构出图像。通过研究LDM的不同组成部分（例如图像的潜在向量Z、条件输入C以及去噪U-Net的不同元素）与不同的脑功能之间的关系，表征了LDM的内部机制。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/37518e9468c57551a11a023e42c06497/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-06-26T20:14:47+08:00" />
<meta property="article:modified_time" content="2023-06-26T20:14:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">AIGC论文串烧！从GAN和Diffusion讲起</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/ad/a5/KWFIuiHU_o.png" alt="5a9f8bbe7391ddecf1242e914be7a1dd.png"></p> 
 <p><strong>来源：夕小瑶科技说</strong></p> 
 <p>刚刚过去的几个月，无疑是生成式AI爆发的奇点。</p> 
 <p>说到生成式AI，就不得不提到AIGC。AIGC全称为AI-Generated Content，指基于预训练大模型、生成式对抗网络（GAN）等人工智能技术，通过已有数据寻找规律，并通过释放泛化能力生成相关技术的内容。</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/a1/d2/WkwUwrJl_o.jpg" alt="f8c2d9891a967a17650a5517650eddd7.jpeg"></p> 
 <p style="text-align:center;">AIGC 在图像生成中的示例</p> 
 <p>虽然在文生图领域，扩散模型似乎已经一统天下，但GAN 依然存在不可磨灭的优势。这使得一些研究者在这一方向上持续努力，并取得了非常实用的成果，相关的论文已被 CVPR 2023 接收。</p> 
 <p>这次我整理了46篇【CVPR 2023的AIGC应用汇总】图像转换、翻译/可控文生图/图像恢复/语义布局可控生成/医学图像/face相关的基于diffusion扩散模型/GAN生成对抗方法论文合集+部分代码，我特地选了6篇具有代表性的文章为大家叙述，希望对在该领域想发论文的同学带来一些新思路！</p> 
 <p>“</p> 
 <p><strong>01<br></strong></p> 
 <p><strong><strong>GAN的反击！朱俊彦新作GigaGAN，出图速度秒杀Stable Diffusion</strong></strong></p> 
 <p><strong>题目：</strong><br></p> 
 <p><img src="https://images2.imgbox.com/ed/08/U43hGIgV_o.png" alt="cf8731f7bc87738d3d33665fb80667d9.png"></p> 
 <p><img src="https://images2.imgbox.com/f1/18/9Sg1ThWd_o.jpg" alt="ee14cc2d8b857ca5226d040f89ef7803.jpeg"></p> 
 <p>最近，文字-图像生成技术的成功已经席卷全球，激发了大众的想象力。从技术的角度来看，它也标志着设计生成图像模型所青睐的架构的巨大变化。GANs曾经是事实上的选择，有StyleGAN这样的优秀技术。随着DALL·e2的出现，自回归和扩散模型似乎一夜之间成为大规模生成模型的新标准。</p> 
 <p>CycleGAN 的主要作者、曾获 2018 年 ACM SIGGRAPH 最佳博士论文奖的朱俊彦是这篇 CVPR 论文的第二作者。</p> 
 <p>该研究首先使用 StyleGAN2 进行实验，并观察到简单地扩展主干网络会导致训练不稳定。基于此，研究者确定了几个关键问题，并提出了一种在增加模型容量的同时稳定训练的技术。</p> 
 <p>“</p> 
 <p><strong>02<br></strong></p> 
 <p><strong><strong>基于示例的图像转换的屏蔽和自适应变压器</strong></strong><strong><br></strong></p> 
 <p><strong>题目：</strong><br></p> 
 <p><img src="https://images2.imgbox.com/ed/8a/20SAOrEh_o.png" alt="525297f80f40b07542c0f213265d912d.png"></p> 
 <p><img src="https://images2.imgbox.com/4d/88/GowqtDrc_o.jpg" alt="1c45362c15f5b06e2cea4157d82b49a8.jpeg"></p> 
 <p>该论文提出了一个基于样本的图像转换新方法。用于此任务的先进方法主要集中在建立跨域语义对应上，但跨域语义匹配具有挑战性，匹配错误最终会降低生成图像的质量。<br></p> 
 <p>为了克服这一挑战，该论文提出了一种掩码和自适应变换器 (MAT)，用于学习准确的跨域对应关系，并执行上下文感知特征增强。为了实现后者，使用样本的输入源特征和全局样式代码作为补充信息来解码图像。</p> 
 <p>此外，设计了一种新的对比风格学习方法，用于获取质量区分风格表示，这反过来有利于高质量图像的生成。实验结果表明在各种图像转换任务中表现更好。</p> 
 <p>“</p> 
 <p><strong>03<br></strong></p> 
 <p><strong><strong>具有列行纠缠像素合成的高效尺度不变生成器</strong></strong></p> 
 <p><strong>题目：</strong><br></p> 
 <p><img src="https://images2.imgbox.com/0f/6d/LJ4YgtM5_o.png" alt="a41ae559b2b23a7aec8f919661ce68fe.png"></p> 
 <p><img src="https://images2.imgbox.com/da/87/9T0QcPIV_o.jpg" alt="6cdba13368a2965479389991896c1a65.jpeg"></p> 
 <p>该论文说明任意尺寸图像生成（Any-scale image synthesis）提供了一种高效和可扩展的解决方案，可以在任何比例下合成逼真的图像，甚至超过2K分辨率。</p> 
 <p>这项工作提出了列行耦合的像素生成（Column-Row Entangled Pixel Synthesis，CREPS），一种既高效又具有尺度等变性的新型生成模型，而不使用任何空间卷积或粗到细的设计。在各种数据集上的实验，包括FFHQ、LSUNChurch、MetFaces和Flickr-Scenery，证实了CREPS具有在任意任意分辨率下合成尺度一致图像的能力。</p> 
 <p>“</p> 
 <p><strong>04<br></strong></p> 
 <p><strong><strong>图像恢复，基于GAN生成对抗</strong></strong><strong><strong>/diffusion扩散模型方法</strong></strong></p> 
 <p><strong>题目：</strong><br></p> 
 <p><img src="https://images2.imgbox.com/84/65/zSF0MHdD_o.png" alt="92e47aeb75099f53f0a2d79a06379aca.png"></p> 
 <p><img src="https://images2.imgbox.com/b5/f8/VCrcQUdI_o.jpg" alt="32e5e1a66d44ac6a087f0fa139edceba.jpeg"></p> 
 <p>该论文研究JPEG图像恢复问题，即加密比特流中的比特错误。比特错误会导致解码后的图像内容出现不可预测的色偏和块位移，这些问题无法通过现有的主要依赖于像素域中预定义退化模型的图像恢复方法来解决。该论文提出了一个强健的JPEG解码器，并采用两阶段补偿和对齐框架来恢复受比特流损坏的JPEG图像。<br></p> 
 <p>具体而言，JPEG解码器采用了一种具有容错机制的方法来解码受损的JPEG比特流。两阶段框架由自补偿和对齐（SCA）阶段和引导补偿和对齐（GCA）阶段组成。在三个不同比特错误率的基准测试上进行了实验。实验结果和消融研究表明了我们所提出的方法的优越性。</p> 
 <p>“</p> 
 <p><strong>05<br></strong></p> 
 <p><strong><strong>PosterLayout：内容感知视觉</strong></strong><strong><strong>文本演示布局的新基准和方法</strong></strong></p> 
 <p><strong>题目：</strong><br></p> 
 <p><img src="https://images2.imgbox.com/47/5e/iCjLmFsL_o.png" alt="24bce73f349267e300925f1a5aa5e144.png"></p> 
 <p><img src="https://images2.imgbox.com/f8/70/kS4N9udX_o.jpg" alt="afd97e4c8a112b3852fdec74006741c3.jpeg"></p> 
 <p>该论文提出了设计序列形成（DSF）方法，以模拟人类设计师的设计过程重新组织布局中的元素，并提出了一种基于CNN-LSTM的条件生成对抗网络（GAN）来生成适当的布局。具体来说，鉴别器是设计序列感知的，将监督生成器的“设计”过程。<br></p> 
 <p>实验结果验证了新基准的有用性和所提出方法的有效性，该方法通过为不同的画布生成适当的布局实现了最佳性能。</p> 
 <p>“</p> 
 <p><strong>06<br></strong></p> 
 <p><strong><strong>使用人脑活动的潜在扩散模型进行高分辨率图像重建</strong></strong></p> 
 <p><strong>题目：</strong><br></p> 
 <p><img src="https://images2.imgbox.com/cc/e9/29KlZWmz_o.png" alt="7764806aed5748b7d25c5772e81e0579.png"></p> 
 <p><img src="https://images2.imgbox.com/f5/82/7URQu5et_o.jpg" alt="440e2c682d3e20326a00ba1a4d80fb6c.jpeg"></p> 
 <p>本文提出一种基于扩散模型（DM）的新方法，通过功能性磁共振成像（functional magnetic resonance imaging，fMRI）从人脑活动来重构出图像。通过研究LDM的不同组成部分（例如图像的潜在向量Z、条件输入C以及去噪U-Net的不同元素）与不同的脑功能之间的关系，表征了LDM的内部机制。<br></p> 
 <p>方法可以在简单的方式下重构具有高保真度的高分辨率图像，而不需要任何额外的训练和精调复杂的深度学习模型。还提供了从神经科学角度对不同LDM组件的定量解释。总体而言，研究提出了一种重构人类脑活动中图像的有前途的方法，并为理解DM提供了新的框架。</p> 
 <p>未来智能实验室的主要工作包括：建立AI智能系统智商评测体系，开展世界人工智能智商评测；开展互联网（城市）大脑研究计划，构建互联网（城市）大脑技术和企业图谱，为提升企业，行业与城市的智能水平服务。每日推荐范围未来科技发展趋势的学习型文章。目前线上平台已收藏上千篇精华前沿科技文章和报告。<br></p> 
 <p>  如果您对实验室的研究感兴趣，欢迎加入未来智能实验室线上平台。扫描以下二维码或点击本文左下角“阅读原文”</p> 
 <p><img src="https://images2.imgbox.com/90/a1/t22N3KYx_o.png" alt="eb6f19fdae66920df24533a251a26818.jpeg"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/14a87fa2117fed14f4b4c0454af0d590/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">STM32CubeMx之硬件SPI驱动W25Q64</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8251fe02bef2f3cea7c90ffa7db8ddbe/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">R语言结构方程模型代码与理解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>