<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>2023年人工智能行业总结 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="2023年人工智能行业总结" />
<meta property="og:description" content="在2023年，人工智能（AI）领域的发展犹如疾风骤雨，令人目不暇接。这一年中，AI领域经历了众多的变革，仿佛将过去十几年的积累在一夜之间彻底释放。今天，我们将通过三条主线来盘点今年AI领域最重要的里程碑，并以此为契机，探索明年AI可能的发展方向。请各位小伙伴们务必点赞关注，以免错过精彩内容。
首先，我们来到了第一条线——语言模型线。简单来说，这是人工智能在聊天方面的应用。去年年底，一款名为ChatGPT的人工智能横空出世，上线短短五天就吸引了100万用户。仅仅两个月后，用户数量便突破了一个亿，创下了史上最快增长纪录。ChatGPT的成功得益于两个技术突破：一是通过人工调教，使其回答人类问题更加自然、不机械；二是发现了大模型的涌现现象。所谓涌现，是指当模型规模较小时并未出现某种能力，但当模型规模达到一定程度后，这种能力突然出现。例如上下文学习能力、思维链能力等。这种现象让大模型的智能水平得到了质的飞跃，仿佛从猴子进化成了人。有时候我也在想，人类意识的起源会不会也是一次进化的涌现呢？
二月Meta发布开源大模型Llama，三月智普发布了开源中文大模型ChatGLM！三月OpenAI发布了GPT4，至今最强模型诞生。三月份百度发布了文心一言，但当时仅能通过内测申请来提供服务。四月阿里发布通义千问模型，五月科大讯飞发布讯飞星火模型。此后，大模型百花齐放，但能力至今都还没有超越GPT4（此处接受反驳）。
九月GPT4V发布，让GPT有了眼睛,可以看图了。而变声模型vits和文本转语音TTS的发展，也让GPT有了耳朵和嘴巴。年底谷歌发布了多模态大模型Gemini，可以理解文字、图片、代码和音视频。大模型从语言开始卷多模态！但还没过年就被爆出Gemini训练数据疑似用了文心一言生成的数据。世界真的像个草台班子啊。
另一条围绕ChatGPT的支线是语言模型的应用生态系统。这条生态线不仅丰富多彩，而且充满了创新和变革。
在今年三月，OpenAI联合向量数据库厂商推出了插件体系，为ChatGPT增加了联网功能和代码解释器。这一创新引发了广泛的关注，使得向量数据库厂商成为了市场的宠儿。同时，也催生出了像langchain这样的语言模型框架，使得语言模型不再仅仅是一个简单的聊天工具。在这个生态系统中，语言模型被赋予了更多的功能。它们可以检索知识库、使用工具，甚至相互协作完成某一任务。这种智能体Agent的概念开始盛行，人们看到了语言模型在未来的巨大潜力。
故事总有但是，但是，在今年11月，OpenAI在开发者大会上宣布了GPT开始内建向量数据库，并内置了向量检索功能。同时，他们还发布了Assistants API，封装了Agent的各项能力。这一系列的举措无疑是对插件服务商的一次重击。好不容易被培养起来的用户，一把就被OpenAI给薅没了。在这个过程中，值得注意的是山姆奥特曼的命运转折。他先是离开了OpenAI，但又很快重新回归。这也反映了当下语言类大模型领域中各个公司和个人的命运起伏。
说完了语言模型线，今年AI发展的第二条主线是绘画线，也就是AI画图。
从AI绘画工具看，依旧是三分天下。Midjourney依旧是简单易用、高画质的代名词，今年从V4升级到了V5，现在马上要出V6，生成的图片也更加稳定自然，对于光影的把控简直令人发指。摄影师看了都直摇头，年初比较火的马斯克在苏联和钢铁侠炸油条系列就是Midjourney的作品。
然后是StableDiffusion以其免费、开源、可定制性的多样玩法，牢牢占据了三分天下有其一的地位。不仅各种插件层出不穷，光是各种Checkpoint和Lora模型都撑起了一个千万市值的C站，赛博朋克风格，二次元萌妹、机甲风、国风、甚至建筑图、Logo制作、头像制作等等等等，不管你喜欢什么画风，只需一个Lora，就能源源不断的生成图片。今年8月份妙鸭相机火出圈，其底层就是一个证件照风格的Lora，可以省下一大笔海马体照相馆的钱。而controlnet则是稳居SD插件榜首。
ControlNet是什么？通俗点来说，如果要画一幅画，一方面是构图，一方面是风格。ControlNet就是用来控制构图的，Checkpoint和LoRA模型就是用来控制风格的。
ControlNet可以控轮廓，控表情、控姿势、控景深，从各种角度控制画面的内容，所以大家要是想从事AI绘画那就必学ControlNet。
而底模方面，SD也从1.5升级到了SDXL，画质得到了巨大提升。
这AI绘画的最后一块版图，就是dalle了，dalle的定位有点尴尬，论画质卷不过midjourney,论可控性卷不过SD. 今年上半年一度已经淡出人们视野了。但随着dalle3的发布，画质又重回第一梯队，而下半年openai更是直接将dalle3的绘画能力集成到了ChatGPT当中,dalle重生了。目前dalle3的定位也是简单易用，而且还有成熟的API体系和语言模型的支持。
AI绘画的三国江湖明年将如何演变，我们拭目以待。但无论哪种工具，目前还都有一个致命的缺陷亟待解决，那就是生成的形象在前后画面中的不一致问题。现在很多商用的AIGC产品都卡在这一关，一旦突破，必将掀起新一轮的应用浪潮。想创业的明年可以重点关注在这条线。现在网上也有很多AI绘画的培训课程，入门版都不贵，大家可以先花小钱看看，确定了自己的方向和爱好之后，再深入研究。最后给想入门AI绘画的新人几个关键词：秋叶大佬、Nenly同学、WebUI、ComfyUI、liblib.ai。
今年AI发展的第三条主线是视频线。在这个领域，AI技术不断创新，为我们带来了诸多惊喜。
年初的so-vits项目成为了关注的焦点，它能够通过几个小时的音频，完美模拟出人的声音特点，实现了让机器模仿音色的目标。这项技术的实际使用在B站爆火的AI孙燕姿上得到了体现。通过对孙燕姿的专辑进行分离和声音提取，经过训练后，AI孙燕姿竟然能够唱周杰伦的歌，而且听起来非常动人。
除了so-vits项目，还有一项令人惊叹的技术是sad talker。它只需要给AI一张图片，经过训练后就能让图片开口说话，甚至还能眨眼。这种技术的出现让人感觉图片中的人物仿佛真的活了一样，今年的小和尚说话就是使用了sad talker技术。
Wav2Lip技术也值得一提。作为Deepfake领域的一把好手，它能够修改视频的唇形，实现生成的视频人物口型与输入语音同步。这种技术让视频中的人物口型与语音更加协调，增加了视频的真实感。
最近很火的叫Heygen的产品将多项技术整合在一起，让人物用自己的声音说出任何你想让他说的话。这款产品的原理是先分离视频中的音频，然后使用so-vits技术学习说话人的音色，接着将任何说话脚本或原文翻译成音频并赋予说话人的口音。最后，通过对口型技术对视频进行修改整合，实现让郭德纲说英语相声的效果。整个过程看起来非常和谐且流畅，让人感觉这段话就是视频中人物说的。
此外，还有一些其他值得关注的技术。例如，Meta开源的Whisper项目能够识别世界上大部分主要语言的视频语音；Roop和FaceFusion两款开源换脸软件不仅能直接给图片和视频换脸，还能将多张图片融合成一张脸；AnimateDiff能够将两张美女跳舞的不同动作图片转换成一段动画，也就是说给出视频关键帧，就可以生成一段视频。
年底时，SD团队发布了SVD模型，这个模型只需要几句描述文字就能让静态画面动起来。这一技术的出现给创意设计带来了更多可能性。
虽然这些技术给人们带来了诸多便利和创新体验，但我对此仍有些担忧。对于我们这些了解这些技术的人来说，真假难辨，更不用说普通人了。AI给了我们一把利剑，但我们也要思考如何防止坏人使用它。
回顾2023年AI领域的发展，我们见证了技术的飞速进步和广泛应用。面对未来，我们期待AI能更好地服务于人类，同时也希望各方共同努力，确保技术的发展与道德伦理相协调，为人类创造更加美好的未来。
2023年人工智能行业总结 - AI魔法学院" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/39283e81ad2c164e0297d37a7eed0345/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-29T18:16:55+08:00" />
<meta property="article:modified_time" content="2023-12-29T18:16:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">2023年人工智能行业总结</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>在2023年，人工智能（AI）领域的发展犹如疾风骤雨，令人目不暇接。这一年中，AI领域经历了众多的变革，仿佛将过去十几年的积累在一夜之间彻底释放。今天，<strong>我们将通过三条主线来盘点今年AI领域最重要的里程碑</strong>，并以此为契机，<strong>探索明年AI可能的发展方向</strong>。请各位小伙伴们务必点赞关注，以免错过精彩内容。</p> 
<p><strong>首先，我们来到了第一条线——语言模型线。简单来说，这是人工智能在聊天方面的应用。</strong>去年年底，一款名为ChatGPT的人工智能横空出世，上线短短五天就吸引了100万用户。仅仅两个月后，用户数量便突破了一个亿，创下了史上最快增长纪录。ChatGPT的成功得益于两个技术突破：一是通过人工调教，使其回答人类问题更加自然、不机械；二是发现了大模型的涌现现象。所谓涌现，是指当模型规模较小时并未出现某种能力，但当模型规模达到一定程度后，这种能力突然出现。例如上下文学习能力、思维链能力等。这种现象让大模型的智能水平得到了质的飞跃，仿佛从猴子进化成了人。有时候我也在想，人类意识的起源会不会也是一次进化的涌现呢？</p> 
<p>二月Meta发布开源大模型Llama，三月智普发布了开源中文大模型ChatGLM！三月OpenAI发布了GPT4，至今最强模型诞生。三月份百度发布了文心一言，但当时仅能通过内测申请来提供服务。四月阿里发布通义千问模型，五月科大讯飞发布讯飞星火模型。此后，大模型百花齐放，但能力至今都还没有超越GPT4（此处接受反驳）。</p> 
<p>九月GPT4V发布，让GPT有了眼睛,可以看图了。而变声模型vits和文本转语音TTS的发展，也让GPT有了耳朵和嘴巴。年底谷歌发布了多模态大模型Gemini，可以理解文字、图片、代码和音视频。大模型从语言开始卷多模态！但还没过年就被爆出Gemini训练数据疑似用了文心一言生成的数据。世界真的像个草台班子啊。</p> 
<p><strong>另一条围绕ChatGPT的支线是语言模型的应用生态系统。这条生态线不仅丰富多彩，而且充满了创新和变革。</strong></p> 
<p>在今年三月，OpenAI联合向量数据库厂商推出了插件体系，为ChatGPT增加了联网功能和代码解释器。这一创新引发了广泛的关注，使得向量数据库厂商成为了市场的宠儿。同时，也催生出了像langchain这样的语言模型框架，使得语言模型不再仅仅是一个简单的聊天工具。在这个生态系统中，语言模型被赋予了更多的功能。它们可以检索知识库、使用工具，甚至相互协作完成某一任务。这种智能体Agent的概念开始盛行，人们看到了语言模型在未来的巨大潜力。</p> 
<p>故事总有但是，但是，在今年11月，OpenAI在开发者大会上宣布了GPT开始内建向量数据库，并内置了向量检索功能。同时，他们还发布了Assistants API，封装了Agent的各项能力。这一系列的举措无疑是对插件服务商的一次重击。好不容易被培养起来的用户，一把就被OpenAI给薅没了。在这个过程中，值得注意的是山姆奥特曼的命运转折。他先是离开了OpenAI，但又很快重新回归。这也反映了当下语言类大模型领域中各个公司和个人的命运起伏。</p> 
<p></p> 
<p><strong>说完了语言模型线，今年AI发展的第二条主线是绘画线，也就是AI画图。</strong></p> 
<p>从AI绘画工具看，依旧是三分天下。Midjourney依旧是简单易用、高画质的代名词，今年从V4升级到了V5，现在马上要出V6，生成的图片也更加稳定自然，对于光影的把控简直令人发指。摄影师看了都直摇头，年初比较火的马斯克在苏联和钢铁侠炸油条系列就是Midjourney的作品。</p> 
<p>然后是StableDiffusion以其免费、开源、可定制性的多样玩法，牢牢占据了三分天下有其一的地位。不仅各种插件层出不穷，光是各种Checkpoint和Lora模型都撑起了一个千万市值的C站，赛博朋克风格，二次元萌妹、机甲风、国风、甚至建筑图、Logo制作、头像制作等等等等，不管你喜欢什么画风，只需一个Lora，就能源源不断的生成图片。今年8月份妙鸭相机火出圈，其底层就是一个证件照风格的Lora，可以省下一大笔海马体照相馆的钱。而controlnet则是稳居SD插件榜首。</p> 
<p>ControlNet是什么？通俗点来说，如果要画一幅画，一方面是构图，一方面是风格。ControlNet就是用来控制构图的，Checkpoint和LoRA模型就是用来控制风格的。</p> 
<p>ControlNet可以控轮廓，控表情、控姿势、控景深，从各种角度控制画面的内容，所以大家要是想从事AI绘画那就必学ControlNet。</p> 
<p>而底模方面，SD也从1.5升级到了SDXL，画质得到了巨大提升。</p> 
<p>这AI绘画的最后一块版图，就是dalle了，dalle的定位有点尴尬，论画质卷不过midjourney,论可控性卷不过SD. 今年上半年一度已经淡出人们视野了。但随着dalle3的发布，画质又重回第一梯队，而下半年openai更是直接将dalle3的绘画能力集成到了ChatGPT当中,dalle重生了。目前dalle3的定位也是简单易用，而且还有成熟的API体系和语言模型的支持。</p> 
<p>AI绘画的三国江湖明年将如何演变，我们拭目以待。但无论哪种工具，目前还都有一个致命的缺陷亟待解决，那就是生成的形象在前后画面中的不一致问题。现在很多商用的AIGC产品都卡在这一关，一旦突破，必将掀起新一轮的应用浪潮。想创业的明年可以重点关注在这条线。现在网上也有很多AI绘画的培训课程，入门版都不贵，大家可以先花小钱看看，确定了自己的方向和爱好之后，再深入研究。<strong>最后给想入门AI绘画的新人几个关键词：秋叶大佬、Nenly同学、WebUI、ComfyUI、liblib.ai。</strong></p> 
<p></p> 
<p><strong>今年AI发展的第三条主线是视频线。在这个领域，AI技术不断创新，为我们带来了诸多惊喜。</strong></p> 
<p>年初的so-vits项目成为了关注的焦点，它能够通过几个小时的音频，完美模拟出人的声音特点，实现了让机器模仿音色的目标。这项技术的实际使用在B站爆火的AI孙燕姿上得到了体现。通过对孙燕姿的专辑进行分离和声音提取，经过训练后，AI孙燕姿竟然能够唱周杰伦的歌，而且听起来非常动人。</p> 
<p>除了so-vits项目，还有一项令人惊叹的技术是sad talker。它只需要给AI一张图片，经过训练后就能让图片开口说话，甚至还能眨眼。这种技术的出现让人感觉图片中的人物仿佛真的活了一样，今年的小和尚说话就是使用了sad talker技术。</p> 
<p>Wav2Lip技术也值得一提。作为Deepfake领域的一把好手，它能够修改视频的唇形，实现生成的视频人物口型与输入语音同步。这种技术让视频中的人物口型与语音更加协调，增加了视频的真实感。</p> 
<p>最近很火的叫Heygen的产品将多项技术整合在一起，让人物用自己的声音说出任何你想让他说的话。这款产品的原理是先分离视频中的音频，然后使用so-vits技术学习说话人的音色，接着将任何说话脚本或原文翻译成音频并赋予说话人的口音。最后，通过对口型技术对视频进行修改整合，实现让郭德纲说英语相声的效果。整个过程看起来非常和谐且流畅，让人感觉这段话就是视频中人物说的。</p> 
<p>此外，还有一些其他值得关注的技术。例如，Meta开源的Whisper项目能够识别世界上大部分主要语言的视频语音；Roop和FaceFusion两款开源换脸软件不仅能直接给图片和视频换脸，还能将多张图片融合成一张脸；AnimateDiff能够将两张美女跳舞的不同动作图片转换成一段动画，也就是说给出视频关键帧，就可以生成一段视频。</p> 
<p>年底时，SD团队发布了SVD模型，这个模型只需要几句描述文字就能让静态画面动起来。这一技术的出现给创意设计带来了更多可能性。</p> 
<p></p> 
<p>虽然这些技术给人们带来了诸多便利和创新体验，但我对此仍有些担忧。对于我们这些了解这些技术的人来说，真假难辨，更不用说普通人了。AI给了我们一把利剑，但我们也要思考如何防止坏人使用它。</p> 
<p><strong>回顾2023年AI领域的发展，我们见证了技术的飞速进步和广泛应用。面对未来，我们期待AI能更好地服务于人类</strong>，同时也希望各方共同努力，确保技术的发展与道德伦理相协调，为人类创造更加美好的未来。</p> 
<p></p> 
<p><a href="https://www.aimaven.vip/article/4773" rel="nofollow" title="2023年人工智能行业总结 - AI魔法学院">2023年人工智能行业总结 - AI魔法学院</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/542c75de7dcfcab1e1fef057a0bbdc6f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Kotlin基础语法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d2e2a80a78ae411a14069d05873ef6f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【计算机图形学】Few-Shot Physically-Aware Articulated Mesh Generation via Hierarchical Deformation</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>