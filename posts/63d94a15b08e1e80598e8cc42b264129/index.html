<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Python 数据获取（一）—— request模块、变量使用与传参方式 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Python 数据获取（一）—— request模块、变量使用与传参方式" />
<meta property="og:description" content="一、 页面渲染 服务端渲染：
服务器端将数据和html整合到一起，统一返回给浏览器页面源代码中能看到数据，直接、简单数据通常没什么格式，需要想办法匹配 客户端渲染：
第一次只请求一个html骨架，随着输入操作等在后续请求获取数据，进行展示页面源代码不能看到数据，需要第二次请求，需要抓包分析数据通常是json或者固定格式的，处理方便 所以本质上，两种渲染方式对爬取各有优劣。
二、 headers处理 这个headers指的是html的头信息，这部分信息是给浏览器看的。打开一个网页，例如x瓣电影。按 F12抓包，刷新一下页面，这个headers部分就是了。
我们下面就要用到这个User-Agent，它表示这个请求来自哪里，图中蓝框表示来自浏览器。很多网页最基础的一个反爬方法就是判断你的User-Agent是什么，如果来自程序，就拦截不给返回。
例如我们来请求一下上面的页面。
import requests url=&#34;https://movie.douban.com/top250&#34; resp = requests.get(url=url) print(resp.text) 返回结果为空，说明请求被拦截了
这里我们先看看代码的请求头是什么样的？
import requests url=&#34;https://movie.douban.com/top250&#34; resp = requests.get(url=url) # resp.request表示发出的请求，再.headers表示这个请求的headers信息 print(resp.request.headers) 很明显这是个python程序
我们来修改headers，假装自己是浏览器（一个简单的小反爬）
import requests url=&#34;https://movie.douban.com/top250&#34; # 把F12中的User-Agent信息拷过来，改成字典格式 headers = {&#34;User-Agent&#34;:&#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36&#34;} # 把字典传入headers参数即可 resp = requests.get(url=url,headers=headers) print(resp.request.headers) print(resp.text) 看这次的User-Agent信息
网页返回结果很长，我们简单搜一个电影名，能看到就OK
不少网页都会有这个请求头检测功能，所以headers参数其实也可以作为常规参数加上，避免每次再去处理。
三、使用变量 我们换一个小说网页 https://www.qu-la.com/
假如我要搜一本小说，更好的方式是把书名作为一个变量，例如
https://so.biqusoso.com/s2.php?ie=utf-8&amp;siteid=qu-la.com&amp;q=探虚陵
1. 直接在字符串使用变量 格式是 url = f&#39;xxx网址其他部分xxx{变量名}&#39;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/63d94a15b08e1e80598e8cc42b264129/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-03T22:55:03+08:00" />
<meta property="article:modified_time" content="2022-12-03T22:55:03+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Python 数据获取（一）—— request模块、变量使用与传参方式</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 style="text-align:justify;"><strong>一、 页面渲染</strong></h3> 
<p><strong>服务端渲染：</strong></p> 
<ul><li>服务器端将数据和html整合到一起，统一返回给浏览器</li><li>页面源代码中能看到数据，直接、简单</li><li>数据通常没什么格式，需要想办法匹配</li></ul> 
<p><strong>客户端渲染：</strong></p> 
<ul><li>第一次只请求一个html骨架，随着输入操作等在后续请求获取数据，进行展示</li><li>页面源代码不能看到数据，需要第二次请求，需要抓包分析</li><li>数据通常是json或者固定格式的，处理方便</li></ul> 
<p><span style="color:#4da8ee;">所以本质上，两种渲染方式对爬取各有优劣。</span></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h3 style="text-align:justify;"><strong>二、 headers处理</strong></h3> 
<p style="margin-left:0;text-align:justify;">       这个headers指的是html的头信息，这部分信息是给浏览器看的。打开一个网页，例如x瓣电影。按 F12抓包，刷新一下页面，这个headers部分就是了。</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="695" src="https://images2.imgbox.com/1e/ab/CXzoEv1b_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">       我们下面就要用到这个User-Agent，它表示这个请求来自哪里，图中蓝框表示来自浏览器。很多网页最基础的一个反爬方法就是判断你的User-Agent是什么，如果来自程序，就拦截不给返回。</p> 
<p style="margin-left:0;text-align:justify;">    例如我们来请求一下上面的页面。</p> 
<pre><code class="language-python">import requests

url="https://movie.douban.com/top250"
resp = requests.get(url=url)
print(resp.text)</code></pre> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="454" src="https://images2.imgbox.com/da/37/FM4EONyR_o.png" width="974"></p> 
<p style="margin-left:0;text-align:justify;">返回结果为空，说明请求被拦截了</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;">这里我们先看看代码的请求头是什么样的？</p> 
<pre><code class="language-python">import requests

url="https://movie.douban.com/top250"
resp = requests.get(url=url)
# resp.request表示发出的请求，再.headers表示这个请求的headers信息
print(resp.request.headers)</code></pre> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="594" src="https://images2.imgbox.com/b1/11/GtRIUzpZ_o.png" width="1088"></p> 
<p style="margin-left:0;text-align:justify;">很明显这是个python程序</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><strong>我们来修改headers，假装自己是浏览器</strong>（一个简单的小反爬）</p> 
<pre><code class="language-python">import requests

url="https://movie.douban.com/top250"
# 把F12中的User-Agent信息拷过来，改成字典格式
headers = {"User-Agent":"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.5005.63 Safari/537.36"}

# 把字典传入headers参数即可
resp = requests.get(url=url,headers=headers)
print(resp.request.headers)
print(resp.text)</code></pre> 
<p style="margin-left:0;text-align:justify;">看这次的User-Agent信息</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="175" src="https://images2.imgbox.com/a8/21/Uod4JfOf_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">网页返回结果很长，我们简单搜一个电影名，能看到就OK</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="216" src="https://images2.imgbox.com/fb/94/ZelnLAZK_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">       不少网页都会有这个请求头检测功能，所以headers参数其实也可以作为常规参数加上，避免每次再去处理。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h3 style="margin-left:0px;text-align:justify;"><strong>三、使用变量</strong></h3> 
<p style="margin-left:0;text-align:justify;">我们换一个小说网页 https://www.qu-la.com/</p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#4da8ee;">假如我要搜一本小说，更好的方式是把书名作为一个变量</span>，例如</p> 
<p style="margin-left:0;text-align:left;">https://so.biqusoso.com/s2.php?ie=utf-8&amp;siteid=qu-la.com&amp;q=<span style="color:#4da8ee;">探虚陵</span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="425" src="https://images2.imgbox.com/fc/72/bFqf1FkV_o.png" width="1163"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="text-align:justify;"><strong>1. 直接在字符串使用变量</strong></h4> 
<p style="margin-left:0;text-align:justify;">格式是 url = <span style="color:#ff0000;">f'</span>xxx网址其他部分xxx<span style="color:#ff0000;">{<!-- --></span><span style="color:#ff0000;">变量名}'</span></p> 
<pre><code class="language-python">import requests  # 导入requests包

book = "探虚陵"
url = f'https://so.biqusoso.com/s2.php?ie=utf-8&amp;siteid=qu-la.com&amp;q={book}'
response = requests.get(url)  # Get方式获取网页数据
print(response.request.url)
# 最后记得关掉response
response.close()</code></pre> 
<p style="margin-left:0;text-align:justify;">那串乱码不用管它，从网页直接复制中文也会变成这样，点击可以访问的</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="124" src="https://images2.imgbox.com/40/29/4Ngfi0ky_o.png" width="943"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="text-align:justify;"><strong>2. 查看入参</strong></h4> 
<p style="margin-left:0;text-align:justify;">F12 还可以查看输入的参数，注意?后面的都是入参（黄色部分）</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="643" src="https://images2.imgbox.com/63/8b/E375aAD3_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">https://so.biqusoso.com/s2.php<span style="background-color:#ffff00;">?ie=utf-8&amp;siteid=qu-la.com&amp;q=</span><span style="background-color:#ffff00;">探虚陵</span></p> 
<p style="margin-left:0;text-align:justify;">所以可以看到，这个网页一共有3个参数</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><strong>3. get请求传参</strong></h4> 
<p style="margin-left:0;text-align:justify;">对于搜索框输入的、网页url里直接写的，基本上都是get格式的。如果要确认的话可以抓包查看。</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="689" src="https://images2.imgbox.com/d1/70/TPdHn8zv_o.png" width="670"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><strong>get请求的传参方法是：</strong></p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#fe2c24;">将Query String Parameters部分的参数全部复制出来，组一个字典，然后通过get方法的params参数传进去。</span></p> 
<p style="margin-left:0;text-align:justify;">book = "探虚陵"<br> myParams = {<!-- --><br> "ie": "utf-8",<br> "siteid": "qu-la.com",<br> "q": book<br> }</p> 
<p style="margin-left:0;text-align:justify;">代码如下</p> 
<pre><code class="language-python">import requests  # 导入requests包

book = "探虚陵"

# 获取到的参数
myParams = {
"ie": "utf-8",
"siteid": "qu-la.com",
"q": book
}

#url，只要问号前面部分
url = 'https://so.biqusoso.com/s2.php'

# Get方式获取网页数据，params传参
response = requests.get(url=url,params=myParams)
# 查看拼出来的链接结果
print(response.request.url)

# 最后记得关掉response
response.close()</code></pre> 
<p style="margin-left:0;text-align:justify;">输出结果是一样的</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="118" src="https://images2.imgbox.com/c4/47/XERZW9KO_o.png" width="920"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<h4 style="margin-left:0px;text-align:justify;"><strong>4. post请求传参</strong></h4> 
<p style="margin-left:0;text-align:justify;">post请求通常传一些机密性比较高的内容。这个案例稍微复杂一点，主要复杂在抓包的部分，这次用百度翻译的网页做例子</p> 
<p style="margin-left:0px;text-align:left;"><span style="color:#4da8ee;">F12打开抓包工具，刷新，在我们什么都没输的时候有3个页面。</span>选all的话页面会太多，数据相关的主要在Fetch/XHR部分，所以直接点到这部分。</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="536" src="https://images2.imgbox.com/1b/80/KmdqvNVX_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">输入一个dog（注意要用英文输入法，否则新的页面不会出来）</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="747" src="https://images2.imgbox.com/6d/f7/pl79WTqo_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">新增了好多页面，怎么找哪一个有dog的翻译数据？</p> 
<p style="margin-left:0;text-align:justify;">       <span style="color:#4da8ee;">逐个点点新增的页面，选中preview，看看页面效果。</span>你会发现有一个sug的内容跟下拉框是一样的，这就是我们要找的数据。</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="591" src="https://images2.imgbox.com/17/bd/ketmMeqO_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">如果打开源码看看，你会发现没有搜索出来的“狗”这个关键字</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="506" src="https://images2.imgbox.com/eb/b8/pfpEmzz5_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#fe2c24;">       其实这就是前面提到的客户端渲染的网页。它的源码中只有一个框架，数据是在第二次请求的时候传入的（输入dog，才新传入sug中的数据）。</span></p> 
<p style="margin-left:0;text-align:justify;">       点headers，可以看到这是个post类型的请求，并且真正的url是https://fanyi.baidu.com/sug</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="275" src="https://images2.imgbox.com/7f/31/QL3yPLml_o.png" width="907"></p> 
<p style="margin-left:0;text-align:justify;">它的入参也在Payload页面，就一个 kw:dog</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="252" src="https://images2.imgbox.com/ab/b3/qcK7yzgZ_o.png" width="859"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#fe2c24;">这样我们需要的关键元素就齐活了：</span></p> 
<ul><li style="text-align:justify;"><span style="color:#fe2c24;">url链接：<a href="https://fanyi.baidu.com/sug" rel="nofollow" title="https://fanyi.baidu.com/sug">https://fanyi.baidu.com/sug</a></span></li><li style="text-align:justify;"><span style="color:#fe2c24;">请求类型：post</span></li><li style="text-align:justify;"><span style="color:#fe2c24;">入参：kw:dog</span></li></ul> 
<pre><code class="language-python">import requests 

# 待查单词
word = 'dog'
# 入参字典
myParams = {
"kw": word
}

url = 'https://fanyi.baidu.com/sug'

# Get方式获取网页数据，params传参
response = requests.post(url=url,params=myParams)
# 查看返回数据
print(response.json())
response.close()</code></pre> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="144" src="https://images2.imgbox.com/c9/16/BGiII9MD_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;"><strong>代码跟之前get其实没太大区别，主要是两点：</strong></p> 
<ol><li style="text-align:justify;">get方法变成了<span style="color:#fe2c24;">post方法</span></li><li style="text-align:left;">返回的数据直接是<span style="color:#fe2c24;">json格式</span>（还记得我们之前提到过，客户端渲染虽然抓包麻烦一点，但返回的数据通常都是格式化的，处理更方便）</li></ol> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="text-align:justify;"><strong>5. 一个常用案例——传参翻页</strong></p> 
<p style="margin-left:0;text-align:justify;">上面的功能其实还不太常用，最常用的可以处理翻页问题，来看这个网页，随便找一本小说 <a href="https://m.gdedu.tv/dir/73358/?page=2&amp;sort=asc" rel="nofollow" title="https://m.gdedu.tv/dir/73358/?page=2&amp;sort=asc">https://m.gdedu.tv/dir/73358/?page=2&amp;sort=asc</a></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="664" src="https://images2.imgbox.com/af/d2/cm6dAnzO_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">改一下代码，循环page参数（这个页数比较简单，可以直接看出来的）</p> 
<pre><code class="language-python">import requests 

#url，只要问号前面部分
url = 'https://m.gdedu.tv/dir/73358/'

for i in range(1,5):
    # 获取到的参数
    myParams = {
    "page": i,
    "sort": "arc"
    }

    # Get方式获取网页数据，params传参
    response = requests.get(url,params=myParams)
    # 查看拼出来的链接结果
    print(response.request.url)
    # 最后记得关掉response
    response.close()</code></pre> 
<p style="margin-left:0;text-align:justify;">查看拼出来的链接</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="276" src="https://images2.imgbox.com/96/59/bGsa3xNX_o.png" width="796"></p> 
<p>都是可以打开的 https://m.gdedu.tv/dir/73358/?page=1&amp;sort=arc</p> 
<p></p> 
<h3><strong>四、 遗留问题</strong></h3> 
<p style="margin-left:0;text-align:justify;">1. 随便点进去一个链接，里面还有很多具体章节，<span style="color:#4da8ee;">怎么爬取具体章节信息？</span></p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="785" src="https://images2.imgbox.com/44/45/E9Q8bBpp_o.png" width="1161"></p> 
<p style="margin-left:0;text-align:justify;">       这里先简单提一下，点击查看源码，你会看到每个标题都是一个超链接，后面我们会学习怎么提取这些超链接和章节名。</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="748" src="https://images2.imgbox.com/84/d5/paLcWsvb_o.png" width="903"></p> 
<p style="margin-left:0;text-align:justify;">再随便打开一章，你会发现每章里面也是有分页的</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="221" src="https://images2.imgbox.com/f8/f6/iW1d5uFz_o.png" width="712"></p> 
<p style="margin-left:0;text-align:justify;">再用F12获取下对应的参数，找啊找，发现没有对应的page参数。很明显这个页数就在链接里了。</p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;"><span style="color:#4da8ee;">2. 这种情况要怎么判断每章有多少页，下页链接是什么呢？</span></p> 
<p style="margin-left:0;text-align:justify;">其实同理，这个“下一章”也有自己对应的链接</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="922" src="https://images2.imgbox.com/82/18/J3cgfDwT_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;">      查看源码，搜729776，这玩意在JavaScript标签里。但是没关系，只要你会匹配上面的超链接，你自然就会匹配下面这个，具体我们以后再看~</p> 
<p style="margin-left:0;text-align:justify;"><img alt="" height="524" src="https://images2.imgbox.com/b9/1f/V3GQxGS1_o.png" width="1200"></p> 
<p style="margin-left:0;text-align:justify;"></p> 
<p style="margin-left:0;text-align:justify;">参考：B站课程 P1-P16</p> 
<p style="margin-left:0;text-align:justify;"><a href="https://www.bilibili.com/video/BV1i54y1h75W?p=12&amp;vd_source=6837e4916355e0432ae00a719911412d" rel="nofollow" title="2021年最新Python爬虫教程+实战项目案例（最新录制）_哔哩哔哩_bilibili">2021年最新Python爬虫教程+实战项目案例（最新录制）_哔哩哔哩_bilibili</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1d4bfb1ab7705faa1c8e3c538a8295b7/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">4-5:关注，取消关注</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/76ca3c614aabd42c7f4e36b71e66e545/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">tinymce富文本编辑器的使用</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>