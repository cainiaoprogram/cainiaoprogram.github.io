<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>数据降维与可视化——t-SNE - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="数据降维与可视化——t-SNE" />
<meta property="og:description" content="声明：
manifold：可以称之为流形数据。像绳结一样的数据，虽然在高维空间中可分，但是在人眼所看到的低维空间中，绳结中的绳子是互相重叠的不可分的。参考sklearn官方文档对数据降维比较熟悉的朋友可以看这篇博客 t-SNE实践——sklearn教程 数据降维与可视化——t-SNE t-SNE是目前来说效果最好的数据降维与可视化方法，但是它的缺点也很明显，比如：占内存大，运行时间长。但是，当我们想要对高维数据进行分类，又不清楚这个数据集有没有很好的可分性（即同类之间间隔小，异类之间间隔大），可以通过t-SNE投影到2维或者3维的空间中观察一下。如果在低维空间中具有可分性，则数据是可分的；如果在高维空间中不具有可分性，可能是数据不可分，也可能仅仅是因为不能投影到低维空间。 下面会简单介绍t-SNE的原理，参数和实例。
t-distributed Stochastic Neighbor Embedding(t-SNE) t-SNE（TSNE）将数据点之间的相似度转换为概率。原始空间中的相似度由高斯联合概率表示，嵌入空间的相似度由“学生t分布”表示。
虽然Isomap，LLE和variants等数据降维和可视化方法，更适合展开单个连续的低维的manifold。但如果要准确的可视化样本间的相似度关系，如对于下图所示的S曲线（不同颜色的图像表示不同类别的数据），t-SNE表现更好。因为t-SNE主要是关注数据的局部结构。 通过原始空间和嵌入空间的联合概率的Kullback-Leibler（KL）散度来评估可视化效果的好坏，也就是说用有关KL散度的函数作为loss函数，然后通过梯度下降最小化loss函数，最终获得收敛结果。注意，该loss不是凸函数，即具有不同初始值的多次运行将收敛于KL散度函数的局部最小值中，以致获得不同的结果。因此，尝试不同的随机数种子(Python中可以通过设置seed来获得不同的随机分布)有时候是有用的，并选择具有最低KL散度值的结果。 使用t-SNE的缺点大概是：
t-SNE的计算复杂度很高，在数百万个样本数据集中可能需要几个小时，而PCA可以在几秒钟或几分钟内完成Barnes-Hut t-SNE方法（下面讲）限于二维或三维嵌入。算法是随机的，具有不同种子的多次实验可以产生不同的结果。虽然选择loss最小的结果就行，但可能需要多次实验以选择超参数。全局结构未明确保留。这个问题可以通过PCA初始化点（使用init =&#39;pca&#39;）来缓解。 优化 t-SNE t-SNE的主要目的是高维数据的可视化。因此，当数据嵌入二维或三维时，效果最好。有时候优化KL散度可能有点棘手。有五个参数可以控制t-SNE的优化，即会影响最后的可视化质量：
perplexity困惑度early exaggeration factor前期放大系数learning rate学习率maximum number of iterations最大迭代次数angle角度 Barnes-Hut t-SNE Barnes-Hut t-SNE主要是对传统t-SNE在速度上做了优化，是现在最流行的t-SNE方法，同时它与传统t-SNE还有一些不同：
Barnes-Hut仅在目标维度为3或更小时才起作用。以2D可视化为主。Barnes-Hut仅适用于密集的输入数据。稀疏数据矩阵只能用特定的方法嵌入，或者可以通过投影近似，例如使用sklearn.decomposition.TruncatedSVDBarnes-Hut是一个近似值。使用angle参数对近似进行控制，因此当参数method=&#34;exact&#34;时，TSNE()使用传统方法，此时angle参数不能使用。Barnes-Hut可以处理更多的数据。 Barnes-Hut可用于嵌入数十万个数据点。 为了可视化的目的（这是t-SNE的主要用处），强烈建议使用Barnes-Hut方法。method=&#34;exact&#34;时，传统的t-SNE方法尽管可以达到该算法的理论极限，效果更好，但受制于计算约束，只能对小数据集的可视化。
对于MNIST来说，t-SNE可视化后可以自然的将字符按标签分开，见本文最后的例程；而PCA降维可视化后的手写字符，不同类别之间会重叠在一起，这也证明了t-SNE的非线性特性的强大之处。值得注意的是：未能在2D中用t-SNE显现良好分离的均匀标记的组不一定意味着数据不能被监督模型正确分类，还可能是因为2维不足以准确地表示数据的内部结构。
注意事项 数据集在所有特征维度上的尺度应该相同 参数说明 parametersdescriptionn_componentsint, 默认为2，嵌入空间的维度（嵌入空间的意思就是结果空间）perplexityfloat, 默认为30，数据集越大，需要参数值越大，建议值位5-50early_exaggerationfloat, 默认为12.0，控制原始空间中的自然集群在嵌入式空间中的紧密程度以及它们之间的空间。 对于较大的值，嵌入式空间中自然群集之间的空间将更大。 再次，这个参数的选择不是很关键。 如果在初始优化期间成本函数增加，则可能是该参数值过高。learning_ratefloat, default:200.0, 学习率，建议取值为10.0-1000.0n_iterint, default:1000, 最大迭代次数n_iter_without_progressint, default:300, 另一种形式的最大迭代次数，必须是50的倍数min_grad_normfloat, default:1e-7, 如果梯度低于该值，则停止算法metricstring or callable, 精确度的计量方式initstring or numpy array, default:”random”, 可以是’random’, ‘pca’或者一个numpy数组(shape=(n_samples, n_components)。verboseint, default:0, 训练过程是否可视random_stateint, RandomState instance or None, default:None，控制随机数的生成methodstring, default:’barnes_hut’, 对于大数据集用默认值，对于小数据集用’exact’anglefloat, default:0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ca4228f6174f495afa5897702da2c389/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-09-30T17:26:56+08:00" />
<meta property="article:modified_time" content="2017-09-30T17:26:56+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">数据降维与可视化——t-SNE</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>声明：</p> 
<ol><li>manifold：可以称之为流形数据。像绳结一样的数据，虽然在高维空间中可分，但是在人眼所看到的低维空间中，绳结中的绳子是互相重叠的不可分的。</li><li>参考<a href="http://scikit-learn.org/stable/modules/manifold.html#manifold" rel="nofollow">sklearn官方文档</a></li><li>对数据降维比较熟悉的朋友可以看这篇博客<a href="https://blog.csdn.net/hustqb/article/details/80628721"> <br> t-SNE实践——sklearn教程</a></li></ol> 
<h2 id="数据降维与可视化t-sne">数据降维与可视化——t-SNE</h2> 
<p>  t-SNE是目前来说效果最好的数据降维与可视化方法，但是它的缺点也很明显，比如：占内存大，运行时间长。但是，当我们想要对高维数据进行分类，又不清楚这个数据集有没有很好的可分性（即同类之间间隔小，异类之间间隔大），可以通过t-SNE投影到2维或者3维的空间中观察一下。如果在低维空间中具有可分性，则数据是可分的；如果在高维空间中不具有可分性，可能是数据不可分，也可能仅仅是因为不能投影到低维空间。 <br>   下面会简单介绍t-SNE的原理，参数和实例。</p> 
<h3 id="t-distributed-stochastic-neighbor-embeddingt-sne">t-distributed Stochastic Neighbor Embedding(t-SNE)</h3> 
<p>  <strong>t-SNE（TSNE）将数据点之间的相似度转换为概率</strong>。原始空间中的相似度由高斯联合概率表示，嵌入空间的相似度由“学生t分布”表示。</p> 
<p>  虽然Isomap，LLE和variants等数据降维和可视化方法，更适合展开单个连续的低维的manifold。但如果要准确的可视化样本间的相似度关系，如对于下图所示的S曲线（不同颜色的图像表示不同类别的数据），t-SNE表现更好。因为<strong>t-SNE主要是关注数据的局部结构</strong>。 <br> </p> 
<center> 
 <img src="https://images2.imgbox.com/04/e1/mRIrfOOJ_o.png" width="25%" height="25%"> 
</center> 
<br>    
<strong>通过原始空间和嵌入空间的联合概率的Kullback-Leibler（KL）散度来评估可视化效果的好坏，也就是说用有关KL散度的函数作为loss函数，然后通过梯度下降最小化loss函数，最终获得收敛结果</strong>。注意，该loss不是凸函数，即具有不同初始值的多次运行将收敛于KL散度函数的局部最小值中，以致获得不同的结果。因此，尝试不同的随机数种子(Python中可以通过设置seed来获得不同的随机分布)有时候是有用的，并选择具有最低KL散度值的结果。 
<p></p> 
<p>  使用t-SNE的缺点大概是：</p> 
<ul><li>t-SNE的计算复杂度很高，在数百万个样本数据集中可能需要几个小时，而PCA可以在几秒钟或几分钟内完成</li><li>Barnes-Hut t-SNE方法（下面讲）限于二维或三维嵌入。</li><li>算法是随机的，具有不同种子的多次实验可以产生不同的结果。虽然选择loss最小的结果就行，但可能需要多次实验以选择超参数。</li><li>全局结构未明确保留。这个问题可以通过PCA初始化点（使用<code>init ='pca'</code>）来缓解。</li></ul> 
<h4 id="优化-t-sne">优化 t-SNE</h4> 
<p>  t-SNE的主要目的是高维数据的可视化。因此，当数据嵌入二维或三维时，效果最好。有时候优化KL散度可能有点棘手。有五个参数可以控制t-SNE的优化，即会影响最后的可视化质量：</p> 
<ul><li>perplexity困惑度</li><li>early exaggeration factor前期放大系数</li><li>learning rate学习率</li><li>maximum number of iterations最大迭代次数</li><li>angle角度</li></ul> 
<h4 id="barnes-hut-t-sne">Barnes-Hut t-SNE</h4> 
<p>  Barnes-Hut t-SNE主要是对传统t-SNE在速度上做了优化，是现在最流行的t-SNE方法，同时它与传统t-SNE还有一些不同：</p> 
<ul><li>Barnes-Hut仅在目标维度为3或更小时才起作用。以2D可视化为主。</li><li>Barnes-Hut仅适用于密集的输入数据。稀疏数据矩阵只能用特定的方法嵌入，或者可以通过投影近似，例如使用<a href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html#sklearn.decomposition.TruncatedSVD" rel="nofollow">sklearn.decomposition.TruncatedSVD</a></li><li>Barnes-Hut是一个近似值。使用angle参数对近似进行控制，因此当参数<code>method="exact"</code>时，<code>TSNE()</code>使用传统方法，此时angle参数不能使用。</li><li>Barnes-Hut可以处理更多的数据。 Barnes-Hut可用于嵌入数十万个数据点。</li></ul> 
<p>  为了可视化的目的（这是t-SNE的主要用处），强烈建议使用Barnes-Hut方法。<code>method="exact"</code>时，传统的t-SNE方法尽管可以达到该算法的理论极限，效果更好，但受制于计算约束，只能对小数据集的可视化。</p> 
<p>  对于MNIST来说，t-SNE可视化后可以自然的将字符按标签分开，见本文最后的例程；而PCA降维可视化后的手写字符，不同类别之间会重叠在一起，这也证明了t-SNE的非线性特性的强大之处。值得注意的是：未能在2D中用t-SNE显现良好分离的均匀标记的组不一定意味着数据不能被监督模型正确分类，还可能是因为2维不足以准确地表示数据的内部结构。</p> 
<h4 id="注意事项">注意事项</h4> 
<ul><li>数据集在所有特征维度上的尺度应该相同</li></ul> 
<h4 id="参数说明">参数说明</h4> 
<table><thead><tr><th>parameters</th><th>description</th></tr></thead><tbody><tr><td>n_components</td><td>int, 默认为2，嵌入空间的维度（嵌入空间的意思就是结果空间）</td></tr><tr><td>perplexity</td><td>float, 默认为30，数据集越大，需要参数值越大，建议值位5-50</td></tr><tr><td>early_exaggeration</td><td>float, 默认为12.0，控制原始空间中的自然集群在嵌入式空间中的紧密程度以及它们之间的空间。 对于较大的值，嵌入式空间中自然群集之间的空间将更大。 再次，这个参数的选择不是很关键。 如果在初始优化期间成本函数增加，则可能是该参数值过高。</td></tr><tr><td>learning_rate</td><td>float, default:200.0, 学习率，建议取值为10.0-1000.0</td></tr><tr><td>n_iter</td><td>int, default:1000, 最大迭代次数</td></tr><tr><td>n_iter_without_progress</td><td>int, default:300, 另一种形式的最大迭代次数，必须是50的倍数</td></tr><tr><td>min_grad_norm</td><td>float, default:1e-7, 如果梯度低于该值，则停止算法</td></tr><tr><td>metric</td><td>string or callable, 精确度的计量方式</td></tr><tr><td>init</td><td>string or numpy array, default:”random”, 可以是’random’, ‘pca’或者一个numpy数组(shape=(n_samples, n_components)。</td></tr><tr><td>verbose</td><td>int, default:0, 训练过程是否可视</td></tr><tr><td>random_state</td><td>int, RandomState instance or None, default:None，控制随机数的生成</td></tr><tr><td>method</td><td>string, default:’barnes_hut’, 对于大数据集用默认值，对于小数据集用’exact’</td></tr><tr><td>angle</td><td>float, default:0.5, 只有<code>method='barnes_hut'</code>时可用</td></tr></tbody></table> 
<hr> 
<table><thead><tr><th>attributes</th><th>description</th></tr></thead><tbody><tr><td>embedding_</td><td>嵌入向量</td></tr><tr><td>kl_divergence</td><td>最后的KL散度</td></tr><tr><td>n_iter_</td><td>迭代的次数</td></tr></tbody></table> 
<hr> 
<table><thead><tr><th>Methods</th><th>description</th></tr></thead><tbody><tr><td>fit</td><td>将X投影到一个嵌入空间</td></tr><tr><td>fit_transform</td><td>将X投影到一个嵌入空间并返回转换结果</td></tr><tr><td>get_params</td><td>获取t-SNE的参数</td></tr><tr><td>set_params</td><td>设置t-SNE的参数</td></tr></tbody></table> 
<h4 id="实例">实例</h4> 
<h5 id="hello-world">Hello World</h5> 
<p>一个简单的例子，输入4个3维的数据，然后通过t-SNE降维称2维的数据。</p> 
<pre class="prettyprint"><code class="language-Python hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> sklearn.manifold <span class="hljs-keyword">import</span> TSNE
X = np.array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])
tsne = TSNE(n_components=<span class="hljs-number">2</span>)
tsne.fit_transform(X)
print(tsne.embedding_)
<span class="hljs-string">'''输出
[[   3.17274952 -186.43092346]
 [  43.70787048 -283.6920166 ]
 [ 100.43157196 -145.89025879]
 [ 140.96669006 -243.15138245]]'''</span></code></pre> 
<h5 id="s曲线的降维与可视化">S曲线的降维与可视化</h5> 
<p>S曲线上的数据是高维的数据，其中不同颜色表示数据的不同类别。当我们通过t-SNE嵌入到二维空间中后，可以看到数据点之间的类别信息完美的保留了下来</p> 
<pre class="prettyprint"><code class="language-Python hljs python"><span class="hljs-comment"># coding='utf-8'</span>
<span class="hljs-string">"""# 一个对S曲线数据集上进行各种降维的说明。"""</span>
<span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> time

<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">from</span> mpl_toolkits.mplot3d <span class="hljs-keyword">import</span> Axes3D
<span class="hljs-keyword">from</span> matplotlib.ticker <span class="hljs-keyword">import</span> NullFormatter

<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> manifold, datasets

<span class="hljs-comment"># # Next line to silence pyflakes. This import is needed.</span>
<span class="hljs-comment"># Axes3D</span>

n_points = <span class="hljs-number">1000</span>
<span class="hljs-comment"># X是一个(1000, 3)的2维数据，color是一个(1000,)的1维数据</span>
X, color = datasets.samples_generator.make_s_curve(n_points, random_state=<span class="hljs-number">0</span>)
n_neighbors = <span class="hljs-number">10</span>
n_components = <span class="hljs-number">2</span>

fig = plt.figure(figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">8</span>))
<span class="hljs-comment"># 创建了一个figure，标题为"Manifold Learning with 1000 points, 10 neighbors"</span>
plt.suptitle(<span class="hljs-string">"Manifold Learning with %i points, %i neighbors"</span>
             % (<span class="hljs-number">1000</span>, n_neighbors), fontsize=<span class="hljs-number">14</span>)


<span class="hljs-string">'''绘制S曲线的3D图像'''</span>
ax = fig.add_subplot(<span class="hljs-number">211</span>, projection=<span class="hljs-string">'3d'</span>)
ax.scatter(X[:, <span class="hljs-number">0</span>], X[:, <span class="hljs-number">1</span>], X[:, <span class="hljs-number">2</span>], c=color, cmap=plt.cm.Spectral)
ax.view_init(<span class="hljs-number">4</span>, -<span class="hljs-number">72</span>)  <span class="hljs-comment"># 初始化视角</span>

<span class="hljs-string">'''t-SNE'''</span>
t0 = time()
tsne = manifold.TSNE(n_components=n_components, init=<span class="hljs-string">'pca'</span>, random_state=<span class="hljs-number">0</span>)
Y = tsne.fit_transform(X)  <span class="hljs-comment"># 转换后的输出</span>
t1 = time()
print(<span class="hljs-string">"t-SNE: %.2g sec"</span> % (t1 - t0))  <span class="hljs-comment"># 算法用时</span>
ax = fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)
plt.scatter(Y[:, <span class="hljs-number">0</span>], Y[:, <span class="hljs-number">1</span>], c=color, cmap=plt.cm.Spectral)
plt.title(<span class="hljs-string">"t-SNE (%.2g sec)"</span> % (t1 - t0))
ax.xaxis.set_major_formatter(NullFormatter())  <span class="hljs-comment"># 设置标签显示格式为空</span>
ax.yaxis.set_major_formatter(NullFormatter())
<span class="hljs-comment"># plt.axis('tight')</span>

plt.show()</code></pre> 
<p></p> 
<center> 
 <img src="https://images2.imgbox.com/45/c5/aurfFchy_o.png" alt="这里写图片描述" title=""> 
</center> 
<p></p> 
<h5 id="手写数字的降维可视化">手写数字的降维可视化</h5> 
<p>这里的手写数字数据集是一堆8*8的数组，每一个数组都代表着一个手写数字。如下图所示。 <br> </p> 
<center> 
 <img src="https://images2.imgbox.com/ab/28/kxKE8ZHY_o.png" alt="这里写图片描述" title=""> 
</center> 
<br> t-SNE将8*8即64维的数据降维成2维，并在平面图中显示，这里只选取了0-5，6个手写数字。 
<p></p> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-comment"># coding='utf-8'</span>
<span class="hljs-string">"""t-SNE对手写数字进行可视化"""</span>
<span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">from</span> sklearn.manifold <span class="hljs-keyword">import</span> TSNE


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_data</span><span class="hljs-params">()</span>:</span>
    digits = datasets.load_digits(n_class=<span class="hljs-number">6</span>)
    data = digits.data
    label = digits.target
    n_samples, n_features = data.shape
    <span class="hljs-keyword">return</span> data, label, n_samples, n_features


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_embedding</span><span class="hljs-params">(data, label, title)</span>:</span>
    x_min, x_max = np.min(data, <span class="hljs-number">0</span>), np.max(data, <span class="hljs-number">0</span>)
    data = (data - x_min) / (x_max - x_min)

    fig = plt.figure()
    ax = plt.subplot(<span class="hljs-number">111</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(data.shape[<span class="hljs-number">0</span>]):
        plt.text(data[i, <span class="hljs-number">0</span>], data[i, <span class="hljs-number">1</span>], str(label[i]),
                 color=plt.cm.Set1(label[i] / <span class="hljs-number">10.</span>),
                 fontdict={<!-- --><span class="hljs-string">'weight'</span>: <span class="hljs-string">'bold'</span>, <span class="hljs-string">'size'</span>: <span class="hljs-number">9</span>})
    plt.xticks([])
    plt.yticks([])
    plt.title(title)
    <span class="hljs-keyword">return</span> fig


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">main</span><span class="hljs-params">()</span>:</span>
    data, label, n_samples, n_features = get_data()
    print(<span class="hljs-string">'Computing t-SNE embedding'</span>)
    tsne = TSNE(n_components=<span class="hljs-number">2</span>, init=<span class="hljs-string">'pca'</span>, random_state=<span class="hljs-number">0</span>)
    t0 = time()
    result = tsne.fit_transform(data)
    fig = plot_embedding(result, label,
                         <span class="hljs-string">'t-SNE embedding of the digits (time %.2fs)'</span>
                         % (time() - t0))
    plt.show(fig)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    main()</code></pre> 
<p></p> 
<center> 
 <img src="https://images2.imgbox.com/f8/39/mB6VfOw4_o.png" alt="这里写图片描述" title=""> 
</center> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1276612690f04048b2de61eae6f8594a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux防火墙开放端口号 及 常用端口号详解</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8852af49b7c8ed827c065610c95f2ba3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Apache JMeter常用函数</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>