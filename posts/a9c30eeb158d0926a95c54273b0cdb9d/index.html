<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Tensorflow实现cifar10识别 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Tensorflow实现cifar10识别" />
<meta property="og:description" content="首先要准备的是cifa10数据集，下载地址：http://www.cs.toronto.edu/~kriz/cifar.html下载binary版。cifar-10分类数据集为60000张32 * 32的彩色图片，总共有10个类别，其中50000张训练集，10000张测试集。
之后从https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10下载cifar10.py和cifar10_input.py。将这两个文件放在工程目录下即可。
载入需要的库 import tensorflow as tf import numpy as np import cifar10 import cifar10_input import time 2. 初始化权重函数
def variable_with_weight_loss(shape,std,w1): var = tf.Variable(tf.truncated_normal(shape,stddev=std),dtype=tf.float32) #使用tf.truncated_normal截断的正态分布，加上L2的loss，相当于做了一个L2的正则化处理 #w1:控制L2 loss的大小，tf.nn.l2_loss函数计算weight的L2 loss if w1 is not None: weight_loss = tf.multiply(tf.nn.l2_loss(var),w1,name=&#34;weight_loss&#34;) tf.add_to_collection(&#34;losses&#34;,weight_loss)#加入losses列表 return var 3. 计算softmax和loss
def loss_func(logits,labels): labels = tf.cast(labels,tf.int32) cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels,name=&#34;cross_entropy_per_example&#34;) #softmax和cross entropy loss的计算合在一起 cross_entropy_mean = tf.reduce_mean(tf.reduce_sum(cross_entropy)) #计算cross entropy 均值 tf.add_to_collection(&#34;losses&#34;,cross_entropy_mean) #把交叉熵均值加入到losses中 return tf.add_n(tf.get_collection(&#34;losses&#34;),name=&#34;total_loss&#34;) #将整体losses的collection中的全部loss求和，即最终的loss，有cross entropy loss，两个全连接层 中weight的L2 loss 4." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a9c30eeb158d0926a95c54273b0cdb9d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-12-02T19:41:00+08:00" />
<meta property="article:modified_time" content="2018-12-02T19:41:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Tensorflow实现cifar10识别</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-indent:50px;">首先要准备的是cifa10数据集，下载地址：<a href="http://www.cs.toronto.edu/~kriz/cifar.html" rel="nofollow">http://www.cs.toronto.edu/~kriz/cifar.html</a>下载binary版。cifar-10分类数据集为60000张32 * 32的彩色图片，总共有10个类别，其中50000张训练集，10000张测试集。</p> 
<p style="text-indent:50px;">之后从<a href="https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10">https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10</a>下载cifar10.py和cifar10_input.py。将这两个文件放在工程目录下即可。</p> 
<ol><li style="text-indent:0px;">载入需要的库</li></ol> 
<pre class="has"><code class="language-python">import tensorflow as tf
import numpy as np
import cifar10
import cifar10_input
import time</code></pre> 
<p style="text-indent:0px;">    2. 初始化权重函数</p> 
<pre class="has"><code class="language-python">def variable_with_weight_loss(shape,std,w1):
    var = tf.Variable(tf.truncated_normal(shape,stddev=std),dtype=tf.float32)
#使用tf.truncated_normal截断的正态分布，加上L2的loss，相当于做了一个L2的正则化处理
#w1:控制L2 loss的大小，tf.nn.l2_loss函数计算weight的L2 loss
    if w1 is not None:
        weight_loss = tf.multiply(tf.nn.l2_loss(var),w1,name="weight_loss")
        tf.add_to_collection("losses",weight_loss)#加入losses列表
    return var</code></pre> 
<p>   3. 计算softmax和loss</p> 
<pre class="has"><code class="language-python">def loss_func(logits,labels):
    labels = tf.cast(labels,tf.int32)
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,
                           labels=labels,name="cross_entropy_per_example")
    #softmax和cross entropy loss的计算合在一起
    cross_entropy_mean = tf.reduce_mean(tf.reduce_sum(cross_entropy))
    #计算cross entropy 均值
    tf.add_to_collection("losses",cross_entropy_mean)
    #把交叉熵均值加入到losses中
    return tf.add_n(tf.get_collection("losses"),name="total_loss")
    #将整体losses的collection中的全部loss求和，即最终的loss，有cross entropy loss，两个全连接层   中weight的L2 loss</code></pre> 
<p>   4. 定义参数，处理数据，载入数据</p> 
<pre class="has"><code class="language-python">    #设置最大迭代次数
    max_steps = 10000
    #设置每次训练的数据大小
    batch_size = 128
    # 设置数据的存放目录
    cifar10_dir = "C:\\Users\\zlj\\Downloads\\cifar-10-batches-bin"
    #训练集
    #distored_inputs函数产生训练需要使用的数据，包括特征和其对应的label,返回已经封装好的tensor，每次执行都会生成一个batch_size的数量的样本
    images_train,labels_train = cifar10_input.distorted_inputs(cifar10_dir,batch_size)
    #测试集
    images_test,labels_test = cifar10_input.inputs(eval_data=True,data_dir=cifar10_dir
                                                   ,batch_size=batch_size)
    #载入数据
    image_holder = tf.placeholder(dtype=tf.float32,shape=[batch_size,24,24,3])
    #裁剪后尺寸为24×24，彩色图像通道数为3
    label_holder = tf.placeholder(dtype=tf.int32,shape=[batch_size])</code></pre> 
<p>    5. 设计卷积层</p> 
<p>   第一层：</p> 
<pre class="has"><code>    weight1 = variable_with_weight_loss(shape=[5,5,3,64],std=5e-2,w1=0)
    #使用variable_with_weight_loss函数创建卷积核的参数并进行初始化。5×5的卷积和，3个通道，64个滤波器。weight1初始化函数的标准差为0.05，不进行正则wl(weight loss)设为0
    kernel1 = tf.nn.conv2d(image_holder,weight1,[1,1,1,1],padding="SAME")
    #tf.nn.conv2d函数对输入进行卷积
    bais1 = tf.Variable(tf.constant(0.0,dtype=tf.float32,shape=[64]))
    conv1 = tf.nn.relu(tf.nn.bias_add(kernel1,bais1))
    #最大池化层尺寸为3x3,步长为2x2
    pool1 = tf.nn.max_pool(conv1,[1,3,3,1],[1,2,2,1],padding="SAME")
    #LRN层模仿生物神经系统的侧抑制机制
    norm1 = tf.nn.lrn(pool1,4,bias=1.0,alpha=0.001 / 9,beta=0.75)</code></pre> 
<p>   第二层：</p> 
<pre class="has"><code>    weight2 = variable_with_weight_loss(shape=[5,5,64,64],std=5e-2,w1=0)
    #5×5的卷积和，第一个卷积层输出64个通道，64个滤波器
    kernel2 = tf.nn.conv2d(norm1,weight2,[1,1,1,1],padding="SAME")
    bais2 = tf.Variable(tf.constant(0.1,dtype=tf.float32,shape=[64]))
    #初始化为0.1
    conv2 = tf.nn.relu(tf.nn.bias_add(kernel2,bais2))
    norm2 = tf.nn.lrn(conv2,4,bias=1.0,alpha=0.01 / 9,beta=0.75)
    pool2 = tf.nn.max_pool(norm2,[1,3,3,1],[1,2,2,1],padding="SAME")</code></pre> 
<p>     6. 设计全连接层</p> 
<p>     第一层：</p> 
<pre class="has"><code class="language-python">    reshape = tf.reshape(pool2,[batch_size,-1])#将数据变为1D数据
    dim = reshape.get_shape()[1].value#获取维度
    weight3 = variable_with_weight_loss([dim,384],std=0.04,w1=0.004)
    bais3 = tf.Variable(tf.constant(0.1,shape=[384],dtype=tf.float32))
    local3 = tf.nn.relu(tf.matmul(reshape,weight3)+bais3)</code></pre> 
<p>    第二层和第三层：</p> 
<pre class="has"><code>    weight4 = variable_with_weight_loss([384,192],std=0.04,w1=0.004)
    bais4 = tf.Variable(tf.constant(0.1,shape=[192],dtype=tf.float32))
    local4 = tf.nn.relu(tf.matmul(local3,weight4)+bais4)

    weight5 = variable_with_weight_loss([192,10],std=1/192.0,w1=0)
    bais5 = tf.Variable(tf.constant(0.0,shape=[10],dtype=tf.float32))
    logits = tf.add(tf.matmul(local4,weight5),bais5)</code></pre> 
<p>      7.数据准备</p> 
<pre class="has"><code>    #获取损失函数
    loss = loss_func(logits,label_holder)
    #设置优化算法使得成本最小
    train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)
    #获取最高类的分类准确率，取top1作为衡量标准
    top_k_op = tf.nn.in_top_k(logits,label_holder,1)
    #创建会话
    sess = tf.InteractiveSession()
    tf.global_variables_initializer().run()
    #动线程，在图像数据增强队列例使用了16个线程进行加速。
    tf.train.start_queue_runners()</code></pre> 
<p>     8. 训练过程</p> 
<pre class="has"><code class="language-python">for step in range(max_steps):
        start_time = time.time()
        #获得一个batch的训练数据
        images_batch,labels_batch = sess.run([images_train,labels_train])
        #将batch的数据传入train_op和loss的计算
        _,loss_value = sess.run([train_step,loss],feed_dict={image_holder:images_batch,
                                                             label_holder:labels_batch})
        #获取计算时间
        duration = time.time() - start_time
        if step % 1000 == 0:
            #计算每秒处理多少张图片
            per_images_second = batch_size / duration
            #获取计算一个batch需要的时间
            sec_per_batch = float(duration)
            print("step:%d,duration:%.3f,per_images_second:%.2f,loss:%.3f"%(step,duration
                                                                ,per_images_second,loss_value))</code></pre> 
<p>    9.计算准确率</p> 
<pre class="has"><code class="language-python">    num_examples = 10000
    import math
    num_iter = int(math.ceil(num_examples / batch_size))
    true_count = 0
    total_sample_count = num_iter * batch_size
    step = 0
    while step &lt; num_iter:
        images_batch,labels_batch = sess.run([images_test,labels_test])
        pred = sess.run([top_k_op],feed_dict={image_holder:images_batch,label_holder:labels_batch})
        true_count += np.sum(pred)
        step += 1
    #计算测试集的准确率
    precision = true_count / total_sample_count
    print("test accuracy:%.3f"%precision)</code></pre> 
<p>结果如下：</p> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/1d/ac/FLkxYcLm_o.png"></p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/efec81079f6679ce968c2f65e0a6d652/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">如何在pc上安装安卓应用程序</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2d97827a47e17795cf35b37be0fd5a29/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">腾讯公司面试题（大数据岗位）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>