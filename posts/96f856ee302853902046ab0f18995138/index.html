<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>用Keras写出像PyTorch一样的DataLoader方法 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="用Keras写出像PyTorch一样的DataLoader方法" />
<meta property="og:description" content="Keras
Author：Iouwill
Machine Learning Lab
数据导入、网络构建和模型训练永远是深度学习代码的主要模块。笔者此前曾写过PyTorch数据导入的pipeline标准结构总结PyTorch数据Pipeline标准化代码模板，本文参考PyTorch的DataLoader，给Keras也总结一套自定义的DataLoader框架。
Keras常规用法
按照正常人使用Keras的方法，大概就像如下代码一样：
import numpy as np from keras.models import Sequential # 导入全部数据 X, y = np.load(&#39;some_training_set_with_labels.npy&#39;) # Design model model = Sequential() [...] # 网络结构 model.compile() # 模型训练 model.fit(x=X, y=y) 虽然一次性导入训练数据一定程度上能够提高训练速度，但随着数据量增多，这种将数据一次性读入内存的方法很容易造成显存溢出的问题。所以，在开启一个深度学习项目时，一个较为明智的做法就是分批次读取训练数据。
数据存放方式
常规情况下，我们的训练数据要么是按照分类和阶段有组织的存放在硬盘目录下(多见于比赛和标准数据集)，要么以csv格式将数据路径和对应标签给出(多见于深度学习项目情形)。
数据按照类别和使用阶段存放(kaggle猫狗分类数据集)
数据按照csv文件形式给出（花朵分类数据集）
ImageDataGenerator
Keras早就考虑到了按批次导入数据的需求，所以ImageDataGenerator模块提供了按批次导入的数据生成器方法，包括数据增强和分批训练等方法。如下所示，分别对训练集和验证集调用ImageDataGenerator函数，然后从目录下按批次导入。
from tensorflow.keras.preprocessing.image import ImageDataGenerator # 数据增强 train_datagen = ImageDataGenerator( rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True) test_datagen = ImageDataGenerator(rescale=1./255) # 从目录下按批次读取 train_generator = train_datagen.flow_from_directory( &#39;data/train&#39;, target_size=(150, 150), batch_size=32, class_mode=&#39;binary&#39;) validation_generator = test_datagen." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/96f856ee302853902046ab0f18995138/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-01-07T17:08:37+08:00" />
<meta property="article:modified_time" content="2020-01-07T17:08:37+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">用Keras写出像PyTorch一样的DataLoader方法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align: center">Keras<br><br></p> 
 <p style="text-align: center"><strong>Author：Iouwill</strong></p> 
 <p style="text-align: center"><strong>Machine Learning Lab</strong></p> 
 <p>     数据导入、网络构建和模型训练永远是深度学习代码的主要模块。笔者此前曾写过PyTorch数据导入的pipeline标准结构总结<a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/103231898" rel="noopener noreferrer">PyTorch数据Pipeline标准化代码模板</a>，本文参考PyTorch的DataLoader，给Keras也总结一套自定义的DataLoader框架。</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/2a/ca/M5Z3Rnqx_o.png"></p> 
 <p>Keras常规用法</p> 
 <p>     按照正常人使用Keras的方法，大概就像如下代码一样：</p> 
 <pre class="has"><code class="language-python">import numpy as np
from keras.models import Sequential
# 导入全部数据
X, y = np.load('some_training_set_with_labels.npy')
# Design model
model = Sequential()
[...] # 网络结构
model.compile()
# 模型训练
model.fit(x=X, y=y)
</code></pre> 
 <p>     虽然一次性导入训练数据一定程度上能够提高训练速度，但随着数据量增多，这种将数据一次性读入内存的方法很容易造成显存溢出的问题。所以，在开启一个深度学习项目时，一个较为明智的做法就是分批次读取训练数据。</p> 
 <p>数据存放方式</p> 
 <p>     常规情况下，我们的训练数据要么是按照分类和阶段有组织的存放在硬盘目录下(多见于比赛和标准数据集)，要么以csv格式将数据路径和对应标签给出(多见于深度学习项目情形)。</p> 
 <p><img src="https://images2.imgbox.com/ae/06/6RH6s9by_o.png"></p> 
 <p style="text-align: center">数据按照类别和使用阶段存放(kaggle猫狗分类数据集)</p> 
 <p><img src="https://images2.imgbox.com/77/f9/ZKW0Rpv4_o.png"></p> 
 <p style="text-align: center">数据按照csv文件形式给出（花朵分类数据集）</p> 
 <p><strong>ImageDataGenerator</strong></p> 
 <p>     Keras早就考虑到了按批次导入数据的需求，所以ImageDataGenerator模块提供了按批次导入的数据生成器方法，包括数据增强和分批训练等方法。如下所示，分别对训练集和验证集调用ImageDataGenerator函数，然后从目录下按批次导入。</p> 
 <pre class="has"><code class="language-makefile">from tensorflow.keras.preprocessing.image import ImageDataGenerator
# 数据增强
train_datagen = ImageDataGenerator(
      rescale=1./255,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True)


test_datagen = ImageDataGenerator(rescale=1./255)
# 从目录下按批次读取
train_generator = train_datagen.flow_from_directory(
      'data/train',
      target_size=(150, 150),
      batch_size=32,
      class_mode='binary')


validation_generator = test_datagen.flow_from_directory(
      'data/validation',
      target_size=(150, 150),
      batch_size=32,
      class_mode='binary')
</code></pre> 
 <p>最后对模型调用fit_generator方法进行训练：</p> 
 <pre class="has"><code class="language-makefile">model.fit_generator(
      train_generator,
      steps_per_epoch=2000,
      epochs=50,
      validation_data=validation_generator,
      validation_steps=800)
</code></pre> 
 <p>     以上Keras提供的数据生成器的方法读入数据虽然好，但还不够灵活，实际深度学习项目会碰到各种不同的数据存放情况，根据实际情况来自定义一套类似于PyTorch的DataLoader非常有必要。</p> 
 <p><strong>Keras Sequence</strong></p> 
 <p>     Keras Sequence方法用于拟合一个数据序列，每一个Sequence必须提供__getitem__和__len__方法，这跟Torch的Dataset模块类似。Sequence是进行多进程处理的更安全的方法，这种结构保证网络在每个时期每个样本只训练一次，这与生成器不同。使用示例如下：</p> 
 <pre class="has"><code class="language-ruby">from skimage.io import imread
from skimage.transform import resize 
import numpy as np 
from keras.utils import Sequence


# x_set是图像的路径列表 
# y_set是对应的类别
class CIFAR10Sequence(Sequence): 
    def __init__(self, x_set, y_set, batch_size): 
        self.x, self.y = x_set, y_set 
        self.batch_size = batch_size 


    def __len__(self): 
        return int(np.ceil(len(self.x) / float(self.batch_size))) 


    def __getitem__(self, idx): 
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size] 
        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size] 
        return np.array([ resize(imread(file_name), (200, 200)) for file_name in batch_x]), np.array(batch_y)
</code></pre> 
 <p><strong>Torch风格的Keras DataLoader</strong></p> 
 <p>     现在我们针对一个13分类的多标签图像分类问题来自定义Torch风格的DataLoader。数据以csv的形式存放图片路径和对应标签，具体如下：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/5a/44/7TKkWxzR_o.png"></p> 
 <p>     可以看到，每张图像都有至少一个、至多三个的动物标签。所以标签在处理的时候需要进行转化。首先定义继承Sequence的DataGenerator类和一些初始化方法。</p> 
 <pre class="has"><code class="language-python">class DataGenerator(Sequence):
    """
    基于Sequence的自定义Keras数据生成器
    """
    def __init__(self, df, list_IDs,
                 to_fit=True, batch_size=8, dim=(256, 472),
                 n_channels=3, n_classes=13, shuffle=True):
        """ 初始化方法
        :param df: 存放数据路径和标签的数据框
        :param list_IDs: 数据索引列表
        :param to_fit: 设定是否返回标签y
        :param batch_size: batch size 
        :param dim: 图像大小
        :param n_channels: 图像通道
        :param n_classes: 标签类别
        :param shuffle: 每一个epoch后是否打乱数据
        """
        self.df = df
        self.list_IDs = list_IDs
        self.to_fit = to_fit
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.on_epoch_end()
</code></pre> 
 <p>     然后定义on_epoch_end方法来在每个epoch之后shuffle数据，以及底层数据读取和标签编码方法。</p> 
 <pre class="has"><code class="language-python">def on_epoch_end(self):
    """每个epoch之后更新索引
    """
    self.indexes = np.arange(len(self.list_IDs))
    if self.shuffle == True:
        np.random.shuffle(self.indexes)
</code></pre> 
 <p>     图像读取方法：</p> 
 <pre class="has"><code class="language-python">def _load_image(self, image_path):
    """cv2读取图像
    """
    # img = cv2.imread(image_path)
    img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
    w, h, _ = img.shape
    if w&gt;h:
        img = np.rot90(img)
    img = cv2.resize(img, (472, 256))
    return img
</code></pre> 
 <p>     标签编码转换方法：</p> 
 <pre class="has"><code class="language-python">def _labels_encode(self, s, keys):
    """标签one-hot编码转换
    """
    cs = s.split('_')
    y = np.zeros(13)
    for i in range(len(cs)):
        for j in range(len(keys)):
            for c in cs:
                if c == keys[j]:
                    y[j] = 1
    return y
</code></pre> 
 <p>     然后定义每个批次生成图片和标签的方法：</p> 
 <pre class="has"><code class="language-python">def _generate_X(self, list_IDs_temp):
    """生成每一批次的图像
    :param list_IDs_temp: 批次数据索引列表
    :return: 一个批次的图像
    """
    # 初始化
    X = np.empty((self.batch_size, *self.dim, self.n_channels))
    # 生成数据
    for i, ID in enumerate(list_IDs_temp):
        # 存储一个批次
        X[i,] = self._load_image(self.df.iloc[ID].images)
    return X


def _generate_y(self, list_IDs_temp):
    """生成每一批次的标签
    :param list_IDs_temp: 批次数据索引列表
    :return: 一个批次的标签
    """
    y = np.empty((self.batch_size, self.n_classes), dtype=int)
    # Generate data
    for i, ID in enumerate(list_IDs_temp):
        # Store sample
        y[i,] = self._labels_encode(self.df.iloc[ID].labels, config.LABELS)
    return y
</code></pre> 
 <p>     底层读取和生成方法定义完成后，即可定义__getitem__和__len__方法：</p> 
 <pre class="has"><code class="language-python">def __getitem__(self, index):
    """生成每一批次训练数据
    :param index: 批次索引
    :return: 训练图像和标签
    """
    # 生成批次索引
    indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
    # 索引列表
    list_IDs_temp = [self.list_IDs[k] for k in indexes]
    # 生成数据
    X = self._generate_X(list_IDs_temp)
    if self.to_fit:
        y = self._generate_y(list_IDs_temp)
        return X, y
    else:
        return X
        
def __len__(self):
    """每个epoch下的批次数量
    """
    return int(np.floor(len(self.list_IDs) / self.batch_size))
</code></pre> 
 <p>    完整的Keras DataLoader代码如下：</p> 
 <pre class="has"><code class="language-python">class DataGenerator(Sequence):
    """
    基于Sequence的自定义Keras数据生成器
    """
    def __init__(self, df, list_IDs,
                 to_fit=True, batch_size=8, dim=(256, 472),
                 n_channels=3, n_classes=13, shuffle=True):
        """ 初始化方法
        :param df: 存放数据路径和标签的数据框
        :param list_IDs: 数据索引列表
        :param to_fit: 设定是否返回标签y
        :param batch_size: batch size 
        :param dim: 图像大小
        :param n_channels: 图像通道
        :param n_classes: 标签类别
        :param shuffle: 每一个epoch后是否打乱数据
        """
        self.df = df
        self.list_IDs = list_IDs
        self.to_fit = to_fit
        self.batch_size = batch_size
        self.dim = dim
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.shuffle = shuffle
        self.on_epoch_end()
        
   def __getitem__(self, index):
        """生成每一批次训练数据
        :param index: 批次索引
        :return: 训练图像和标签
        """
        # 生成批次索引
        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]
        # 索引列表
        list_IDs_temp = [self.list_IDs[k] for k in indexes]
        # 生成数据
        X = self._generate_X(list_IDs_temp)
        if self.to_fit:
            y = self._generate_y(list_IDs_temp)
            return X, y
        else:
            return X
        
    def __len__(self):
        """每个epoch下的批次数量
        """
        return int(np.floor(len(self.list_IDs) / self.batch_size))
        
        def _generate_X(self, list_IDs_temp):
        """生成每一批次的图像
        :param list_IDs_temp: 批次数据索引列表
        :return: 一个批次的图像
        """
        # 初始化
        X = np.empty((self.batch_size, *self.dim, self.n_channels))
        # 生成数据
        for i, ID in enumerate(list_IDs_temp):
            # 存储一个批次
            X[i,] = self._load_image(self.df.iloc[ID].images)
        return X


    def _generate_y(self, list_IDs_temp):
        """生成每一批次的标签
        :param list_IDs_temp: 批次数据索引列表
        :return: 一个批次的标签
        """
        y = np.empty((self.batch_size, self.n_classes), dtype=int)
        # Generate data
        for i, ID in enumerate(list_IDs_temp):
            # Store sample
            y[i,] = self._labels_encode(self.df.iloc[ID].labels, config.LABELS)
        return y
        
     def on_epoch_end(self):
        """每个epoch之后更新索引
        """
        self.indexes = np.arange(len(self.list_IDs))
        if self.shuffle == True:
            np.random.shuffle(self.indexes)
            
     def _load_image(self, image_path):
        """cv2读取图像
        """
        # img = cv2.imread(image_path)
        img = cv2.imdecode(np.fromfile(image_path, dtype=np.uint8), cv2.IMREAD_COLOR)
        w, h, _ = img.shape
        if w&gt;h:
            img = np.rot90(img)
        img = cv2.resize(img, (472, 256))
        return img
        
     def _labels_encode(self, s, keys):
        """标签one-hot编码转换
        """
        cs = s.split('_')
        y = np.zeros(13)
        for i in range(len(cs)):
            for j in range(len(keys)):
                for c in cs:
                    if c == keys[j]:
                        y[j] = 1
        return y
</code></pre> 
 <p>     使用效果如下（打印每一批次输入输出的shape）：</p> 
 <p style="text-align: center"><img src="https://images2.imgbox.com/f2/f6/juXZrbSi_o.png"></p> 
 <p>     实际训练时，我们可以大致编写如下训练代码框架：</p> 
 <pre class="has"><code class="language-python">import numpy as np
from keras.models import Sequential
import DataGenerator
# Parameters
params = {'batch_size': 64,
          'n_classes': 6,
          'n_channels': 1,
          'shuffle': True}
# Generators
training_generator = DataGenerator(train_df, train_idx, **params)
validation_generator = DataGenerator(val_df, val_idx, **params)


# Design model
model = Sequential()
[...] # Architecture
model.compile()


# Train model on dataset
model.fit_generator(generator=training_generator,
                    validation_data=validation_generator,
                    use_multiprocessing=True,
                    workers=4)
</code></pre> 
 <p><br>     以上就是本文主要内容。本文提供的Keras DataLoader方法仅供参考使用，自定义Keras DataLoader还应根据具体数据组织形式来灵活决定。<br></p> 
 <p><strong>  参考资料：</strong></p> 
 <p><em> https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c</em></p> 
 <p><strong>往期精彩：</strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/103231898" rel="noopener noreferrer">PyTorch数据Pipeline标准化代码模板</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/103692140" rel="noopener noreferrer">PyTorch深度学习训练可视化工具visdom</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/103116387" rel="noopener noreferrer">深度学习100问-13：深度学习如何制作个人数据集？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/103105375" rel="noopener noreferrer">深度学习100问-12：深度学习有哪些经典数据集？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/103083447" rel="noopener noreferrer">深度学习100问-11：什么是学习率衰减？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920493" rel="noopener noreferrer">深度学习100问-10：如何部署一个轻量级的深度学习项目？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920452" rel="noopener noreferrer">深度学习100问-9：为什么EfficientNet号称是最好的分类网络？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920430" rel="noopener noreferrer">深度学习100问-8：什么是Batch Normalization？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920420" rel="noopener noreferrer">深度学习100问-7：dropout有哪些细节问题？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920408" rel="noopener noreferrer">深度学习100问-6：有哪些经典的卷积类型？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920397" rel="noopener noreferrer">深度学习100问-5：如何阅读一份深度学习项目代码？</a><br></strong></p> 
 <p><strong><a href="http://mp.weixin.qq.com/s?__biz=MzI4ODY2NjYzMQ%3D%3D&amp;chksm=ec3bade9db4c24ffc5c5281144484713c500f636c8b8bf5e412f8de8573b351e24228bb2ebe1&amp;idx=1&amp;mid=2247485569&amp;scene=21&amp;sn=6de0e03c04eb721aad974e5d77a0c2cb#wechat_redirect" rel="nofollow">深度学习100问-4：深度学习应遵循怎样的论文研读路线？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920391" rel="noopener noreferrer">深度学习100问-3：深度学习应掌握哪些Linux开发技术？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920382" rel="noopener noreferrer">深度学习100问-2：深度学习应掌握哪些Git开发技术？</a><br></strong></p> 
 <p><strong><a target="_blank" href="https://blog.csdn.net/weixin_37737254/article/details/102920379" rel="noopener noreferrer">深度学习100问-1：深度学习环境配置有哪些坑？</a></strong></p> 
 <hr> 
 <p style="text-align: center">一个算法工程师的成长之路</p> 
 <p><img width="100%" src="https://images2.imgbox.com/2e/da/MOKQWnSd_o.png"></p> 
 <p><img src="https://images2.imgbox.com/25/c0/D8qFRfCL_o.png"></p> 
 <p style="text-align: center">长按二维码.关注机器学习实验室</p> 
 <p><img src="https://images2.imgbox.com/5d/dd/IvpoWtkb_o.png"></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7e7bcc012b985fcdc077277a634a4cf0/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">基于Vue和Vant-ui开发的移动端周历日期选择器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/0b0319635189c2b3a88a2449660457b9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">线性回归损失函数求偏导（推到过程）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>