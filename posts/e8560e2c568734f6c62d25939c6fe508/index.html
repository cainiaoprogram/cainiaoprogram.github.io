<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习：pyTorch实战计算机视觉 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习：pyTorch实战计算机视觉" />
<meta property="og:description" content="pyTorch深度学习框架：基于动态图计算的特性，基于静态图计算深度学习框架相比，更多的优势，速度快，强大的包可调用。
一、人工智能 1、人工智能：强人工智能： 智能 弱人工智能：人工
2、人工智能的三起两落：
1956年提出人工智能概念 1980 专家系统：指解决特定领域问题的能力已达到该领域的专家能力水平，其核心运用专家多年积累的丰富经验和专业知识，不断模拟专家解决问题的思维，处理只有专家才能解决的问题1990 机器学习 深度学习 机器学习=统计学习方法（统计学原理）
3、1957 单层计算单元神经网络模型==感知机 perceptron 分类问题，二分类线性模型。
&#43;1 -1 分离超平面 优点：容易处理线性可分，不能处理异或问题，也就是不能处理非线性问题。
4、多层神经网络模型，输入层 隐藏层 输出层
5、计算机视觉：机器能否对视觉信息进行收集，处理和分析，是机器智能一个重要的体现用途，让机器拥有人类一样的视觉能力也是计算机视觉诞生的初衷。 计算机视觉分为信息的收集，信息的分析，信息的处理。
6、图片分类，图像目标识别，图像语义分割（对识别的类别使用同一种像素进行标识打上标签）
7、自动驾驶
8、图像风格迁移Neural style
二、相关数学知识 1、矩阵运算
标量：独立存在的数
向量：一维：一列按顺序排列的元素
矩阵matrix：二维数组结构
张量：数组的维度超过了二维，高维数组
矩阵的加法 减法 乘法。
2、导数求导
一阶导数的几何意义：斜率
复合链式求导法则
三、深度学习网络基础 监督学习 无监督学习半监督学习弱监督学习回归问题（连续）聚类 分类问题（离散） 过拟合增加数据dropout采用正则化方法(L0.L1L2) 欠拟合增加特征项构造复杂多项式减少正则化参数 1、向后传播
2、损失函数
均方误差函数 mse均方根误差函数 RMSE平均绝对误差函数 3、优化算法
相关参数的初始化，参数以何种形式调优，取适合的学习率 梯度： 偏导，向后传播中对各个参数求得的偏导数
一阶 优化函数 GD 梯度下降 gradient descent 全局梯度下降 训练的样本的总数，学习率，容易出现局部最优和抖动 J(θ) 是总体SGD 随机梯度下降stochastic gradient descent J(θ) 是选取随机一部分数据集包含随机个样本数量 ，因为是随机容易发生局部最优解BGD 批量梯度下降batch gradient descent J(θ) 是一个batch Momentum adgrad Adamadaptive moment estimation 通过让每个参数获得自适应的学习率，大损失大学习率 小损失小学习率，避免出现局部最优解，优点收敛快，学习效果好，对学习速率消失，收敛过慢，高方差的参数更新等损失值波动，adam有很好的解决方案。 4、激活函数" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/e8560e2c568734f6c62d25939c6fe508/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-02-21T12:02:17+08:00" />
<meta property="article:modified_time" content="2019-02-21T12:02:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习：pyTorch实战计算机视觉</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>pyTorch深度学习框架：基于动态图计算的特性，基于静态图计算深度学习框架相比，更多的优势，速度快，强大的包可调用。</p> 
<h2>一、人工智能</h2> 
<p>1、人工智能：强人工智能： 智能          弱人工智能：人工</p> 
<p>2、人工智能的三起两落：</p> 
<ul><li>1956年提出人工智能概念 </li><li>1980 专家系统：指解决特定领域问题的能力已达到该领域的专家能力水平，其核心运用专家多年积累的丰富经验和专业知识，不断模拟专家解决问题的思维，处理只有专家才能解决的问题</li><li>1990 机器学习 深度学习</li></ul> 
<p><img alt="" class="has" height="223" src="https://images2.imgbox.com/ca/2c/wTLf6yat_o.png" width="310"></p> 
<p>机器学习=统计学习方法（统计学原理）</p> 
<p>3、1957 单层计算单元神经网络模型==<span style="color:#f33b45;"><strong>感知机 perceptron</strong></span>  分类问题，二分类线性模型。</p> 
<p style="margin-left:0in;">+1 -1  分离超平面 优点：容易处理线性可分，不能处理异或问题，也就是不能处理非线性问题。</p> 
<p>4、多层神经网络模型，输入层 <span style="color:#f33b45;"><strong>隐藏层</strong></span> 输出层</p> 
<p>5、<strong><span style="color:#f33b45;">计算机视觉</span></strong>：机器能否对视觉信息进行收集，处理和分析，是机器智能一个重要的体现用途，让机器拥有人类一样的视觉能力也是计算机视觉诞生的初衷。 计算机视觉分为信息的收集，信息的分析，信息的处理。</p> 
<p>6、图片分类，图像目标识别，图像语义分割（对识别的类别使用同一种<strong>像素</strong>进行标识打上标签）</p> 
<p>7、自动驾驶</p> 
<p>8、图像风格迁移Neural style</p> 
<h2>二、相关数学知识</h2> 
<p>1、矩阵运算</p> 
<p>标量：独立存在的数</p> 
<p>向量：一维：一列按顺序排列的元素</p> 
<p>矩阵matrix：二维数组结构</p> 
<p>张量：数组的维度超过了二维，高维数组</p> 
<p>矩阵的加法 减法 乘法。</p> 
<p>2、导数求导</p> 
<p>一阶导数的几何意义：斜率</p> 
<p>复合<strong>链式求导法则</strong></p> 
<h2>三、深度学习网络基础</h2> 
<p> </p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td style="width:143px;">监督学习</td><td style="width:121px;"> 无监督学习</td><td style="width:99px;">半监督学习</td><td style="width:127px;">弱监督学习</td></tr><tr><td style="width:143px;">回归问题（连续）</td><td style="width:121px;">聚类</td><td style="width:99px;"> </td><td style="width:127px;"> </td></tr><tr><td style="width:143px;">分类问题（离散）</td><td style="width:121px;"> </td><td style="width:99px;"> </td><td style="width:127px;"> </td></tr></tbody></table> 
<p> </p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td style="width:89px;">过拟合</td><td style="width:90px;">增加数据</td><td style="width:110px;">dropout</td><td style="width:188px;">采用正则化方法(L0.L1L2)</td><td style="width:21px;"> </td></tr><tr><td style="width:89px;">欠拟合</td><td style="width:90px;">增加特征项</td><td style="width:110px;">构造复杂多项式</td><td style="width:188px;">减少正则化参数</td><td style="width:21px;"> </td></tr></tbody></table> 
<p> </p> 
<p>1、向后传播</p> 
<p>2、损失函数</p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td>均方误差函数 mse</td><td><img alt="" class="has" height="59" src="https://images2.imgbox.com/1f/bd/zD1HpyUR_o.png" width="246"></td></tr><tr><td>均方根误差函数 RMSE</td><td><img alt="" class="has" height="58" src="https://images2.imgbox.com/34/ee/9Pkco1qX_o.png" width="276"></td></tr><tr><td>平均绝对误差函数</td><td><img alt="" class="has" height="59" src="https://images2.imgbox.com/0c/62/x701u1co_o.png" width="241"></td></tr><tr><td> </td><td> </td></tr><tr><td> </td><td> </td></tr><tr><td> </td><td> </td></tr></tbody></table> 
<p><br> 3、优化算法</p> 
<p>相关参数的初始化，参数以何种形式调优，取适合的学习率 </p> 
<p>梯度： 偏导，<strong>向后传播中对各个参数求得的偏导数</strong></p> 
<p><img alt="" class="has" height="69" src="https://images2.imgbox.com/56/bb/ffx58lXt_o.png" width="192"></p> 
<p> </p> 
<p> </p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td style="width:147px;">一阶 优化函数</td><td style="width:351px;"> </td></tr><tr><td style="width:147px;">GD 梯度下降 gradient descent </td><td style="width:351px;">全局梯度下降 训练的样本的总数，学习率，容易出现局部最优和抖动  J(θ) 是总体</td></tr><tr><td style="width:147px;">SGD 随机梯度下降</td><td style="width:351px;">stochastic gradient descent  J(θ) 是选取<strong>随机一部分数据集包含随机个样本数量</strong> ，因为是随机容易发生局部最优解</td></tr><tr><td>BGD 批量梯度下降</td><td style="width:351px;">batch gradient descent  J(θ) 是一<strong>个batch</strong> </td></tr><tr><td>Momentum</td><td style="width:351px;"> </td></tr><tr><td style="width:147px;">adgrad</td><td style="width:351px;"> </td></tr><tr><td style="width:147px;">Adam</td><td style="width:351px;">adaptive moment estimation 通过让每个参数获得自适应的<strong>学习率，大损失大学习率 小损失小学习率，避免出现局部最优解，优点收敛快，学习效果好，</strong>对学习速率消失，收敛过慢，高方差的参数更新等损失值波动，adam有很好的解决方案。</td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr><tr><td style="width:147px;"> </td><td style="width:351px;"> </td></tr></tbody></table> 
<p> </p> 
<p>4、激活函数</p> 
<p>如果没有激活函数，构造神经网络模型过程中，一直就是<strong> <span style="color:#f33b45;">线性模型 ，</span>线性模型在对非线性问题的时候有这很大的局限，激活函数，<span style="color:#f33b45;">引入非线性因素</span>，非线性模型处理更加复杂的问题</strong></p> 
<table border="1" cellpadding="1" cellspacing="1" style="width:500px;"><tbody><tr><td style="width:146px;">sigmoid</td><td style="width:352px;"> <p><img alt="" class="has" height="154" src="https://images2.imgbox.com/bd/8c/c4e1PtSr_o.png" width="262"> 0 -1 </p> <p>sigmoid 的导数取值是0-0.25 </p> <p> </p> <p><img alt="" class="has" height="171" src="https://images2.imgbox.com/bb/54/ipBE56ad_o.png" width="268"></p> <p>缺点：<span style="color:#f33b45;">在正无穷和负无穷的时候会出现梯度消失。</span></p> <p><span style="color:#f33b45;">反向传播过程中，最大0.25</span> ，如果模型到达一定的深度，那么反向传播的梯度就会越来越小</p> <p><span style="color:#f33b45;">sigmoid 函数的输出值恒大于0，</span>优化过程中收敛变慢。增加时间成本， 取参使用<strong>零中心，zero-centered</strong> 数据。</p> </td></tr><tr><td style="width:146px;">tanh</td><td style="width:352px;"> <p><img alt="" class="has" height="78" src="https://images2.imgbox.com/5d/8d/f3mwXzaE_o.png" width="157"></p> <p> </p> <p><img alt="" class="has" height="239" src="https://images2.imgbox.com/65/3c/BoRWQVk3_o.png" width="334"></p> <p><span style="color:#f33b45;">tanh函数输出结果是零中心数据，解决激活函数过程中收敛速度变慢的问题，但是导数0-1之间，仍然不够大。</span></p> </td></tr><tr><td style="width:146px;">relu 修正线性单元</td><td style="width:352px;"> <p>f(x)=max(0,x)</p> <p><img alt="" class="has" height="157" src="https://images2.imgbox.com/c0/8e/Vl2fYnma_o.png" width="285"></p> <p><strong>收敛速度快</strong>，<strong> ReLu 的输出不是零数据中心， 有些神经元永远不会被更新</strong>，模型参数初始化使用全正或者全负的值，后向传播速度太快， 合理学习率使用Adam.</p> <p>leaky-relu,r-relu.</p> <p><strong>优点： sigmoid 和tanh 计算指数</strong></p> <p><strong>           非饱和性，解决梯度消失的问题</strong></p> <p>           单侧抑制，提供网络的稀疏性表达能力。</p> </td></tr></tbody></table> 
<p>5、GPU/CPU</p> 
<p>CPU:中央处理器 计算处理核心，负责计算机的控制命令处理和核心运算输出 <strong> 串行</strong></p> 
<p>GPU：图像处理器，主机的显示处理核心，主要负责对计算机中的图形和图像的处理与运算  并行</p> 
<p>       深度学习张量、矩阵 <strong>并行计算</strong></p> 
<h2><strong>四、卷积神经网络 convolutional neural network cnn </strong></h2> 
<p><strong>1、卷积核：特征的提取，卷积核，卷积边界像素填充：same:最外层指定层数的值全为0的像素边界，  valid 直接对输入图像进行卷积。</strong></p> 
<p>卷积通用公式 s 步长，p padding</p> 
<blockquote> 
 <p><img alt="" class="has" height="156" src="https://images2.imgbox.com/a4/b7/6itf4HYu_o.png" width="328"></p> 
</blockquote> 
<p><img alt="" class="has" height="166" src="https://images2.imgbox.com/f0/3b/5Mbrn1uO_o.png" width="610"></p> 
<p><strong>三通道卷积</strong></p> 
<p><img alt="" class="has" height="553" src="https://images2.imgbox.com/59/75/CYtAxtng_o.png" width="495"></p> 
<p>2、池化  卷积神经网络中的一种提取输入数据特征的方式，压缩数据。减少参与模型计算的参数。</p> 
<p>max 、average</p> 
<p><img alt="" class="has" height="137" src="https://images2.imgbox.com/4c/46/U5fMqQZL_o.png" width="382"></p> 
<p>3、全连接层 特征压缩完成模型的分类功能。</p> 
<p>4、<strong>经典网络模型：lenet, alexnet,vggnet goolenet,resnet</strong></p> 
<p><a href="https://blog.csdn.net/weixin_41108334/article/details/83827332">https://blog.csdn.net/weixin_41108334/article/details/83827332</a></p> 
<h2><strong>五、python入门</strong></h2> 
<p><a href="https://mp.csdn.net/postedit/85873680">https://mp.csdn.net/postedit/85873680</a></p> 
<h2>九、多模型融合</h2> 
<p>集百家之长 ：宗旨：通过科学的方法融合各个模型的优势，以获得对未知问题的更强的解决能力。</p> 
<p><span style="color:#f33b45;">结果融合：针对模型的输出结果进行融合，主要包括<strong>结果多数表决</strong>，<strong>结果直接平均</strong> 和 <strong>结果加权平均</strong>这三个主要的类型。</span></p> 
<p><img alt="" class="has" height="431" src="https://images2.imgbox.com/2f/82/kL9PB1I9_o.png" width="622"></p> 
<p>十、循环神经网络</p> 
<p>recurrent neural network  处理序列 sequences</p> 
<p>循环卷积 循环单元可以随意的控制输入输入和输出的数量，具有非常大的灵活性</p> 
<p>RNN ---&gt;LSTM(长短期记忆， 如果近期的数据发生变化，则对输出结果产生重大影响，)</p> 
<p>RNN 手写体识别 分类任务</p> 
<p><img alt="" class="has" height="428" src="https://images2.imgbox.com/fd/e6/tZO8lG0B_o.png" width="479"></p> 
<p><img alt="" class="has" height="106" src="https://images2.imgbox.com/50/cc/EAkn82qC_o.png" width="385"></p> 
<p>模型变成rnn 其他的 loss和优化算法 准确度等同</p> 
<p>RNN--》自然语言处理领域， 视频数据</p> 
<p> </p> 
<h2>十一、自动编码器 autoencoder</h2> 
<p><strong>无监督</strong>学习的神经网络  1、核心特征提取的<strong>编码部</strong>分，2、 实现数据重构的<strong>解码</strong>部分</p> 
<p><img alt="" class="has" height="307" src="https://images2.imgbox.com/1e/d1/7Fa2XWLe_o.png" width="591"></p> 
<p>自动编码： 用途实现输入数据的清洗， 除去数据中的噪声数据，对输入数据的某些关键特征进行增强和放大</p> 
<p><img alt="" class="has" height="620" src="https://images2.imgbox.com/8e/5c/3r0xZUg5_o.png" width="691"></p> 
<p>上采样</p> 
<p><img alt="" class="has" height="332" src="https://images2.imgbox.com/2b/aa/Rf7DvE52_o.png" width="805"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c2c08594a1ce486bab58b3f6ed042519/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">操作系统（一）引导程序</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/4bfa57ed5ff6f93e185eb07869a4d599/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">SAP用户信息查询的几张表</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>