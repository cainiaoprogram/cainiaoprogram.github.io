<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于 InternLM 和 LangChain 搭建你的知识库 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于 InternLM 和 LangChain 搭建你的知识库" />
<meta property="og:description" content="基于 InternLM 和 LangChain 搭建你的知识库 大模型开发范式LLM的局限性：RAG 检索增强生成 LangChain简介构建向量数据库搭建知识库助手Web Demo部署环境配置下载 NLTK 相关资源下载本项目代码 大模型开发范式 LLM的局限性： 知识实效性受限：如何让LLM能够获得更新的知识专业能力有限：如何打造垂直领域大模型定制化成本高：如何打造个人专属的LLM应用 两种开发范式：
RAG 检索增强生成 LangChain简介 LangChain框架是一个开源工具，通过为各种LLM提供通用接口来简化应用程序的开发流程，帮助开发者自由构建LLM应用。
LangChain的核心组成模块：
链：将组件组合实现端到端应用，通过一个对象封装实现一系列LLM操作Eg.检索问答链：覆盖实现了GAR（增强检索生成）的全部流程
构建向量数据库 加载源文件
确定源文件类型，针对不同类型源文件选用不同的加载器，核心在于将带格式文本转化为无格式字符串文档分块
由于单个文档往往超过了模型上下文上限，我们需要对加载的文档进行切分
一般按字符串长度进行分割
可以手动控制分割块的长度和重叠区间的长度文档向量化
使用向量数据库来支持语义检索，需要将文档向量化存入向量数据库
可以使用任一一种Embedding模型来进行向量化
可以使用多种支持语义检索的向量数据库，一般使用轻量级的Chroma 搭建知识库助手 将InternLM接入LangChain
基于RAG的问答系统性能核心受限于：
检索精度Prompt性能
一些可能优化的点：检索方面： 基于语义进行分割，保证每一个chunk的语义完整给每个chunk生成概括性索引，检索时匹配索引 Prompt方面 迭代优化Prompt策略 Web Demo部署 有很多支持简易web部署的框架，如Gradio、Streamlit等
环境配置 在环境中安装运行 demo 所需要的依赖
# 升级pip python -m pip install --upgrade pip pip install modelscope==1.9.5 pip install transformers==4.35.2 pip install streamlit==1.24.0 pip install sentencepiece==0.1.99 pip install accelerate==0.24.1 在 /root 路径下新建目录 data，在目录下新建 download." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/44c25563313d16354d7932a41bebf533/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-10T09:03:34+08:00" />
<meta property="article:modified_time" content="2024-01-10T09:03:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于 InternLM 和 LangChain 搭建你的知识库</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>基于 InternLM 和 LangChain 搭建你的知识库</h4> 
 <ul><li><a href="#_1" rel="nofollow">大模型开发范式</a></li><li><ul><li><a href="#LLM_2" rel="nofollow">LLM的局限性：</a></li><li><a href="#RAG__9" rel="nofollow">RAG 检索增强生成</a></li></ul> 
  </li><li><a href="#LangChain_12" rel="nofollow">LangChain简介</a></li><li><a href="#_18" rel="nofollow">构建向量数据库</a></li><li><a href="#_29" rel="nofollow">搭建知识库助手</a></li><li><a href="#Web_Demo_41" rel="nofollow">Web Demo部署</a></li><li><ul><li><a href="#_44" rel="nofollow">环境配置</a></li><li><a href="#_NLTK__59" rel="nofollow">下载 NLTK 相关资源</a></li><li><a href="#_72" rel="nofollow">下载本项目代码</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_1"></a>大模型开发范式</h2> 
<h3><a id="LLM_2"></a>LLM的局限性：</h3> 
<ul><li>知识实效性受限：如何让LLM能够获得更新的知识</li><li>专业能力有限：如何打造垂直领域大模型</li><li>定制化成本高：如何打造个人专属的LLM应用</li></ul> 
<p>两种开发范式：<br> <img src="https://images2.imgbox.com/1b/e6/Ed05Wvf1_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="RAG__9"></a>RAG 检索增强生成</h3> 
<p><img src="https://images2.imgbox.com/21/d9/QuFLik40_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="LangChain_12"></a>LangChain简介</h2> 
<p>LangChain框架是一个开源工具，通过为各种LLM提供通用接口来简化应用程序的开发流程，帮助开发者自由构建LLM应用。<br> LangChain的核心组成模块：</p> 
<ul><li>链：将组件组合实现端到端应用，通过一个对象封装实现一系列LLM操作</li><li>Eg.检索问答链：覆盖实现了GAR（增强检索生成）的全部流程<br> <img src="https://images2.imgbox.com/74/76/Y9hixSOY_o.png" alt="在这里插入图片描述"></li></ul> 
<h2><a id="_18"></a>构建向量数据库</h2> 
<ul><li>加载源文件<br> 确定源文件类型，针对不同类型源文件选用不同的加载器，核心在于将带格式文本转化为无格式字符串</li><li>文档分块<br> 由于单个文档往往超过了模型上下文上限，我们需要对加载的文档进行切分<br> 一般按字符串长度进行分割<br> 可以手动控制分割块的长度和重叠区间的长度</li><li>文档向量化<br> 使用向量数据库来支持语义检索，需要将文档向量化存入向量数据库<br> 可以使用任一一种Embedding模型来进行向量化<br> 可以使用多种支持语义检索的向量数据库，一般使用轻量级的Chroma</li></ul> 
<h2><a id="_29"></a>搭建知识库助手</h2> 
<p>将InternLM接入LangChain<br> <img src="https://images2.imgbox.com/b5/2d/NRNstmkQ_o.png" alt="在这里插入图片描述"><br> 基于RAG的问答系统性能核心受限于：</p> 
<ul><li>检索精度</li><li>Prompt性能<br> 一些可能优化的点：</li><li>检索方面： 
  <ul><li>基于语义进行分割，保证每一个chunk的语义完整</li><li>给每个chunk生成概括性索引，检索时匹配索引</li></ul> </li><li>Prompt方面 
  <ul><li>迭代优化Prompt策略</li></ul> </li></ul> 
<h2><a id="Web_Demo_41"></a>Web Demo部署</h2> 
<p>有很多支持简易web部署的框架，如Gradio、Streamlit等</p> 
<h3><a id="_44"></a>环境配置</h3> 
<p>在环境中安装运行 demo 所需要的依赖</p> 
<pre><code class="prism language-shell"><span class="token comment"># 升级pip</span>
python <span class="token parameter variable">-m</span> pip <span class="token function">install</span> <span class="token parameter variable">--upgrade</span> pip

pip <span class="token function">install</span> <span class="token assign-left variable">modelscope</span><span class="token operator">==</span><span class="token number">1.9</span>.5
pip <span class="token function">install</span> <span class="token assign-left variable">transformers</span><span class="token operator">==</span><span class="token number">4.35</span>.2
pip <span class="token function">install</span> <span class="token assign-left variable">streamlit</span><span class="token operator">==</span><span class="token number">1.24</span>.0
pip <span class="token function">install</span> <span class="token assign-left variable">sentencepiece</span><span class="token operator">==</span><span class="token number">0.1</span>.99
pip <span class="token function">install</span> <span class="token assign-left variable">accelerate</span><span class="token operator">==</span><span class="token number">0.24</span>.1
</code></pre> 
<p>在 /root 路径下新建目录 data，在目录下新建 download.py 文件并在其中输入以下内容，粘贴代码后记得保存文件，如下图所示。并运行 python /root/data/download.py 执行下载，模型大小为 14 GB，下载模型大概需要 10~20 分钟.<br> <img src="https://images2.imgbox.com/de/54/QhsWFSl6_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_NLTK__59"></a>下载 NLTK 相关资源</h3> 
<p>我们在使用开源词向量模型构建开源词向量的时候，需要用到第三方库 nltk 的一些资源。正常情况下，其会自动从互联网上下载，但可能由于网络原因会导致下载中断，此处我们可以从国内仓库镜像地址下载相关资源，保存到服务器上。</p> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /root
<span class="token function">git</span> clone https://gitee.com/yzy0612/nltk_data.git  <span class="token parameter variable">--branch</span> gh-pages
<span class="token builtin class-name">cd</span> nltk_data
<span class="token function">mv</span> packages/*  ./
<span class="token builtin class-name">cd</span> tokenizers
<span class="token function">unzip</span> punkt.zip
<span class="token builtin class-name">cd</span> <span class="token punctuation">..</span>/taggers
<span class="token function">unzip</span> averaged_perceptron_tagger.zip
</code></pre> 
<h3><a id="_72"></a>下载本项目代码</h3> 
<pre><code class="prism language-shell"><span class="token builtin class-name">cd</span> /root/data
<span class="token function">git</span> clone https://github.com/InternLM/tutorial
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8eb63ebef58b2da37fc5f7b8ab988950/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">盘点一个Python自动化办公的需求——一键批量插图到Excel指定单元格</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/a932ea1638aa583351b7a719b6c752f3/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Proteus仿真】【Arduino单片机】智能感应温控风扇</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>