<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>scrapy初学：爬百度图片 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="scrapy初学：爬百度图片" />
<meta property="og:description" content="爬虫初学：基于Pycharm用scrapy爬取百度图片 初学爬虫选择工具功能说明具体内容和代码踩过的坑 初学爬虫 本人最近初学爬虫的相关知识和实现，这里简单介绍一下对如何用scrapy进行百度图片的抓取，记录一下自己踩过的坑。
选择工具 Pycharm 2020.1Scrapypython 3.8 功能说明 制作百度图片的scrapy爬虫，能够根据关键字下载百度图片并标明序号和进行存储。
具体内容和代码 由于scrapy工具有出色的表现和良好的口碑，因此一直想学习用scrapy来爬取数据。
在Pycharm中安装scrapy，运用Pycharm安装库方法即可，打开Pycharm后，点击File-&gt;Setting-&gt;Project
Interpreter后，选择弹出对话框的&#43;，从选择包中选择scrapy安装即可。! 在这里插入图片描述
其中踩过的坑在后续章节中会写明。
安装完scrapy, 即可在Pycharm终端处通过命令
scrapy startproject projectname
建立爬虫项目，生成pipeline, setting等相关文件。这里我写的项目名称是BaiduScrapy。在./BaiduScrapy/Spiders文件夹下的新建爬虫的python文件：BaiduPicSpider.py，作为爬虫的类。
生成的项目目录如下图：
3.
后续修改以下程序实现目标工程：
Settings.py处增加：
ROBOTSTXT_OBEY = False MAX_PAGE = 30 IMAGES_STORE = &#39;./images&#39; ITEM_PIPELINES = { &#39;BaiduScrapy.pipelines.BaiduImagePipeline&#39;: 300, } BaiduPicScrapy.py的代码为：
# -*- coding: utf-8 -*- # Define here the models for image scrape from scrapy import Spider, Request from urllib.parse import quote from BaiduScrapy.items import BaiduImageItem import json class ImageSpider(Spider): name = &#39;image&#39; allowed_domain = [&#39;images." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d14a76a6302bb5191b9821ee77a4309b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-06-26T14:00:23+08:00" />
<meta property="article:modified_time" content="2020-06-26T14:00:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">scrapy初学：爬百度图片</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>爬虫初学：基于Pycharm用scrapy爬取百度图片</h4> 
 <ul><li><a href="#_2" rel="nofollow">初学爬虫</a></li><li><ul><li><a href="#_6" rel="nofollow">选择工具</a></li><li><a href="#_10" rel="nofollow">功能说明</a></li><li><a href="#_13" rel="nofollow">具体内容和代码</a></li><li><a href="#_134" rel="nofollow">踩过的坑</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_2"></a>初学爬虫</h2> 
<p>本人最近初学爬虫的相关知识和实现，这里简单介绍一下对如何用scrapy进行百度图片的抓取，记录一下自己踩过的坑。</p> 
<h3><a id="_6"></a>选择工具</h3> 
<ol><li>Pycharm 2020.1</li><li>Scrapy</li><li>python 3.8</li></ol> 
<h3><a id="_10"></a>功能说明</h3> 
<p>制作百度图片的scrapy爬虫，能够根据关键字下载百度图片并标明序号和进行存储。</p> 
<h3><a id="_13"></a>具体内容和代码</h3> 
<p>由于scrapy工具有出色的表现和良好的口碑，因此一直想学习用scrapy来爬取数据。</p> 
<ol><li>在Pycharm中安装scrapy，运用Pycharm安装库方法即可，打开Pycharm后，点击File-&gt;Setting-&gt;Project<br> Interpreter后，选择弹出对话框的+，从选择包中选择scrapy安装即可。!</li></ol> 
<p><a href="https://img-blog.csdnimg.cn/20200626113901997.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21jemhhbzA1MDI=,size_16,color_FFFFFF,t_70#pic_center" rel="nofollow">在这里插入图片描述</a><br> 其中踩过的坑在后续章节中会写明。</p> 
<ol start="2"><li></ol> 
<p>安装完scrapy, 即可在Pycharm终端处通过命令</p> 
<p>scrapy startproject <em>projectname</em></p> 
<p>建立爬虫项目，生成pipeline, setting等相关文件。这里我写的项目名称是BaiduScrapy。在./BaiduScrapy/Spiders文件夹下的新建爬虫的python文件：BaiduPicSpider.py，作为爬虫的类。<br> 生成的项目目录如下图：<br> <img alt="在这里插入图片描述" src="https://images2.imgbox.com/3e/6f/ib8IepPp_o.jpg"><br> 3.<br> 后续修改以下程序实现目标工程：<br> Settings.py处增加：</p> 
<pre><code class="prism language-python">ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>

MAX_PAGE <span class="token operator">=</span> <span class="token number">30</span>

IMAGES_STORE <span class="token operator">=</span> <span class="token string">'./images'</span>

ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
   <span class="token string">'BaiduScrapy.pipelines.BaiduImagePipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span></code></pre> 
<p>BaiduPicScrapy.py的代码为：</p> 
<pre><code class="prism language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>

<span class="token comment"># Define here the models for image scrape</span>

<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Spider<span class="token punctuation">,</span> Request
<span class="token keyword">from</span> urllib<span class="token punctuation">.</span>parse <span class="token keyword">import</span> quote
<span class="token keyword">from</span> BaiduScrapy<span class="token punctuation">.</span>items <span class="token keyword">import</span> BaiduImageItem
<span class="token keyword">import</span> json

<span class="token keyword">class</span> <span class="token class-name">ImageSpider</span><span class="token punctuation">(</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'image'</span>
    allowed_domain <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'images.baidu.com'</span><span class="token punctuation">]</span>
    start_url <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://image.baidu.com/'</span><span class="token punctuation">]</span>
    url_info <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'url_seq'</span><span class="token punctuation">:</span> <span class="token number">1</span><span class="token punctuation">}</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        images <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> image <span class="token keyword">in</span> images<span class="token punctuation">:</span>
            item <span class="token operator">=</span> BaiduImageItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">try</span><span class="token punctuation">:</span>
                item<span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> image<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'thumbURL'</span><span class="token punctuation">)</span>
                item<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>url_info<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span>
                item<span class="token punctuation">[</span><span class="token string">'url_name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> self<span class="token punctuation">.</span>url_info<span class="token punctuation">[</span><span class="token string">'url_name'</span><span class="token punctuation">]</span>
                self<span class="token punctuation">.</span>url_info<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span>  <span class="token operator">=</span> self<span class="token punctuation">.</span>url_info<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span>  <span class="token operator">+</span> <span class="token number">1</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%s:%s\n"</span> <span class="token operator">%</span> <span class="token punctuation">(</span><span class="token string">"parse"</span><span class="token punctuation">,</span> item<span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> item
            <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>
        <span class="token keyword">pass</span>

    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token string">'queryWord'</span><span class="token punctuation">:</span><span class="token string">'战斗机'</span><span class="token punctuation">,</span><span class="token string">'word'</span><span class="token punctuation">:</span> <span class="token string">'战斗机'</span><span class="token punctuation">}</span>   <span class="token comment">####此处可以根据要求修改关键词</span>
        base_url <span class="token operator">=</span> <span class="token string">'https://image.baidu.com/search/acjson?tn=resultjson_com&amp;ipn=rj&amp;ct=201326592&amp;is=&amp;fp=result&amp;queryWord='</span>
        <span class="token keyword">if</span> data<span class="token punctuation">[</span><span class="token string">'queryWord'</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'战斗机'</span><span class="token punctuation">:</span>               <span class="token comment">####此处可以根据要求修改关键词</span>
            self<span class="token punctuation">.</span>url_info<span class="token punctuation">[</span><span class="token string">'url_name'</span><span class="token punctuation">]</span><span class="token operator">=</span> <span class="token string">'Fighter'</span>       <span class="token comment">####此处可以根据要求修改关键词</span>
        <span class="token keyword">for</span> page <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>settings<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'MAX_PAGE'</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            data<span class="token punctuation">[</span><span class="token string">'pn'</span><span class="token punctuation">]</span> <span class="token operator">=</span> page <span class="token operator">*</span> <span class="token number">30</span>
            url <span class="token operator">=</span> base_url <span class="token operator">+</span> quote<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'queryWord'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'&amp;cl=2&amp;lm=-1&amp;ie=utf-8&amp;oe=utf-8&amp;adpicid=&amp;st=-1&amp;z=&amp;ic=0&amp;hd=&amp;latest=&amp;copyright=&amp;word='</span><span class="token operator">+</span>quote<span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'word'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'&amp;s=&amp;se=&amp;tab=&amp;width=&amp;height=&amp;face=0&amp;istype=2&amp;qc=&amp;nc=1&amp;fr=&amp;expermode=&amp;force=&amp;pn='</span><span class="token operator">+</span>quote<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>data<span class="token punctuation">[</span><span class="token string">'pn'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'&amp;rn=30&amp;gsm=1e'</span>
            <span class="token keyword">yield</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> callback <span class="token operator">=</span> self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span></code></pre> 
<p>items.py的代码修改为：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">BaiduImageItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:MG_URL</span>
    url <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    url_name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    url_seq <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">pass</span></code></pre> 
<p>pipelines.py的代码修改为：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> Request
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>pipelines<span class="token punctuation">.</span>images <span class="token keyword">import</span> ImagesPipeline

<span class="token keyword">class</span> <span class="token class-name">BaiduImagePipeline</span><span class="token punctuation">(</span>ImagesPipeline<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">get_media_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span class="token punctuation">:</span>
        file_meta <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span><span class="token punctuation">}</span>
        file_meta<span class="token punctuation">[</span><span class="token string">'url_name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'url_name'</span><span class="token punctuation">]</span>
        file_meta<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span> <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span>
        <span class="token keyword">yield</span> Request<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'url'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> meta<span class="token operator">=</span>file_meta<span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">file_path</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> info<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        url <span class="token operator">=</span> request<span class="token punctuation">.</span>url
        <span class="token builtin">format</span> <span class="token operator">=</span> url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'.'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        file_meta <span class="token operator">=</span> request<span class="token punctuation">.</span>meta
        file_name <span class="token operator">=</span> file_meta<span class="token punctuation">[</span><span class="token string">'url_name'</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">'_'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span>file_meta<span class="token punctuation">[</span><span class="token string">'url_seq'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token string">'.'</span><span class="token operator">+</span><span class="token builtin">format</span>
        <span class="token keyword">return</span> file_name
</code></pre> 
<ol start="4"><li></ol> 
<p>调试运行程序时，需要配置运行环境，将X:\Program Files\Python\Python38\Lib\site-packages\scrapy\cmdlines.py拷贝到建立项目文件夹中，与scrapy.cfg在相同目录，然后点击Pycharm界面中的Configurations，在弹出对话框中，按以下内容进行配置：</p> 
<p><img alt="在这里插入图片描述" src="https://images2.imgbox.com/8a/54/Ih5UcVxt_o.jpg">然后点击Pycharm中Run-&gt;Run’BaiduPicSpider’即可运行爬虫。</p> 
<h3><a id="_134"></a>踩过的坑</h3> 
<ol><li>在Pycharm安装scrapy可能会出现需要安装VC14 ++的情况，下载Twisted.whl，然后安装即可解决此问题。</li><li>在项目解释器（Project Interpreter）时，可以选择为Python安装目录中的python.exe，因为Pycharm针对每个项目都会建立虚拟环境，如果是自己联系，选择Python安装目录中的python.exe，则安装完所需安装包后，后续项目可以继续用。如果是开发项目，可以针对每个项目用专用的python.exe，这样方便移植。</li></ol>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/bf2e63a4d0219c260f29b6d9114e399b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">多值依赖 模式分解 （学习感想）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5e0389a9f8658750df532bd65aa7f21d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">注册和登录Github</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>