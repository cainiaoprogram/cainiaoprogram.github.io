<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Java 中文分词器 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Java 中文分词器" />
<meta property="og:description" content="CWSS是一个开源的中文分词系统，其中它有两个版本。一个是提供对lucene3.0的支持。一个是纯中文分词，主要是为了方便大家使用。
CWSS1.0由来
一个星期疯狂啃读中科院和paoding分词过程中，突然想开发一套中文分词。
CWSS1.0的特性：
1、采用了中科院的做法，断句处理，原子处理。
2、基于“词库”切词。
3、支持简繁体。
下载地址
http://code.google.com/p/cwss/
演示地址
http://www.agrilink.cn/cwss.jsp
分词效果示例
原文
CWSS是一个开源的，基于java语言开发的轻量级的中文分词工具包,并提供对lucene3.0的支持。目前正在测试阶段,暂不开源代码.测试完毕.在以GPL开源协议发布.
分词后
CWSS/是/一个/开源/的/基于/java/语言/开发/的/轻量级/量级/的/中文/分词/工具/工具包/并/提供/对/lucene3.0/的/支持/目前/前/正在/测试/阶段/暂/不开/源代码/代码/./测试/完毕/.在以/GPL/开源/协议/发布/./ 原文
作者博客：loiy.javaeye.com 电子邮件：lzj0470@163.com 分词后
作者/博客/loiy.javaeye.com/电子/邮件/lzj0470@163.com/ 原文
甘刑一终字第200号
分词后
甘刑一/终字/第/200/号/
原文
北大学生活动
分词后
北大/学生/活动/ 原文
的的确确实实在在
分词后
的的确确/的确/实实在在/实在/
原文
我和你都很棒
分词后
我/和/你/都很/很棒/
原文
永和服装饰品有限公司
分词后
永和/服装/饰品/有限/公司/
原文
你欠我一万九千八百零五毛
分词后
你/欠/我/一万九千八百零五/毛/ 原文
你到底喜不喜欢我
分词后
你/到底/喜/不/喜欢/我/
原文
你说不说，不说打PP
分词后
你/说不说/不说/打/PP/ package wss.analysis.test; import java.io.BufferedReader; import java.io.File; import java.io.FileReader; import java.io.IOException; import java.io.Reader; import org.apache.lucene.analysis.Analyzer; import org.apache.lucene.document.Document; import org." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b18d7a722e54c98fefeb937983f32699/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2010-09-14T11:14:00+08:00" />
<meta property="article:modified_time" content="2010-09-14T11:14:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Java 中文分词器</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>CWSS是一个开源的中文分词系统，其中它有两个版本。一个是提供对lucene3.0的支持。一个是纯中文分词，主要是为了方便大家使用。</p> 
<p> </p> 
<p><strong>CWSS1.0由来</strong><br>    一个星期疯狂啃读中科院和paoding分词过程中，突然想开发一套中文分词。<br>    <br> <strong>CWSS1.0的特性：</strong><br> 1、采用了中科院的做法，断句处理，原子处理。<br> 2、基于“词库”切词。<br> 3、支持简繁体。<br> <br> <strong>下载地址</strong><br> http://code.google.com/p/cwss/</p> 
<p><br> </p> 
<p style="font-weight:bold">演示地址</p> 
<p>http://www.agrilink.cn/cwss.jsp</p> 
<p><strong>分词效果示例</strong><br> 原文<br> CWSS是一个开源的，基于java语言开发的轻量级的中文分词工具包,并提供对lucene3.0的支持。目前正在测试阶段,暂不开源代码.测试完毕.在以GPL开源协议发布.<br> 分词后<br> CWSS/是/一个/开源/的/基于/java/语言/开发/的/轻量级/量级/的/中文/分词/工具/工具包/并/提供/对/lucene3.0/的/支持/目前/前/正在/测试/阶段/暂/不开/源代码/代码/./测试/完毕/.在以/GPL/开源/协议/发布/./ <br> <br> 原文<br> 作者博客：loiy.javaeye.com 电子邮件：lzj0470@163.com <br> 分词后<br> 作者/博客/loiy.javaeye.com/电子/邮件/lzj0470@163.com/ <br> <br> 原文<br> 甘刑一终字第200号<br> 分词后<br> 甘刑一/终字/第/200/号/<br> <br> 原文<br> 北大学生活动<br> 分词后<br> 北大/学生/活动/ <br> <br> 原文<br> 的的确确实实在在<br> 分词后<br> 的的确确/的确/实实在在/实在/<br> <br> 原文<br> 我和你都很棒<br> 分词后<br> 我/和/你/都很/很棒/<br> <br> 原文<br> 永和服装饰品有限公司<br> 分词后<br> 永和/服装/饰品/有限/公司/<br> <br> 原文<br> 你欠我一万九千八百零五毛<br> 分词后<br> 你/欠/我/一万九千八百零五/毛/ <br> <br> 原文<br> 你到底喜不喜欢我<br> 分词后<br> 你/到底/喜/不/喜欢/我/<br> <br> 原文<br> 你说不说，不说打PP<br> 分词后<br> 你/说不说/不说/打/PP/ </p> 
<p><textarea name="code" class="java">package wss.analysis.test;
import java.io.BufferedReader;
import java.io.File;
import java.io.FileReader;
import java.io.IOException;
import java.io.Reader;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.index.CorruptIndexException;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.queryParser.ParseException;
import org.apache.lucene.queryParser.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.store.LockObtainFailedException;
import org.apache.lucene.util.Version;
import wss.analysis.analyzer.wssAnalyzer;
public class testLucene {
	private Analyzer analyzer = new wssAnalyzer();
	
	/**
	 *  content文件夹存在两个文件。文件内容分别是
	 *  1、朝鲜队小组必出线内幕：赛前全队必读知音和故事会
	 *  2、CWSS是一个开源的，基于java语言开发的轻量级的中文分词工具包,并提供对lucene3.0的支持。目前正在测试阶段,暂不开源代码.测试完毕. 在以GPL开源协议发布.
	 *  3、世界杯朝鲜输掉了
	 */
	private String getString(Reader input) throws IOException{
		BufferedReader buf;
		buf = new BufferedReader(input);
		String str;
		StringBuffer sb = new StringBuffer();
		while ((str = buf.readLine()) != null) {        
			sb.append(str);    
	    }
		str = sb.toString();
		sb = null;
		return str;
	}
	
	private void index() throws CorruptIndexException, LockObtainFailedException, IOException{
		 File indexDir=new File("D:/luceneIndex/");  
		 //需要建立索引的文档集合的位置  
		  File docDir = new File("D:/content/");   
		 //创建索引器(核心)  
		 IndexWriter standardWriter = new IndexWriter(FSDirectory.open(indexDir), analyzer, true , IndexWriter.MaxFieldLength.LIMITED);//new IndexWriter(FSDirectory.open(indexDir),analyzer, true, IndexWriter.MaxFieldLength.LIMITED);           
		 //不建立复合式索引文件，默认的情况下是复合式的索引文件  
		 standardWriter.setUseCompoundFile(false);  
		 //为原文档集合中的每个文档的相关信息建立索引  
		 for (File fileSrc : docDir.listFiles()) {     
		         //Lucene的文档结构  
		         Document doc = new Document();                       
		         //文件名称，可查询，不分词  
		         String fileName=fileSrc.getName().substring(0,fileSrc.getName().indexOf("."));
		         doc.add(new Field("name",fileName, Field.Store.YES, Field.Index.NOT_ANALYZED));    
		          //文件路径，可查询，不分词  
		         String filePath=fileSrc.getPath();  
		         doc.add(new Field("path", filePath, Field.Store.YES, Field.Index.NOT_ANALYZED));  
		         //文件内容，需要检索
		         doc.add(new Field("content", getString(new FileReader(fileSrc)),Field.Store.YES,Field.Index.ANALYZED));              
		         //使用索引器对Document文档建索引  
		        standardWriter.addDocument(doc);    
		 }    
		 //关闭索引器，并写入磁盘索引文件  
		 standardWriter.optimize();    
		 standardWriter.close();  
	}
	
	private void search(String keyword){
		File indexDir=new File("D:/luceneIndex/"); 
		Directory directory;
		IndexSearcher isearcher = null;
		//实例化搜索器   
		try {
			directory = FSDirectory.open(indexDir);
			isearcher = new IndexSearcher(directory);
			QueryParser parser = new QueryParser(Version.LUCENE_CURRENT, "content",
					analyzer);
			//使用IKQueryParser查询分析器构造Query对象
			Query query = parser.parse(keyword);
			
			//搜索相似度最高的5条记录
			TopDocs topDocs = isearcher.search(query, 2);
			System.out.println("命中：" + topDocs.totalHits);
			//输出结果
			ScoreDoc[] scoreDocs = topDocs.scoreDocs;
			for (int i = 0; i &lt; topDocs.totalHits; i++){
				Document targetDoc = isearcher.doc(scoreDocs[i].doc);
				System.out.println("内容：" + targetDoc.toString());
			}
		} catch (CorruptIndexException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (IOException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		} catch (ParseException e) {
			// TODO Auto-generated catch block
			e.printStackTrace();
		}
	}
	public static void main(String[] args) throws IOException {
		testLucene lucene = new testLucene();
		lucene.index();
		lucene.search("java");
		lucene.search("朝鲜");
	}
}
建立索引与搜索结果。
命中：1
内容：Document&lt;stored,indexed&lt;name:2&gt; stored,indexed&lt;path:D:/content/2.txt&gt; stored,indexed,tokenized&lt;content:CWSS是一个开源的，基于java语言开发的轻量级的中文分词工具包,并提供对lucene3.0的支持。目前正在测试阶段,暂不开源代码.测试完毕. 在以GPL开源协议发布.&gt;&gt;
命中：2
内容：Document&lt;stored,indexed&lt;name:3&gt; stored,indexed&lt;path:D:/content/3.txt&gt; stored,indexed,tokenized&lt;content:世界杯朝鲜输掉了&gt;&gt;
内容：Document&lt;stored,indexed&lt;name:1&gt; stored,indexed&lt;path:D:/content/1.txt&gt; stored,indexed,tokenized&lt;content:朝鲜队小组必出线内幕：赛前全队必读知音和故事会&gt;&gt;
</textarea> </p> 
<p> </p> 
<p>欢迎大家使用。如果你认为分词不好，可以给我留言，我会尽量补修不足的地方。如果你认为不错，也可以发信息给我，鼓励一下下。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3804bdf0ca992cfca0c5f9d538f1cd95/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">fftw的使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/940f6188176c99e9ac0f4c2d1b9c4631/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">找济南 .Net开发的 SOHO 工作者，长期合作</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>