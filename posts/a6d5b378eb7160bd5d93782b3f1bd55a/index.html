<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>libevent http server multithread - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="libevent http server multithread" />
<meta property="og:description" content="Libevent是一个轻量级高效的开源高性能网络库，很多公司都基于该网络库进行开发，我之前参与过的几个的项目客户端的网络底层以及服务端的网络库都是基于该网络库的开发，并且取得良好的性能，并未遇到明显的性能瓶颈。我相信很多大公司也是跟我一样做出相同明智的选择。因此，基于该库进行一系列的扩展也是理所当然。前几天我们客户提出了需求，需要服务器提供http服务，以便接受各种http的请求，这种http请求有其特殊性，一般是短链接，瞬间流量较大，需要抵抗瞬间峰值流量。因为我们服务器是基于libevent的开发，很自然想到了利用libevent的原始库进行支持，因为他底层是支持http服务器的一些接口，很自然写起来代码。传统的代码还是类似的写法，都是基于单线程的，意思是说，一个线程监听在ip以及对外开放的http端口上。伪代码如下：
short http_port = 8081;
char *http_addr = &#34;127.0.0.1&#34;;
if (argc &gt; 1)
{
strcpy(filename,argv[1]);
printf(&#34;Using %s\n&#34;,filename);
}
else
{
strcpy(filename,DEFAULT_FILE);
}
struct event_base * base = event_base_new();
struct evhttp * http_server = evhttp_new(base);
if(!http_server)
{
return -1;
}
int ret = evhttp_bind_socket(http_server,http_addr,http_port);
if(ret!=0)
{
return -1;
}
evhttp_set_gencb(http_server, generic_handler, NULL);
read_file();
load_file(base);
printf(&#34;http server start OK! \n&#34;);
event_base_dispatch(base);
evhttp_free(http_server); 以上基本上能满足很多初级用户需求，也是在网上能找到最多的处理方法，但是并不能得到大多数用户满意，因为跑在一台32核，带宽千兆的一台服务器上，只有一个线程接受前端大量的http请求，是一种浪费，也不能给发薪水的老板交代。所以很自然我想到要提高性能，以便抵抗更大的http请求的压力。我的设想是这样的，前端多个线程监听http的端口上，接受各种http的请求，一旦有新的http请求来了，其中一个线程立即接受处理，并且解析请求的性质以及请求的合法性。处理好之后，立即交给一个任务线程池，待任务线程处理好任务之后，立即返回给原线程处理以reply给http请求的客户端。如下图所示：
之所以这样设计的原因是因为
1. 多个线程监听在这个端口上，可以达到同时能处理多个http请求，而不像单线程的条件，同时只能处理一个http请求
2. 当一个线程处理http请求时候，解析数值，交出任务给任务处理线程之后，马上可以接着处理新的http请求，这样加大了http请求的处理性能
这两点是我认为可以大幅提高处理http请求性能的关键所在，所以势必要修改老的逻辑处理方式，我认为做到我说的目的，有两个难点
但是我的做法有两点比较麻烦
第一：如何利用多线程监听同一个端口上，而不至于出现线程错误。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a6d5b378eb7160bd5d93782b3f1bd55a/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2017-11-23T20:28:31+08:00" />
<meta property="article:modified_time" content="2017-11-23T20:28:31+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">libevent http server multithread</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p></p> 
<p>Libevent是一个轻量级高效的开源高性能网络库，很多公司都基于该网络库进行开发，我之前参与过的几个的项目客户端的网络底层以及服务端的网络库都是基于该网络库的开发，并且取得良好的性能，并未遇到明显的性能瓶颈。我相信很多大公司也是跟我一样做出相同明智的选择。因此，基于该库进行一系列的扩展也是理所当然。前几天我们客户提出了需求，需要服务器提供http服务，以便接受各种http的请求，这种http请求有其特殊性，一般是短链接，瞬间流量较大，需要抵抗瞬间峰值流量。因为我们服务器是基于libevent的开发，很自然想到了利用libevent的原始库进行支持，因为他底层是支持http服务器的一些接口，很自然写起来代码。传统的代码还是类似的写法，都是基于单线程的，意思是说，一个线程监听在ip以及对外开放的http端口上。伪代码如下：</p> 
<p><span style="color:blue">short</span>          http_port = <span style="color:purple"> 8081</span>;</p> 
<p><span style="color:blue">char</span>          *http_addr = <span style="color:maroon"> "127.0.0.1"</span>;</p> 
<p><span style="color:blue">if</span> (argc &gt; <span style="color:purple">1</span>)</p> 
<p>{<!-- --></p> 
<p>strcpy(filename,argv[<span style="color:purple">1</span>]);</p> 
<p>printf(<span style="color:maroon">"Using %s\n"</span>,filename);</p> 
<p>}</p> 
<p><span style="color:blue">else</span></p> 
<p>{<!-- --></p> 
<p>strcpy(filename,DEFAULT_FILE);</p> 
<p>}</p> 
<p><span style="color:blue">struct</span> event_base * <span style="color:blue">base</span> = event_base_new();</p> 
<p><span style="color:blue">struct</span> evhttp * http_server = evhttp_new(<span style="color:blue">base</span>);</p> 
<p><span style="color:blue">if</span>(!http_server)</p> 
<p>{<!-- --></p> 
<p><span style="color:blue">return</span> -<span style="color:purple">1</span>;</p> 
<p>}</p> 
<p><span style="color:blue">int</span> ret = evhttp_bind_socket(http_server,http_addr,http_port);</p> 
<p><span style="color:blue">if</span>(ret!=<span style="color:purple">0</span>)</p> 
<p>{<!-- --></p> 
<p><span style="color:blue">return</span> -<span style="color:purple">1</span>;</p> 
<p>}</p> 
<p>evhttp_set_gencb(http_server, generic_handler, NULL);</p> 
<p>read_file();</p> 
<p>load_file(<span style="color:blue">base</span>);</p> 
<p>printf(<span style="color:maroon">"http server start OK! \n"</span>);</p> 
<p>event_base_dispatch(<span style="color:blue">base</span>);</p> 
<p>evhttp_free(http_server); </p> 
<p> </p> 
<p>以上基本上能满足很多初级用户需求，也是在网上能找到最多的处理方法，但是并不能得到大多数用户满意，因为跑在一台32核，带宽千兆的一台服务器上，只有一个线程接受前端大量的http请求，是一种浪费，也不能给发薪水的老板交代。所以很自然我想到要提高性能，以便抵抗更大的http请求的压力。我的设想是这样的，前端多个线程监听http的端口上，接受各种http的请求，一旦有新的http请求来了，其中一个线程立即接受处理，并且解析请求的性质以及请求的合法性。处理好之后，立即交给一个任务线程池，待任务线程处理好任务之后，立即返回给原线程处理以reply给http请求的客户端。如下图所示：</p> 
<p> </p> 
<p>之所以这样设计的原因是因为</p> 
<p>1.  多个线程监听在这个端口上，可以达到同时能处理多个http请求，而不像单线程的条件，同时只能处理一个http请求</p> 
<p>2.  当一个线程处理http请求时候，解析数值，交出任务给任务处理线程之后，马上可以接着处理新的http请求，这样加大了http请求的处理性能</p> 
<p>这两点是我认为可以大幅提高处理http请求性能的关键所在，所以势必要修改老的逻辑处理方式，我认为做到我说的目的，有两个难点</p> 
<p>但是我的做法有两点比较麻烦</p> 
<p>第一：如何利用多线程监听同一个端口上，而不至于出现线程错误。</p> 
<p>第二：如何将线程交给任务线程处理，并且当任务处理好之后，能轻松交回给原先http请求事件触发线程处理，而不至于给别的线程，任何别的线程处理，必然会导致内部线程冲突紊乱，直接导致崩溃。</p> 
<p>我们换了一个思考方式，我们事先创建好一个tcp的对应的fd，并且监听在http服务器的ip和端口上，该tcp的fd是我们的关键。截取了部分代码：</p> 
<p>evutil_socket_t  sock_fd = ::socket(AF_INET,SOCK_STREAM, 0); //创建tcp的fd</p> 
<p>evutil_make_socket_nonblocking(fd);//设置非阻塞</p> 
<p>InetAddress addr(ip, port); //设置监听地址和端口</p> 
<p>Socket::bind(sock_fd, addr.get_sock_addr() );//bind刚刚创建的fd以及地址</p> 
<p>Socket::listen(sock_fd, 10);//创建监听</p> 
<p>监听sock_fd之后，我们就可以创建多个evhttp来接受同一个sock_fd的各种http请求，并且每一个evhttp从属于一个线程</p> 
<p>struct evhttp* httpd = evhttp_new(loop-&gt;base);//创建新的evhttp于当前线程相关，即唯一一个线程处理所有的evhttp线程事件</p> 
<p>evhttp_accept_socket(httpd, sock_fd);//将evhttp接受sock_fd的各种请求</p> 
<p>evhttp_set_allowed_methods(httpd,EVHTTP_REQ_GET|EVHTTP_REQ_PUT|EVHTTP_REQ_DELETE);//接受各种http类型的请求</p> 
<p>evhttp_set_gencb(httpd, default_generic_handler, this);//设置http请求的回调函数</p> 
<p>接下来的工作就是如何将多个evhttp绑定到不同的线程上，以及将事件线程分发到任务线程以及返回给原事件现场，我这里使用的是muduo库的的runinloop系列函数，可以很轻松的将线程交付给另外一个线程去执行。并且在抛出任务的时候，带上原线程的线程信息，以方便一会能找回到原线程上。</p> 
<p>在这种条件下我做了性能测试，利用jmeter做的性能测试，机器配置并不是很好，基本上接受是在20w+每秒的http请求，满足我们的需求是毫无压力。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6c5d8578470abc61d8a5f60b0b1480c4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Fabric 远端 批量部署</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ff9cf978603e2d482a9b2d0ec2503e5e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">logstash使用之json输入输出</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>