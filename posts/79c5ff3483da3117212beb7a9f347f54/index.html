<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>HRNet人体关键点检测 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="HRNet人体关键点检测" />
<meta property="og:description" content="Deep High-Resolution Representation Learning for Human Pose Estimation (CVPR 2019 oral)
文章地址：https://arxiv.org/abs/1902.09212
源码：GitHub - leoxiaobin/deep-high-resolution-net.pytorch: The project is an official implementation of our CVPR2019 paper &#34;Deep High-Resolution Representation Learning for Human Pose Estimation&#34;
1、 引言 HRNet（High-Resolution Net）针对2D人体姿态估计（Human Pose Estimation或Keypoint Detection）任务提出的，且该网络主要是针对单一个体的姿态评估。即网络输入只能是单个人。人体姿态估计主要的应用场景为：人体行为动作识别、人机交互、动画制作（比如根据人体的关键点信息生成对应卡通人物的动作）等等。
对于Human Pose Estimation任务，现在基于深度学习的方法主要有两种：
1）基于regressing的方式，即直接预测每个关键点的位置坐标。
2）基于heatmap的方式，即针对每个关键点预测一张热力图（预测出现在每个位置上的分数）。
注：当前检测效果最好的一些方法基本都是基于heatmap的，所以HRNet也是采用基于heatmap的方式。
2、HRNet网络结构 现在存在的大多数方法，都是提取图象的低分辨率特征，然后恢复成高分辨率特征进行预测。我们提出的方法，在整个网络中，主要以高分辨率为主。论文的核心思想就是不断地去融合不同尺度上的信息，也就是论文中所说的Exchange Blocks。
HRNet的架构。它由并行的高分辨率到低分辨率的子网组成，在多分辨率子网之间进行重复的信息交换(多尺度融合)。水平方向和垂直方向分别对应网络的深度和特征图的尺度。
3、相关工作 传统的单人位姿估计方法大多采用概率图形模型或图形结构模型，最近通过深度学习，自动提取特征方式，相对于传统的算法，提升是比较明显的。现在深度学习提出的解决方式主要分为两类，分别为关键点位置回归，以及估算关键点热图。
大多数网络都包含了一个主干网络，类似于分类网络一样，其降低了分辨率。以及另外一个主干网络，其产生与其输入具有相同分辨率的特征图。然后利用该特征去回归关键点或者估算热图。其主要是采用了分辨率 high-to-low 以及 low-to-high 的结构。可能增加多尺度融合和中间(深层)监督。
4、实现方法 人类姿态估算，关键点检测，输入为一张行人图像，输出为与关键点个数相同的特征图数量，由每个特征图预测对应的关键点。首先使用2个strided的卷积，减少输入图像的分辨率，获得初步特征图，然后把该特征图作为一个主体网络的输入，该主体网络的输出和输入的分辨率一样，其会其估算关键点的heatmaps。
4.1、连续多分辨率子网络 有的位姿估计网络是通过串联高分辨率子网来建立的，每个子网形成一个stage，由一系列卷积组成，并且在相邻的子网之间有一个下样本层来将分辨率减半。
4.2、并行多分辨率子网 首先我们在第一个 stage 开始了一个高分辨率的网络分支，然后逐步增加高分辨率到低分辨率的子网路，形成一个新的 stages，并将多分辨率子网并行连接。因此，后一阶段并行子网的分辨率由前一阶段的分辨率和一个更低的分辨率组成，一个包含4个并行子网络的网络结构示例如下：
4.3、重复的多尺度融合 我们引入了平行网络信息交换单元，比如每个子网络重复接受来自其他平行子网络的信息。下面是一个例子，展示了信息交换的方案。我们将第三 stage 分为几个(例如3个)交换模块，每个模块由3个并行卷积单元和一个跨并行单元的交换单元组成，其结构如下：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/79c5ff3483da3117212beb7a9f347f54/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-28T12:53:13+08:00" />
<meta property="article:modified_time" content="2022-08-28T12:53:13+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">HRNet人体关键点检测</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>        Deep High-Resolution Representation Learning for Human Pose Estimation (CVPR 2019 oral)</p> 
<p>        文章地址：<a href="https://arxiv.org/abs/1902.09212" rel="nofollow" title="https://arxiv.org/abs/1902.09212">https://arxiv.org/abs/1902.09212</a></p> 
<p>        源码：<a href="https://github.com/leoxiaobin/deep-high-resolution-net.pytorch" title='GitHub - leoxiaobin/deep-high-resolution-net.pytorch: The project is an official implementation of our CVPR2019 paper "Deep High-Resolution Representation Learning for Human Pose Estimation"'>GitHub - leoxiaobin/deep-high-resolution-net.pytorch: The project is an official implementation of our CVPR2019 paper "Deep High-Resolution Representation Learning for Human Pose Estimation"</a></p> 
<h3>1、 引言</h3> 
<p>        HRNet（High-Resolution Net）针对2D人体姿态估计（Human Pose Estimation或Keypoint Detection）任务提出的，且该网络主要是针对单一个体的姿态评估。即网络输入只能是单个人。人体姿态估计主要的应用场景为：人体行为动作识别、人机交互、动画制作（比如根据人体的关键点信息生成对应卡通人物的动作）等等。</p> 
<p class="img-center"><img alt="" height="147" src="https://images2.imgbox.com/2c/ec/Sg5CHGHC_o.png" width="460"></p> 
<p>        对于Human Pose Estimation任务，现在基于深度学习的方法主要有两种：</p> 
<p>        1）基于regressing的方式，即直接预测每个关键点的位置坐标。</p> 
<p>        2）基于heatmap的方式，即针对每个关键点预测一张热力图（预测出现在每个位置上的分数）。</p> 
<p>       <span style="color:#fe2c24;"> 注：当前检测效果最好的一些方法基本都是基于heatmap的，所以HRNet也是采用基于heatmap的方式。</span></p> 
<h3>2、HRNet网络结构</h3> 
<p>        现在存在的大多数方法，都是提取图象的低分辨率特征，然后恢复成高分辨率特征进行预测。我们提出的方法，在整个网络中，主要以高分辨率为主。论文的核心思想就是不断地去融合不同尺度上的信息，也就是论文中所说的Exchange Blocks。</p> 
<p class="img-center"><img alt="" height="233" src="https://images2.imgbox.com/b4/e4/7vUL1Nvu_o.png" width="460"></p> 
<p>        HRNet的架构。它由并行的高分辨率到低分辨率的子网组成，在多分辨率子网之间进行重复的信息交换(多尺度融合)。水平方向和垂直方向分别对应网络的深度和特征图的尺度。</p> 
<h3>3、相关工作</h3> 
<p>        传统的单人位姿估计方法大多采用概率图形模型或图形结构模型，最近通过深度学习，自动提取特征方式，相对于传统的算法，提升是比较明显的。现在深度学习提出的解决方式主要分为两类，分别为关键点位置回归，以及估算关键点热图。</p> 
<p>        大多数网络都包含了一个主干网络，类似于分类网络一样，其降低了分辨率。以及另外一个主干网络，其产生与其输入具有相同分辨率的特征图。然后利用该特征去回归关键点或者估算热图。其主要是采用了分辨率 high-to-low 以及 low-to-high 的结构。可能增加多尺度融合和中间(深层)监督。</p> 
<h3>4、实现方法</h3> 
<p>        人类姿态估算，关键点检测，输入为一张行人图像，输出为与关键点个数相同的特征图数量，由每个特征图预测对应的关键点。首先使用2个strided的卷积，减少输入图像的分辨率，获得初步特征图，然后把该特征图作为一个主体网络的输入，该主体网络的输出和输入的分辨率一样，其会其估算关键点的heatmaps。</p> 
<h4>4.1、连续多分辨率子网络</h4> 
<p>        有的位姿估计网络是通过串联高分辨率子网来建立的，每个子网形成一个stage，由一系列卷积组成，并且在相邻的子网之间有一个下样本层来将分辨率减半。</p> 
<p class="img-center"><img alt="" height="145" src="https://images2.imgbox.com/57/14/rHmmRe00_o.png" width="460"></p> 
<h4>4.2、并行多分辨率子网</h4> 
<p>        首先我们在第一个 stage 开始了一个高分辨率的网络分支，然后逐步增加高分辨率到低分辨率的子网路，形成一个新的 stages，并将多分辨率子网并行连接。因此，后一阶段并行子网的分辨率由前一阶段的分辨率和一个更低的分辨率组成，一个包含4个并行子网络的网络结构示例如下：</p> 
<p class="img-center"><img alt="" height="98" src="https://images2.imgbox.com/90/93/AQpaAE9Q_o.png" width="280"></p> 
<h4>4.3、重复的多尺度融合</h4> 
<p>        我们引入了平行网络信息交换单元，比如每个子网络重复接受来自其他平行子网络的信息。下面是一个例子，展示了信息交换的方案。我们将第三 stage 分为几个(例如3个)交换模块，每个模块由3个并行卷积单元和一个跨并行单元的交换单元组成，其结构如下：</p> 
<p class="img-center"><img alt="" height="92" src="https://images2.imgbox.com/d4/a3/BayrcAJm_o.png" width="420"></p> 
<p>        卷积实现如下形式：</p> 
<p class="img-center"><img alt="" height="260" src="https://images2.imgbox.com/8d/68/phXWKOWr_o.png" width="460"></p> 
<h3>5、损失设计</h3> 
<p>        均方差。一些细节，在真值周围做高斯运算得到点的扩展，防止仅有一个关键点时训练难收敛的问题。</p> 
<h3>6、评价指标</h3> 
<p>        数据集使用coco集。标准的量化评估是基于 Object Keypoint Similarity (OKS)，计算公式如下：</p> 
<p class="img-center"><img alt="" height="61" src="https://images2.imgbox.com/a1/ef/ON1UtHZg_o.png" width="320"></p> 
<p>        其中，di是预测值与真实值的欧式距离，vi表示真值是否可见标志。s是目标缩放的比例，ki是一个控制衰减的每个关键点长度。</p> 
<p>        Training： 按照等比例，将人体检测结果扩展到高度：宽度 = 4 ：3，然后剪裁到固定尺寸256×192或者384×288。</p> 
<p>        使用了 Adam 优化器，基础学习率设置为1e-3，在迭代170个 epochs 以及 200 个 epoch 进行10倍的学习率衰减。训练过程在210个epochs 内结束。</p> 
<p>        Testing： 使用2个阶段的方式 - 使用person检测器检测person实例，然后预测检测关键点。对于验证集和测试开发集，我们使SimpleBaseline2提供的person检测器。计算了原图，和水平反转图估算出来 heatmap 的平均值。每个关键点的位置，都是通过调整最高热值来进行判断的。</p> 
<p><strong>结果：</strong></p> 
<p class="img-center"><img alt="" height="295" src="https://images2.imgbox.com/54/40/ruAqfxx5_o.png" width="560"></p> 
<p>        论文中更多的是思想描述， 更多细节可查看代码获得，下面是模型结构：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/74/0e/Qo0icIof_o.png"></p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3d7c5087ba9cdd3276f8d21a6d2cf528/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">安卓TextView实现文字跑马灯(失去焦点可用)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ccc5ad2a1e4076d05557015b19584523/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">项目中遇到的LocalDateTime时间格式转换问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>