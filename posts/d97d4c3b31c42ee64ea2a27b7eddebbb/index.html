<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>XGBoost与GBDT和LGBM区别 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="XGBoost与GBDT和LGBM区别" />
<meta property="og:description" content="XGBoost的优缺点： 与GBDT相比： 1）GBDT以传统CART作为基分类器，而XGBoost支持线性分类器，相当于引入L1和L2正则化项的逻辑回归（分类问题）和线性回归（回归问题）；
2）GBDT在优化时只用到一阶导数，XGBoost对代价函数做了二阶泰勒展开，引入了一阶导数和二阶导数，一方面增加了精度，另一方面支持自定义的损失函数，只要是能满足二阶连续可导的函数均可以作为损失函数；
3）XGBoost在损失函数中引入正则化项，用于控制模型的复杂度。正则化项包含全部叶子节点的个数gammaT，以及每个叶子节点输出的结果score（wj）的L2模的平方和1/2lambda||w||^2。从Bias-variance tradeoff角度考虑，正则项降低了模型的方差，防止模型过拟合，这也是xgboost优于传统GBDT的一个特性。其中gamma与lambda需要进行调参。
4）当样本存在缺失值时，xgBoosting能自动学习分裂方向，即XGBoost对样本缺失值不敏感，该处理源于稀疏感知算法，在初次计算Gain时剔除缺失值，然后将缺失值先后加入不同方向节点，最终取Gain值最优的结果。
5）XGBoost借鉴RF的做法，支持列抽样，这样不仅能防止过拟合，还能降低计算，这也是xgboost异于传统gbdt的一个特性。
6）XGBoost在每次迭代之后，会将叶子节点的权重乘上一个学习率（相当于XGBoost中的eta，论文中的Shrinkage），主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点；
7）XGBoost工具支持并行，但并行不是tree粒度的并行，XGBoost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值），XGBoost的并行是在特征粒度上的。XGBoost在训练之前，预先对数据进行了排序，然后保存为(block)结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个块结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行；
8）可并行的近似直方图算法，树结点在进行分裂时，需要计算每个节点的增益，若数据量较大，对所有节点的特征进行排序，遍历的得到最优分割点，这种贪心法异常耗时，这时引进近似直方图算法，用于生成高效的分割点，首先根据特征分布的百分位数提出候选分割点，基于候选分割点，将连续特征映射到各个桶里，最后根据聚合后的分割点效果找出最优的分割点，为了限制树的增长，引入阈值，当增益大于阈值时，进行分裂；
9）XGBoost的原生语言为C/C&#43;&#43;，这是也是它训练速度快的一个原因。
与LightGBM相比: 1）XGBoost采用预排序，在迭代之前，对结点的特征做预排序（其中预排续的结果会存储到内存中，保存排序的数据及其对应的节点，因此当数据量增大时，其内存占用量大），遍历选择最优分割点，数据量大时，贪心法耗时；LightGBM方法采用histogram算法，占用的内存低，数据分割的复杂度更低，但是不能找到最精确的数据分割点；
2）XGBoost采用level-wise生成决策树策略，同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合，但很多叶子节点的分裂增益较低，没必要进行更进一步的分裂，这就带来了不必要的开销；LightGBM采用leaf-wise生长策略，每次从当前叶子中选择增益最大的叶子进行分裂，如此循环，但会生长出更深的决策树，产生过拟合，因此 LightGBM 在leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合）。另一个比较巧妙的优化是 histogram 做差加速。一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。
参考文献：
(88条消息) XGBoost的基本原理_Y学习使我快乐V的博客-CSDN博客_xgboost的原理
(88条消息) 集成学习之Xgboost_Aliert的博客-CSDN博客
(88条消息) GBDT算法的升级--XGBoost与LightGBM算法_CquptDJ的博客-CSDN博客_efb算法" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d97d4c3b31c42ee64ea2a27b7eddebbb/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-10-10T17:57:44+08:00" />
<meta property="article:modified_time" content="2022-10-10T17:57:44+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">XGBoost与GBDT和LGBM区别</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>XGBoost的优缺点： 与GBDT相比： 1）GBDT以传统CART作为基分类器，而XGBoost支持线性分类器，相当于引入L1和L2正则化项的逻辑回归（分类问题）和线性回归（回归问题）；</p> 
<p>2）GBDT在优化时只用到一阶导数，XGBoost对代价函数做了二阶泰勒展开，引入了一阶导数和二阶导数，一方面增加了精度，另一方面支持自定义的损失函数，只要是能满足二阶连续可导的函数均可以作为损失函数；</p> 
<p>3）XGBoost在损失函数中引入正则化项，用于控制模型的复杂度。正则化项包含全部叶子节点的个数gamma<em>T，以及每个叶子节点输出的结果score（wj）的L2模的平方和1/2lambda</em>||w||^2。从Bias-variance tradeoff角度考虑，正则项降低了模型的方差，防止模型过拟合，这也是xgboost优于传统GBDT的一个特性。其中gamma与lambda需要进行调参。</p> 
<p>4）当样本存在缺失值时，xgBoosting能自动学习分裂方向，即XGBoost对样本缺失值不敏感，该处理源于稀疏感知算法，在初次计算Gain时剔除缺失值，然后将缺失值先后加入不同方向节点，最终取Gain值最优的结果。</p> 
<p>5）XGBoost借鉴RF的做法，支持列抽样，这样不仅能防止过拟合，还能降低计算，这也是xgboost异于传统gbdt的一个特性。</p> 
<p>6）XGBoost在每次迭代之后，会将叶子节点的权重乘上一个学习率（相当于XGBoost中的eta，论文中的Shrinkage），主要是为了削弱每棵树的影响，让后面有更大的学习空间。实际应用中，一般把eta设置得小一点，然后迭代次数设置得大一点；</p> 
<p>7）XGBoost工具支持并行，但并行不是tree粒度的并行，XGBoost也是一次迭代完才能进行下一次迭代的（第t次迭代的代价函数里包含了前面t-1次迭代的预测值），XGBoost的并行是在特征粒度上的。XGBoost在训练之前，预先对数据进行了排序，然后保存为(block)结构，后面的迭代中重复地使用这个结构，大大减小计算量。这个块结构也使得并行成为了可能，在进行节点的分裂时，需要计算每个特征的增益，最终选增益最大的那个特征去做分裂，那么各个特征的增益计算就可以开多线程进行；</p> 
<p>8）可并行的近似直方图算法，树结点在进行分裂时，需要计算每个节点的增益，若数据量较大，对所有节点的特征进行排序，遍历的得到最优分割点，这种贪心法异常耗时，这时引进近似直方图算法，用于生成高效的分割点，首先根据特征分布的百分位数提出候选分割点，基于候选分割点，将连续特征映射到各个桶里，最后根据聚合后的分割点效果找出最优的分割点，为了限制树的增长，引入阈值，当增益大于阈值时，进行分裂；</p> 
<p>9）XGBoost的原生语言为C/C++，这是也是它训练速度快的一个原因。</p> 
<p>与LightGBM相比: 1）XGBoost采用预排序，在迭代之前，对结点的特征做预排序（其中预排续的结果会存储到内存中，保存排序的数据及其对应的节点，因此当数据量增大时，其内存占用量大），遍历选择最优分割点，数据量大时，贪心法耗时；LightGBM方法采用histogram算法，占用的内存低，数据分割的复杂度更低，但是不能找到最精确的数据分割点；</p> 
<p>2）XGBoost采用level-wise生成决策树策略，同时分裂同一层的叶子，从而进行多线程优化，不容易过拟合，但很多叶子节点的分裂增益较低，没必要进行更进一步的分裂，这就带来了不必要的开销；LightGBM采用leaf-wise生长策略，每次从当前叶子中选择增益最大的叶子进行分裂，如此循环，但会生长出更深的决策树，产生过拟合，因此 LightGBM 在leaf-wise之上增加了一个最大深度的限制，在保证高效率的同时防止过拟合）。另一个比较巧妙的优化是 histogram 做差加速。一个容易观察到的现象：一个叶子的直方图可以由它的父亲节点的直方图与它兄弟的直方图做差得到。</p> 
<p></p> 
<p>参考文献：</p> 
<p><a href="https://blog.csdn.net/qq_24519677/article/details/81809157?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166538204716782395352633%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=166538204716782395352633&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-4-81809157-null-null.142%5Ev52%5Econtrol,201%5Ev3%5Econtrol_2&amp;utm_term=xgboost%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86&amp;spm=1018.2226.3001.4187" title="(88条消息) XGBoost的基本原理_Y学习使我快乐V的博客-CSDN博客_xgboost的原理">(88条消息) XGBoost的基本原理_Y学习使我快乐V的博客-CSDN博客_xgboost的原理</a></p> 
<p><a href="https://blog.csdn.net/qq_38375203/article/details/124859022?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166538295116800184172348%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=166538295116800184172348&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-6-124859022-null-null.142%5Ev52%5Econtrol,201%5Ev3%5Econtrol_2&amp;utm_term=xgBoost%E4%B8%BA%E4%BB%80%E4%B9%88%E8%83%BD%E8%87%AA%E5%8A%A8%E5%AD%A6%E4%B9%A0%E5%88%86%E8%A3%82%E6%96%B9%E5%90%91&amp;spm=1018.2226.3001.4187" title="(88条消息) 集成学习之Xgboost_Aliert的博客-CSDN博客">(88条消息) 集成学习之Xgboost_Aliert的博客-CSDN博客</a></p> 
<p><a href="https://blog.csdn.net/qq_44694861/article/details/114379006?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522166538320616800180699820%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=166538320616800180699820&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~rank_v31_ecpm-6-114379006-null-null.142%5Ev52%5Econtrol,201%5Ev3%5Econtrol_2&amp;utm_term=xgboost%E7%9A%84%E7%A8%80%E7%96%8F%E6%84%9F%E7%9F%A5%E7%AE%97%E6%B3%95&amp;spm=1018.2226.3001.4187" title="(88条消息) GBDT算法的升级--XGBoost与LightGBM算法_CquptDJ的博客-CSDN博客_efb算法">(88条消息) GBDT算法的升级--XGBoost与LightGBM算法_CquptDJ的博客-CSDN博客_efb算法</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0ac7bb41f7c788e64110cfb3c95d14af/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">dataGridVie控件绑定List＜T＞数据</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f70a37a694b761370bfdb552279fcbac/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">单片机课设———基于51单片机的智能风扇控制器（汇编语言）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>