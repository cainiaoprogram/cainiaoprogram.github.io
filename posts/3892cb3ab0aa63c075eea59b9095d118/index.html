<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>lecture 5 ： policy gradient introduction - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="lecture 5 ： policy gradient introduction" />
<meta property="og:description" content="lecture 5 ： policy gradient introduction 求 时运用了 如下一个技巧：
于是，
由于 则 变为：
在代码实现的时候，用trajactory的平均来估计，即：
接下来又分析了 vanila policy gradient 方法 的 high varience ：
直观上的理解就是，某个概率分布（如图中的r(r), 受数据的偏移影响较大）
为了减少varience, 开始如下分析：
由于某个时刻 前面的reward 对现在时刻的微分没有影响，所以 变为：
之后又加了baseline， 如下所示： b 可以取任何值(不依赖于cita) , 为什么要减？因为要减少varience （计算方差的公式前面的平方项的效果不后面那一项大)
减去b 之后，有无影响？ 没有（也可以认为 是 unbiased 的项) ，因为：
/******************************************************************************************************************/
课程中也讨论了， b 该取何值？从计算方差的定义出发：
后面那一项，与没有减之前相等，所以消去，前一项对b 求偏导得 ：
直观的理解就是 weighted expeted reward, weight 由 gradient 决定。
/******************************************************************************************************************/
以上policy gradient 是 on-policy 方法， 即由 pilicy 运行产生的data 进行训练，所以此时的方法 是data inefficient 的因为它用过一个数据之后就把它丢弃了。 一个解决方法是 off-policy的 policy gradient 方法： important sampling: 通过其他的分布来估计现有分布的值。 可以看到 的微分由 的分布决定。 至此，算法变为了off-policy, 即通过不是该策略产生的数据来训练参数。通过等式可以看出，要通过importance ratio 进行调整。其中 ：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/3892cb3ab0aa63c075eea59b9095d118/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-06-10T22:40:28+08:00" />
<meta property="article:modified_time" content="2020-06-10T22:40:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">lecture 5 ： policy gradient introduction</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <ol><li> <strong>lecture 5 ： policy gradient introduction</strong></li></ol> 
<ul><li> <p style="text-indent:33px;">求  <img alt="\nabla_{\theta} J(\theta)" class="mathcode" src="https://images2.imgbox.com/78/a3/d3WxAMKh_o.gif"> 时运用了 如下一个技巧：</p> </li></ul> 
<p style="text-indent:0;">                <img alt="" height="99" src="https://images2.imgbox.com/d3/aa/tdSrCjNA_o.png" width="378"></p> 
<p style="text-indent:0;">于是，</p> 
<p style="text-indent:0;"><img alt="" height="38" src="https://images2.imgbox.com/b7/84/M1aHCBuS_o.png" width="594"></p> 
<p style="text-indent:0;">由于<img alt="\pi_{\theta}\left(\mathbf{s}_{1}, \mathbf{a}_{1}, \ldots, \mathbf{s}_{T}, \mathbf{a}_{T}\right)=p\left(\mathbf{s}_{1}\right) \prod_{t=1}^{T} \pi_{\theta}\left(\mathbf{a}_{t} | \mathbf{s}_{t}\right) p\left(\mathbf{s}_{t+1} | \mathbf{s}_{t}, \mathbf{a}_{t}\right)" class="mathcode" src="https://images2.imgbox.com/b2/dc/yfKGhTIz_o.gif"> 则 <img alt="\nabla_{\theta} J(\theta)" class="mathcode" src="https://images2.imgbox.com/70/f8/dTsdQhNY_o.gif"> 变为：</p> 
<p style="text-indent:0;"><img alt="\nabla_{\theta} J(\theta)=E_{\tau \sim \pi_{\theta}(\tau)}\left[\left(\sum_{t=1}^{T} \nabla_{\theta} \log \pi_{\theta}\left(\mathbf{a}_{t} | \mathbf{s}_{t}\right)\right)\left(\sum_{t=1}^{T} r\left(\mathbf{s}_{t}, \mathbf{a}_{t}\right)\right)\right]" class="mathcode" src="https://images2.imgbox.com/5c/84/esSOxMYE_o.gif"></p> 
<p style="text-indent:0;">在代码实现的时候，用trajactory的平均来估计<img alt="\nabla_{\theta} J(\theta)" class="mathcode" src="https://images2.imgbox.com/95/27/AoNALTcV_o.gif">，即：</p> 
<p style="text-indent:0;"><img alt="" height="73" src="https://images2.imgbox.com/63/b4/nAAuUB8B_o.png" width="470"></p> 
<p style="text-indent:0;">接下来又分析了 vanila policy gradient 方法  的 high varience ：</p> 
<p style="text-indent:0;"><img alt="" height="160" src="https://images2.imgbox.com/67/c2/439QODFX_o.png" width="648"></p> 
<p style="text-indent:0;">直观上的理解就是，某个概率分布（如图中的r(r), 受数据的偏移影响较大）</p> 
<p style="text-indent:0;">   为了减少varience,  开始如下分析：</p> 
<p style="text-indent:0;">由于某个时刻 <strong>前面的reward 对现在时刻的微分没有影响</strong>，所以<img alt="\nabla_{\theta} J(\theta)" class="mathcode" src="https://images2.imgbox.com/bf/80/rUumDEEd_o.gif"> 变为：</p> 
<p style="text-indent:0;"><img alt="" height="97" src="https://images2.imgbox.com/0f/c5/yIYV0U1s_o.png" width="445"></p> 
<p style="text-indent:0;">之后又加了baseline， 如下所示： </p> 
<p style="text-indent:0;"><img alt="" height="73" src="https://images2.imgbox.com/59/11/RhwlEpZZ_o.png" width="295"></p> 
<p style="text-indent:0;">b 可以取任何值(不依赖于cita) , 为什么要减？因为要减少varience （计算方差的公式前面的平方项的效果不后面那一项大)</p> 
<p style="text-indent:0;">减去b 之后，有无影响？ 没有（也可以认为 是 unbiased 的项)  ，因为：</p> 
<p style="text-indent:0;"><img alt="" height="58" src="https://images2.imgbox.com/52/eb/r7GejslN_o.png" width="703"></p> 
<p style="text-indent:0;">/******************************************************************************************************************/</p> 
<p style="text-indent:0;">课程中也讨论了， b 该取何值？从计算方差的定义出发：</p> 
<p style="text-indent:0;"><img alt="" height="60" src="https://images2.imgbox.com/b1/ef/BEE90jXZ_o.png" width="693"></p> 
<p style="text-indent:0;">后面那一项，与没有减之前相等，所以消去，前一项对b 求偏导得 ：</p> 
<p style="text-indent:0;"><img alt="" height="161" src="https://images2.imgbox.com/7c/da/SLqYd8Un_o.png" width="685"></p> 
<p style="text-indent:0;">直观的理解就是 weighted expeted reward, weight 由 gradient 决定。</p> 
<p style="text-indent:0;">/******************************************************************************************************************/</p> 
<p style="text-indent:0;"> </p> 
<p style="text-indent:0;"> </p> 
<ul><li>以上policy gradient 是 on-policy 方法， 即由 pilicy 运行产生的data 进行训练，所以此时的方法 是data inefficient 的因为它用过一个数据之后就把它丢弃了。 一个解决方法是 off-policy的 policy gradient 方法： important sampling:<img alt="" height="267" src="https://images2.imgbox.com/32/39/a1MbPgZI_o.png" width="386"> 通过其他的分布来估计现有分布的值。<img alt="" height="87" src="https://images2.imgbox.com/1e/53/mIGTK3Qs_o.png" width="748"></li></ul> 
<p style="text-indent:0;"> 可以看到 <img alt="\theta^{\prime}\right" class="mathcode" src="https://images2.imgbox.com/69/e3/1U9NKwm3_o.png"> 的微分由 <img alt="\theta" class="mathcode" src="https://images2.imgbox.com/6f/54/D8SLyavU_o.gif"> 的分布决定。 至此，算法变为了off-policy, <strong>即通过不是该策略产生的数据来训练参数</strong>。通过等式可以看出，要通过importance ratio 进行调整。其中 ：</p> 
<p style="text-indent:0;"><img alt="" height="136" src="https://images2.imgbox.com/e0/3c/uTEnXVqx_o.png" width="306"></p> 
<p style="text-indent:0;">之后介绍了一种简化expotial 的方法</p> 
<p style="text-indent:0;">课程最后介绍了使用important sampling 的例子， 如 locomotion  imitation , 从现实中的人类行走这个分布抽取数据。</p> 
<p style="text-indent:0;"> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/965be8df9a799ae36537b9da61b847c4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">工作三年四面（技术面）里巴巴拿offer阿定级P6，月薪36K（Java岗）章</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f65cb45c17b7f1ff8728b3d5859dfe00/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Qt——错误总结</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>