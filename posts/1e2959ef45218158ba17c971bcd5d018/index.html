<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于代码一步一步教你深度学习中循环神经网络(RNN)的原理 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于代码一步一步教你深度学习中循环神经网络(RNN)的原理" />
<meta property="og:description" content="当谈到基于RNN（循环神经网络）的机器学习例子时，一个常见的任务是文本生成。RNN是一种能够处理序列数据的神经网络，它具有记忆能力。以下是一个基于RNN的文本生成例子，并给每一行添加了详细注释：
import torchimport torch.nn as nnimport torch.optim as optim # 定义文本数据集text = “Hello, how are you?” # 创建字符索引映射表chars = list(set(text))char2idx = {c: i for i, c in enumerate(chars)}idx2char = {i: c for i, c in enumerate(chars)} # 将文本转换为数字序列data = [char2idx[c] for c in text] 在这个例子中，我们首先定义了一个文本数据集text，它包含了要生成的文本。
接下来，我们创建了字符索引映射表。我们使用set(text)得到文本中的唯一字符，并使用enumerate为每个字符分配一个索引。char2idx是字符到索引的映射表，idx2char是索引到字符的映射表。
然后，我们将文本转换为数字序列。通过遍历文本中的每个字符，并使用char2idx将字符映射为对应的索引，得到一个数字序列作为我们模型的输入。
# 定义RNN模型class RNN(nn.Module): def init(self, input_size, hidden_size, output_size): super(RNN, self).init() self.hidden_size = hidden_size self.embedding = nn.Embedding(input_size, hidden_size) self.rnn = nn.RNN(hidden_size, hidden_size) self.fc = nn." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/1e2959ef45218158ba17c971bcd5d018/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-18T18:28:01+08:00" />
<meta property="article:modified_time" content="2023-12-18T18:28:01+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于代码一步一步教你深度学习中循环神经网络(RNN)的原理</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<p>当谈到基于RNN（循环神经网络）的机器学习例子时，一个常见的任务是文本生成。RNN是一种能够处理序列数据的神经网络，它具有记忆能力。以下是一个基于RNN的文本生成例子，并给每一行添加了详细注释：</p> 
<div class="codebox"> 
 <div class="btn-clipboard bgt" title="Copy"> 
  <i class="be be-clipboard"></i> 
 </div> 
 <pre class="code-normal prettyprint linenums prettyprinted">  
  <ol class="linenums"><li class="L0"><span class="kwd">import</span><span class="pln"> torch</span></li><li class="L1"><span class="kwd">import</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">nn </span><span class="kwd">as</span><span class="pln"> nn</span></li><li class="L2"><span class="kwd">import</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">optim </span><span class="kwd">as</span><span class="pln"> optim</span></li><li class="L3"><span class="pln"> </span></li><li class="L4"><span class="com"># 定义文本数据集</span></li><li class="L5"><span class="pln">text </span><span class="pun">=</span><span class="pln"> </span><span class="str">“Hello, how are you?”</span></li><li class="L6"><span class="pln"> </span></li><li class="L7"><span class="com"># 创建字符索引映射表</span></li><li class="L8"><span class="pln">chars </span><span class="pun">=</span><span class="pln"> list</span><span class="pun">(</span><span class="kwd">set</span><span class="pun">(</span><span class="pln">text</span><span class="pun">))</span></li><li class="L9"><span class="pln">char2idx </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{<!-- --></span><span class="pln">c</span><span class="pun">:</span><span class="pln"> i </span><span class="kwd">for</span><span class="pln"> i</span><span class="pun">,</span><span class="pln"> c </span><span class="kwd">in</span><span class="pln"> enumerate</span><span class="pun">(</span><span class="pln">chars</span><span class="pun">)}</span></li><li class="L0"><span class="pln">idx2char </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{<!-- --></span><span class="pln">i</span><span class="pun">:</span><span class="pln"> c </span><span class="kwd">for</span><span class="pln"> i</span><span class="pun">,</span><span class="pln"> c </span><span class="kwd">in</span><span class="pln"> enumerate</span><span class="pun">(</span><span class="pln">chars</span><span class="pun">)}</span></li><li class="L1"><span class="pln"> </span></li><li class="L2"><span class="com"># 将文本转换为数字序列</span></li><li class="L3"><span class="pln">data </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="pln">char2idx</span><span class="pun">[</span><span class="pln">c</span><span class="pun">]</span><span class="pln"> </span><span class="kwd">for</span><span class="pln"> c </span><span class="kwd">in</span><span class="pln"> text</span><span class="pun">]</span></li></ol></pre> 
</div> 
<p>在这个例子中，我们首先定义了一个文本数据集<code>text</code>，它包含了要生成的文本。</p> 
<p>接下来，我们创建了字符索引映射表。我们使用<code>set(text)</code>得到文本中的唯一字符，并使用<code>enumerate</code>为每个字符分配一个索引。<code>char2idx</code>是字符到索引的映射表，<code>idx2char</code>是索引到字符的映射表。</p> 
<p>然后，我们将文本转换为数字序列。通过遍历文本中的每个字符，并使用<code>char2idx</code>将字符映射为对应的索引，得到一个数字序列作为我们模型的输入。</p> 
<div class="codebox"> 
 <div class="btn-clipboard bgt" title="Copy"> 
  <i class="be be-clipboard"></i> 
 </div> 
 <pre class="code-normal prettyprint linenums prettyprinted">  
  <ol class="linenums"><li class="L0"><span class="com"># 定义RNN模型</span></li><li class="L1"><span class="kwd">class</span><span class="pln"> RNN</span><span class="pun">(</span><span class="pln">nn</span><span class="pun">.</span><span class="typ">Module</span><span class="pun">):</span></li><li class="L2"><span class="pln">    </span><span class="kwd">def</span><span class="pln"> <strong>init</strong></span><span class="pun">(</span><span class="kwd">self</span><span class="pun">,</span><span class="pln"> input_size</span><span class="pun">,</span><span class="pln"> hidden_size</span><span class="pun">,</span><span class="pln"> output_size</span><span class="pun">):</span></li><li class="L3"><span class="pln">        </span><span class="kwd">super</span><span class="pun">(</span><span class="pln">RNN</span><span class="pun">,</span><span class="pln"> </span><span class="kwd">self</span><span class="pun">).</span><span class="pln"><strong>init</strong></span><span class="pun">()</span></li><li class="L4"><span class="pln">        </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">hidden_size </span><span class="pun">=</span><span class="pln"> hidden_size</span></li><li class="L5"><span class="pln">        </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">embedding </span><span class="pun">=</span><span class="pln"> nn</span><span class="pun">.</span><span class="typ">Embedding</span><span class="pun">(</span><span class="pln">input_size</span><span class="pun">,</span><span class="pln"> hidden_size</span><span class="pun">)</span></li><li class="L6"><span class="pln">        </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">rnn </span><span class="pun">=</span><span class="pln"> nn</span><span class="pun">.</span><span class="pln">RNN</span><span class="pun">(</span><span class="pln">hidden_size</span><span class="pun">,</span><span class="pln"> hidden_size</span><span class="pun">)</span></li><li class="L7"><span class="pln">        </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">fc </span><span class="pun">=</span><span class="pln"> nn</span><span class="pun">.</span><span class="typ">Linear</span><span class="pun">(</span><span class="pln">hidden_size</span><span class="pun">,</span><span class="pln"> output_size</span><span class="pun">)</span></li><li class="L8"><span class="pln"> </span></li><li class="L9"><span class="pln">    </span><span class="kwd">def</span><span class="pln"> forward</span><span class="pun">(</span><span class="kwd">self</span><span class="pun">,</span><span class="pln"> x</span><span class="pun">,</span><span class="pln"> hidden</span><span class="pun">):</span></li><li class="L0"><span class="pln">        x </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">embedding</span><span class="pun">(</span><span class="pln">x</span><span class="pun">)</span></li><li class="L1"><span class="pln">        x</span><span class="pun">,</span><span class="pln"> hidden </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">rnn</span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="pln"> hidden</span><span class="pun">)</span></li><li class="L2"><span class="pln">        x </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">self</span><span class="pun">.</span><span class="pln">fc</span><span class="pun">(</span><span class="pln">x</span><span class="pun">)</span></li><li class="L3"><span class="pln">        </span><span class="kwd">return</span><span class="pln"> x</span><span class="pun">,</span><span class="pln"> hidden</span></li></ol></pre> 
</div> 
<p>接下来，我们定义了一个RNN模型。这个模型继承自<code>nn.Module</code>，并在<code><strong>init</strong></code>方法中定义了模型的各个层次和参数。模型包括一个嵌入层（<code>embedding</code>），一个RNN层（<code>rnn</code>），和一个线性层（<code>fc</code>）。在前向传播过程中，我们将输入张量通过嵌入层转换为向量表示，然后通过RNN层处理序列并输出隐藏状态，最后通过线性层映射隐藏状态到输出空间。</p> 
<div class="codebox"> 
 <div class="btn-clipboard bgt" title="Copy"> 
  <i class="be be-clipboard"></i> 
 </div> 
 <pre class="code-normal prettyprint linenums prettyprinted">  
  <ol class="linenums"><li class="L0"><span class="com"># 定义模型参数</span></li><li class="L1"><span class="pln">input_size </span><span class="pun">=</span><span class="pln"> len</span><span class="pun">(</span><span class="pln">chars</span><span class="pun">)</span></li><li class="L2"><span class="pln">hidden_size </span><span class="pun">=</span><span class="pln"> </span><span class="lit">32</span></li><li class="L3"><span class="pln">output_size </span><span class="pun">=</span><span class="pln"> len</span><span class="pun">(</span><span class="pln">chars</span><span class="pun">)</span></li><li class="L4"><span class="pln"> </span></li><li class="L5"><span class="com"># 实例化模型和损失函数</span></li><li class="L6"><span class="pln">rnn </span><span class="pun">=</span><span class="pln"> RNN</span><span class="pun">(</span><span class="pln">input_size</span><span class="pun">,</span><span class="pln"> hidden_size</span><span class="pun">,</span><span class="pln"> output_size</span><span class="pun">)</span></li><li class="L7"><span class="pln">criterion </span><span class="pun">=</span><span class="pln"> nn</span><span class="pun">.</span><span class="typ">CrossEntropyLoss</span><span class="pun">()</span></li><li class="L8"><span class="pln">optimizer </span><span class="pun">=</span><span class="pln"> optim</span><span class="pun">.</span><span class="typ">Adam</span><span class="pun">(</span><span class="pln">rnn</span><span class="pun">.</span><span class="pln">parameters</span><span class="pun">(),</span><span class="pln"> lr</span><span class="pun">=</span><span class="lit">0.01</span><span class="pun">)</span></li></ol></pre> 
</div> 
<p>然后，我们定义了模型的参数，包括输入大小（字符的种类数）、隐藏层大小、输出大小（字符的种类数）。</p> 
<p>接着，我们实例化了RNN模型，并定义了损失函数和优化器。在这个例子中，我们使用交叉熵损失函数（<code>nn.CrossEntropyLoss()</code>）和Adam优化器（<code>optim.Adam()</code>）。</p> 
<div class="codebox"> 
 <div class="btn-clipboard bgt" title="Copy"> 
  <i class="be be-clipboard"></i> 
 </div> 
 <pre class="code-normal prettyprint linenums prettyprinted">  
  <ol class="linenums"><li class="L0"><span class="com"># 训练模型</span></li><li class="L1"><span class="pln">num_epochs </span><span class="pun">=</span><span class="pln"> </span><span class="lit">100</span></li><li class="L2"><span class="pln">hidden </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">None</span></li><li class="L3"><span class="kwd">for</span><span class="pln"> epoch </span><span class="kwd">in</span><span class="pln"> range</span><span class="pun">(</span><span class="pln">num_epochs</span><span class="pun">):</span></li><li class="L4"><span class="pln">    inputs </span><span class="pun">=</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">tensor</span><span class="pun">(</span><span class="pln">data</span><span class="pun">[:-</span><span class="lit">1</span><span class="pun">]).</span><span class="pln">unsqueeze</span><span class="pun">(</span><span class="lit">0</span><span class="pun">)</span></li><li class="L5"><span class="pln">    targets </span><span class="pun">=</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">tensor</span><span class="pun">(</span><span class="pln">data</span><span class="pun">[</span><span class="lit">1</span><span class="pun">:]).</span><span class="pln">unsqueeze</span><span class="pun">(</span><span class="lit">0</span><span class="pun">)</span></li><li class="L6"><span class="pln">    </span></li><li class="L7"><span class="pln">    optimizer</span><span class="pun">.</span><span class="pln">zero_grad</span><span class="pun">()</span></li><li class="L8"><span class="pln">    </span></li><li class="L9"><span class="pln">    outputs</span><span class="pun">,</span><span class="pln"> hidden </span><span class="pun">=</span><span class="pln"> rnn</span><span class="pun">(</span><span class="pln">inputs</span><span class="pun">,</span><span class="pln"> hidden</span><span class="pun">)</span></li><li class="L0"><span class="pln">    loss </span><span class="pun">=</span><span class="pln"> criterion</span><span class="pun">(</span><span class="pln">outputs</span><span class="pun">.</span><span class="pln">squeeze</span><span class="pun">(),</span><span class="pln"> targets</span><span class="pun">.</span><span class="pln">squeeze</span><span class="pun">())</span></li><li class="L1"><span class="pln">    loss</span><span class="pun">.</span><span class="pln">backward</span><span class="pun">()</span></li><li class="L2"><span class="pln">    optimizer</span><span class="pun">.</span><span class="pln">step</span><span class="pun">()</span></li><li class="L3"><span class="pln"> </span></li><li class="L4"><span class="pln">    </span><span class="kwd">if</span><span class="pln"> </span><span class="pun">(</span><span class="pln">epoch</span><span class="pun">+</span><span class="lit">1</span><span class="pun">)</span><span class="pln"> </span><span class="pun">%</span><span class="pln"> </span><span class="lit">10</span><span class="pln"> </span><span class="pun">==</span><span class="pln"> </span><span class="lit">0</span><span class="pun">:</span></li><li class="L5"><span class="pln">        </span><span class="kwd">print</span><span class="pun">(</span><span class="pln">f</span><span class="str">‘Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}’</span><span class="pun">)</span></li></ol></pre> 
</div> 
<p>在训练阶段，我们使用数据进行多个epoch的训练。每个epoch中，我们首先将输入序列和目标序列加载到模型中。然后，我们将梯度缓存清零（通过<code>optimizer.zero_grad()</code>），执行前向传播、计算损失和反向传播，并通过优化器更新模型的参数。我们还打印出每个epoch的损失。</p> 
<div class="codebox"> 
 <div class="btn-clipboard bgt" title="Copy"> 
  <i class="be be-clipboard"></i> 
 </div> 
 <pre class="code-normal prettyprint linenums prettyprinted">  
  <ol class="linenums"><li class="L0"><span class="com"># 生成文本</span></li><li class="L1"><span class="kwd">with</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">no_grad</span><span class="pun">():</span></li><li class="L2"><span class="pln">    input_char </span><span class="pun">=</span><span class="pln"> text</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]</span></li><li class="L3"><span class="pln">    result </span><span class="pun">=</span><span class="pln"> input_char</span></li><li class="L4"><span class="pln">    hidden </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">None</span></li><li class="L5"><span class="pln">    </span></li><li class="L6"><span class="pln">    </span><span class="kwd">for</span><span class="pln"> _ </span><span class="kwd">in</span><span class="pln"> range</span><span class="pun">(</span><span class="pln">len</span><span class="pun">(</span><span class="pln">text</span><span class="pun">)-</span><span class="lit">1</span><span class="pun">):</span></li><li class="L7"><span class="pln">        input_idx </span><span class="pun">=</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">tensor</span><span class="pun">(</span><span class="pln">char2idx</span><span class="pun">[</span><span class="pln">input_char</span><span class="pun">]).</span><span class="pln">unsqueeze</span><span class="pun">(</span><span class="lit">0</span><span class="pun">)</span></li><li class="L8"><span class="pln">        output</span><span class="pun">,</span><span class="pln"> hidden </span><span class="pun">=</span><span class="pln"> rnn</span><span class="pun">(</span><span class="pln">input_idx</span><span class="pun">,</span><span class="pln"> hidden</span><span class="pun">)</span></li><li class="L9"><span class="pln">        _</span><span class="pun">,</span><span class="pln"> top_idx </span><span class="pun">=</span><span class="pln"> torch</span><span class="pun">.</span><span class="pln">max</span><span class="pun">(</span><span class="pln">output</span><span class="pun">.</span><span class="pln">squeeze</span><span class="pun">(),</span><span class="pln"> dim</span><span class="pun">=</span><span class="lit">1</span><span class="pun">)</span></li><li class="L0"><span class="pln">        predicted_char </span><span class="pun">=</span><span class="pln"> idx2char</span><span class="pun">[</span><span class="pln">top_idx</span><span class="pun">.</span><span class="pln">item</span><span class="pun">()]</span></li><li class="L1"><span class="pln">        result </span><span class="pun">+=</span><span class="pln"> predicted_char</span></li><li class="L2"><span class="pln">        input_char </span><span class="pun">=</span><span class="pln"> predicted_char</span></li><li class="L3"><span class="pln"> </span></li><li class="L4"><span class="kwd">print</span><span class="pun">(</span><span class="str">“Generated Text:”</span><span class="pun">,</span><span class="pln"> result</span><span class="pun">)</span></li></ol></pre> 
</div> 
<p>在生成文本阶段，我们使用训练好的模型进行文本生成。我们从初始字符开始，迭代地将字符索引输入到模型中，获取模型的输出并选择最高分数对应的字符作为预测结果。然后，我们将预测字符添加到结果中，并将预测字符作为下一个时间步的输入，继续迭代生成下一个字符，直到生成与原始文本长度相同的文本序列。</p> 
<p>最后，我们打印出生成的文本结果。</p> 
<p>这个基于RNN的文本生成例子展示了如何使用深度学习来生成具有一定连贯性的文本。通过构建一个简单的RNN模型并进行训练，我们能够生成类似于原始文本的新文本序列。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/25b82299f7df3ee3518fd5d40fbdb2f8/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">小白看得懂的 Transformer (图解)</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/86405b1ab8b637f9ef045a27fb742741/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android13音频录制适配</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>