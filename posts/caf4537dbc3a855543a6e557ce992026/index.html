<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>基于全卷积Fully-Convolutional-Siamese-Networks的目标跟踪仿真 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="基于全卷积Fully-Convolutional-Siamese-Networks的目标跟踪仿真" />
<meta property="og:description" content="目录
1.算法概述
2.仿真效果预览
3.核心MATLAB代码预览
4.完整MATLAB程序
1.算法概述 1.正确版本组合：Win7&#43;Matlab R2015b&#43;CUDA7.5&#43;vs2013
CUDA7.5下载地址为：
http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_windows.exe
vs2013要专业版。
如下所示：
全部安装好之后，做如下操作：
2.CPU配置，运行CNN工具箱中的 ，然后再运行 可以完成CPP文件的编译。
3.编译成功后，会产生
这些必须在电脑上编译，否则别人的复制给你，如果配置不一样，可能会报错。
4.GPU配置：
安装cudnn：https://developer.nvidia.com/rdp/cudnn-archive，放到CNN工具箱中的新建local文件夹中，
然后mex -setup下，操作和CPU一样。
然后执行matlab程序：
vl_setupnn;
vl_compilenn(&#39;enableGpu&#39;, true,&#39;cudaRoot&#39;, &#39;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5&#39;,&#39;cudaMethod&#39;, &#39;nvcc&#39;, &#39;enableCudnn&#39;, &#39;true&#39;,&#39;cudnnRoot&#39;, &#39;E:\A_2016_FPGA_Test\FC_tracking\A_FC\matconvnet-1.0-beta20\local\cudnn&#39;);
红色部分为你的路径，不要有中文。
5.然后运行我给的程序 ，就可以自动运行了，原来程序的运行非常麻烦，我定义了这个程序，可以一步运行处结果。
2.仿真效果预览 Win7&#43;Matlab R2015b&#43;CUDA7.5&#43;vs2013
运行后，如果可以出现如下结果：
3.核心MATLAB代码预览 % ------------------------------------------------------------------------------------------------- function bboxes = tracker(varargin) %TRACKER % is the main function that performs the tracking loop % Default parameters are overwritten by VARARGIN % % Luca Bertinetto, Jack Valmadre, Joao F." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/caf4537dbc3a855543a6e557ce992026/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-11-28T16:40:43+08:00" />
<meta property="article:modified_time" content="2022-11-28T16:40:43+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">基于全卷积Fully-Convolutional-Siamese-Networks的目标跟踪仿真</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0-toc" style="margin-left:0px;"><a href="#1.%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0" rel="nofollow">1.算法概述</a></p> 
<p id="2.%E4%BB%BF%E7%9C%9F%E6%95%88%E6%9E%9C%E9%A2%84%E8%A7%88-toc" style="margin-left:0px;"><a href="#2.%E4%BB%BF%E7%9C%9F%E6%95%88%E6%9E%9C%E9%A2%84%E8%A7%88" rel="nofollow">2.仿真效果预览</a></p> 
<p id="3.%E6%A0%B8%E5%BF%83MATLAB%E4%BB%A3%E7%A0%81%E9%A2%84%E8%A7%88-toc" style="margin-left:0px;"><a href="#3.%E6%A0%B8%E5%BF%83MATLAB%E4%BB%A3%E7%A0%81%E9%A2%84%E8%A7%88" rel="nofollow">3.核心MATLAB代码预览</a></p> 
<p id="4.%E5%AE%8C%E6%95%B4MATLAB%E7%A8%8B%E5%BA%8F-toc" style="margin-left:0px;"><a href="#4.%E5%AE%8C%E6%95%B4MATLAB%E7%A8%8B%E5%BA%8F" rel="nofollow">4.完整MATLAB程序</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="1.%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0">1.算法概述</h2> 
<p style="margin-left:0px;"><span style="background-color:#ffffff;">1.正确版本组合：Win7+Matlab R2015b+CUDA7.5+vs2013</span></p> 
<p style="margin-left:0px;"><span style="background-color:#ffffff;">CUDA7.5下载地址为：</span></p> 
<p style="margin-left:.0001pt;text-align:justify;">http://developer.download.nvidia.com/compute/cuda/7.5/Prod/local_installers/cuda_7.5.18_windows.exe</p> 
<p style="margin-left:.0001pt;text-align:justify;">vs2013要专业版。</p> 
<p style="margin-left:.0001pt;text-align:justify;">如下所示：</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="90" src="https://images2.imgbox.com/38/2a/Oy157c3G_o.png" width="228"></p> 
<p> 全部安装好之后，做如下操作：</p> 
<p style="margin-left:.0001pt;text-align:justify;">2.CPU配置，运行CNN工具箱中的<img alt="" height="20" src="https://images2.imgbox.com/13/7c/2cNMvMtb_o.png" width="88"> ，然后再运行<img alt="" height="29" src="https://images2.imgbox.com/93/40/ogmPKR2Y_o.png" width="114"> 可以完成CPP文件的编译。</p> 
<p style="margin-left:.0001pt;text-align:justify;">3.编译成功后，会产生</p> 
<p style="margin-left:.0001pt;text-align:justify;"><img alt="" height="131" src="https://images2.imgbox.com/b5/6a/r6xRCHsM_o.png" width="252"></p> 
<p style="margin-left:.0001pt;text-align:justify;">这些必须在电脑上编译，否则别人的复制给你，如果配置不一样，可能会报错。</p> 
<p style="margin-left:.0001pt;text-align:justify;">4.GPU配置：</p> 
<p style="margin-left:.0001pt;text-align:justify;">安装cudnn：https://developer.nvidia.com/rdp/cudnn-archive，放到CNN工具箱中的新建local文件夹中，</p> 
<p style="margin-left:.0001pt;text-align:justify;">然后mex -setup下，操作和CPU一样。</p> 
<p style="margin-left:.0001pt;text-align:justify;">然后执行matlab程序：</p> 
<p style="margin-left:.0001pt;text-align:left;"><span style="color:#000000;">vl_setupnn;</span></p> 
<p style="margin-left:.0001pt;text-align:left;"><span style="color:#000000;">vl_compilenn(</span><span style="color:#a020f0;">'enableGpu'</span><span style="color:#000000;">, true,</span><span style="color:#a020f0;">'cudaRoot'</span><span style="color:#000000;">, </span><span style="color:#a020f0;">'</span><span style="color:#ff0000;">C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5</span><span style="color:#a020f0;">'</span><span style="color:#000000;">,</span><span style="color:#a020f0;">'cudaMethod'</span><span style="color:#000000;">, </span><span style="color:#a020f0;">'nvcc'</span><span style="color:#000000;">, </span><span style="color:#a020f0;">'enableCudnn'</span><span style="color:#000000;">, </span><span style="color:#a020f0;">'true'</span><span style="color:#000000;">,</span><span style="color:#a020f0;">'cudnnRoot'</span><span style="color:#000000;">, </span><span style="color:#a020f0;">'</span><span style="color:#ff0000;">E:\A_2016_FPGA_Test\FC_tracking\A_FC\matconvnet-1.0-beta20\local\cudnn</span><span style="color:#a020f0;">'</span><span style="color:#000000;">);</span></p> 
<p style="margin-left:.0001pt;text-align:justify;">红色部分为你的路径，不要有中文。</p> 
<p style="margin-left:.0001pt;text-align:justify;">5.然后运行我给的程序<img alt="" height="19" src="https://images2.imgbox.com/10/ca/z2AyLIeR_o.png" width="78"> ，就可以自动运行了，原来程序的运行非常麻烦，我定义了这个程序，可以一步运行处结果。</p> 
<p style="margin-left:.0001pt;text-align:justify;"></p> 
<h2 id="2.%E4%BB%BF%E7%9C%9F%E6%95%88%E6%9E%9C%E9%A2%84%E8%A7%88" style="margin-left:.0001pt;text-align:justify;">2.仿真效果预览</h2> 
<p style="margin-left:.0001pt;text-align:justify;"><span style="background-color:#ffffff;">Win7+Matlab R2015b+CUDA7.5+vs2013</span></p> 
<p style="margin-left:.0001pt;text-align:justify;">运行后，如果可以出现如下结果：</p> 
<p style="margin-left:.0001pt;text-align:center;"><img alt="" height="419" src="https://images2.imgbox.com/7a/15/vDLlNFCp_o.png" width="560"></p> 
<h2 id="3.%E6%A0%B8%E5%BF%83MATLAB%E4%BB%A3%E7%A0%81%E9%A2%84%E8%A7%88">3.核心MATLAB代码预览</h2> 
<pre><code>% -------------------------------------------------------------------------------------------------
function bboxes = tracker(varargin)
%TRACKER
%   is the main function that performs the tracking loop
%   Default parameters are overwritten by VARARGIN
%
%   Luca Bertinetto, Jack Valmadre, Joao F. Henriques, 2016
% -------------------------------------------------------------------------------------------------
    % These are the default hyper-params for SiamFC-3S
    % The ones for SiamFC (5 scales) are in params-5s.txt
    p.numScale = 3;
    p.scaleStep = 1.0375;
    p.scalePenalty = 0.9745;
    p.scaleLR = 0.59; % damping factor for scale update
    p.responseUp = 16; % upsampling the small 17x17 response helps with the accuracy
    p.windowing = 'cosine'; % to penalize large displacements
    p.wInfluence = 0.176; % windowing influence (in convex sum)
    p.net = '2016-08-17.net.mat';
    %% execution, visualization, benchmark
    p.video = 'vot15_bag';
    p.visualization = false;
    p.gpus = 1;
    p.bbox_output = false;
    p.fout = -1;
    %% Params from the network architecture, have to be consistent with the training
    p.exemplarSize = 127;  % input z size
    p.instanceSize = 255;  % input x size (search region)
    p.scoreSize = 17;
    p.totalStride = 8;
    p.contextAmount = 0.5; % context amount for the exemplar
    p.subMean = false;
    %% SiamFC prefix and ids
    p.prefix_z = 'a_'; % used to identify the layers of the exemplar
    p.prefix_x = 'b_'; % used to identify the layers of the instance
    p.prefix_join = 'xcorr';
    p.prefix_adj = 'adjust';
    p.id_feat_z = 'a_feat';
    p.id_score = 'score';
    % Overwrite default parameters with varargin
    p = vl_argparse(p, varargin);
% -------------------------------------------------------------------------------------------------

    % Get environment-specific default paths.
    p = env_paths_tracking(p);
    1
    % Load ImageNet Video statistics
    if exist(p.stats_path,'file')
        stats = load(p.stats_path);
    else
        warning('No stats found at %s', p.stats_path);
        stats = [];
    end
    
    2
    % Load two copies of the pre-trained network
    net_z = load_pretrained([p.net_base_path p.net], p.gpus);
    3
    net_x = load_pretrained([p.net_base_path p.net], []);
    4
    p.seq_base_path
    p.video
    [imgFiles, targetPosition, targetSize] = load_video_info(p.seq_base_path, p.video);
    nImgs = numel(imgFiles);
    startFrame = 1;
    5
    % Divide the net in 2
    % exemplar branch (used only once per video) computes features for the target
    remove_layers_from_prefix(net_z, p.prefix_x);
    remove_layers_from_prefix(net_z, p.prefix_join);
    remove_layers_from_prefix(net_z, p.prefix_adj);
    % instance branch computes features for search region x and cross-correlates with z features
    6
    remove_layers_from_prefix(net_x, p.prefix_z);
    zFeatId = net_z.getVarIndex(p.id_feat_z);
    scoreId = net_x.getVarIndex(p.id_score);
    % get the first frame of the video
    im = gpuArray(single(imgFiles{startFrame}));
    % if grayscale repeat one channel to match filters size
	if(size(im, 3)==1)
        im = repmat(im, [1 1 3]);
    end
    % Init visualization
    videoPlayer = [];
    if p.visualization &amp;&amp; isToolboxAvailable('Computer Vision System Toolbox')
        videoPlayer = vision.VideoPlayer('Position', [100 100 [size(im,2), size(im,1)]+30]);
    end
    7
    % get avg for padding
    avgChans = gather([mean(mean(im(:,:,1))) mean(mean(im(:,:,2))) mean(mean(im(:,:,3)))]);

    wc_z = targetSize(2) + p.contextAmount*sum(targetSize);
    hc_z = targetSize(1) + p.contextAmount*sum(targetSize);
    s_z = sqrt(wc_z*hc_z);
    scale_z = p.exemplarSize / s_z;
    % initialize the exemplar
    [z_crop, ~] = get_subwindow_tracking(im, targetPosition, [p.exemplarSize p.exemplarSize], [round(s_z) round(s_z)], avgChans);
    if p.subMean
        z_crop = bsxfun(@minus, z_crop, reshape(stats.z.rgbMean, [1 1 3]));
    end
    d_search = (p.instanceSize - p.exemplarSize)/2;
    pad = d_search/scale_z;
    s_x = s_z + 2*pad;
    % arbitrary scale saturation
    min_s_x = 0.2*s_x;
    max_s_x = 5*s_x;

    switch p.windowing
        case 'cosine'
            window = single(hann(p.scoreSize*p.responseUp) * hann(p.scoreSize*p.responseUp)');
        case 'uniform'
            window = single(ones(p.scoreSize*p.responseUp, p.scoreSize*p.responseUp));
    end
    % make the window sum 1
    window = window / sum(window(:));
    scales = (p.scaleStep .^ ((ceil(p.numScale/2)-p.numScale) : floor(p.numScale/2)));
    % evaluate the offline-trained network for exemplar z features
    net_z.eval({'exemplar', z_crop});
    z_features = net_z.vars(zFeatId).value;
    z_features = repmat(z_features, [1 1 1 p.numScale]);

    bboxes = zeros(nImgs, 4);
    % start tracking
    tic;
    for i = startFrame:nImgs
        i
        if i&gt;startFrame
            % load new frame on GPU
            im = gpuArray(single(imgFiles{i}));
   			% if grayscale repeat one channel to match filters size
    		if(size(im, 3)==1)
        		im = repmat(im, [1 1 3]);
    		end
            scaledInstance = s_x .* scales;
            scaledTarget = [targetSize(1) .* scales; targetSize(2) .* scales];
            % extract scaled crops for search region x at previous target position
            x_crops = make_scale_pyramid(im, targetPosition, scaledInstance, p.instanceSize, avgChans, stats, p);
            % evaluate the offline-trained network for exemplar x features
            [newTargetPosition, newScale] = tracker_eval(net_x, round(s_x), scoreId, z_features, x_crops, targetPosition, window, p);
            targetPosition = gather(newTargetPosition);
            % scale damping and saturation
            s_x = max(min_s_x, min(max_s_x, (1-p.scaleLR)*s_x + p.scaleLR*scaledInstance(newScale)));
            targetSize = (1-p.scaleLR)*targetSize + p.scaleLR*[scaledTarget(1,newScale) scaledTarget(2,newScale)];
        else
            % at the first frame output position and size passed as input (ground truth)
        end

        rectPosition = [targetPosition([2,1]) - targetSize([2,1])/2, targetSize([2,1])];
        % output bbox in the original frame coordinates
        oTargetPosition = targetPosition; % .* frameSize ./ newFrameSize;
        oTargetSize = targetSize; % .* frameSize ./ newFrameSize;
        bboxes(i, :) = [oTargetPosition([2,1]) - oTargetSize([2,1])/2, oTargetSize([2,1])];

%         if p.visualization
            if isempty(videoPlayer)
                figure(1), imshow(im/255);
                figure(1), rectangle('Position', rectPosition, 'LineWidth', 4, 'EdgeColor', 'y');
                drawnow
                fprintf('Frame %d\n', startFrame+i);
            else
                im = gather(im)/255;
                im = insertShape(im, 'Rectangle', rectPosition, 'LineWidth', 4, 'Color', 'yellow');
                % Display the annotated video frame using the video player object.
                step(videoPlayer, im);
            end
%         end

        if p.bbox_output
            fprintf(p.fout,'%.2f,%.2f,%.2f,%.2f\n', bboxes(i, :));
        end

    end

    bboxes = bboxes(startFrame : i, :);

end
A000</code></pre> 
<h2 id="4.%E5%AE%8C%E6%95%B4MATLAB%E7%A8%8B%E5%BA%8F">4.完整MATLAB程序</h2> 
<p><a href="https://blog.csdn.net/hlayumi1234567/article/details/127852763?spm=1001.2014.3001.5502" title="matlab源码说明_我爱C编程的博客-CSDN博客">matlab源码说明_我爱C编程的博客-CSDN博客</a></p> 
<p style="text-align:center;"><span style="color:#fe2c24;"><strong>V</strong></span></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1eb591daf03f492e31735c5f182db48d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【ESP32 C语言】ESP32与ESP32-S2使用adc_dma_read心得</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/3b85d66952d4351f7129df1e133f63ff/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Android TV 开发 RecycleView重新获得焦点并回到原来的item位置让item获取焦点</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>