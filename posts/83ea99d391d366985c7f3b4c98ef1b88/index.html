<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>《CBAM: Convolutional Block Attention Module》论文阅读之 Channel Attention 与 Spatial Attention - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="《CBAM: Convolutional Block Attention Module》论文阅读之 Channel Attention 与 Spatial Attention" />
<meta property="og:description" content="为了提高神经网络的性能，许多研究都集中在 “depth, width, and cardinality” 上，而本文的重点在 “Attention”。
“注意力机制（Attention mechanism）”听起来很高大上，实际上是关于调整权重的问题，这篇论文提出了一个“即插即用的”的网络结构——CBAM，能够很方便的加到其他的CNN结构中。CBAM利用了通道注意力（channel attention）与空间注意力（spatial attention）。实际上就是在通道（channel）维度上与空间（spatial）维度上对传进来的特征图（intermediate feature map）进行加权处理，权重越大，说明这一通道（channel 维度）或这一点（spatial维度）的信息很重要。如何确定给每一个channel或每一点的权重大小，不同的论文可能会有不同的衡量方法，例如采用均值，例如采用方差等等，这篇论文是通过最大池化（MaxPool）与平均池化（AvgPool）来决定的。
先看Channel Attention，结构如图所示：
Channel Attention 关注的是channel维度。特征图的每个通道被认为是一种特征检测器检测到的特征（每个通道特征由不同的卷积核（Kernel)得到），论文中说的是“what”，就是说哪一个channel比较重要（有用信息多）。对于一个特征图（C*H*W），计算出每个channel的重要性，也就是权值（C*1*1），将权值与特征图相乘得到加权的特征图，就是Channel Attention。权值通过MaxPool与AvgPool计算（为什么是这两个，因为实验结果证明使用这两个比单独地使用其中一个效果要好）。为了获得Channel维度上的权值，需将每一个Channel（1*H*W）压缩成一个数（1*1*1），两种方法：计算每个Channel的平均值（AvgPool）和最大值（MaxPool）。计算完后，将它们通过一个共同的多层感知机MLP（也就是含有一个隐层的全连接网络），MLP的结构是（输入神经元：C，隐层神经元：C/r，输出神经元：C）,再将这两个输出相加，通过sigmoid函数归一化，得到最后的权重。将此权重与原始特征图相乘，得到channel维度上的加权特征图。Channel Attention基本完成。
Spatial Attention 关注的是“where”，就是每一个通道上（1*H*W）哪一点比较重要，因此我们需要生成一个维度为（1*H*W）的空间权重。怎么生成这个权重，同样，我们将不同的channel在同一平面空间点上的值做平均（AvgPool）和取最大值（MaxPool）来获得（1*H*W）的权重。再通过一个卷积层和sigmoid函数来得到最终的权重，将此权重在spatial维度上和每一个channel（1*H*W）相乘，得到spatial维度上的加权特征图。spatial attention基本完成。
最后的问题是按什么顺序给传进来的特征图加上Channel Attention与Spatial Attention。这里有两种思路，（1）并行模型，Channel Attention 与Spatial Attention并行；（2）顺序模型，先让特征图通过Channel Attention再通过Spatial Attention或者相反。实验证明先通过Channel Attention比较好（深度学习有时候就是不讲道理，看结果调）。因此最后的结构如下所示：
原文地址：CBAM: Convolutional Block Attention Module
Official PyTorch code：https://github.com/Jongchan/attention-module" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/83ea99d391d366985c7f3b4c98ef1b88/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-10-12T19:45:17+08:00" />
<meta property="article:modified_time" content="2019-10-12T19:45:17+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">《CBAM: Convolutional Block Attention Module》论文阅读之 Channel Attention 与 Spatial Attention</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-indent:33px;">为了提高神经网络的性能，许多研究都集中在 “depth, width, and cardinality” 上，而本文的重点在 “Attention”。</p> 
<p style="text-indent:33px;">“注意力机制（Attention mechanism）”听起来很高大上，实际上是关于调整权重的问题，这篇论文提出了一个“即插即用的”的网络结构——CBAM，能够很方便的加到其他的CNN结构中。CBAM利用了通道注意力（channel attention）与空间注意力（spatial attention）。实际上就是在通道（channel）维度上与空间（spatial）维度上对传进来的特征图（intermediate feature map）进行加权处理，权重越大，说明这一通道（channel 维度）或这一点（spatial维度）的信息很重要。如何确定给每一个channel或每一点的权重大小，不同的论文可能会有不同的衡量方法，例如采用均值，例如采用方差等等，这篇论文是通过最大池化（MaxPool）与平均池化（AvgPool）来决定的。</p> 
<p style="text-indent:33px;">先看Channel Attention，结构如图所示：</p> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/f0/32/2dyoJ0WX_o.png"></p> 
<p style="text-indent:33px;">Channel Attention 关注的是channel维度。特征图的每个通道被认为是一种特征检测器检测到的特征（每个通道特征由不同的卷积核（Kernel)得到），论文中说的是“what”，就是说哪一个channel比较重要（有用信息多）。对于一个特征图（C*H*W），计算出每个channel的重要性，也就是权值（C*1*1），将权值与特征图相乘得到加权的特征图，就是Channel Attention。权值通过MaxPool与AvgPool计算（为什么是这两个，因为实验结果证明使用这两个比单独地使用其中一个效果要好）。为了获得Channel维度上的权值，需将每一个Channel（1*H*W）压缩成一个数（1*1*1），两种方法：计算每个Channel的平均值（AvgPool）和最大值（MaxPool）。计算完后，将它们通过一个共同的多层感知机MLP（也就是含有一个隐层的全连接网络），MLP的结构是（输入神经元：C，隐层神经元：C/r，输出神经元：C）,再将这两个输出相加，通过sigmoid函数归一化，得到最后的权重。将此权重与原始特征图相乘，得到channel维度上的加权特征图。Channel Attention基本完成。</p> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/0b/be/SlEB0I0i_o.png"></p> 
<p style="text-indent:33px;">Spatial Attention 关注的是“where”，就是每一个通道上（1*H*W）哪一点比较重要，因此我们需要生成一个维度为（1*H*W）的空间权重。怎么生成这个权重，同样，我们将不同的channel在同一平面空间点上的值做平均（AvgPool）和取最大值（MaxPool）来获得（1*H*W）的权重。再通过一个卷积层和sigmoid函数来得到最终的权重，将此权重在spatial维度上和每一个channel（1*H*W）相乘，得到spatial维度上的加权特征图。spatial attention基本完成。</p> 
<p style="text-indent:33px;">最后的问题是按什么顺序给传进来的特征图加上Channel Attention与Spatial Attention。这里有两种思路，（1）并行模型，Channel Attention 与Spatial Attention并行；（2）顺序模型，先让特征图通过Channel Attention再通过Spatial Attention或者相反。实验证明先通过Channel Attention比较好（深度学习有时候就是不讲道理，看结果调）。因此最后的结构如下所示：</p> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/eb/77/oVmvJuj2_o.png"></p> 
<p> </p> 
<p> </p> 
<p>原文地址：<a href="https://arxiv.org/abs/1807.06521v2" rel="nofollow">CBAM: Convolutional Block Attention Module</a></p> 
<p>Official PyTorch code：<a href="https://github.com/Jongchan/attention-module">https://github.com/Jongchan/attention-module</a></p> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b32e2c347bf6162d129ebff068f51372/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue3.0全家桶实战过程中配置出现的问题解决记录</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8c2994c909099dcb7d8f768eaaadda34/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java  Reference核心原理分析</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>