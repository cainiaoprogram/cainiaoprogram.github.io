<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>c&#43;&#43;使用onnxruntime加载模型进行图片去噪 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="c&#43;&#43;使用onnxruntime加载模型进行图片去噪" />
<meta property="og:description" content="1. visual stdio 安装使用onnxruntime
visual stdio 安装onnxruntime，工具-&gt;Nuget包管理-&gt;点管理台后输入如第二张图 PM&gt; xxx, 等下载好后就可以在本项目的目录中看到package文件夹中的onnxruntime了
2. 模型推理代码
首先配置好项目的依赖 属性中配置include和lib，如下二图。再找到onnxruntime.dll copy到项目根目录下。（注不清楚这一步做不做有没有关系，因为后来我发现vs中自己导入了onnxruntime.dll，onnxruntime_providers_shared.dll这两个文件）
代码如下：
c&#43;&#43;接口 导出成dll后还依赖源码
void printModelInfo(Ort::Session &amp;session, Ort::AllocatorWithDefaultOptions &amp;allocator) { //输出模型输入节点的数量 size_t num_input_nodes = session.GetInputCount(); size_t num_output_nodes = session.GetOutputCount(); cout &lt;&lt; &#34;Number of input node is:&#34; &lt;&lt; num_input_nodes &lt;&lt; endl; cout &lt;&lt; &#34;Number of output node is:&#34; &lt;&lt; num_output_nodes &lt;&lt; endl; //获取输入输出维度 for (auto i = 0; i &lt; num_input_nodes; i&#43;&#43;) { std::vector&lt;int64_t&gt; input_dims = session." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/1732feb4b8380c69bbfa190975d2ab5b/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-04-21T14:45:22+08:00" />
<meta property="article:modified_time" content="2023-04-21T14:45:22+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">c&#43;&#43;使用onnxruntime加载模型进行图片去噪</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>1. visual stdio 安装使用onnxruntime</p> 
<p></p> 
<p>visual stdio 安装onnxruntime，工具-&gt;Nuget包管理-&gt;点管理台后输入如第二张图 PM&gt; xxx, 等下载好后就可以在本项目的目录中看到package文件夹中的onnxruntime了</p> 
<p><img alt="" height="514" src="https://images2.imgbox.com/2d/0c/Sm12V2yj_o.png" width="779"></p> 
<p></p> 
<p><img alt="" height="274" src="https://images2.imgbox.com/e0/58/VDI6vevj_o.png" width="710"></p> 
<p></p> 
<p></p> 
<p>2. 模型推理代码</p> 
<p>首先配置好项目的依赖 属性中配置include和lib，如下二图。再找到onnxruntime.dll copy到项目根目录下。（注不清楚这一步做不做有没有关系，因为后来我发现vs中自己导入了onnxruntime.dll，onnxruntime_providers_shared.dll这两个文件）</p> 
<p><img alt="" height="618" src="https://images2.imgbox.com/79/2d/dcJ4UrmS_o.png" width="1200"></p> 
<p> <img alt="" height="505" src="https://images2.imgbox.com/ec/ee/EBm6wvSP_o.png" width="1200"></p> 
<p>代码如下：</p> 
<p>c++接口 导出成dll后还依赖源码</p> 
<pre><code class="language-cpp">

void printModelInfo(Ort::Session &amp;session, Ort::AllocatorWithDefaultOptions &amp;allocator)
{
	//输出模型输入节点的数量
	size_t num_input_nodes = session.GetInputCount();
	size_t num_output_nodes = session.GetOutputCount();
	cout &lt;&lt; "Number of input node is:" &lt;&lt; num_input_nodes &lt;&lt; endl;
	cout &lt;&lt; "Number of output node is:" &lt;&lt; num_output_nodes &lt;&lt; endl;

	//获取输入输出维度
	for (auto i = 0; i &lt; num_input_nodes; i++)
	{
		std::vector&lt;int64_t&gt; input_dims = session.GetInputTypeInfo(i).GetTensorTypeAndShapeInfo().GetShape();
		cout &lt;&lt; endl &lt;&lt; "input " &lt;&lt; i &lt;&lt; " dim is: ";
		for (auto j = 0; j &lt; input_dims.size(); j++)
			cout &lt;&lt; input_dims[j] &lt;&lt; " ";
	}
	for (auto i = 0; i &lt; num_output_nodes; i++)
	{
		std::vector&lt;int64_t&gt; output_dims = session.GetOutputTypeInfo(i).GetTensorTypeAndShapeInfo().GetShape();
		cout &lt;&lt; endl &lt;&lt; "output " &lt;&lt; i &lt;&lt; " dim is: ";
		for (auto j = 0; j &lt; output_dims.size(); j++)
			cout &lt;&lt; output_dims[j] &lt;&lt; " ";
	}

	cout &lt;&lt;  endl;
	//input_dims_2[0] = input_dims_1[0] = output_dims[0] = 1;//batch size = 1
}

void testImgenDenosing() {

	//refer： https://blog.csdn.net/qq_42995327/article/details/122622222
	// initialize  environment...one environment per process
	Ort::Env env(ORT_LOGGING_LEVEL_WARNING, "test");

	// initialize session options if needed
	Ort::SessionOptions session_options;
	session_options.SetInterOpNumThreads(1);
	Ort::AllocatorWithDefaultOptions allocator;

#ifdef _WIN32
	const wchar_t* model_path = L"D:\\Documents\\projects\\Image-Denoising-using-Deep-Learning\\model.onnx";
#else
	const char* model_path = "D:\\Documents\\projects\\Image-Denoising-using-Deep-Learning\\model.onnx";
#endif

//#ifdef _WIN32
//	const wchar_t* model_path = L"D:\\Documents\\projects\\Image-Denoising-using-Deep-Learning\\best_REDNet_blindnoise_256x256.onnx";
//#else
//	const char* model_path = "D:\\Documents\\projects\\Image-Denoising-using-Deep-Learning\\best_REDNet_blindnoise_256x256.onnx";
//#endif

	Ort::Session session(env, model_path, session_options);
	Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtAllocatorType::OrtArenaAllocator, OrtMemType::OrtMemTypeDefault);

	// print number of model input nodes
	size_t num_input_nodes = session.GetInputCount();

	cout &lt;&lt; num_input_nodes &lt;&lt; endl;

	printModelInfo(session, allocator);
	cout &lt;&lt; session.GetInputTypeInfo(0).GetTensorTypeAndShapeInfo().GetElementType() &lt;&lt; endl;

	/**
	输出的数字对应
typedef enum ONNXTensorElementDataType {
  ONNX_TENSOR_ELEMENT_DATA_TYPE_UNDEFINED,
  ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT,   // maps to c type float
  ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8,   // maps to c type uint8_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_INT8,    // maps to c type int8_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT16,  // maps to c type uint16_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_INT16,   // maps to c type int16_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_INT32,   // maps to c type int32_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_INT64,   // maps to c type int64_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_STRING,  // maps to c++ type std::string
  ONNX_TENSOR_ELEMENT_DATA_TYPE_BOOL,
  ONNX_TENSOR_ELEMENT_DATA_TYPE_FLOAT16,
  ONNX_TENSOR_ELEMENT_DATA_TYPE_DOUBLE,      // maps to c type double
  ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT32,      // maps to c type uint32_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT64,      // maps to c type uint64_t
  ONNX_TENSOR_ELEMENT_DATA_TYPE_COMPLEX64,   // complex with float32 real and imaginary components
  ONNX_TENSOR_ELEMENT_DATA_TYPE_COMPLEX128,  // complex with float64 real and imaginary components
  ONNX_TENSOR_ELEMENT_DATA_TYPE_BFLOAT16     // Non-IEEE floating-point format based on IEEE754 single-precision
} ONNXTensorElementDataType;

	**/



	//输入网络的维度
	static constexpr const int width = 256;
	static constexpr const int height = 256;
	static constexpr const int channel = 3;
	std::array&lt;int64_t, 4&gt; input_shape_{ 1,width, height,channel };


	Mat img_1 = cv::imread("C:\\Users\\cls\\Downloads\\240px-NIND_BruegelLibraryS1_ISOH1.png");
	//通道交换
	cv::cvtColor(img_1, img_1, COLOR_BGR2RGB);
	Mat Input_1;
	resize(img_1, Input_1, Size(width, height));


	通道分离
	//vector&lt;Mat&gt; channels;
	//split(Input_1, channels);

	//Mat imageBlueChannel;
	//Mat imageGreenChannel;
	//Mat imageRedChannel;

	//imageBlueChannel = channels.at(0);
	//imageGreenChannel = channels.at(1);
	//imageRedChannel = channels.at(2);

	//channels.at(0) = imageRedChannel;
	//channels.at(2) = imageBlueChannel;

	//merge(channels, Input_1);


	std::vector&lt;const char*&gt; input_node_names = { "input_layer" };
	std::vector&lt;const char*&gt; output_node_names = { "add_3" };


	std::array&lt;UINT8, width * height *channel&gt; input_image_1{};
	UINT8* input_1 = input_image_1.data();

	for (int i = 0; i &lt; Input_1.rows; i++) {
		for (int j = 0; j &lt; Input_1.cols; j++) {
			for (int c = 0; c &lt; 3; c++)
			{
				//NHWC 格式
				if (c == 0)
					input_1[i*Input_1.cols * 3 + j * 3 + c] = Input_1.ptr&lt;uchar&gt;(i)[j * 3 + 2];
				if (c == 1)
					input_1[i*Input_1.cols * 3 + j * 3 + c] = Input_1.ptr&lt;uchar&gt;(i)[j * 3 + 1];
				if (c == 2)
					input_1[i*Input_1.cols * 3 + j * 3 + c] = Input_1.ptr&lt;uchar&gt;(i)[j * 3 + 0];
				//NCHW 格式
//                if (c == 0)
//                     input_1[c*imgSource.rows*imgSource.cols + i * imgSource.cols + j] = imgSource.ptr&lt;uchar&gt;(i)[j * 3 + 2]/255.0;
//                if (c == 1)
//                     input_1[c*imgSource.rows*imgSource.cols + i * imgSource.cols + j] = imgSource.ptr&lt;uchar&gt;(i)[j * 3 + 1]/255.0;
//                if (c == 2)
//                     input_1[c*imgSource.rows*imgSource.cols + i * imgSource.cols + j] = imgSource.ptr&lt;uchar&gt;(i)[j * 3 + 0]/255.0;


			}
		}
	}


	std::vector&lt;Ort::Value&gt; input_tensors;
	input_tensors.push_back(Ort::Value::CreateTensor&lt;UINT8&gt;(
		memory_info, input_1, input_image_1.size(), input_shape_.data(), input_shape_.size()));


	auto output_tensors = session.Run(Ort::RunOptions{ nullptr },
		input_node_names.data(), //输入节点名
		input_tensors.data(),     //input tensors
		input_tensors.size(),     //1
		output_node_names.data(), //输出节点名
		output_node_names.size()); //1



	float* output = output_tensors[0].GetTensorMutableData&lt;float&gt;();


	Mat output_1 = Mat::zeros(Size(256, 256), CV_8UC3);

	//for (int i = 0; i &lt; output_1.rows; i++) {
	//	for (int j = 0; j &lt; output_1.cols; j++) {
	//		for (int c = 0; c &lt; 3; c++)
	//		{
	//			//NHWC 格式
	//			if (c == 0)
	//			{
	//				output_1.at&lt;Vec3f&gt;(i, j)[2] = int(output[i*output_1.cols * 3 + j * 3 + c]); cout &lt;&lt; output_1.at&lt;Vec3f&gt;(i, j)[2] &lt;&lt; " ";
	//			}
	//			
	//			else if (c == 1)
	//			{
	//				output_1.at&lt;Vec3f&gt;(i, j)[1] = int(output[i*output_1.cols * 3 + j * 3 + c]); cout &lt;&lt; output_1.at&lt;Vec3f&gt;(i, j)[2] &lt;&lt; " ";
	//			}
	//			else if (c == 2)
	//			{
	//				output_1.at&lt;Vec3f&gt;(i, j)[0] = int(output[i*output_1.cols * 3 + j * 3 + c]); cout &lt;&lt; output_1.at&lt;Vec3f&gt;(i, j)[2] &lt;&lt; " ";
	//			}
	//			
	//		}
	//		cout &lt;&lt; endl;
	//	}
	//}

	for (int i = 0; i &lt; output_1.rows; i++) {
		for (int j = 0; j &lt; output_1.cols; j++) {
			for (int c = 0; c &lt; 3; c++)
			{
				//NHWC 格式
				if (c == 0)
				{
					output_1.ptr&lt;UINT8&gt;(i)[j * 3 + 2] = UINT8(output[i*output_1.cols * 3 + j * 3 + c]);
				}

				else if (c == 1)
				{
					output_1.ptr&lt;UINT8&gt;(i)[j * 3 + 1] = UINT8(output[i*output_1.cols * 3 + j * 3 + c]);
				}
				else if (c == 2)
				{
					output_1.ptr&lt;UINT8&gt;(i)[j * 3 + 0] = UINT8(output[i*output_1.cols * 3 + j * 3 + c]);
				}
			}
		}
	}

	cout &lt;&lt; "tun to here" &lt;&lt; endl;
	cv::imshow("input", Input_1);
	cv::imshow("output", output_1);
	cv::waitKey(0);
}
</code></pre> 
<p>去噪效果感觉不行，主要是跑网络模型啦：</p> 
<p><img alt="" height="366" src="https://images2.imgbox.com/70/22/XNLVgtuk_o.png" width="724"></p> 
<p></p> 
<p>c接口 将版本设成10再导成dll可不依赖源码</p> 
<pre><code class="language-cpp">	const char* inputNames[] = { "input_layer" }; //输入节点名
	const char* outputNames[] = { "add_3" }; //输出节点名
	int inputNodeNum = 1;//输入节点个数
	int outputNodeNum = 1; //输出节点个数

	int input_w = 256;//模型输入width
	int input_h = 256;//模型输入height

	//H*W*C
	size_t model_input_ele_count = input_h * input_w * 3;

	//input data
	UINT8* model_input = (UINT8*)malloc(sizeof(UINT8) * model_input_ele_count);

	//{N,C,H,W}
	int64_t input_shape[4];
	input_shape[0] = 1;
	input_shape[1] = input_h;
	input_shape[2] = input_w;
	input_shape[3] = 3;

	size_t input_shape_len = 4;//dim = 4

	size_t model_input_len = model_input_ele_count * sizeof(UINT8);

	//初始化OrtApi
	const OrtApi* g_ort = nullptr;
	//g_ort = OrtGetApiBase()-&gt;GetApi(ORT_API_VERSION); //这里得用10
	g_ort = OrtGetApiBase()-&gt;GetApi(10);
	//初始化OrtEnv
	OrtEnv* env;
	g_ort-&gt;CreateEnv(ORT_LOGGING_LEVEL_WARNING, "test", &amp;env);

	//初始化session_options
	OrtSessionOptions* session_options;
	g_ort-&gt;CreateSessionOptions(&amp;session_options);

	//初始化session
	OrtSession* session;
	g_ort-&gt;CreateSession(env, model_path, session_options, &amp;session);


	//预处理
	cv::resize(srcimg, srcimg, Size(input_w, input_h));


	//BGR2RGB
	for (int i = 0; i &lt; input_h; i++) {
		for (int j = 0; j &lt; input_w; j++) {
			model_input[i * input_w + j + 0] = srcimg.at&lt;cv::Vec3b&gt;(i, j)[2];//R
			model_input[i * input_w + j + 1 * input_w * input_h] = srcimg.at&lt;cv::Vec3b&gt;(i, j)[1];//G
			model_input[i * input_w + j + 2 * input_w * input_h] = srcimg.at&lt;cv::Vec3b&gt;(i, j)[0];//B
		}
	}

	//input_tensor
	OrtValue* input_tensor = NULL;
	OrtMemoryInfo* memory_info = NULL;
	g_ort-&gt;CreateCpuMemoryInfo(OrtArenaAllocator, OrtMemTypeDefault, &amp;memory_info);
	g_ort-&gt;CreateTensorWithDataAsOrtValue(memory_info, model_input, model_input_len, input_shape, input_shape_len, ONNX_TENSOR_ELEMENT_DATA_TYPE_UINT8, &amp;input_tensor);
	assert(input_tensor != NULL);

	//推理
	OrtValue* output_tensor = NULL;
	g_ort-&gt;Run(session, NULL, inputNames, &amp;input_tensor, inputNodeNum, outputNames, outputNodeNum, &amp;output_tensor);
	assert(output_tensor != NULL);

	//后处理
	std::vector&lt;float&gt; result;

	//获取output的shape
	struct OrtTensorTypeAndShapeInfo* shape_info;
	g_ort-&gt;GetTensorTypeAndShape(output_tensor, &amp;shape_info);


	//获取output的dim
	size_t dim_count;
	g_ort-&gt;GetDimensionsCount(shape_info, &amp;dim_count);
	//std::cout&lt;&lt; dim_count &lt;&lt; std::endl;

	//获取output的shape
	int64_t dims[2];
	g_ort-&gt;GetDimensions(shape_info, dims, sizeof(dims) / sizeof(dims[0]));
	//std::cout&lt;&lt; dims[0] &lt;&lt; "," &lt;&lt; dims[1] &lt;&lt; std::endl;
	

	//取output数据
	float* f;
	auto onnx_status = g_ort-&gt;GetTensorMutableData(output_tensor, (void**)&amp;f);
	float max_val = *max_element(f, f + input_h * input_w * 3);
	float min_val = *min_element(f, f + input_h * input_w * 3);
	float scale = max_val - min_val;

	Mat output = Mat::zeros(Size(input_h, input_w), CV_8UC3);

	//BGR2RGB
	for (int i = 0; i &lt; input_h; i++) {
		for (int j = 0; j &lt; input_w; j++) {
			output.at&lt;cv::Vec3b&gt;(i, j)[2] = UINT8((f[i * input_h + j + 0] - min_val) / scale * 255);
			output.at&lt;cv::Vec3b&gt;(i, j)[1] = UINT8((f[i * input_h + j + 1 * input_h * input_w] - min_val) / scale * 255);
			output.at&lt;cv::Vec3b&gt;(i, j)[0] = UINT8((f[i * input_h + j + 2 * input_h * input_w] - min_val) / scale * 255);
		}
	}


	cv::imshow("res", output);
	cv::waitKey(0);
	cv::destroyAllWindows();</code></pre> 
<p>refer:  https://blog.csdn.net/qq_42995327/article/details/122622222</p> 
<p>模型：<a href="https://download.csdn.net/download/qq_41061370/87494008" title="深度学习去噪onnx模型-深度学习文档类资源-CSDN文库">深度学习去噪onnx模型-深度学习文档类资源-CSDN文库</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0a5371a3b20cd9c3953301b84f6899c5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">jackson序列化时传入前端Long类型缺失精度问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5141509d95f1f731fe0313a29c657d6d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux内核模块的插入和删除</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>