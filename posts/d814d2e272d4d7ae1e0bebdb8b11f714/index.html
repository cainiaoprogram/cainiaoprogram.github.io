<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CBAM注意力回顾 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CBAM注意力回顾" />
<meta property="og:description" content="首先回顾一下CBAM注意力机制：
在CBAM中，通道的注意力使用的是：首先对特征图分别进行一个全局MaxPool和AvgPool操作，再将得到的特征图进行一个共享的感知机，生成两个特征向量，对两个特征向量进行相加，然后进行一个sigmod操作。这样得到了一个通道域的注意力权重。
个人感觉就是将特征图沿着通道找出一个特征点（如上图中，全局MaxPool操作就是将一个特征图H*W*C暴力转换为一个1*1*C的，即在一个H*W的矩阵中找一个最大值作为其中1*1的值，一共找通道数C个）
我们再回顾一下BAM：
BAM的目的就只有一个：对原特征进行重构。依靠权重进行调整。网络图如下：
对于输入特征图F有
M即为一系列操作，对F进行M操作后，得到一个特征图权重系数矩阵是H*W*C维的。这与输入F的维度相符，因此可以最后的步骤为：对F和M(F)进行按元素相乘，再将F与之相加形成残差块。
BAM是一个混合域的注意力机制。因此它有两个分支，Channel branch和Spatial branch
对于Channel branch而言，它对于输入特征图F的操作为：
其中MLP可视为全连接层
全连接层的计算如下：对于输入向量X，每个神经元输出计算向量X的逻辑斯特回归，再经过一个激活函数：如rule，sigmod·增加网络的非线性。
这也就是说BAM的通道注意力部位的计算步骤是这样的：对于一个输入F，首先进行一个全局平均池化，再过两个全连接层，第一个层的神经元个数为c / r，其中r是一个超参数，用于调节网络神经元个数（起到一个降参的作用）。
对于Spatial branch：先进行降维打击，即经过一个1*1的卷积，然后经过两个3*3的空洞卷积，再通过1*1的卷积，得到：
其中
这个过程中1*1的卷积的作用在于升/降维。从最后的输入M可以看出，这是将一个H*W*C的特征图把通道的维度将为1，这样每个像素点代表了原来C个通道像素点的信息。因为得到的是一个H*W的平面，因此称为空间域的注意力机制。
需要注意的是：这里最开始的降维处理跟Channel branch中的bottle neck一样都为c/r
在最后需要将通道和空间这两个部分的权重进行一个组合。也即Combine branch。
BAM中的组合操作是将通道和空域的权重矩阵进行相加，首先要进行维度的统一。毕竟通道权重矩阵的维度是1*1*C而空域的权重矩阵系数是H*W*1，调整的方式也很简单，最后都是调成维度维H*W*C，通道的权重是将每个通道中都扩展为H*W，每个面(H*W)中的值都是当初那个唯一的值。空域的权重扩展是将面进行复制，复制C个。这样两者都成为了H*W*C。
在最后需要元素相乘并于F相加形成残差快。
而CBAM与BAM的不同在于：通道域使用一个全局平均一个全局最大池化，然后共用一个MLP，
在空间域上BAM使用的是3*3的空洞卷积，通过1*1的卷积进行降维，而CBAM用了一个固定的7*7的卷积，或者为固定的3*3，并且是对一个拼接的矩阵进行操作，维度为H*W*2。
二者的不同还在于，BAM是一个并行的结构，而CBAM采用了一个串行的结构。
另外，BAM的作者表明BAM再Bottle neck处更加有效，而CBAM则是插在卷积块之中更有效。
毕竟CBAM全称（Convolutional Block Attention Module）而BAM全称（Bottleneck Attention Module）" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/d814d2e272d4d7ae1e0bebdb8b11f714/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-08-20T20:24:39+08:00" />
<meta property="article:modified_time" content="2022-08-20T20:24:39+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CBAM注意力回顾</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>首先回顾一下CBAM注意力机制：</p> 
<p><img alt="" height="424" src="https://images2.imgbox.com/9b/75/qpNZKuXS_o.png" width="841"></p> 
<p> 在CBAM中，通道的注意力使用的是：首先对特征图分别进行一个全局MaxPool和AvgPool操作，再将得到的特征图进行一个共享的感知机，生成两个特征向量，对两个特征向量进行相加，然后进行一个sigmod操作。这样得到了一个通道域的注意力权重。</p> 
<p>个人感觉就是将特征图沿着通道找出一个特征点（如上图中，<strong>全局MaxPool操作就是将一个特征图H*W*C暴力转换为一个1*1*C的，即在一个H*W的矩阵中找一个最大值作为其中1*1的值，一共找通道数C个</strong>）</p> 
<p>我们再回顾一下BAM：</p> 
<p>BAM的目的就只有一个：<strong>对原特征进行重构。依靠权重进行调整。</strong>网络图如下：</p> 
<p><img alt="" height="231" src="https://images2.imgbox.com/50/28/HKASxdeu_o.png" width="764"></p> 
<p>对于输入特征图F有</p> 
<p style="text-align:center;"> <img alt="M(F)\epsilon \mathbb{R}^{H*W*C}" class="mathcode" src="https://images2.imgbox.com/a2/c2/qmlhVFVd_o.png"></p> 
<p> M即为一系列操作，对F进行M操作后，得到一个<strong>特征图权重系数矩阵</strong>是H*W*C维的。这与输入F的维度相符，因此可以最后的步骤为：对F和M(F)进行<strong>按元素相乘，</strong>再将F与之相加形成残差块<strong>。</strong></p> 
<p><strong>BAM是一个混合域的注意力机制。因此它有两个分支，Channel branch和Spatial branch</strong></p> 
<p>对于Channel branch而言，它对于输入特征图F的操作为：</p> 
<p style="text-align:center;"><img alt="M_{c}(F)=BN(MLP(AvgPool(F)))" class="mathcode" src="https://images2.imgbox.com/6a/c7/78X04Q3q_o.png"></p> 
<p>其中MLP可视为全连接层</p> 
<p>全连接层的计算如下：对于输入向量X，每个神经元输出计算向量X的逻辑斯特回归，再经过一个激活函数：如rule，sigmod·增加网络的非线性。<img alt="" height="434" src="https://images2.imgbox.com/ca/f2/aSC53TQG_o.png" width="914"></p> 
<p> 这也就是说BAM的通道注意力部位的计算步骤是这样的：对于一个输入F，首先进行一个全局平均池化，再过两个全连接层，第一个层的神经元个数为<strong>c / r</strong>，其中r是一个超参数，用于调节网络神经元个数（<strong>起到一个降参的作用</strong>）。</p> 
<p>对于Spatial branch：先进行降维打击，即<strong>经过一个1*1的卷积，然后经过两个3*3的空洞卷积，再通过1*1的卷积</strong>，得到：</p> 
<p style="text-align:center;"><img alt="M{_{s}}(F)=BN(f_{3}^{1\times 1}(f_{2}^{3\times 3}(f_{1}^{3\times 3}(f_{0}^{1\times 1}(F)))))" class="mathcode" src="https://images2.imgbox.com/6e/ac/inCKtjjP_o.png"></p> 
<p> 其中</p> 
<p style="text-align:center;"> <img alt="M_{s}\epsilon \mathbb{R}^{H\times W\times1}" class="mathcode" src="https://images2.imgbox.com/d3/57/ze7cuQ4c_o.png"></p> 
<p> 这个过程中1*1的卷积的作用在于升/降维。从最后的输入M可以看出，这是将一个H*W*C的特征图把通道的维度将为1，这样每个像素点代表了原来C个通道像素点的信息。因为得到的是一个H*W的平面，因此称为空间域的注意力机制。</p> 
<p>需要注意的是：<strong>这里最开始的降维处理跟Channel branch中的bottle neck一样都为c/r</strong></p> 
<p> 在最后需要将通道和空间这两个部分的权重进行一个组合。也即Combine branch。</p> 
<p>BAM中的组合操作是将通道和空域的权重矩阵进行相加，首先要进行<strong>维度的统一。</strong>毕竟通道权重矩阵的维度是1*1*C而空域的权重矩阵系数是H*W*1，调整的方式也很简单，最后都是调成维度维H*W*C，通道的权重是将每个通道中都扩展为H*W，每个面(H*W)中的值都是当初那个唯一的值。空域的权重扩展是将面进行复制，复制C个。这样两者都成为了H*W*C。</p> 
<p>在最后需要元素相乘并于F相加形成残差快。</p> 
<p>而CBAM与BAM的不同在于：通道域使用一个全局平均一个全局最大池化，然后共用一个MLP，</p> 
<p><img alt="" height="92" src="https://images2.imgbox.com/31/c7/b1L6wOpq_o.png" width="605"></p> 
<p> 在空间域上BAM使用的是<strong>3*3的空洞卷积</strong>，通过<strong>1*1的卷积进行降维</strong>，而CBAM用了一个<strong>固定的7*7的卷积</strong>，<strong>或者为固定的3*3</strong>，并且是对一个拼接的矩阵进行操作，维度为H*W*2。<img alt="" height="302" src="https://images2.imgbox.com/7a/a8/DM2fmu6R_o.png" width="1200"></p> 
<p>二者的不同还在于，<strong>BAM是一个并行的结构，而CBAM采用了一个串行的结构。</strong></p> 
<p><strong>另外，BAM的作者表明BAM再Bottle neck处更加有效，而CBAM则是插在卷积块之中更有效。</strong></p> 
<p>毕竟CBAM全称（Convolutional Block Attention Module）而BAM全称（Bottleneck Attention Module）</p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3f4b3692c95ea28196d4b49e439f737b/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">在 Windows 10 环境 Docker Desktop V4.11.1 版本中为 Kubernetes 开通 30000 以下端口的使用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/64e6b428cf11ce91b652a5be0df8070a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Python/numpy 设置数组某一整行列的值为0/1 修改数组行列设置为特定值</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>