<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>《YOLO小目标检测》专栏介绍 &amp; CSDN独家改进创新实战&amp;专栏目录 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="《YOLO小目标检测》专栏介绍 &amp; CSDN独家改进创新实战&amp;专栏目录" />
<meta property="og:description" content="💡💡💡Yolo小目标检测，独家首发创新（原创），适用于Yolov5、Yolov7、Yolov8等各个Yolo系列，专栏文章提供每一步步骤和源码，带你轻松实现小目标检测涨点
💡💡💡重点：通过本专栏的阅读，后续你可以结合自己的小目标检测数据集，在网络不同位置（Backbone、head、detect、loss等）进行魔改，实现小目标涨点和创新！！！
专栏介绍：
✨✨✨解决小目标检测难点并提升小目标检测性能；
🚀🚀🚀小目标、遮挡物性能提升和创新；
💡💡💡 工业界小目标检测性能提升和部署可行性；
🍉🍉🍉持续更新中，定期更新不同数据集涨点情况；
layers parametersGFLOPskb mAP50yolov816830058438.161030.755Wasserstein loss16830058438.161030.784yolov8_smallob207292117212.261370.878yolov8_SEAM21931093318.363310.785yolov8_SPD174359873949.273940.875yolov8_EVC217729352311.5145130.779yolov8_BiFPN16830058498.161040.766yolov8_ContextAggregation19530080928.161210.759yolov8_EMA19230067398.161140.766yolov8_DCNV326428923177.958920.765yolov8_MCALayer20925456597.251940.769yolov8_BiFormerBlock204335617922.468000.758yolov8_LSKblockAttention20133433338.767840.775yolov8_GPFN21629861318.160790.766yolov8_C2f_Pconv17727168837.655370.758yolov8_ODConv17930121107.961210.76yolov8_TripletAttention20130064438.261200.79yolov8_ChannelAttention17131374277.864280.815yolov8_DySnakeConv22933562878.568220.77yolov8_MultiSEAM3255742291117110.87yolov8_MobileViTAttention241395765911.179920.799yolov8-RFA25830194398.261660.765yolov8_BasicRFB30334402358.970400.762yolov8_RepViTBlock18633383877.967710.791yolov8-goldyolo359601512311.9121230.768yolov8_DualAttention18646048198.392360.766 目录
1.小目标检测介绍
1.1 小目标定义
1.2 难点
2. 本专栏小目标数据集
3.小目标专栏难点优化方向
3.1 合理的数据增强
3.2 网络多尺度
3.2.1 多头检测器
3.2.2 BiFPN高效双向跨尺度连接和加权特征融合
3.2.3 小目标到大目标一网打尽，轻骨干重Neck的轻量级目标检测器GiraffeDet
3.2.4 多分支卷积模块RFB
3.2.5 GOLD-YOLO，遥遥领先
3.3 loss优化
3.3.1 Wasserstein Distance Loss
3.4 注意力机制
3.4.1SEAM注意力机制
3.4.2 即插即用的多尺度融合模块EVC
3.4.3 微小目标检测的上下文增强和特征细化网络ContextAggregation
3.4.4 EMA跨空间学习的高效多尺度注意力 | ICASSP2023
3.4.5 动态稀疏注意力BiFormer | CVPR 2023 3.4.6 LSKblockAttention | ICCV 2023 3.4.7 TripletAttention注意力
3.4.8 通道优先卷积注意力（CPCA）| 中科院 2023.6
3.4.8 多尺度MultiSEAM" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/24607345d85015f63aa429a0158da892/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-09-30T13:05:55+08:00" />
<meta property="article:modified_time" content="2023-09-30T13:05:55+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">《YOLO小目标检测》专栏介绍 &amp; CSDN独家改进创新实战&amp;专栏目录</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="1.%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BB%8B%E7%BB%8D"> 💡💡💡<strong><span style="color:#fe2c24;">Yolo小目标检测</span></strong><span style="color:#ff9900;"><strong><strong>，</strong>独家首发创新（原创），适用于Yolov5、Yolov7、Yolov8等各个Yolo系列，专栏文章提供每一步步骤和源码，带你轻松实现小目标检测涨点</strong></span></p> 
<p>💡💡💡<span style="color:#956fe7;"><strong>重点：</strong>通过本专栏的阅读，后续你可以结合自己的小目标检测数据集，在网络不同位置（Backbone、head、detect、loss等）进行魔改，实现小目标涨点和创新！！！</span></p> 
<p><span style="color:#fe2c24;"><strong>专栏介绍：</strong></span></p> 
<p>✨✨✨<span style="color:#a2e043;">解决小目标检测难点并提升小目标检测性能；</span></p> 
<p>🚀🚀🚀<span style="color:#38d8f0;">小目标、遮挡物性能提升和创新；</span></p> 
<p>💡💡💡<span style="color:#4da8ee;"> 工业界小目标检测性能提升和部署可行性；</span></p> 
<p>🍉🍉🍉<span style="color:#1c7331;">持续更新中，定期更新不同数据集涨点情况；</span></p> 
<p></p> 
<table cellspacing="0" style="width:421pt;"><tbody><tr><td style="vertical-align:bottom;width:189pt;"></td><td style="vertical-align:bottom;width:37pt;"><span style="color:#000000;">layers</span></td><td style="vertical-align:bottom;width:64pt;"><span style="color:#000000;"> parameters</span></td><td style="vertical-align:bottom;width:46pt;"><span style="color:#000000;">GFLOPs</span></td><td style="vertical-align:bottom;width:37pt;"><span style="color:#000000;">kb</span></td><td style="vertical-align:bottom;width:48pt;"><span style="color:#000000;"> mAP50</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">168</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3005843</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6103</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.755</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">Wasserstein loss</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">168</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3005843</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6103</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.784</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_smallob</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">207</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">2921172</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">12.2</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6137</span></td><td style="vertical-align:bottom;"><span style="color:#fe2c24;">0.878</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_SEAM</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">219</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3109331</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.3</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6331</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.785</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_SPD</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">174</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3598739</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">49.2</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7394</span></td><td style="vertical-align:bottom;"><span style="color:#fe2c24;">0.875</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_EVC</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">217</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7293523</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">11.5</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">14513</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.779</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_BiFPN</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">168</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3005849</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6104</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.766</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_ContextAggregation</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">195</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3008092</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6121</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.759</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_EMA</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">192</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3006739</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6114</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.766</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_DCNV3</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">264</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">2892317</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7.9</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">5892</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.765</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_MCALayer</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">209</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">2545659</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7.2</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">5194</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.769</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_BiFormerBlock</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">204</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3356179</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">22.4</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6800</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.758</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_LSKblockAttention</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">201</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3343333</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.7</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6784</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.775</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_GPFN</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">216</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">2986131</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6079</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.766</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_C2f_Pconv</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">177</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">2716883</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7.6</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">5537</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.758</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_ODConv</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">179</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3012110</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7.9</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6121</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.76</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_TripletAttention</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">201</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3006443</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.2</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6120</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.79</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_ChannelAttention</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">171</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3137427</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7.8</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6428</span></td><td style="vertical-align:bottom;"><span style="color:#fe2c24;">0.815</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_DySnakeConv</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">229</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3356287</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.5</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6822</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.77</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_MultiSEAM</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">325</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">5742291</span></td><td style="vertical-align:bottom;"></td><td style="vertical-align:bottom;"><span style="color:#000000;">11711</span></td><td style="vertical-align:bottom;"><span style="color:#fe2c24;">0.87</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_MobileViTAttention</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">241</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3957659</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">11.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7992</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.799</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8-RFA</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">258</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3019439</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.2</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6166</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.765</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_BasicRFB</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">303</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3440235</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.9</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7040</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.762</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_RepViTBlock</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">186</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3338387</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">7.9</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6771</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.791</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8-goldyolo</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">359</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6015123</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">11.9</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">12123</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.768</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_DualAttention</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">186</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">4604819</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.3</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">9236</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.766</span></td></tr></tbody></table> 
<h2 id="%E2%80%8B%E7%BC%96%E8%BE%91" style="text-align:center;"><img alt="" src="https://images2.imgbox.com/e6/6d/8yWd88BG_o.jpg"></h2> 
<p></p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BB%8B%E7%BB%8D-toc" style="margin-left:0px;"><a href="#1.%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BB%8B%E7%BB%8D" rel="nofollow">1.小目标检测介绍</a></p> 
<p id="1.1%20%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%B9%89-toc" style="margin-left:40px;"><a href="#1.1%20%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%B9%89" rel="nofollow">1.1 小目标定义</a></p> 
<p id="1.2%20%E9%9A%BE%E7%82%B9-toc" style="margin-left:40px;"><a href="#1.2%20%E9%9A%BE%E7%82%B9" rel="nofollow">1.2 难点</a></p> 
<p id="2.%20%E6%9C%AC%E4%B8%93%E6%A0%8F%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:0px;"><a href="#2.%20%E6%9C%AC%E4%B8%93%E6%A0%8F%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow">2. 本专栏小目标数据集</a></p> 
<p id="3.%E5%B0%8F%E7%9B%AE%E6%A0%87%E4%B8%93%E6%A0%8F%E9%9A%BE%E7%82%B9%E4%BC%98%E5%8C%96%E6%96%B9%E5%90%91-toc" style="margin-left:0px;"><a href="#3.%E5%B0%8F%E7%9B%AE%E6%A0%87%E4%B8%93%E6%A0%8F%E9%9A%BE%E7%82%B9%E4%BC%98%E5%8C%96%E6%96%B9%E5%90%91" rel="nofollow">3.小目标专栏难点优化方向</a></p> 
<p id="3.1%20%E5%90%88%E7%90%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA-toc" style="margin-left:40px;"><a href="#3.1%20%E5%90%88%E7%90%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA" rel="nofollow">3.1 合理的数据增强</a></p> 
<p id="3.2%20%E7%BD%91%E7%BB%9C%E5%A4%9A%E5%B0%BA%E5%BA%A6-toc" style="margin-left:40px;"><a href="#3.2%20%E7%BD%91%E7%BB%9C%E5%A4%9A%E5%B0%BA%E5%BA%A6" rel="nofollow">3.2 网络多尺度</a></p> 
<p id="%C2%A03.2.1%20%E5%A4%9A%E5%A4%B4%E6%A3%80%E6%B5%8B%E5%99%A8-toc" style="margin-left:80px;"><a href="#%C2%A03.2.1%20%E5%A4%9A%E5%A4%B4%E6%A3%80%E6%B5%8B%E5%99%A8" rel="nofollow"> 3.2.1 多头检测器</a></p> 
<p id="%C2%A03.2.2%C2%A0BiFPN%E9%AB%98%E6%95%88%E5%8F%8C%E5%90%91%E8%B7%A8%E5%B0%BA%E5%BA%A6%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%8A%A0%E6%9D%83%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88-toc" style="margin-left:80px;"><a href="#%C2%A03.2.2%C2%A0BiFPN%E9%AB%98%E6%95%88%E5%8F%8C%E5%90%91%E8%B7%A8%E5%B0%BA%E5%BA%A6%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%8A%A0%E6%9D%83%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88" rel="nofollow"> 3.2.2 BiFPN高效双向跨尺度连接和加权特征融合</a></p> 
<p id="3.2.3%C2%A0%C2%A0%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%88%B0%E5%A4%A7%E7%9B%AE%E6%A0%87%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%EF%BC%8C%E8%BD%BB%E9%AA%A8%E5%B9%B2%E9%87%8DNeck%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet-toc" style="margin-left:80px;"><a href="#3.2.3%C2%A0%C2%A0%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%88%B0%E5%A4%A7%E7%9B%AE%E6%A0%87%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%EF%BC%8C%E8%BD%BB%E9%AA%A8%E5%B9%B2%E9%87%8DNeck%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet" rel="nofollow">3.2.3  小目标到大目标一网打尽，轻骨干重Neck的轻量级目标检测器GiraffeDet</a></p> 
<p id="3.2.4%C2%A0%E5%A4%9A%E5%88%86%E6%94%AF%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97RFB-toc" style="margin-left:80px;"><a href="#3.2.4%C2%A0%E5%A4%9A%E5%88%86%E6%94%AF%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97RFB" rel="nofollow">3.2.4 多分支卷积模块RFB</a></p> 
<p id="3.2.5%20GOLD-YOLO%EF%BC%8C%E9%81%A5%E9%81%A5%E9%A2%86%E5%85%88-toc" style="margin-left:80px;"><a href="#3.2.5%20GOLD-YOLO%EF%BC%8C%E9%81%A5%E9%81%A5%E9%A2%86%E5%85%88" rel="nofollow">3.2.5 GOLD-YOLO，遥遥领先</a></p> 
<p id="3.3%20loss%E4%BC%98%E5%8C%96-toc" style="margin-left:40px;"><a href="#3.3%20loss%E4%BC%98%E5%8C%96" rel="nofollow">3.3 loss优化</a></p> 
<p id="3.3.1%C2%A0Wasserstein%20Distance%20Loss-toc" style="margin-left:80px;"><a href="#3.3.1%C2%A0Wasserstein%20Distance%20Loss" rel="nofollow">3.3.1 Wasserstein Distance Loss</a></p> 
<p id="-toc" style="margin-left:40px;"></p> 
<p id="3.4%C2%A0%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:40px;"><a href="#3.4%C2%A0%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">3.4  注意力机制</a></p> 
<p id="3.4.1SEAM%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6-toc" style="margin-left:80px;"><a href="#3.4.1SEAM%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" rel="nofollow">3.4.1SEAM注意力机制</a></p> 
<p id="3.4.2%C2%A0%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88%E6%A8%A1%E5%9D%97EVC-toc" style="margin-left:80px;"><a href="#3.4.2%C2%A0%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88%E6%A8%A1%E5%9D%97EVC" rel="nofollow">3.4.2 即插即用的多尺度融合模块EVC</a></p> 
<p id="%C2%A03.4.3%C2%A0%E5%BE%AE%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A2%9E%E5%BC%BA%E5%92%8C%E7%89%B9%E5%BE%81%E7%BB%86%E5%8C%96%E7%BD%91%E7%BB%9CContextAggregation-toc" style="margin-left:80px;"><a href="#%C2%A03.4.3%C2%A0%E5%BE%AE%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A2%9E%E5%BC%BA%E5%92%8C%E7%89%B9%E5%BE%81%E7%BB%86%E5%8C%96%E7%BD%91%E7%BB%9CContextAggregation" rel="nofollow"> 3.4.3 微小目标检测的上下文增强和特征细化网络ContextAggregation</a></p> 
<p id="3.4.4%C2%A0EMA%E8%B7%A8%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AB%98%E6%95%88%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%B3%A8%E6%84%8F%E5%8A%9B%C2%A0%7C%20ICASSP2023-toc" style="margin-left:80px;"><a href="#3.4.4%C2%A0EMA%E8%B7%A8%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AB%98%E6%95%88%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%B3%A8%E6%84%8F%E5%8A%9B%C2%A0%7C%20ICASSP2023" rel="nofollow">3.4.4 EMA跨空间学习的高效多尺度注意力 | ICASSP2023</a></p> 
<p id="3.4.5%20%E5%8A%A8%E6%80%81%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9BBiFormer%20%7C%20CVPR%202023%C2%A0-toc" style="margin-left:80px;"><a href="#3.4.5%20%E5%8A%A8%E6%80%81%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9BBiFormer%20%7C%20CVPR%202023%C2%A0" rel="nofollow">3.4.5 动态稀疏注意力BiFormer | CVPR 2023 </a></p> 
<p id="3.4.6%C2%A0%20LSKblockAttention%20%7C%20ICCV%202023%C2%A0-toc" style="margin-left:80px;"><a href="#3.4.6%C2%A0%20LSKblockAttention%20%7C%20ICCV%202023%C2%A0" rel="nofollow">3.4.6  LSKblockAttention | ICCV 2023 </a></p> 
<p id="3.4.7%C2%A0TripletAttention%E6%B3%A8%E6%84%8F%E5%8A%9B-toc" style="margin-left:80px;"><a href="#3.4.7%C2%A0TripletAttention%E6%B3%A8%E6%84%8F%E5%8A%9B" rel="nofollow">3.4.7 TripletAttention注意力</a></p> 
<p id="3.4.8%C2%A0%C2%A0%E9%80%9A%E9%81%93%E4%BC%98%E5%85%88%E5%8D%B7%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%88CPCA%EF%BC%89%7C%20%E4%B8%AD%E7%A7%91%E9%99%A2%202023.6-toc" style="margin-left:80px;"><a href="#3.4.8%C2%A0%C2%A0%E9%80%9A%E9%81%93%E4%BC%98%E5%85%88%E5%8D%B7%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%88CPCA%EF%BC%89%7C%20%E4%B8%AD%E7%A7%91%E9%99%A2%202023.6" rel="nofollow">3.4.8  通道优先卷积注意力（CPCA）| 中科院 2023.6</a></p> 
<p id="3.4.8%C2%A0%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6MultiSEAM-toc" style="margin-left:80px;"><a href="#3.4.8%C2%A0%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6MultiSEAM" rel="nofollow">3.4.8  多尺度MultiSEAM</a></p> 
<p id="3.4.9%C2%A0%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%B3%A8%E6%84%8F%E5%8A%9BMobileViTAttention%20%7C%20ECCV2022%C2%A0-toc" style="margin-left:80px;"><a href="#3.4.9%C2%A0%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%B3%A8%E6%84%8F%E5%8A%9BMobileViTAttention%20%7C%20ECCV2022%C2%A0" rel="nofollow">3.4.9 轻量级注意力MobileViTAttention | ECCV2022 </a></p> 
<p id="3.4.10%C2%A0%E6%84%9F%E5%8F%97%E9%87%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97-toc" style="margin-left:80px;"><a href="#3.4.10%C2%A0%E6%84%9F%E5%8F%97%E9%87%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97" rel="nofollow">3.4.10 感受野注意力卷积运算</a></p> 
<p id="3.4.11%C2%A0Dual-ViT%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%8F%8C%E8%A7%86%E8%A7%89Transformer-toc" style="margin-left:80px;"><a href="#3.4.11%C2%A0Dual-ViT%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%8F%8C%E8%A7%86%E8%A7%89Transformer" rel="nofollow">3.4.11 Dual-ViT：一种多尺度双视觉Transformer</a></p> 
<p id="3.5%20%E5%8D%B7%E7%A7%AF%E5%8F%98%E4%BD%93-toc" style="margin-left:40px;"><a href="#3.5%20%E5%8D%B7%E7%A7%AF%E5%8F%98%E4%BD%93" rel="nofollow">3.5 卷积变体</a></p> 
<p id="3.5.1%20SPD-Conv-toc" style="margin-left:80px;"><a href="#3.5.1%20SPD-Conv" rel="nofollow">3.5.1 SPD-Conv</a></p> 
<p id="3.5.2%20DCNv3%E5%8F%AF%E5%BD%A2%E5%8F%98%E5%8D%B7%E7%A7%AF%20%7C%20CVPR2023-toc" style="margin-left:80px;"><a href="#3.5.2%20DCNv3%E5%8F%AF%E5%BD%A2%E5%8F%98%E5%8D%B7%E7%A7%AF%20%7C%20CVPR2023" rel="nofollow">3.5.2 DCNv3可形变卷积 | CVPR2023</a></p> 
<p id="3.5.3%C2%A0%E6%96%B0%E7%9A%84Partial%E5%8D%B7%E7%A7%AF(PConv)%20%7C%20CVPR2023%20FasterNet%C2%A0-toc" style="margin-left:80px;"><a href="#3.5.3%C2%A0%E6%96%B0%E7%9A%84Partial%E5%8D%B7%E7%A7%AF%28PConv%29%20%7C%20CVPR2023%20FasterNet%C2%A0" rel="nofollow">3.5.3 新的Partial卷积(PConv) | CVPR2023 FasterNet </a></p> 
<p id="3.5.4%C2%A0ODConv%C2%A0%7C%20ICLR%202022-toc" style="margin-left:80px;"><a href="#3.5.4%C2%A0ODConv%C2%A0%7C%20ICLR%202022" rel="nofollow">3.5.4 ODConv | ICLR 2022</a></p> 
<p id="3.5.5%C2%A0%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF%EF%BC%88Dynamic%20Snake%20Convolution%EF%BC%89%20%7C%20ICCV2023-toc" style="margin-left:80px;"><a href="#3.5.5%C2%A0%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF%EF%BC%88Dynamic%20Snake%20Convolution%EF%BC%89%20%7C%20ICCV2023" rel="nofollow">3.5.5 动态蛇形卷积（Dynamic Snake Convolution） | ICCV2023</a></p> 
<p id="%E7%95%AA%E5%A4%96%E7%AF%87%EF%BC%9A%E5%B7%A5%E4%B8%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B-toc" style="margin-left:0px;"><a href="#%E7%95%AA%E5%A4%96%E7%AF%87%EF%BC%9A%E5%B7%A5%E4%B8%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B" rel="nofollow">番外篇：工业小目标缺陷检测</a></p> 
<p id="1.1%20%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF%EF%BC%88Dynamic%20Snake%20Convolution%EF%BC%89%EF%BC%8C%E5%AE%9E%E7%8E%B0%E6%9A%B4%E5%8A%9B%E6%B6%A8%E7%82%B9%20%7C%20ICCV2023-toc" style="margin-left:80px;"><a href="#1.1%20%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF%EF%BC%88Dynamic%20Snake%20Convolution%EF%BC%89%EF%BC%8C%E5%AE%9E%E7%8E%B0%E6%9A%B4%E5%8A%9B%E6%B6%A8%E7%82%B9%20%7C%20ICCV2023" rel="nofollow">1.1 动态蛇形卷积（Dynamic Snake Convolution），实现暴力涨点 | ICCV2023</a></p> 
<p id="1.2%20%E5%BE%AE%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E6%A3%80%E6%B5%8B%E8%83%BD%E5%8A%9B%E4%B8%8D%E4%BD%B3%E7%9A%84%E7%8E%B0%E8%B1%A1%EF%BC%8C%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AA%E5%BE%AE%E5%B0%8F%E7%89%A9%E4%BD%93%E7%9A%84%E6%A3%80%E6%B5%8B%E5%A4%B4-toc" style="margin-left:80px;"><a href="#1.2%20%E5%BE%AE%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E6%A3%80%E6%B5%8B%E8%83%BD%E5%8A%9B%E4%B8%8D%E4%BD%B3%E7%9A%84%E7%8E%B0%E8%B1%A1%EF%BC%8C%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AA%E5%BE%AE%E5%B0%8F%E7%89%A9%E4%BD%93%E7%9A%84%E6%A3%80%E6%B5%8B%E5%A4%B4" rel="nofollow">1.2 微小目标检测可能存在检测能力不佳的现象，添加一个微小物体的检测头</a></p> 
<p id="1.3%20SPD-Conv%EF%BC%8C%E4%BD%8E%E5%88%86%E8%BE%A8%E7%8E%87%E5%9B%BE%E5%83%8F%E5%92%8C%E5%B0%8F%E7%89%A9%E4%BD%93%E6%B6%A8%E7%82%B9%E6%98%8E%E6%98%BE-toc" style="margin-left:80px;"><a href="#1.3%20SPD-Conv%EF%BC%8C%E4%BD%8E%E5%88%86%E8%BE%A8%E7%8E%87%E5%9B%BE%E5%83%8F%E5%92%8C%E5%B0%8F%E7%89%A9%E4%BD%93%E6%B6%A8%E7%82%B9%E6%98%8E%E6%98%BE" rel="nofollow">1.3 SPD-Conv，低分辨率图像和小物体涨点明显</a></p> 
<p id="1.4%E5%A4%A7%E7%BC%BA%E9%99%B7%E5%B0%8F%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet-toc" style="margin-left:80px;"><a href="#1.4%E5%A4%A7%E7%BC%BA%E9%99%B7%E5%B0%8F%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet" rel="nofollow">1.4大缺陷小缺陷一网打尽的轻量级目标检测器GiraffeDet</a></p> 
<p id="%C2%A01.5%20%E5%A4%9A%E6%A3%80%E6%B5%8B%E5%A4%B4%E7%BB%93%E5%90%88%E5%B0%8F%E7%BC%BA%E9%99%B7%E5%88%B0%E5%A4%A7%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet-toc" style="margin-left:80px;"><a href="#%C2%A01.5%20%E5%A4%9A%E6%A3%80%E6%B5%8B%E5%A4%B4%E7%BB%93%E5%90%88%E5%B0%8F%E7%BC%BA%E9%99%B7%E5%88%B0%E5%A4%A7%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet" rel="nofollow"> 1.5 多检测头结合小缺陷到大缺陷一网打尽的轻量级目标检测器GiraffeDet</a></p> 
<p id="%C2%A01.6%C2%A0Wasserstein%20Distance%20Loss%EF%BC%8C%E5%8A%A9%E5%8A%9B%E5%B7%A5%E4%B8%9A%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B-toc" style="margin-left:80px;"><a href="#%C2%A01.6%C2%A0Wasserstein%20Distance%20Loss%EF%BC%8C%E5%8A%A9%E5%8A%9B%E5%B7%A5%E4%B8%9A%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B" rel="nofollow"> 1.6 Wasserstein Distance Loss，助力工业缺陷检测</a></p> 
<p id="1.7%20%E5%B7%A5%E4%B8%9A%E9%83%A8%E7%BD%B2%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%C2%A0%E5%A4%9A%E5%A4%B4%E6%A3%80%E6%B5%8B%E5%99%A8%2B%E5%B0%8F%E7%BC%BA%E9%99%B7%E5%88%B0%E5%A4%A7%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%2BWasserstein%20Distance%20Loss-toc" style="margin-left:80px;"><a href="#1.7%20%E5%B7%A5%E4%B8%9A%E9%83%A8%E7%BD%B2%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%C2%A0%E5%A4%9A%E5%A4%B4%E6%A3%80%E6%B5%8B%E5%99%A8%2B%E5%B0%8F%E7%BC%BA%E9%99%B7%E5%88%B0%E5%A4%A7%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%2BWasserstein%20Distance%20Loss" rel="nofollow">1.7 工业部署级解决方案： 多头检测器+小缺陷到大缺陷一网打尽的+Wasserstein Distance Loss</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="1.%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%BB%8B%E7%BB%8D">1.小目标检测介绍</h2> 
<h3 id="1.1%20%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%AE%9A%E4%B9%89">1.1 小目标定义</h3> 
<p>1）以物体检测领域的通用数据集COCO物体定义为例，小目标是指小于32×32个像素点（中物体是指32*32-96*96，大物体是指大于96*96）；<br> 2）在实际应用场景中，通常更倾向于使用相对于原图的比例来定义：物体标注框的长宽乘积，除以整个图像的长宽乘积，再开根号，如果结果小于3%，就称之为小目标；</p> 
<p><img alt="" height="563" src="https://images2.imgbox.com/e2/f9/hss3yVxm_o.png" width="700"></p> 
<h3 id="1.2%20%E9%9A%BE%E7%82%B9">1.2 难点</h3> 
<p>1）包含小目标的样本数量较少，这样潜在的让目标检测模型更关注中大目标的检测；</p> 
<p>2）由小目标覆盖的区域更小，这样小目标的位置会缺少多样性。我们推测这使得小目标检测的在验证时的通用性变得很难；</p> 
<p><img alt="" height="171" src="https://images2.imgbox.com/f0/ec/s9L7Vlzi_o.png" width="603"></p> 
<p>3）anchor难匹配问题。这主要针对anchor-based方法，由于小目标的gt box和anchor都很小，anchor和gt box稍微产生偏移，IoU就变得很低，导致很容易被网络判断为negative sample；</p> 
<p>4）它们不仅仅是小，而且是难，存在不同程度的遮挡、模糊、不完整现象；</p> 
<p>等等难点</p> 
<p>参考论文：<a href="http://sjcj.nuaa.edu.cn/sjcjycl/article/html/202103001" rel="nofollow" title="http://sjcj.nuaa.edu.cn/sjcjycl/article/html/202103001">http://sjcj.nuaa.edu.cn/sjcjycl/article/html/202103001</a>  </p> 
<h2 id="2.%20%E6%9C%AC%E4%B8%93%E6%A0%8F%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%95%B0%E6%8D%AE%E9%9B%86">2. 本专栏小目标数据集</h2> 
<p>数据集下载地址：<a href="https://github.com/YimianDai/sirst/tree/master" title="GitHub - YimianDai/sirst: A dataset constructed for single-frame infrared small target detection">GitHub - YimianDai/sirst: A dataset constructed for single-frame infrared small target detection</a></p> 
<p>Single-frame InfraRed Small Target </p> 
<p>数据集大小：427张，进行3倍数据增强得到1708张，最终训练集验证集测试集随机分配为8：1：1</p> 
<p><img alt="" height="994" src="https://images2.imgbox.com/b6/f7/AGo8Rzn9_o.png" width="993"></p> 
<p></p> 
<h2 id="3.%E5%B0%8F%E7%9B%AE%E6%A0%87%E4%B8%93%E6%A0%8F%E9%9A%BE%E7%82%B9%E4%BC%98%E5%8C%96%E6%96%B9%E5%90%91">3.小目标专栏难点优化方向</h2> 
<h3 id="3.1%20%E5%90%88%E7%90%86%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA">3.1 合理的数据增强</h3> 
<ul><li> <p>将小目标在同一张图像中多拷贝几次；增加了匹配到小目标GT的anchor的数量；如涂鸦式增强</p> </li></ul> 
<p><img alt="" height="486" src="https://images2.imgbox.com/e0/68/5oMrerMe_o.png" width="553"></p> 
<h3 id="3.2%20%E7%BD%91%E7%BB%9C%E5%A4%9A%E5%B0%BA%E5%BA%A6">3.2 网络多尺度</h3> 
<p>         通过<em>P</em>2层特征引出了新的检测头.<em>P</em>2层检测头分辨率为160×160像素, 相当于在主干网络中只进行了2次下采样操作, 含有目标更为丰富的底层特征信息. 颈部网络中自上而下和自下而上得到的两个<em>P</em>2层特征与主干网络中的同尺度特征通过concat形式进行特征融合, 输出的特征为3个输入特征的融合结果, 这样使得<em>P</em>2层检测头应对微小目标时, 能够快速有效的检测. <img alt="" height="563" src="https://images2.imgbox.com/bd/44/p3DpUlnp_o.png" width="890"></p> 
<h4 id="%C2%A03.2.1%20%E5%A4%9A%E5%A4%B4%E6%A3%80%E6%B5%8B%E5%99%A8"> 3.2.1 多头检测器</h4> 
<p><span style="color:#fe2c24;"> <strong>亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.878</strong></span></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132379054" rel="nofollow" title="Yolov8红外弱小目标检测（3）：多头检测头提升红外弱小目标检测精度_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（3）：多头检测头提升红外弱小目标检测精度_AI小怪兽的博客-CSDN博客</a></p> 
<p><img alt="" src="https://images2.imgbox.com/5c/d5/YG11NagQ_o.jpg"></p> 
<table cellspacing="0" style="width:459pt;"><tbody><tr><td style="vertical-align:bottom;width:201pt;"></td><td style="vertical-align:bottom;width:41pt;"><span style="color:#000000;">layers</span></td><td style="vertical-align:bottom;width:71pt;"><span style="color:#000000;"> parameters</span></td><td style="vertical-align:bottom;width:51pt;"><span style="color:#000000;">GFLOPs</span></td><td style="vertical-align:bottom;width:41pt;"><span style="color:#000000;">kb</span></td><td style="vertical-align:bottom;width:54pt;"><span style="color:#000000;"> mAP50</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">168</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3005843</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6103</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.755</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8_smallob</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">207</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">2921172</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">12.2</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6137</span></td><td style="vertical-align:bottom;"><span style="color:#fe2c24;"><strong>0.878</strong></span></td></tr></tbody></table> 
<h4 id="%C2%A03.2.2%C2%A0BiFPN%E9%AB%98%E6%95%88%E5%8F%8C%E5%90%91%E8%B7%A8%E5%B0%BA%E5%BA%A6%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%8A%A0%E6%9D%83%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88"> 3.2.2 BiFPN高效双向跨尺度连接和加权特征融合</h4> 
<p> BiFPN 的主要思想：高效双向跨尺度连接和加权特征融合 </p> 
<p><img alt="" height="647" src="https://images2.imgbox.com/46/f0/IaUBjI25_o.png" width="1200"></p> 
<p>        文中提出了BiFPN和联合缩放方法（Compound Scaling），BiFPN考虑到不同特征融合对于输出特征的重要性；联合缩放方法（Compound Scaling） 综合考虑图像输入分辨率、网络宽度和深度这些因素，权衡了准确率和效率。如图所示为本文的整体结构图：</p> 
<p><img alt="" height="306" src="https://images2.imgbox.com/de/a9/FdaJQ77S_o.png" width="741"></p> 
<p></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132445937" rel="nofollow" title="Yolov8红外弱小目标检测（7）：BiFPN高效双向跨尺度连接和加权特征融合，助力小目标检测_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（7）：BiFPN高效双向跨尺度连接和加权特征融合，助力小目标检测_AI小怪兽的博客-CSDN博客</a></p> 
<p><strong><span style="color:#fe2c24;">BiFPN |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.766 </span></strong></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_BiFPN</td><td>168</td><td>3005849</td><td>8.1</td><td>6104</td><td>0.766</td></tr></tbody></table> 
<h4 id="3.2.3%C2%A0%C2%A0%E5%B0%8F%E7%9B%AE%E6%A0%87%E5%88%B0%E5%A4%A7%E7%9B%AE%E6%A0%87%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%EF%BC%8C%E8%BD%BB%E9%AA%A8%E5%B9%B2%E9%87%8DNeck%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet">3.2.3  小目标到大目标一网打尽，轻骨干重Neck的轻量级目标检测器GiraffeDet</h4> 
<p> 本文是阿里巴巴在目标检测领域的工作(已被ICLR2022接收)，提出了一种新颖的类“长颈鹿”的GiraffeDet架构，它采用了轻骨干、重Neck的架构设计范式。所提GiraffeDet在COCO数据集上取得了比常规CNN骨干更优异的性能，取得了54.1%mAP指标，具有更优异的处理目标大尺度变化问题的能力。</p> 
<p><img alt="" height="397" src="https://images2.imgbox.com/56/49/vU1Rgb7n_o.png" width="866">​</p> 
<p>         本文提出了GiraffeDet用于高效目标检测，giraffe包含轻量space-to-depth chain、Generalized-FPN以及预测网络</p> 
<p><img alt="" height="429" src="https://images2.imgbox.com/94/a1/PeSdLDiG_o.png" width="1012">​</p> 
<p><span style="color:#fe2c24;">        <strong>GFPN |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.766</strong></span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_GPFN</td><td>216</td><td>2986131</td><td>8.1</td><td>6079</td><td>0.766</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132581415" rel="nofollow" title="Yolov8小目标检测（14）：小目标到大目标一网打尽，轻骨干重Neck的轻量级目标检测器GiraffeDet_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（14）：小目标到大目标一网打尽，轻骨干重Neck的轻量级目标检测器GiraffeDet_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.2.4%C2%A0%E5%A4%9A%E5%88%86%E6%94%AF%E5%8D%B7%E7%A7%AF%E6%A8%A1%E5%9D%97RFB">3.2.4 多分支卷积模块RFB</h4> 
<p>    受启发于人类视觉的Receptive Fields结构，本文提出RFB，将RFs的尺度、离心率纳入考虑范围，使用轻量级主干网也能提取到高判别性特征，使得检测器速度快、精度高；具体地，RFB基于RFs的不同尺度，使用不同的卷积核，设计了多分支的conv、pooling操作（makes use of <strong>multi-branch pooling with varying kernels</strong>），并通过虫洞卷积（dilated conv）来控制感受野的离心率，最后一步reshape操作后，形成生成的特征<img alt="" height="469" src="https://images2.imgbox.com/69/ac/ryBjkqqW_o.png" width="923"></p> 
<p> <img alt="" height="476" src="https://images2.imgbox.com/dc/5d/CDaXYVL2_o.png" width="991"></p> 
<p><span style="color:#fe2c24;"> <strong>map@0.5 从原始0.755提升至0.762</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_BasicRFB</td><td>303</td><td>3440235</td><td>8.9</td><td>7040</td><td>0.762</td></tr></tbody></table> 
<p> <a href="https://cv2023.blog.csdn.net/article/details/132922040" rel="nofollow" title="Yolov8小目标检测（23）：多分支卷积模块RFB，扩大感受野提升小目标检测精度_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（23）：多分支卷积模块RFB，扩大感受野提升小目标检测精度_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.2.5%20GOLD-YOLO%EF%BC%8C%E9%81%A5%E9%81%A5%E9%A2%86%E5%85%88">3.2.5 GOLD-YOLO，遥遥领先</h4> 
<p><img alt="" height="445" src="https://images2.imgbox.com/6f/c3/nRUbfKye_o.png" width="1078"></p> 
<p>链接：<a href="https://arxiv.org/pdf/2309.11331.pdf" rel="nofollow" title="https://arxiv.org/pdf/2309.11331.pdf">https://arxiv.org/pdf/2309.11331.pdf</a> </p> 
<p><strong>传统YOLO的问题</strong></p> 
<p>在检测模型中，通常先经过backbone提取得到一系列不同层级的特征，FPN利用了backbone的这一特点，构建了相应的融合结构：不层级的特征包含着不同大小物体的位置信息，虽然这些特征包含的信息不同，但这些特征在相互融合后能够互相弥补彼此缺失的信息，增强每一层级信息的丰富程度，提升网络性能。</p> 
<p>原始的FPN结构由于其层层递进的信息融合模式，使得相邻层的信息能够充分融合，但也导致了跨层信息融合存在问题：当跨层的信息进行交互融合时，由于没有直连的交互通路，只能依靠中间层充当“中介”进行融合，导致了一定的信息损失。之前的许多工作中都关注到了这一问题，而解决方案通常是通过添加shortcut增加更多的路径，以增强信息流动。</p> 
<p><img alt="" height="411" src="https://images2.imgbox.com/46/a2/fuVYWdMe_o.png" width="917"></p> 
<p> <img alt="" height="610" src="https://images2.imgbox.com/3b/3e/WA0ltRFH_o.png" width="1173"></p> 
<p>提出了一种全新的信息交互融合机制：<strong>信息聚集-分发机制(Gather-and-Distribute Mechanism)</strong>。该机制通过在全局上融合不同层次的特征得到全局信息，并将全局信息注入到不同层级的特征中，实现了高效的信息交互和融合。在不显著增加延迟的情况下GD机制显著增强了Neck部分的信息融合能力，提高了模型对不同大小物体的检测能力。 </p> 
<p><img alt="" height="475" src="https://images2.imgbox.com/19/5c/HfZju8Od_o.png" width="1159"></p> 
<p> 在Gold-YOLO中，针对模型需要检测不同大小的物体的需要，并权衡精度和速度，我们构建了两个GD分支对信息进行融合：低层级信息聚集-分发分支(Low-GD)和高层级信息聚集-分发分支(High-GD)，分别基于卷积和transformer提取和融合特征信息。</p> 
<p><img alt="" height="422" src="https://images2.imgbox.com/37/39/Dhft5zVa_o.png" width="1200"></p> 
<p><strong> map@0.5 从原始0.755提升至0.768</strong></p> 
<p><img alt="" height="501" src="https://images2.imgbox.com/89/ad/im2ZZNtz_o.png" width="754"></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8-goldyolo</td><td>359</td><td>6015123</td><td>11.9</td><td>12123</td><td>0.768</td></tr></tbody></table> 
<pre><code>YOLOv8-goldYOLO summary: 359 layers, 6015123 parameters, 0 gradients, 11.9 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04&lt;00:00,  1.41s/it]
                   all        171        199      0.871      0.679      0.768      0.461
Speed: 0.3ms preprocess, 3.9ms inference, 0.0ms loss, 1.6ms postprocess per image</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133314007" rel="nofollow" title="Yolov8小目标检测（24）：Gold-YOLO，遥遥领先，超越所有YOLO | 华为诺亚NeurIPS23_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（24）：Gold-YOLO，遥遥领先，超越所有YOLO | 华为诺亚NeurIPS23_AI小怪兽的博客-CSDN博客</a></p> 
<h3 id="3.3%20loss%E4%BC%98%E5%8C%96">3.3 loss优化</h3> 
<h4 id="3.3.1%C2%A0Wasserstein%20Distance%20Loss">3.3.1 Wasserstein Distance Loss</h4> 
<p>1）分析了 IoU 对微小物体位置偏差的敏感性，并提出 NWD 作为衡量两个边界框之间相似性的更好指标；</p> 
<p>2）通过将NWD 应用于基于锚的检测器中的标签分配、NMS 和损失函数来设计强大的微小物体检测器；</p> 
<p>3）提出的 NWD 可以显着提高流行的基于锚的检测器的 TOD 性能，它在 AI-TOD 数据集上的 Faster R-CNN 上实现了从 11.1% 到 17.6% 的性能提升；<br>  </p> 
<p><img alt="" src="https://images2.imgbox.com/17/0d/ZC3EYACp_o.png">​</p> 
<h3><br>  </h3> 
<p><span style="color:#fe2c24;"><strong>Wasserstein Distance Loss</strong> |  <strong> 亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.784</strong> </span></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132402459" rel="nofollow" title="Yolov8红外弱小目标检测（2）：Wasserstein Distance Loss，助力小目标涨点_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（2）：Wasserstein Distance Loss，助力小目标涨点_AI小怪兽的博客-CSDN博客</a></p> 
<table cellspacing="0" style="width:459pt;"><tbody><tr><td style="vertical-align:bottom;width:201pt;"></td><td style="vertical-align:bottom;width:41pt;"><span style="color:#000000;">layers</span></td><td style="vertical-align:bottom;width:71pt;"><span style="color:#000000;"> parameters</span></td><td style="vertical-align:bottom;width:51pt;"><span style="color:#000000;">GFLOPs</span></td><td style="vertical-align:bottom;width:41pt;"><span style="color:#000000;">kb</span></td><td style="vertical-align:bottom;width:54pt;"><span style="color:#000000;"> mAP50</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">yolov8</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">168</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3005843</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6103</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.755</span></td></tr><tr><td style="vertical-align:bottom;"><span style="color:#000000;">Wasserstein loss</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">168</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">3005843</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">8.1</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">6103</span></td><td style="vertical-align:bottom;"><span style="color:#000000;">0.784</span></td></tr></tbody></table> 
<h3 id="3.4%C2%A0%20%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">3.4  注意力机制</h3> 
<h4 id="3.4.1SEAM%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6">3.4.1SEAM注意力机制</h4> 
<p id="articleContentId">SEAM注意力机制，提升遮挡小目标检测性能</p> 
<p><img alt="" height="737" src="https://images2.imgbox.com/32/86/A7epKCnX_o.png" width="876">​</p> 
<p> 即不同小目标之间的遮挡，以及其他物体对小目标的遮挡。前者使得检测精度对 NMS 阈值非常敏感，从而导致漏检。作者使用排斥损失进行小目标检测，它惩罚预测框转移到其他真实目标，并要求每个预测框远离具有不同指定目标的其他预测框，以使检测结果对 NMS 不太敏感。后者导致特征消失导致定位不准确，设计了注意力模块 SEAM 来增强人脸特征的学习。</p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132420389" rel="nofollow" title="Yolov8红外弱小目标检测（5）：SEAM注意力机制，提升遮挡小目标检测性能_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（5）：SEAM注意力机制，提升遮挡小目标检测性能_AI小怪兽的博客-CSDN博客</a></p> 
<p><span style="color:#fe2c24;"><strong>SEAM</strong> |  <strong> 亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.785</strong> </span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_SEAM</td><td>219</td><td>3109331</td><td>8.3</td><td>6331</td><td>0.785</td></tr></tbody></table> 
<h4 id="3.4.2%C2%A0%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8%E7%9A%84%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88%E6%A8%A1%E5%9D%97EVC">3.4.2 即插即用的多尺度融合模块EVC</h4> 
<p><img alt="" height="976" src="https://images2.imgbox.com/c2/3a/H7laqZpZ_o.png" width="1200">​</p> 
<p> 如图2所示，CFP主要由以下部分组成：输入图像、用于提取视觉特征金字塔的CNN主干、提出的显式视觉中心（EVC）、提出的全局集中规则（GCR）以及用于目标检测的去解耦head网络（由分类损失、回归损失和分割损失组成）。在图2中，EVC和GCR在提取的特征金字塔上实现。</p> 
<p>   提出的EVC主要由两个并行连接的块组成，其中使用轻量级MLP来捕获顶级特征的全局长期依赖性（即全局信息）。</p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132429208" rel="nofollow" title="Yolov8红外弱小目标检测（6）：即插即用的多尺度融合模块EVC，即插即用，助力小目标检测_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（6）：即插即用的多尺度融合模块EVC，即插即用，助力小目标检测_AI小怪兽的博客-CSDN博客</a></p> 
<p><span style="color:#fe2c24;"><strong>EVC</strong>|  <strong> 亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.779</strong> </span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_EVC</td><td>217</td><td>7293523</td><td>11.5</td><td>14513</td><td>0.779</td></tr></tbody></table> 
<h4 id="%C2%A03.4.3%C2%A0%E5%BE%AE%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%A2%9E%E5%BC%BA%E5%92%8C%E7%89%B9%E5%BE%81%E7%BB%86%E5%8C%96%E7%BD%91%E7%BB%9CContextAggregation"> 3.4.3 微小目标检测的上下文增强和特征细化网络ContextAggregation</h4> 
<p> <img alt="" height="367" src="https://images2.imgbox.com/4f/3a/9dWaj9BP_o.png" width="1046">​</p> 
<p>        提供了一个统一视角表明：它们均是更广义方案下通过神经网络集成空间上下文信息的特例。我们提出了CONTAINER(CONText AggregatIon NEtwoRK)，一种用于多头上下文集成（Context Aggregation）的广义构建模块 。</p> 
<p><span style="color:#fe2c24;"><strong>  ContextAggregation |   亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.759</strong> </span></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132446606" rel="nofollow" title="Yolov8红外弱小目标检测（8）：微小目标检测的上下文增强和特征细化网络ContextAggregation，助力小目标检测_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（8）：微小目标检测的上下文增强和特征细化网络ContextAggregation，助力小目标检测_AI小怪兽的博客-CSDN博客</a></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_ContextAggregation</td><td>195</td><td>3008092</td><td>8.1</td><td>6121</td><td>0.759</td></tr></tbody></table> 
<h4 id="3.4.4%C2%A0EMA%E8%B7%A8%E7%A9%BA%E9%97%B4%E5%AD%A6%E4%B9%A0%E7%9A%84%E9%AB%98%E6%95%88%E5%A4%9A%E5%B0%BA%E5%BA%A6%E6%B3%A8%E6%84%8F%E5%8A%9B%C2%A0%7C%20ICASSP2023">3.4.4 EMA跨空间学习的高效多尺度注意力 | ICASSP2023</h4> 
<p>        通过通道降维来建模跨通道关系可能会给提取深度视觉表示带来副作用。本文提出了一种新的高效的多尺度注意力(EMA)模块。以保留每个通道上的信息和降低计算开销为目标，将部分通道重塑为批量维度，并将通道维度分组为多个子特征，使空间语义特征在每个特征组中均匀分布。 </p> 
<p><img alt="" height="475" src="https://images2.imgbox.com/24/88/XMiFATBd_o.png" width="899">​</p> 
<p><span style="color:#fe2c24;"><strong>EMA</strong> <strong>|   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.766</strong></span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_EMA</td><td>192</td><td>3006739</td><td>8.1</td><td>6114</td><td>0.766</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132466160" rel="nofollow" title="Yolov8小目标检测（9）： EMA基于跨空间学习的高效多尺度注意力、效果优于ECA、CBAM、CA | ICASSP2023_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（9）： EMA基于跨空间学习的高效多尺度注意力、效果优于ECA、CBAM、CA | ICASSP2023_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.5%20%E5%8A%A8%E6%80%81%E7%A8%80%E7%96%8F%E6%B3%A8%E6%84%8F%E5%8A%9BBiFormer%20%7C%20CVPR%202023%C2%A0">3.4.5 动态稀疏注意力BiFormer | CVPR 2023 </h4> 
<p> 本文方法：本文提出一种动态稀疏注意力的双层路由方法。对于一个查询，首先在粗略的区域级别上过滤掉不相关的键值对，然后在剩余候选区域（即路由区域）的并集中应用细粒度的令牌对令牌关注力。所提出的双层路由注意力具有简单而有效的实现方式，利用稀疏性来节省计算和内存，只涉及GPU友好的密集矩阵乘法。在此基础上构建了一种新的通用Vision Transformer，称为BiFormer。</p> 
<p><img alt="" height="493" src="https://images2.imgbox.com/0b/40/r847sKeE_o.png" width="678">​</p> 
<p><span style="color:#fe2c24;"> <strong>BiFormer |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.758</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_BiFormerBlock</td><td>204</td><td>3356179</td><td>22.4</td><td>6800</td><td>0.758</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132554862" rel="nofollow" title="Yolov8小目标检测（12）：动态稀疏注意力BiFormer | CVPR 2023_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（12）：动态稀疏注意力BiFormer | CVPR 2023_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.6%C2%A0%20LSKblockAttention%20%7C%20ICCV%202023%C2%A0">3.4.6  LSKblockAttention | ICCV 2023 </h4> 
<p> 提出的方法包括动态调整特征提取骨干的感受野，以便更有效地处理被检测物体的不同的广泛背景。这是通过一个空间选择机制来实现的，该机制对一连串的大 depth-wise 卷积核所处理的特征进行有效加权，然后在空间上将它们合并。这些核的权重是根据输入动态确定的，允许该模型自适应地使用不同的大核，并根据需要调整空间中每个目标的感受野。</p> 
<p><img alt="" height="406" src="https://images2.imgbox.com/80/00/7GWoQOo8_o.png" width="1200">​</p> 
<p> <img alt="" height="366" src="https://images2.imgbox.com/17/02/cvFxHuV8_o.png" width="1200">​</p> 
<p></p> 
<p> <span style="color:#fe2c24;"><strong> LSKblockAttention |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.775</strong></span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_LSKblockAttention</td><td>201</td><td>3343333</td><td>8.7</td><td>6784</td><td>0.775</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132561647" rel="nofollow" title="Yolov8小目标检测（13）：LSKblockAttention助力小目标检测 | ICCV 2023 南开大学LSKNet_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（13）：LSKblockAttention助力小目标检测 | ICCV 2023 南开大学LSKNet_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.7%C2%A0TripletAttention%E6%B3%A8%E6%84%8F%E5%8A%9B">3.4.7 TripletAttention注意力</h4> 
<p>  所提出的Triplet Attention如下图所示，Triplet Attention由3个平行的Branch组成，其中两个负责捕获通道C和空间H或W之间的跨维交互。最后一个Branch类似于CBAM，用于构建Spatial Attention，最终3个Branch的输出使用平均求和。<img alt="" height="339" src="https://images2.imgbox.com/ea/86/0fXAdR0o_o.png" width="915">​</p> 
<p></p> 
<p><span style="color:#fe2c24;"><strong>TripletAttention |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.79</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_TripletAttention</td><td>201</td><td>3006443</td><td>8.2</td><td>6120</td><td>0.79</td></tr></tbody></table> 
<p> <a href="https://cv2023.blog.csdn.net/article/details/132684139" rel="nofollow" title="Yolov8小目标检测（16）：TripletAttention注意力，即插即用，效果优于cbam、se，涨点明显_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（16）：TripletAttention注意力，即插即用，效果优于cbam、se，涨点明显_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.8%C2%A0%C2%A0%E9%80%9A%E9%81%93%E4%BC%98%E5%85%88%E5%8D%B7%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B%EF%BC%88CPCA%EF%BC%89%7C%20%E4%B8%AD%E7%A7%91%E9%99%A2%202023.6">3.4.8  通道优先卷积注意力（CPCA）| 中科院 2023.6</h4> 
<p> 通道先验卷积注意力（CPCA）的整体结构包括通道注意力和空间注意力的顺序放置。特征图的空间信息是由通道注意力通过平均池化和最大池化等操作来聚合的。 随后，空间信息通过共享 MLP（多层感知器）进行处理并添加以生成通道注意力图。 通道先验是通过输入特征和通道注意力图的元素相乘获得的。 随后，通道先验被输入到深度卷积模块中以生成空间注意力图。 卷积模块接收空间注意力图以进行通道混合。 最终，通过通道混合结果与通道先验的逐元素相乘，获得细化的特征作为输出。 通道混合过程有助于增强特征的表示<img alt="" height="488" src="https://images2.imgbox.com/fc/ed/53zePg72_o.png" width="988">​</p> 
<p><span style="color:#fe2c24;"><strong>CPCA |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.815</strong></span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_ChannelAttention</td><td>171</td><td>3137427</td><td>7.8</td><td>6428</td><td>0.815</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132692099" rel="nofollow" title="Yolov8小目标检测（18）：通道优先卷积注意力（Channel Prior Convolutional Attention，CPCA）| 中科院 2023.6发布_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（18）：通道优先卷积注意力（Channel Prior Convolutional Attention，CPCA）| 中科院 2023.6发布_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.8%C2%A0%C2%A0%E5%A4%9A%E5%B0%BA%E5%BA%A6MultiSEAM">3.4.8  多尺度MultiSEAM</h4> 
<p>  解决多尺度问题的主要方法是构建金字塔来融合人脸的多尺度特征。例如，在 <code>YOLOv5</code> 中，<code>FPN</code> 融合了 <code>P3</code>、<code>P4</code> 和 <code>P5</code> 层的特征。但是对于小尺度的目标，经过多层卷积后信息很容易丢失，保留的像素信息很少，即使在较浅的<code>P3</code>层也是如此。因此，提高特征图的分辨率无疑有利于小目标的检测。</p> 
<p><img alt="" height="737" src="https://images2.imgbox.com/f3/f8/m8nv9KVl_o.png" width="876"></p> 
<p><span style="color:#fe2c24;"><strong>MultiSEAM</strong>|  <strong> 亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.87</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_MultiSEAM</td><td>325</td><td>5742291</td><td></td><td>11711</td><td>0.87</td></tr></tbody></table> 
<p> <a href="https://cv2023.blog.csdn.net/article/details/132730700" rel="nofollow" title="Yolov8小目标检测（20）：多尺度MultiSEAM，提高特征图的分辨率增强小目标检测能力_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（20）：多尺度MultiSEAM，提高特征图的分辨率增强小目标检测能力_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.9%C2%A0%E8%BD%BB%E9%87%8F%E7%BA%A7%E6%B3%A8%E6%84%8F%E5%8A%9BMobileViTAttention%20%7C%20ECCV2022%C2%A0">3.4.9 轻量级注意力MobileViTAttention | ECCV2022 </h4> 
<p>  MobileViT 主要是为了解决 ViT 网络的缺陷而设计提出的，将 CNN 的优点融入到 Transformer 的结构中以解决 Transformer 网络存在的训练困难、迁移困难、调整困难的缺点，加快网络的推理和收敛速度，使得网络更加稳定高效。 </p> 
<p><img alt="" height="458" src="https://images2.imgbox.com/1a/89/hxCGrElF_o.png" width="1089"></p> 
<p><span style="color:#fe2c24;"><strong>MobileViTAttention |   亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.799</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_MobileViTAttention</td><td>241</td><td>3957659</td><td>11.1</td><td>7992</td><td>0.799</td></tr></tbody></table> 
<p> <a href="https://cv2023.blog.csdn.net/article/details/132736386" rel="nofollow" title="Yolov8小目标检测（21）：轻量级注意力MobileViTAttention | ECCV2022_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（21）：轻量级注意力MobileViTAttention | ECCV2022_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.10%C2%A0%E6%84%9F%E5%8F%97%E9%87%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E5%8D%B7%E7%A7%AF%E8%BF%90%E7%AE%97">3.4.10 <strong>感受野注意力卷积运算</strong></h4> 
<p></p> 
<p> 关于感受野空间特征，我们提出<strong>感受野注意（RFA）</strong>。 这种方法不仅强调感受野滑块内不同特征的重要性，而且优先考虑感受野空间特征。 通过这种方法，彻底解决了卷积核参数共享的问题。 感受野空间特征是根据卷积核的大小动态生成的，因此，RFA是卷积的固定组合，离不开卷积运算的帮助，同时依靠RFA来提高性能，所以我们 提出感受野注意卷积（RFAConv）。 具有3×3尺寸卷积核的RFAConv的整体结构如图2所示。</p> 
<p><img alt="" height="656" src="https://images2.imgbox.com/5e/48/gKCo7SRL_o.png" width="994"></p> 
<p><span style="color:#fe2c24;"> <strong>RFAConv |   亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.765</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8-RFA</td><td>258</td><td>3019439</td><td>8.2</td><td>6166</td><td>0.765</td></tr></tbody></table> 
<p> <a href="https://cv2023.blog.csdn.net/article/details/132868499" rel="nofollow" title="Yolov8小目标检测（22）：感受野注意力卷积运算（RFAConv），助力小目标检测_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（22）：感受野注意力卷积运算（RFAConv），助力小目标检测_AI小怪兽的博客-CSDN博客</a></p> 
<p>3.4.11 移动端网络架构 RepViT | RepViTBlock | 清华 ICCV 2023</p> 
<p>  RepViT 通过逐层微观设计来调整轻量级 CNN，这包括选择合适的卷积核大小和优化挤压-激励（Squeeze-and-excitation，简称SE）层的位置。这两种方法都能显著改善模型性能。</p> 
<p><img alt="" height="657" src="https://images2.imgbox.com/f9/7a/RazTpjTh_o.png" width="643"></p> 
<p><span style="color:#fe2c24;"><strong>RepViTBlock|   亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.791</strong> </span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_RepViTBlock</td><td>186</td><td>3338387</td><td>7.9</td><td>6771</td><td>0.791</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132995568" rel="nofollow" title="Yolov8小目标检测（24）： 最新开源移动端网络架构 RepViT | RepViTBlock | 清华 ICCV 2023_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（24）： 最新开源移动端网络架构 RepViT | RepViTBlock | 清华 ICCV 2023_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.4.11%C2%A0Dual-ViT%EF%BC%9A%E4%B8%80%E7%A7%8D%E5%A4%9A%E5%B0%BA%E5%BA%A6%E5%8F%8C%E8%A7%86%E8%A7%89Transformer">3.4.11 Dual-ViT：一种多尺度双视觉Transformer</h4> 
<p></p> 
<p>         摘要：以前的工作已经提出了几种降低自注意力机制计算成本的策略。其中许多工作考虑将自注意力过程分解为区域和局部特征提取过程，每个过程产生的计算复杂度要小得多。然而，区域信息通常仅以由于下采样而丢失的不希望的信息为代价。在本文中，作者提出了一种旨在缓解成本问题的新型Transformer架构，称为<strong>双视觉Transformer（Dual ViT）</strong>。新架构结合了一个关键的语义路径，可以更有效地将token向量压缩为全局语义，并降低复杂性。这种压缩的全局语义通过另一个构建的像素路径，作为学习内部像素级细节的有用先验信息。然后将语义路径和像素路径整合在一起，并进行联合训练，通过这两条路径并行传播增强的自注意力信息。因此，双ViT能够在不影响精度的情况下降低计算复杂度。实证证明，双ViT比SOTA Transformer架构提供了更高的精度，同时降低了训练复杂度。</p> 
<p>        如图1（a）所示。Twins（上图（b））在SRA之前添加了额外的局部分组自注意力层，以通过区域内相互作用进一步增强表示。RegionViT（上图（c））通过区域和局部自注意力分解原始注意力。然而，由于上述方法严重依赖于特征映射到区域的下采样，在有效节省总计算成本的同时，观察到了明显的性能下降。</p> 
<p>        如上图（d）所示，双ViT由两个特殊路径组成，分别称为“语义路径”和“像素路径”。通过构造的“像素路径”进行局部像素级特征提取是强烈依赖于“语义路径”之外的压缩全局先验。由于梯度同时通过语义路径和像素路径，因此双ViT训练过程可以有效地补偿全局特征压缩的信息损失，同时减少局部特征提取的困难。前者和后者都可以并行显著降低计算成本，因为注意力大小较小，并且两条路径之间存在强制依赖关系。</p> 
<p><img alt="" height="433" src="https://images2.imgbox.com/0f/5a/Zcwx5JCh_o.png" width="1170"></p> 
<p>在本文中，我们提出了一种新颖的 Transformer 架构，它优雅地利用全局语义进行自注意力学习，即双视觉 Transformer (Dual-ViT)。</p> 
<p><img alt="" height="389" src="https://images2.imgbox.com/f5/dd/o66UlJXT_o.png" width="1165"></p> 
<p><strong> map@0.5 从原始0.755提升至0.768</strong></p> 
<p><img alt="" height="496" src="https://images2.imgbox.com/08/57/hzSXgH8w_o.png" width="757"></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_DualAttention</td><td>186</td><td>4604819</td><td>8.3</td><td>9236</td><td>0.766</td></tr></tbody></table> 
<pre><code>YOLOv8_DualAttention summary (fused): 186 layers, 4604819 parameters, 0 gradients, 8.3 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:04&lt;00:00,  1.29it/s]
                   all        171        199      0.865      0.707      0.766      0.452</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133375830" rel="nofollow" title="Yolov8小目标检测（25）：Dual-ViT：一种多尺度双视觉Transformer ，Dualattention助力小目标检测| 顶刊TPAMI 2023_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（25）：Dual-ViT：一种多尺度双视觉Transformer ，Dualattention助力小目标检测| 顶刊TPAMI 2023_AI小怪兽的博客-CSDN博客</a></p> 
<h3 id="3.5%20%E5%8D%B7%E7%A7%AF%E5%8F%98%E4%BD%93">3.5 卷积变体</h3> 
<h4 id="3.5.1%20SPD-Conv">3.5.1 SPD-Conv</h4> 
<p>SPD-Conv由一个空间到深度(SPD)层和一个无卷积步长(Conv)层组成，可以应用于大多数CNN体系结构。我们从两个最具代表性的计算即使觉任务:目标检测和图像分类来解释这个新设计。然后，我们将SPD-Conv应用于YOLOv5和ResNet，创建了新的CNN架构，并通过经验证明，我们的方法明显优于最先进的深度学习模型，特别是在处理低分辨率图像和小物体等更困难的任务时。<br><img alt="" src="https://images2.imgbox.com/d7/63/nQb44xP9_o.png">​</p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132420154" rel="nofollow" title="Yolov8红外弱小目标检测（4）：SPD-Conv，低分辨率图像和小物体涨点明显_AI小怪兽的博客-CSDN博客">Yolov8红外弱小目标检测（4）：SPD-Conv，低分辨率图像和小物体涨点明显_AI小怪兽的博客-CSDN博客</a></p> 
<p><span style="color:#fe2c24;"><strong>SPD-Conv</strong> |  <strong> 亲测在红外弱小目标检测涨点明显，map@0.5 从0.755提升至0.875</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_SPD</td><td>174</td><td>3598739</td><td>49.2</td><td>7394</td><td><span style="color:#fe2c24;"><strong>0.875</strong></span></td></tr></tbody></table> 
<h4 id="3.5.2%20DCNv3%E5%8F%AF%E5%BD%A2%E5%8F%98%E5%8D%B7%E7%A7%AF%20%7C%20CVPR2023">3.5.2 DCNv3可形变卷积 | CVPR2023</h4> 
<p>InternImage通过重新设计算子和模型结构提升了卷积模型的可扩展性并且缓解了归纳偏置，包括（1）DCNv3算子，基于DCNv2算子引入共享投射权重、多组机制和采样点调制。</p> 
<p>（2）基础模块，融合先进模块作为模型构建的基本模块单元</p> 
<p>（3）模块堆叠规则，扩展模型时规范化模型的宽度、深度、组数等超参数。</p> 
<div> 
 <p><img alt="" height="502" src="https://images2.imgbox.com/30/26/FLXjCpfc_o.png" width="456">​</p> 
</div> 
<p></p> 
<p><span style="color:#fe2c24;"><strong>DCNv3 |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.765</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_DCNV3</td><td>264</td><td>2892317</td><td>7.9</td><td>5892</td><td>0.765</td></tr></tbody></table> 
<p> <a href="https://cv2023.blog.csdn.net/article/details/132493819" rel="nofollow" title="Yolov8小目标检测（10）：DCNv3可形变卷积助力涨点，COCO新纪录65.4mAP | CVPR2023 InternImage_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（10）：DCNv3可形变卷积助力涨点，COCO新纪录65.4mAP | CVPR2023 InternImage_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.5.3%C2%A0%E6%96%B0%E7%9A%84Partial%E5%8D%B7%E7%A7%AF(PConv)%20%7C%20CVPR2023%20FasterNet%C2%A0">3.5.3 新的Partial卷积(PConv) | CVPR2023 FasterNet </h4> 
<p>为了设计快速神经网络，许多工作都集中在减少浮点运算（FLOPs）的数量上。然而，作者观察到FLOPs的这种减少不一定会带来延迟的类似程度的减少。这主要源于每秒低浮点运算（FLOPS）效率低下。为了实现更快的网络，作者重新回顾了FLOPs的运算符，并证明了如此低的FLOPS主要是由于运算符的频繁内存访问，尤其是深度卷积。因此，本文提出了一种新的partial convolution（PConv），通过同时减少冗余计算和内存访问可以更有效地提取空间特征。</p> 
<p><img alt="" height="591" src="https://images2.imgbox.com/71/a6/wAWrlKVQ_o.png" width="831">​ </p> 
<p><span style="color:#fe2c24;"><strong>    </strong><strong>PConv </strong><strong>|   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.758，同时参数量param及计算量FLOPs都有降低</strong></span></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_C2f_Pconv</td><td>177</td><td>2716883</td><td>7.6</td><td>5537</td><td>0.758</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132670620" rel="nofollow" title="Yolov8小目标检测（15）：新的Partial卷积(PConv) ，减少冗余计算和内存访问 | CVPR2023 FasterNet_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（15）：新的Partial卷积(PConv) ，减少冗余计算和内存访问 | CVPR2023 FasterNet_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.5.4%C2%A0ODConv%C2%A0%7C%20ICLR%202022" style="background-color:transparent;">3.5.4 ODConv | ICLR 2022</h4> 
<p>        ODConv通过并行策略引入一种多维注意力机制以对卷积核空间的四个维度学习更灵活的注意力。ODConv可以描述成如下形式：</p> 
<p>        表示新引入的三个注意力，分别沿空域维度、输入通道维度以及输出通道维度。这四个注意力采用多头注意力模块 计算得到</p> 
<p><img alt="" src="https://images2.imgbox.com/90/6d/F720Fklp_o.png">​</p> 
<p>       </p> 
<p><span style="color:#fe2c24;"><strong>ODConv |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.76</strong></span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_ODConv</td><td>179</td><td>3012110</td><td>7.9</td><td>6121</td><td>0.76</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132684314" rel="nofollow" title="Yolov8小目标检测（17）：ODConv提升小目标检测能力 | ICLR 2022_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（17）：ODConv提升小目标检测能力 | ICLR 2022_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="3.5.5%C2%A0%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF%EF%BC%88Dynamic%20Snake%20Convolution%EF%BC%89%20%7C%20ICCV2023">3.5.5 动态蛇形卷积（Dynamic Snake Convolution） | ICCV2023</h4> 
<p> 主要的挑战源于细长微弱的局部结构特征与复杂多变的全局形态特征。本文关注到管状结构细长连续的特点，并利用这一信息在神经网络以下三个阶段同时增强感知：特征提取、特征融合和损失约束。分别设计了动态蛇形卷积（Dynamic Snake Convolution），多视角特征融合策略与连续性拓扑约束损失。 </p> 
<p><img alt="" height="550" src="https://images2.imgbox.com/c9/d4/PKIiTfFm_o.png" width="663"></p> 
<p><span style="color:#fe2c24;"><strong>Dynamic Snake Convolution |   亲测在红外弱小目标检测涨点，map@0.5 从0.755提升至0.77</strong></span></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td>kb</td><td> mAP50</td></tr><tr><td>yolov8</td><td>168</td><td>3005843</td><td>8.1</td><td>6103</td><td>0.755</td></tr><tr><td>yolov8_DySnakeConv</td><td>229</td><td>3356287</td><td>8.5</td><td>6822</td><td>0.77</td></tr></tbody></table> 
<p><a href="https://cv2023.blog.csdn.net/article/details/132707201" rel="nofollow" title="Yolov8小目标检测（19）：动态蛇形卷积（Dynamic Snake Convolution），增强细长微弱特征 | ICCV2023_AI小怪兽的博客-CSDN博客">Yolov8小目标检测（19）：动态蛇形卷积（Dynamic Snake Convolution），增强细长微弱特征 | ICCV2023_AI小怪兽的博客-CSDN博客</a></p> 
<p></p> 
<p><span style="color:#fe2c24;"><strong>持续更新中</strong></span></p> 
<p></p> 
<h2 id="%E7%95%AA%E5%A4%96%E7%AF%87%EF%BC%9A%E5%B7%A5%E4%B8%9A%E5%B0%8F%E7%9B%AE%E6%A0%87%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B" style="background-color:transparent;"><strong><span style="color:#fe2c24;">番外篇：工业小目标缺陷检测</span></strong></h2> 
<p></p> 
<p><img alt="" src="https://images2.imgbox.com/dc/65/BPdf9blY_o.jpg"></p> 
<p></p> 
<table cellspacing="0"><tbody><tr><td></td><td>layers</td><td> parameters</td><td>GFLOPs</td><td> mAP50</td><td>mAP50-95</td></tr><tr><td>YOLOv8n </td><td>168</td><td>3006038</td><td>8.1</td><td><strong>0.679</strong></td><td>0.322</td></tr><tr><td>YOLOv8n_smallobject </td><td>207</td><td>2977720</td><td>12.5</td><td>0.702</td><td>0.359</td></tr><tr><td>Wasserstein loss</td><td>168</td><td>3006038</td><td>8.1</td><td>0.714</td><td>0.342</td></tr><tr><td>YOLOv8n_CSPStage</td><td>232</td><td>2982742</td><td>8.1</td><td>0.727</td><td>0.339</td></tr><tr><td>YOLOv8n_smallobject _CSPStage</td><td>303</td><td>2953528</td><td>12.5</td><td>0.734</td><td>0.376</td></tr><tr><td>YOLOv8n_smallobject _CSPStage+Wasserstein loss</td><td>303</td><td>2953528</td><td>12.5</td><td><span style="color:#fe2c24;"><strong>0.814</strong></span></td><td>0.416</td></tr></tbody></table> 
<p><strong>工业油污数据集介绍</strong><br> 三星油污缺陷类别：头发丝和小黑点，["TFS","XZW"] </p> 
<p>数据集大小：660张，包括部分良品图像，提升背景检测能力。</p> 
<p>数据集地址：https://download.csdn.net/download/m0_63774211/87741209</p> 
<p>缺陷特点：小目标缺陷，检测难度大，如下图所示；</p> 
<p><img alt="" height="588" src="https://images2.imgbox.com/bd/6b/QdNJ62VC_o.png" width="588"></p> 
<p></p> 
<h4 id="1.1%20%E5%8A%A8%E6%80%81%E8%9B%87%E5%BD%A2%E5%8D%B7%E7%A7%AF%EF%BC%88Dynamic%20Snake%20Convolution%EF%BC%89%EF%BC%8C%E5%AE%9E%E7%8E%B0%E6%9A%B4%E5%8A%9B%E6%B6%A8%E7%82%B9%20%7C%20ICCV2023">1.1 动态蛇形卷积（Dynamic Snake Convolution），实现暴力涨点 | ICCV2023</h4> 
<p><strong>Dynamic Snake Convolution</strong> |  <strong> 亲测在工业小目标缺陷涨点明显，原始mAP@0.5 0.679提升至0.743</strong></p> 
<p>  主要的挑战源于细长微弱的局部结构特征与复杂多变的全局形态特征。本文关注到管状结构细长连续的特点，并利用这一信息在神经网络以下三个阶段同时增强感知：特征提取、特征融合和损失约束。分别设计了动态蛇形卷积（Dynamic Snake Convolution），多视角特征融合策略与连续性拓扑约束损失。 </p> 
<p><img alt="" height="550" src="https://images2.imgbox.com/1e/b6/wWeJhBdr_o.png" width="663"></p> 
<p>         我们希望卷积核一方面能够<strong>自由</strong>地贴合结构学习特征，另一方面能够在<strong>约束</strong>条件下不偏离目标结构太远。在观察管状结构的细长连续的特征后，脑海里想到了一个动物——<strong>蛇</strong>。我们希望卷积核能够像蛇一样动态地扭动，来贴合目标的结构。</p> 
<p></p> 
<p><strong>原始mAP@0.5 0.679提升至0.743</strong></p> 
<p><img alt="" height="497" src="https://images2.imgbox.com/7a/77/AmtXeMYz_o.png" width="757"></p> 
<pre><code>YOLOv8-C2f-DySnakeConv summary: 249 layers, 3425894 parameters, 0 gradients, 8.7 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:04&lt;00:00,  2.15s/it]
                   all         66        187      0.722      0.668      0.743      0.342
                   TFS         66        130      0.582        0.6      0.638      0.295
                   XZW         66         57      0.862      0.737      0.847      0.388</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133125904" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（2）：动态蛇形卷积（Dynamic Snake Convolution），实现暴力涨点 | ICCV2023_AI小怪兽的博客-CSDN博客">基于Yolov8的工业小目标缺陷检测（2）：动态蛇形卷积（Dynamic Snake Convolution），实现暴力涨点 | ICCV2023_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="1.2%20%E5%BE%AE%E5%B0%8F%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%8F%AF%E8%83%BD%E5%AD%98%E5%9C%A8%E6%A3%80%E6%B5%8B%E8%83%BD%E5%8A%9B%E4%B8%8D%E4%BD%B3%E7%9A%84%E7%8E%B0%E8%B1%A1%EF%BC%8C%E6%B7%BB%E5%8A%A0%E4%B8%80%E4%B8%AA%E5%BE%AE%E5%B0%8F%E7%89%A9%E4%BD%93%E7%9A%84%E6%A3%80%E6%B5%8B%E5%A4%B4">1.2 微小目标检测可能存在检测能力不佳的现象，<strong>添加一个微小物体的检测头</strong></h4> 
<p><strong>多头检测器</strong> |  <strong> 亲测在工业小目标缺陷涨点明显，原始mAP@0.5 0.679提升至0.702</strong></p> 
<p><img alt="" height="383" src="https://images2.imgbox.com/96/47/ObvurTws_o.jpg" width="900"></p> 
<p><strong>原始mAP@0.5 0.679提升至0.702</strong></p> 
<p><img alt="" height="502" src="https://images2.imgbox.com/6d/3d/kWTO4Bnb_o.png" width="747"></p> 
<pre><code>YOLOv8n_4 summary (fused): 207 layers, 2977720 parameters, 0 gradients, 12.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04&lt;00:00,  1.64s/it]
                   all         66        187       0.68      0.612      0.702      0.359
                   TFS         66        130      0.486      0.487       0.52      0.228
                   XZW         66         57      0.875      0.737      0.885       0.49</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133139506" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（3）：多检测头提升小目标检测精度_AI小怪兽的博客-CSDN博客">基于Yolov8的工业小目标缺陷检测（3）：多检测头提升小目标检测精度_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="1.3%20SPD-Conv%EF%BC%8C%E4%BD%8E%E5%88%86%E8%BE%A8%E7%8E%87%E5%9B%BE%E5%83%8F%E5%92%8C%E5%B0%8F%E7%89%A9%E4%BD%93%E6%B6%A8%E7%82%B9%E6%98%8E%E6%98%BE">1.3 SPD-Conv，低分辨率图像和小物体涨点明显</h4> 
<p><strong>SPD-Conv</strong> |  <strong> 亲测在工业小目标缺陷涨点明显，原始mAP@0.5 0.679提升至0.775</strong></p> 
<p>SPD- conv由一个空间到深度(SPD)层和一个非跨步卷积层组成。SPD组件推广了一种(原始)图像转换技术[29]来对CNN内部和整个CNN的特征映射进行下采样：</p> 
<p><img alt="" height="454" src="https://images2.imgbox.com/e5/f0/VwadykNz_o.png" width="758"></p> 
<p></p> 
<p><strong> 原始mAP@0.5 0.679提升至0.775</strong></p> 
<p></p> 
<p><img alt="" height="501" src="https://images2.imgbox.com/2f/d3/ChryQ52y_o.png" width="755"></p> 
<pre><code>YOLOv8n_SPD summary (fused): 174 layers, 3598934 parameters, 0 gradients, 49.2 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:13&lt;00:00,  4.51s/it]
                   all         66        187      0.741      0.693      0.775      0.415
                   TFS         66        130      0.593      0.562      0.629      0.314
                   XZW         66         57       0.89      0.825       0.92      0.516</code></pre> 
<p></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133169091" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（4）：SPD-Conv，低分辨率图像和小物体涨点明显_AI小怪兽的博客-CSDN博客">基于Yolov8的工业小目标缺陷检测（4）：SPD-Conv，低分辨率图像和小物体涨点明显_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="1.4%E5%A4%A7%E7%BC%BA%E9%99%B7%E5%B0%8F%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet">1.4大缺陷小缺陷一网打尽的轻量级目标检测器GiraffeDet</h4> 
<p>  <strong>GiraffeDet </strong>|  <strong> 亲测在工业小目标缺陷涨点明显，原始mAP@0.5 0.679提升至0.727</strong></p> 
<p> <img alt="" height="397" src="https://images2.imgbox.com/9c/c9/cSRXXhZ0_o.png" width="866"></p> 
<p>         本文提出了GiraffeDet用于高效目标检测，giraffe包含轻量space-to-depth chain、Generalized-FPN以及预测网络</p> 
<p><img alt="" height="429" src="https://images2.imgbox.com/1b/d0/5Hok9007_o.png" width="1012"></p> 
<p>        FPN旨在对CNN骨干网络提取的不同分辨率的多尺度特征进行融合。上图给出了FPN的进化，从最初的FPN到PANet再到BiFPN。我们注意到：这些FPN架构仅聚焦于特征融合，缺少了块内连接。因此，我们设计了一种新的路径融合GFPN：包含跳层与跨尺度连接，见上图d。</p> 
<p></p> 
<p><strong> 原始mAP@0.5 0.679提升至0.734</strong></p> 
<p><img alt="" height="505" src="https://images2.imgbox.com/56/7f/vu8KNs1E_o.png" width="753"></p> 
<pre><code>YOLOv8n_4_CSPStage summary: 303 layers, 2953528 parameters, 0 gradients, 12.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04&lt;00:00,  1.56s/it]
                   all         66        187      0.689       0.68      0.734      0.376
                   TFS         66        130      0.523      0.554      0.571      0.267
                   XZW         66         57      0.855      0.807      0.896      0.486</code></pre> 
<p></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133179221" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（5）：大缺陷小缺陷一网打尽的轻量级目标检测器GiraffeDet，暴力提升工业缺陷检测能力_AI小怪兽的博客-CSDN博客">基于Yolov8的工业小目标缺陷检测（5）：大缺陷小缺陷一网打尽的轻量级目标检测器GiraffeDet，暴力提升工业缺陷检测能力_AI小怪兽的博客-CSDN博客</a></p> 
<h4 id="%C2%A01.5%20%E5%A4%9A%E6%A3%80%E6%B5%8B%E5%A4%B4%E7%BB%93%E5%90%88%E5%B0%8F%E7%BC%BA%E9%99%B7%E5%88%B0%E5%A4%A7%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%E8%BD%BB%E9%87%8F%E7%BA%A7%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%99%A8GiraffeDet"> 1.5 多检测头结合小缺陷到大缺陷一网打尽的轻量级目标检测器GiraffeDet</h4> 
<p><strong>多头检测器+</strong> <strong>GiraffeDet </strong>|  <strong> 亲测在工业小目标缺陷涨点明显，原始mAP@0.5 0.679提升至0.734</strong></p> 
<p><img alt="" height="383" src="https://images2.imgbox.com/aa/8f/4w254bam_o.jpg" width="900"></p> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133169684" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（6）：多检测头结合小缺陷到大缺陷一网打尽的轻量级目标检测器GiraffeDet，暴力提升工业小目标缺陷检测能力_AI小怪兽的博客-CSDN博客">基于Yolov8的工业小目标缺陷检测（6）：多检测头结合小缺陷到大缺陷一网打尽的轻量级目标检测器GiraffeDet，暴力提升工业小目标缺陷检测能力_AI小怪兽的博客-CSDN博客</a></p> 
<p></p> 
<p><strong> 原始mAP@0.5 0.679提升至0.734</strong></p> 
<p><img alt="" height="505" src="https://images2.imgbox.com/ea/f7/jRZV4ZrS_o.png" width="753"></p> 
<pre><code>YOLOv8n_4_CSPStage summary: 303 layers, 2953528 parameters, 0 gradients, 12.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04&lt;00:00,  1.56s/it]
                   all         66        187      0.689       0.68      0.734      0.376
                   TFS         66        130      0.523      0.554      0.571      0.267
                   XZW         66         57      0.855      0.807      0.896      0.486</code></pre> 
<p></p> 
<h4 id="%C2%A01.6%C2%A0Wasserstein%20Distance%20Loss%EF%BC%8C%E5%8A%A9%E5%8A%9B%E5%B7%A5%E4%B8%9A%E7%BC%BA%E9%99%B7%E6%A3%80%E6%B5%8B"> 1.6 Wasserstein Distance Loss，助力工业缺陷检测</h4> 
<p><strong>Wasserstein Distance Loss </strong>|  <strong> 亲测在工业小目标缺陷涨点明显，原始mAP@0.5 0.679提升至0.727</strong></p> 
<p> <img alt="" height="765" src="https://images2.imgbox.com/bf/ea/JlCqcEJe_o.png" width="1031">​</p> 
<p><strong>Wasserstein distance的主要优点是</strong>：</p> 
<ol><li>无论小目标之间有没有重叠都可以度量分布相似性;</li><li>NWD对不同尺度的目标不敏感，更适合测量小目标之间的相似性。</li></ol> 
<p>NWD可应用于One-Stage和Multi-Stage Anchor-Based检测器。此外，NWD不仅可以替代标签分配中的IoU，还可以替代非最大抑制中的IoU(NMS)和回归损失函数。在一个新的TOD数据集AI-TOD上的大量实验表明，本文提出的NWD可以持续地提高所有检测器的检测性能。</p> 
<p></p> 
<p><strong> 原始mAP@0.5 0.679提升至0.727</strong></p> 
<p>​<img alt="" height="500" src="https://images2.imgbox.com/be/ba/8R8iDai1_o.png" width="756"></p> 
<pre><code>YOLOv8n summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:04&lt;00:00,  1.45s/it]
                   all         66        187      0.673      0.649      0.714      0.342
                   TFS         66        130      0.573      0.579      0.615      0.283
                   XZW         66         57      0.772      0.719      0.813      0.401</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133179529" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（7）：Wasserstein Distance Loss，助力工业缺陷检测_AI小怪兽的博客-CSDN博客">基于Yolov8的工业小目标缺陷检测（7）：Wasserstein Distance Loss，助力工业缺陷检测_AI小怪兽的博客-CSDN博客</a></p> 
<p></p> 
<h4 id="1.7%20%E5%B7%A5%E4%B8%9A%E9%83%A8%E7%BD%B2%E7%BA%A7%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%C2%A0%E5%A4%9A%E5%A4%B4%E6%A3%80%E6%B5%8B%E5%99%A8%2B%E5%B0%8F%E7%BC%BA%E9%99%B7%E5%88%B0%E5%A4%A7%E7%BC%BA%E9%99%B7%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%E7%9A%84%2BWasserstein%20Distance%20Loss">1.7 工业部署级解决方案： 多头检测器+小缺陷到大缺陷一网打尽的+Wasserstein Distance Loss</h4> 
<p><strong><strong><strong><strong><strong><strong><strong><strong><img alt="" src="https://images2.imgbox.com/bb/79/tPz09jxt_o.jpg"></strong></strong></strong></strong></strong></strong></strong></strong></p> 
<p><strong> 原始mAP@0.5 0.679提升至0.814</strong></p> 
<p>​<img alt="" height="502" src="https://images2.imgbox.com/18/d2/AxXTleFG_o.png" width="752">​</p> 
<pre><code>YOLOv8_4_CSPStage summary: 303 layers, 2953528 parameters, 0 gradients, 12.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:04&lt;00:00,  2.19s/it]
                   all         66        187      0.783      0.705      0.814      0.416
                   TFS         66        130      0.647      0.619      0.693      0.317
                   XZW         66         57      0.919      0.792      0.935      0.514
</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133273158" rel="nofollow" title="基于Yolov8的工业小目标缺陷检测（8）：工业部署解决方案 | 多头检测器+小缺陷到大缺陷一网打尽的+Wasserstein Distance Loss | 助力工业缺陷检测-CSDN博客">基于Yolov8的工业小目标缺陷检测（8）：工业部署解决方案 | 多头检测器+小缺陷到大缺陷一网打尽的+Wasserstein Distance Loss | 助力工业缺陷检测-CSDN博客</a></p> 
<p></p> 
<h2 style="background-color:transparent;"><strong><span style="color:#fe2c24;">番外篇：工业 端面小目标计数</span></strong></h2> 
<p></p> 
<p id="1.%E5%B7%A5%E4%B8%9A%E6%B2%B9%E6%B1%A1%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><strong>  端面小目标计数数据集介绍</strong></p> 
<p>工业端面小目标计数类别：一类，类别名object</p> 
<p>数据集大小：训练集864张，验证集98张</p> 
<p>数据集下载地址：<a href="https://cv2023.blog.csdn.net/article/details/133217107" rel="nofollow" title="目标检测数据集：工业端面小目标缺陷计数数据集_AI小怪兽的博客-CSDN博客">目标检测数据集：工业端面小目标缺陷计数数据集_AI小怪兽的博客-CSDN博客</a></p> 
<p><strong>缺陷特点：小目标计数，检测难度大，如下图所示；</strong></p> 
<p><img alt="" height="579" src="https://images2.imgbox.com/7c/9f/UXTPyVYY_o.png" width="581"></p> 
<p><img alt="" height="584" src="https://images2.imgbox.com/3d/79/HaC0jBwP_o.png" width="577"></p> 
<p> 原始性能</p> 
<p><strong>  预测结果：</strong></p> 
<p><img alt="" height="498" src="https://images2.imgbox.com/b5/ea/6KJ8m7gZ_o.png" width="758"></p> 
<p><img alt="" height="582" src="https://images2.imgbox.com/da/18/ACo5Q9JP_o.png" width="585"></p> 
<p></p> 
<pre><code>YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients, 8.1 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:47&lt;00:00, 15.76s/it]
                   all         96       5055      0.912      0.915      0.936      0.772</code></pre> 
<h4>1.1  Gold-YOLO，遥遥领先，超越所有YOLO | 华为诺亚NeurIPS23</h4> 
<p><img alt="" height="610" src="https://images2.imgbox.com/9f/4f/7yZ8DWJG_o.png" width="1173">​</p> 
<p>提出了一种全新的信息交互融合机制：<strong>信息聚集-分发机制(Gather-and-Distribute Mechanism)</strong>。该机制通过在全局上融合不同层次的特征得到全局信息，并将全局信息注入到不同层级的特征中，实现了高效的信息交互和融合。在不显著增加延迟的情况下GD机制显著增强了Neck部分的信息融合能力，提高了模型对不同大小物体的检测能力。 </p> 
<p><img alt="" height="475" src="https://images2.imgbox.com/82/5a/ZsV1A5xW_o.png" width="1159">​</p> 
<p> 在Gold-YOLO中，针对模型需要检测不同大小的物体的需要，并权衡精度和速度，我们构建了两个GD分支对信息进行融合：低层级信息聚集-分发分支(Low-GD)和高层级信息聚集-分发分支(High-GD)，分别基于卷积和transformer提取和融合特征信息。</p> 
<p><img alt="" height="422" src="https://images2.imgbox.com/2c/5f/THeSLILS_o.png" width="1200">​</p> 
<p><strong> 原始mAP@0.5 0.936提升至0.945</strong></p> 
<p><img alt="" height="505" src="https://images2.imgbox.com/00/74/EPSCyNt5_o.png" width="751"></p> 
<p></p> 
<p>​</p> 
<pre><code>YOLOv8-goldYOLO summary: 359 layers, 6015123 parameters, 0 gradients, 11.9 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:09&lt;00:00,  3.11s/it]
                   all         96       5055       0.91      0.922      0.945      0.787</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133337820" rel="nofollow" title="基于Yolov8的工业端面小目标计数检测（2）：Gold-YOLO，遥遥领先，超越所有YOLO | 华为诺亚NeurIPS23_AI小怪兽的博客-CSDN博客">基于Yolov8的工业端面小目标计数检测（2）：Gold-YOLO，遥遥领先，超越所有YOLO | 华为诺亚NeurIPS23_AI小怪兽的博客-CSDN博客</a></p> 
<h4> 1.2 小目标计数解决方案: 多头检测器+小缺陷到大缺陷一网打尽的GiraffeDet+Wasserstein Distance Loss</h4> 
<p><strong> 原始mAP@0.5 0.936提升至0.955</strong></p> 
<p>​<img alt="" height="501" src="https://images2.imgbox.com/21/ab/7cQBy6yW_o.png" width="755">​​</p> 
<pre><code>YOLOv8_4_CSPStage summary: 303 layers, 2953396 parameters, 0 gradients, 12.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:22&lt;00:00,  3.75s/it]
                   all         96       5055       0.92      0.951      0.955      0.811</code></pre> 
<p><a href="https://cv2023.blog.csdn.net/article/details/133375930" rel="nofollow" title="基于YOLOv8的端面小目标计数解决方案: 多头检测器+小缺陷到大缺陷一网打尽的GiraffeDet+Wasserstein Distance Loss | 助力工业小目标缺陷检测_AI小怪兽的博客-CSDN博客">基于YOLOv8的端面小目标计数解决方案: 多头检测器+小缺陷到大缺陷一网打尽的GiraffeDet+Wasserstein Distance Loss | 助力工业小目标缺陷检测_AI小怪兽的博客-CSDN博客</a></p> 
<p><strong>未完待续，持续更新中</strong>​​​​​​​</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6fcbd0f86d66c2c176fb08986f2fa83c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">百度飞桨(PaddlePaddle) - PP-OCRv3 文字检测识别系统 预测部署简介与总览</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/b405c453e95d1d5c70198673dbedc9c5/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">基于STM32单片机的智能药盒定时提示吃药喂水蓝牙APP方案原理图设计</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>