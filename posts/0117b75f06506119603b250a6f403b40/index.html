<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【机器学习|Python】sklearn中的数据预处理方法 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【机器学习|Python】sklearn中的数据预处理方法" />
<meta property="og:description" content="前言 本篇文章主要讲解Python的sklearn库中常用的数据预处理方法，主要介绍工具中的内容，即该库中的相关方法包含的常用接口和基本使用，并不适合手把手入门学习，此外将涉及更少的原理和使用情况说明。
更多关于本文涉及的数据预处理方法的原理知识：【机器学习】数据预处理方法中的数学原理 (1) - 掘金 (juejin.cn) sklearn中的数据预处理 sklearn.preprocessing：sklearn中的数据预处理模块sklearn.impute：sklearn中的缺失值填充模块 本文主要涉及的方法：
极差归一化：sklearn.preprocessing.MinMaxScaler数据标准化：sklearn.preprocessing.StandardScaler标签编码：sklearn.preprocessing.LabelEncoder特征编码：sklearn.preprocessing.OrdinalEncoder数据二值化：sklearn.preprocessing.Binarizer数据分箱：sklearn.preprocessing.KBinsDiscretizer缺失值处理：sklearn.impute.SimpleImputer ps：拟合的时候可以传入多个特征数据，sklearn中的方法大多都会自动分别对每一列进行处理，但sklearn一般不支持一维数据导入，至少为二维，若想传入一维数组进行处理可以使用reshape(-1, 1)转为二维数组，若想传入单个Series对象则需要先将其转为DataFrame对象。
数据无量纲化 极差归一化：统一量纲，将某特征下所有的值归一化在指定范围内，默认该范围为 [0,1][0, 1][0,1]，也可以手动确定范围。
常用接口如下：
import pandas as pd import numpy as np from sklearn.preprocessing import MinMaxScaler data = pd.DataFrame(np.random.randint(10, 100, (5, 2))) # 准备测试数据 # 常用接口 scaler = MinMaxScaler() # 默认范围为 [0,1] scaler = MinMaxScaler(feature_range=[5, 10]) # 自定义归一化数据范围 scaler.fit(data) # 拟合数据 scaler.partial_fit(data) # 数据量大的时候fit()报错，可以使用partial_fit() result = scaler.transform(data) # 变换数据 result = scaler.fit_transform(data) # 拟合和变换一步达成 data = scaler." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0117b75f06506119603b250a6f403b40/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-05T18:23:00+08:00" />
<meta property="article:modified_time" content="2024-01-05T18:23:00+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【机器学习|Python】sklearn中的数据预处理方法</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>前言</h2> 
<p>本篇文章主要讲解Python的sklearn库中常用的数据预处理方法，主要介绍工具中的内容，即该库中的相关方法包含的常用接口和基本使用，并不适合手把手入门学习，此外将涉及更少的原理和使用情况说明。</p> 
<ul><li>更多关于本文涉及的数据预处理方法的原理知识：<a href="https://juejin.cn/post/7270822762725949500" rel="nofollow" title="https://juejin.cn/post/7270822762725949500">【机器学习】数据预处理方法中的数学原理 (1) - 掘金 (juejin.cn)</a></li></ul> 
<h2><a id="sklearn_8"></a>sklearn中的数据预处理</h2> 
<ul><li><code>sklearn.preprocessing</code>：sklearn中的数据预处理模块</li><li><code>sklearn.impute</code>：sklearn中的缺失值填充模块</li></ul> 
<p>本文主要涉及的方法：</p> 
<ul><li>极差归一化：<code>sklearn.preprocessing.MinMaxScaler</code></li><li>数据标准化：<code>sklearn.preprocessing.StandardScaler</code></li><li>标签编码：<code>sklearn.preprocessing.LabelEncoder</code></li><li>特征编码：<code>sklearn.preprocessing.OrdinalEncoder</code></li><li>数据二值化：<code>sklearn.preprocessing.Binarizer</code></li><li>数据分箱：<code>sklearn.preprocessing.KBinsDiscretizer</code></li><li>缺失值处理：<code>sklearn.impute.SimpleImputer</code></li></ul> 
<blockquote> 
 <p>ps：拟合的时候可以传入多个特征数据，sklearn中的方法大多都会自动分别对每一列进行处理，但sklearn一般不支持一维数据导入，至少为二维，若想传入一维数组进行处理可以使用<code>reshape(-1, 1)</code>转为二维数组，若想传入单个Series对象则需要先将其转为DataFrame对象。</p> 
</blockquote> 
<h2><a id="_26"></a>数据无量纲化</h2> 
<p><strong>极差归一化</strong>：统一量纲，将某特征下所有的值归一化在指定范围内，默认该范围为 [0,1][0, 1][0,1]，也可以手动确定范围。</p> 
<p>常用接口如下：</p> 
<pre><code>import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler

data = pd.DataFrame(np.random.randint(10, 100, (5, 2)))  # 准备测试数据

# 常用接口
scaler = MinMaxScaler()  # 默认范围为 [0,1]
scaler = MinMaxScaler(feature_range=[5, 10])  # 自定义归一化数据范围

scaler.fit(data)  # 拟合数据
scaler.partial_fit(data)  # 数据量大的时候fit()报错，可以使用partial_fit()

result = scaler.transform(data)   # 变换数据
result = scaler.fit_transform(data)    # 拟合和变换一步达成
data = scaler.inverse_transform(result)  # 逆向变换

</code></pre> 
<p><code>.partial_fit()</code>：该方法是一种增量学习的方式，可以逐步从流式数据中学习缩放参数，当数据量太大导致 <code>.fit()</code> 接口报错时，可以使用该接口</p> 
<blockquote> 
 <p>我们把大批量的数据想象成一个大湖，既然我们无法一次性将这个大湖中的所有水进行处理（学习），但我们可以将其延伸出来一条小河，对顺着小何流动的水（数据流）不断进行处理（学习）。</p> 
 <ul><li>增量学习：是一种可以逐步从新数据中学习的机器学习方法。它不需要重新训练整个模型,而是可迭代地更新模型参数。</li><li>流式数据：指的是连续不断产生的数据流</li></ul> 
</blockquote> 
<p><strong>Z-score标准化</strong>：统一量纲，且变换后的数据服从均值为0方差为1的标准正态分布。</p> 
<p>常用接口如下：和MinMaxScaler基本一样</p> 
<pre><code>import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

data = pd.DataFrame(np.random.randint(10, 100, (5, 2)))  # 准备测试数据

# 常用接口
scaler = StandardScaler()  # 创建对象

scaler.fit(data)  # 拟合数据
scaler.partial_fit(data)  # 数据量大的时候fit()报错，可以使用partial_fit()

result = scaler.transform(data)  # 变换数据
result = scaler.fit_transform(data)  # 拟合和变换一步达成
data = scaler.inverse_transform(result)  # 逆向变换

# 常用属性
scaler.var_  # 拟合后查看各列数据的方差
scaler.mean_  # 拟合后查看各列数据的均值

</code></pre> 
<p>对于 StandardScaler 和 MinMaxScaler 来说，空值<code>NaN</code>会被当做是缺失值，在 fit 的时候忽略，在 transform 的时候保持缺失 NaN 的状态显示。</p> 
<h2><a id="_89"></a>缺失值处理</h2> 
<p>SimpleImputer 是sklearn中的简单填充方案，可以填充均值、中位数、众数或特定值</p> 
<p>常用参数：</p> 
<ul><li><code>missing_values</code>：改组数据中的缺失值是什么样的，默认为 <code>np.nan</code></li><li><code>strategy</code>：填充策略，默认为<code>'mean'</code> 
  <ul><li><code>'mean'</code>：均值填充</li><li><code>'median'</code>：中位数填充</li><li><code>'most_frequent'</code>：众数填充</li><li><code>'constant'</code>：填充固定值，该值在 <code>fill_value</code>参数中设置</li></ul> </li><li><code>fill_value</code>：在 <code>strategy</code> 参数设置为 <code>'constant'</code> 时，设置填充值</li><li><code>copy</code>：默认为True，给处理后的数据创建副本并返回，否则在原对象上进行修改</li></ul> 
<p>常用接口：</p> 
<pre><code>import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer

data = pd.DataFrame(np.random.randint(10, 100, (5, 2)))  # 准备测试数据

# 常用接口
imp_mean = SimpleImputer()  # 均值填充缺失值
imp_median = SimpleImputer(strategy='median')  # 中位数填充缺失值
imp_mode = SimpleImputer(strategy='most_frequent')  # 众数填充
imp_0 = SimpleImputer(strategy='constant', fill_value=0)  # 0填充

imp_mean.fit(data)  # 拟合数据

result = imp_mean.transform(data)  # 变换数据
result = imp_mean.fit_transform(data)  # 拟合和变换一步到位

</code></pre> 
<p>除了使用sklearn中的SimpleImputer进行简单填充，利用pandas也可以直接进行填充：</p> 
<pre><code>import pandas as pd
import numpy as np

data = pd.DataFrame(np.random.randint(10, 100, (5, 2)))  # 准备测试数据
data.iloc[0:2, 0:2] = np.nan

# 使用pandas进行缺失值填充
result = data.fillna(0)  # 0填充所有缺失值
# 均值填充第0列,中位数填充、众数填充同理
result = data.iloc[:, 0] = data.iloc[:, 0].fillna(data.iloc[:, 0].mean())  
result = data.dropna(axis=0)  # 删除所有含有缺失值的样本数据

</code></pre> 
<p>注意：pandas中的<code>.mean()</code>和<code>.median()</code>方法返回对应均值或中位数，但由于众数可能含有多个，取众数<code>.mode()</code>方法返回的是一个Series对象，填充时取其中的任意值即可，一般取索引为0的值。</p> 
<blockquote> 
 <p>中位数只可能是一个或者两个，若为两个，则取这两个数的均值，但众数则可能有很多个</p> 
</blockquote> 
<h2><a id="_148"></a>编码和哑变量</h2> 
<p>LabelEncoder和OrdinalEncoder分别用于给标签和特征数据进行编码，主要用于非名义变量。</p> 
<pre><code>import pandas as pd
from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, OneHotEncoder

# 准备测试数据
data_dic = {
    '性别': ['男', '女', '女', '男', '女'],
    '学历': ['小学', '初中', '初中', '大学', '高中'],
    '标签': ['标签3', '标签1', '标签2', '标签3', '标签2'],
}

data = pd.DataFrame(data_dic) 

# 常用接口
le = LabelEncoder()  # 创建对象
oe = OrdinalEncoder()

le = le.fit(data.loc[:, '标签'])  # 拟合数据

result = le.transform(data.loc[:, '标签'])  # 变换数据
result = le.fit_transform(data.loc[:, '标签'])  # 拟合和变换一步达成
data = le.inverse_transform(result)  # 逆向变换

data = pd.DataFrame(data_dic)

# 一般这样写
result = LabelEncoder().fit_transform(data.loc[:, '标签']) 
result = OrdinalEncoder().fit_transform(data.loc[:, ['性别', '学历']])

# 常用属性
le.classes_   # 返回原来的字符串标签唯一值数组, 按该数组顺序编号
oe.categories_    # 返回原来的字符串标签数组, 按该数组顺序编号

</code></pre> 
<p>OrdinalEcoder和LabelEncoder用法和接口几乎一致，区别在于LabelEncoder可以处理一维数据，且使用<code>.classes_</code>属性来查看标签编号数组，OrdinalEncoder不能处理一维数据，且使用<code>.categories_</code>属性来查看标签编号数组</p> 
<p>OneHotEncoder独热编码主要用于名义变量，将特征转换为哑变量。</p> 
<blockquote> 
 <p>特征可以转换为哑变量，标签也可以，许多算法可以处理多标签问题，但这样的做法在现实中不常见。</p> 
</blockquote> 
<p>常用参数：</p> 
<ul><li><code>categories</code>：表示每个特征都有哪些类别，默认为 ‘auto’，一般情况我们都用默认值 
  <ul><li><code>'auto'</code>：为自行判断</li><li>嵌套列表：列表中里面每个元素都是一个包含特征类别的列表。</li></ul> </li><li><code>'handle_unknown'</code>：表示对于未注明特征或类别的处理方式，默认为 <code>'error'</code> 
  <ul><li><code>'error'</code>：设置<code>categories</code>后，算法遇到了列表中没有包含的特征或类别时，会报错，</li><li><code>'ignore'</code>：未在 <code>categories</code> 注明的特征或类别的哑变量都会显示0，在逆向变换时未知特征或类别则会显示None</li></ul> </li></ul> 
<pre><code>import pandas as pd
from sklearn.preprocessing import OneHotEncoder
# 准备测试数据
data_dic = {
    '性别': ['男', '女', '女', '男', '女'],
    '学历': ['小学', '初中', '初中', '大学', '高中'],
    '标签': ['标签3', '标签1', '标签2', '标签3', '标签2'],
}

data = pd.DataFrame(data_dic) 

# 常用接口
encoder = OneHotEncoder()

encoder.fit(data[['性别']])  # 拟合数据

result = encoder.transform(data[['性别']])  # 变换数据
result = encoder.fit_transform(data[['性别']])  # 拟合和变换一步到位
data = encoder.inverse_transform(result)  # 逆向变换

# 一般这样写
result = OneHotEncoder().fit_transform(data[['性别']])

</code></pre> 
<p>注意：OneHotEncoder在transform后返回的是稀疏矩阵，需要使用 <code>.toarray()</code> 方法转为矩阵(二维数组)；inverse_transfrom可以接收稀疏矩阵也可以接收正常的矩阵，返回正常的矩阵。</p> 
<p>此外，在经过OneHotEncoder处理后我们需要自行使用pandas将哑变量拼接到原矩阵（pd.concat()）和删除原来的特征（pd.drop()）</p> 
<h2><a id="_233"></a>连续型特征处理</h2> 
<p>Binarizer用于将数据二值化，所谓数据二值化，就是设置一个阈值，小于等于该阈值的记为0，大于该阈值的记为1。</p> 
<p>常用接口：</p> 
<pre><code>import numpy as np
from sklearn.preprocessing import Binarizer

data = np.arange(10, 20).reshape(-1, 1)

bin = Binarizer(threshold=15)  # 默认threshold为0

bin.fit(data)  # 拟合数据

result = bin.transform(data)  # 变换数据
result = bin.fit_transform(data)  # 拟合和变换一步达成

# 一般这样用
result = Binarizer(threshold=15).fit_transform(data)

</code></pre> 
<p>KBinsDiscretizer用于将连续型变量划分为分类变量，能够将连续型变量排序后按顺序分箱后编码。</p> 
<p>常用参数：</p> 
<ul><li><code>'n_bins'</code>：每个特征中分箱的个数，默认为5，</li><li><code>'encode'</code>：编码方式，默认为 <code>'onehot'</code> 
  <ul><li><code>'onehot'</code>：独热编码为哑变量，返回一个稀疏矩阵</li><li><code>'onehot-dense'</code>：独热编码为哑变量，返回一个密集矩阵 (一般的矩阵)</li><li><code>'ordinal'</code>：每个特征的每箱数据都被编码为一个整数，返回编码后的矩阵</li></ul> </li><li><code>'strategy'</code>：定义分箱方式，默认为 <code>'quantile'</code> 
  <ul><li><code>'uniform'</code>：等宽分箱，每个特征的每箱数据中的极差不得高于 max(x)−min(x)Nbins\frac{max(x)-min(x)}{N_{bins}}Nbins​max(x)−min(x)​，其中 xxx 表示某特征下的数据，NbinsN_{bins}Nbins​ 表示分箱个数</li><li><code>'quantile'</code>：等位分箱，即每个特征中的每个箱内的样本数量都相同</li><li><code>'kmeans'</code>：按kmeans聚类分箱，每个箱中的值到最近的一维k均值聚类的簇心的距离都相同</li></ul> </li></ul> 
<p>常用接口：</p> 
<pre><code>import numpy as np
import pandas as pd
from sklearn.preprocessing import KBinsDiscretizer

data = pd.DataFrame(np.random.randint(10, 100, (5, 2)))  # 准备测试数据
est = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile')

est.fit(data)  # 拟合数据

result = est.transform(data)  # 变换数据
result = est.fit_transform(data)  # 拟合和变换一步到位
data = est.inverse_transform(result)  # 

# 一般这样用
result = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='quantile').fit_transform(data)

</code></pre> 
<p>需要注意的是，这里的inverse_transform已经无法将数据转为原来的数据，因为在进行分箱离散化时,原始的连续值已经被转换到了分箱区间中，inverse_transform不可能恢复到与原始值完全相同的结果，但是它可以通过区间映射，将分类变量映射回连续值的范围中，从而部分恢复原始数据的连续分布区间，结果并不会每一个值都完全等于原始数据，但整体上逼近了原始数据的分布范围。</p> 
<blockquote> 
 <p>不建议使用inverse_transform，因为逆向变换后的数据已经不是原本的数据了。</p> 
</blockquote> 
<h2><a id="Reference_297"></a>Reference</h2> 
<ul><li>菜菜的sklearn机器学习</li><li>相关网络资源和书籍</li></ul> 
<center> 
 <b>---------------------------END--------------------------- </b> 
</center> 
<h3><a id="_308"></a>题外话</h3> 
<img src="https://images2.imgbox.com/5a/94/VAE8Nolp_o.png"> ![在这里插入图片描述](https://img-blog.csdnimg.cn/cb9eaa37ce994535bdf60e07ba4cf09e.jpeg#pic_center) 
<p><font face="幼圆" size="4" color="red">感兴趣的小伙伴，赠送全套Python学习资料，包含面试题、简历资料等具体看下方。<br> </font></p> 
<p>👉<font color="red">CSDN大礼包🎁：</font><a href="https://blog.csdn.net/weixin_68789096/article/details/132275547?spm=1001.2014.3001.5502">全网最全《Python学习资料》免费赠送🆓！</a><font color="#66cc66">（安全链接，放心点击）</font></p> 
<p><strong>一、Python所有方向的学习路线</strong></p> 
<p>Python所有方向的技术点做的整理，形成各个领域的知识点汇总，它的用处就在于，你可以按照下面的知识点去找对应的学习资源，保证自己学得较为全面。</p> 
<p><img src="https://images2.imgbox.com/cc/d6/Qc3UkjDF_o.png" alt="img"><br> <img src="https://images2.imgbox.com/24/8f/sBe2gtBW_o.png" alt="img"></p> 
<p><strong>二、Python必备开发工具</strong></p> 
<p>工具都帮大家整理好了，安装就可直接上手！<img src="https://images2.imgbox.com/1c/6d/zbNQdzZJ_o.gif" alt="img"></p> 
<p><strong>三、最新Python学习笔记</strong></p> 
<p>当我学到一定基础，有自己的理解能力的时候，会去阅读一些前辈整理的书籍或者手写的笔记资料，这些笔记详细记载了他们对一些技术点的理解，这些理解是比较独到，可以学到不一样的思路。</p> 
<p><img src="https://images2.imgbox.com/37/7b/uPOvvuGw_o.png" alt="img"></p> 
<p><strong>四、Python视频合集</strong></p> 
<p>观看全面零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><img src="https://images2.imgbox.com/ff/a8/TLEmWCHj_o.png" alt="img"></p> 
<p><strong>五、实战案例</strong></p> 
<p>纸上得来终觉浅，要学会跟着视频一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。</p> 
<p><img src="https://images2.imgbox.com/87/68/ZAxp2gl4_o.png" alt="img"></p> 
<p><strong>六、面试宝典</strong></p> 
<p><img src="https://images2.imgbox.com/5d/18/8AQ80yeM_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/12/97/H4Ht66Pt_o.png" alt="在这里插入图片描述"></p> 
<h6><a id="httpsimgblogcsdnimgcn646863996ac44da8af500c049bb72fbdpngpic_centerimg_srchttpsimgblogcsdnimgcnimg_convert8977ea37c34bc4a7a9b9db2d4102ee7bpng_360"></a><strong>简历模板</strong><img src="https://images2.imgbox.com/54/30/2CVnM0nv_o.png" alt="在这里插入图片描述"><img src="https://images2.imgbox.com/9e/41/TCxVExCg_o.png"></h6> 
<p>👉<font color="red">CSDN大礼包🎁：</font><a href="https://blog.csdn.net/weixin_68789096/article/details/132275547?spm=1001.2014.3001.5502">全网最全《Python学习资料》免费赠送🆓！</a><font color="#66cc66">（安全链接，放心点击）</font></p> 
<p>若有侵权，请联系删除</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b77b2ae93608b673e60117438f73623a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">贪心算法：活动选择问题以及贪心选择性质证明</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/7c508ed17a7a22274448aedd89714422/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C语言——指针</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>