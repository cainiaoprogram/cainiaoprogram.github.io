<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python3_实现BP神经网络 &#43; BP神经网络应用实例 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python3_实现BP神经网络 &#43; BP神经网络应用实例" />
<meta property="og:description" content="0.目录 1.BP神经网络简介
2.前期理论准备
2.算法数学原理
（一）符号说明
（二）公式推导
3.python实现（python3编程实现）
（一）sigmoid函数
（二）BP主函数实现
4.数据格式
1.BP神经网络简介 BP神经网络是1986年由Rumelhart和McClelland为首的科学家提出的概念，是一种按照逆向传播算法训练的多层前馈神经网络，是目前应用最广泛的神经网络。
目录
0.目录
1.BP神经网络简介
2.前期理论准备
2.算法数学原理
（一）符号说明
（二）公式推导
3.python实现（python3编程实现）
（一）sigmoid函数
（二）BP主函数实现
4.数据格式
优点：
1.具有任意复杂的模式分类能力和优良的多维函数映射能力，解决了简单感知器不能解决的异或问题的问题（参考博客：https://www.jianshu.com/p/a25788130897 或 https://www.cnblogs.com/xym4869/p/11282469.html）2.从结构上讲，BP神经网络具有输入层、隐含层和输出层3.从本质上讲，BP算法就是以网络误差平方目标函数、采用梯度下降法来计算目标函数的最小值。基本BP算法包括信号的前向传播和误差的反向传播两个过程。 缺点：
1.学习速度慢，即使是一个简单的过程，也需要几百次甚至上千次的学习才能收敛。2.容易陷入局部极小值3.网络层数、神经元个数的选择没有相应的理论指导4.网络推广能力有限。 应用：
1.函数逼近2.模式识别3.分类4.数据压缩 2.前期理论准备 网络训练的目标：找到合适的权值和阈值，使得误差E最小。
sigmoid函数：在信息科学当中，由于其单增以及其反函数单增等性质，sigmoid函数常被用作神经网络的阈值函数，将变量映射当0和1之间。（该函数的对x的求导也应该理解）
2.算法数学原理 （一）符号说明 Xi: 输入信号。
Xd: 隐层的阈值（是从求和函数中-θ中分离出的-1）。
Vih: 第h个隐层神经元所对应输入信号Xi的权值。
αh: 第h个隐层神经元的输入。
-γh=--1*γh：隐层神经元的阈值。
bh: 第h个隐层神经元的输入。
ωhj: 第j个输出层神经元所对应的隐层神经元输出bh的权值。
-θj=-1*θj: 输出层神经元的阈值（bq）
：第j个输出层神经元的输出（预测输出值，yj为真实值）
（二）公式推导 通过公式变换可得输出层权值与阈值的变化量：
同理可得隐层权值和阈值的变化量：
3.python实现（python3编程实现） （一）sigmoid函数 def sigmoid(x): &#34;&#34;&#34; 隐含层和输出层对应的函数法则 &#34;&#34;&#34; return 1/(1&#43;np.exp(-x)) （二）BP主函数实现 def BP(data_tr, data_te, maxiter=600): # --pandas是基于numpy设计的，效率略低 # 为提高处理效率，转换为数组 data_tr, data_te = np." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/249c2a1d7195e3e2633656fa42196ddc/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-29T22:10:28+08:00" />
<meta property="article:modified_time" content="2018-07-29T22:10:28+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python3_实现BP神经网络 &#43; BP神经网络应用实例</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3 id="main-toc"><strong>0.目录</strong></h3> 
<p id="1.BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B-toc" style="margin-left:40px;"><a href="#1.BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B" rel="nofollow">1.BP神经网络简介</a></p> 
<p id="2.%E5%89%8D%E6%9C%9F%E7%90%86%E8%AE%BA%E5%87%86%E5%A4%87-toc" style="margin-left:40px;"><a href="#2.%E5%89%8D%E6%9C%9F%E7%90%86%E8%AE%BA%E5%87%86%E5%A4%87" rel="nofollow">2.前期理论准备</a></p> 
<p id="2.%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86-toc" style="margin-left:40px;"><a href="#2.%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86" rel="nofollow">2.算法数学原理</a></p> 
<p id="%EF%BC%88%E4%B8%80%EF%BC%89%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E-toc" style="margin-left:80px;"><a href="#%EF%BC%88%E4%B8%80%EF%BC%89%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E" rel="nofollow">（一）符号说明</a></p> 
<p id="%EF%BC%88%E4%BA%8C%EF%BC%89%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC-toc" style="margin-left:80px;"><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC" rel="nofollow">（二）公式推导</a></p> 
<p id="3.python%E5%AE%9E%E7%8E%B0%EF%BC%88python3%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%EF%BC%89-toc" style="margin-left:40px;"><a href="#3.python%E5%AE%9E%E7%8E%B0%EF%BC%88python3%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%EF%BC%89" rel="nofollow">3.python实现（python3编程实现）</a></p> 
<p id="%EF%BC%88%E4%B8%80%EF%BC%89sigmoid%E5%87%BD%E6%95%B0-toc" style="margin-left:80px;"><a href="#%EF%BC%88%E4%B8%80%EF%BC%89sigmoid%E5%87%BD%E6%95%B0" rel="nofollow">（一）sigmoid函数</a></p> 
<p id="%EF%BC%88%E4%BA%8C%EF%BC%89BP%E4%B8%BB%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0-toc" style="margin-left:80px;"><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89BP%E4%B8%BB%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0" rel="nofollow">（二）BP主函数实现</a></p> 
<p id="4.%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F-toc" style="margin-left:40px;"><a href="#4.%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F" rel="nofollow">4.数据格式</a></p> 
<h3 id="1.BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B">1.BP神经网络简介</h3> 
<blockquote> 
 <p>BP神经网络是1986年由Rumelhart和McClelland为首的科学家提出的概念，是一种按照逆向传播算法训练的多层前馈神经网络，是目前应用最广泛的神经网络。</p> 
 <p><strong>目录</strong></p> 
 <p id="main-toc-toc" style="margin-left:40px;"><a href="#main-toc" rel="nofollow">0.目录</a></p> 
 <p style="margin-left:40px;"><a href="#1.BP%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B" rel="nofollow">1.BP神经网络简介</a></p> 
 <p style="margin-left:40px;"><a href="#2.%E5%89%8D%E6%9C%9F%E7%90%86%E8%AE%BA%E5%87%86%E5%A4%87" rel="nofollow">2.前期理论准备</a></p> 
 <p style="margin-left:40px;"><a href="#2.%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86" rel="nofollow">2.算法数学原理</a></p> 
 <p style="margin-left:80px;"><a href="#%EF%BC%88%E4%B8%80%EF%BC%89%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E" rel="nofollow">（一）符号说明</a></p> 
 <p style="margin-left:80px;"><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC" rel="nofollow">（二）公式推导</a></p> 
 <p style="margin-left:40px;"><a href="#3.python%E5%AE%9E%E7%8E%B0%EF%BC%88python3%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%EF%BC%89" rel="nofollow">3.python实现（python3编程实现）</a></p> 
 <p style="margin-left:80px;"><a href="#%EF%BC%88%E4%B8%80%EF%BC%89sigmoid%E5%87%BD%E6%95%B0" rel="nofollow">（一）sigmoid函数</a></p> 
 <p style="margin-left:80px;"><a href="#%EF%BC%88%E4%BA%8C%EF%BC%89BP%E4%B8%BB%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0" rel="nofollow">（二）BP主函数实现</a></p> 
 <p style="margin-left:40px;"><a href="#4.%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F" rel="nofollow">4.数据格式</a></p> 
 <hr id="hr-toc"> 
 <p><span style="color:#f33b45;"><u><strong>优点</strong></u></span>：</p> 
 <ul><li>1.具有任意复杂的模式分类能力和优良的多维函数映射能力，解决了简单感知器不能解决的异或问题的问题（参考博客：<a href="https://www.jianshu.com/p/a25788130897" rel="nofollow">https://www.jianshu.com/p/a25788130897</a> 或 <a href="https://www.cnblogs.com/xym4869/p/11282469.html" rel="nofollow">https://www.cnblogs.com/xym4869/p/11282469.html</a>）</li><li>2.从结构上讲，BP神经网络具有输入层、隐含层和输出层</li><li>3.从本质上讲，BP算法就是以网络误差平方目标函数、采用梯度下降法来计算目标函数的最小值。基本BP算法包括<span style="color:#86ca5e;"><u><strong>信号的前向传播</strong></u></span>和<span style="color:#86ca5e;"><u><strong>误差的反向传播</strong></u></span>两个过程。</li></ul> 
 <p><span style="color:#f33b45;"><u><strong>缺点</strong></u></span>：</p> 
 <ul><li>1.学习速度慢，即使是一个简单的过程，也需要几百次甚至上千次的学习才能收敛。</li><li>2.容易陷入局部极小值</li><li>3.网络层数、神经元个数的选择没有相应的理论指导</li><li>4.网络推广能力有限。</li></ul> 
 <p><span style="color:#f33b45;"><u><strong>应用</strong></u></span>：</p> 
 <ul><li>1.函数逼近</li><li>2.模式识别</li><li>3.分类</li><li>4.数据压缩</li></ul> 
</blockquote> 
<h3 id="2.%E5%89%8D%E6%9C%9F%E7%90%86%E8%AE%BA%E5%87%86%E5%A4%87">2.前期理论准备</h3> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/2e/fb/egRCeWxU_o.png"></p> 
<blockquote> 
 <p><span style="color:#f33b45;"><u><strong>网络训练的目标</strong></u></span>：找到合适的权值和阈值，使得误差E最小。</p> 
 <p><span style="color:#f33b45;"><u><strong>sigmoid函数</strong></u></span>：在信息科学当中，由于其单增以及其反函数单增等性质，sigmoid函数常被用作神经网络的阈值函数，将变量映射当0和1之间。（该函数的对x的求导也应该理解）</p> 
</blockquote> 
<h3 id="2.%E7%AE%97%E6%B3%95%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86">2.算法数学原理</h3> 
<h4 id="%EF%BC%88%E4%B8%80%EF%BC%89%E7%AC%A6%E5%8F%B7%E8%AF%B4%E6%98%8E">（一）符号说明</h4> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/3a/1a/zy9aP620_o.png"></p> 
<blockquote> 
 <p>Xi: 输入信号。</p> 
 <p>Xd: 隐层的阈值（是从求和函数中-θ中分离出的-1）。</p> 
 <p>Vih: 第h个隐层神经元所对应输入信号Xi的权值。</p> 
 <p>αh: 第h个隐层神经元的输入。</p> 
 <p>-γh=--1*γh：隐层神经元的阈值。</p> 
 <p>bh: 第h个隐层神经元的输入。</p> 
 <p>ωhj: 第j个输出层神经元所对应的隐层神经元输出bh的权值。</p> 
 <p>-θj=-1*θj:  输出层神经元的阈值（bq）</p> 
 <p style="margin-left:0cm;"><img alt="" class="has" height="31" src="https://images2.imgbox.com/d8/e4/UmFnHYI6_o.png" width="18">：第j个输出层神经元的输出（预测输出值，yj为真实值）</p> 
</blockquote> 
<h4 id="%EF%BC%88%E4%BA%8C%EF%BC%89%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC" style="margin-left:0cm;">（二）公式推导</h4> 
<p>通过公式变换可得输出层权值与阈值的变化量：</p> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/25/0b/kLx3EP8I_o.png"></p> 
<p>同理可得隐层权值和阈值的变化量：</p> 
<p style="text-align:center;"><img alt="" class="has" src="https://images2.imgbox.com/69/4e/b0VkOAWq_o.png"></p> 
<h3 id="3.python%E5%AE%9E%E7%8E%B0%EF%BC%88python3%E7%BC%96%E7%A8%8B%E5%AE%9E%E7%8E%B0%EF%BC%89">3.python实现（python3编程实现）</h3> 
<h4 id="%EF%BC%88%E4%B8%80%EF%BC%89sigmoid%E5%87%BD%E6%95%B0">（一）sigmoid函数</h4> 
<pre class="has"><code class="language-python">def sigmoid(x):
    """
    隐含层和输出层对应的函数法则
    """
    return 1/(1+np.exp(-x))
</code></pre> 
<h4 id="%EF%BC%88%E4%BA%8C%EF%BC%89BP%E4%B8%BB%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0">（二）BP主函数实现</h4> 
<pre class="has"><code class="language-python">def BP(data_tr, data_te, maxiter=600):

    # --pandas是基于numpy设计的，效率略低
    # 为提高处理效率，转换为数组
    data_tr, data_te = np.array(data_tr), np.array(data_te)

    # --隐层输入
    # -1： 代表的是隐层的阈值
    net_in = np.array([0.0, 0, -1])
    w_mid = np.random.rand(3, 4)          # 隐层权值阈值（-1x其中一个值：阈值）

    # 输出层输入
    # -1：代表输出层阈值
    out_in = np.array([0.0, 0, 0, 0, -1])
    w_out = np.random.rand(5)             # 输出层权值阈值（-1x其中一个值：阈值）
    delta_w_out = np.zeros([5])           # 存放输出层权值阈值的逆向计算误差
    delta_w_mid = np.zeros([3, 4])        # 存放因此能权值阈值的逆向计算误差
    yita = 1.75                           # η： 学习速率
    Err = np.zeros([maxiter])             # 记录总体样本每迭代一次的错误率

    # 1.样本总体训练的次数
    for it in range(maxiter):

        # 衡量每一个样本的误差
        err = np.zeros([len(data_tr)])

        # 2.训练集训练一遍
        for j in range(len(data_tr)):
            net_in[:2] = data_tr[j, :2]                       # 存储当前对象前两个属性值
            real = data_tr[j, 2]

            # 3.当前对象进行训练
            for i in range(4):
                out_in[i] = sigmoid(sum(net_in*w_mid[:, i]))  # 计算输出层输入
            res = sigmoid(sum(out_in * w_out))                # 获得训练结果

            err[j] = abs(real - res)

            # --先调节输出层的权值与阈值
            delta_w_out = yita*res*(1-res)*(real-res)*out_in  # 权值调整
            delta_w_out[4] = -yita*res*(1-res)*(real-res)     # 阈值调整
            w_out = w_out + delta_w_out

            # --隐层权值和阈值的调节
            for i in range(4):
                # 权值调整
                delta_w_mid[:, i] = yita * out_in[i] * (1 - out_in[i]) * w_out[i] * res * (1 - res) * (real - res) * net_in
                # 阈值调整
                delta_w_mid[2, i] = -yita * out_in[i] * (1 - out_in[i]) * w_out[i] * res * (1 - res) * (real - res)
            w_mid = w_mid + delta_w_mid
        Err[it] = err.mean()
    plt.plot(Err)
    plt.show()

    # 存储预测误差
    err_te = np.zeros([100])

    # 预测样本100个
    for j in range(100):
        net_in[:2] = data_te[j, :2]                         # 存储数据
        real = data_te[j, 2]                                # 真实结果

        # net_in和w_mid的相乘过程
        for i in range(4):
            # 输入层到隐层的传输过程
            out_in[i] = sigmoid(sum(net_in*w_mid[:, i]))
        res = sigmoid(sum(out_in*w_out))                    # 网络预测结果输出
        err_te[j] = abs(real-res)                           # 预测误差
        print('res:', res, ' real:', real)
    
    plt.plot(err_te)
    plt.show()




if "__main__" == __name__:

    # 1.读取样本
    data_tr = pd.read_csv("5.2 data_tr.txt")
    data_te = pd.read_csv("5.2 data_te.txt")
    BP(data_tr, data_te, maxiter=600)</code></pre> 
<h3 id="4.%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F">4.数据格式</h3> 
<blockquote> 
 <p>训练集、测试集下载链接见置顶评论：</p> 
 <p><a href="https://download.csdn.net/download/admin_maxin/19844122">https://download.csdn.net/download/admin_maxin/19844122</a></p> 
</blockquote> 
<p style="text-align:center;"><img alt="" height="427" src="https://images2.imgbox.com/1c/20/LorUxgad_o.png" width="834"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d8505c321b51705a8f3474efe61b03de/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Android进程间通信 - 几种方式的对比总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ab573b4d353a4540d29281a1de29ca0a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">《区块链100问》第31-40节</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>