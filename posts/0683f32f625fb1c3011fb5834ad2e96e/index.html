<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>从零开始学爬虫(9)——requests模块发送带headers的请求和带参数的请求 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="从零开始学爬虫(9)——requests模块发送带headers的请求和带参数的请求" />
<meta property="og:description" content="一、发送简单的请求 Requests是用python语言基于urllib编写的，采用的是Apache2 Licensed开源协议的HTTP库。与urllib相比，Requests更加方便，可以节约我们大量的工作，建议爬虫使用Requests库。具体可以参考这篇文章：《Python爬虫之requests库》
下面来完成一个小需求：通过requests向百度首页发送请求，获取百度首页的数据
常用的方法：
response.textresponse.contentresponse.status_coderesponse.request.headersresponse.headers 实现代码：
import requests response = requests.get(&#34;http://www.baidu.com&#34;) 二、发送带header的请求 在上图中，可以看到返回response.request.headers的时候，默认的user-Agent是python-requests/2.22.0，这个时候，网站就会知道访问自己的家伙是个程序（或者起码不是一个正常的浏览器），然后网站就可能会进行一些欺骗的操作来返回一些虚假的信息给爬虫。
因此，请求带上header的目的就是模拟浏览器，欺骗服务器，获取和浏览器一致的内容
header的形式：字典
例如：
header = { &#34;User-Agent&#34;:&#34;Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit/537.36(KHTML,like Gecko)Chrome/54.0.2840.99 Safari/537.36&#34; } 用法：requests.get(url,headers = header)
效果图：
此时返回的数据才是百度真实的页面源码
发送带参数的请求 当我们使用百度搜索Python的时候，我们看一下他的导航栏会变成什么样子(注意观察，会发现参数与参数之间使用&amp;连接)：
然而在这一堆参数里面，我们尝试着删除那些我们看不懂的参数（这些参数可能是由js生成的），我们留下关键的参数wd=Python，然后我们会发现网页依旧可以搜索到我们想要的数据：
因此，发送带参数的请求时，我们注意下列几点：
参数的形式：字典kw = {‘wd’:‘Python’}用法：requests.get(url,params = kw)注意：url里面不用自己写问号，url写根网址就行 使用实例：
课后题目： 获取新浪首页，查看response.text和response.content.decode()的区别 使用response.text时：
使用content时：
区别在于解码" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0683f32f625fb1c3011fb5834ad2e96e/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2019-11-20T23:45:07+08:00" />
<meta property="article:modified_time" content="2019-11-20T23:45:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">从零开始学爬虫(9)——requests模块发送带headers的请求和带参数的请求</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>一、发送简单的请求</h2> 
<p>Requests是用python语言基于urllib编写的，采用的是Apache2 Licensed开源协议的HTTP库。与urllib相比，Requests更加方便，可以节约我们大量的工作，建议爬虫使用Requests库。具体可以参考这篇文章：<a href="https://www.jianshu.com/p/fb6ee6cc5c1c" rel="nofollow">《Python爬虫之requests库》</a></p> 
<p>下面来完成一个小需求：通过requests向百度首页发送请求，获取百度首页的数据<br> 常用的方法：</p> 
<ul><li>response.text</li><li>response.content</li><li>response.status_code</li><li>response.request.headers</li><li>response.headers</li></ul> 
<p>实现代码：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> requests
response <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">"http://www.baidu.com"</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/74/ff/iATM7rzX_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="header_18"></a>二、发送带header的请求</h2> 
<p>在上图中，可以看到返回response.request.headers的时候，默认的user-Agent是python-requests/2.22.0，这个时候，网站就会知道访问自己的家伙是个程序（或者起码不是一个正常的浏览器），然后网站就可能会进行一些欺骗的操作来返回一些虚假的信息给爬虫。</p> 
<p>因此，请求带上header的目的就是<strong>模拟浏览器，欺骗服务器，获取和浏览器一致的内容</strong></p> 
<p>header的形式：字典<br> 例如：</p> 
<pre><code>header = {
	"User-Agent":"Mozilla/5.0(Windows NT 10.0;Win64;x64)AppleWebKit/537.36(KHTML,like Gecko)Chrome/54.0.2840.99 Safari/537.36"
}
</code></pre> 
<p>用法：requests.get(url,headers = header)</p> 
<p>效果图：<br> <img src="https://images2.imgbox.com/6f/5b/hit0ab8A_o.png" alt="在这里插入图片描述"><br> 此时返回的数据才是百度真实的页面源码</p> 
<h2><a id="_36"></a>发送带参数的请求</h2> 
<p>当我们使用百度搜索Python的时候，我们看一下他的导航栏会变成什么样子(注意观察，会发现参数与参数之间使用&amp;连接)：<br> <img src="https://images2.imgbox.com/7c/be/Y4GoMeKG_o.png" alt="在这里插入图片描述"><br> 然而在这一堆参数里面，我们尝试着删除那些我们看不懂的参数（这些参数可能是由js生成的），我们留下关键的参数wd=Python，然后我们会发现网页依旧可以搜索到我们想要的数据：<br> <img src="https://images2.imgbox.com/d3/00/bIPQiDrX_o.png" alt="在这里插入图片描述"><br> 因此，发送带参数的请求时，我们注意下列几点：</p> 
<ul><li>参数的形式：字典</li><li>kw = {‘wd’:‘Python’}</li><li>用法：requests.get(url,params = kw)</li><li>注意：url里面不用自己写问号，url写根网址就行</li></ul> 
<p>使用实例：<br> <img src="https://images2.imgbox.com/ea/fa/2o1EKA8y_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_51"></a>课后题目：</h2> 
<h3><a id="responsetextresponsecontentdecode_52"></a>获取新浪首页，查看response.text和response.content.decode()的区别</h3> 
<p>使用response.text时：<br> <img src="https://images2.imgbox.com/23/03/NHVVomMY_o.png" alt="在这里插入图片描述"><br> 使用content时：<br> <img src="https://images2.imgbox.com/8f/26/N9JnSDRX_o.png" alt="在这里插入图片描述"><br> 区别在于解码</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4467db010469f3ea4adf3f4e2a3ebfb5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">JSONObject对象常用方法讲解--fromObject和toBean</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/be6982aea1dd2d5c1575ca3ba4821558/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Golang三种引号详解：单引号、双引号、反引号</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>