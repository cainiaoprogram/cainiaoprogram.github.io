<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>cv mat 灰度值和_深度学习CV实践指南！ - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="cv mat 灰度值和_深度学习CV实践指南！" />
<meta property="og:description" content="Datawhale干货 作者：黄星源、樊亮、陈桦、斯国一
深度学习的发展不仅突破了许多视觉难题，也加速了计算机视觉领域相关技术的进步。本文主要从CV数据处理、CV模型(CNN)、CV模型训练流程以及CV模型集成对计算机视觉的基础知识和基本环节进行了讲解。
CV数据下载 https://tianchi.aliyun.com/competition/entrance/531795/information(阿里天池-零基础入门CV赛事)
CV数据处理 五种数据读取方法 目前较为主流的Python图像库的基本使用方法： 1. matplotlib
matplotlib是Python的绘图库，在科学绘图领域被广泛使用。使用plt.imread()读取图片将其储存为一个RGB像素值矩阵，再进行处理。故其可以与opencv或pillow结合使用，只需要传入像素值矩阵，matplotlib便可以接手处理接下来想要完成的操作。 2. PIL(pillow) PIL即Python Imaging Library，而pillow是PIL的一个分支。pillow提供了常见的图像读取和处理的操作，它比opencv更为轻巧，且可以与ipython notebook无缝集成。使用Image.open()读取图片储存为一个对象，并非是numpy矩阵。
3. OpenCV
OpenCV是一个跨平台的计算机视觉库，是今天介绍的所有图像库中最全面也最强大的库。使用cv2.imread()读取图片将其储存为一个BGR像素值矩阵，故若要结合使用matplotlib则要先进行转化。 4. skimage
skimage包是scikit-image SciKit (toolkit for SciPy) 的简称，它对scipy.ndimage进行了扩展，提供了更多的图片处理功能。skimage包由许多的子模块组成，各个子模块功能不同。使用io.imread()读取图片将其储存为一个RGB像素值矩阵。 5. imageio Imageio是一个Python库，提供了一个简单的接口用于读取和写入各种图像数据，包括动画图像，视频，体积数据和科学格式。使用imageio.imread()读取图片将其储存为一个RGB像素值矩阵。 五种数据扩增技巧
在深度学习模型的训练过程中，数据扩增是必不可少的环节。现有深度学习的参数非常多，一般的模型可训练的参数量基本上都是万到百万级别，而训练集样本的数量很难有这么多，数据扩增可以扩展样本空间。
扩增一般不会改变标签；对于物体检测，数据扩增会改变物体坐标位置；对于图像分割，数数据扩增方法有很多：从颜色空间、尺度空间到样本空间，同时根据不同任务数据扩增都有相应的区别。对于图像分类，数据据扩增会改变像素标签。以torchvision.transforms为例，首先整体了解数据扩增的方法，包括： 1. 裁剪
中心裁剪：transforms.CenterCrop；
随机裁剪：transforms.RandomCrop；
随机长宽比裁剪：transforms.RandomResizedCrop；
上下左右中心裁剪：transforms.FiveCrop；
上下左右中心裁剪后翻转: transforms.TenCrop。
2. 翻转和旋转 依概率p水平翻转：transforms.RandomHorizontalFlip(p=0.5)；
依概率p垂直翻转：transforms.RandomVerticalFlip(p=0.5)；
随机旋转：transforms.RandomRotation。
3. 随机遮挡 对图像进行随机遮挡: transforms.RandomErasing。
4. 图像变换 尺寸变换：transforms.Resize；
标准化：transforms.Normalize；
填充：transforms.Pad；
修改亮度、对比度和饱和度：transforms.ColorJitter；
转灰度图：transforms.Grayscale；
依概率p转为灰度图：transforms.RandomGrayscale；
线性变换：transforms.LinearTransformation()；
仿射变换：transforms.RandomAffine；
将数据转换为PILImage：transforms.ToPILImage；
转为tensor，并归一化至[0-1]：transforms.ToTensor；
用户自定义方法：transforms.Lambda。
5. 对transforms操作，使数据增强更灵活 transforms.RandomChoice(transforms): 从给定的一系列transforms中选一个进行操作；
transforms.RandomApply(transforms, p=0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/00e1044ae07b4e6d2c84407cd9fd26e5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-11-24T03:12:29+08:00" />
<meta property="article:modified_time" content="2020-11-24T03:12:29+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">cv mat 灰度值和_深度学习CV实践指南！</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div class="._5ce-wx-style" style="font-size:16px;"> 
 <div class="rich_media_content" id="js_content"> 
   Datawhale干货  
  <p><strong>作者：黄星源、樊亮、陈桦、斯国一</strong></p> 
  <p>深度学习的发展不仅突破了许多视觉难题，也加速了计算机视觉领域相关技术的进步。本文主要从CV数据处理、CV模型(CNN)、CV模型训练流程以及CV模型集成对计算机视觉的基础知识和基本环节进行了讲解。</p> 
  <h3>CV数据下载</h3> 
  <p>https://tianchi.aliyun.com/competition/entrance/531795/information(阿里天池-零基础入门CV赛事)</p> 
  <h3>CV数据处理</h3> 
  <p><img src="https://images2.imgbox.com/b3/58/smhpEBUj_o.png" alt="41b8f871b9df8484bfe132767cb961a6.png"></p> 
  <strong>五种数据读取方法</strong> 
  目前较为主流的Python图像库的基本使用方法： 
  <p><strong>1. matplotlib</strong></p> 
  matplotlib是Python的绘图库，在科学绘图领域被广泛使用。使用<strong>plt.imread()</strong>读取图片将其储存为一个RGB像素值矩阵，再进行处理。故其可以与opencv或pillow结合使用，只需要传入像素值矩阵，matplotlib便可以接手处理接下来想要完成的操作。 
  <strong>2. PIL(pillow)</strong> 
  <p>PIL即Python Imaging Library，而pillow是PIL的一个分支。pillow提供了常见的图像读取和处理的操作，它比opencv更为轻巧，且可以与ipython notebook无缝集成。使用<strong>Image.open()</strong>读取图片储存为一个对象，并非是numpy矩阵。</p> 
  <p><strong>3. OpenCV</strong></p> 
  OpenCV是一个跨平台的计算机视觉库，是今天介绍的所有图像库中最全面也最强大的库。使用<strong>cv2.imread()</strong>读取图片将其储存为一个BGR像素值矩阵，故若要结合使用matplotlib则要先进行转化。 
  <p><strong>4. skimage</strong></p> 
  skimage包是scikit-image SciKit (toolkit for SciPy) 的简称，它对scipy.ndimage进行了扩展，提供了更多的图片处理功能。skimage包由许多的子模块组成，各个子模块功能不同。使用<strong>io.imread()</strong>读取图片将其储存为一个RGB像素值矩阵。 
  <h5><span style="font-weight:bold;"><strong>5. imageio</strong></span></h5> 
  Imageio是一个Python库，提供了一个简单的接口用于读取和写入各种图像数据，包括动画图像，视频，体积数据和科学格式。使用<strong>imageio.imread()</strong>读取图片将其储存为一个RGB像素值矩阵。 
  <p><strong>五种数据扩增技巧</strong></p> 
  <p>在深度学习模型的训练过程中，数据扩增是必不可少的环节。现有深度学习的参数非常多，一般的模型可训练的参数量基本上都是万到百万级别，而训练集样本的数量很难有这么多，数据扩增可以扩展样本空间。</p> 
  <p><img src="https://images2.imgbox.com/9e/ce/TaPcsHD8_o.png" alt="88cc82787e35d7a8de6e6c79db753222.png"></p> 
  扩增一般不会改变标签；对于物体检测，数据扩增会改变物体坐标位置；对于图像分割，数数据扩增方法有很多：从颜色空间、尺度空间到样本空间，同时根据不同任务数据扩增都有相应的区别。对于图像分类，数据据扩增会改变像素标签。以<strong>torchvision.transforms</strong>为例，首先整体了解数据扩增的方法，包括： 
  <p><strong>1. 裁剪</strong></p> 
  <ul><li><p>中心裁剪：transforms.CenterCrop；</p></li><li><p>随机裁剪：transforms.RandomCrop；</p></li><li><p>随机长宽比裁剪：transforms.RandomResizedCrop；</p></li><li><p>上下左右中心裁剪：transforms.FiveCrop；</p></li><li><p>上下左右中心裁剪后翻转: transforms.TenCrop。</p></li></ul> 
  <strong>2. 翻转和旋转</strong> 
  <ul><li><p>依概率p水平翻转：transforms.RandomHorizontalFlip(p=0.5)；</p></li><li><p>依概率p垂直翻转：transforms.RandomVerticalFlip(p=0.5)；</p></li><li><p>随机旋转：transforms.RandomRotation。</p></li></ul> 
  <strong>3. 随机遮挡</strong> 
  <ul><li><p>对图像进行随机遮挡: transforms.RandomErasing。</p></li></ul> 
  <strong>4. 图像变换</strong> 
  <ul><li><p>尺寸变换：transforms.Resize；</p></li><li><p>标准化：transforms.Normalize；</p></li><li><p>填充：transforms.Pad；</p></li><li><p>修改亮度、对比度和饱和度：transforms.ColorJitter；</p></li><li><p>转灰度图：transforms.Grayscale；</p></li><li><p>依概率p转为灰度图：transforms.RandomGrayscale；</p></li><li><p>线性变换：transforms.LinearTransformation()；</p></li><li><p>仿射变换：transforms.RandomAffine；</p></li><li><p>将数据转换为PILImage：transforms.ToPILImage；</p></li><li><p>转为tensor，并归一化至[0-1]：transforms.ToTensor；</p></li><li><p>用户自定义方法：transforms.Lambda。</p></li></ul> 
  <strong>5. 对transforms操作，使数据增强更灵活</strong> 
  <ul><li><p>transforms.RandomChoice(transforms): 从给定的一系列transforms中选一个进行操作；</p></li><li><p>transforms.RandomApply(transforms, p=0.5): 给一个transform加上概率，依概率进行操作；</p></li><li><p>transforms.RandomOrder: 将transforms中的操作随机打乱。</p></li></ul> 
  <h5><span style="font-weight:bold;"><strong>常用的数据扩增库</strong></span></h5> 
  <p><strong>1. torchvision</strong></p> 
  <p>pytorch官方提供的数据扩增库，提供了基本的数据扩增方法，可以无缝与torch进行集成；但数据扩增方法种类较少，且速度中等；</p> 
  链接：https://github.com/pytorch/vision 
  <p><strong>2. imgaug</strong></p> 
  <p>imgaug是常用的第三方数据扩增库，提供了多样的数据扩增方法，且组合起来非常方便，速度较快；</p> 
  链接：https://github.com/aleju/imgaug 
  <p><strong>3. alb</strong><strong>um</strong><strong>entations</strong></p> 
  <p>是常用的第三方数据扩增库，提供了多样的数据扩增方法，对图像分类、语义分割、物体检测和关键点检测都支持，速度较快。</p> 
  <p>链接：https://albumentations.readthedocs.io</p> 
  <h3>CV模型(CNN)</h3> 
  <p><img src="https://images2.imgbox.com/2f/dd/81UJTjcR_o.png" alt="4918e90d133ed7e8df7486e8b60db314.png"></p> 
  <strong>CNN原理</strong> 
  卷积神经网络(Convolutional Neural Network, CNN)是一类特殊的人工神经网络，是深度学习中重要的一个分支。CNN在很多领域都表现优异，精度和速度比传统计算学习算法高很多。特别是在计算机视觉领域，CNN是解决图像分类、图像检索、物体检测和语义分割的主流模型。 
  CNN每一层由众多的卷积核组成，每个卷积核对输入的像素进行卷积操作，得到下一次的输入。随着网络层的增加卷积核会逐渐扩大感受野，并缩减图像的尺寸。 
  卷积神经网络与普通神经网络非常相似，它们都由具有可学习的权重和偏置常量的神经元组成。每个神经元都接收一些输入，并做一些点积计算，输出是每个分类的分数，普通神经网络里的一些计算技巧到这里依旧适用。 
  两者的不同点在于，卷积神经网络默认输入是图像，可以让我们把特定的性质编码入网络结构，使我们的前馈函数更加有效率，并减少了大量参数。 
  <p><strong>1. 具有三维体积的神经元(3D volumes of neurons)</strong></p> 
  <p>卷积神经网络利用输入图片的特点，把神经元设计成三个维度 ：width, height, depth。比如输入的图片大小是 32 × 32 × 3 (rgb)，那么输入神经元就也具有 32×32×3 的维度。下面是传统神经网络的示意图：</p> 
  <p><img src="https://images2.imgbox.com/cb/65/Ty03iHQI_o.png" alt="380d55b13b7c3b8891e4267b357ddcd5.png"></p> 
  <p>一个卷积神经网络由很多层组成，它们的输入是三维的，输出也是三维的，有的层有参数，有的层不需要参数。卷积神经网络的示意图如下：</p> 
  <p><img src="https://images2.imgbox.com/0c/12/tJf7oIth_o.png" alt="6336d12396ccceee09ba6fd28a28e6d0.png"></p> 
  <p><strong>2. 卷积神经网络结构</strong></p> 
  <strong>2.1 卷积层(Convolutional layer)</strong> 
  <p>卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。</p> 
  <p><img src="https://images2.imgbox.com/df/83/opqD9rTq_o.png" alt="1f989bb9a4947d1b4246ffe30ecbe5f5.png"></p> 
  <p><strong>2.2 池化层(Pooling layer)</strong></p> 
  通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。 
  <p>池化即下采样，目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种：</p> 
  <ul><li><p>最大池化(Max Pooling)。取4个点的最大值。这是最常用的池化方法。</p></li><li><p>均值池化(Mean Pooling)。取4个点的均值。</p></li><li><p>高斯池化。借鉴高斯模糊的方法。不常用。</p></li><li>可训练池化。训练函数 ff ，接受4个点为输入，出入1个点。不常用。</li></ul> 
  最常见的池化层是规模为2*2， 步幅为2，对输入的每个深度切片进行下采样。每个MAX操作对四个数进行，如下图所示： 
  <p><img src="https://images2.imgbox.com/3e/2f/jdfHm1wM_o.png" alt="a3f01ebc8d25b430c54dc7c72026e371.png"></p> 
  池化操作将保存深度大小不变。如果池化层的输入单元大小不是二的整数倍，一般采取边缘补零(zero-padding)的方式补成2的倍数，然后再池化。 
  <p><strong>2.3 非线性激活函数</strong></p> 
  神经的非线性激活化函数，用于增加网络的非线性分割能力，一般用Relu函数。 
  <p><strong>2.4 全连接层( Fully-Connected layer)</strong></p> 
  <p>完全连接层是一个传统的多层感知器，它在输出层使用 softmax 激活函数。把所有局部特征结合变成全局特征，用来计算最后每一类的得分。一个卷积神经网络各层应用实例：</p> 
  <p><img src="https://images2.imgbox.com/4e/3e/zLTh8efx_o.png" alt="e173964614beb89d592361b0eba2684f.png"></p> 
  <strong>CNN常见模型</strong> 
  <strong>1. 卷积神经网络基础：LeNet5</strong> 
  手写字体识别模型LeNet5诞生于1994年，是最早的卷积神经网络之一。LeNet5通过巧妙的设计，利用卷积、参数共享、池化等操作提取特征，避免了大量的计算成本，最后再使用全连接神经网络进行分类识别，这个网络也是最近大量神经网络架构的起点。 
  <p>如下图所示为LeNet网络结构，总共有7层网络(不含输入层)，2个卷积层、2个池化层、3个全连接层。</p> 
  <p><img src="https://images2.imgbox.com/a2/51/z8qLW4kI_o.png" alt="cfee54211ff326576daec2b0cd54f63c.png"></p> 
  <strong>2. 卷积神经网络进阶</strong> 
  <p>随着网络结构的发展，研究人员最初发现网络模型结构越深、网络参数越多模型的精度更优。比较典型的是AlexNet、VGG、InceptionV3和ResNet的发展脉络。   </p> 
  <p><img src="https://images2.imgbox.com/de/65/trUx0StD_o.png" alt="cd21d44c54e32fc2ef78ee8b6e0edd40.png"></p> 
  <h5><span style="font-weight:bold;"><strong>2.1 AlexNet(2012)</strong></span></h5> 
  2012年，AlexNet横空出世。这个模型的名字来源于论文第一作者的姓名Alex Krizhevsky。AlexNet使用了8层卷积神经网络，并以很大的优势赢得了ImageNet 2012图像识别挑战赛。它首次证明了学习到的特征可以超越手工设计的特征，从而一举打破计算机视觉研究的现状。 
  <p>与相对较小的LeNet相比，AlexNet包含8层变换，其中有5层卷积和2层全连接隐藏层，以及1个全连接输出层。AlexNet在LeNet的基础上增加了3个卷积层。但AlexNet作者对它们的卷积窗口、输出通道数和构造顺序均做了大量的调整。虽然AlexNet指明了深度卷积神经网络可以取得出色的结果，但并没有提供简单的规则以指导后来的研究者如何设计新的网络。</p> 
  <p><img src="https://images2.imgbox.com/06/c1/3kjNsCiV_o.png" alt="56867068e4a97649ee8631ab5437c105.png"></p> 
  <h5><span style="font-weight:bold;"><strong>2.2 VGG-16(2014) </strong></span><strong> </strong></h5> 
  <p>VGG，它的名字来源于论文作者所在的实验室Visual Geometry Group。VGG提出了可以通过重复使用简单的基础块来构建深度模型的思路。VGG16相比AlexNet的一个改进是采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核(11x11，7x7，5x5) 。VGG16包含了16个隐藏层(13个卷积层和3个全连接层)。<strong>VGG的结构图如下：</strong></p> 
  <p><img src="https://images2.imgbox.com/33/a8/uUj1NJvD_o.png" alt="bb6e0f2f12fd90bd7f74405ca35866c3.png"></p> 
  <h5><span style="font-weight:bold;"><strong>2.3 网络中的网络(NiN)</strong></span></h5> 
  <h5><span style="font-weight:bold;">LeNet、AlexNet和VGG：先以由卷积层构成的模块充分抽取空间特征，再以由全连接层构成的模块来输出分类结果。NiN：串联多个由卷积层和“全连接”层构成的小⽹络来构建⼀个深层⽹络。 ⽤了输出通道数等于标签类别数的NiN块，然后使⽤全局平均池化层对每个通道中所有元素求平均并直接用于分类。 </span></h5> 
  <h5><span style="font-weight:bold;"><img src="https://images2.imgbox.com/da/84/pNhrgj8s_o.png" alt="211196f87cbb466373e55f748d16c4e1.png"></span></h5> 
  <h5><span style="font-weight:bold;"><strong>2.4 含并行连结的网络(GoogLeNet)</strong></span></h5> 
  <p>在2014年的ImageNet图像识别挑战赛中，一个名叫GoogLeNet的网络结构大放异彩。它虽然在名字上向LeNet致敬，但在网络结构上已经很难看到LeNet的影子。GoogLeNet吸收了NiN中网络串联网络的思想，并在此基础上做了很大改进。在随后的几年里，研究人员对GoogLeNet进行了数次改进，本节将介绍这个模型系列的第一个版本。</p> 
  <ul><li><p>由Inception基础块组成。 </p></li><li><p>Inception块相当于⼀个有4条线路的⼦⽹络。它通过不同窗口形状的卷积层和最⼤池化层来并⾏抽取信息，并使⽤1×1卷积层减少通道数从而降低模型复杂度。 </p></li><li>可以⾃定义的超参数是每个层的输出通道数，我们以此来控制模型复杂度。 </li></ul> 
  Inception块GoogLeNet中的基础卷积块叫作Inception块，得名于同名电影《盗梦空间》(Inception)。与上一节的NiN块相比，这个基础块在结构上更加复杂。 
   
  <img src="https://images2.imgbox.com/80/45/JqfRS9aT_o.png" alt="d2e8bd8da6d145fef8845483f821a32c.png"> 
  <h5><span style="font-weight:bold;"><strong>2.5 残差网络(ResNet-50)  </strong></span><strong>    </strong></h5> 
  <p>深度学习的问题：深度CNN网络达到一定深度后再一味地增加层数并不能带来进一步地分类性能提高，反而会招致网络收敛变得更慢，准确率也变得更差。- - -残差块(Residual Block)恒等映射：</p> 
  <ul><li><p>左边：f(x)=x；</p></li><li><p>右边：f(x)-x=0 (易于捕捉恒等映射的细微波动)。</p></li></ul> 
  <img src="https://images2.imgbox.com/3a/f6/tIhYcgf3_o.png" alt="7f1c040b4f8556a4e878fcfc0ccc4fcb.png"> 
  <p>ResNet的前两层跟之前介绍的GoogLeNet中的一样：在输出通道数为64、步幅为2的7*7卷积层后接步幅为2的3*3的最大池化层。不同之处在于ResNet每个卷积层后增加的批量归一化层。ResNet-50网络结构如下：</p> 
  <p><img src="https://images2.imgbox.com/b7/a6/bpfhvVX6_o.png" alt="ba18350df6f668ea560e9f8e749457fe.png"></p> 
  <h3>CV模型训练流程</h3> 
  <p><img src="https://images2.imgbox.com/04/c3/J7QlUYRc_o.png" alt="148714a2025fd028102c371b4e00a36f.png"></p> 
  <p>在机器学习模型(特别是深度学习模型)的训练过程中，模型是非常容易过拟合的。深度学习模型在不断的训练过程中训练误差会逐渐降低，但测试误差的走势则不一定。</p> 
  <p>在模型的训练过程中，模型只能利用训练数据来进行训练，并不能接触到测试集上的样本，故需要构建验证数据集对模型进行验证。</p> 
  <strong>过拟合与欠拟合</strong> 
  <p><img src="https://images2.imgbox.com/20/5b/hbxiYfyP_o.png" alt="d6af96ca9dd7e2f2f8e5ca73e49efd92.png"></p> 
  <p><strong>拟合(Fitting)</strong>：就是说这个曲线能不能很好的描述某些样本，并且有比较好的泛化能力。</p> 
  <p><strong>过拟合(Overfitting)</strong>：模型把数据学习的太彻底，以至于把噪声数据的特征也学习到了，这样就会导致在后期测试的时候不能够很好地识别数据，即不能正确的分类，模型泛化能力太差。</p> 
  <p><strong>欠拟合(UnderFitting)</strong>：模型没有很好地捕捉到数据特征，不能够很好地拟合数据，或者是模型过于简单无法拟合或区分样本。</p> 
  <img src="https://images2.imgbox.com/2c/7f/YQvQPgAB_o.png" alt="ccc61b05122e120fec91464a7417ccdc.png"> 
  <p><img src="https://images2.imgbox.com/63/dd/VSIF4qsU_o.png" alt="14b11ee2c478a09f4401e15715787160.png"></p> 
  <strong>防止过拟合方法</strong> 
  <ol><li><strong>正则化方法</strong>。正则化方法包括L0正则、L1正则和L2正则，而正则一般是在目标函数之后加上对于的范数。但是在机器学习中一般使用L2正则。</li><li><strong>数据增强</strong>(Data augmentation)，增大数据的训练量，还有一个原因就是我们用于训练的数据量太小导致的，训练数据占总数据的比例过小。</li><li><strong>重新清洗数据</strong>，导致过拟合的一个原因也有可能是数据不纯导致的，如果出现了过拟合就需要我们重新清洗数据。</li><li><strong>提前终止法</strong>(Early stopping)，对模型进行训练的过程即是对模型的参数进行学习更新的过程，这个参数学习的过程往往会用到一些迭代方法，如梯度下降(Gradient descent)学习算法。提前终止法便是一种迭代次数截断的方法来防止过拟合的方法，即在模型对训练数据集迭代收敛之前停止迭代来防止过拟合。</li><li><strong>丢弃法</strong>(Dropout)。这个方法在神经网络里面很常用。丢弃法是ImageNet中提出的一种方法，通俗一点讲就是丢弃法在训练的时候让神经元以一定的概率不工作。具体看下图：</li></ol> 
  <center> 
   <p><img src="https://images2.imgbox.com/f5/4c/kQNOogXa_o.png" alt="30ad9476f9593decfab9661b87c54f64.png"></p> 
  </center> 
  <center> 
   左侧为全连接网络，右侧的网络以 0.5 的概率丢弃神经元。输出层并没有应用 Dropout 
  </center> 
  <p><strong>防止欠拟合方法</strong></p> 
  <ol><li><strong>添加其他特征项</strong>，有时候我们模型出现欠拟合的时候是因为特征项不够导致的，可以添加其他特征项来很好地解决。例如，“组合”、“泛化”、“相关性”三类特征是特征添加的重要手段，无论在什么场景，都可以照葫芦画瓢，总会得到意想不到的效果。除上面的特征之外，“上下文特征”、“平台特征”等等，都可以作为特征添加的首选项。</li><li><strong>添加多项式特征</strong>，这个在机器学习算法里面用的很普遍，例如将线性模型通过添加二次项或者三次项使模型泛化能力更强。例如上面的图片的例子。</li><li><p><strong>减少正则化参数</strong>，正则化的目的是用来防止过拟合的，但是现在模型出现了欠拟合，则需要减少正则化参数。</p></li></ol> 
  <p><strong>数据集划分</strong></p> 
  <ul><li>训练集(Train Set)：模型用于训练和调整模型参数。</li><li>验证集(Validation Set)：用来验证模型精度和调整模型超参数。</li><li><p>测试集(Test Set)：验证模型的泛化能力。</p></li></ul> 
  因为训练集和验证集是分开的，所以模型在验证集上面的精度在一定程度上可以反映模型的泛化能力。在划分验证集的时候，需要注意验证集的分布应该与测试集尽量保持一致，不然模型在验证集上的精度就失去了指导意义。 
  <p>既然验证集这么重要，那么如何划分本地验证集呢。在一些比赛中，赛题方会给定验证集；如果赛题方没有给定验证集，那么参赛选手就需要从训练集中拆分一部分得到验证集。验证集的划分有如下几种方式：</p> 
  <p><img src="https://images2.imgbox.com/0c/25/pVnfbkl3_o.png" alt="e42cceef47eef1aadd9d350639b8b20a.png"></p> 
  <ul><li><p>留出法(Hold-Out) 直接将训练集划分成两部分，新的训练集和验证集。这种划分方式的优点是最为直接简单；缺点是只得到了一份验证集，有可能导致模型在验证集上过拟合。留出法应用场景是数据量比较大的情况。</p></li><li><p>交叉验证法(Cross Validation，CV) 将训练集划分成K份，将其中的K-1份作为训练集，剩余的1份作为验证集，循环K训练。这种划分方式是所有的训练集都是验证集，最终模型验证精度是K份平均得到。这种方式的优点是验证集精度比较可靠，训练K次可以得到K个有多样性差异的模型；CV验证的缺点是需要训练K次，不适合数据量很大的情况。</p></li><li>自助采样法(BootStrap) 通过有放回的采样方式得到新的训练集和验证集，每次的训练集和验证集都是有区别的。这种划分方式一般适用于数据量较小的情况。</li></ul> 
  <p>这些划分方法是从数据划分方式的角度来讲的，在现有的数据比赛中一般采用留出法和交叉验证法。如果数据量比较大，留出法还是比较合适的。</p> 
  <p><strong>训练神经网络的流程</strong></p> 
  <p><strong>1. 好好检查数据</strong></p> 
  <p>训练神经网络的第一步是完全不接触任何神经网络代码，而是从彻底检查数据开始。此步骤至关重要。花时间去检查数据是一件比较重要的工作。因为数据中往往可能存在异常值，而且了解它们的分布可以有利于我们找到一个更好的模型。</p> 
  <strong>2. 评估框架并得到一个并不完美的baseline</strong> 
  <p>此阶段的提示和技巧：</p> 
  <ul><li><p>固定随机种子：始终使用固定的随机种子来确保两次运行代码时您将获得相同的结果；</p></li><li><p>简化：在此阶段，请务必关闭任何数据扩充功能。数据扩充是我们稍后可能会采用的一种正则化策略，但是目前这只是引入一种错误的尝试；</p></li><li><p>验证损失：验证您的损失是否从正确的损失值开始；</p></li><li><p>设定一个好的初始化；</p></li><li><p>人类基线：监控除损失之外的指标，这些指标是人类可以解释和检查的(例如准确性)。尽可能评估自己(人类)的准确性并与之进行比较；</p></li><li><p>可视化预测动态。在训练过程中可视化固定测试批次上的模型预测。这些预测如何运动的“动力”将对训练的进行方式有非常好的直觉。如果网络以某种方式过度摆动，可能会感觉网络“努力”以适应您的数据，这表明不稳定。抖动量也很容易注意到非常低或非常高的学习率。</p></li></ul> 
  <strong>3. 过度拟合</strong> 
  <p>找到一个好的模型的方法有两个阶段：首先获得一个足够大的模型以使其可以过度拟合(即专注于训练损失)，然后适当地对其进行正则化(放弃一些训练损失以提高验证损失)。</p> 
  <p>此阶段的一些提示和技巧：</p> 
  <ul><li><p>选择模型：为了减少训练损失，您需要为数据选择合适的体系结构。</p></li><li><p>Adam是安全的。在设定基准的早期阶段，我喜欢以3e-4的学习率使用Adam 。以我的经验，亚当更宽容超参数，包括不良的学习速度。对于ConvNets，调整良好的SGD几乎总是比Adam稍胜一筹，但是最佳学习率区域要狭窄得多且针对特定问题。</p></li><li><p>一次只使一个复杂化。如果您有多个信号要插入您的分类器，我建议您将它们一个接一个地插入，并每次确保获得预期的性能提升。</p></li><li><p>不要相信学习率衰减的默认值。如果您要重新使用其他领域的代码，请务必小心学习率。</p></li></ul> 
  <strong>4. 正则化</strong> 
  <p>此阶段的一些提示和技巧：</p> 
  <ul><li><p>获取更多数据</p></li><li><p>数据扩充</p></li><li><p>创意增强：如果半假数据没有做到这一点，伪造数据也可能会有所作为。人们正在寻找扩展数据集的创新方法。例如，领域随机化，模拟的使用，巧妙的混合，例如将(潜在模拟的)数据插入场景，甚至GAN。</p></li><li><p>使用预训练网络</p></li><li><p>坚持监督学习</p></li><li><p>减小输入维数</p></li><li><p>减小模型尺寸</p></li><li><p>减小批量大小</p></li><li><p>Dropout</p></li><li><p>提早停止训练。根据您测得的验证损失提前停止训练，以在模型快要过拟合的时候捕获模型。</p></li><li><p>尝试更大的模型。大型模型大多数最终会过拟合，但是它们的“早期停止”性能通常会比小型模型好得多。</p></li></ul> 
  <p><strong>5. 微调</strong></p> 
  <p>此阶段的一些提示和技巧：</p> 
  <ul><li><p>随机网格搜索</p></li><li><p>超参数优化</p></li></ul> 
  <strong>6. 进一步提高精确率</strong> 
  <ul><li><p>模型集成</p></li></ul> 
  <h3>CV模型集成</h3> 
  <p><img src="https://images2.imgbox.com/4f/90/TexOeYWw_o.png" alt="7faab61959c960c5f7b154e9f65c447a.png"></p> 
  <strong>分类器(Classifier)</strong> 
  <p>分类器是数据挖掘中对样本进行分类的方法的统称，包含决策树、逻辑回归、朴素贝叶斯、神经网络等算法。</p> 
  分类器的构造和实施大体会经过以下几个步骤： 
  <ul><li>选定样本(包含正样本和负样本)，将所有样本分成训练样本和测试样本两部分。</li><li>在训练样本上执行分类器算法，生成分类模型。</li><li>在测试样本上执行分类模型，生成预测结果。</li><li>根据预测结果，计算必要的评估指标，评估分类模型的性能。</li></ul> 
  <strong>1. 决策树分类器</strong> 
  <p>构造这个分类器不需要任何领域的知识，也不需要任何的参数设置。因此它特别适合于探测式的知识发现。此外，这个分类器还可以处理高维数据，而且采用的是类似于树这种形式，也特别直观和便于理解。因此，决策树是许多商业规则归纳系统的基础。</p> 
  <p><strong>2. 朴素贝叶斯分类器</strong></p> 
  <p>素贝叶斯分类器是假设数据样本特征完全独立，以贝叶斯定理为基础的简单概率分类器。</p> 
  <p><strong>3. AdaBoost算法</strong></p> 
  <p>AdaBoost算法的自适应在于前一个分类器产生的错误分类样本会被用来训练下一个分类器，从而提升分类准确率，但是对于噪声样本和异常样本比较敏感。</p> 
  <p><strong>4. 支持向量机</strong></p> 
  <p>支持向量机是用过构建一个或者多个高维的超平面来将样本数据进行划分，超平面即为样本之间的分类边界。</p> 
  <p><strong>5. K近邻算法</strong></p> 
  <p>基于k近邻的K个样本作为分析从而简化计算提升效率，K近邻算法分类器是基于距离计算的分类器。</p> 
  <strong>集成学习方法</strong> 
  <p>集成学习有许多集成模型，例如自助法、自助聚合(Bagging)、随机森林、提升法(Boosting)、 堆叠法(stacking) 以及许多其它的基础集成学习模型。</p> 
  集成方法的思想是通过将这些个体学习器(个体学习器称为“基学习器”，基学习器也被称为弱学习器。)的偏置和/或方差结合起来，从而创建一个 强学习器(或 集成模型)，从而获得更好的性能。 
  <p>我们可以用三种主要的旨在组合弱学习器的元算法：</p> 
  <ul><li><p>自助聚合(Bagging)，该方法通常考虑的是同质弱学习器，相互独立地并行学习这些弱学习器，并按照某种确定性的平均过程将它们组合起来。</p></li></ul> 
  <p><img src="https://images2.imgbox.com/07/ee/expgxTZ4_o.png" alt="bf7404225c15c993dcf6c98406a3b940.png"></p> 
  <ul><li><p>提升法(Boosting)，该方法通常考虑的也是同质弱学习器。它以一种高度自适应的方法顺序地学习这些弱学习器(每个基础模型都依赖于前面的模型)，并按照某种确定性的策略将它们组合起来。</p></li></ul> 
  <p><img src="https://images2.imgbox.com/2a/07/CIC4pKOZ_o.png" alt="7d586d4b4731c5bb0b535905b590b965.png"></p> 
  <ul><li><p>堆叠法(Stacking)，该方法通常考虑的是异质弱学习器，并行地学习它们，并通过训练一个 元模型 将它们组合起来，根据不同弱模型的预测结果输出一个最终的预测结果。</p></li></ul> 
  <p><img src="https://images2.imgbox.com/07/21/eSXLcusp_o.png" alt="714845a7fe1c3e524141c385bb8e90be.png"></p> 
  <p>非常粗略地说，我们可以说Bagging的重点在于获得一个方差比其组成部分更小的集成模型，而Boosting和Stacking则将主要生成偏置比其组成部分更低的强模型(即使方差也可以被减小)。</p> 
  <p><strong>十折交叉验证</strong></p> 
  由于深度学习模型一般需要较长的训练周期，如果硬件设备不允许建议选取留出法，如果需要追求精度可以使用交叉验证的方法。 
  十折交叉验证用来测试算法准确性。将数据集分成十份，轮流将其中九份作为训练数据，一份作为测试数据，进行试验。每次试验都会得出相应的正确率(或差错率)。十次的结果的正确率(或差错率)的平均值作为对算法精度的估计，一般还需要进行多次十折交叉验证(例如十次十折交叉验证)，再求其均值，作为对算法准确性的估计。 
  下面假设构建了十折交叉验证，训练得到十个CNN模型。 
  <p><img src="https://images2.imgbox.com/0e/46/eqg3rKgW_o.png" alt="aa883dbb312d38398f09be633f118c4d.png"></p> 
  <p>那么在十个CNN模型可以使用如下方式进行集成：</p> 
  <ul><li><p>对预测的结果的概率值进行平均，然后解码为具体字符</p></li><li><p>对预测的字符进行投票，得到最终字符</p></li></ul> 
  <h3><span style="font-weight:bold;"><strong>深度学习中的集成学习</strong></span></h3> 
  在深度学习中本身还有一些集成学习思路的做法，值得借鉴学习： 
  <ul><li><p>丢弃法Dropout</p></li><li>测试集数据扩增TTA</li><li><p>Snapshot</p></li></ul> 
  <h3>延伸阅读</h3> 
  <pre><code></code></pre> 
  <p><code>【1】数据读取：</code></p> 
  <code></code> 
  <p><code>https://mp.weixin.qq.com/s/IOlHIEIQhuIaubTeP4o39</code></p> 
  <code></code> 
  <p><code>【2】CNN模型：</code></p> 
  <code></code> 
  <p><code>https://mp.weixin.qq.com/s/JhFun5I_8Kjkbz6S4613Xw</code></p> 
  <code></code> 
  <p><code>【3】模型训练：</code></p> 
  <code></code> 
  <p><code>https://mp.weixin.qq.com/s/ZwfrIkHQMsHl_16xvCSejQ</code></p> 
  <code></code> 
  <p><code>【4】模型集成：</code></p> 
  <code></code> 
  <p><code>https://mp.weixin.qq.com/s/I41c-i-6y-pPdZOeiMM_0Q</code></p> 
  <code></code> 
  <p><code>【5】理论实践：</code></p> 
  <code></code> 
  <p><em>本文电子版教程 后台回复 <strong>cv实践指南 </strong>下载</em></p> 
  <p><img src="https://images2.imgbox.com/6d/b0/Se04DJMr_o.png" alt="6cf2cdac7d72b2e075c4c23ea20f99d3.png"></p> 
  <p>“在看，为学习到这<strong>点赞</strong>↓</p> 
 </div> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5e020c6d158db6743bb8416ce90eb65d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">距离矢量路由算法_动态路由的相关知识</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e91704e3aa5c6b63924afb33d75596a9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">手把手教你学Python之常见运算符</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>