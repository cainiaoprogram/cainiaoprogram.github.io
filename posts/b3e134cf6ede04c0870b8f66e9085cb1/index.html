<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Gstreamer基础讲解 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Gstreamer基础讲解" />
<meta property="og:description" content="Gstreamer讲解 文章目录 Gstreamer讲解基础背景小结 元件（Element）衬垫(Pads)Gstreamer的面向对象Gstreamer的多线程 实用工具Gstreamer常用插件介绍gstreamer工程记录关于YUV的补充知识 基础 背景 ​ 从历史的角度来看，Linux在多媒体方面已经远远落后于其他的操作系统。Microsoft’s Windows 和Apple’s MacOS它们对多媒体设备、多媒体创作、播放和实时处理等方面已经有了很好的支持。另一方面，Linux对多媒体应用的综合贡献比较少，这也使得Linux很难在专业级别的软件上与MS Windows和MacOS去竞争。GStreamer正是为解决Linux多媒体方面当前问题而设计的。
​ GStreamer 是一个非常强大而且通用的流媒体应用程序框架。GStreamer并不受限于音频和视频处理, 它能够处理任意类型的数据流。主要的优点在于: 它的可插入组件能够很方便的接入到任意的流水线（pipeline）当中。这个优点使得利用GStreamer编写一个万能的可编辑音视频应用程序成为可能。
​ GStreamer框架是基于插件的。所有的插件都能够被链接到任意的已经定义了的数据流水线中。
官方网站：https://gstreamer.freedesktop.org/
小结 Gstreamer的优点
1.结构清晰且威力强大
GStreamer提供一套清晰的接口，无论是构建媒体管道的应用程序员还是插件程序员，均可以方便的使用这些API。
2.面向对象的编程思想
GStreamer是依附于GLib 2.0对象模型的，采用了信号与对象属性的机制。
3.灵活的可扩展性能
所有的GStreamer对象都可以采用GObject继承的方法进行扩展
所有的插件都可以被动态装载，可以独立的扩展或升级。
4.核心库与插件(core/plugins)分离
所有的媒体处理功能都是由插件从外部提供给内核的，并告诉内核如何去处理特定的媒体类型。
元件（Element） ​ 元件(Element)是GStreamer中最重要的概念。
​ 可以通过创建一系列的元件，并把它们连接起来,从而让数据流在这个被连接的各个元件之间传输。
​ 可以将若干个元件连接在一起,从而创建一个流水线(pipeline)来完成一个特殊的任务,例如,媒体播放或者录音。
​ 对程序员来说， GStreamer中最重要的一个概念就是GstElement对象。元件是构建一个媒体流水线的基本块。每一个元件都对应一个GstElement。任何一个解码器编码器、分离器、视频/音频输出部件实际上都是一个GstElement对象。
​ 下图为一个流水线的实例，实现 文件-&gt;音视频解码-&gt;分别播放 的功能
源元件（source element）
​ 源元件为管道产生数据，比如从磁盘或者声卡读取数据。下图是形象化的源元件，我们总是将**源衬垫(source pad)**画在元件的右端。
​ 源元件不接收数据，仅产生数据。你可从上图中明白这一点，因为上图仅有一个源衬垫（右端 ）。
过滤/类过滤元件（filter/filter-like element）
​ 过滤器(Filters)以及类过滤元件(Filter-like elements)都同时拥有输入和输出衬垫。他们对从输入衬垫得到的数据进行操作，然后将数据提供给输出衬垫。音量元件(filter) 、视频转换器(convertor) 、Ogg分流器或者Vorbis解码器都是这种类型的元件。
​ 类过滤元件可以拥有任意个的源衬垫或者接收衬垫。像解码器只有一个源衬垫及一个接收衬垫。而视频分流器可能有一个接收衬垫以及多个源衬垫，每个接收衬垫对应一种元数据流。
接收元件（sink element）
​ 接收元件是媒体管道的末端，它接收数据但不产生任何数据。写磁盘、利用声卡播放声音以及视频输出等都是由接收元件实现的。下图显示了接收元件。
将元件链接(link)起来" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b3e134cf6ede04c0870b8f66e9085cb1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-20T12:30:26+08:00" />
<meta property="article:modified_time" content="2022-09-20T12:30:26+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Gstreamer基础讲解</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Gstreamer_0"></a>Gstreamer讲解</h2> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#Gstreamer_0" rel="nofollow">Gstreamer讲解</a></li><li><ul><li><a href="#_2" rel="nofollow">基础</a></li><li><ul><li><a href="#_4" rel="nofollow">背景</a></li><li><ul><li><a href="#_14" rel="nofollow">小结</a></li></ul> 
    </li><li><a href="#Element_28" rel="nofollow">元件（Element）</a></li><li><a href="#Pads_70" rel="nofollow">衬垫(Pads)</a></li><li><a href="#Gstreamer_120" rel="nofollow">Gstreamer的面向对象</a></li><li><a href="#Gstreamer_153" rel="nofollow">Gstreamer的多线程</a></li></ul> 
   </li><li><a href="#_162" rel="nofollow">实用工具</a></li><li><a href="#Gstreamer_189" rel="nofollow">Gstreamer常用插件介绍</a></li><li><a href="#gstreamer_309" rel="nofollow">gstreamer工程记录</a></li><li><ul><li><ul><li><ul><li><a href="#YUV_502" rel="nofollow">关于YUV的补充知识</a></li></ul> 
    </li></ul> 
   </li></ul> 
  </li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="_2"></a>基础</h3> 
<h4><a id="_4"></a>背景</h4> 
<p>​ 从历史的角度来看，Linux在多媒体方面已经远远落后于其他的操作系统。Microsoft’s Windows 和Apple’s MacOS它们对多媒体设备、多媒体创作、播放和实时处理等方面已经有了很好的支持。另一方面，Linux对多媒体应用的综合贡献比较少，这也使得Linux很难在专业级别的软件上与MS Windows和MacOS去竞争。<strong>GStreamer正是为解决Linux多媒体方面当前问题而设计的</strong>。</p> 
<p>​ GStreamer 是一个非常强大而且<strong>通用</strong>的<strong>流媒体</strong>应用程序框架。GStreamer并不受限于音频和视频处理, 它能够处理任意类型的数据流。主要的优点在于: 它的可插入组件能够很方便的接入到任意的流水线（pipeline）当中。这个优点使得利用GStreamer编写一个万能的可编辑音视频应用程序成为可能。</p> 
<p>​ <strong>GStreamer框架是基于插件的</strong>。所有的插件都能够被链接到任意的已经定义了的数据流水线中。</p> 
<p>官方网站：https://gstreamer.freedesktop.org/</p> 
<h5><a id="_14"></a>小结</h5> 
<p>Gstreamer的优点<br> 1.结构清晰且威力强大<br> GStreamer提供一套清晰的接口，无论是构建媒体管道的应用程序员还是插件程序员，均可以方便的使用这些API。<br> 2.<strong>面向对象</strong>的编程思想<br> GStreamer是依附于GLib 2.0对象模型的，采用了信号与对象属性的机制。<br> 3.灵活的可扩展性能<br> 所有的GStreamer对象都可以采用GObject继承的方法进行扩展<br> 所有的插件都可以被动态装载，可以独立的扩展或升级。<br> 4.核心库与插件(core/plugins)分离<br> 所有的媒体处理功能都是由插件从外部提供给内核的，并告诉内核如何去处理特定的媒体类型。</p> 
<p><img src="https://images2.imgbox.com/8c/49/BazkfgkN_o.png" alt="image-20220114212052396"></p> 
<h4><a id="Element_28"></a>元件（Element）</h4> 
<p>​ 元件(Element)是GStreamer中最重要的概念。</p> 
<p>​ 可以通过创建一系列的元件，并把它们连接起来,从而让数据流在这个被连接的各个元件之间传输。</p> 
<p>​ 可以将若干个元件连接在一起,从而创建一个流水线(pipeline)来完成一个特殊的任务,例如,媒体播放或者录音。</p> 
<p>​ 对程序员来说， GStreamer中最重要的一个概念就是GstElement对象。元件是构建一个媒体流水线的基本块。每一个元件都对应一个GstElement。任何一个解码器编码器、分离器、视频/音频输出部件实际上都是一个GstElement对象。</p> 
<p>​ 下图为一个流水线的实例，实现 文件-&gt;音视频解码-&gt;分别播放 的功能</p> 
<p><img src="https://images2.imgbox.com/9e/ce/j70EWYRe_o.png" alt="image-20220114215215203"></p> 
<p><strong>源元件（source element）</strong></p> 
<p>​ 源元件为管道产生数据，比如从磁盘或者声卡读取数据。下图是形象化的源元件，我们总是将**源衬垫(source pad)**画在元件的右端。</p> 
<p><img src="https://images2.imgbox.com/34/71/dPNbuy7n_o.png" alt="image-20220114220749263"></p> 
<p>​ 源元件不接收数据，仅产生数据。你可从上图中明白这一点，因为上图仅有一个源衬垫（右端 ）。</p> 
<p><strong>过滤/类过滤元件（filter/filter-like element）</strong></p> 
<p>​ 过滤器(Filters)以及类过滤元件(Filter-like elements)都同时拥有输入和输出衬垫。他们对从输入衬垫得到的数据进行操作，然后将数据提供给输出衬垫。音量元件(filter) 、视频转换器(convertor) 、Ogg分流器或者Vorbis解码器都是这种类型的元件。</p> 
<p>​ 类过滤元件可以拥有任意个的源衬垫或者接收衬垫。像解码器只有一个源衬垫及一个接收衬垫。而视频分流器可能有一个接收衬垫以及多个源衬垫，每个接收衬垫对应一种元数据流。</p> 
<p><img src="https://images2.imgbox.com/6c/64/fERkCoWb_o.png" alt="image-20220114224254934"></p> 
<p><strong>接收元件（sink element）</strong></p> 
<p>​ 接收元件是媒体管道的末端，它接收数据但不产生任何数据。写磁盘、利用声卡播放声音以及视频输出等都是由接收元件实现的。下图显示了接收元件。</p> 
<p><img src="https://images2.imgbox.com/10/1e/XKuLVGkV_o.png" alt="image-20220114225023291"></p> 
<p><strong>将元件链接(link)起来</strong></p> 
<p>​ 通过将一个源元件，零个或多个类过滤元件，和一个接收元件链接在一起，你可以建立起一条媒体管道。数据将在这些元件间流过。这是 GStreamer中处理媒体的基本概念。</p> 
<p><img src="https://images2.imgbox.com/31/e6/ClD2Bp2j_o.png" alt="image-20220114225536564"></p> 
<h4><a id="Pads_70"></a>衬垫(Pads)</h4> 
<p>​ 衬垫(Pads)在GStreamer中被用于多个元件的链接,从而让数据流能在这样的链接中流动。衬垫是元件对外的接口，可以被看作是一个元件的插座或者端口,元件之间的链接就是依靠着衬垫。数据流从一个元件的源衬垫(source pad)到另一个元件的接收衬垫(sink pad)。衬垫的功能(capabilities)决定了一个元件所能处理的媒体类型。</p> 
<p>​ 衬垫有处理特殊数据的能力:一个衬垫能够限制数据流类型的通过。链接成功的条件是：只有在两个衬垫允许通过的数据类型一致的时候才被建立。这个被称为协商（negotiation）</p> 
<p>pad的信息，通过gst-inspect-1.0即可查看</p> 
<pre><code>Pad Templates:
  SINK template: 'sink'                    ------&gt;sink pad：数据流入
    Availability: Always                   ------&gt;pad时效性：永久型
    Capabilities:                          ------&gt;pad支持的caps
      video/quicktime
      video/mj2
      audio/x-m4a
      application/x-3gp

  SRC template: 'video_%u'                 ------&gt;src pad：数据流出
    Availability: Sometimes                ------&gt;pad时效性：随机型
    Capabilities:
      ANY

  SRC template: 'audio_%u'
    Availability: Sometimes
    Capabilities:
      ANY

  SRC template: 'subtitle_%u'
    Availability: Sometimes
    Capabilities:
      ANY

</code></pre> 
<p>从上面可以看到，每个pad，都会有以下属性：padname、direction、presence、caps。</p> 
<ul><li> <p>padname：pad名称</p> </li><li> <p>direction：pad的输入输出方向，有src和sink两种</p> </li><li> <p>presence：pad的时效性，有永久型GST_PAD_ALWAYS、随机型GST_PAD_SOMETIMES、请求型GST_PAD_REQUEST，请求型的仅在<code>gst_element_request_pad()</code>调用，随机型的则是会根据不同的输入数据使用不同的pad。三种时效性的意义顾名思义: 永久型的衬垫一直会存在，随机型的衬垫只在某种特定的条件下才存在(会随机消失的衬垫也属于随机型)，请求型的衬垫只在应用程序明确发出请求时才出现。</p> </li><li> <p>caps：pad支持的功能</p> </li></ul> 
<p>参考资料：<br> https://blog.csdn.net/houxiaoni01/article/details/98509594</p> 
<h4><a id="Gstreamer_120"></a>Gstreamer的面向对象</h4> 
<p>​ Gstreamer使用C语言来模拟面向对象的实现，主要基于glib库里面的GObject库的数据类型来实现，GObject是一个程序库，它可以帮助我们使用C语言编写面向对象的程序。</p> 
<p>​ 很多人被灌输了这样一种概念：要写面向对象程序，那么就需要学习一种面向对象编程语言，例如C++、Java、C# 等等，而 C 语言是用来编写结构化程序的。事实上，面向对象只是一种编程思想，不是一种编程语言。换句话说，面向对象是一种游戏规则，它不是游戏。GObject 告诉我们，使用 C 语言编写程序时，可以运用面向对象这种编程思想。</p> 
<p>​ 在 GObject 世界里，<strong>类</strong>是两个结构体的组合，一个是<strong>实例结构体</strong>，另一个是<strong>类结构体</strong>。例如， MyObject 是实例结构体，MyObjectClass 是类结构体，它们合起来便可以称为 MyObject<strong>类。</strong></p> 
<pre><code class="prism language-c"><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;glib-object.h&gt;</span></span>

<span class="token comment">//实例结构体</span>
<span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">_MyObject</span><span class="token punctuation">{<!-- --></span>
        GObject parent_instance<span class="token punctuation">;</span>
<span class="token punctuation">}</span> MyObject<span class="token punctuation">;</span>
<span class="token comment">//类结构体</span>
<span class="token keyword">typedef</span> <span class="token keyword">struct</span> <span class="token class-name">_MyObjectClass</span> <span class="token punctuation">{<!-- --></span>
        GObjectClass parent_class<span class="token punctuation">;</span>
<span class="token punctuation">}</span> MyObjectClass<span class="token punctuation">;</span>

<span class="token comment">//让GObjectx系统知道你定义了这个类</span>
<span class="token function">G_DEFINE_TYPE</span><span class="token punctuation">(</span>MyObject<span class="token punctuation">,</span> my_object<span class="token punctuation">,</span> G_TYPE_OBJECT<span class="token punctuation">)</span><span class="token punctuation">;</span>

</code></pre> 
<p>​ 在GObject中一个对象的产生遵循如下原则:</p> 
<p>​ 如果产生的是该类的第一个实例，那么先分配Class结构体，再分配针对该实例的结构体。否则直接分配针对该实例的结构。也就是说在Class结构体中所有的内容，是通过该类生成的实例所公有的。而实例化每个对象时，为其单独分配专门的实例用结构体。</p> 
<p>​ 也许你会注意到，MyObject<strong>类</strong>的<strong>实例结构体</strong>的第一个成员是 GObject 结构体，MyObject<strong>类</strong>的<strong>类结构体</strong>的第一个成员是 GObjectClass 结构体。其实，GObject 结构体与 GObjectClass 结构体分别是 <strong>GObject类</strong>的<strong>实例结构体</strong>与<strong>类结构体</strong>，当它们分别作为 MyObject<strong>类</strong>的<strong>实例结构体</strong>与<strong>类结构体</strong>的<strong>第一个成员</strong>时，这意味着 MyObject<strong>类</strong>继承自 <strong>GObject类</strong>。</p> 
<p>​ 每个类必须定义为两个结构体：它的类结构体和它的实例结构体。所有的类结构体的第一个成员必须是一个GTypeClass结构，所有的实例结构体的第一个成员必须是GTypeInstance结构。</p> 
<h4><a id="Gstreamer_153"></a>Gstreamer的多线程</h4> 
<p>​ GStreamer 是一个支持多线程的框架，而且是绝对安全的线程。</p> 
<p>​ Gstreamer的多线程由元件queue来实现，queue前后的两部分被分成两个线程执行。</p> 
<p><img src="https://images2.imgbox.com/f2/3e/ajAuRQly_o.png" alt="image-20220119215443674"></p> 
<h3><a id="_162"></a>实用工具</h3> 
<p>​ gst-inspect 用于查看一个插件的信息，在gstreamer1.0版本下，为gst-inspect-1.0</p> 
<p>​ gst-launch 用于启动一个流水线，在gstreamer1.0版本下，为gst-launch-1.0</p> 
<p>​ gst-launch主要用于临时启用或调试一个流水线，如果一个已经定型的流水线，需要使用gstreamer提供的C函数来形成一个流水线。</p> 
<p>​ 为了使得我们自己的插件能够成功被gstreamer检测到，gstreamer支持添加GST_PLUGIN_PATH环境变量来增加插件的搜索路径。</p> 
<p>​ 在gst-launch启动前，会先扫描需要使用的各插件对应的so库，当扫描到了对应的库，但是无法载入成功时，则会把插件加入黑名单，如果需要查看黑名单，只需要gst-inspect-1.0 -b即可。</p> 
<p>​ 损坏的插件在第一次扫描到时会报出加入黑名单的原因，后续再扫描时将不会报出原因，如果需要查看加入黑名单的原因，需要删除相应的缓存再执行。</p> 
<pre><code class="prism language-shell"><span class="token function">rm</span> ~/.cache/gstreamer-1.0/registry.x86_64.bin
gst-inspect-1.0 -b
</code></pre> 
<p>​ gstreamer调试等级，通过设置环境变量GST_PLUGIN来设置gstreamer运行时的调试等级，不同等级会打印出不同等级的信息。</p> 
<p>总共有六个等级［0，5］<br> 0： 什么都不打印<br> 1： 打印GST_ERROR ()的信息<br> 2： 打印GST_ERROR () GST_WARNING () 的信息<br> 3： 打印GST_ERROR () GST_WARNING () GST_INFO () 的信息<br> 4： 打印GST_ERROR () GST_WARNING () GST_INFO () GST_DEBUG () 的信息<br> 5： 打印GST_ERROR () GST_WARNING () GST_INFO () GST_DEBUG () GST_LOG () 的信息</p> 
<h3><a id="Gstreamer_189"></a>Gstreamer常用插件介绍</h3> 
<p>Gstreamer有一些常用的用于搭建流水线的插件，这里做一个介绍。</p> 
<p><strong>v4l2src（Video for Linux 2 source）</strong></p> 
<p>Video for Linux 2是内核提供给应用程序访问音、视频驱动的统一接口，v4l2src则是其提供给gstreamer的一个插件element，它属于插件video4linux2，动态链接库文件名为libgstvideo4linux2.so。</p> 
<p><img src="https://images2.imgbox.com/0d/74/hg8jHeP8_o.png" alt="image-20220118223403315"></p> 
<p>v4l2src属性里，常用的有</p> 
<p>device：用于指定Linux 设备文件，例如/dev/video0</p> 
<p>num-buffers: 用于指定从设备中读入多少帧。</p> 
<p>v4l2src可以从外部指定caps类型。</p> 
<p>由gst-inspect-1.0 v4l2src可发现</p> 
<p><img src="https://images2.imgbox.com/88/48/5mVTsTUQ_o.png" alt="image-20220118224209893"></p> 
<p>v4l2src实例：</p> 
<p>gst-launch-1.0 v4l2src devce=/dev/video0 num-buffers=60 ! video/x-raw,width=1280,height=720 ! fakesink</p> 
<p>其中fakesink是一个万能结束元件，用于在调试中结束一条流水线。</p> 
<p>官方文档：</p> 
<p>https://gstreamer.freedesktop.org/documentation/video4linux2/v4l2src.html?gi-language=c</p> 
<p>内容与直接执行gst-inspect-1.0 v4l2src差不多</p> 
<p><strong>filesrc</strong></p> 
<p>filesrc是gstreamer的核心插件之一，用于从文件系统中读取某一文件。</p> 
<p>常用属性：</p> 
<p>location: 文件位置</p> 
<p>num-buffers: 用于指定从设备中读入多少帧。</p> 
<p><strong>filesink</strong></p> 
<p>用于存放视频流至文件中</p> 
<p>常用属性：</p> 
<p>location: 文件位置</p> 
<p><strong>qtdemux(QuickTime Demuxer)</strong></p> 
<p>用于将文件中的音频和视频分开，一般读取文件后应接该元件，不过有的视频文件不需要，这个与文件本身有关。</p> 
<p>实例：gst-launch-1.0 filesrc location=flower_groundtruth.mp4 ! qtdemux ! h264parse ! omxh264dec ! omxh264enc ！filesink location=output.mp4</p> 
<p>功能：读文件-&gt;提取视频-&gt;解析h264视频流-&gt;h264解码-&gt;h264编码-&gt;写入文件</p> 
<p><strong>videotestsrc</strong></p> 
<p>gstreamer自带的测试视频源</p> 
<p>常用属性：</p> 
<p>pattern：测试视频显示图案</p> 
<p><img src="https://images2.imgbox.com/83/a3/lLR6hgjl_o.png" alt="image-20220119150355022"></p> 
<p>实例：gst-launch-1.0 videotestsrc pattern=2 ! ximagesink</p> 
<p>其中ximagesink是指窗口显示</p> 
<p><strong>fakesrc 与fakesink</strong></p> 
<p>gstreamer自带的万能src和sink</p> 
<p><strong>videocrop</strong></p> 
<p>裁剪视频，与v4l2src一样在外部指定caps</p> 
<p>常用属性：</p> 
<p><img src="https://images2.imgbox.com/4e/68/LeyzayhY_o.png" alt="image-20220119151006293"></p> 
<p><strong>videoscale</strong></p> 
<p>改变视频尺寸，与v4l2src一样在外部指定caps</p> 
<p>常用属性：</p> 
<p>method：插值方法</p> 
<p>n-threads：线程数</p> 
<p><strong>videoconvert</strong></p> 
<p>改变视频格式，通常用于两个插件格式不匹配时，作为中间插件协调两个插件的格式，与v4l2src一样在外部指定caps。</p> 
<p><strong>kmssink</strong></p> 
<p>用于将视频发送至HDMI输出。</p> 
<p>常用属性：</p> 
<p>sync: 同步，当为True时，当处理速度过慢时，会采用丢弃一些帧的策略来处理最新帧，当为false时，不会放弃任何帧，内部有buffer存放还没处理完的帧。</p> 
<p>bus-id: 填写HDMI输出所对应的设备。例如a0007000.v_mix，具体信息查看需要在dmesg里查看。</p> 
<p><img src="https://images2.imgbox.com/4d/4d/X1yJtFmC_o.png" alt="image-20220119154355851"></p> 
<p><strong>jpegdec</strong></p> 
<p>jpeg解码，当使用USB摄像头时，送入的是JPEG图像，此时需要进行解码才能正常处理。</p> 
<p>其他实用插件可参考gstreamer官方文档。</p> 
<h3><a id="gstreamer_309"></a>gstreamer工程记录</h3> 
<p>​ 如果想把自定义的硬件集成在gstreamer框架下，需要编写gstreamer插件。</p> 
<p><strong>关于Gstreamer的x86环境与aarch64交叉编译环境的搭建</strong></p> 
<p>​ 对于x86的Ubuntu环境</p> 
<pre><code class="prism language-shell"><span class="token function">apt-get</span> <span class="token function">install</span> libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libgstreamer-plugins-bad1.0-dev gstreamer1.0-plugins-base gstreamer1.0-plugins-good gstreamer1.0-plugins-bad gstreamer1.0-plugins-ugly gstreamer1.0-libav gstreamer1.0-doc gstreamer1.0-tools gstreamer1.0-x gstreamer1.0-alsa gstreamer1.0-gl gstreamer1.0-gtk3 gstreamer1.0-qt5 gstreamer1.0-pulseaudio
</code></pre> 
<p>​ 对于aarch64的交叉编译环境</p> 
<p>​ 首先按照交叉编译器工具链，这个除了gcc之外还包括了其他必要的工具</p> 
<pre><code class="prism language-shell"><span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> gcc-aarch64-linux-gnu
</code></pre> 
<p><img src="https://images2.imgbox.com/bb/05/KT8RAbml_o.png" alt="image-20220116184832612"></p> 
<pre><code>	其次，准备好必要的依赖库。库依赖关系：
</code></pre> 
<p><img src="https://images2.imgbox.com/31/34/D6uG8b3h_o.png" alt="image-20220115164854318"></p> 
<p>​ 如果想准备gst-plugins-base和gstreamer core的交叉编译环境，则需要按照依赖关系准备好前述编译环境。</p> 
<p>​ <strong>注意事项</strong>：交叉编译环境的版本应与开发板的gstreamer版本保持一致，这是为了保证头文件和连接的依赖库保持一致。特别地，gstreamer 1.12之前和1.14以后的版本不能通用，两个版本的插件也不能通用。</p> 
<ul><li> <p>安装orc 0.4.27支持库</p> <p>如果安装了gtk-doc-tools和libgtk2.0-doc后提示gtkdoc-mktmpl: command not found，将./autogen.sh --prefix=/usr改为下面的命令</p> </li></ul> 
<pre><code class="prism language-shell">./configure --prefix<span class="token operator">=</span>/home/rongyitong/aarch64 --host<span class="token operator">=</span>aarch64-linux-gnu
<span class="token function">make</span> 
<span class="token function">sudo</span> <span class="token function">make</span> <span class="token function">install</span>
</code></pre> 
<ul><li>zlib 1.2.11交叉编译</li></ul> 
<pre><code class="prism language-shell"><span class="token builtin class-name">export</span> <span class="token assign-left variable">CC</span><span class="token operator">=</span>arm-linux-gnu-gcc   <span class="token comment">#它的configure不支持用CC变量来指定交叉工具链</span>
./configure --prefix<span class="token operator">=</span>/home/rongyitong/aarch64  <span class="token comment">#最后生成的库、头文件和man文件都在该目录下</span>
<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">make</span> <span class="token function">install</span>
</code></pre> 
<ul><li> <p>libffi 3.4.2交叉编译</p> <pre><code class="prism language-shell"><span class="token builtin class-name">export</span> <span class="token assign-left variable">CC</span><span class="token operator">=</span>aarch64-linux-gnu-gcc
./configure --prefix<span class="token operator">=</span>/home/rongyitong/aarch64 --host<span class="token operator">=</span>aarch64-linux-gnu
<span class="token function">make</span> <span class="token operator">&amp;&amp;</span> <span class="token function">sudo</span> <span class="token function">make</span> <span class="token function">install</span>
</code></pre> </li><li> <p>glib 2.45.3 交叉编译<br> glib根目录下新建glib.cache，里面写入</p> </li></ul> 
<pre><code>glib_cv_long_long_format=ll
glib_cv_stack_grows=no
glib_cv_have_strlcpy=no
glib_cv_have_qsort_r=yes
glib_cv_va_val_copy=yes
glib_cv_uscore=no
glib_cv_rtldglobal_broken=no
ac_cv_func_posix_getpwuid_r=yes
ac_cv_func_posix_getgrgid_r=yes
</code></pre> 
<pre><code class="prism language-shell">./autogen.sh --prefix<span class="token operator">=</span>/home/rongyitong/aarch64 --host<span class="token operator">=</span>aarch64-linux-gnu <span class="token assign-left variable">CC</span><span class="token operator">=</span>aarch64-linux-gnu-gcc  <span class="token assign-left variable">LIBFFI_CFLAGS</span><span class="token operator">=</span><span class="token string">"-I/home/rongyitong/aarch64/lib/libffi-3.0.13/include"</span> <span class="token assign-left variable">LIBFFI_LIBS</span><span class="token operator">=</span><span class="token string">"-L/home/rongyitong/aarch64/lib -lffi"</span> -cache-file<span class="token operator">=</span>glib.cache  --disable-selinux  --disable-xattr --disable-libelf <span class="token assign-left variable">ZLIB_CFLAGS</span><span class="token operator">=</span><span class="token string">"-I/home/rongyitong/aarch64/include"</span> <span class="token assign-left variable">ZLIB_LIBS</span><span class="token operator">=</span><span class="token string">"-lz -L/home/rongyitong/aarch64/lib"</span>
</code></pre> 
<p>如果遇到</p> 
<p><img src="https://images2.imgbox.com/a1/5f/i2rcbtPB_o.png" alt="image-20220103153940015"></p> 
<p>这是编译器版本问题，在 glib/gdate.c前面加上#pragma GCC diagnostic ignored “-Wformat-nonliteral”</p> 
<ul><li> <p>gstreamer 1.12交叉编译（因为开发板是1.12版本，因此需要保持一致）</p> <p>注意在之前添加环境变量PKG_CONFIG_PATH，用于./configure里用pkg-config检测glib是否存在，如果x86版本的glib干扰，可以将/usr/local/lib临时改名</p> </li></ul> 
<pre><code class="prism language-shell"> ./configure --prefix<span class="token operator">=</span>/home/rongyitong/aarch64 --host<span class="token operator">=</span>aarch64-linux-gnu <span class="token assign-left variable">GLIB_LIBS</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span>-lglib-2.0 -L/home/rongyitong/aarch64/lib<span class="token variable">`</span></span> <span class="token assign-left variable">GLIB_CFLAGS</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span>-I /home/rongyitong/aarch64/include/glib-2.0 -I /home/rongyitong/aarch64/lib/glib-2.0/include<span class="token variable">`</span></span> <span class="token assign-left variable">GIO_LIBS</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span>-lgio-2.0 -lgobject-2.0 -lglib-2.0 -L/home/rongyitong/aarch64/lib<span class="token variable">`</span></span> <span class="token assign-left variable">GIO_CFLAGS</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span>-pthread -I/home/rongyitong/aarch64/include/glib-2.0 -I/home/rongyitong/aarch64/lib/glib-2.0/include<span class="token variable">`</span></span> <span class="token assign-left variable">LIBS</span><span class="token operator">=</span><span class="token variable"><span class="token variable">`</span>-lzlib -L<span class="token operator">=</span>/home/rongyitong/aarch64/lib<span class="token variable">`</span></span>
</code></pre> 
<ul><li>编译gst-plugin-base库</li></ul> 
<pre><code class="prism language-shell">./configure --prefix<span class="token operator">=</span>/home/rongyitong/aarch64 --host<span class="token operator">=</span>aarch64-linux-gnu --disable-ogg --disable-vorbis
</code></pre> 
<p>这里已经配好了pkg-config路径，如果没有配好，需要像gstreamer一样配置好环境变量</p> 
<p><strong>关于动态链接库(shared object library)的补充知识</strong></p> 
<p>​ gstreamer插件库是以动态链接库的形式出现的，因此了解动态链接库的知识是非常必要的。</p> 
<p>​ 软件库一般分为<strong>静态链接库</strong>与<strong>动态链接库</strong>，其中静态链接库扩展名为.a（linux）或.lib（windows），动态链接库扩展名为.so（Linux）或.dll（Windows）。</p> 
<p>​ 动态链接的基本思想是把程序按照模块拆分成各个相对独立的部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有的程序模块都链接成一个单独的可执行文件。</p> 
<p>​ Linux下的动态链接库通常为libxxx.so格式，在gcc中链接需要的动态库，只需简写为-lxxx。</p> 
<p>​ 静态链接库会在链接过程合并至目标程序中，而动态链接库只会在目标程序运行时需要这个函数时才会去对应的so文件中寻找该函数，因此动态链接库经常出现依赖问题。</p> 
<p>​ 动态链接库的依赖问题通常有两种：</p> 
<ol><li> <p>找不到对应的.so文件，或对应的.so文件格式与目标程序不匹配。此错误通常在链接时就会报错。</p> </li><li> <p>在对应的.so文件中找不到需要的函数。此错误在可以正常链接，但是在目标程序执行时才会报错。<br> 错误类型通常为<strong>符号</strong>未定义问题，例如undefined symbol: pthread_create</p> <p>动态和静态链接库中，函数和变量统称为<strong>符号</strong>（symbol），函数名或变量名称为<strong>符号名</strong>（Symbol Name），每个库中都有一个<strong>符号表</strong>（symbol table）</p> <p><strong>动态链接库的实用工具：</strong></p> <p><strong>readelf</strong></p> <p>常见用法</p> <p>readelf -h libxxx.so</p> <p>选项 -h(elf header)，显示elf文件开始的文件头信息。</p> <p><img src="https://images2.imgbox.com/3e/65/wNbMTUNV_o.png" alt="image-20220118141843116"></p> <p>readelf -s libxxx.so</p> <p>选项 -s, 显示符号表段中的项，（如果Name显示不全，可以再加个-W参数，表示完整显示）</p> <p><img src="https://images2.imgbox.com/0a/88/I7pDpSwM_o.png" alt="image-20220118151931033"></p> <p><img src="https://images2.imgbox.com/90/2c/EeX2x9RU_o.png" alt="image-20220118152014689"></p> <p><img src="https://images2.imgbox.com/47/9f/AjWYwiIM_o.png" alt="image-20220118151427682"></p> <p>​ Ndx表示该符号所在的段，UND表示未定义，表示在该文件里没有定义该符号，只引用了该符号，符号定义在其他文件里。</p> <p>​ <strong>ldd（list dynamic dependencies）工具</strong></p> <p>​ 用于查看一个库或可执行文件所依赖的其他库。</p> <p><img src="https://images2.imgbox.com/67/d1/zGgxTWee_o.png" alt="image-20220118153659677"></p> </li></ol> 
<p>有时候使用ldd工具，提示</p> 
<p><img src="https://images2.imgbox.com/bc/5b/V3Tk2VAw_o.png" alt="image-20220118154609043"></p> 
<p>这种情况可能是由于该文件的架构和执行命令的平台不匹配，比如aarch64平台在x86平台运行。解决方法可以使用aarch64版本的ldd工具，并移植到aarch64平台进行。</p> 
<p>ldd工具本质上只是个shell脚本，因此修改代码即可。</p> 
<p>1.注意保证#!/bin/bash与平台解释器一致；<br> 2.修改变量RTLDLIST值。将其修改为aarch64平台下的链接动态库(ld-linux-xx.so)，多数位于/lib目录下;</p> 
<p><img src="https://images2.imgbox.com/0a/d3/tZ1Bnod4_o.png" alt="image-20220118154942345"></p> 
<p><strong>从模板开始编写一个插件</strong></p> 
<pre><code>git clone https://gitlab.freedesktop.org/gstreamer/gst-template.git
</code></pre> 
<p>进入git目录，需要把branch切换到1.18版本，master版本的模板有一些问题。利用make_element工具替换名字后，</p> 
<p><strong>以videocrop插件为例，基于实际插件重构</strong></p> 
<p>插件继承关系</p> 
<pre><code>GObject
    ╰──GInitiallyUnowned
        ╰──GstObject
            ╰──GstElement
                ╰──GstBaseTransform
                    ╰──GstVideoFilter
                        ╰──videocrop
</code></pre> 
<p>插件重构方式，gstvideofilter.c与gstbasetransform.c分别集成至了libgstvideo.so和libgstreamer-1.0.so中，如无必要，不要修改两个的源码，直接链接相应的动态库即可。如果直接修改源码，则两个c文件会依赖一系列头文件及其他依赖库，其中有些头文件还是在编译gstreamer核心库时产生的，这个头文件环境相当复杂，因此不建议采用这种方法。</p> 
<p><strong>关于图像在内存中的存放方式</strong></p> 
<p>​ 当视频图像存储在内存时，图像的每一行末尾也许包含一些扩展的内容，这些扩展的内容只影响图像如何存储在内存中，但是不影响图像如何显示出来；</p> 
<p>​ Stride 就是这些扩展内容的名称，Stride 也被称作 Pitch，如果图像的每一行像素末尾拥有扩展内容，Stride 的值一定大于图像的宽度值，就像下图所示：<br> ​ <img src="https://images2.imgbox.com/a9/1c/r2xAmlQx_o.png" alt="这里写图片描述"></p> 
<p>​ 两个缓冲区包含同样大小（宽度和高度）的视频帧，却不一定拥有同样的 Stride 值，如果你处理一个视频帧，你必须在计算的时候把 Stride 考虑进去；</p> 
<p>​ 另外，一张图像在内存中有两种不同的存储序列（arranged），对于一个从上而下存储（Top-Down） 的图像，最顶行的像素保存在内存中最开头的部分，对于一张从下而上存储（Bottom-Up）的图像，最后一行的像素保存在内存中最开头的部分，下面图示展示了这两种情况：</p> 
<p><img src="https://images2.imgbox.com/54/67/6dmJk3vZ_o.png" alt="这里写图片描述"></p> 
<p>​ YUV 图像永远都是从上而下表示的，RGB 图像保存在系统内存时通常是从下而上；</p> 
<h6><a id="YUV_502"></a>关于YUV的补充知识</h6> 
<p>YUV(YCrCb)是指将亮度参量Y和色度参量U/V分开表示的像素格式，主要用于优化彩色视频信号的传输。</p> 
<p>由于我们眼睛的视网膜杆细胞多于视网膜的锥细胞，而视网膜的杆细胞是识别亮度的，锥细胞是识别色度的，所以我们的眼睛对于明暗的分辨要比对颜色的分辨要精细，也就是我们眼睛对于亮度的敏感程度要大于色度的敏感程度。那么，我们在存储图像信息时，为了节约空间，就没有必要将所有的色度信息全部存储下来了。</p> 
<p>YUV像素格式来源于RGB像素格式，通过公式运算，YUV 三分量可以还原出 RGB。</p> 
<p><strong>YUV的存储格式</strong></p> 
<p>YUV格式有两大类：planar和packed。</p> 
<ul><li>对于planar的YUV格式，先连续存储所有像素点的Y，紧接着存储所有像素点的U，随后是所有像素点的V。</li><li>对于packed的YUV格式，每个像素点的Y,U,V是连续交叉存储的。</li></ul> 
<p><strong>YUV的采样格式</strong></p> 
<p>YUV码流的存储格式其实与其采样的方式密切相关，主流的采样方式有三种，YUV4:4:4，YUV4:2:2，YUV4:2:0</p> 
<p>用三个图来直观地表示采集的方式吧，以黑点表示采样该像素点的Y分量，以空心圆圈表示采用该像素点的UV分量。</p> 
<p><img src="https://images2.imgbox.com/f3/6b/21yqedIT_o.jpg" alt="这里写图片描述"></p> 
<ul><li>YUV 4:4:4采样，每一个Y对应一组UV分量。</li><li>YUV 4:2:2采样，每两个Y共用一组UV分量。</li><li>YUV 4:2:0采样，每四个Y共用一组UV分量。</li></ul> 
<p>存储方式实例：</p> 
<p><strong>&lt;1&gt;YUV422存储类型</strong></p> 
<p>&lt;1-1&gt;YUYV格式（采样格式为YUV422，存储格式为packed）</p> 
<p><img src="https://images2.imgbox.com/83/21/WJkHjSIu_o.png" alt="img"></p> 
<p>YUYV是YUV422采样的存储格式的一种，相邻的两个Y公用其相邻的两个Cb(U)、Cr(V)。对于像素点Y’00、Y’01而言，其Cb、Cr的值均为Cb00、Cr00，其他的像素点的YUV取值依次类推。</p> 
<p>&lt;1-2&gt;UYVY格式（采样格式为YUV422，存储格式为packed）</p> 
<p><img src="https://images2.imgbox.com/67/42/peDSYhkB_o.png" alt="img"></p> 
<p>&lt;1-3&gt;YUV422P（采样格式为YUV422，存储格式为planar）</p> 
<p><img src="https://images2.imgbox.com/d8/46/HLnx07AQ_o.png" alt="img"></p> 
<p>​ YUV422P是一种Plane模式，即planar模式，并不是像上面YUV数据交错存储，而是先存储所有的Y分量，然后存储所有的U（Cb）分量，最后存储所有的V（Cr）分量。其每一个像素点的YUV值提取方法也是遵循YUV422格式的最基本提取方法，即两个Y共用一个UV。比如，对于像素点Y’00、Y’01而言，其Cb、Cr的值均为Cb00、Cr00。</p> 
<p><strong>&lt;2&gt;YUV420存储类型</strong></p> 
<p>基于 YUV 4:2:0 采样的格式主要有 YUV 420P 和 YUV 420SP 两种类型，每个类型又对应其他具体格式。</p> 
<ul><li>YUV 420P 类型 
  <ul><li>YU12 格式</li><li>YV12 格式</li></ul> </li><li>YUV 420SP 类型 
  <ul><li> <p>NV12 格式</p> </li><li> <p>NV21 格式</p> </li></ul> </li></ul> 
<p>YUV 420P 和 YUV 420SP 都是基于 Planar <strong>平面格式</strong> 进行存储的，先存储所有的 Y 分量后， YUV420P 类型就会先存储所有的 U 分量或者 V 分量，而 YUV420SP 则是按照 UV 或者 VU 的交替顺序进行存储了，</p> 
<p>&lt;2-1&gt;YUV420sp（采样格式为YUV420，存储格式为planar，分Y-planner和UV-planar，其中UV平面为packed）</p> 
<p><img src="https://images2.imgbox.com/0d/58/roDvJrF1_o.png" alt="img"></p> 
<p><img src="https://images2.imgbox.com/c8/6e/kmE7UVjH_o.png" alt="img"></p> 
<p>NV21、NV12都属于YUV420格式，是一种two-plane模式，即Y和UV分为两个Plane，但是UV（CbCr）为交错存储，而不是分为三个plane。其提取方式与上面一种类似，即Y’00、Y’01、Y’10、Y’11共用Cr00、Cb00。</p> 
<p>&lt;2-2&gt;YUV420p（采样格式为YUV420，存储格式为planar，分Y-planner和U-planar和V-planar）</p> 
<p><img src="https://images2.imgbox.com/0e/42/BDrRXFOz_o.png" alt="img"></p> 
<p><img src="https://images2.imgbox.com/b8/4b/QwArYi0i_o.png" alt="img"></p> 
<p>YU12（又称I420）和YV12属于YUV420格式，也是一种Plane模式，将Y、U、V分量分别打包，依次存储。其没一个像素点的YUV数据提取都遵循YUV420格式的提取方式，即4个Y分量共用一组UV。如上图中，Y’00、Y’01、Y’10、Y’11共用Cr00、Cb00，其他以此类推。</p> 
<p>注意，YU12与YV12的区别在于是先存U还是先存V。对于YU12来说，存储顺序是YUV，即YCbCr；对于YV12来说，存储顺序是YVU，即YCrCb。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c9e4611583a2a9902a519dc3e088bf8d/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Docker常用命令总结</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/13e987ae0bd808d8b9154f86e285d668/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C#基础入门教程-方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>