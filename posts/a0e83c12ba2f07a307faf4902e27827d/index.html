<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>词嵌入位置编码的实现（基于pytorch） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="词嵌入位置编码的实现（基于pytorch）" />
<meta property="og:description" content="背景介绍 在transformers架构当中，对于词向量的输入需要加上原本词对应的位置信息，作为输入到模型中训练的input，那具体的位置编码如何实现呢？本篇博客就跟大家一起分享一下对应的步骤
位置编码的公式 对于词向量的位置编码的方式有多种，这里就介绍用三角函数进行位置编码的公式
PE是position embeding位置编码的意思，pos表示词的位置，表示词向量的维度,i表示词向量的第i维度
那接下来我们就根据公式进行位置编码的代码实现
代码实现 环境依赖的库
import torch import math import numpy as np import matplotlib.pyplot as plt 定义一个函数获取位置编码的信息
def generate_word_embeding(max_len,d_model): # 初始化位置信息 pos = torch.arange(max_len).unsqueeze(1) # 初始化位置编码矩阵 result = torch.zeros(max_len,d_model) # 获得公式对应的值 coding = torch.exp(torch.arange(0,d_model,2)*(-math.log(10000.0))/d_model) result[:,0::2] = torch.sin(pos*coding) result[:,1::2] = torch.cos(pos*coding) # 为了与原编码直接相加，格式为[B,seq_len,d_model]，需要再增加一个维度 return result.unsqueeze(0) 假设我们的max_len是100，d_model为20，那么pos的维度为[100,1]，result的维度为[100,20]，coding的维度为[1,d_model/2]，result[:,0::2]是指对result的每列从第0列开始每隔一列赋值，对应公式中的PE(pos,2i)；同理，result[:,1::2]对应公式中的PE(pos,2i&#43;1)
位置编码信息可视化 我们把得位置编码信息进行可视化从而得到更直观的感受
d = 6 pos_code = generate_word_embeding(100,d) print(pos_code.shape) plt.plot(np.arange(100),pos_code[0,:,0:d]) plt.legend([&#39;dim=%d&#39;%p for p in range(d)]) plt.show() 把词的时序长度设置为6，显示对应时序上每一个维度的位置编码信息
可以看到每一个时序位置上对应每一个维度都对应一个三角函数的变换规律，在放进model中训练的后就能够通过学习获得位置对应的知识
欢迎大家讨论交流~" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a0e83c12ba2f07a307faf4902e27827d/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-02T20:17:24+08:00" />
<meta property="article:modified_time" content="2024-01-02T20:17:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">词嵌入位置编码的实现（基于pytorch）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>背景介绍</h2> 
<p>在transformers架构当中，对于词向量的输入需要加上原本词对应的位置信息，作为输入到模型中训练的input，那具体的位置编码如何实现呢？本篇博客就跟大家一起分享一下对应的步骤<img alt="" height="572" src="https://images2.imgbox.com/8a/b3/ayeJWssq_o.jpg" width="753"></p> 
<h2></h2> 
<h2>位置编码的公式</h2> 
<p>对于词向量的位置编码的方式有多种，这里就介绍用三角函数进行位置编码的公式</p> 
<p><img alt="PE(pos,2i)=\sin (pos/10000^{2i/d_{model}})" class="mathcode" src="https://images2.imgbox.com/10/70/V6Q9OIrq_o.png"></p> 
<p><img alt="PE(pos,2i+1)=\cos(pos/10000^{2i/d_{model}})" class="mathcode" src="https://images2.imgbox.com/b2/59/tWQKSIg9_o.png"></p> 
<p>PE是position embeding位置编码的意思，pos表示词的位置，<img alt="d_{model}" class="mathcode" src="https://images2.imgbox.com/51/7f/Nrh0HSVj_o.png">表示词向量的维度,i表示词向量的第i维度</p> 
<p>那接下来我们就根据公式进行位置编码的代码实现</p> 
<h2></h2> 
<h2>代码实现</h2> 
<p>环境依赖的库</p> 
<pre><code class="language-python">import torch
import math
import numpy as np
import matplotlib.pyplot as plt</code></pre> 
<p>定义一个函数获取位置编码的信息</p> 
<pre><code class="language-python">def generate_word_embeding(max_len,d_model):
    # 初始化位置信息
    pos = torch.arange(max_len).unsqueeze(1)
    
    # 初始化位置编码矩阵
    result = torch.zeros(max_len,d_model)

    # 获得公式对应的值
    coding = torch.exp(torch.arange(0,d_model,2)*(-math.log(10000.0))/d_model)
    result[:,0::2] = torch.sin(pos*coding)
    result[:,1::2] = torch.cos(pos*coding)

    # 为了与原编码直接相加，格式为[B,seq_len,d_model]，需要再增加一个维度
    return result.unsqueeze(0)</code></pre> 
<p>假设我们的max_len是100，d_model为20，那么pos的维度为[100,1]，result的维度为[100,20]，coding的维度为[1,d_model/2]，result[:,0::2]是指对result的每列从第0列开始每隔一列赋值，对应公式中的PE(pos,2i)；同理，result[:,1::2]对应公式中的PE(pos,2i+1)</p> 
<p></p> 
<h2>位置编码信息可视化</h2> 
<p>我们把得位置编码信息进行可视化从而得到更直观的感受</p> 
<pre><code class="language-python">d = 6
pos_code = generate_word_embeding(100,d)
print(pos_code.shape)
plt.plot(np.arange(100),pos_code[0,:,0:d])
plt.legend(['dim=%d'%p for p in range(d)])
plt.show()</code></pre> 
<p>把词的时序长度设置为6，显示对应时序上每一个维度的位置编码信息</p> 
<p><img alt="" height="882" src="https://images2.imgbox.com/bf/66/Smdyhu7J_o.png" width="1200"></p> 
<p>可以看到每一个时序位置上对应每一个维度都对应一个三角函数的变换规律，在放进model中训练的后就能够通过学习获得位置对应的知识</p> 
<p>欢迎大家讨论交流~</p> 
<hr> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1f20f05a624ca6cc7de6250cff0f0f16/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">从C到C&#43;&#43;2——C&#43;&#43;引用</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/5573f2d677b6bb837556e9ddec9f60b2/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Shell脚本学习笔记</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>