<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Stable Diffusion：最先进的文本生成图像模型 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Stable Diffusion：最先进的文本生成图像模型" />
<meta property="og:description" content="稳定扩散 生成式 AI 技术正在迅速发展，现在可以简单地根据文本输入生成文本和图像。Stable Diffusion 是一种文本到图像模型，使您能够创建逼真的应用程序。
扩散模型通过学习去除添加到真实图像中的噪声进行训练。这种降噪过程会产生逼真的图像。这些模型还可以通过调节文本的生成过程，仅从文本生成图像。例如，稳定扩散是一种潜在扩散，模型学习识别纯噪声图像中的形状，如果形状与输入文本中的单词匹配，则逐渐使这些形状成为焦点。必须首先使用语言模型将文本嵌入到潜在空间中。然后，采用U-Net架构在潜在空间中进行一系列的噪声添加和消除操作。最后，将去噪后的输出解码到像素空间中。
以下是 Stable Diffusion 生成的输入文本和相应输出图像的一些示例。
以下图片是对输入的回应：“宇航员在火星上骑马的照片”、“印象派风格的纽约市绘画”和“穿西装的狗”。
以下图像是对输入的响应：（i） 玩扑克的狗，（ii） 森林中树木丛生的城堡的彩色照片，以及 （iii） 森林中树木丛生的城堡的彩色照片。负面提示：黄色
基于稳定扩散AI 模型开发的工具包 DreamTexture.js自动纹理化开发包 是基于 Stable Diffusion AI模型的3D 模型纹理自动生成与设置开发包，可以为 webGL 应用增加 3D 模型的快速自动纹理化能力。
图一为原始模型, 图二图三为贴图后的模型。提示词：city, Realistic , cinematic , Front view ,Game scene graph
1、DreamTexture.js 开发包内容 DreamTexture.js 基于 Three.js 和稳定扩散(stable diffusion) AI 模型开发，用于实现 3D 模型的自动纹理化,当然版本 V1.0,主要文件及目录组织结构如下：
开发包文件说明dream-texture.cjscjs 格式库文件dream-texture.esmesm 格式库文件dream-texture.umdumd 格式库文件stable-diffusion-guide.md用于 DreamTexture.js 的稳定扩散服务安装指南LICENSE.md开发包许可协议文件example/DreamTexture.js 使用示例目录 2、DreamTexture.js 开发包快速上手 以 ESM 库为例介绍如何使用 DreamTexture.js 开发包为 Three.js 应用增加 3D 模型的自动化纹理能力。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9a277399650d6ee1654bd021ef83f9d1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-08T10:59:59+08:00" />
<meta property="article:modified_time" content="2023-11-08T10:59:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Stable Diffusion：最先进的文本生成图像模型</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h3>稳定扩散</h3> 
<p>生成式 AI 技术正在迅速发展，现在可以简单地根据文本输入生成文本和图像。Stable Diffusion 是一种文本到图像模型，使您能够创建逼真的应用程序。</p> 
<p>扩散模型通过学习去除添加到真实图像中的噪声进行训练。这种降噪过程会产生逼真的图像。这些模型还可以通过调节文本的生成过程，仅从文本生成图像。例如，稳定扩散是一种潜在扩散，模型学习识别纯噪声图像中的形状，如果形状与输入文本中的单词匹配，则逐渐使这些形状成为焦点。必须首先使用语言模型将文本嵌入到潜在空间中。然后，采用U-Net架构在潜在空间中进行一系列的噪声添加和消除操作。最后，将去噪后的输出解码到像素空间中。</p> 
<p>以下是 Stable Diffusion 生成的输入文本和相应输出图像的一些示例。</p> 
<p>以下图片是对输入的回应：“宇航员在火星上骑马的照片”、“印象派风格的纽约市绘画”和“穿西装的狗”。</p> 
<p></p> 
<p class="img-center"><img alt="" height="512" src="https://images2.imgbox.com/93/af/81S6kPFO_o.jpg" width="1200"></p> 
<p>以下图像是对输入的响应：（i） 玩扑克的狗，（ii） 森林中树木丛生的城堡的彩色照片，以及 （iii） 森林中树木丛生的城堡的彩色照片。负面提示：黄色</p> 
<p></p> 
<p class="img-center"><img alt="" height="337" src="https://images2.imgbox.com/43/32/dQ3xsFSG_o.jpg" width="1000"></p> 
<h3>基于稳定扩散AI 模型开发的工具包</h3> 
<p><a href="https://tools.nsdt.cloud/DreamTexture" rel="nofollow" title="DreamTexture.js自动纹理化开发包">DreamTexture.js自动纹理化开发包</a> 是基于 Stable Diffusion AI模型的3D 模型纹理自动生成与设置开发包，可以为 webGL 应用增加 3D 模型的快速自动纹理化能力。</p> 
<p></p> 
<p class="img-center"><img alt="" height="260" src="https://images2.imgbox.com/e9/6a/Byl9EeuM_o.png" width="1200"></p> 
<p>图一为原始模型, 图二图三为贴图后的模型。提示词：city, Realistic , cinematic , Front view ,Game scene graph</p> 
<h4>1、DreamTexture.js 开发包内容</h4> 
<p>DreamTexture.js 基于 Three.js 和稳定扩散(stable diffusion) AI 模型开发，用于实现 3D 模型的自动纹理化,当然版本 V1.0,主要文件及目录组织结构如下：</p> 
<table><thead><tr><th>开发包文件</th><th>说明</th></tr></thead><tbody><tr><td>dream-texture.cjs</td><td>cjs 格式库文件</td></tr><tr><td>dream-texture.esm</td><td>esm 格式库文件</td></tr><tr><td>dream-texture.umd</td><td>umd 格式库文件</td></tr><tr><td>stable-diffusion-guide.md</td><td>用于 DreamTexture.js 的稳定扩散服务安装指南</td></tr><tr><td>LICENSE.md</td><td>开发包许可协议文件</td></tr><tr><td>example/</td><td>DreamTexture.js 使用示例目录</td></tr></tbody></table> 
<h4>2、DreamTexture.js 开发包快速上手</h4> 
<p>以 ESM 库为例介绍如何使用 DreamTexture.js 开发包为 Three.js 应用增加 3D 模型的自动化纹理能力。</p> 
<p>首先参考开发包中的稳定扩散服务安装指南部署自己的 stable diffusion api 服务，支持 windows 和 Linux。</p> 
<p>接下来安装 three.js 开发环境，安装完成后需要引入 DreamTexture.js 库文件，以 ESM 库为例，引入代码如下：</p> 
<pre><code>import * as THREE from 'three';
import DreamTexture from './dream-texture.esm.min';
</code></pre> 
<p>现在创建一个场景，在场景中导入 GLTF 模型 ，并可以适当的旋转或移动模型：</p> 
<pre><code>//将模型导入到场景
const gltfLoader = new THREE.GLTFLoader();
gltfLoader.load('monkey.glb', async (e) =&gt; {
  scene.add(e.scene);
});

// 将模型旋转到任何你想要的角度!
box.rotation.y = -Math.PI / 4;
</code></pre> 
<p>然后实例化一个 DreamTexture 对象，注意要在参数中指定你的稳定扩散 API 服务的 URL：</p> 
<pre><code>//初始化DreamTexture对象，传入您的stable diffusion api 地址
const dt = new DreamTexture({
  baseUrl: 'http://127.0.0.1:7860', //stable diffusion url
});
</code></pre> 
<p>现在就可以调用 DreamTexture 对象的 setTexture 方法传入提示词等参数, 让 AI 模型自动生成生成一张纹理图片，并投射到模型上，代码如下：</p> 
<pre><code>//编写提示词和其他参数
// 成功启动stable diffusion api后，可在 http://127.0.0.1:7860/docs 查看文档
const params = {
    prompt: 'monkey head, Brown hair, cartoon',//描述所需图像的细节越详细，Stable Diffusion生成效果越接近描述，较少描述则更具创意性。
    negative_prompt: 'blurry',//不希望Stable Diffusion生成的内容，用于排除不需要的元素。
    denoising_strength: 0.85,// 去噪强度
    cfg_scale: 15,//文字CFG比例
    image_cfg_scale: 7,//图片CFG比例
    steps: 10,//采样步数
    sampler_index: 'DPM++ SDE Karras',
    sampler_name: '',
};
dt.setTexture(scene, params).then((res) =&gt; {
  console.log('纹理添加成功！');
});
</code></pre> 
<p>3D 模型的自动纹理化效果如下：</p> 
<p>案例 1：</p> 
<p></p> 
<p class="img-center"><img alt="aa2" height="340" src="https://images2.imgbox.com/97/02/sHUg90kA_o.png" width="1200"></p> 
<p>图一为原始模型, 图二图三为贴图后的模型。提示词：</p> 
<blockquote>
  car, Realistic , photography , hyper quality , high detail , high resolution , Unreal Engine , Side view 
</blockquote> 
<p>案例 2：</p> 
<p></p> 
<p class="img-center"><img alt="aa1" height="339" src="https://images2.imgbox.com/fe/01/k47vVowt_o.png" width="1200"></p> 
<p>图一为原始模型, 图二图三为贴图后的模型。图二提示词：</p> 
<blockquote>
  Realistic , photography, bottle, porcelain 
</blockquote> 
<p>图三：将'porcelain'换为'glass'</p> 
<h4>3、DreamTexture.js 开发包 cjs/umd 库文件的使用</h4> 
<p>DreamTexture 支持三种常用的 js 库格式，除了前面介绍的 esm 格式，还支持 cjs、umd 格式：</p> 
<p>cjs 库的引入代码如下：</p> 
<pre><code>const ProjectedMaterial = require('./dream-texture.cjs.js');
</code></pre> 
<p>umd 库的引入代码如下：</p> 
<pre><code>&lt;script src="./three.js"&gt;&lt;/script&gt;
&lt;script src="./dream-texture.umd.js"&gt;&lt;/script&gt;
</code></pre> 
<h3>4、DreamTexture.js 开发包 API 接口说明</h3> 
<p>DreamTexture.js 的 API 接口非常简单，说明如下：</p> 
<ul><li>new DreamTexture({ baseUrl })</li></ul> 
<p>初始化 DreamTexture 对象,稍后用于 3D 模型的自动纹理化。</p> 
<table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td><code>baseUrl</code></td><td>stable diffusion api 地址</td></tr></tbody></table> 
<ul><li>dreamTexture.setTexture(object3d:THREE.Object3D, params)</li></ul> 
<p>DreamTexture 会将传入的 object3d 的正视图作为依据来完成 3D 场景的自动纹理化，包括纹理的生成和自动投射。</p> 
<table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td><code>object3d</code></td><td>THREE.Object3D。支持 Group 和 Mesh。</td></tr><tr><td><code>params</code></td><td>stable diffusion img2img api 的参数</td></tr></tbody></table> 
<p> 转载：<a href="https://www.mvrlink.com/stable-diffusion-the-most-advanced-text-generation-image-model/" rel="nofollow" title="Stable Diffusion：最先进的文本生成图像模型 (mvrlink.com)">Stable Diffusion：最先进的文本生成图像模型 (mvrlink.com)</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/1ac5af53d7cf7bbc1ab69f8981c240bb/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">最全的语言和时区对照表</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d0af6c037a365e13018fe2f66e71fb3d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Linux抓包框架对比</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>