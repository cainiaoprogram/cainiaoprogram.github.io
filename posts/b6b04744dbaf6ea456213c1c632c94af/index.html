<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【Azkaban报错解决】FAILED: SemanticException Failed to get a spark session - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【Azkaban报错解决】FAILED: SemanticException Failed to get a spark session" />
<meta property="og:description" content="问题描述： ods_to_dwd_log报以下错误
ods_to_dim_db报一下错误
可以看出都是相同报错，无法创建spark事务
Logging initialized using configuration in jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true 05-05-2022 14:31:02 CST ods_to_dim_db INFO - Hive Session ID = 77b1dd10-3b70-44b7-8c41-96571c4a00c2 05-05-2022 14:31:04 CST ods_to_dim_db INFO - No Stats for gmall@ods_user_info, Columns: birthday, login_name, gender, create_time, nick_name, name, user_level, phone_num, id, email, operate_time 05-05-2022 14:32:36 CST ods_to_dim_db INFO - FAILED: SemanticException Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create Spark client for Spark session 6115db31-a456-4b8a-bd68-2b9defe20b95 05-05-2022 14:32:37 CST ods_to_dim_db INFO - Process with id 32405 completed unsuccessfully in 102 seconds." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b6b04744dbaf6ea456213c1c632c94af/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-05-07T22:32:42+08:00" />
<meta property="article:modified_time" content="2022-05-07T22:32:42+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【Azkaban报错解决】FAILED: SemanticException Failed to get a spark session</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_1"></a>问题描述：</h2> 
<p><img src="https://images2.imgbox.com/c8/46/8vxBZbRf_o.png" alt="在这里插入图片描述"><br> ods_to_dwd_log报以下错误<br> <img src="https://images2.imgbox.com/fe/d2/RXTvYePx_o.png" alt="在这里插入图片描述"><br> ods_to_dim_db报一下错误<br> <img src="https://images2.imgbox.com/68/95/ZwEpjdvL_o.png" alt="在这里插入图片描述"><br> 可以看出都是相同报错，无法创建spark事务</p> 
<pre><code class="prism language-bash">Logging initialized using configuration <span class="token keyword">in</span> jar:file:/opt/module/hive/lib/hive-common-3.1.2.jar<span class="token operator">!</span>/hive-log4j2.properties Async: <span class="token boolean">true</span>
05-05-2022 <span class="token number">14</span>:31:02 CST ods_to_dim_db INFO - Hive Session ID <span class="token operator">=</span> 77b1dd10-3b70-44b7-8c41-96571c4a00c2
05-05-2022 <span class="token number">14</span>:31:04 CST ods_to_dim_db INFO - No Stats <span class="token keyword">for</span> gmall@ods_user_info, Columns: birthday, login_name, gender, create_time, nick_name, name, user_level, phone_num, id, email, operate_time
05-05-2022 <span class="token number">14</span>:32:36 CST ods_to_dim_db INFO - FAILED: SemanticException Failed to get a spark session: org.apache.hadoop.hive.ql.metadata.HiveException: Failed to create Spark client <span class="token keyword">for</span> Spark session 6115db31-a456-4b8a-bd68-2b9defe20b95
05-05-2022 <span class="token number">14</span>:32:37 CST ods_to_dim_db INFO - Process with <span class="token function">id</span> <span class="token number">32405</span> completed unsuccessfully <span class="token keyword">in</span> <span class="token number">102</span> seconds.
05-05-2022 <span class="token number">14</span>:32:37 CST ods_to_dim_db ERROR - Job run failed<span class="token operator">!</span>
java.lang.RuntimeException: azkaban.jobExecutor.utils.process.ProcessFailureException: Process exited with code <span class="token number">64</span>
	at azkaban.jobExecutor.ProcessJob.run<span class="token punctuation">(</span>ProcessJob.java:312<span class="token punctuation">)</span>
	at azkaban.execapp.JobRunner.runJob<span class="token punctuation">(</span>JobRunner.java:823<span class="token punctuation">)</span>
	at azkaban.execapp.JobRunner.doRun<span class="token punctuation">(</span>JobRunner.java:602<span class="token punctuation">)</span>
	at azkaban.execapp.JobRunner.run<span class="token punctuation">(</span>JobRunner.java:563<span class="token punctuation">)</span>
	at java.util.concurrent.Executors<span class="token variable">$RunnableAdapter</span>.call<span class="token punctuation">(</span>Executors.java:511<span class="token punctuation">)</span>
	at java.util.concurrent.FutureTask.run<span class="token punctuation">(</span>FutureTask.java:266<span class="token punctuation">)</span>
	at java.util.concurrent.ThreadPoolExecutor.runWorker<span class="token punctuation">(</span>ThreadPoolExecutor.java:1149<span class="token punctuation">)</span>
	at java.util.concurrent.ThreadPoolExecutor<span class="token variable">$Worker</span>.run<span class="token punctuation">(</span>ThreadPoolExecutor.java:624<span class="token punctuation">)</span>
	at java.lang.Thread.run<span class="token punctuation">(</span>Thread.java:748<span class="token punctuation">)</span>
Caused by: azkaban.jobExecutor.utils.process.ProcessFailureException: Process exited with code <span class="token number">64</span>
	at azkaban.jobExecutor.utils.process.AzkabanProcess.run<span class="token punctuation">(</span>AzkabanProcess.java:125<span class="token punctuation">)</span>
	at azkaban.jobExecutor.ProcessJob.run<span class="token punctuation">(</span>ProcessJob.java:304<span class="token punctuation">)</span>
	<span class="token punctuation">..</span>. <span class="token number">8</span> <span class="token function">more</span>
</code></pre> 
<h2><a id="_31"></a>排除问题</h2> 
<p>先对问题进行排除：<br> 首先，在该服务器上尝试启动hive，并且手动执行该脚本。<br> ods_to_dwd_log执行成功。<br> <img src="https://images2.imgbox.com/56/e6/vKuWYWm2_o.png" alt="在这里插入图片描述"><br> ods_to_dim_db也执行成功<br> <img src="https://images2.imgbox.com/48/93/U1ApJTlC_o.png" alt="在这里插入图片描述">如果执行成功，说明hive-on-spark搭建成功。如果失败，则搭建失败。就要考虑是版本兼容性问题还是配置文件出错。</p> 
<h2><a id="_40"></a>解决方案一</h2> 
<p><strong>尝试解决方法一：</strong><br> 可以尝试调整hadoop/etc/hadoop/capacity-scheduler.xml中yarn.scheduler.capacity.maximum-am-resource-percent参数，application master资源比例，默认为0.8，如果该值设置过大，就会导致mapreduce时内存不足，就会报上面错误。如果该值是默认值，在学习环境下application master分配内存较少，可能同时只能执行一个job，影响效率。可以尝试调整0.5，</p> 
<pre><code class="prism language-xml">  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.scheduler.capacity.maximum-am-resource-percent<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>0.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>
      Maximum percent of resources in the cluster which can be used to run
      application masters i.e. controls number of concurrent running
      applications.
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

</code></pre> 
<p>成功执行。<br> <img src="https://images2.imgbox.com/04/3f/9fitRl5B_o.png" alt="在这里插入图片描述"><br> 但是再运行一次还是失败，说明是存在偶然性。<br> 然后去yarn的web：<a href="http://hadoop103:8088/cluster/apps" rel="nofollow">http://hadoop103:8088/cluster/apps</a>界面查看具体的报错信息。<br> 通过Hive Session ID = c1fbe469-6f9d-4dba-b7e8-d6092676f8b8找到对应的task<br> <img src="https://images2.imgbox.com/99/35/CFqMm8pC_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/cf/b7/GkDajQZ0_o.png" alt="在这里插入图片描述"></p> 
<pre><code class="prism language-bash"><span class="token number">2022</span>-05-05 <span class="token number">16</span>:58:21,139 INFO yarn.ApplicationMaster: Final app status: FAILED, exitCode: <span class="token number">13</span>, <span class="token punctuation">(</span>reason: User class threw exception: java.lang.NoClassDefFoundError: org/apache/hadoop/hive/conf/HiveConf<span class="token variable">$ConfVars</span>
at org.apache.hive.spark.client.rpc.RpcConfiguration.<span class="token operator">&lt;</span>clinit<span class="token operator">&gt;</span><span class="token punctuation">(</span>RpcConfiguration.java:48<span class="token punctuation">)</span>
at org.apache.hive.spark.client.RemoteDriver.<span class="token operator">&lt;</span>init<span class="token operator">&gt;</span><span class="token punctuation">(</span>RemoteDriver.java:138<span class="token punctuation">)</span>
at org.apache.hive.spark.client.RemoteDriver.main<span class="token punctuation">(</span>RemoteDriver.java:536<span class="token punctuation">)</span>
at sun.reflect.NativeMethodAccessorImpl.invoke0<span class="token punctuation">(</span>Native Method<span class="token punctuation">)</span>
at sun.reflect.NativeMethodAccessorImpl.invoke<span class="token punctuation">(</span>NativeMethodAccessorImpl.java:62<span class="token punctuation">)</span>
at sun.reflect.DelegatingMethodAccessorImpl.invoke<span class="token punctuation">(</span>DelegatingMethodAccessorImpl.java:43<span class="token punctuation">)</span>
at java.lang.reflect.Method.invoke<span class="token punctuation">(</span>Method.java:498<span class="token punctuation">)</span>
at org.apache.spark.deploy.yarn.ApplicationMaster<span class="token variable">$$</span>anon<span class="token variable">$2</span>.run<span class="token punctuation">(</span>ApplicationMaster.scala:728<span class="token punctuation">)</span>
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.hive.conf.HiveConf<span class="token variable">$ConfVars</span>
at java.net.URLClassLoader.findClass<span class="token punctuation">(</span>URLClassLoader.java:382<span class="token punctuation">)</span>
at java.lang.ClassLoader.loadClass<span class="token punctuation">(</span>ClassLoader.java:424<span class="token punctuation">)</span>
at java.lang.ClassLoader.loadClass<span class="token punctuation">(</span>ClassLoader.java:357<span class="token punctuation">)</span>
<span class="token punctuation">..</span>. <span class="token number">8</span> <span class="token function">more</span>
</code></pre> 
<p>后来发现这几个报错都有个共同点，就是任务都是在hadoop104的节点上进行的。然后在104的节点上手动跑了这个任务，确实发生了报错。<br> <img src="https://images2.imgbox.com/2c/a7/AAxIRc7Q_o.png" alt="在这里插入图片描述"><br> 查了好多资料都不知道为社么。</p> 
<h2><a id="_86"></a>解决方案二</h2> 
<p>其实当出现报错的时候，就感觉是内存太小，以至于同时跑几个脚本都跑不了。<br> 所以尝试关闭虚拟机，将虚拟机的内存由4G调升至8G。<br> 再尝试跑一下，成功</p> 
<h3><a id="hive_on_spark_91"></a>然后我们再分析下hive on spark的具体内存开销是什么样的？</h3> 
<blockquote> 
 <p>Hive on Spark：Hive既作为存储元数据又负责SQL的解析优化，语法是HQL语法，执行引擎变成了Spark，Spark负责采用RDD执行。<br> Spark on Hive : Hive只作为存储元数据，Spark负责SQL解析优化，语法是Spark SQL语法，Spark负责采用RDD执行。</p> 
</blockquote> 
<p>当运行ods_to_dwd_log.sh数据装载脚本时，会启动hive，然后经过驱动器（解析器，编译器，优化器，装载器）就会向yarn提交spark任务。<br> 当脚本执行前，jvm进程主要有Hadoop，azkaban进行<br> <img src="https://images2.imgbox.com/bc/a5/LoOeOXDn_o.png" alt="在这里插入图片描述"><br> 然后当spark任务提交时<br> <img src="https://images2.imgbox.com/71/dc/er85Qt10_o.png" alt="在这里插入图片描述"><br> 当运行任务时<br> <img src="https://images2.imgbox.com/b3/f2/Hjk0wEy4_o.png" alt="在这里插入图片描述"><br> Spark在Yarn-Cluster部署模式下，程序在提交之后会依次创建三个进程：SparkSubmit，ApplicationMaster和CoarseGrainedExecutorBackend。</p> 
<blockquote> 
 <p>Cluster 模式将用于监控和调度的 Driver 模块启动在 Yarn 集群资源中执行。一般应用于实际生产环境。<br> ➢ 在 YARN Cluster 模式下，任务提交后会和 ResourceManager 通讯申请启动ApplicationMaster，<br> ➢ 随后 ResourceManager 分配 container，在合适的 NodeManager 上启动 ApplicationMaster，此时的 ApplicationMaster 就是 Driver。<br> ➢ Driver 启动后向 ResourceManager 申请 Executor 内存，ResourceManager 接到ApplicationMaster 的资源申请后会分配 container，然后在合适的 NodeManager 上启动Executor 进程<br> ➢ Executor 进程启动后会向 Driver 反向注册，Executor 全部注册完成后 Driver 开始执行main 函数，<br> ➢ 之后执行到 Action 算子时，触发一个 Job，并根据宽依赖开始划分 stage，每个 stage 生成对应的 TaskSet，之后将 task 分发到各个 Executor 上执行。</p> 
</blockquote> 
<h3><a id="Executor_114"></a>Executor参数设置</h3> 
<p><a href="https://blog.csdn.net/prague6695/article/details/124040954?spm=1001.2014.3001.5501">参考</a><br> 在spark的的一个工作节点的上的一个jvm进程<mark>Executor</mark>，是整个集群专门用于计算的节点。在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。这里的资源一般指的是工作节点 Executor 的内存大小和使用的虚拟 CPU 核（Core）数量。</p> 
<p>应用程序相关启动参数如下：<br> <img src="https://images2.imgbox.com/4e/af/6HjXTha0_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="yarnsite_120"></a>yarn-site相关调优</h3> 
<p>/opt/module/hadoop-3.1.3/etc/hadoop/yarn-site.xml</p> 
<ol><li>调度器的选择，默认容量</li><li>ResourceManager处理调度器请求的线程数量,默认50</li><li>是否让yarn自动检测硬件进行配置，默认是false</li><li>是否将虚拟核数当作CPU核数，默认是false，采用物理CPU核数</li><li>虚拟核数和物理核数乘数，默认是1.0</li><li>NodeManager使用内存数 和 cpu核数</li><li>容器最大内存，最小内存，最小cpu核数，最大cpu核数</li><li>关闭虚拟内存检查</li><li>虚拟内存和物理内存设置比例,默认2.1</li><li>是否启动一个线程检查每个任务正使用的物理内存量，如果任务超出分配值，则直接将其杀掉，默认是 true</li><li>是否启动一个线程检查每个任务正使用的虚拟内存量，如果任务超出分配值，则直接将其杀掉，默认是 true</li></ol> 
<h3><a id="capacityscheduler_135"></a>capacity-scheduler相关调优</h3> 
<p>/opt/module/hadoop-3.1.3/etc/hadoop/capacity-scheduler.xml</p> 
<pre><code class="prism language-bash"><span class="token punctuation">[</span>atguigu@hadoop102 hadoop<span class="token punctuation">]</span>$ <span class="token function">vim</span> capacity-scheduler.xml

<span class="token operator">&lt;</span>property<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>name<span class="token operator">&gt;</span>yarn.scheduler.capacity.maximum-am-resource-percent<span class="token operator">&lt;</span>/name<span class="token operator">&gt;</span>
    <span class="token operator">&lt;</span>value<span class="token operator">&gt;</span><span class="token number">0</span>.<span class="token operator"><span class="token file-descriptor important">8</span>&lt;</span>/value<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span>/property

</code></pre> 
<p>容量调度器对每个资源队列中同时运行的Application Master占用的资源进行了限制，该限制通过yarn.scheduler.capacity.maximum-am-resource-percent参数实现，其默认值是0.1，表示每个资源队列上Application Master最多可使用的资源为该队列总资源的10%，目的是防止大部分资源都被Application Master占用，而导致Map/Reduce Task无法执行。<br> 生产环境该参数可使用默认值。但学习环境，集群资源总数很少，如果只分配10%的资源给Application Master，则可能出现，同一时刻只能运行一个Job的情况，因为一个Application Master使用的资源就可能已经达到10%的上限了。故此处可将该值适当调大</p> 
<h3><a id="JVM_151"></a>JVM相关调优</h3> 
<pre><code class="prism language-bash">ERROR hdfs.HDFSEventSink: process failed
java.lang.OutOfMemoryError: GC overhead limit exceeded

</code></pre> 
<pre><code class="prism language-bash"><span class="token builtin class-name">export</span> <span class="token assign-left variable">JAVA_OPTS</span><span class="token operator">=</span><span class="token string">"-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote"</span>
</code></pre> 
<p>JVM heap一般设置为4G或更高<br> -Xmx与-Xms最好设置一致，减少内存抖动带来的性能影响，如果设置不一致容易导致频繁fullgc。<br> -Xms表示JVM Heap（堆内存）最小尺寸，初始分配；-Xmx 表示JVM Heap(堆内存)最大允许的尺寸，按需分配。如果不设置一致，容易在初始化时，由于内存不够，频繁触发fullgc。</p> 
<h3><a id="hive_ob_spark_167"></a>hive ob spark的相关调优</h3> 
<p><img src="https://images2.imgbox.com/51/56/lgDhYiW1_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_170"></a>容量调度器的调优</h3> 
<h2><a id="_174"></a>参考</h2> 
<p><a href="https://blog.csdn.net/niuyang0066/article/details/122050157">hive-on-spark报错：org.apache.hadoop.hive.ql.parse.SemanticException:Failed to get a spark session</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/357381125#:~:text=%E7%AC%AC%E4%B8%80%E7%A7%8D%EF%BC%9A%E8%B0%83%E8%8A%82AM%E7%9A%84%E8%B5%84%E6%BA%90%E5%8D%A0%E6%AF%94%EF%BC%8C%E8%80%83%E8%99%91%E8%B0%83%E6%95%B4yarn.scheduler.capacity.maximum-am-resource-percent%E8%AF%A5%E5%8F%82%E6%95%B0%E3%80%82,%E9%BB%98%E8%AE%A4%E5%80%BC%E6%98%AF0.1%EF%BC%8C%E8%A1%A8%E7%A4%BA%E9%9B%86%E7%BE%A4%E4%B8%8AAM%E6%9C%80%E5%A4%9A%E5%8F%AF%E4%BD%BF%E7%94%A8%E7%9A%84%E8%B5%84%E6%BA%90%E6%AF%94%E4%BE%8B%EF%BC%8C%E7%9B%AE%E7%9A%84%E4%B8%BA%E9%99%90%E5%88%B6%E8%BF%87%E5%A4%9A%E7%9A%84app%E6%95%B0%E9%87%8F%E3%80%82" rel="nofollow">解决hive on spark中队列占用问题</a></p> 
<p><a href="https://blog.csdn.net/qq_22473611/article/details/105989061">Spark 中 JVM 内存使用及配置详情、spark报错与调优、Spark内存溢出OOM异常</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/dd6472b21daabdb6617d2b6391ff87bc/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">hiveservice2安装问题</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2e869125b1ca762e25300e5cff495c6a/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">OpenCV入门（九）——图像分割技术之分水岭分割</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>