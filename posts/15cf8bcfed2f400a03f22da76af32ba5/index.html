<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Requests库常用方法及参数介绍 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Requests库常用方法及参数介绍" />
<meta property="og:description" content="Requests 库中定义了七个常用的请求方法，这些方法各自有着不同的作用，在这些请求方法中 requests.get() 与 requests.post() 方法最为常用。请求方法如下所示：
方法说明requests.request()构造一个请求对象，该方法是实现以下各个方法的基础。requests.get()获取HTML网页的主要方法，对应于 HTTP 的 GET 方法。requests.head()获取HTML网页头信息的方法，对应于 HTTP 的 HEAD 方法。requests.post()获取 HTML 网页提交 POST请求方法，对应于 HTTP 的 POST。requests.put()获取HTML网页提交PUT请求方法，对应于 HTTP 的 PUT。requests.patch()获取HTML网页提交局部修改请求，对应于 HTTP 的 PATCH。requests.delete()获取HTML页面提交删除请求，对应于 HTTP 的 DELETE。 上述方法都提供了相同的参数，其中某些参数已经使用过，比如headers和params，前者用来构造请求头，后者用来构建查询字符串。这些参数对于编写爬虫程序有着至关重要的作用。本节对其他常用参数做重点介绍。
SSL认证-verify参数 SSL 证书是数字证书的一种，类似于驾驶证、护照和营业执照。因为配置在服务器上，也称为 SSL 服务器证书。SSL 证书遵守 SSL 协议，由受信任的数字证书颁发机构 CA（电子认证服务）颁发。 SSL 具有服务器身份验证和数据传输加密功能。
verify参数的作用是检查 SSL 证书认证，参数的默认值为 True，如果设置为 False 则表示不检查 SSL证书，此参数适用于没有经过 CA 机构认证的 HTTPS 类型的网站。其使用格式如下：
response = requests.get(url=url,params=params,headers=headers,verify=False) 代理IP-proxies参数 一些网站为了限制爬虫从而设置了很多反爬策略，其中一项就是针对 IP 地址设置的。比如，访问网站超过规定次数导致流量异常，或者某个时间段内频繁地更换浏览器访问，存在上述行为的 IP 极有可能被网站封杀掉。
代理 IP 就是解决上述问题的，它突破了 IP 地址的访问限制，隐藏了本地网络的真实 IP，而使用第三方 IP 代替自己去访问网站。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/15cf8bcfed2f400a03f22da76af32ba5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-29T09:52:27+08:00" />
<meta property="article:modified_time" content="2023-01-29T09:52:27+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Requests库常用方法及参数介绍</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>Requests 库中定义了七个常用的请求方法，这些方法各自有着不同的作用，在这些请求方法中 requests.get() 与 requests.post() 方法最为常用。请求方法如下所示：</p> 
<table><thead><tr><th>方法</th><th>说明</th></tr></thead><tbody><tr><td>requests.request()</td><td>构造一个请求对象，该方法是实现以下各个方法的基础。</td></tr><tr><td>requests.get()</td><td>获取HTML网页的主要方法，对应于 HTTP 的 GET 方法。</td></tr><tr><td>requests.head()</td><td>获取HTML网页头信息的方法，对应于 HTTP 的 HEAD 方法。</td></tr><tr><td>requests.post()</td><td>获取 HTML 网页提交 POST请求方法，对应于 HTTP 的 POST。</td></tr><tr><td>requests.put()</td><td>获取HTML网页提交PUT请求方法，对应于 HTTP 的 PUT。</td></tr><tr><td>requests.patch()</td><td>获取HTML网页提交局部修改请求，对应于 HTTP 的 PATCH。</td></tr><tr><td>requests.delete()</td><td>获取HTML页面提交删除请求，对应于 HTTP 的 DELETE。</td></tr></tbody></table> 
<p>上述方法都提供了相同的参数，其中某些参数已经使用过，比如<code>headers</code>和<code>params</code>，前者用来构造请求头，后者用来构建查询字符串。这些参数对于编写爬虫程序有着至关重要的作用。本节对其他常用参数做重点介绍。</p> 
<h3><a id="SSLverify_16"></a>SSL认证-verify参数</h3> 
<p>SSL 证书是数字证书的一种，类似于驾驶证、护照和营业执照。因为配置在服务器上，也称为 SSL 服务器证书。SSL 证书遵守 SSL 协议，由受信任的数字证书颁发机构 CA（电子认证服务）颁发。 SSL 具有服务器身份验证和数据传输加密功能。</p> 
<p><code>verify</code>参数的作用是检查 SSL 证书认证，参数的默认值为 True，如果设置为 False 则表示不检查 SSL证书，此参数适用于没有经过 CA 机构认证的 HTTPS 类型的网站。其使用格式如下：</p> 
<ol><li>response = requests.get(</li><li>url=url,</li><li>params=params,</li><li>headers=headers,</li><li>verify=False</li><li>)</li></ol> 
<h3><a id="IPproxies_29"></a>代理IP-proxies参数</h3> 
<p>一些网站为了限制爬虫从而设置了很多反爬策略，其中一项就是针对 IP 地址设置的。比如，访问网站超过规定次数导致流量异常，或者某个时间段内频繁地更换浏览器访问，存在上述行为的 IP 极有可能被网站封杀掉。</p> 
<p>代理 IP 就是解决上述问题的，它突破了 IP 地址的访问限制，隐藏了本地网络的真实 IP，而使用第三方 IP 代替自己去访问网站。</p> 
<h5><a id="1_IP_35"></a>1) 代理IP池</h5> 
<p>通过构建代理 IP 池可以让你编写的爬虫程序更加稳定，从 IP 池中随机选择一个 IP 去访问网站，而不使用固定的真实 IP。总之将爬虫程序伪装的越像人，它就越不容易被网站封杀。当然代理 IP 也不是完全不能被察觉，通过端口探测技等术识仍然可以辨别。其实爬虫与反爬虫永远相互斗争的，就看谁的技术更加厉害。</p> 
<h5><a id="2_proxies_39"></a>2) proxies参数</h5> 
<p>Requests 提供了一个代理 IP 参数<code>proxies</code>，该参数的语法结构如下：</p> 
<p>**</p> 
<pre><code>proxies = {
      '协议类型(http/https)':'协议类型://IP地址:端口号'
    }
</code></pre> 
<p>下面构建了两个协议版本的代理 IP，示例如下：</p> 
<p>**</p> 
<pre><code>proxies = {
   'http':'http://IP:端口号',
   'https':'https://IP:端口号'
}
</code></pre> 
<h5><a id="3_IP_62"></a>3) 代理IP使用</h5> 
<p>下面通过简单演示如何使用<code>proxies</code>参数，示例如下：</p> 
<ol><li>import requests</li><li>​</li><li>url = ‘http://httpbin.org/get’</li><li>headers = {<!-- --></li><li>‘User-Agent’:‘Mozilla/5.0’</li><li>}</li><li> <h2><a id="ip_72"></a>网上找的免费代理ip</h2> </li><li>proxies = {<!-- --></li><li>‘http’:‘http://191.231.62.142:8000’,</li><li>‘https’:‘https://191.231.62.142:8000’</li><li>}</li><li>html = requests.get(url,proxies=proxies,headers=headers,timeout=5).text</li><li>print(html)</li></ol> 
<p>输出结果：</p> 
<p>**</p> 
<pre><code>{
  "args": {},
  "headers": {
    "Accept": "*/*",
    "Accept-Encoding": "gzip, deflate",
    "Cache-Control": "max-age=259200",
    "Host": "httpbin.org",
    "User-Agent": "Mozilla/5.0",
    "X-Amzn-Trace-Id": "Root=1-605073b0-4f54db1b2d2cfc0c074a1193"
  },

  # 注意此处显示两个IP，第一个是你自己的真实IP，另外一个是对外展示的IP
  "origin": "121.17.25.194, 191.235.72.144", 
  "url": "http://httpbin.org/get"
}
</code></pre> 
<p>由于上述示例使用的是免费代理 IP，因此其质量、稳定性较差，可能会随时失效。如果想构建一个稳定的代理 IP 池，就需要花费成本。</p> 
<h5><a id="4_IP_104"></a>4) 付费代理IP</h5> 
<p>网上有许多提供代理 IP 服务的网 站，比如快代理、代理精灵、齐云代理等。这些网站也提供了相关文档说明，以及 API 接口，爬虫程序通过访问 API 接口，就可以构建自己的代理 IP 池。</p> 
<p>付费代理 IP 按照资源类型可划分为：开发代理、私密代理、隧道代理、独享代理，其中最常使用的是开放代理与私密代理。</p> 
<p><strong>开放代理：</strong> 开放代理是从公网收集的代理服务器，具有 IP 数量大，使用成本低的特点，全年超过 80% 的时间都能有 3000 个以上的代理 IP 可供提取使用。</p> 
<p><strong>私密代理：</strong> 私密代理是基于云主机构建的高品质代理服务器，为您提供高速、可信赖的网络代理服务。私密代理每天可用 IP 数量超过 20 万个，可用率在 95 %以上，1 次可提取 IP 数量超过 700 个，可以为爬虫业务提供强大的助力。</p> 
<p>付费代理的收费标准根据 IP 使用的时间长短，以及 IP 的质量高低，从几元到几百元不等。89 免费代理（<a href="http://www.89ip.cn/" rel="nofollow">http://www.89ip.cn/</a>）是一个专门提供免费代理 IP 的网站，不过想找到一个质量较高的免费代理好比大海捞针。</p> 
<h3><a id="auth_116"></a>用户认证-auth参数</h3> 
<p>Requests 提供了一个<code>auth</code>参数，该参数的支持用户认证功能，也就是适合那些需要验证用户名、密码的网站。auth 的参数形式是一个元组，其格式如下：</p> 
<p>**</p> 
<pre><code>auth = ('username','password')
</code></pre> 
<p>其使用示例如下所示：</p> 
<ol><li>class xxxSpider(object):</li><li>def <strong>init</strong>(self):</li><li>self.url = ‘http://code.tarena.com.cn/AIDCode/aid1906/13Redis/’</li><li> <h2><a id="_131"></a>网站使用的用户名，密码</h2> </li><li>self.auth = (‘c语言中文网’,‘c.biancheng.net’)</li><li>​</li><li>def get_headers(self):</li><li>headers = {‘User-Agent’:“Mozilla/5.0”}</li><li>return headers</li><li>​</li><li>def get_html(self,url):</li><li>res = requests.get(url,headers=self.get_headers(),auth=self.auth)</li><li>html = res.content</li><li>return html</li><li>…</li></ol> 
<p>如果想更多地了解关于 Requests 库的参数，可以参考官方文档：<a href="https://requests.readthedocs.io/zh_CN/latest/" rel="nofollow">https://requests.readthedocs.io/zh_CN/latest/</a></p> 
<h3><a id="Python_146"></a>零基础Python学习资源介绍</h3> 
<p><strong>👉Python学习路线汇总👈</strong></p> 
<p><strong>温馨提示</strong>：篇幅有限，已打包文件夹<strong>获取方式</strong>在：点击这里【 <a href="https://mp.weixin.qq.com/s/Cj32iIh5LBLLi4kNhupMrw" rel="nofollow"><strong><code>Python全套资料</code></strong></a>】 即可获取。</p> 
<p><img src="https://images2.imgbox.com/de/53/J8l2eZQt_o.png" alt="image.png"></p> 
<p><strong>👉Python必备开发工具👈</strong></p> 
<p><img src="https://images2.imgbox.com/40/3c/61yeARX9_o.png" alt="image.png"></p> 
<p><strong>温馨提示</strong>：篇幅有限，已打包文件夹<strong>获取方式</strong>在：点击这里【 <a href="https://mp.weixin.qq.com/s/Cj32iIh5LBLLi4kNhupMrw" rel="nofollow"><strong><code>Python全套资料</code></strong></a>】 即可获取。</p> 
<p><strong>👉Python学习视频600合集👈</strong></p> 
<p><img src="https://images2.imgbox.com/42/58/74obSU5L_o.png" alt="image.png"><br> 观看零基础学习视频，看视频学习是最快捷也是最有效果的方式，跟着视频中老师的思路，从基础到深入，还是很容易入门的。</p> 
<p><strong>👉实战案例👈</strong></p> 
<p><img src="https://images2.imgbox.com/b1/29/Dox5EVoq_o.png" alt="image.png"></p> 
<p>光学理论是没用的，要学会跟着一起敲，要动手实操，才能将自己的所学运用到实际当中去，这时候可以搞点实战案例来学习。</p> 
<p><strong>👉100道Python练习题👈检查学习结果。</strong></p> 
<p><img src="https://images2.imgbox.com/3b/ff/7hDIKZgQ_o.png" alt="image.png"></p> 
<p><strong>👉面试刷题👈</strong></p> 
<p><img src="https://images2.imgbox.com/55/63/Q89DNhAa_o.png" alt="image.png"></p> 
<p><strong>温馨提示</strong>：篇幅有限，已打包文件夹<strong>获取方式</strong>在：点击这里【 <a href="https://mp.weixin.qq.com/s/Cj32iIh5LBLLi4kNhupMrw" rel="nofollow"><strong><code>Python全套资料</code></strong></a>】 即可获取。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0d61f6618ad24b52df5557be05b74829/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【选择结构】苹果和虫子</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2d82c5d000693e00c228a243595597f9/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">教育学原理笔记-整理</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>