<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>IoU Loss综述（IOU,GIOU,CIOU,EIOU,SIOU,WIOU） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="IoU Loss综述（IOU,GIOU,CIOU,EIOU,SIOU,WIOU）" />
<meta property="og:description" content="边界框回归（BBR）的损失函数对于目标检测至关重要。它的良好定义将为模型带来显著的性能改进。大多数现有的工作假设训练数据中的样本是高质量的，并侧重于增强BBR损失的拟合能力。
一、L2-norm 最初的基于回归的BBR损失定义为L2-norm，L2-norm损失主要有两个缺点：
1、边界框的坐标（以xt、xb、xl、xr的形式）被优化为四个独立变量。这个假设违背了对象的边界高度相关的事实。简单的分开计算每个变量的回归loss无法反映这种相关性，它会导致预测框的一个或两个边界非常接近GT，但整个边界框是不满足条件的。
2、这种形式的损失函数并不能屏蔽边界框大小的干扰，使得模型对小目标的定位性能较差。
二、IoU loss 论文:《UnitBox: An Advanced Object Detection Network》
在目标检测任务中，使用IoU来测量anchor box与目标box之间的重叠程度。它以比例的形式有效地屏蔽了边界框大小的干扰，使该模型在使用1-IoU作为BBR损失时，能够很好地平衡对大物体和小物体的学习。
IoU loss的函数定义为：
当边界框没有重叠时Liou对Wi求导会等于0，即：
此时Liou的反向投影梯度消失，在训练期间无法更新重叠区域Wi的宽度。
IoU损失会有两个主要的缺点： 1、当预测框与真实框都没有交集时，计算出来的IoU都为0，损失都为1，但是缺失距离信息，预测框与GT相对位置较近时，损失函数应该较小。
2、当预测框和真实框的交并比相同，但是预测框所在位置不同，因为计算出来的损失一样，所以这样并不能判断哪种预测框更加准确。
现有的工作GIOU、DIOU、Focal EIOU、CIOU以及SIOU中考虑了许多与边界框相关的几何因子，并构造了惩罚项Ri来解决这个问题。现有的BBR损失遵循以下范例：
三、GIoU loss 论文：《Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression》
为了解决IoU loss的第一个问题，即当预测框与真实框都没有交集的时候，计算出来的IoU都为0，损失都为1，引入了一个最小闭包区的概念，即能将预测框和真实框包裹住的最小矩形框
其中紫色框为GT，蓝色框为预测框，绿色的边框则为最小包围框。
GIoU的伪代码：
与IoU相似，GIoU也是一种距离度量，IoU取值[0,1]，GIoU取值范围[-1,1]。在两者重合的时候取最大值1，在两者无交集且无限远的时候取最小值-1，因此GIoU是一个非常好的距离度量指标。与IoU只关注重叠区域不同，GIoU不仅关注重叠区域，还关注其他的非重合区域，能更好的反映两者的重合度。
但是GIoU同时也存在一些问题：
1、当预测框包裹GT时，计算的iou相同，但是质量却不同，对于预测框的中心点靠近GT中心点的情况，loss应该相对小一些
GIoU loss的定义：
四、DIoU/CIoU loss 论文：《Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression》
DIoU为了解决GIoU中存在的问题，作者认为好的检测回归loss应该考虑三个几何度量，预测框和GT框的重叠度、中心点距离、长宽比的一致性。于是在IoU loss和GIoU loss基础上引入预测框和GT框中心点距离作DIoU loss，在DIoU loss基础上引入了预测框的长宽比和GT框的长宽比之间的差异作CIoU loss。此外，将DIoU加入nms替代IoU，提升了nms的鲁棒性。
DIoU定义：
DIoU也存在一个缺点，当真实框和预测框的中心点重合时，但是长宽比不同，交并比一样，CIoU在此基础上增加一个惩罚项。
CIoU定义：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/2a9a9a43f3b376dfee83e0328e335be7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-02-09T14:53:23+08:00" />
<meta property="article:modified_time" content="2023-02-09T14:53:23+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">IoU Loss综述（IOU,GIOU,CIOU,EIOU,SIOU,WIOU）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p style="text-align:justify;">        边界框回归（BBR）的损失函数对于目标检测至关重要。它的良好定义将为模型带来显著的性能改进。大多数现有的工作假设训练数据中的样本是高质量的，并侧重于增强BBR损失的拟合能力。</p> 
<h2 style="text-align:justify;">一、L2-norm</h2> 
<p style="text-align:justify;">        最初的基于回归的BBR损失定义为L2-norm，L2-norm损失主要有两个缺点：<br> 1、边界框的坐标（以xt、xb、xl、xr的形式）被优化为四个独立变量。这个假设违背了对象的边界高度相关的事实。简单的分开计算每个变量的回归loss无法反映这种相关性，它会导致预测框的一个或两个边界非常接近GT，但整个边界框是不满足条件的。<br> 2、这种形式的损失函数并不能屏蔽边界框大小的干扰，使得模型对小目标的定位性能较差。</p> 
<h2 style="text-align:justify;">二、IoU loss</h2> 
<blockquote> 
 <p>论文:<a class="link-info" href="https://arxiv.org/pdf/1608.01471.pdf" rel="nofollow" title="《UnitBox: An Advanced Object Detection Network》">《UnitBox: An Advanced Object Detection Network》</a></p> 
</blockquote> 
<p style="text-align:justify;">        在目标检测任务中，使用IoU来测量anchor box与目标box之间的重叠程度。它以比例的形式有效地屏蔽了边界框大小的干扰，使该模型在使用1-IoU作为BBR损失时，能够很好地平衡对大物体和小物体的学习。</p> 
<p style="text-align:center;"><img alt="" height="317" src="https://images2.imgbox.com/23/07/45b5WKyP_o.png" width="630"></p> 
<p>IoU loss的函数定义为：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/cd/c5/TPnsUFpx_o.png">  </p> 
<p>当边界框没有重叠时Liou对Wi求导会等于0，即：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/40/fe/tWaLh2eW_o.png">  </p> 
<p>此时Liou的反向投影梯度消失，在训练期间无法更新重叠区域Wi的宽度。</p> 
<p>IoU损失会有两个主要的缺点： </p> 
<p>1、当预测框与真实框都没有交集时，计算出来的IoU都为0，损失都为1，但是缺失距离信息，预测框与GT相对位置较近时，损失函数应该较小。<br> 2、当预测框和真实框的交并比相同，但是预测框所在位置不同，因为计算出来的损失一样，所以这样并不能判断哪种预测框更加准确。</p> 
<p>        现有的工作GIOU、DIOU、Focal EIOU、CIOU以及SIOU中考虑了许多与边界框相关的几何因子，并构造了惩罚项Ri来解决这个问题。现有的BBR损失遵循以下范例：</p> 
<p class="img-center"><img alt="" height="83" src="https://images2.imgbox.com/ef/94/qknbMnwM_o.png" width="252"></p> 
<h2>三、GIoU loss</h2> 
<blockquote> 
 <p>论文：<a class="link-info" href="https://arxiv.org/pdf/1902.09630.pdf" rel="nofollow" title="《Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression》">《Generalized Intersection over Union: A Metric and A Loss for Bounding Box Regression》</a></p> 
</blockquote> 
<p>        为了解决IoU loss的第一个问题，即当预测框与真实框都没有交集的时候，计算出来的IoU都为0，损失都为1，引入了一个最小闭包区的概念，即能将预测框和真实框包裹住的最小矩形框</p> 
<p style="text-align:center;"><img alt="" height="320" src="https://images2.imgbox.com/0a/b8/GoF1gJ05_o.png" width="436"></p> 
<p>        其中紫色框为GT，蓝色框为预测框，绿色的边框则为最小包围框。</p> 
<p>GIoU的伪代码：</p> 
<p style="text-align:center;"><img alt="" height="282" src="https://images2.imgbox.com/67/c4/LhzLC9En_o.png" width="569"></p> 
<p style="text-align:justify;">        与IoU相似，GIoU也是一种距离度量，IoU取值[0,1]，GIoU取值范围[-1,1]。在两者重合的时候取最大值1，在两者无交集且无限远的时候取最小值-1，因此GIoU是一个非常好的距离度量指标。与IoU只关注重叠区域不同，GIoU不仅关注重叠区域，还关注其他的非重合区域，能更好的反映两者的重合度。</p> 
<p>但是GIoU同时也存在一些问题：</p> 
<p>1、当预测框包裹GT时，计算的iou相同，但是质量却不同，对于预测框的中心点靠近GT中心点的情况，loss应该相对小一些</p> 
<p>GIoU loss的定义：</p> 
<p style="text-align:center;"><img alt="" height="84" src="https://images2.imgbox.com/2c/09/IyvgzBrf_o.png" width="286"></p> 
<h2>四、DIoU/CIoU loss</h2> 
<blockquote> 
 <p>论文：<a class="link-info" href="https://arxiv.org/pdf/1911.08287.pdf" rel="nofollow" title="《Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression》">《Distance-IoU Loss: Faster and Better Learning for Bounding Box Regression》</a></p> 
</blockquote> 
<p>        DIoU为了解决GIoU中存在的问题，作者认为好的检测回归loss应该考虑三个几何度量，预测框和GT框的重叠度、中心点距离、长宽比的一致性。于是在IoU loss和GIoU loss基础上引入预测框和GT框中心点距离作DIoU loss，在DIoU loss基础上引入了预测框的长宽比和GT框的长宽比之间的差异作CIoU loss。此外，将DIoU加入nms替代IoU，提升了nms的鲁棒性。</p> 
<p style="text-align:center;"><img alt="" height="277" src="https://images2.imgbox.com/47/79/3jaGrRfA_o.png" width="492"></p> 
<p>DIoU定义：</p> 
<p class="img-center"><img alt="" height="95" src="https://images2.imgbox.com/bf/98/nl5UMkPF_o.png" width="329"></p> 
<p>        DIoU也存在一个缺点，当真实框和预测框的中心点重合时，但是长宽比不同，交并比一样，CIoU在此基础上增加一个惩罚项。</p> 
<p>CIoU定义：</p> 
<p class="img-center"><img alt="" height="100" src="https://images2.imgbox.com/c3/03/QenVguxC_o.png" width="371"></p> 
<p>其中：</p> 
<p class="img-center"><img alt="" height="108" src="https://images2.imgbox.com/11/30/N8DPTysk_o.png" width="354"></p> 
<p>        v用于计算预测框和目标框的高宽比的一致性，这里是用tan角来衡量 </p> 
<p class="img-center"><img alt="" height="97" src="https://images2.imgbox.com/b6/26/zBohjKr9_o.png" width="209"></p> 
<p>        α是一个平衡参数（这个系数不参与梯度计算），这里根据IoU值来赋予优先级，当预测框和目标框IoU越大时，系数越大 。</p> 
<h2>五、<strong>EIoU Loss/Focal EIoU Loss</strong></h2> 
<blockquote> 
 <p>论文：<a class="link-info" href="https://arxiv.org/pdf/2101.08158.pdf" rel="nofollow" title="Focal and Efficient IOU Loss for Accurate Bounding Box Regression》">Focal and Efficient IOU Loss for Accurate Bounding Box Regression》</a></p> 
</blockquote> 
<p> 主要思想：</p> 
<p>        一是认为CIoU loss对于长宽比加入loss的设计不太合理，于是将CIoU loss中反应长宽比一致性的部分替换成了分别对于长和宽的一致性loss，形成了EIoU loss。</p> 
<p>        二是认为不太好的回归样本对回归loss产生了比较大的影响，回归质量相对较好的样本则难以进一步优化，所以论文提出Focal EIoU loss进行回归质量较好和质量较差的样本之间的平衡。</p> 
<p>EIoU loss定义：</p> 
<p class="img-center"><img alt="" height="136" src="https://images2.imgbox.com/eb/2d/EXtVJO7V_o.png" width="613"></p> 
<p> 其中hc和wc为最小包围框的高和宽。</p> 
<p>       要平衡回归质量较好的样本的偏小loss和回归质量较差的样本的偏大loss，很自然的，选择和GT的IoU形成类似focal loss中的(1-p)的γ次方的权重来调节是一个很好的想法。</p> 
<p>Focal EIoU loss定义：</p> 
<p class="img-center"><img alt="" height="87" src="https://images2.imgbox.com/c9/29/e8L7pEZI_o.png" width="312"></p> 
<p>最终形式：</p> 
<p class="img-center"><img alt="" height="61" src="https://images2.imgbox.com/47/ea/VhaB1Y9T_o.png" width="380"></p> 
<p>指标对比：</p> 
<p class="img-center"><img alt="" height="404" src="https://images2.imgbox.com/f1/42/BISxQAEv_o.png" width="715"></p> 
<h2>六、SIoU loss</h2> 
<blockquote> 
 <p>论文：<a class="link-info" href="https://arxiv.org/ftp/arxiv/papers/2205/2205.12740.pdf" rel="nofollow" title="《SIoU Loss: More Powerful Learning for Bounding Box Regression》">《SIoU Loss: More Powerful Learning for Bounding Box Regression》</a></p> 
</blockquote> 
<p style="text-align:justify;">        已有方法匹配真实框和预测框之间的IoU、中心点距离、宽高比等，它们均未考虑真实框和预测框之间不匹配的方向。这种不足导致收敛速度较慢且效率较低，因为预测框可能在训练过程中“徘徊”，最终生成更差的模型。</p> 
<p style="text-align:justify;">        本文提出了一种新的损失函数SCYLLA-IoU（SIoU），考虑到期望回归之间向量的角度，重新定义角度惩罚度量，它可以使预测框快速漂移到最近的轴，随后则只需要回归一个坐标（X或Y），这有效地减少了自由度的总数。</p> 
<p>        Zhora证明了中心对准anchor box具有更快的收敛速度，并根据角度成本、距离成本和形状成本构造了SIoU。</p> 
<p class="img-center"><img alt="" height="256" src="https://images2.imgbox.com/93/50/w2bbwcRX_o.png" width="782"></p> 
<p style="text-align:justify;">        <strong>Angle cost</strong>描述了中心点连接（图1）与x-y轴之间的最小角度，当中心点在x轴或y轴上对齐时，Λ = 0。当中心点连接到x轴45°时，Λ = 1。这一惩罚可以引导anchor box移动到目标框的最近的轴上，减少了BBR的总自由度数。</p> 
<p class="img-center"><img alt="" height="126" src="https://images2.imgbox.com/43/aa/tfGdBkR7_o.png" width="356"></p> 
<p style="text-align:justify;">        <strong>Distance cost</strong>描述了中心点之间的距离，其惩罚代价与角度代价呈正相关，当𝛼→0时，Distance cost的贡献大大降低。相反，𝛼越接近pi/4，Distance cost贡献越大。</p> 
<p style="text-align:justify;">具体来说：以X轴为例，即两框近乎平行时，a趋近于0，这样计算出来两框之间的角度距离接近于0，此时γ也接近于2，那么两框之间的距离对于整体loss的贡献变少了。而当a趋近与45°时，计算出来两框之间的角度为1，此时γ接近1，则两框之间的距离应该被重视，需要占更大的loss。</p> 
<p class="img-center"><img alt="" height="155" src="https://images2.imgbox.com/88/fc/EOtBY6Wu_o.png" width="302"></p> 
<p style="text-align:justify;"><strong>        Shape cost</strong>这里作者考虑的两框之间的长宽比，是通过计算两框之间宽之差和二者之间最大宽之比（长同理）来定义的，大体思路和CIOU类似，只不过CIOU可以的考虑是两框整体形状的收敛，而SIoU是以长、宽两个边收敛来达到整体形状收敛的效果。</p> 
<p style="text-align:justify;">        θ是个可调变量，来表示网络需要对形状这个，给予多少注意力，即占多少权重。实验中设置为4。</p> 
<p>SIoU loss定义：</p> 
<p class="img-center"><img alt="" height="160" src="https://images2.imgbox.com/74/3a/LhCLrNz2_o.png" width="251"></p> 
<h2>七、WIoU loss</h2> 
<blockquote> 
 <p> 论文：<a class="link-info" href="https://arxiv.org/pdf/2301.10051v1.pdf" rel="nofollow" title="《Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism》">《Wise-IoU: Bounding Box Regression Loss with Dynamic Focusing Mechanism》</a></p> 
</blockquote> 
<p>        Focal EIoU v1被提出来解决质量较好和质量较差的样本间的BBR平衡问题，但由于其静态聚焦机制（FM），非单调FM的潜力没有被充分利用，基于这一思想，作者提出了一种基于IoU的损失，该损失具有动态非单调FM，名为Wise IoU（WIoU）。</p> 
<p style="text-align:justify;">主要贡献总结如下：</p> 
<ol><li> <p style="text-align:justify;">提出了BBR的基于注意力的损失WIoU v1，它在仿真实验中实现了比最先进的SIoU更低的回归误差。</p> </li><li> <p style="text-align:justify;">设计了具有单调FM的WIoU v2和具有动态非单调FM的WIoU v3。利用动态非单调FM的明智的梯度增益分配策略，WIoU v3获得了优越的性能。</p> </li><li> <p style="text-align:justify;">对低质量的样本的影响进行了一系列详细的研究，证明了动态非单调调频的有效性和效率。</p> </li></ol> 
<p style="text-align:justify;">        由于训练数据不可避免地包含低质量示例，几何因素（如距离和纵横比）将加重对低质量示例的惩罚，从而降低模型的泛化性能。当anchor box与目标box很好地重合时，一个好的损失函数应该会削弱几何因素的惩罚，而较少的训练干预将使模型获得更好的泛化能力。</p> 
<p>WIoU loss定义：</p> 
<p class="img-center"><img alt="" height="139" src="https://images2.imgbox.com/78/9f/B2ZKLKjU_o.png" width="552"></p> 
<p style="text-align:justify;">        其中Wg，Hg表示最小包围框的宽和高。为了防止Rwiou产生阻碍收敛的梯度，Wg和Hg从计算图中分离出来（上标*表示此操作）。因为它有效地消除了阻碍收敛的因素，所以没有引入新的度量，例如纵横比。</p> 
<p style="text-align:justify;">1、Rwiou∈[1,e),这将显著放大普通质量anchor box的LIoU。 </p> 
<p style="text-align:justify;">2、Liou∈[0,1]，这将显著降低高质量anchor box的Rwiou，并在anchor box与目标框重合时，重点关注中心点之间的距离。</p> 
<p style="text-align:justify;">消融实验的结果：</p> 
<p class="img-center"><img alt="" height="449" src="https://images2.imgbox.com/3c/c4/uARxkRnH_o.png" width="681"></p> 
<p>        从消融实验的结果可以看出WIoU v3的效果最好。</p> 
<h2>代码</h2> 
<p>        上述的IoU loss的实现可以参看我的另一篇文章：<a class="link-info" href="https://blog.csdn.net/athrunsunny/article/details/128862478?spm=1001.2014.3001.5502" title="yolov5增加iou loss，无痛涨点trick">yolov5增加iou loss，无痛涨点trick</a></p> 
<p></p> 
<p></p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/16fab371e18d7df2ab146ae9e45c9c73/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vs code代码格式化配置</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d335dd7ab4c2807bac7b501b4e86077e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">协方差、协方差矩阵、马氏距离与欧式距离的理解</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>