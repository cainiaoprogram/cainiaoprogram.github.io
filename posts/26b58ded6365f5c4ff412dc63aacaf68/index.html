<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CNN卷积神经网络 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CNN卷积神经网络" />
<meta property="og:description" content="CNN卷积神经网络 前言一、相关概念卷积彩色图像卷积池化paddingDropout正则化局部归一化 二、经典网络AlexNetVGGNet介绍GoogLeNetResNet介绍resnet解决方案结果 三、实操一般步骤结构举例代码链接 前言 为什么用卷积神经网络
全连接神经网络问题
参数过多过拟合需要更多数据收敛到较差的局部极值 卷积神经网络
局部连接参数共享 提示：以下是本篇文章正文内容，下面案例可供参考
一、相关概念 卷积 彩色图像卷积 池化 最大池化平均池化 padding 每次卷积图像都会缩小，层数越多，缩小的越多。
边沿的像素会被忽略
padding大小
n&#43;2p-f&#43;1=npadding 类型
valid
same如果有步长则
（n-f)/S&#43;1&#43;2p=n Dropout正则化 目的
减少过拟合方法
在一次训练时的迭代中，对每一层中的神经元（总数为N）以概率P随机剔除，用余下的（1-P）×N个神经元所构成的网络来训练本次迭代中的数据。
一般来说对于CNN，Dropout仅在池化层后使用
局部归一化 LRN ( Local Response Normalization) 局部响应归一化
二、经典网络 AlexNet 作者：
– Alex Krizhevsky2012 ILSVRC（ImageNet Large Scale Visual Recognition Challenge）竞赛的冠军网络
– 分类准确率从传统的74%提升到84%
– top-5错误率16.4%
亮点：首次使用了GPU进行网络加速训练
– 使用了ReLU 激活函数，而不是传统的sigmoid和tanh
– 在全连接层前两层使用了Dropout，减少过拟合
– 局部归一化（Local Response Normalization，简称LRN） VGGNet介绍 VGGNet由牛津大学计算机视觉组合和Google DeepMind公司研究员一起研发的深度卷积神经网络成绩：
ILSVRC 2014年比赛的亚军和定位项目的冠军
将 Top-5错误率降到7." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/26b58ded6365f5c4ff412dc63aacaf68/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-12-22T01:24:59+08:00" />
<meta property="article:modified_time" content="2022-12-22T01:24:59+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CNN卷积神经网络</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>CNN卷积神经网络</h4> 
 <ul><li><a href="#_5" rel="nofollow">前言</a></li><li><a href="#_23" rel="nofollow">一、相关概念</a></li><li><ul><li><a href="#_24" rel="nofollow">卷积</a></li><li><a href="#_26" rel="nofollow">彩色图像卷积</a></li><li><a href="#_29" rel="nofollow">池化</a></li><li><a href="#padding_36" rel="nofollow">padding</a></li><li><a href="#Dropout_47" rel="nofollow">Dropout正则化</a></li><li><a href="#_54" rel="nofollow">局部归一化</a></li></ul> 
  </li><li><a href="#_62" rel="nofollow">二、经典网络</a></li><li><ul><li><a href="#AlexNet_63" rel="nofollow">AlexNet</a></li><li><a href="#VGGNet_76" rel="nofollow">VGGNet介绍</a></li><li><a href="#GoogLeNet_93" rel="nofollow">GoogLeNet</a></li><li><a href="#ResNet_108" rel="nofollow">ResNet介绍</a></li><li><ul><li><a href="#resnet_120" rel="nofollow">resnet解决方案</a></li><li><a href="#_124" rel="nofollow">结果</a></li></ul> 
  </li></ul> 
  </li><li><a href="#_130" rel="nofollow">三、实操一般步骤结构</a></li><li><ul><li><a href="#_132" rel="nofollow">举例</a></li><li><a href="#_134" rel="nofollow">代码链接</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_5"></a>前言</h2> 
<p>为什么用卷积神经网络</p> 
<p>全连接神经网络问题</p> 
<ul><li>参数过多</li><li>过拟合</li><li>需要更多数据</li><li>收敛到较差的局部极值</li></ul> 
<p>卷积神经网络</p> 
<ul><li>局部连接</li><li>参数共享</li></ul> 
<hr> 
<p><code>提示：以下是本篇文章正文内容，下面案例可供参考</code></p> 
<h2><a id="_23"></a>一、相关概念</h2> 
<h3><a id="_24"></a>卷积</h3> 
<p><img src="https://images2.imgbox.com/eb/f0/Py8UPQXV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_26"></a>彩色图像卷积</h3> 
<p><img src="https://images2.imgbox.com/fc/bb/aIqt7q0q_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0a/47/2Bc3XCnq_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_29"></a>池化</h3> 
<ul><li>最大池化</li><li><img src="https://images2.imgbox.com/74/9b/WzLAEgB1_o.png" alt="在这里插入图片描述"></li><li>平均池化</li><li><img src="https://images2.imgbox.com/55/6e/L2zY0muY_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="padding_36"></a>padding</h3> 
<p>每次卷积图像都会缩小，层数越多，缩小的越多。<br> 边沿的像素会被忽略</p> 
<ul><li>padding大小<br> n+2p-f+1=n</li><li>padding 类型<br> valid<br> same</li><li>如果有步长则<br> （n-f)/S+1+2p=n</li></ul> 
<h3><a id="Dropout_47"></a>Dropout正则化</h3> 
<ul><li>目的<br> 减少过拟合</li><li>方法<br> 在一次训练时的迭代中，对每一层中的神经元（总数为N）以概率P随机剔除，用余下的（1-P）×N个神经元所构成的网络来训练本次迭代中的数据。<br> 一般来说对于CNN，Dropout仅在池化层后使用<br> <img src="https://images2.imgbox.com/ab/13/1kn8BwWa_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="_54"></a>局部归一化</h3> 
<p><img src="https://images2.imgbox.com/54/e6/qorkXzKL_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ce/22/7IX4dczo_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/49/16/7bOavtDM_o.png" alt="在这里插入图片描述"><br> LRN ( Local Response Normalization) 局部响应归一化<br> <img src="https://images2.imgbox.com/42/98/1RIv7jnw_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_62"></a>二、经典网络</h2> 
<h3><a id="AlexNet_63"></a>AlexNet</h3> 
<ul><li>作者：<br> – Alex Krizhevsky</li><li>2012 ILSVRC（ImageNet Large Scale Visual Recognition Challenge）竞赛的冠军网络<br> – 分类准确率从传统的74%提升到84%<br> – top-5错误率16.4%<br> 亮点：</li><li>首次使用了GPU进行网络加速训练<br> – 使用了ReLU 激活函数，而不是传统的sigmoid和tanh<br> – 在全连接层前两层使用了Dropout，减少过拟合<br> – 局部归一化（Local Response Normalization，简称LRN）</li></ul> 
<p><img src="https://images2.imgbox.com/96/27/ThbliwnT_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="VGGNet_76"></a>VGGNet介绍</h3> 
<ul><li>VGGNet由牛津大学计算机视觉组合和Google DeepMind公司研究员一起研发的深度卷积神经网络</li><li>成绩：<br> ILSVRC 2014年比赛的亚军和定位项目的冠军<br> 将 Top-5错误率降到7.3%</li><li>特点：<br> – 小卷积核和多卷积子层<br> — 3<em>3<br> – 小池化核<br> — 2</em>2<br> weight初始赋值<br> 小型的VGG :正态分布<br> 大型的VGG: 从已经训练好的小型VGG中拷贝过去<br> input图像处理<br> [256;512]<br> <img src="https://images2.imgbox.com/36/53/kxOVpfY8_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/6b/cb/e4u2LOp8_o.png" alt="在这里插入图片描述"></li></ul> 
<h3><a id="GoogLeNet_93"></a>GoogLeNet</h3> 
<ul><li>谷歌团队创建<br> 成绩：<br> 2014 ILSVRC2014比赛中取得冠军<br> 22层神经网络达到top-5错误率6.7%</li><li>亮点<br> 所用模型参数不足AlexNet（2012年冠军）的1/12<br> Inception结构<br> 丢弃全连接层，使用平均池化层（大大的减少了模型参数）<br> 添加了两个辅助分类器帮助训练<br> 使用1X1卷积核进行降维以及映射<br> <img src="https://images2.imgbox.com/a6/cc/r2GQnm8l_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/04/04/aI1Umhv5_o.png" alt="在这里插入图片描述"></li></ul> 
<p><img src="https://images2.imgbox.com/6f/32/7IJlnz4z_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="ResNet_108"></a>ResNet介绍</h3> 
<ul><li>ResNet（Residual Neural Network）由微软研究院的Kaiming He等四名华人提出</li><li>成绩：<br> 2015 ILSVRC2015比赛中取得冠军<br> 152层神经网络top5上的错误率为3.57%<br> 同时参数量比VGGNet低<br> <img src="https://images2.imgbox.com/f4/cb/0GHwZkzr_o.png" alt="在这里插入图片描述"><br> 发现层数越多反而效果不i好<br> <img src="https://images2.imgbox.com/b1/e7/7D4Mrjq0_o.png" alt="在这里插入图片描述"></li></ul> 
<p>原因：梯度消失<br> <img src="https://images2.imgbox.com/12/4e/e4He9ChN_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="resnet_120"></a>resnet解决方案</h4> 
<p><img src="https://images2.imgbox.com/2e/27/qoN5GImr_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/f1/92/hrBgCL8N_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/93/b9/PzulR0Wc_o.png" alt="在这里插入图片描述"></p> 
<h4><a id="_124"></a>结果</h4> 
<p><img src="https://images2.imgbox.com/f2/8e/IMYneuAg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/02/e9/deK7nkpW_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a9/c4/Clj5CKOT_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_130"></a>三、实操一般步骤结构</h2> 
<p><img src="https://images2.imgbox.com/0e/aa/xfrIAbD9_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_132"></a>举例</h3> 
<p><img src="https://images2.imgbox.com/d5/0c/1C51CcIV_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="_134"></a>代码链接</h3> 
<p><a href="https://github.com/anglersking/simple_deep_learning/tree/master/CNN">https://github.com/anglersking/simple_deep_learning/tree/master/CNN</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/70bd35d58b29514db1e82c29464c599e/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">1.CSS-属性和选择器</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d94fd8b5f6ccc94c5d41f0ccbb734bce/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">git diff 命令6种使用场景</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>