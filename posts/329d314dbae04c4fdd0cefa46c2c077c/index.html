<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【EAI 006】ChatGPT for Robotics：将 ChatGPT 应用于机器人任务的提示词工程研究 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【EAI 006】ChatGPT for Robotics：将 ChatGPT 应用于机器人任务的提示词工程研究" />
<meta property="og:description" content="论文标题：ChatGPT for Robotics: Design Principles and Model Abilities
论文作者：Sai Vemprala, Rogerio Bonatti, Arthur Bucker, Ashish Kapoor
作者单位：Scaled Foundations, Microsoft Autonomous Systems and Robotics Research
论文原文：https://arxiv.org/abs/2306.17582
论文出处：TMLR
论文被引：148（01/05/2024）
论文代码：https://github.com/microsoft/PromptCraft-Robotics，1.6k star
项目主页：http://aka.ms/ChatGPT-Robotics
Abstract 本文介绍了一项关于将 OpenAI 的 ChatGPT [1] 用于机器人应用的实验研究。我们概述了一种策略，该策略结合了提示工程的设计原则和高级函数库的创建，使 ChatGPT 能够适应不同的机器人任务，模拟器和外形因素（form factors）。我们重点评估了不同提示工程技术和对话策略在执行各类机器人任务时的有效性。除了使用特定任务的提示功能和通过对话进行闭环推理之外，我们还探索了 ChatGPT 使用自由形式对话，解析 XML 标记和合成代码的能力。我们的研究涵盖了机器人领域的一系列任务，从基本的逻辑，几何和数学推理一直到复杂的领域，如空中导航，操纵和具身Agent。我们的研究表明，ChatGPT 可以有效地解决其中几项任务，同时允许用户主要通过自然语言指令与之交互。除了这些研究之外，我们还介绍了一个名为 PromptCraft 的开源研究工具，其中包含一个平台，研究人员可以通过该平台合作上传并投票选出机器人应用中的优秀提示方案示例，以及一个集成了 ChatGPT 的机器人模拟器示例，使用户更容易开始将 ChatGPT 用于机器人。
1. Introduction 自然语言处理（NLP）技术的飞速发展带动了大型语言模型（LLM）的发展，如 BERT [2]，GPT-3 [3] 和 Codex [4]，它们正在为广泛的应用带来变革。这些模型在文本生成，机器翻译和代码合成等各种任务中取得了令人瞩目的成果。OpenAI ChatGPT [1]是这一系列模型中的最新成员，它是一个预训练的文本生成模型，并通过人类反馈进行了微调。与之前主要在单一提示下运行的模型不同，ChatGPT 通过对话提供了特别令人印象深刻的交互技能，将文本生成与代码合成相结合。我们在本文中的目标是研究 ChatGPT 的能力能否以及如何推广到机器人领域。
与纯文字应用不同，机器人系统需要深入了解现实世界的物理学，环境背景以及执行物理动作的能力。生成式机器人模型需要具备强大的常识性知识和复杂的世界模型，并能与用户互动，以物理上可行且在现实世界中合理的方式解释和执行命令。这些挑战超出了语言模型的原有范围，因为它们不仅要理解给定文本的含义，还要将意图转化为符合逻辑顺序的物理动作。
近年来，人们一直在尝试将语言融入机器人系统。这些努力主要集中在使用语言标记嵌入模型，LLM 特征和多模式模型特征，以适应特定的形式因素或场景。应用范围包括：
视觉语言导航[5, 6]基于语言的人机交互[7, 8]视觉语言操纵控制[9, 10, 11] 然而，尽管在机器人技术中使用 LLMs 具有潜在的优势，但大多数现有方法都受到了严格的范围和有限的函数集（limited set of functionalities）的限制，或者由于其开环性质，无法进行流畅的交互，也无法根据用户反馈修正行为。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/329d314dbae04c4fdd0cefa46c2c077c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-01-08T00:25:32+08:00" />
<meta property="article:modified_time" content="2024-01-08T00:25:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【EAI 006】ChatGPT for Robotics：将 ChatGPT 应用于机器人任务的提示词工程研究</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>论文标题：ChatGPT for Robotics: Design Principles and Model Abilities<br> 论文作者：Sai Vemprala, Rogerio Bonatti, Arthur Bucker, Ashish Kapoor<br> 作者单位：Scaled Foundations, Microsoft Autonomous Systems and Robotics Research<br> 论文原文：https://arxiv.org/abs/2306.17582<br> 论文出处：TMLR<br> 论文被引：148（01/05/2024）<br> 论文代码：https://github.com/microsoft/PromptCraft-Robotics，1.6k star<br> 项目主页：http://aka.ms/ChatGPT-Robotics</p> 
</blockquote> 
<h2><a id="Abstract_9"></a>Abstract</h2> 
<p>本文介绍了一项关于将 OpenAI 的 ChatGPT [1] 用于机器人应用的实验研究。<strong>我们概述了一种策略，该策略结合了提示工程的设计原则和高级函数库的创建，使 ChatGPT 能够适应不同的机器人任务，模拟器和外形因素（form factors）</strong>。我们重点评估了不同提示工程技术和对话策略在执行各类机器人任务时的有效性。除了使用特定任务的提示功能和通过对话进行闭环推理之外，我们还探索了 ChatGPT 使用自由形式对话，解析 XML 标记和合成代码的能力。我们的研究涵盖了机器人领域的一系列任务，从基本的逻辑，几何和数学推理一直到复杂的领域，如空中导航，操纵和具身Agent。我们的研究表明，ChatGPT 可以有效地解决其中几项任务，同时允许用户主要通过自然语言指令与之交互。除了这些研究之外，我们还介绍了一个名为 PromptCraft 的开源研究工具，其中包含一个平台，研究人员可以通过该平台合作上传并投票选出机器人应用中的优秀提示方案示例，以及一个集成了 ChatGPT 的机器人模拟器示例，使用户更容易开始将 ChatGPT 用于机器人。</p> 
<h2><a id="1_Introduction_13"></a>1. Introduction</h2> 
<p>自然语言处理（NLP）技术的飞速发展带动了大型语言模型（LLM）的发展，如 BERT [2]，GPT-3 [3] 和 Codex [4]，它们正在为广泛的应用带来变革。这些模型在文本生成，机器翻译和代码合成等各种任务中取得了令人瞩目的成果。OpenAI ChatGPT [1]是这一系列模型中的最新成员，它是一个预训练的文本生成模型，并通过人类反馈进行了微调。<strong>与之前主要在单一提示下运行的模型不同，ChatGPT 通过对话提供了特别令人印象深刻的交互技能，将文本生成与代码合成相结合。我们在本文中的目标是研究 ChatGPT 的能力能否以及如何推广到机器人领域</strong>。</p> 
<p>与纯文字应用不同，机器人系统需要深入了解现实世界的物理学，环境背景以及执行物理动作的能力。生成式机器人模型需要具备强大的常识性知识和复杂的世界模型，并能与用户互动，以物理上可行且在现实世界中合理的方式解释和执行命令。这些挑战超出了语言模型的原有范围，因为它们不仅要理解给定文本的含义，还要将意图转化为符合逻辑顺序的物理动作。</p> 
<p>近年来，人们一直在尝试将语言融入机器人系统。这些努力主要集中在<strong>使用语言标记嵌入模型，LLM 特征和多模式模型特征，以适应特定的形式因素或场景</strong>。应用范围包括：</p> 
<ul><li>视觉语言导航[5, 6]</li><li>基于语言的人机交互[7, 8]</li><li>视觉语言操纵控制[9, 10, 11]</li></ul> 
<p>然而，尽管在机器人技术中使用 LLMs 具有潜在的优势，但<strong>大多数现有方法都受到了严格的范围和有限的函数集（limited set of functionalities）的限制，或者由于其开环性质，无法进行流畅的交互，也无法根据用户反馈修正行为</strong>。</p> 
<p>GPT-3，LaMDA 和 Codex 等模型也显示了在零样本机器人场景中执行高级Agent规划 [12, 13] 或代码生成 [14, 15] 任务的前景。这些早期演示启发我们研究 ChatGPT，将其作为机器人领域一种潜在的多功能工具，因为它结合了自然语言和代码生成模型的优势以及对话的灵活性。ChatGPT 能够进行自由形式的对话并捕捉长时间的上下文，因此用户能以更自然的方式与模型进行交互，并能灵活地纠正行为。</p> 
<p><img src="https://images2.imgbox.com/8a/78/qvnff6CR_o.png" alt="在这里插入图片描述"></p> 
<p>本文旨在展示 ChatGPT 在机器人应用方面的潜力。<strong>我们概述了利用 ChatGPT 解决机器人应用问题的一个关键概念，即创建一个高级函数库</strong>。鉴于机器人技术是一个多样化的领域，存在多种平台，应用场景和工具，因此有各种各样的库和API。我们没有要求 LLM 输出特定于平台或库的代码，这可能会涉及大量的微调，相反，<strong>我们创建了一个简单的高级函数库供 ChatGPT 处理，然后可以在后端链接到所选平台的实际 API</strong>。因此，我们允许 ChatGPT 从自然对话中解析用户意图，并将其转换为高级函数调用的逻辑链。我们还概述了几条有助于 ChatGPT 解决机器人任务的提示性工程指南。</p> 
<p>我们的研究表明，ChatGPT 能够以零样本的方式解决各种与机器人相关的任务，同时适应多种外形因素，并允许通过对话进行闭环推理（closed-loop reasoning）。此外，我们还旨在展示当前模型的局限性，并就如何克服这些局限性提出想法。我们的主要贡献如下：</p> 
<ul><li>我们展示了将 ChatGPT 应用于机器人任务的流程。该流程涉及多种提示技术，如自由形式的自然语言对话，代码提示，XML 标记和闭环推理。我们还展示了用户如何<strong>利用高级函数库，让模型快速解析人类意图并生成解决问题的代码</strong>；</li><li>我们通过实验评估了 ChatGPT 执行各种机器人任务的能力。我们展示了该模型在解决数学，逻辑和几何运算时的能力和局限性，然后探索了涉及具身Agent，空中导航和操纵的更复杂场景。我们还包括 ChatGPT 计划的模拟和实际实验；</li><li>我们推出了一个协作式开源平台 PromptCraft，研究人员可以在该平台上合作，提供在机器人环境中使用 LLM 时积极（和消极）提示策略的示例。提示工程主要是一门经验科学，我们希望为研究人员提供一个简单的界面，让他们作为一个社区贡献知识。随着时间的推移，我们的目标是提供不同的环境，让用户可以测试他们的提示，并欢迎新的贡献；</li><li>我们发布了一款基于微软 AirSim [16] 并与 ChatGPT 集成的模拟工具。AirSim-ChatGPT 仿真包含一个无人机导航环境示例，旨在为研究人员探索 ChatGPT 如何实现机器人应用场景提供一个起点。</li></ul> 
<p>我们希望通过这项工作，为未来将 LLM 与机器人技术相结合的研究开辟新的机遇和途径。我们相信，我们的研究成果将激励和指导这一激动人心的领域的进一步研究，为开发能够以自然，直观的方式与人类互动的新型，创新机器人系统铺平道路。欲了解更多详情，我们鼓励读者在项目网页上观看我们的详细实验视频：https://aka.ms/ChatGPT-robotics。</p> 
<h2><a id="2_Robotics_with_ChatGPT_43"></a>2. Robotics with ChatGPT</h2> 
<p>在机器人控制中提示 LLMs 会带来一些挑战，例如提供完整准确的问题描述，确定正确的允许函数调用和 API 集，以及用特殊参数调整答案结构。为了在机器人应用中有效利用 ChatGPT，我们构建了一个由以下步骤组成的流水线：</p> 
<ol><li>首先，我们定义一个高级机器人函数库。</li><li>接下来，我们为 ChatGPT 创建一个提示，在描述目标的同时，确定库中允许使用的高级函数集。<strong>提示中还可以包含约束信息，或 ChatGPT 应如何构建其响应结构的信息</strong>。</li><li>用户可以通过直接分析或模拟的方式，继续循环评估 ChatGPT 输出的代码，并就输出代码的质量和安全性向 ChatGPT 提供反馈。</li><li>在对 ChatGPT 生成的实现进行迭代后，可将最终代码部署到机器人上。</li></ol> 
<p>图 2 以家用机器人为例，形象地描述了这一流程。</p> 
<p><img src="https://images2.imgbox.com/97/4d/wLZuCqVC_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="21_Construction_and_description_of_the_robotics_API_library_57"></a>2.1. Construction and description of the robotics API library</h3> 
<p>机器人技术是一个成熟的领域，目前已有大量黑盒或开源库，可用于感知和动作领域的基本功能（如物体检测和分割，映射，运动规划，控制和抓取）。如果在提示中正确指定，LLM 就能使用这些预定义的函数进行机器人推理和执行。</p> 
<p><strong>一个重要的提示设计要求是，所有API的名称必须能够描述整体功能行为。要让 LLM 能够推理出 API 之间的功能联系，并为问题生成所需的结果，明确的名称是必不可少的</strong>。因此，我们可以定义高级函数，将其作为各自库中实际实现的封装器。例如，名为 <code>detect_object(object_name)</code> 的函数可以内部链接到 OpenCV 函数或计算机视觉模型，而类似 <code>move_to(x,y,z)</code> 的函数则可以内部调用运动规划和避障管道以及无人机的相应底层电机指令。<strong>在提示中列出这样一组高级函数，对于 ChatGPT 创建行为基元的逻辑序列，以及泛化到不同场景和平台至关重要</strong>。</p> 
<p><img src="https://images2.imgbox.com/92/fc/KhaVcA1i_o.png" alt="在这里插入图片描述"></p> 
<p>根据具体情况，我们建议解释API的功能，并在必要时将其分解为具有明确输入和输出的子组件，类似于代码文档。在图 3 中，我们以家庭烹饪机器人为例，介绍了一种良好的 API 提示策略。该策略允许 ChatGPT 根据机器人实际能够执行的函数来推理任务的顺序和内容。感兴趣的读者参阅附录 A.1，以了解 ChatGPT 在未提供 API 指导时如何进行推理，这将导致基于文本的无限制回答；或参阅附录 A.2，以了解 API 不够清晰时的情况，这将导致对函数调用参数产生幻觉。</p> 
<p>我们注意到，经典的符号人工智能结构脆弱，需要在物体和函数之间预先定义严格的关系，而 LLM 与之不同，当与特定问题相关时，它能够完全定义新的函数和概念。在处理机器人应用时，这种能力赋予了 LLM 灵活性和稳健性。图 4 显示了 ChatGPT 如何在需要解决问题时创建新的高级概念，甚至低级代码，甚至融合现有的API。环路上的用户可以将这种能力作为一种设计策略加以利用，当目前的API不足以解决手头的任务时，可以在 LLM 的帮助下反复定义新的API。</p> 
<p><img src="https://images2.imgbox.com/bf/e8/Jsoq8qqp_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="22_Clear_description_of_the_task_details_in_the_prompt_73"></a>2.2. Clear description of the task details in the prompt</h3> 
<p>通过对所需机器人任务及其上下文进行简明扼要的描述，ChatGPT 可以生成更准确的回复。除了机器人API外，一个好的上下文描述还应包含以下内容：</p> 
<ul><li> <p>限制和要求：指定与任务相关的限制或要求。如果任务涉及移动物体，可以指定要移动的物体的重量，大小和形状。</p> </li><li> <p>环境：描述机器人任务所处的环境。例如，如果任务是在迷宫中导航，可以描述迷宫的大小和形状，以及需要避开的任何障碍或危险。</p> </li><li> <p>当前状态：描述机器人系统的当前状态。例如，如果任务是拾取一个物体，可以描述机器人和物体的当前位置和方向。</p> </li><li> <p>目标和目的：说明任务的目标和目的。如果任务是组装拼图，可以说明需要组装的拼图块数和预期完成时间。</p> </li><li> <p>解决方案示例：演示如何解决类似任务，以此指导 LLM 的解决策略。例如，如果任务涉及与用户的互动，我们可以举例说明机器人应如何以及何时询问用户的输入（见图 5）。需要注意的是，<strong>引子也会带来偏差，因此我们应该提供多种多样的示例，避免使用规定性过强的语言</strong>。</p> </li></ul> 
<p><img src="https://images2.imgbox.com/61/a7/JxZK0VQV_o.png" alt="在这里插入图片描述"></p> 
<p><strong>即使是精心设计的提示也可能不包含解决问题所需的所有必要信息，或者在某些情况下 ChatGPT 无法以 zero-shot 的方式生成正确的回复。在这种情况下，我们发现用户可以采取一种简单而有效的策略，那就是以聊天格式向 ChatGPT 发送描述问题的额外指令，让它自行纠正</strong>。以往依赖 GPT-3 或 Codex 模型 [15, 14] 的方法需要用户重新设计输入提示，并从头开始生成新的输出。然而，ChatGPT 的对话能力是一种令人惊讶的有效行为纠正工具。第 3.2 节和补充视频展示了用户与 ChatGPT 之间的交互行为示例。</p> 
<h3><a id="23_Special_arguments_to_bias_the_answers_structure_89"></a>2.3. Special arguments to bias the answer’s structure</h3> 
<p>不同的提示方法可以用来强制模型的输出服从某种特定的模式。例如，用户可能希望自动解析 ChatGPT 的输出，以便将其用于其他脚本的实时执行。如图 3 所示，一种简单的策略是直接要求 ChatGPT 生成特定语言（如 Python，C++）的代码。接下来通常是一段自由格式的文本，然后是一个代码块。如图 5 所示，通过要求模型使用 XML 标记来帮助我们自动解析输出，可以生成更有条理的响应。</p> 
<p>在其他情况下，用户可能希望强制模型按照列表模式而不是代码或自由格式文本输出答案。附录 A.3 展示了这种方法的一个示例，其中用户提示的最后一行指示模型的输出。</p> 
<h2><a id="3_ChatGPT_abilities_for_solving_robotics_problems_95"></a>3. ChatGPT abilities for solving robotics problems</h2> 
<p>本节将深入探讨 ChatGPT 解决机器人问题的能力。具体来说，我们研究了 ChatGPT 在处理各种机器人相关任务时的表现，从简单的时空推理问题一直到真实世界的空中Agent和操纵部署。我们强调了在这些实验中观察到的几个有趣的功能。</p> 
<p>虽然 ChatGPT 的功能令人印象深刻，但实际部署中的安全考虑也不容忽视，尤其是在物理机器人部署的情况下。如图 2 所示，我们发现在 ChatGPT 出现意外行为时，有必要派人进行监控和干预。此外，在现实世界中部署之前，使用模拟器对评估模型性能也特别有帮助。<strong>我们强调，在机器人技术中使用 ChatGPT 并不是一个完全自动化的过程，而是一种增强人类能力的工具</strong>。</p> 
<p>我们在附录 B 中提供了本节问题的所有初始提示。为简洁起见，我们只摘录了每个任务的简要内容。完整对话可在以下资源库中找到：https://github.com/microsoft/PromptCraft-Robotics。</p> 
<h3><a id="31_Zeroshot_task_planning_103"></a>3.1. Zero-shot task planning</h3> 
<p>首先，我们注意到，ChatGPT 能够以 "0-shot "的方式解决多个机器人任务，只需访问提示和函数库说明，而无需实际代码示例。</p> 
<p>3.1.1. Spatio-temporal reasoning: catching a basketball with visual servoing</p> 
<p><img src="https://images2.imgbox.com/e6/a6/p6zmy5sq_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/dd/6a/wD6gAiV0_o.png" alt="在这里插入图片描述"></p> 
<p>在这个示例中，我们要求 ChatGPT 控制一个装有向上摄像头的平面机器人。机器人要根据篮球的外观，使用视觉伺服方法接住篮球。我们看到，ChatGPT 能够恰当地使用所提供的 API 函数，推理出球的外观并调用相关的 OpenCV 函数，并根据比例控制器来控制机器人的速度。更令人印象深刻的是，ChatGPT 可以使用 SVG 代码估算摄像机图像中球和天空的外观。这种行为暗示了一种可能性，即 LLM 跟踪的隐式世界模型超越了基于文本的概率。</p> 
<p>3.1.2. Aerial robotics: real-world drone flight with intuitive human-robot interface (<a href="https://youtu.be/i5wZJFb4dyA" rel="nofollow">Click for video</a>)</p> 
<p><img src="https://images2.imgbox.com/54/98/nf1xBJ5Z_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/78/36/XYfIXCqZ_o.png" alt="在这里插入图片描述"></p> 
<p>我们还使用 ChatGPT 和不同的API来控制一架真正的无人机。ChatGPT 在用户和机器人之间提供了一个极其直观的自然语言界面，可以根据模棱两可，定义不清的指令编写机器人代码，并在必要时提出澄清问题。该模型还能仅根据提示的基础API编写复杂的代码结构，用于无人机导航（环形和割草机检查）。</p> 
<p>3.1.3. Aerial robotics: AirSim industrial inspection (<a href="https://youtu.be/38lA3U2J43w" rel="nofollow">Click for video</a>)</p> 
<p><img src="https://images2.imgbox.com/6c/26/4m3KPpMY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/a3/7a/Q6LWemU8_o.png" alt="在这里插入图片描述"></p> 
<p>我们还将 ChatGPT 应用于微软 AirSim [16] 模拟器的模拟领域。我们探索了由非技术用户指挥模型控制无人机并执行工业检查的想法。我们从下面的摘录中观察到，ChatGPT 能够有效地解析用户输入的意图和几何线索，并准确地控制无人机。</p> 
<h3><a id="32_User_on_the_loop_interactive_conversations_for_complex_tasks_139"></a>3.2. User on the loop: interactive conversations for complex tasks</h3> 
<p>下一步，我们重点研究了 ChatGPT 在用户提供文字反馈的情况下执行更复杂任务的能力。我们注意到，这种交互模式允许进行复杂的构造，例如课程学习，<strong>在课程学习中，系统将学习较小范围的技能，这些技能可以组合成更大，更复杂的任务</strong>。此外，我们还发现 ChatGPT 能够接收有关生成代码或其性能的高级文本反馈，并将其映射到所需的低层次代码更改中，从而使潜在的非技术用户能够轻松地与之互动。</p> 
<p>3.2.1. Manipulation with curriculum learning (<a href="https://youtu.be/wLOChUtdqoA" rel="nofollow">Click for video</a>)</p> 
<p><img src="https://images2.imgbox.com/71/33/RtnNuAfg_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/7a/8b/V3erR4ap_o.png" alt="在这里插入图片描述"></p> 
<p>作为第一个例子，我们使用机械臂设置了一个积木排列任务，并为此设计了一套课程。我们要求 ChatGPT 学习拾取物体和放置物体的简单技能。随后，当被要求使用这些技能来完成更复杂的积木排列任务时，ChatGPT 会将这些学到的技能逻辑地串联起来。此外，在用木块拼出微软徽标的任务中，该模型还展示了在文字和物理领域之间架起桥梁的可概括性的精彩实例。这项任务需要记忆公司徽标的外观（包括颜色），然后将徽标抽象为物理部分，并通过现有的机器人动作进行构建。</p> 
<p>3.2.2. Aerial robotics: AirSim obstacle avoidance (<a href="https://youtu.be/Vn6NapLlHPE" rel="nofollow">Click for video</a>)</p> 
<p><img src="https://images2.imgbox.com/ec/18/sgHPXKSm_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/0a/66/YVlg89pm_o.png" alt="在这里插入图片描述"></p> 
<p>我们委托 ChatGPT 为一架配备了前向距离传感器的无人机编写一个具有避障功能的目标搜索算法。ChatGPT 构建了避障算法的大部分关键构件，但在无人机的方位问题上，还需要一些人工反馈。虽然反馈完全是以高级文本的形式提供的，但 ChatGPT 还是在适当的地方对代码进行了局部修改，从而改进了其解决方案。</p> 
<h3><a id="33_Perceptionaction_loops_158"></a>3.3. Perception-action loops</h3> 
<p>我们还对 ChatGPT 感知-行动循环的推理能力进行了评估。首先，我们概述了该模型利用 API 库在代码输出中构建感知-动作循环的能力。该模型正确使用了图像采集和物体检测等感知功能，以提取机器人导航和控制的相关信息。</p> 
<p>在复杂性的第二个层面，我们试图回答 ChatGPT 的对话系统本身是否可以作为一个封闭的反馈感知-行动环路的问题。我们探索了通过文本对话向模型持续提供感知信息的想法，在对话过程中，我们向 ChatGPT 输入观察结果（转换成文本格式）。我们发现 ChatGPT 能够解析这些观察信息流并输出相关行动。</p> 
<p>3.3.1. Embodied agent: closed loop object navigation with API library (<a href="https://youtu.be/p0fDH9zZm_c" rel="nofollow">Click for video</a>)</p> 
<p><img src="https://images2.imgbox.com/28/04/4tuL11EB_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/d9/46/jfehGEdy_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e9/d4/ownQ55p0_o.png" alt="在这里插入图片描述"><br> 我们让 ChatGPT 访问计算机视觉模型，作为其功能库的一部分，并要求它探索未知环境并导航至用户指定的物体。物体检测API（后端为 YOLOv8 [17]）会返回边界框，而 ChatGPT 会生成代码来估算物体的相对角度并导航至物体。当我们向 ChatGPT 提供来自深度传感器的额外信息时，它就会生成一个具有 pixel depth masking 的改进算法，并以模块化流水线的形式表达出来。</p> 
<p>3.3.2. Embodied agent: closed loop visual-language navigation using ChatGPT’s dialogue (<a href="https://youtu.be/p0fDH9zZm_c?t=69" rel="nofollow">Click for video</a>)</p> 
<p><img src="https://images2.imgbox.com/3b/06/f62EomxL_o.png" alt="在这里插入图片描述"></p> 
<p>在实验中，我们还<strong>评估了 ChatGPT 使用其对话功能作为感知-行动控制反馈回路的能力。在这种操作模式下，新的状态观察结果以对话文本的形式输入系统，机器人每一步都会执行模型的输出，从而产生新的观察结果</strong>。我们注意到，这类行为在很大程度上依赖于基于对话的 LLM，如 ChatGPT，它可以自然地接收观察结果流。我们使用 Habitat 模拟器构建了一个场景[18]，要求机器人导航到感兴趣的区域。每一步，我们都会向 ChatGPT 提供场景描述，即相对于Agent的可见物体的极坐标。我们对 ChatGPT 的输出进行了限制，使其只能返回前向运动距离和转弯角度。我们验证了该模型能够完成简单的导航任务，但<strong>对于更复杂的任务和环境，还需要进行更多的研究，才能以文本或矢量形式正确描述场景背景</strong>。</p> 
<p>有关其他实验，请读者参阅附录 C。</p> 
<h3><a id="34_Reasoning_and_commonsense_robotics_tasks_180"></a>3.4. Reasoning and common-sense robotics tasks</h3> 
<p>我们让 ChatGPT 回答简单的逻辑推理问题以及基本的机器人问题，如附录 D 所示。我们发现，ChatGPT 提供了丰富的常识和逻辑推理能力基础，在此基础上可以构建更高级的机器人能力。这种逻辑基础让用户可以更自然地与模型互动，而不必提示或从头定义每个概念。此外，ChatGPT 对控制，摄像头几何形状和物理形状因素等基本机器人概念的开箱即用的理解，使其成为建立可通用和用户友好型机器人管道的绝佳选择。</p> 
<h2><a id="4_PromptCraft_a_collaborative_tool_for_LLM__Robotics_research_184"></a>4. PromptCraft, a collaborative tool for LLM + Robotics research</h2> 
<p>提示（Prompt）是在大型语言模型（LLM）中生成所需行为的关键组成部分。在 LLM 与机器人技术的交叉领域，提示工程尤其具有挑战性，因为在这些领域缺乏提供积极（和消极）互动示例的全面，可访问的资源。为了填补这一空白，我们推出了 PromptCraft，这是一个供研究人员共享提示策略示例并在机器人环境示例中测试其算法的协作式开源平台。</p> 
<p>PromptCraft 是一个基于 Github 的平台，允许研究人员分享不同机器人类别（如导航，抓取和操纵）中的提示工程策略示例。用户可以提交自己的示例，并对他人提交的示例进行评分，我们希望这将为使用 LLMs 的研究人员创建一个社区驱动的资源。提交的提示和对话主要基于文本，但我们也鼓励用户分享描述机器人行为的视频和图片，尤其是针对实际部署场景的视频和图片。</p> 
<p>PromptCraft 不仅提供了一个分享提示示例的平台，还提供了一个带有 ChatGPT 封装程序的 AirSim [16] 环境，供研究人员在受控的模拟环境中对提示和算法进行原型开发。我们欢迎大家提供新的测试环境，以扩大研究人员测试算法的场景范围。</p> 
<p>通过 Promptcraft，我们旨在支持提示工程的实证科学，使研究人员能够推动该领域的发展。</p> 
<p><img src="https://images2.imgbox.com/89/a0/3YhxZMGd_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="5_Related_Work_197"></a>5. Related Work</h2> 
<h3><a id="Natural_language_and_robotics_199"></a>Natural language and robotics</h3> 
<p>长期以来，自然语言处理（NLP）一直被认为是人机交互的重要组成部分。在许多应用中，机器人都能从 NLP 中受益，包括但不限于任务指令，导航和信息检索。传统上，使用语言模拟人与机器人的交互具有挑战性，因为它迫使用户在一套死板的指令中操作 [19]，或者需要复杂的数学算法来跟踪行动和目标物体的多种概率分布 [20，21]。最近的研究探索利用神经网络来隐式地跟踪语言和动作之间的复杂映射，但这类技术通常需要大量的标注数据进行训练 [22, 5, 6, 23] 。</p> 
<h3><a id="Large_vision_and_language_models_for_robotics_203"></a>Large (vision and) language models for robotics</h3> 
<p>论文 [24] 中介绍的 Transformer 架构给 NLP 带来了革命性的变化，在机器人技术领域也大有可为。变压器已被用于机器人控制和规划 [25, 26, 27]，物体识别 [28] 和机器人导航 [29]。变压器在机器人技术中更常见的用途是同时作为一种或多种模式的特征提取模块。这些系统通常与来自预训练的大规模视觉和语言模型的附加特征相结合 [30, 10, 31, 32, 11, 9]。</p> 
<p>SayCan [31]等模型侧重于将 LLM 落地（grounding），从而使用自由形式的文本命令来计算值函数（value function），以便在机器人专用库中对最佳动作类型进行排序。另一方面，RT-1 [33] 采用端到端方法学习语言命令与低级动作之间的映射，而不使用中间的高级函数。近期的研究还探索了大型语言模型（LLM）在零点高级机器人任务规划方面的能力[15, 14, 12]。这些模型利用带有预定义函数，行为和示例的提示结构来指导模型答案的生成。[13]还探索了在桌面操作设置中使用用户和 LLM 之间的交互性。</p> 
<p>从概念上讲，这些方法与我们利用 ChatGPT [1] 所做工作的主要区别在于，<strong>我们的 LLM 具备对话能力，允许用户交互式地改进和纠正机器人的行为（而不是从头开始重新设计提示并生成另一个零样本答案）</strong>。此外，我们的工作旨在提供一个可通用的管道和一套原则，供机器人学不同领域的研究人员使用，而不是专注于桌面操作或任务规划等单一领域。</p> 
<h3><a id="Prompting_LLMs_with_APIs_and_its_connections_to_symbolic_AI_211"></a>Prompting LLMs with APIs, and its connections to symbolic AI</h3> 
<p>在为机器人应用设计 LLM 提示时，用户通常会使用高级 API 库来表示要使用的特定行为。我们可以将这种方法与经典的符号人工智能联系起来，后者使用逻辑和规则来表示和推理知识[34]。传统的符号人工智能方法在新知识获取和处理分布外数据方面存在困难，而我们相信 LLM 可以克服这些挑战。正如我们在第 2.1 节和第 3 节中所展示的，像 ChatGPT 这样的模型可以根据上下文组成新的原始函数，并自动为其生成代码。</p> 
<h2><a id="6_Conclusions_and_Future_Work_215"></a>6. Conclusions and Future Work</h2> 
<p>我们提出了一个将 ChatGPT 用于机器人应用的框架。该框架包括设计和实现一个用于机器人控制的 API 库，该 API 库可用于 ChatGPT 的提示工程。我们讨论了创建此类 API 的设计原则，以及可用于通过 ChatGPT 生成机器人应用代码的提示策略。所提出的框架允许用户通过一系列方法（包括模拟和人工检查）对生成的代码进行测试，验证和确认。我们演示了如何将该框架用于多种应用，从简单的常识性机器人知识任务一直到空中机器人，操纵和视觉导航的部署。</p> 
<p>我们相信，这项工作只展示了机器人领域大型语言模型交叉领域的一小部分成果。我们希望不仅能激励其他研究人员迈出下一步，还能帮助他们利用 PromptCraft 协作工具取得成果。</p> 
<p>我们强调，不应让这些工具完全控制机器人流水线，尤其是对安全要求较高的应用而言。鉴于 LLM 最终会产生错误响应的倾向，因此在机器人上执行代码之前，在人工监督下确保解决方案的质量和安全性相当重要。我们期待接下来的几项研究工作能采用适当的方法，为在机器人领域运行的 LLM 正确设计，构建和创建测试，验证和确认管道。</p> 
<p><strong>我们在这项工作中展示的大多数示例都是开放式的感知-行动循环，即 ChatGPT 生成代码以解决任务，之后并不向模型提供反馈。鉴于闭环控制在感知-行动循环中的重要性，我们希望未来在这一领域的大部分研究都能探索如何正确利用 ChatGPT 的能力，以文本或特殊用途模态的形式接收任务反馈</strong>。</p> 
<h3><a id="61_ChatGPT_for_paper_writing_225"></a>6.1. ChatGPT for paper writing</h3> 
<p>请注意，本文主要是在 ChatGPT 的协助下撰写的，并由作者提供了提示。我们注意到，使用 LLM 可以大大加快写作过程，我们向感兴趣的读者推荐使用 LLM。</p> 
<h2><a id="A_Additional_examples_on_design_principles_on_prompt_engineering_229"></a>A. Additional examples on design principles on prompt engineering</h2> 
<p><img src="https://images2.imgbox.com/af/8b/hgx5a4aI_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/94/bd/98hfoUle_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/7e/e3/JGOCONCw_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="B_Original_initial_prompts_for_robotics_tasks_examples_240"></a>B. Original initial prompts for robotics tasks examples</h2> 
<p>B.1. Spatial-temporal reasoning: catching a basketball with visual servoing</p> 
<p>Full conversation found at: https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/spatial_temporal_reasoning/visual_servoing_basketball.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/64/32/rNFWABaT_o.png" alt="在这里插入图片描述"></p> 
<p>B.2. Aerial robotics: real-world drone flight</p> 
<p>Full conversation found at: https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/aerial_robotics/tello_example.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/1a/00/HaQyJpV0_o.png" alt="在这里插入图片描述"></p> 
<p>B.3. Aerial robotics: AirSim industrial inspection</p> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/aerial_robotics/airsim_turbine_inspection.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/a3/b9/V2OUIAV6_o.png" alt="在这里插入图片描述"></p> 
<p>B.4. Aerial robotics: AirSim obstacle avoidance</p> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/aerial_robotics/airsim_obstacleavoidance.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/96/57/DN82OlAi_o.png" alt="在这里插入图片描述"></p> 
<p>B.5. Embodied agent: Habitat navigation</p> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/embodied_agents/visual_language_navigation_1.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/ca/c1/BNYOMR1s_o.png" alt="在这里插入图片描述"></p> 
<p>B.6. Embodied agent: AirSim object navigation</p> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/embodied_agents/airsim_objectnavigation.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/20/57/zDXrJnKo_o.png" alt="在这里插入图片描述"></p> 
<p>B.7. Manipulation with curriculum learning: Picking, stacking, and building the Microsoft logo</p> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/manipulation/pick_stack_msft_logo.md</p> 
<p>Initial ChatGPT prompt:</p> 
<p><img src="https://images2.imgbox.com/3e/31/uob5b1dH_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="C_Additional_experiments_305"></a>C. Additional experiments</h2> 
<h3><a id="C1_Zeroshot_manipulation_Pick_and_place_stacking_and_pushing_307"></a>C.1. Zero-shot manipulation: Pick and place, stacking, and pushing</h3> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/manipulation/manipulation_zeroshot.md</p> 
<h3><a id="C2_Controlling_multiple_robot_form_factors_from_a_single_prompt_311"></a>C.2. Controlling multiple robot form factors from a single prompt</h3> 
<p>Full conversation found at:https://github.com/microsoft/PromptCraft-Robotics/blob/main/examples/multiple_robots/multiple_robots.md</p> 
<h2><a id="D_Other_commonsensereasoning_tasks_315"></a>D. Other commonsense/reasoning tasks</h2> 
<h3><a id="D1_Computer_vision_problem_317"></a>D.1. Computer vision problem</h3> 
<p><img src="https://images2.imgbox.com/15/6d/na1eTIoZ_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="D2_Transformation_matrices_322"></a>D.2. Transformation matrices</h3> 
<p><img src="https://images2.imgbox.com/58/e2/dpN0RenS_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="D3_Balancing_a_ball_on_a_plate_327"></a>D.3. Balancing a ball on a plate</h3> 
<p><img src="https://images2.imgbox.com/bf/ca/C121Konm_o.png" alt="在这里插入图片描述"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/413d05bc40e3fd3ace7edbc04a2904ad/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">【读书笔记】《白帽子讲web安全》跨站脚本攻击</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/be24cf056deeafe3c609c39148b1456d/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【EAI 005】EmbodiedGPT：通过具身思维链进行视觉语言预训练的具身智能大模型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>