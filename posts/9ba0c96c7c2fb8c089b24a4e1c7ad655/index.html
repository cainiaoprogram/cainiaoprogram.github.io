<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Pytorch实战笔记(2)——CNN实现情感分析 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Pytorch实战笔记(2)——CNN实现情感分析" />
<meta property="og:description" content="本文展示的是使用 Pytorch 构建一个 TextCNN 来实现情感分析。本文的架构是第一章详细介绍 TextCNN（不带公式版），第二章是核心代码部分。
目录 1. TextCNN2. TextCNN 实现情感分析参考 1. TextCNN 相较于 LSTM 而言，我个人其实是没看过 CNN 的任何公式的，主要是我觉得也没必要，因为从使用的角度上讲，会用就行；从 CNN 的角度上讲，你只需要知道 CNN 提取的是一种聚合关系就行（与 GNN 不同的是，CNN 提取的是欧式数据的聚合关系，GNN 提取的是非欧数据的聚合关系）。
TextCNN [1] 的模型图如下图所示。其中一共包含了有 3 个模块：卷积层，最大池化层，和输出层。
在原论文中，作者采用了多个通道来提取不同词嵌入的特征，然而如果只有一种词嵌入输入的话，可以参考下面这篇论文[2]中的模型图：
我们现在就以上图作为例子，详细介绍下 TextCNN（仅有一种词嵌入输入时）的具体流程（放心，没有任何公式）：
首先是输入，TextCNN 的输入是词嵌入，设序列长度为 s s s（在图中为 s = 7 s=7 s=7），设嵌入维度为 d d d（在图中 d = 5 d=5 d=5）。接着 TextCNN 会经过一次二维卷积。首先是卷积核，从图中可以看到，一共有三个卷积核，大小分别为 ( 4 × 5 ) (4\times 5) (4×5)， ( 3 × 5 ) (3\times 5) (3×5)， ( 2 × 5 ) (2\times 5) (2×5)。先从卷积核的第二维开始说，我们发现卷积核的第二维都是 5，这个尺寸大小与嵌入维度 d d d 相同，就是说对于 TextCNN 而言，一次卷积要囊括所有词嵌入，这个也很好理解，因为只有 d d d 才能够代表整个词语。而对于第一维，分别为 4、3、2，这个就指的是，一次卷积考虑几个词语的依赖关系。假设卷积核大小为 ( 4 × 5 ) (4\times5) (4×5)，那么就说明该卷积核一次聚合 4 个词语的依赖关系。(注：图中从左到右第二个区域是卷积核，第三个区域才是卷积后的输出)然后从图上可以发现，该图中每个卷积核共有 2 个滤波器（filter），所以一共有 2 个 ( 4 × 5 ) (4\times5) (4×5) 的卷积核、2 个 ( 3 × 5 ) (3\times5) (3×5) 的卷积核、2 个 ( 2 × 5 ) (2\times5) (2×5) 的卷积核。这里就是说，我们用不同数量的滤波器来捕获这个区间内不同的特征，以 ( 4 × 5 ) (4\times5) (4×5) 的卷积核举例，我们用滤波器 A 来捕获这4个词语之间的 A 特征，用滤波器 B 来捕获这4个词语之间的 B 特征。卷积之后是一次一维最大池化操作。该过程提取卷积后的向量中的最大值，作为该滤波器的特征。最后将所有滤波器通过最大池化后得到的特征拼接在一起，放到分类器中进行输出。 通过上述的解释，我们可以发现，TextCNN 是通过卷积核的尺寸，来控制模型捕获多少个词语之间的上下文关系。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/9ba0c96c7c2fb8c089b24a4e1c7ad655/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-01-20T14:43:45+08:00" />
<meta property="article:modified_time" content="2023-01-20T14:43:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Pytorch实战笔记(2)——CNN实现情感分析</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <p>本文展示的是使用 Pytorch 构建一个 TextCNN 来实现情感分析。本文的架构是第一章详细介绍 TextCNN（不带公式版），第二章是核心代码部分。</p> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#1_TextCNN_3" rel="nofollow">1. TextCNN</a></li><li><a href="#2_TextCNN__20" rel="nofollow">2. TextCNN 实现情感分析</a></li><li><a href="#_113" rel="nofollow">参考</a></li></ul> 
</div> 
<p></p> 
<h2><a id="1_TextCNN_3"></a>1. TextCNN</h2> 
<p>相较于 LSTM 而言，我个人其实是没看过 CNN 的任何公式的，主要是我觉得也没必要，因为从使用的角度上讲，会用就行；从 CNN 的角度上讲，你只需要知道 <strong>CNN 提取的是一种聚合关系就行</strong>（与 GNN 不同的是，CNN 提取的是欧式数据的聚合关系，GNN 提取的是非欧数据的聚合关系）。</p> 
<p>TextCNN [1] 的模型图如下图所示。其中一共包含了有 3 个模块：<strong>卷积层</strong>，<strong>最大池化层</strong>，和<strong>输出层</strong>。<br> <img src="https://images2.imgbox.com/cc/3a/CJTAHXvI_o.png" alt="TextCNN"><br> 在原论文中，作者采用了多个通道来提取不同词嵌入的特征，然而如果只有一种词嵌入输入的话，可以参考下面这篇论文[2]中的模型图：<br> <img src="https://images2.imgbox.com/3d/3c/MfaxhwAH_o.png" alt="TextCNN"><br> 我们现在就以上图作为例子，详细介绍下 TextCNN（仅有一种词嵌入输入时）的具体流程（放心，没有任何公式）：</p> 
<ol><li>首先是输入，TextCNN 的输入是词嵌入，设序列长度为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          s 
         
        
       
         s 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span></span>（在图中为<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          s 
         
        
          = 
         
        
          7 
         
        
       
         s=7 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">7</span></span></span></span></span>），设嵌入维度为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          d 
         
        
       
         d 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span>（在图中 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          d 
         
        
          = 
         
        
          5 
         
        
       
         d=5 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.6444em;"></span><span class="mord">5</span></span></span></span></span>）。</li><li>接着 TextCNN 会经过一次二维卷积。首先是卷积核，从图中可以看到，一共有三个卷积核，大小分别为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          4 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (4\times 5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          3 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (3\times 5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span>，<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          2 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (2\times 5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span>。先从卷积核的第二维开始说，我们发现卷积核的第二维都是 <code>5</code>，这个尺寸大小与嵌入维度 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          d 
         
        
       
         d 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span> 相同，就是说对于 TextCNN 而言，一次卷积要囊括所有词嵌入，这个也很好理解，因为<strong>只有 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
       
        
         
         
           d 
          
         
        
          d 
         
        
      </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal">d</span></span></span></span></span> 才能够代表整个词语</strong>。而对于第一维，分别为 <code>4</code>、<code>3</code>、<code>2</code>，这个就指的是，<strong>一次卷积考虑几个词语的依赖关系</strong>。假设卷积核大小为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          4 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (4\times5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span>，那么就说明该卷积核一次聚合 <code>4</code> 个词语的依赖关系。(<code>注</code>：图中从左到右第二个区域是卷积核，第三个区域才是卷积后的输出)</li><li>然后从图上可以发现，该图中每个卷积核共有 2 个滤波器（<code>filter</code>），所以一共有 <code>2</code> 个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          4 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (4\times5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span> 的卷积核、<code>2</code> 个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          3 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (3\times5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span> 的卷积核、<code>2</code> 个 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          2 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (2\times5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">2</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span> 的卷积核。这里就是说，我们用不同数量的滤波器来捕获这个区间内不同的特征，以 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
      
       
        
        
          ( 
         
        
          4 
         
        
          × 
         
        
          5 
         
        
          ) 
         
        
       
         (4\times5) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord">5</span><span class="mclose">)</span></span></span></span></span> 的卷积核举例，我们用滤波器 A 来捕获这4个词语之间的 A 特征，用滤波器 B 来捕获这4个词语之间的 B 特征。</li><li>卷积之后是一次一维最大池化操作。该过程提取卷积后的向量中的最大值，作为该滤波器的特征。</li><li>最后将所有滤波器通过最大池化后得到的特征拼接在一起，放到分类器中进行输出。</li></ol> 
<p>通过上述的解释，我们可以发现，TextCNN 是通过卷积核的尺寸，来控制模型捕获多少个词语之间的上下文关系。</p> 
<h2><a id="2_TextCNN__20"></a>2. TextCNN 实现情感分析</h2> 
<ul><li>全部代码在 github 上，网址为：<a href="https://github.com/Balding-Lee/Pytorch4NLP">https://github.com/Balding-Lee/Pytorch4NLP</a></li><li>我采用的是 IMDb 数据集，由于数据集没有验证集，而且读取起来很麻烦，所以我将数据给读取出来，放到了一个文件中，并且将训练集中的10%划分为了验证集，数据集链接如下： <a href="https://pan.baidu.com/s/128EYenTiEirEn0StR9slqw" rel="nofollow">https://pan.baidu.com/s/128EYenTiEirEn0StR9slqw</a>，提取码：xtu3 。</li><li>采用的词嵌入是谷歌的词嵌入，词嵌入的链接如下：链接：<a href="https://pan.baidu.com/s/1SPf8hmJCHF-kdV6vWLEbrQ" rel="nofollow">https://pan.baidu.com/s/1SPf8hmJCHF-kdV6vWLEbrQ</a>，提取码：r5vx<br> 在本博客中仅介绍模型部分，详细代码见 github。</li></ul> 
<p>具体的模型代码如下：</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F


<span class="token keyword">class</span> <span class="token class-name">Config</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 训练配置</span>
        self<span class="token punctuation">.</span>seed <span class="token operator">=</span> <span class="token number">22</span>
        self<span class="token punctuation">.</span>batch_size <span class="token operator">=</span> <span class="token number">64</span>
        self<span class="token punctuation">.</span>lr <span class="token operator">=</span> <span class="token number">1e-3</span>
        self<span class="token punctuation">.</span>weight_decay <span class="token operator">=</span> <span class="token number">1e-4</span>
        self<span class="token punctuation">.</span>num_epochs <span class="token operator">=</span> <span class="token number">100</span>
        self<span class="token punctuation">.</span>early_stop <span class="token operator">=</span> <span class="token number">512</span>
        self<span class="token punctuation">.</span>max_seq_length <span class="token operator">=</span> <span class="token number">128</span>
        self<span class="token punctuation">.</span>save_path <span class="token operator">=</span> <span class="token string">'../model_parameters/CNN_SA.bin'</span>

        <span class="token comment"># 模型配置</span>
        self<span class="token punctuation">.</span>filter_sizes <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_filters <span class="token operator">=</span> <span class="token number">100</span>
        self<span class="token punctuation">.</span>dense_hidden_size <span class="token operator">=</span> <span class="token number">128</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> <span class="token number">0.5</span>
        self<span class="token punctuation">.</span>embed_size <span class="token operator">=</span> <span class="token number">300</span>
        self<span class="token punctuation">.</span>num_outputs <span class="token operator">=</span> <span class="token number">2</span>


<span class="token keyword">class</span> <span class="token class-name">Model</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embed<span class="token punctuation">,</span> config<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embedding <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>embed<span class="token punctuation">,</span> freeze<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>convs <span class="token operator">=</span> nn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span>
            <span class="token punctuation">[</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span>num_filters<span class="token punctuation">,</span> <span class="token punctuation">(</span>k<span class="token punctuation">,</span> config<span class="token punctuation">.</span>embed_size<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token keyword">for</span> k <span class="token keyword">in</span> config<span class="token punctuation">.</span>filter_sizes<span class="token punctuation">]</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>dropout <span class="token operator">=</span> nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dropout<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>relu <span class="token operator">=</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>ffn <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>num_filters <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>filter_sizes<span class="token punctuation">)</span><span class="token punctuation">,</span> config<span class="token punctuation">.</span>dense_hidden_size<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>classifier <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>config<span class="token punctuation">.</span>dense_hidden_size<span class="token punctuation">,</span> config<span class="token punctuation">.</span>num_outputs<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">max_pooling</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>max_pool1d<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># shape: (batch_size, max_seq_length, embed_size)</span>
        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>embedding<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>

        <span class="token comment"># CNN 接受四维数据输入,</span>
        <span class="token comment"># 第一维: batch,</span>
        <span class="token comment"># 第二维: 通道数 (Channel), 在图像中指的是 RGB 这样的通道, 在自然语言里面指的是多少种词嵌入, 本项目中仅采用一种词嵌入, 所以就是 1 通道</span>
        <span class="token comment"># 第三维: 高度 (Height), 在图像中指的是图片的高, 在自然语言里面就是序列长度</span>
        <span class="token comment"># 第四维: 宽度 (Weight), 在图像中指的是图片的宽, 在自然语言里面就是嵌入维度</span>
        <span class="token comment"># shape: (batch_size, 1, max_seq_length, embed_size)</span>
        embed <span class="token operator">=</span> embed<span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>

        cnn_outputs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">:</span>
            <span class="token comment"># shape: (batch_size, filter_size, max_seq_length - kernel_size + 1, 1)</span>
            conv_output <span class="token operator">=</span> conv<span class="token punctuation">(</span>embed<span class="token punctuation">)</span>
            <span class="token comment"># shape: (batch_size, filter_size, max_seq_length - kernel_size + 1, 1)</span>
            relu_output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>conv_output<span class="token punctuation">)</span>
            <span class="token comment"># shape: (batch_size, filter_size, max_seq_length - kernel_size + 1, 1)</span>
            relu_output <span class="token operator">=</span> relu_output<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
            <span class="token comment"># shape: (batch_size, filter_size)</span>
            pooling_output <span class="token operator">=</span> self<span class="token punctuation">.</span>max_pooling<span class="token punctuation">(</span>relu_output<span class="token punctuation">)</span>
            cnn_outputs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>pooling_output<span class="token punctuation">)</span>

        <span class="token comment"># shape: (batch, num_filters * len(num_filters))</span>
        cnn_outputs <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>cnn_outputs<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        cnn_outputs <span class="token operator">=</span> self<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>cnn_outputs<span class="token punctuation">)</span>
        <span class="token comment"># shape: (batch, dense_hidden_size)</span>
        ffn_output <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>ffn<span class="token punctuation">(</span>cnn_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># shape: (batch, num_outputs)</span>
        logits <span class="token operator">=</span> self<span class="token punctuation">.</span>classifier<span class="token punctuation">(</span>ffn_output<span class="token punctuation">)</span>

        <span class="token keyword">return</span> logits
</code></pre> 
<p>在该代码中，我才用的卷积核尺寸是 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         3 
        
       
         × 
        
        
        
          e 
         
        
          m 
         
        
          b 
         
        
          e 
         
        
          d 
         
        
          _ 
         
        
          s 
         
        
          i 
         
        
          z 
         
        
          e 
         
        
       
         ) 
        
       
      
        (3\times {\rm embed\_size}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">3</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">embed_size</span></span></span><span class="mclose">)</span></span></span></span></span>、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         4 
        
       
         × 
        
        
        
          e 
         
        
          m 
         
        
          b 
         
        
          e 
         
        
          d 
         
        
          _ 
         
        
          s 
         
        
          i 
         
        
          z 
         
        
          e 
         
        
       
         ) 
        
       
      
        (4\times {\rm embed\_size}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">4</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">embed_size</span></span></span><span class="mclose">)</span></span></span></span></span>、<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
       
         5 
        
       
         × 
        
        
        
          e 
         
        
          m 
         
        
          b 
         
        
          e 
         
        
          d 
         
        
          _ 
         
        
          s 
         
        
          i 
         
        
          z 
         
        
          e 
         
        
       
         ) 
        
       
      
        (5\times {\rm embed\_size}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mopen">(</span><span class="mord">5</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">embed_size</span></span></span><span class="mclose">)</span></span></span></span></span>，每个卷积核共有100个滤波器。同时，分类器一共有两层，一层的尺寸大小为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
        
        
          n 
         
        
          u 
         
        
          m 
         
        
          _ 
         
        
          f 
         
        
          i 
         
        
          l 
         
        
          t 
         
        
          e 
         
        
          r 
         
        
          s 
         
        
          × 
         
        
          l 
         
        
          e 
         
        
          n 
         
        
          ( 
         
        
          n 
         
        
          u 
         
        
          m 
         
        
          _ 
         
        
          f 
         
        
          i 
         
        
          l 
         
        
          t 
         
        
          e 
         
        
          r 
         
        
          s 
         
        
          ) 
         
        
       
         , 
        
        
        
          d 
         
        
          e 
         
        
          n 
         
        
          s 
         
        
          e 
         
        
          _ 
         
        
          h 
         
        
          i 
         
        
          d 
         
        
          d 
         
        
          e 
         
        
          n 
         
        
          _ 
         
        
          s 
         
        
          i 
         
        
          z 
         
        
          e 
         
        
       
         ) 
        
       
      
        ({\rm num\_filters \times len(num\_filters)}, {\rm dense\_hidden\_size}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathrm">num_filters</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mord mathrm">len</span><span class="mopen">(</span><span class="mord mathrm">num_filters</span><span class="mclose">)</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">dense_hidden_size</span></span></span><span class="mclose">)</span></span></span></span></span>，一层的尺寸大小为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         ( 
        
        
        
          d 
         
        
          e 
         
        
          n 
         
        
          s 
         
        
          e 
         
        
          _ 
         
        
          h 
         
        
          i 
         
        
          d 
         
        
          d 
         
        
          e 
         
        
          n 
         
        
          _ 
         
        
          s 
         
        
          i 
         
        
          z 
         
        
          e 
         
        
       
         , 
        
        
        
          n 
         
        
          u 
         
        
          m 
         
        
          _ 
         
        
          o 
         
        
          u 
         
        
          t 
         
        
          p 
         
        
          u 
         
        
          t 
         
        
          s 
         
        
       
         ) 
        
       
      
        ({\rm dense\_hidden\_size}, {\rm num\_outputs}) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1.06em; vertical-align: -0.31em;"></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathrm">dense_hidden_size</span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord"><span class="mord mathrm">num_outputs</span></span></span><span class="mclose">)</span></span></span></span></span>。</p> 
<p>实验结果如下：</p> 
<pre><code class="prism language-python">test loss <span class="token number">0.367522</span> <span class="token operator">|</span> test accuracy <span class="token number">0.833840</span> <span class="token operator">|</span> test precision <span class="token number">0.822838</span> <span class="token operator">|</span> test recall <span class="token number">0.850880</span> <span class="token operator">|</span> test F1 <span class="token number">0.836624</span>
</code></pre> 
<h2><a id="_113"></a>参考</h2> 
<p>[1] Yoon Kim. Convolutional Neural Networks for Sentence Classification [EB/OL]. <a href="https://arxiv.org/pdf/1408.5882.pdf" rel="nofollow">https://arxiv.org/pdf/1408.5882.pdf</a>, 2014.<br> [2] Ye Zhang, Byron C. Wallace. A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional Neural Networks for Sentence Classification [EB/OL]. <a href="https://arxiv.org/pdf/1510.03820.pdf" rel="nofollow">https://arxiv.org/pdf/1510.03820.pdf</a>, 2015.</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/a2f8a32f7fdc76ede8500207d81f7a26/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">分类算法常用的评价指标</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/763ab0f3ec23686a46e5d6aa47e03a00/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">C&#43;&#43;调用yolov5 onnx模型的初步探索</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>