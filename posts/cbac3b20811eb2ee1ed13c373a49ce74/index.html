<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Redis高级(持久化--redis主从架构--redis哨兵模式--redis分片集群) - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Redis高级(持久化--redis主从架构--redis哨兵模式--redis分片集群)" />
<meta property="og:description" content="目录
redis实现持久化的两种模式
redis主从架构
redis主从集群 -- 数据同步优化
redis主从集群&#43;哨兵框架
redis分片集群
redis实现持久化的两种模式 RDB持久化
RDB全称Redis Database Backup file（Redis数据备份文件）,也被称为数据快照,就是把redis内存中的所有数据写入到本地磁盘中, 当服务宕机重启后,可以读取本地磁盘文件来恢复数据,Redis数据备份文件被称为RDB文件,默认是保存在当前运行目录下(可通过配置文件更改相关保存信息)
执行时机:
1) 执行save命令
2) 执行bgsave命令
3) 正常停机时
4) 达到RDB自动保存的阈值时
save命令:
执行save命令,会触发一次RDB持久,是主进程在进行磁盘IO, 此时无法对外提供服务,会阻塞请求, 只适用于手动停机,数据迁移的场景
bgsave命令:
与save命令不同的是,bgsave是异步执行的,从主进程fork一个子进程进行持久化操作,在磁盘IO的时候,不会阻塞请求,主进程能够正常的提供服务,值得注意的是在主线程fork的时候是阻塞请求的状态
RDB自动保存阈值:
Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：
save 900 1 # 900秒内，如果至少有1个key被修改，则执行bgsave save 300 10 # 300秒内, 如果至少有10个key被修改,则执行bgsave save 60 10000 # 60秒内,10000个key # 如果是save &#34;&#34; 则表示禁用RDB 其他配置:
# 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱 rdbcompression yes # RDB文件名称 dbfilename dump.rdb # 文件保存的路径目录 dir ./ RDB执行原理:
save:
操作系统会在redis中维护一个虚拟内存表&#34; 页表 &#34;" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/cbac3b20811eb2ee1ed13c373a49ce74/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-03-04T20:35:53+08:00" />
<meta property="article:modified_time" content="2022-03-04T20:35:53+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Redis高级(持久化--redis主从架构--redis哨兵模式--redis分片集群)</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="redis%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F-toc" style="margin-left:80px;"><a href="#redis%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F" rel="nofollow">redis实现持久化的两种模式</a></p> 
<p id="redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84-toc" style="margin-left:80px;"><a href="#redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84" rel="nofollow">redis主从架构</a></p> 
<p id="redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%20--%20%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%BC%98%E5%8C%96-toc" style="margin-left:80px;"><a href="#redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%20--%20%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%BC%98%E5%8C%96" rel="nofollow">redis主从集群 -- 数据同步优化</a></p> 
<p id="redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%2B%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F-toc" style="margin-left:80px;"><a href="#redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%2B%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F" rel="nofollow">redis主从集群+哨兵框架</a></p> 
<p id="redis%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4-toc" style="margin-left:80px;"><a href="#redis%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4" rel="nofollow">redis分片集群</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h4 id="redis%E5%AE%9E%E7%8E%B0%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%BC%8F">redis实现持久化的两种模式</h4> 
<blockquote> 
 <p><span style="color:#0d0016;"><strong>RDB持久化</strong></span></p> 
 <hr> 
 <p>RDB全称Redis Database Backup file（<strong>Redis数据备份文件</strong>）,也被称为数据快照,就是把redis内存中的所有数据写入到本地磁盘中, 当服务宕机重启后,可以读取本地磁盘文件来恢复数据,<strong>Redis数据备份文件</strong>被称为<span style="color:#4da8ee;"><strong>RDB文件</strong></span><span style="color:#0d0016;">,默认是保存在当前运行目录下(可通过配置文件更改相关保存信息)</span></p> 
 <hr> 
 <p><strong>执行时机:</strong></p> 
 <p>        1) 执行save命令</p> 
 <p>        2) 执行bgsave命令</p> 
 <p>        3) 正常停机时</p> 
 <p>        4) 达到RDB自动保存的阈值时</p> 
 <hr> 
 <p><strong>save命令:</strong></p> 
 <p>        执行save命令,会触发一次RDB持久,是<span style="color:#4da8ee;"><strong>主进程</strong></span>在进行磁盘IO, 此时无法对外提供服务,会<span style="color:#4da8ee;"><strong>阻塞请求</strong></span>, 只适用于手动停机,数据迁移的场景</p> 
 <p><img alt="" height="209" src="https://images2.imgbox.com/f8/08/LLja08Tn_o.png" width="1199"></p> 
 <p><strong> bgsave命令:</strong></p> 
 <p>        与save命令不同的是,bgsave是<span style="color:#4da8ee;"><strong>异步执行</strong></span>的,从主进程fork一个子进程进行持久化操作,在磁盘IO的时候,<span style="color:#4da8ee;"><strong>不会阻塞请求</strong></span>,主进程能够正常的提供服务,<strong>值得注意的是在主线程fork的时候是阻塞请求的状态</strong></p> 
 <p><img alt="" height="109" src="https://images2.imgbox.com/d3/78/uwIqeNfw_o.png" width="1154"></p> 
 <p><strong>RDB自动保存阈值:</strong></p> 
 <p>        Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p> 
 <pre><code class="language-XML">save 900 1            # 900秒内，如果至少有1个key被修改，则执行bgsave
save 300 10           # 300秒内, 如果至少有10个key被修改,则执行bgsave
save 60 10000         # 60秒内,10000个key

# 如果是save "" 则表示禁用RDB
</code></pre> 
 <p>其他配置:</p> 
 <pre><code># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱
rdbcompression yes

# RDB文件名称
dbfilename dump.rdb  

# 文件保存的路径目录
dir ./ </code></pre> 
 <hr> 
 <p><strong>RDB执行原理:</strong></p> 
 <p><strong><img alt="" height="430" src="https://images2.imgbox.com/ca/13/ReRd7hUq_o.png" width="1193"></strong></p> 
 <p><strong> save:</strong></p> 
 <p>         操作系统会在redis中维护一个虚拟内存表" <span style="color:#4da8ee;"><strong>页表 </strong></span>" ,页表和物理内存有映射关系,所以redis主进程在持久化的时候,只需要操作虚拟内存中的页表,操作系统会从页表中读取数据,实现磁盘IO</p> 
 <p><strong>bgsave:</strong></p> 
 <p>        会从主进程fork出一个子进程,fork的过程是将主进程中的页表复制到子进程中,子进程拥有同样的映射关系后,就可以读取物理内存,生成RDB文件. 这样虽然fork效率高,而且不会影响主进程对外提供服务,但是异步的,就会出现脏读的现象出现,而fork也想到了这一点,采用了copy-on-write技术：</p> 
 <p>        在子进程读的时候,会把内存数据标记成read-only状态,此时主线程只能进行读取,若要进行写操作,就要在内存中拷贝一份数据副本,对数据副本进行写操作,数据副本产生后,主线程页表就会映射数据副本,</p> 
 <p>        <strong>在redis优化中,会提到在给redis分配内存的时候尽量有一般的内存留余,在极端情况下,有可能子线程读取很慢,而主进程的写操作很多,就会导致拷贝很多的数据副本,甚至会拷贝全部的数据副本,这样redis内存就翻倍了,但这种情况几乎不会出现,但理论上是会出现</strong></p> 
 <hr> 
 <p><strong>RDB的缺点:</strong></p> 
 <p>        两次RDB操作之间如果服务宕机,就会丢失数据, 无法保证数据的强完整性</p> 
 <p>        fork子进程,生成RDB文件,压缩RDB文件都比较耗时</p> 
</blockquote> 
<blockquote> 
 <p><strong>  AOF持久化</strong></p> 
 <hr> 
 <p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。当需要进行数据恢复的时候,重新执行AOF文件即可</p> 
 <p><img alt="" height="548" src="https://images2.imgbox.com/c5/61/ThMCzncR_o.png" width="1148"></p> 
 <p><strong> AOF模式的开启:</strong></p> 
 <p>        该模式默认是不开启的,需要我们修改redis.conf配置文件来开启AOF：</p> 
 <pre><code># 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename "appendonly.aof"</code></pre> 
 <p>        AOF的IO频率也可以通过配置文件进行更改:</p> 
 <pre><code class="language-XML"># 表示每执行一次写命令，立即记录到AOF文件
appendfsync always 

# 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec 

# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no</code></pre> 
 <p>        三种模式的对比:</p> 
 <p><img alt="" height="199" src="https://images2.imgbox.com/92/b2/NVTyX4H2_o.png" width="1200"></p> 
 <hr> 
 <p><strong>AOF的文件命令重写:</strong></p> 
 <p>        在redis中,往往会有对同一个key有不同的操作,这些操作命令都会被存储在AOF文件中,所以AOF文件会比RDB文件大很多,同时这些对同一个key的多条命令,只有最后一条才有价值,所以我们可以通过执行bgrewriteaof命令对其进行体积优化<a href="http://doc.redisfans.com/server/bgrewriteaof.html" rel="nofollow" title="()BGREWRITEAOF — Redis 命令参考">()BGREWRITEAOF — Redis 命令参考</a><a href="http://doc.redisfans.com/server/bgrewriteaof.html" rel="nofollow" title="BGREWRITEAOF — Redis 命令参考">BGREWRITEAOF — Redis 命令参考</a><a href="http://doc.redisfans.com/server/bgrewriteaof.html" rel="nofollow" title="()BGREWRITEAOF — Redis 命令参考">()BGREWRITEAOF — Redis 命令参考</a>，</p> 
 <p><img alt="" height="160" src="https://images2.imgbox.com/20/cd/QXq30Ns2_o.png" width="1187"></p> 
 <p>         如图，AOF原本有三个命令，但是set num 123 和 set num 666都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。 所以重写命令后，AOF文件内容就是：mset name jack num 666   ,</p> 
 <p><strong>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</strong></p> 
 <pre><code># AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100

# AOF文件体积最小多大以上才触发重写 
auto-aof-rewrite-min-size 64mb </code></pre> 
 <p></p> 
</blockquote> 
<blockquote> 
 <p> <strong>RDB与AOF两种持久化模式对比:</strong></p> 
 <p><img alt="" height="435" src="https://images2.imgbox.com/f5/6e/9nJ8aYnP_o.png" width="1195"></p> 
 <p> 在企业应用中,我们一般会根据数据的价值,效率等各方条件进行评估,再考虑使用哪种方式</p> 
</blockquote> 
<h4 id="redis%E4%B8%BB%E4%BB%8E%E6%9E%B6%E6%9E%84">redis主从架构</h4> 
<blockquote> 
 <p><strong>主从架构</strong></p> 
 <hr> 
 <p>单节点的redis对并发的承受能力是有限的,所以如果业务流量大,我们会对redis搭建主从架构,进行读写分离  <a href="https://blog.csdn.net/qq_24113267/article/details/79150533?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522164638225316780357230244%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=164638225316780357230244&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-3-79150533.pc_search_result_control_group&amp;utm_term=redis%E4%B8%BB%E4%BB%8E%E6%90%AD%E5%BB%BA&amp;spm=1018.2226.3001.4187" title="redis主从搭建">redis主从搭建</a></p> 
 <p><img alt="" height="514" src="https://images2.imgbox.com/a8/92/a8f3puJp_o.png" width="1162"></p> 
 <p><span style="color:#4da8ee;"><strong>redis集群的主从数据同步有两种方式,全量同步/增量同步</strong></span></p> 
</blockquote> 
<blockquote> 
 <p><strong>全量同步</strong></p> 
 <hr> 
 <p><strong>执行时机:</strong></p> 
 <p>        在主从服务器<span style="color:#4da8ee;"><strong>第一次连接</strong></span>或者从服务器<span style="color:#4da8ee;"><strong>长时间未同步</strong></span>的时候会执行全量同步,会将master节点上的所有数据同步到slave节点上</p> 
 <p>        在主从数据同步的时候,会有两个属性, <strong>Replication Id,offset</strong>用来判断slave是否是第一次连接,slave数据同步到哪里了</p> 
 <p><strong>Replication Id：</strong></p> 
 <p>        简称replid，是数据集的标记，master与slave节点都有replid,但是id不一样, 只有在建立连接的时候,slave节点才会继承master分支的replid,所以在进行主从连接的时候, 可以通过id是否一致来判断是需要进行全量同步</p> 
 <p><strong>offset：</strong></p> 
 <p>        偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</p> 
 <p><strong>repl_baklog:</strong></p> 
 <p><strong>        </strong>在master节点执行持久化的时候,会记录所有持久化期间的命令到repl_baklog, 用来计算offset偏移量</p> 
 <p><span style="color:#4da8ee;"><strong>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</strong></span></p> 
 <p><strong>流程图:</strong></p> 
 <p><img alt="" height="468" src="https://images2.imgbox.com/73/e1/r1EXvkW7_o.png" width="1200"></p> 
 <p> <span style="color:#4da8ee;"><strong>全量同步是将生成的RDB文件通过网络进行传输,传输成本较高,所以一般都是主从节点第一次连接的时候进行全量同步,全量同步后,就会陆续执行增量同步,来确保数据一致性</strong></span></p> 
</blockquote> 
<blockquote> 
 <p><strong> 增量同步</strong></p> 
 <hr> 
 <p><strong>执行时机:</strong></p> 
 <p>        <span style="color:#0d0016;">全量同步是将生成的RDB文件通过网络进行传输,传输成本较高,所以一般都是主从节点第一次连接的时候进行全量同步,全量同步后,就会陆续执行增量同步,来确保数据一致性, </span></p> 
 <p>        增量同步是通过<strong>offset</strong>值来判断slave节点同步到哪里了, 然后会将<strong>repl_baklog</strong>中的偏差记录发送给slave节点,slave节点执行记录使其同步</p> 
 <p><strong>流程图:</strong></p> 
 <p><img alt="" height="482" src="https://images2.imgbox.com/d2/df/BRcaH3xa_o.png" width="1197"></p> 
 <p>如何通过<strong>offset值</strong>来确定同步位置的:</p> 
 <p>这就要说到全量同步时的repl_baklog文件了。这个文件是一个固定大小的数组，只不过数组是环形，也就是说角标到达数组末尾后，会再次从0开始读写，这样数组头部的数据就会被覆盖。repl_baklog中会记录Redis处理过的命令日志及，包括master当前的offset值，和slave已经拷贝到的offset值</p> 
 <p><img alt="" height="295" src="https://images2.imgbox.com/80/c0/2TF5p084_o.png" width="283">此时,master的offset值与slave的offset值的差值,就是slave需要增量同步的数据</p> 
 <p><img alt="" height="304" src="https://images2.imgbox.com/0d/2a/cVKKlYhI_o.png" width="276">随着数据的不断持久化,master的offset值会不断增大,而slave也会不断的进行增量同步</p> 
 <p><img alt="" height="314" src="https://images2.imgbox.com/59/48/TWMPiRtt_o.png" width="286">直到数据被填满,,此时master就会覆盖绿色部分(也就是slave已经同步过的数据)</p> 
 <p><img alt="" height="319" src="https://images2.imgbox.com/cd/11/E3Fxa1gg_o.png" width="266"><img alt="" height="318" src="https://images2.imgbox.com/58/a8/G9AeXwgh_o.png" width="270">但如果salve在增量同步的过程中遇到了阻塞,就会导致从节点的进度赶不上主节点的进度,有可能会导致slave的offset被覆盖,如果此时slave状态恢复,就无法进行增量同步了,只能进行<span style="color:#4da8ee;"><strong>全量同步</strong></span></p> 
</blockquote> 
<h4 id="redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%20--%20%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E4%BC%98%E5%8C%96">redis主从集群 -- 数据同步优化</h4> 
<blockquote> 
 <p>主从同步可以保证主从数据的一致性，非常重要。可以从以下几个方面来优化Redis主从就集群：</p> 
 <p>- 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。<br> - Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO<br> - <strong>适当提高repl_baklog的大小</strong>，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步<br> - 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用<span style="color:#4da8ee;"><strong>主-从-从链式结构</strong></span>，减少master压力</p> 
 <p><img alt="" height="368" src="https://images2.imgbox.com/05/f8/eJ2famFa_o.png" width="1182"></p> 
</blockquote> 
<h4 id="redis%E4%B8%BB%E4%BB%8E%E9%9B%86%E7%BE%A4%2B%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F">redis主从集群+哨兵框架</h4> 
<blockquote> 
 <p><strong>redis主从集群可以实现高并发读的功能,配合哨兵框架可实现高可用</strong></p> 
 <hr> 
 <p><strong>架构图:</strong></p> 
 <p><img alt="" height="398" src="https://images2.imgbox.com/14/f7/743szOtR_o.png" width="526"></p> 
 <p><strong>哨兵的作用如下：</strong></p> 
 <p><strong>        监控</strong>：Sentinel 会不断检查您的master和slave是否按预期工作</p> 
 <p><strong>        自动故障恢复</strong>：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主</p> 
 <p><strong>        通知</strong>：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端</p> 
 <hr> 
 <p><strong>集群监控原理:</strong></p> 
 <p>        Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：</p> 
 <p>        主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例主观下线。</p> 
 <p>        客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例**客观下线**。quorum值最好超过Sentinel实例数量的一半。</p> 
 <p><strong>自动故障恢复原理:</strong></p> 
 <p>        一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点然后判断slave节点的<strong>slave-priority</strong>值(默认都为1)，越小优先级越高，如果是0则永不参与选举,如果slave-prority一样，则判断slave节点的<strong>offset值</strong>，越大说明数据越新，优先级越高最后是判断slave节点的运行id大小，越小优先级越高。</p> 
 <p>        <strong>选举成功后的执行流程:</strong></p> 
 <p>        sentinel给备选的slave1节点发送<span style="color:#4da8ee;"><strong>slaveof no one</strong></span>命令，让该节点成为master</p> 
 <p>        sentinel给所有其它slave发送slaveof <strong>(IP地址) + 7002</strong> 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。</p> 
 <p>        最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点</p> 
 <p><img alt="" height="672" src="https://images2.imgbox.com/40/19/IHZVOJBW_o.png" width="1014"></p> 
</blockquote> 
<h4 id="redis%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4">redis分片集群</h4> 
<blockquote> 
 <p><strong>分片集群</strong></p> 
 <hr> 
 <p>redis读写分离配合哨兵模式可以实现高可用,高并发读的要求,但不满足海量数据存储,高并发写的要求,所以我们可以搭建redis分片集群</p> 
 <p><strong>架构图:</strong></p> 
 <p><img alt="" height="751" src="https://images2.imgbox.com/fb/f1/hwyNytZe_o.png" width="928"></p> 
 <p><strong>分片集群特征：</strong></p> 
 <p>        集群中有多个master，每个master保存不同数据      </p> 
 <p>        每个master都可以有多个slave节点 </p> 
 <p>        master之间拥有心跳检测机制,通过ping监测彼此健康状态</p> 
 <p>        分片集群中存在<strong>散列插槽机制</strong>,所以客户端请求可以访问集群任意节点，最终都会被转发到正确节点</p> 
 <p></p> 
</blockquote> 
<blockquote> 
 <p> <strong>散列插槽(hash插槽)</strong></p> 
 <hr> 
 <p>Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到:</p> 
 <p><img alt="" height="144" src="https://images2.imgbox.com/ab/e0/JYINblab_o.png" width="726"></p> 
 <p> 数据中的key不是与master节点进行绑定的,而是<strong>与插槽进行绑定的</strong>,所以不用指定访问哪个节点,redis会根据key的插槽值找到key所在的位置,而插槽值是根据key的有效部分计算的, 盘点有效部分有两种情况</p> 
 <p>- key中包含"{}"，且“{}”中至少包含1个字符，“{}”中的部分是有效部分  # key: {a}num  会根据a计算插槽值<br> - key中不包含“{}”，整个key都是有效部分        # key: num  会根据num计算插槽值</p> 
 <p><strong>计算方式是利用CRC16算法得到一个hash值，然后对16384取余，得到的结果就是slot值。</strong></p> 
 <hr> 
 <p><strong>如何将一类数据分配到统一节点上:</strong></p> 
 <p>        综上得知,分片集群中的每个节点都是映射16384个插槽的一部分,数据进行存储的时候是计算key的slot值进行存储, 那同一类数据对的key值可能会计算出不同的slot值,就会被分配到不同的节点上,如果要实现对一类数据的群组化,我们就可以利用slot值计算的有效部分,在同一类数据key加上{typeID},这样计算出的slot值就会一样了</p> 
</blockquote> 
<blockquote> 
 <p> <strong>集群伸缩</strong></p> 
 <hr> 
 <p><strong>如何添加一个分片节点</strong>:</p> 
 <p>        <img alt="" height="173" src="https://images2.imgbox.com/3c/d2/VYbHgnYc_o.png" width="815"></p> 
 <p>new_host参数:                新节点的ip地址</p> 
 <p>new_port参数:                新节点的端口号</p> 
 <p>existing_host参数:                任意一个已经存在的节点的ip</p> 
 <p>existing_port参数:                任意一个已经存在的节点的端口</p> 
 <p><span style="color:#4da8ee;"><strong>existing_host参数和existing_port参数用于推送新节点上线信息给集群中的其他节点</strong></span></p> 
 <hr> 
 <p><strong>转移插槽</strong>:</p> 
 <p>        在新节点上线后,是没有插槽映射的,所以需要我们手动分配插槽</p> 
 <p><strong>命令:</strong></p> 
 <p><img alt="" height="318" src="https://images2.imgbox.com/03/23/EE86WXZI_o.png" width="1097"></p> 
 <p><strong> 首先建立连接(这里ip和端口号可以填写任意旧节点的信息):</strong></p> 
 <p><img alt="" height="47" src="https://images2.imgbox.com/9f/cb/TIuzKzvi_o.png" width="1093"></p> 
 <p><strong> 选择抽取多少个插槽:</strong></p> 
 <p><img alt="" height="222" src="https://images2.imgbox.com/b0/b8/jZcZJtpM_o.png" width="1195"></p> 
 <p><strong> 填写新节点id,接收插槽:</strong></p> 
 <p><img alt="" height="192" src="https://images2.imgbox.com/c2/73/i0AMqOeY_o.png" width="1052"></p> 
 <p><strong> 以哪种方式抽取插槽:</strong></p> 
 <p><img alt="" height="325" src="https://images2.imgbox.com/08/8f/LHoe8YQ6_o.png" width="1200"></p> 
 <p> - all：代表全部，也就是三个节点各转移一部分<br> - 具体的id：目标节点的id<br> - done：没有了</p> 
 <p><strong>我们这里填写具体的节点id</strong></p> 
 <p><img alt="" height="398" src="https://images2.imgbox.com/f8/bd/O4IvIpjI_o.png" width="1193"></p> 
 <p> 完成</p> 
</blockquote> 
<blockquote> 
 <p> <strong>故障转移</strong></p> 
 <hr> 
 <p><strong>自动故障转移:</strong></p> 
 <p>        分片集群支持自动故障转移,当一台master故障后, 集群内的心跳机制就会发现,当超过一般的节点认为该节点下线后,就会自动选举一个salve当做新的master,而当故障节点重启后,会以salve的角色进行运行</p> 
 <p><strong>手动故障转移:</strong></p> 
 <p>        利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。其流程如下</p> 
 <p><img alt="" height="734" src="https://images2.imgbox.com/e7/f8/DkYA7zwk_o.png" width="913"></p> 
 <p> <img alt="" height="308" src="https://images2.imgbox.com/e6/b1/zX694Hg0_o.png" width="829"></p> 
 <p> </p> 
</blockquote>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/5963eca01fb9b6efb82488dad6c0ca8a/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">SSL认证过程介绍</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/60af8b3a0f79bf41d969bf673dcb6d53/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">win10家庭版升级专业版</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>