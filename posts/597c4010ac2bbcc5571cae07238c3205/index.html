<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>python爬虫案例:爬取电影以及MP4文件合并 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="python爬虫案例:爬取电影以及MP4文件合并" />
<meta property="og:description" content="目录
一、前言
二、爬取ts文件
三、mp4文件合并
四、总结
一、前言 一日心血来潮想看个电影，但很无奈，都是要VIP的，所以我选择去盗版网站看，但是……为什么这么卡啊！！！所以呢，先爬下来，下载之后再来看就不卡了。
二、爬取ts文件 废话少说，直入主题。进入这个盗版电影网站，鼠标右击，选择检查（快捷键：Ctrl&#43;Shift&#43;I）
在Network选项栏里可以看到有许多个ts文件，每个ts文件就是电影的一部分，思路就有了：通过循环请求，下载所有的ts文件然后合并即可。
点进其中一个ts观察请求头（Request URL），发现不同的ts只有最后几位数字是不同的，https://vip.ffzy-online2.com/20230629/40222_a6b8ae3d/2000k/hls/这部分是相同的，不同的是后面的数字的最后四位，0000.ts、0001.ts、0002.ts。
移动进度条到电影最后，发现Network里加载出的ts一直到httpxxxxxx1830.ts还要多一些，这样请求的范围就确定了。
接下来就是代码部分了：
import requests import os from fake_useragent import UserAgent def download(i): i = str(i).rjust(4, &#39;0&#39;) if os.path.exists(f&#39;{i}.mp4&#39;): return headers = {&#39;user-agent&#39;: UserAgent().random}#注意random后不要加() url = &#34;https://vip.ffzy-online2.com/20230629/40222_a6&#34;\ f&#34;b8ae3d/2000k/hls/106d7d7527400{i}.ts&#34; response = requests.get(url, headers=headers) if response.status_code != 404: with open(f&#39;{i}.ts&#39;, &#39;wb&#39;) as f: f.write(response.content) else: print(f&#39;第{i}次404报错&#39;) def main(): for i in range(1831): download(i) if __name__ == &#39;__main__&#39;: main() 首先是四位数的格式，这里用了操作字符串的rjust()函数，右对齐，长度4位，以0填充。也可以选择%04d的格式化方法。
然后是heards，这里用了第三方库fake_useragent（安装方法：按下键盘的win&#43;R键并输入cmd（或右击电脑开始菜单，选择运行再输入cmd），在cmd中输入pip install fake_useragent，然后等待下载安装），UserAgent()函数可以生成一些user-agent，调用random随机选取一个。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/597c4010ac2bbcc5571cae07238c3205/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-07-14T00:09:07+08:00" />
<meta property="article:modified_time" content="2023-07-14T00:09:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">python爬虫案例:爬取电影以及MP4文件合并</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80-toc" style="margin-left:80px;"><a href="#%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80" rel="nofollow">一、前言</a></p> 
<p id="%E4%BA%8C%E3%80%81%E7%88%AC%E5%8F%96ts%E6%96%87%E4%BB%B6-toc" style="margin-left:80px;"><a href="#%E4%BA%8C%E3%80%81%E7%88%AC%E5%8F%96ts%E6%96%87%E4%BB%B6" rel="nofollow">二、爬取ts文件</a></p> 
<p id="%E4%B8%89%E3%80%81mp4%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6-toc" style="margin-left:80px;"><a href="#%E4%B8%89%E3%80%81mp4%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6" rel="nofollow">三、mp4文件合并</a></p> 
<p id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93-toc" style="margin-left:80px;"><a href="#%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93" rel="nofollow">四、总结</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h4 id="%E4%B8%80%E3%80%81%E5%89%8D%E8%A8%80"><strong>一、前言</strong></h4> 
<p>        一日心血来潮想看个电影，但很无奈，都是要VIP的，所以我选择去盗版网站看，但是……为什么这么卡啊！！！所以呢，先爬下来，下载之后再来看就不卡了。</p> 
<h4 id="%E4%BA%8C%E3%80%81%E7%88%AC%E5%8F%96ts%E6%96%87%E4%BB%B6"><strong>二、爬取ts文件</strong></h4> 
<p>        废话少说，直入主题。进入这个盗版电影网站，鼠标右击，选择检查（快捷键：Ctrl+Shift+I）</p> 
<p><img alt="" src="https://images2.imgbox.com/ac/7c/4Mq7Qlno_o.png">         在Network选项栏里可以看到有许多个ts文件，每个ts文件就是电影的一部分，思路就有了：通过循环请求，下载所有的ts文件然后合并即可。</p> 
<p>         点进其中一个ts观察请求头（Request URL），发现不同的ts只有最后几位数字是不同的，<a href="https://vip.ffzy-online2.com/20230629/40222_a6b8ae3d/2000k/hls/106d7d7527400%7Bj%7D.ts" rel="nofollow" title=""></a>https://vip.ffzy-online2.com/20230629/40222_a6b8ae3d/2000k/hls/这部分是相同的，不同的是后面的数字的最后四位，0000.ts、0001.ts、0002.ts。</p> 
<p>        移动进度条到电影最后，发现Network里加载出的ts一直到httpxxxxxx1830.ts还要多一些，这样请求的范围就确定了。</p> 
<p> 接下来就是代码部分了：</p> 
<pre><code class="language-python">import requests
import os
from fake_useragent import UserAgent

def download(i):
    i = str(i).rjust(4, '0')
    if os.path.exists(f'{i}.mp4'):
        return
    headers = {'user-agent': UserAgent().random}#注意random后不要加()
    url = "https://vip.ffzy-online2.com/20230629/40222_a6"\
f"b8ae3d/2000k/hls/106d7d7527400{i}.ts"
    response = requests.get(url, headers=headers)
    if response.status_code != 404:
        with open(f'{i}.ts', 'wb') as f:
            f.write(response.content)
    else:
        print(f'第{i}次404报错')



def main():
    for i in range(1831):
        download(i)


if __name__ == '__main__':
    main()
</code></pre> 
<p>        首先是四位数的格式，这里用了操作字符串的rjust()函数，右对齐，长度4位，以0填充。也可以选择%04d的格式化方法。</p> 
<p>        然后是heards，这里用了第三方库fake_useragent（安装方法：按下键盘的win+R键并输入cmd（或右击电脑开始菜单，选择运行再输入cmd），在cmd中输入pip install fake_useragent，然后等待下载安装），UserAgent()函数可以生成一些user-agent，调用random随机选取一个。</p> 
<p>        懒得安装第三方库的可以在Network里往下滑，找到user-agent项，复制过来即可</p> 
<p>        现在可以把range里的数字改小一点，试着下载几个ts试一试，看一下能否成功下载播放。</p> 
<p>        然后因为一个一个下载太慢，用Pool进程池进行优化：</p> 
<pre><code class="language-python">from multiprocessing import Pool
def main():
    po = Pool(30)  # 进程池,每次30个
    for i in range(1831):
        po.apply_async(download, args=(i,))
    po.close()
    po.join()</code></pre> 
<p>        导入multiprocessing库的Pool类，在main()函数中创建Pool对象，子进程数量可以自己根据电脑CPU性能进行取值。</p> 
<p>        然后循环apply_async()添加所有任务，第一个参数是函数名，第二个参数是该函数的参数，需要是元组类型，所以是args=(i,)。</p> 
<p>        添加任务后close()，最后调用join()依次添加子进程。</p> 
<p>        注意：在使用这个Pool的时候，必须写if __name__='__main__':否则会报错</p> 
<h4 id="%E4%B8%89%E3%80%81mp4%E6%96%87%E4%BB%B6%E5%90%88%E5%B9%B6"><strong>三、mp4文件合并</strong></h4> 
<p>        下载完之后就可以来合并文件了，打开cmd（win+R键，输入cmd），进入文件所在目录，然后输入代码copy /b *.ts movie.mp4</p> 
<p>        进入文件目录的方法：如果是在其他盘下比如E盘，输入E:即可切换到E盘，注意是英文的冒号</p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/64/57/Gna31OfS_o.png"></p> 
<p> </p> 
<p>         然后到文件资源管理器处复制文件路径，输入 cd 文件路径，即可进入该目录 </p> 
<p class="img-center"><img alt="" src="https://images2.imgbox.com/56/d9/Kg3dkhFn_o.png"></p> 
<p> </p> 
<p>         输入copy /b *.ts movie.mp4拼接文件，其中*.ts表示匹配所有.ts文件（如果代码中with open的是mp4类型，这里就改成*.mp4），movie.mp4表示最后生成的文件，文件名可改。</p> 
<h4 id="%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93">四、总结</h4> 
<p>        通过.ts文件(电影的片段)的url发出请求，进程池优化下载，最后通过cmd的copy /b *.ts movie.mp4合并。</p> 
<p>        之后还可以根据自己的喜好或者面向其他使用者进行优化，比如加个进度条等。</p> 
<p></p> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/d442620fab53bb54832a218249ed2c32/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">深入解析Tomcat：从入门到精通，一站式学习Tomcat服务器的完全指南</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/66c9d69151a706b33ef44859888da655/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">(六) 性能提示</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>