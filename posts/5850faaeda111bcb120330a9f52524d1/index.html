<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>cs231n课程作业assignment1（SVM） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="cs231n课程作业assignment1（SVM）" />
<meta property="og:description" content="标签（空格分隔）： 机器学习
前言： 以斯坦福cs231n课程的python编程任务为主线，展开对该课程主要内容的理解和部分数学推导。 该课程相关笔记参考自知乎-CS231n官方笔记授权翻译总集篇发布 课程材料和事例参考自-cs231n
SVM分类器简介： SVM-支持向量机(Support Vector Machine)，是一个有监督的线性分类器 线性分类器：在本模型中，我们从最简单的函数开始，一个线性映射： f(xi,W,b)=Wxi&#43;b 这个公式就是平时最常见到的线性函数，常为一维线性函数（即 W 为一维的）。当这种函数扩展到多维度的情况下时就是我们SVM要面临的情况。首先我们要做的处理是将每个图像数据都拉长为一个长度为D的列向量，大小为 [D * 1] 。其中大小为 [K * D] 的矩阵W和大小为 [K 1] 列向量 b 为该函数的参数。以CIFAR-10为例，CIFAR-10中一个图像的大小等于 [32*32*3] ,含了该图像的所有像素信息，这些信息被拉成为一个 [3072 * 1] 的列向量*， W 大小为 [10*3072] ， b 的大小为 [10*1] 。因此，3072个数字（素数值）输入函数，函数输出10个数字（不同分类得到的评分）。参数 W 被称为权重（weights）。 b 被称为偏差向量（bias vector）。 理解线性分类器 线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出的得分即对该点的接受程度。例如对于飞机来说，飞机图片中包含有大量的蓝色天空，白色的云彩以及白色的飞机，那么这个飞机分类器就会在蓝色通道上的权重比较多，而在其他通道上的权重就较少,正如笔记中指出的：
一个将图像映射到分类分值的例子。为了便于可视化，假设图像只有4个像素（都是黑白像素，这里不考虑RGB通道），有3个分类（红色代表猫，绿色代表狗，蓝色代表船，注意，这里的红、绿和蓝3种颜色仅代表分类，和RGB通道没有关系）。首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。需要注意的是，这个W一点也不好：猫分类的分值非常低。从上图来看，算法倒是觉得这个图像是一只狗。
现在考虑高维度情况：还是以CIFAR-10为例，CIFAR-10中的图片转化成一个向量（3072维）后，就是一个高维度问题，而一个向量（3色通道转化而来）可以看作是3072维空间中的一个点，而线性分类器就是在高维度空间中的一个超平面，将各个空间点分开。如图所示：
图像空间的示意图。其中每个图像是一个点，有3个分类器。以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低。
目标：而我们要做的就是寻找一个W和一个b,使得这个超平面能很好的区分各个类。寻找方法就是不停的改变w和b的值，即不停的旋转平移，直到它使分类的偏差较小。
SVM的组成： 图像数据预处理：在上面的例子中，所有图像都是使用的原始像素值（从0到255）。在机器学习中，对于输入的特征做归一化（normalization）是必然的。在图像处理中，每个像素点可以看作是一个简单的特征,在一般使用过程中，我们都先将特征“集中”，即训练集中所有的图像计算出一个平均图像值，然后每个图像都减去这个平均值，这样图像的像素值就大约分布在[-127, 127]之间了，下一个常见步骤是，让所有数值分布的区间变为[-1, 1]。
损失函数（loss function）：如何评判分类器的偏差就是当前的问题，解决这问题的方法就是损失函数: Li=∑j≠yimax(0,sj−syi&#43;Δ) 这个函数得到的就是当前分类的偏差值。
举例：用一个例子演示公式是如何计算的。假设有3个分类，并且得到了分值s=[13,-7,11]。其中第一个类别是正确类别，即 yi=0 。同时假设 Δ 是10。上面的公式是将所有不正确分类加起来，所以得到两个部分： Li=max(0,−7−13&#43;10)&#43;max(0,11−13&#43;10) 可以看到第一个部分结果是0，这是因为[-7-13&#43;10]得到的是负数，经过函数处理后得到0。这一对类别分数和标签的损失值是0，这是因为正确分类的得分13与错误分类的得分-7的差为20，高于边界值10。而SVM只关心差距至少要大于10，更大的差值还是算作损失值为0。第二个部分计算[11-13&#43;10]得到8。虽然正确分类的得分比不正确分类的得分要高（13&gt;11），但是比10的边界值还是小了，分差只有2，这就是为什么损失值等于8。简而言之，SVM的损失函数想要正确分类类别的分数比不正确类别分数高，而且至少要高。如果不满足这点，就开始计算损失值。 那么在这次的模型中，我们面对的是线性评分函数（f(x_i,W)=Wx_i），所以我们可以将损失函数的公式稍微改写一下： Li=∑j≠yimax(0,wTjxi−wTyixi&#43;Δ) 其中w_j是权重W的第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数f公式，这样做就不是必须的了。 正则化(Regularization):上面损失函数有一个问题。假设有一个数据集和一个权重集W能够正确地分类每个数据（即所有的边界都满足，对于所有的i都有）。问题在于这个W并不唯一：可能有很多相似的W都能正确地分类所有的数据。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/5850faaeda111bcb120330a9f52524d1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2016-11-25T11:10:14+08:00" />
<meta property="article:modified_time" content="2016-11-25T11:10:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">cs231n课程作业assignment1（SVM）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>标签（空格分隔）： 机器学习</p> 
<hr> 
<h2 id="前言">前言：</h2> 
<hr> 
<p>以斯坦福cs231n课程的python编程任务为主线，展开对该课程主要内容的理解和部分数学推导。 <br> 该课程相关笔记参考自知乎-<a href="https://zhuanlan.zhihu.com/p/21930884?refer=intelligentunit" rel="nofollow">CS231n官方笔记授权翻译总集篇发布</a> <br> 课程材料和事例参考自-<a href="http://vision.stanford.edu/teaching/cs231n/index.html" rel="nofollow">cs231n</a></p> 
<h3 id="svm分类器简介">SVM分类器简介：</h3> 
<hr> 
<p>SVM-支持向量机(Support Vector Machine)，是一个有监督的线性分类器 <br> <strong>线性分类器</strong>：在本模型中，我们从最简单的函数开始，一个线性映射： <br> <span class="MathJax_Preview"></span></p> 
<div class="MathJax_Display" style="text-align: center;"> 
 <span class="MathJax" id="MathJax-Element-10-Frame"> 
   
   <span class="math" id="MathJax-Span-248" style="width: 11.896em; display: inline-block;"><span style="display: inline-block; position: relative; width: 9.496em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.816em 1000em 3.149em -0.424em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-249"><span class="mi" id="MathJax-Span-250" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.056em;"></span></span><span class="mo" id="MathJax-Span-251" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-252"><span style="display: inline-block; position: relative; width: 0.909em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-253" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.589em;"><span class="mi" id="MathJax-Span-254" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-255" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-256" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="mo" id="MathJax-Span-257" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-258" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">b</span><span class="mo" id="MathJax-Span-259" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-260" style="font-family: MathJax_Main; padding-left: 0.269em;">=</span><span class="mi" id="MathJax-Span-261" style="font-family: MathJax_Math-italic; padding-left: 0.269em;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="msubsup" id="MathJax-Span-262"><span style="display: inline-block; position: relative; width: 0.909em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-263" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.589em;"><span class="mi" id="MathJax-Span-264" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-265" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mi" id="MathJax-Span-266" style="font-family: MathJax_Math-italic; padding-left: 0.216em;">b</span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 1.403em; vertical-align: -0.397em;"></span></span> 
  </span> 
</div><script type="math/tex; mode=display" id="MathJax-Element-10">  f(x_i,W,b) = Wx_i + b  </script> 
<br> 这个公式就是平时最常见到的线性函数，常为一维线性函数（即 W 为一维的）。当这种函数扩展到多维度的情况下时就是我们SVM要面临的情况。首先我们要做的处理是将每个图像数据都拉长为一个长度为D的列向量，大小为 [D * 1] 。其中大小为 [K * D] 的矩阵W和大小为 [K 
<em>1] </em>列向量 b 为该函数的参数。以CIFAR-10为例，CIFAR-10中一个图像的大小等于 [32*32*3] ,含了该图像的所有像素信息，这些信息被拉成为一个 [3072 * 1] 的列向量*， W 大小为 [10*3072] ， b 的大小为 [10*1] 。因此，3072个数字（素数值）输入函数，函数输出10个数字（不同分类得到的评分）。参数 W 被称为权重（weights）。 b 被称为偏差向量（bias vector）。 
<p></p> 
<h3 id="理解线性分类器">理解线性分类器</h3> 
<hr> 
<p>线性分类器计算图像中3个颜色通道中所有像素的值与权重的矩阵乘，从而得到分类分值。根据我们对权重设置的值，对于图像中的某些位置的某些颜色，函数表现出的得分即对该点的接受程度。例如对于飞机来说，飞机图片中包含有大量的蓝色天空，白色的云彩以及白色的飞机，那么这个飞机分类器就会在蓝色通道上的权重比较多，而在其他通道上的权重就较少,正如笔记中指出的：</p> 
<blockquote> 
 <p><img src="https://images2.imgbox.com/e1/90/Wg8f8FrB_o.jpg" alt="" title=""> <br> 一个将图像映射到分类分值的例子。为了便于可视化，假设图像只有4个像素（都是黑白像素，这里不考虑RGB通道），有3个分类（红色代表猫，绿色代表狗，蓝色代表船，注意，这里的红、绿和蓝3种颜色仅代表分类，和RGB通道没有关系）。首先将图像像素拉伸为一个列向量，与W进行矩阵乘，然后得到各个分类的分值。需要注意的是，这个W一点也不好：猫分类的分值非常低。从上图来看，算法倒是觉得这个图像是一只狗。</p> 
</blockquote> 
<p><strong>现在考虑高维度情况</strong>：还是以CIFAR-10为例，CIFAR-10中的图片转化成一个向量（3072维）后，就是一个高维度问题，而一个向量（3色通道转化而来）可以看作是3072维空间中的一个点，而线性分类器就是在高维度空间中的一个超平面，将各个空间点分开。如图所示：</p> 
<blockquote> 
 <p><img src="https://images2.imgbox.com/a0/05/xZv9Y50L_o.jpg" alt="" title=""> <br> 图像空间的示意图。其中每个图像是一个点，有3个分类器。以红色的汽车分类器为例，红线表示空间中汽车分类分数为0的点的集合，红色的箭头表示分值上升的方向。所有红线右边的点的分数值均为正，且线性升高。红线左边的点分值为负，且线性降低。</p> 
</blockquote> 
<p><strong>目标</strong>：而我们要做的就是寻找一个W和一个b,使得这个超平面能很好的区分各个类。寻找方法就是不停的改变w和b的值，即不停的旋转平移，直到它使分类的偏差较小。</p> 
<h3 id="svm的组成">SVM的组成：</h3> 
<hr> 
<p></p> 
<ul><li><strong>图像数据预处理：</strong>在上面的例子中，所有图像都是使用的原始像素值（从0到255）。在机器学习中，对于输入的特征做<strong>归一化（normalization）</strong>是必然的。在图像处理中，每个像素点可以看作是一个简单的特征,在一般使用过程中，我们都先将特征“集中”，即训练集中所有的图像计算出一个平均图像值，然后每个图像都减去这个平均值，这样图像的像素值就大约分布在[-127, 127]之间了，下一个常见步骤是，让所有数值分布的区间变为[-1, 1]。</li><li><p></p> 
<p></p> 
</li><li><strong>损失函数（loss function）：</strong>如何评判分类器的偏差就是当前的问题，解决这问题的方法就是损失函数: <br> <span class="MathJax_Preview"></span> 
 <div class="MathJax_Display" style="text-align: center;"> 
  <span class="MathJax" id="MathJax-Element-2-Frame"> 
    
    <span class="math" id="MathJax-Span-20" style="width: 16.163em; display: inline-block;"><span style="display: inline-block; position: relative; width: 12.909em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.603em 1000em 4.269em -0.424em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-21"><span class="msubsup" id="MathJax-Span-22"><span style="display: inline-block; position: relative; width: 1.016em; height: 0px;"><span style="position: absolute; clip: rect(1.709em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-23" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.696em;"><span class="mi" id="MathJax-Span-24" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-25" style="font-family: MathJax_Main; padding-left: 0.269em;">=</span><span class="munderover" id="MathJax-Span-26" style="padding-left: 0.269em;"><span style="display: inline-block; position: relative; width: 1.496em; height: 0px;"><span style="position: absolute; clip: rect(2.669em 1000em 4.376em -0.424em); top: -3.784em; left: 0.056em;"><span class="mo" id="MathJax-Span-27" style="font-family: MathJax_Size2; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 3.789em;"></span></span><span style="position: absolute; clip: rect(1.869em 1000em 2.936em -0.477em); top: -1.384em; left: 0.003em;"><span class="texatom" id="MathJax-Span-28"><span class="mrow" id="MathJax-Span-29"><span class="mi" id="MathJax-Span-30" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-31" style="font-size: 70.7%; font-family: MathJax_Main;">≠</span><span class="msubsup" id="MathJax-Span-32"><span style="display: inline-block; position: relative; width: 0.643em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.776em -0.477em); top: -2.451em; left: 0.003em;"><span class="mi" id="MathJax-Span-33" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.376em;"><span class="mi" id="MathJax-Span-34" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.509em;"></span></span></span></span><span class="mi" id="MathJax-Span-35" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">m</span><span class="mi" id="MathJax-Span-36" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-37" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-38" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-39" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-40" style="font-family: MathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-41" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 0.803em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-42" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.483em;"><span class="mi" id="MathJax-Span-43" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-44" style="font-family: MathJax_Main; padding-left: 0.216em;">−</span><span class="msubsup" id="MathJax-Span-45" style="padding-left: 0.216em;"><span style="display: inline-block; position: relative; width: 1.176em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-46" style="font-family: MathJax_Math-italic;">s</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -3.837em; left: 0.483em;"><span class="texatom" id="MathJax-Span-47"><span class="mrow" id="MathJax-Span-48"><span class="msubsup" id="MathJax-Span-49"><span style="display: inline-block; position: relative; width: 0.643em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.776em -0.477em); top: -2.451em; left: 0.003em;"><span class="mi" id="MathJax-Span-50" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.376em;"><span class="mi" id="MathJax-Span-51" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.003em;"></span></span></span></span><span class="mo" id="MathJax-Span-52" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mi" id="MathJax-Span-53" style="font-family: MathJax_Main; padding-left: 0.216em;">Δ</span><span class="mo" id="MathJax-Span-54" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 3.07em; vertical-align: -1.797em;"></span></span> 
   </span> 
 </div><script type="math/tex; mode=display" id="MathJax-Element-2">L_i=\sum_{j\not=y_i}max(0,s_j-s_{y_i}+\Delta)</script> <br> 这个函数得到的就是当前分类的偏差值。</li><li><p></p> 
<blockquote> 
 <p><strong>举例</strong>：用一个例子演示公式是如何计算的。假设有3个分类，并且得到了分值s=[13,-7,11]。其中第一个类别是正确类别，即<span class="MathJax_Preview"></span><span class="MathJax" id="MathJax-Element-3-Frame"> 
    
    <span class="math" id="MathJax-Span-55" style="width: 3.309em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.616em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.923em 1000em 3.149em -0.477em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-56"><span class="msubsup" id="MathJax-Span-57"><span style="display: inline-block; position: relative; width: 0.803em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.936em -0.477em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-58" style="font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.184em; left: 0.483em;"><span class="mi" id="MathJax-Span-59" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-60" style="font-family: MathJax_Main; padding-left: 0.269em;">=</span><span class="mn" id="MathJax-Span-61" style="font-family: MathJax_Main; padding-left: 0.269em;">0</span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 1.27em; vertical-align: -0.397em;"></span></span> 
   </span><script type="math/tex" id="MathJax-Element-3">y_i=0</script>。同时假设<span class="MathJax_Preview"></span><span class="MathJax" id="MathJax-Element-4-Frame"> 
    
    <span class="math" id="MathJax-Span-62" style="width: 1.069em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.856em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.869em 1000em 2.883em -0.424em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-63"><span class="mi" id="MathJax-Span-64" style="font-family: MathJax_Main;">Δ</span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 1.003em; vertical-align: -0.063em;"></span></span> 
   </span><script type="math/tex" id="MathJax-Element-4">\Delta</script>是10。上面的公式是将所有不正确分类加起来，所以得到两个部分： <br> <span class="MathJax_Preview"></span></p> 
 <div class="MathJax_Display" style="text-align: center;"> 
  <span class="MathJax" id="MathJax-Element-5-Frame"> 
    
    <span class="math" id="MathJax-Span-65" style="width: 27.576em; display: inline-block;"><span style="display: inline-block; position: relative; width: 22.029em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.816em 1000em 3.149em -0.424em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-66"><span class="mi" id="MathJax-Span-67" style="font-family: MathJax_Math-italic;">L</span><span class="mi" id="MathJax-Span-68" style="font-family: MathJax_Math-italic;">i</span><span class="mo" id="MathJax-Span-69" style="font-family: MathJax_Main; padding-left: 0.269em;">=</span><span class="mi" id="MathJax-Span-70" style="font-family: MathJax_Math-italic; padding-left: 0.269em;">m</span><span class="mi" id="MathJax-Span-71" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-72" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-73" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-74" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-75" style="font-family: MathJax_Main;">,</span><span class="mo" id="MathJax-Span-76" style="font-family: MathJax_Main; padding-left: 0.163em;">−</span><span class="mn" id="MathJax-Span-77" style="font-family: MathJax_Main;">7</span><span class="mo" id="MathJax-Span-78" style="font-family: MathJax_Main; padding-left: 0.216em;">−</span><span class="mn" id="MathJax-Span-79" style="font-family: MathJax_Main; padding-left: 0.216em;">13</span><span class="mo" id="MathJax-Span-80" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mn" id="MathJax-Span-81" style="font-family: MathJax_Main; padding-left: 0.216em;">10</span><span class="mo" id="MathJax-Span-82" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-83" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mi" id="MathJax-Span-84" style="font-family: MathJax_Math-italic; padding-left: 0.216em;">m</span><span class="mi" id="MathJax-Span-85" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-86" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-87" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-88" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-89" style="font-family: MathJax_Main;">,</span><span class="mn" id="MathJax-Span-90" style="font-family: MathJax_Main; padding-left: 0.163em;">11</span><span class="mo" id="MathJax-Span-91" style="font-family: MathJax_Main; padding-left: 0.216em;">−</span><span class="mn" id="MathJax-Span-92" style="font-family: MathJax_Main; padding-left: 0.216em;">13</span><span class="mo" id="MathJax-Span-93" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mn" id="MathJax-Span-94" style="font-family: MathJax_Main; padding-left: 0.216em;">10</span><span class="mo" id="MathJax-Span-95" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 1.403em; vertical-align: -0.397em;"></span></span> 
   </span> 
 </div><script type="math/tex; mode=display" id="MathJax-Element-5">Li=max(0,-7-13+10)+max(0,11-13+10)</script> 
 <br> 可以看到第一个部分结果是0，这是因为[-7-13+10]得到的是负数，经过函数处理后得到0。这一对类别分数和标签的损失值是0，这是因为正确分类的得分13与错误分类的得分-7的差为20，高于边界值10。而SVM只关心差距至少要大于10，更大的差值还是算作损失值为0。第二个部分计算[11-13+10]得到8。虽然正确分类的得分比不正确分类的得分要高（13&gt;11），但是比10的边界值还是小了，分差只有2，这就是为什么损失值等于8。简而言之，SVM的损失函数想要正确分类类别的分数比不正确类别分数高，而且至少要高。如果不满足这点，就开始计算损失值。 
 <br> 那么在这次的模型中，我们面对的是线性评分函数（f(x_i,W)=Wx_i），所以我们可以将损失函数的公式稍微改写一下： 
 <br> 
 <span class="MathJax_Preview"></span> 
 <div class="MathJax_Display" style="text-align: center;"> 
  <span class="MathJax" id="MathJax-Element-6-Frame"> 
    
    <span class="math" id="MathJax-Span-96" style="width: 19.203em; display: inline-block;"><span style="display: inline-block; position: relative; width: 15.363em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.603em 1000em 4.269em -0.424em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-97"><span class="msubsup" id="MathJax-Span-98"><span style="display: inline-block; position: relative; width: 1.016em; height: 0px;"><span style="position: absolute; clip: rect(1.709em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-99" style="font-family: MathJax_Math-italic;">L</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.696em;"><span class="mi" id="MathJax-Span-100" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-101" style="font-family: MathJax_Main; padding-left: 0.269em;">=</span><span class="munderover" id="MathJax-Span-102" style="padding-left: 0.269em;"><span style="display: inline-block; position: relative; width: 1.496em; height: 0px;"><span style="position: absolute; clip: rect(2.669em 1000em 4.376em -0.424em); top: -3.784em; left: 0.056em;"><span class="mo" id="MathJax-Span-103" style="font-family: MathJax_Size2; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 3.789em;"></span></span><span style="position: absolute; clip: rect(1.869em 1000em 2.936em -0.477em); top: -1.384em; left: 0.003em;"><span class="texatom" id="MathJax-Span-104"><span class="mrow" id="MathJax-Span-105"><span class="mi" id="MathJax-Span-106" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-107" style="font-size: 70.7%; font-family: MathJax_Main;">≠</span><span class="msubsup" id="MathJax-Span-108"><span style="display: inline-block; position: relative; width: 0.643em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.776em -0.477em); top: -2.451em; left: 0.003em;"><span class="mi" id="MathJax-Span-109" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.376em;"><span class="mi" id="MathJax-Span-110" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.509em;"></span></span></span></span><span class="mi" id="MathJax-Span-111" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">m</span><span class="mi" id="MathJax-Span-112" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-113" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-114" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-115" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-116" style="font-family: MathJax_Main;">,</span><span class="msubsup" id="MathJax-Span-117" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 1.229em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.477em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-118" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; clip: rect(1.816em 1000em 2.616em -0.477em); top: -2.771em; left: 0.696em;"><span class="mi" id="MathJax-Span-119" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; clip: rect(1.816em 1000em 2.776em -0.477em); top: -2.131em; left: 0.696em;"><span class="mi" id="MathJax-Span-120" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-121"><span style="display: inline-block; position: relative; width: 0.909em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-122" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.589em;"><span class="mi" id="MathJax-Span-123" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-124" style="font-family: MathJax_Main; padding-left: 0.216em;">−</span><span class="msubsup" id="MathJax-Span-125" style="padding-left: 0.216em;"><span style="display: inline-block; position: relative; width: 1.389em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.477em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-126" style="font-family: MathJax_Math-italic;">w</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; clip: rect(1.816em 1000em 2.616em -0.477em); top: -2.771em; left: 0.696em;"><span class="mi" id="MathJax-Span-127" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; clip: rect(3.523em 1000em 4.323em -0.477em); top: -3.837em; left: 0.696em;"><span class="texatom" id="MathJax-Span-128"><span class="mrow" id="MathJax-Span-129"><span class="msubsup" id="MathJax-Span-130"><span style="display: inline-block; position: relative; width: 0.643em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.776em -0.477em); top: -2.451em; left: 0.003em;"><span class="mi" id="MathJax-Span-131" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.376em;"><span class="mi" id="MathJax-Span-132" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.003em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-133"><span style="display: inline-block; position: relative; width: 0.909em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-134" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.589em;"><span class="mi" id="MathJax-Span-135" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-136" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mi" id="MathJax-Span-137" style="font-family: MathJax_Main; padding-left: 0.216em;">Δ</span><span class="mo" id="MathJax-Span-138" style="font-family: MathJax_Main;">)</span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 3.07em; vertical-align: -1.797em;"></span></span> 
   </span> 
 </div><script type="math/tex; mode=display" id="MathJax-Element-6">L_i=\sum_{j\not=y_i}max(0,w^T_jx_i-w^T_{y_i}x_i+\Delta)</script> 
 <br> 其中w_j是权重W的第j行，被变形为列向量。然而，一旦开始考虑更复杂的评分函数f公式，这样做就不是必须的了。 
 <p></p> 
</blockquote> 
<p></p> 
</li><li><strong>正则化(Regularization):</strong>上面损失函数有一个问题。假设有一个数据集和一个权重集W能够正确地分类每个数据（即所有的边界都满足，对于所有的i都有）。问题在于这个W并不唯一：可能有很多相似的W都能正确地分类所有的数据。</li><li><p></p> 
<blockquote> 
 <p>一个简单的例子：如果W能够正确分类所有数据，即对于每个数据，损失值都是0。那么当时，任何数乘都能使得损失值为0，因为这个变化将所有分值的大小都均等地扩大了，所以它们之间的绝对差值也扩大了。举个例子，如果一个正确分类的分值和举例它最近的错误分类的分值的差距是15，对W乘以2将使得差距变成30。</p> 
</blockquote> 
<p>当然,在没有这种模糊性的情况下我们能很好的控制偏差。而减少这种模糊性的方法是向损失函数增加一个<strong>正则化惩罚（regularization penalty）</strong>部分。最常用的正则化惩罚是L2范式，L2范式通过对所有参数进行逐元素的平方惩罚来抑制大数值的权重,将其展开完整公式是: <br> <span class="MathJax_Preview"></span></p> 
<div class="MathJax_Display" style="text-align: center;"> 
 <span class="MathJax" id="MathJax-Element-7-Frame"> 
   
   <span class="math" id="MathJax-Span-139" style="width: 36.749em; display: inline-block;"><span style="display: inline-block; position: relative; width: 29.389em; height: 0px; font-size: 125%;"><span style="position: absolute; clip: rect(1.229em 1000em 4.269em -0.424em); top: -2.717em; left: 0.003em;"><span class="mrow" id="MathJax-Span-140"><span class="mi" id="MathJax-Span-141" style="font-family: MathJax_Math-italic;">L</span><span class="mo" id="MathJax-Span-142" style="font-family: MathJax_Main; padding-left: 0.269em;">=</span><span class="mfrac" id="MathJax-Span-143" style="padding-left: 0.269em;"><span style="display: inline-block; position: relative; width: 1.016em; height: 0px; margin-right: 0.109em; margin-left: 0.109em;"><span style="position: absolute; clip: rect(1.923em 1000em 2.883em -0.371em); top: -3.411em; left: 50%; margin-left: -0.211em;"><span class="mn" id="MathJax-Span-144" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span><span style="position: absolute; clip: rect(1.709em 1000em 2.723em -0.424em); top: -1.864em; left: 50%; margin-left: -0.424em;"><span class="mi" id="MathJax-Span-145" style="font-family: MathJax_Math-italic;">N<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; clip: rect(0.856em 1000em 1.229em -0.477em); top: -1.277em; left: 0.003em;"><span style="border-left: 1.016em solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0.003em;"></span><span style="display: inline-block; width: 0px; height: 1.069em;"></span></span></span></span><span class="munderover" id="MathJax-Span-146" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 1.443em; height: 0px;"><span style="position: absolute; clip: rect(2.669em 1000em 4.376em -0.424em); top: -3.784em; left: 0.003em;"><span class="mo" id="MathJax-Span-147" style="font-family: MathJax_Size2; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 3.789em;"></span></span><span style="position: absolute; clip: rect(1.816em 1000em 2.723em -0.477em); top: -1.384em; left: 0.589em;"><span class="mi" id="MathJax-Span-148" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="munderover" id="MathJax-Span-149" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 1.496em; height: 0px;"><span style="position: absolute; clip: rect(2.669em 1000em 4.376em -0.424em); top: -3.784em; left: 0.056em;"><span class="mo" id="MathJax-Span-150" style="font-family: MathJax_Size2; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 3.789em;"></span></span><span style="position: absolute; clip: rect(1.869em 1000em 2.936em -0.477em); top: -1.384em; left: 0.003em;"><span class="texatom" id="MathJax-Span-151"><span class="mrow" id="MathJax-Span-152"><span class="mi" id="MathJax-Span-153" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span class="mo" id="MathJax-Span-154" style="font-size: 70.7%; font-family: MathJax_Main;">≠</span><span class="msubsup" id="MathJax-Span-155"><span style="display: inline-block; position: relative; width: 0.643em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.776em -0.477em); top: -2.451em; left: 0.003em;"><span class="mi" id="MathJax-Span-156" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.376em;"><span class="mi" id="MathJax-Span-157" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.509em;"></span></span></span></span><span class="mo" id="MathJax-Span-158" style="font-family: MathJax_Main;">[</span><span class="mi" id="MathJax-Span-159" style="font-family: MathJax_Math-italic;">m</span><span class="mi" id="MathJax-Span-160" style="font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-161" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-162" style="font-family: MathJax_Main;">(</span><span class="mn" id="MathJax-Span-163" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-164" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-165" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.056em;"></span></span><span class="mo" id="MathJax-Span-166" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-167"><span style="display: inline-block; position: relative; width: 0.909em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-168" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.589em;"><span class="mi" id="MathJax-Span-169" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-170" style="font-family: MathJax_Main;">;</span><span class="mi" id="MathJax-Span-171" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="msubsup" id="MathJax-Span-172"><span style="display: inline-block; position: relative; width: 0.696em; height: 0px;"><span style="position: absolute; clip: rect(1.816em 1000em 3.149em -0.424em); top: -2.717em; left: 0.003em;"><span class="mo" id="MathJax-Span-173" style="font-family: MathJax_Main;">)</span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span><span style="position: absolute; top: -2.184em; left: 0.376em;"><span class="mi" id="MathJax-Span-174" style="font-size: 70.7%; font-family: MathJax_Math-italic;">j</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-175" style="font-family: MathJax_Main; padding-left: 0.216em;">−</span><span class="mi" id="MathJax-Span-176" style="font-family: MathJax_Math-italic; padding-left: 0.216em;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.056em;"></span></span><span class="mo" id="MathJax-Span-177" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-178"><span style="display: inline-block; position: relative; width: 0.909em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-179" style="font-family: MathJax_Math-italic;">x</span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.589em;"><span class="mi" id="MathJax-Span-180" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="mo" id="MathJax-Span-181" style="font-family: MathJax_Main;">;</span><span class="mi" id="MathJax-Span-182" style="font-family: MathJax_Math-italic; padding-left: 0.163em;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span class="msubsup" id="MathJax-Span-183"><span style="display: inline-block; position: relative; width: 1.069em; height: 0px;"><span style="position: absolute; clip: rect(1.816em 1000em 3.149em -0.424em); top: -2.717em; left: 0.003em;"><span class="mo" id="MathJax-Span-184" style="font-family: MathJax_Main;">)</span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span><span style="position: absolute; top: -3.731em; left: 0.376em;"><span class="texatom" id="MathJax-Span-185"><span class="mrow" id="MathJax-Span-186"><span class="msubsup" id="MathJax-Span-187"><span style="display: inline-block; position: relative; width: 0.643em; height: 0px;"><span style="position: absolute; clip: rect(1.976em 1000em 2.776em -0.477em); top: -2.451em; left: 0.003em;"><span class="mi" id="MathJax-Span-188" style="font-size: 70.7%; font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span><span style="position: absolute; top: -2.291em; left: 0.376em;"><span class="mi" id="MathJax-Span-189" style="font-size: 50%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.003em;"></span></span></span></span><span class="mo" id="MathJax-Span-190" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mi" id="MathJax-Span-191" style="font-family: MathJax_Main; padding-left: 0.216em;">Δ</span><span class="mo" id="MathJax-Span-192" style="font-family: MathJax_Main;">)</span><span class="mo" id="MathJax-Span-193" style="font-family: MathJax_Main;">]</span><span class="mo" id="MathJax-Span-194" style="font-family: MathJax_Main; padding-left: 0.216em;">+</span><span class="mi" id="MathJax-Span-195" style="font-family: MathJax_Math-italic; padding-left: 0.216em;">λ</span><span class="munderover" id="MathJax-Span-196" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 1.443em; height: 0px;"><span style="position: absolute; clip: rect(2.669em 1000em 4.376em -0.424em); top: -3.784em; left: 0.003em;"><span class="mo" id="MathJax-Span-197" style="font-family: MathJax_Size2; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 3.789em;"></span></span><span style="position: absolute; clip: rect(1.816em 1000em 2.723em -0.424em); top: -1.331em; left: 0.536em;"><span class="mi" id="MathJax-Span-198" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="munderover" id="MathJax-Span-199" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 1.443em; height: 0px;"><span style="position: absolute; clip: rect(2.669em 1000em 4.376em -0.424em); top: -3.784em; left: 0.003em;"><span class="mo" id="MathJax-Span-200" style="font-family: MathJax_Size2; vertical-align: 0.003em;">∑</span><span style="display: inline-block; width: 0px; height: 3.789em;"></span></span><span style="position: absolute; clip: rect(1.816em 1000em 2.723em -0.424em); top: -1.331em; left: 0.643em;"><span class="mi" id="MathJax-Span-201" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span><span style="display: inline-block; width: 0px; height: 2.456em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-202" style="padding-left: 0.163em;"><span style="display: inline-block; position: relative; width: 1.816em; height: 0px;"><span style="position: absolute; clip: rect(1.709em 1000em 2.723em -0.424em); top: -2.557em; left: 0.003em;"><span class="mi" id="MathJax-Span-203" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.109em;"></span></span><span style="display: inline-block; width: 0px; height: 2.563em;"></span></span><span style="position: absolute; clip: rect(1.869em 1000em 2.669em -0.424em); top: -2.931em; left: 1.176em;"><span class="mn" id="MathJax-Span-204" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 2.509em;"></span></span><span style="position: absolute; clip: rect(1.869em 1000em 2.829em -0.424em); top: -2.237em; left: 0.963em;"><span class="texatom" id="MathJax-Span-205"><span class="mrow" id="MathJax-Span-206"><span class="mi" id="MathJax-Span-207" style="font-size: 70.7%; font-family: MathJax_Math-italic;">k</span><span class="mo" id="MathJax-Span-208" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-209" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span></span></span><span style="display: inline-block; width: 0px; height: 2.509em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.723em;"></span></span></span><span style="border-left: 0.003em solid; display: inline-block; overflow: hidden; width: 0px; height: 3.537em; vertical-align: -1.797em;"></span></span> 
  </span> 
</div><script type="math/tex; mode=display" id="MathJax-Element-7">L=\frac{1}{N}\sum_i\sum_{j\not=y_i}[max(0,f(x_i;W)_j-f(x_i;W)_{y_i}+\Delta)]+\lambda \sum_k \sum_l W^2_{k,l}</script> 
<p></p> 
<p>其中，N是训练集的数据量。现在正则化惩罚添加到了损失函数里面，并用超参数来计算其权重。该超参数无法简单确定，需要通过交叉验证来获取,引入了L2惩罚后，SVM们就有了最大边界这一良好性质。（如果感兴趣，可以查看<a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf" rel="nofollow">CS229课程</a>）。</p> 
<hr> 
<h3 id="svm实现">SVM实现：</h3> 
<hr> 
<p></p> 
</li><li>linear_svm.py</li><li><p></p> 
<pre class="prettyprint"><code class="language-pyhton hljs python"><span class="hljs-comment">#coding:utf-8</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> shuffle

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">svm_loss_naive</span><span class="hljs-params">(W, X, y, reg)</span>:</span>
  <span class="hljs-string">"""
  Structured SVM loss function, naive implementation (with loops).

  Inputs have dimension D, there are C classes, and we operate on minibatches
  of N examples.

  Inputs:
  - W: A numpy array of shape (D, C) containing weights.
  - X: A numpy array of shape (N, D) containing a minibatch of data.
  - y: A numpy array of shape (N,) containing training labels; y[i] = c means
    that X[i] has label c, where 0 &lt;= c &lt; C.
  - reg: (float) regularization strength

  Returns a tuple of:
  - loss as single float
  - gradient with respect to weights W; an array of same shape as W
  """</span>
  dW = np.zeros(W.shape) <span class="hljs-comment"># initialize the gradient as zero</span>

  <span class="hljs-comment"># compute the loss and the gradient</span>
  num_classes = W.shape[<span class="hljs-number">1</span>]
  num_train = X.shape[<span class="hljs-number">0</span>]
  loss = <span class="hljs-number">0.0</span>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> xrange(num_train):
    scores = X[i].dot(W)
    correct_class_score = scores[y[i]]
    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> xrange(num_classes):
      <span class="hljs-keyword">if</span> j == y[i]:
        <span class="hljs-keyword">continue</span>
      margin = scores[j] - correct_class_score + <span class="hljs-number">1</span> <span class="hljs-comment"># note delta = 1</span>
      <span class="hljs-keyword">if</span> margin &gt; <span class="hljs-number">0</span>:
        loss += margin
        dW[:, y[i]] += -X[i, :]    
        dW[:, j] += X[i, :]         

  <span class="hljs-comment"># Right now the loss is a sum over all training examples, but we want it</span>
  <span class="hljs-comment"># to be an average instead so we divide by num_train.</span>
  loss /= num_train
  dW /= num_train
  <span class="hljs-comment"># Add regularization to the loss.</span>
  loss +=  reg * np.sum(W * W)
  dW += reg * W

  <span class="hljs-keyword">return</span> loss, dW


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">svm_loss_vectorized</span><span class="hljs-params">(W, X, y, reg)</span>:</span>
  <span class="hljs-string">"""
  Structured SVM loss function, vectorized implementation.

  Inputs and outputs are the same as svm_loss_naive.
  """</span>
  loss = <span class="hljs-number">0.0</span>
  dW = np.zeros(W.shape) <span class="hljs-comment"># initialize the gradient as zero</span>
  scores = X.dot(W)        
  num_classes = W.shape[<span class="hljs-number">1</span>]
  num_train = X.shape[<span class="hljs-number">0</span>]

  scores_correct = scores[np.arange(num_train), y]   <span class="hljs-comment"># 1 by N</span>
  scores_correct = np.reshape(scores_correct, (num_train, -<span class="hljs-number">1</span>))  <span class="hljs-comment"># N by 1</span>
  margins = scores - scores_correct + <span class="hljs-number">1</span>    <span class="hljs-comment"># N by C</span>
  margins = np.maximum(<span class="hljs-number">0</span>,margins)
  margins[np.arange(num_train), y] = <span class="hljs-number">0</span>
  loss += np.sum(margins) / num_train
  loss += <span class="hljs-number">0.5</span> * reg * np.sum(W * W)

  <span class="hljs-comment"># compute the gradient</span>
  margins[margins &gt; <span class="hljs-number">0</span>] = <span class="hljs-number">1</span>
  row_sum = np.sum(margins, axis=<span class="hljs-number">1</span>)                  <span class="hljs-comment"># 1 by N</span>
  margins[np.arange(num_train), y] = -row_sum        
  dW += np.dot(X.T, margins)/num_train + reg * W     <span class="hljs-comment"># D by C</span>

  <span class="hljs-keyword">return</span> loss, dW</code></pre> 
<p></p> 
</li><li>linear_classifier.py</li><li><p></p> 
<pre class="prettyprint"><code class="language-python hljs "><span class="hljs-comment">#coding:utf-8</span>
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> classifiers.linear_svm <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> classifiers.softmax <span class="hljs-keyword">import</span> *

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LinearClassifier</span><span class="hljs-params">(object)</span>:</span>

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,w=None)</span>:</span>
    self.W = w

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(self, X, y, learning_rate=<span class="hljs-number">1e-3</span>, reg=<span class="hljs-number">1e-5</span>, num_iters=<span class="hljs-number">100</span>,
            batch_size=<span class="hljs-number">200</span>, verbose=False)</span>:</span>
    <span class="hljs-string">"""
    Train this linear classifier using stochastic gradient descent.

    Inputs:
    - X: A numpy array of shape (N, D) containing training data; there are N
      training samples each of dimension D.
    - y: A numpy array of shape (N,) containing training labels; y[i] = c
      means that X[i] has label 0 &lt;= c &lt; C for C classes.
    - learning_rate: (float) learning rate for optimization.
    - reg: (float) regularization strength.
    - num_iters: (integer) number of steps to take when optimizing
    - batch_size: (integer) number of training examples to use at each step.
    - verbose: (boolean) If true, print progress during optimization.

    Outputs:
    A list containing the value of the loss function at each training iteration.
    """</span>
    num_train, dim = X.shape
    num_classes = np.max(y) + <span class="hljs-number">1</span> <span class="hljs-comment"># assume y takes values 0...K-1 where K is number of classes</span>
    <span class="hljs-keyword">if</span> self.W <span class="hljs-keyword">is</span> <span class="hljs-keyword">None</span>:
      <span class="hljs-comment"># lazily initialize W</span>
      self.W = <span class="hljs-number">0.001</span> * np.random.randn(dim, num_classes)

    <span class="hljs-comment"># Run stochastic gradient descent to optimize W</span>
    loss_history = []
    <span class="hljs-keyword">for</span> it <span class="hljs-keyword">in</span> xrange(num_iters):
      X_batch = <span class="hljs-keyword">None</span>
      y_batch = <span class="hljs-keyword">None</span>

      sample_index = np.random.choice(num_train, batch_size, replace=<span class="hljs-keyword">False</span>)
      X_batch = X[sample_index, :]   <span class="hljs-comment"># select the batch sample</span>
      y_batch = y[sample_index]      <span class="hljs-comment"># select the batch label</span>

      <span class="hljs-comment"># evaluate loss and gradient</span>
      loss, grad = self.loss(X_batch, y_batch, reg)
      loss_history.append(loss)

      <span class="hljs-comment"># perform parameter update</span>
      self.W += -learning_rate * grad

      <span class="hljs-keyword">if</span> verbose <span class="hljs-keyword">and</span> it % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:
        <span class="hljs-keyword">print</span> <span class="hljs-string">'iteration %d / %d: loss %f'</span> % (it, num_iters, loss)

    <span class="hljs-keyword">return</span> loss_history

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict</span><span class="hljs-params">(self, X)</span>:</span>
    <span class="hljs-string">"""
    Use the trained weights of this linear classifier to predict labels for
    data points.

    Inputs:
    - X: D x N array of training data. Each column is a D-dimensional point.

    Returns:
    - y_pred: Predicted labels for the data in X. y_pred is a 1-dimensional
      array of length N, and each element is an integer giving the predicted
      class.
    """</span>
    y_pred = np.zeros(X.shape[<span class="hljs-number">1</span>])
    score = X.dot(self.W)
    y_pred = np.argmax(score,axis=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">return</span> y_pred

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss</span><span class="hljs-params">(self, X_batch, y_batch, reg)</span>:</span>
    <span class="hljs-string">"""
    Compute the loss function and its derivative. 
    Subclasses will override this.

    Inputs:
    - X_batch: A numpy array of shape (N, D) containing a minibatch of N
      data points; each point has dimension D.
    - y_batch: A numpy array of shape (N,) containing labels for the minibatch.
    - reg: (float) regularization strength.

    Returns: A tuple containing:
    - loss as a single float
    - gradient with respect to self.W; an array of the same shape as W
    """</span>
    <span class="hljs-keyword">pass</span>


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">LinearSVM</span><span class="hljs-params">(LinearClassifier)</span>:</span>
  <span class="hljs-string">""" A subclass that uses the Multiclass SVM loss function """</span>

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss</span><span class="hljs-params">(self, X_batch, y_batch, reg)</span>:</span>
    <span class="hljs-keyword">return</span> svm_loss_vectorized(self.W, X_batch, y_batch, reg)


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Softmax</span><span class="hljs-params">(LinearClassifier)</span>:</span>
  <span class="hljs-string">""" A subclass that uses the Softmax + Cross-entropy loss function """</span>

  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">loss</span><span class="hljs-params">(self, X_batch, y_batch, reg)</span>:</span>
    <span class="hljs-keyword">return</span> softmax_loss_vectorized(self.W, X_batch, y_batch, reg)</code></pre> 
<h2 id="测试">测试：</h2> 
<hr> 
<p>不同参数下SVM10类分类的准确率如下： <br> <img src="https://images2.imgbox.com/21/ac/X6ZjOXYa_o.png" alt="超参数结果" title=""></p> 
<h2 id="总结">总结：</h2> 
<hr> 
<p>SVM在分类少以及线性的情况下有非常好的分类效果（尤其是二类），在配合PCA的情况下会有更好的结果。</p></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/7100ffcd27bfe105d667f0ce4fec42b4/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">java8前后对Collections集合排序操作对比，以及java8版本后的使用lambda对集合Collections操作</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/9e6ee253d070437220f4725e48f65601/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java 8 中 Date与LocalDateTime、LocalDate、LocalTime互转</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>