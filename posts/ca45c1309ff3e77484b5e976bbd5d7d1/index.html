<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Redis高级篇（一） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Redis高级篇（一）" />
<meta property="og:description" content="1.Redis持久化 Redis有两种持久化方案：RDB持久化、AOF持久化
1.1.RDB持久化 什么是RDB持久化
RDB 持久化是指 Redis 可以通过创建快照，来获得存储在内存里面的数据在 某个时间点 上的副本。Redis 得到副本之后，可以将副本留在当前服务器，在重启服务器或者服务器故障的时候使用，也可以将副本复制到其他服务器，从而创建具有相同数据的服务器副本，比如将副本从主库复制到从库一份。快照文件称为 RDB 文件，默认是保存在当前运行目录。
RDB的缺点
RDB 执行间隔时间长，两次 RDB 之间写入数据有丢失的风险
fork 子进程、压缩、写出 RDB 文件都比较耗时
1.1.1.执行时机 RDB 持久化在四种情况下会执行：
执行 save 命令
执行 bgsave 命令
Redis 停机时，触发 save 命令
触发 RDB 条件时，Redis就会自动触发 bgsave 命令
1）save 命令
执行下面的命令，可以立即执行一次 RDB，save 命令会导致主进程执行 RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。
2）bgsave命令
下面的命令可以异步执行RDB：
这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。
3）停机时
Redis停机时会执行一次save命令，实现RDB持久化。
4）触发RDB条件
Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：
# 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save &#34;&#34; 则表示禁用RDB save 900 1 save 300 10 save 60 10000 RDB的其它配置也可以在redis.conf文件中设置：" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ca45c1309ff3e77484b5e976bbd5d7d1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-11-19T20:21:36+08:00" />
<meta property="article:modified_time" content="2023-11-19T20:21:36+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Redis高级篇（一）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <h2>1.Redis持久化</h2> 
<p>Redis有两种持久化方案：RDB持久化、AOF持久化</p> 
<h3>1.1.RDB持久化</h3> 
<p><strong>什么是RDB持久化</strong></p> 
<p>RDB 持久化是指 Redis 可以通过创建快照，来获得存储在内存里面的数据在 <strong>某个时间点</strong> 上的副本。Redis 得到副本之后，可以将副本留在当前服务器，在重启服务器或者服务器故障的时候使用，也可以将副本复制到其他服务器，从而创建具有相同数据的服务器副本，比如将副本从主库复制到从库一份。快照文件称为 RDB 文件，默认是保存在当前运行目录。</p> 
<p><strong>RDB的缺点</strong></p> 
<ul><li> <p>RDB 执行间隔时间长，两次 RDB 之间写入数据有丢失的风险</p> </li><li> <p>fork 子进程、压缩、写出 RDB 文件都比较耗时</p> </li></ul> 
<h4>1.1.1.执行时机</h4> 
<p>RDB 持久化在四种情况下会执行：</p> 
<ul><li> <p>执行 save 命令</p> </li><li> <p>执行 bgsave 命令</p> </li><li> <p><strong>Redis 停机时，</strong>触发 save 命令</p> </li><li> <p><strong>触发 RDB 条件时</strong>，Redis就会自动触发 bgsave 命令</p> </li></ul> 
<p><strong>1）save 命令</strong></p> 
<p>执行下面的命令，可以立即执行一次 RDB，save 命令会导致主进程执行 RDB，这个过程中其它所有命令都会被阻塞。只有在数据迁移时可能用到。</p> 
<p class="img-center"><img alt="" height="159" src="https://images2.imgbox.com/47/f5/xGFsEdYV_o.png" width="900"></p> 
<p><strong>2）bgsave命令</strong></p> 
<p>下面的命令可以异步执行RDB：</p> 
<p class="img-center"><img alt="" height="86" src="https://images2.imgbox.com/64/95/DYq2LpdB_o.png" width="900"></p> 
<p>这个命令执行后会开启独立进程完成RDB，主进程可以持续处理用户请求，不受影响。</p> 
<p><strong>3）停机时</strong></p> 
<p>Redis停机时会执行一次save命令，实现RDB持久化。</p> 
<p><strong>4）触发RDB条件</strong></p> 
<p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p> 
<pre><code class="language-XML"># 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save "" 则表示禁用RDB
save 900 1  
save 300 10  
save 60 10000 </code></pre> 
<p>RDB的其它配置也可以在redis.conf文件中设置：</p> 
<pre><code class="language-XML"># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱
rdbcompression yes
​
# RDB文件名称
dbfilename dump.rdb  
​
# 文件保存的路径目录
dir ./ </code></pre> 
<h4>1.1.2.RDB原理</h4> 
<p>bgsave 开始时会 fork 主进程得到子进程，子进程共享主进程的内存数据。完成 fork 后子线程可以读取直接的内存数据并写入 RDB 文件。</p> 
<p>fork 采用的是 copy-on-write 技术：</p> 
<ul><li> <p>当主进程执行读操作时，访问共享内存；</p> </li><li> <p>当主进程执行写操作时，则会拷贝一份数据，执行写操作。</p> </li></ul> 
<p>如果执行的是 SAVE 命令，则会使主进程执行 RDB 持久化。在持久化过程中，Redis 不能处理任何其他命令，这意味着整个 Redis 服务器会被阻塞，直到 RDB 持久化完成。<strong>因此，SAVE 命令通常在 Redis 停机时使用，</strong>以确保所有数据都被保存到磁盘。</p> 
<p>如果执行的是 bgsave 命令，主进程会 fork 一个子进程，并复制主进程的页表给子进程，子进程可以通过页表来共享主进程的内存数据，从而将共享内存中的数据写到磁盘上的 RDB 文件。fork 采用的是 copy-on-write 技术：</p> 
<ul><li> <p>当有读请求访问主进程时，访问共享内存；</p> </li><li> <p>当有写请求访问主进程时，则会拷贝一份共享内存中的数据，执行写操作。</p> </li></ul> 
<p class="img-center"><img alt="" height="361" src="https://images2.imgbox.com/53/46/HqvST6LY_o.png" width="1000"></p> 
<blockquote> 
 <p><strong>Note：</strong></p> 
 <ul><li> <p>在Linux操作系统中，每个进程都有自己的虚拟内存和页表，页表维护了虚拟内存和直接内存的映射关系，进程通过操作虚拟内存来操作直接内存。</p> </li><li> <p>在Linux中，进程将数据从内存写入磁盘时，通常是通过虚拟内存和文件系统之间的交互来完成的。</p> </li><li> <p>主进程在进行 RDB 时会创建子进程，并复制主进程的页表给子进程，这样，子进程就可以通过这个页表来和主进程共享直接内存中的数据，子进程就可以通过操作虚拟内存将直接内存中数据写到磁盘上的 RDB 文件。</p> </li></ul> 
</blockquote> 
<h3>1.2.AOF持久化</h3> 
<h4>1.2.1.AOF原理</h4> 
<p>AOF 也是用来实现 Redis 中数据的持久化，AOF 默认是关闭的，开启 AOF 持久化后每执行一条更改数据的命令，Redis 就会将该命令写入到 AOF 缓冲区，然后再将 AOF 缓冲区的数据写入到系统内核缓冲区，最后再根据持久化方式的配置来决定何时将系统内核缓存区的数据同步到磁盘中。</p> 
<p class="img-center"><img alt="" height="335" src="https://images2.imgbox.com/d5/de/YNatmSua_o.png" width="700"></p> 
<h4 style="background-color:transparent;">1.2.2.AOF配置</h4> 
<p>AOF默认是关闭的，需要修改 redis.conf 配置文件来开启 AOF：</p> 
<pre><code class="language-XML"># 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename "appendonly.aof"</code></pre> 
<p>AOF 的持久化策略也可以通过 redis.conf 文件来配：</p> 
<pre><code class="language-XML"># 表示每执行一次写命令，立即记录到AOF文件
appendfsync always 
# 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec 
# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no</code></pre> 
<p>三种策略对比：</p> 
<p class="img-center"><img alt="" height="149" src="https://images2.imgbox.com/d1/5e/kxYq6OON_o.png" width="900"></p> 
<h4>1.2.3.AOF文件重写</h4> 
<p>因为是记录命令，AOF 文件会比 RDB 文件大的多。而且 AOF 会记录对同一个 key 的多次写操作，但只有最后一次写操作才有意义。通过执行 bgrewriteaof 命令，可以让磁盘上的 AOF 文件执行重写功能，用最少的命令达到相同效果。</p> 
<p class="img-center"><img alt="" height="85" src="https://images2.imgbox.com/d5/f3/97fO2JFE_o.png" width="700"></p> 
<p>如图，AOF原本有三个命令，但是 set num 123 和 set num 666 都是对 num 的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。所以重写命令后，AOF文件内容就是：mset name jack num 666</p> 
<p>Redis 也会在触发阈值时自动去重写 AOF 文件。阈值也可以在 redis.conf 中配置：</p> 
<pre><code class="language-XML"># AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写 
auto-aof-rewrite-min-size 64mb </code></pre> 
<h3>1.3.RDB与AOF对比</h3> 
<p>RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会<strong>结合</strong>两者来使用。</p> 
<p class="img-center"><img alt="" height="290" src="https://images2.imgbox.com/8f/02/HBONhrxQ_o.png" width="800"></p> 
<h2>2.Redis主从</h2> 
<p>单机的Redis存在的四大问题：</p> 
<p class="img-center"><img alt="" height="279" src="https://images2.imgbox.com/e1/6d/Uva3I41E_o.png" width="700"></p> 
<h3>2.1.搭建主从架构</h3> 
<p>单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。</p> 
<p class="img-center"><img alt="" height="321" src="https://images2.imgbox.com/d8/6d/jOtuOc97_o.png" width="700"></p> 
<p>具体搭建流程参考课前资料《Redis集群.md》</p> 
<h3>2.2.主从数据同步原理</h3> 
<h4>2.2.1.全量同步</h4> 
<p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p> 
<p class="img-center"><img alt="" height="382" src="https://images2.imgbox.com/e9/15/PPKDczDm_o.png" width="700"></p> 
<p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p> 
<p>有几个概念，可以作为判断依据：</p> 
<ul><li> <p><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</p> </li><li> <p><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</p> </li></ul> 
<p>因此slave做数据同步，必须向master声明自己的replication id 和 offset，master才可以判断到底需要同步哪些数据。</p> 
<p>因为slave原本也是一个master，有自己的 replid 和 offset，当第一次变成 slave，与 master 建立连接时，发送的 replid 和 offset 是自己的 replid 和 offset。</p> 
<p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p> 
<p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p> 
<p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p> 
<p>如图：</p> 
<p class="img-center"><img alt="" height="383" src="https://images2.imgbox.com/eb/c0/diGESj2E_o.png" width="700"></p> 
<p>完整流程描述：</p> 
<ul><li> <p>slave节点请求增量同步</p> </li><li> <p>master节点判断replid，发现不一致，拒绝增量同步</p> </li><li> <p>master将完整内存数据生成RDB，发送RDB到slave</p> </li><li> <p>slave清空本地数据，加载master的RDB</p> </li><li> <p>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</p> </li><li> <p>slave执行接收到的命令，保持与master之间的同步</p> </li></ul> 
<h4>2.2.2.增量同步</h4> 
<p>全量同步需要先做RDB，然后将RDB文件通过网络传输给 slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p> 
<p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p> 
<p class="img-center"><img alt="" height="284" src="https://images2.imgbox.com/85/ab/rMngKuYv_o.png" width="700"></p> 
<p>那么master怎么知道slave与自己的数据差异在哪里呢?</p> 
<h4>2.2.3.repl_backlog原理</h4> 
<p>master怎么知道slave与自己的数据差异在哪里呢?</p> 
<p>这就要说到全量同步时的repl_baklog文件了。</p> 
<p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p> 
<p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p> 
<p class="img-center"><img alt="" height="165" src="https://images2.imgbox.com/02/34/m2oOYYcf_o.png" width="200"></p> 
<p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p> 
<p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p> 
<p class="img-center"><img alt="" height="156" src="https://images2.imgbox.com/a0/39/s1cXjLeV_o.png" width="200"></p> 
<p>直到数组被填满：</p> 
<p class="img-center"><img alt="" height="165" src="https://images2.imgbox.com/74/1d/5RkEAvXM_o.png" width="200"></p> 
<p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p> 
<p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset：</p> 
<p class="img-center"><img alt="" height="182" src="https://images2.imgbox.com/54/ad/9yxKOBRy_o.png" width="200"></p> 
<p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p> 
<p class="img-center"><img alt="" height="168" src="https://images2.imgbox.com/c1/e5/gEo3NWQ0_o.png" width="200"></p> 
<p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p> 
<p class="img-center"><img alt="" height="75" src="https://images2.imgbox.com/35/f6/0xiF2Y7E_o.png" width="700"></p> 
<h3>2.3.主从同步优化</h3> 
<p>主从同步可以保证主从数据的一致性，非常重要。</p> 
<p>可以从以下几个方面来优化Redis主从就集群：</p> 
<ul><li> <p>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</p> </li><li> <p>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</p> </li><li> <p>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</p> </li><li> <p>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</p> </li></ul> 
<p>主从从架构图：</p> 
<p class="img-center"><img alt="" height="214" src="https://images2.imgbox.com/8f/fc/66opyf3Z_o.png" width="700"></p> 
<h2>3.Redis哨兵</h2> 
<p>Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。</p> 
<h3>3.1.哨兵原理</h3> 
<h4>3.1.1.集群结构和作用</h4> 
<p>哨兵的结构如图：</p> 
<p class="img-center"><img alt="" height="525" src="https://images2.imgbox.com/03/31/v95b3mPS_o.png" width="700"></p> 
<p>哨兵的作用如下：</p> 
<ul><li> <p><strong>监控</strong>：Sentinel 会不断检查您的master和slave是否按预期工作</p> </li><li> <p><strong>自动故障恢复</strong>：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主</p> </li><li> <p><strong>通知</strong>：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端</p> </li></ul> 
<h4>3.1.2.集群监控原理</h4> 
<p>Sentinel基于心跳机制监测服务状态，每隔1秒向集群的每个实例发送ping命令：</p> 
<p>•主观下线：如果某sentinel节点发现某实例未在规定时间响应，则认为该实例<strong>主观下线</strong>。</p> 
<p>•客观下线：若超过指定数量（quorum）的sentinel都认为该实例主观下线，则该实例<strong>客观下线</strong>。quorum值最好超过Sentinel实例数量的一半。</p> 
<p class="img-center"><img alt="" height="431" src="https://images2.imgbox.com/fd/10/JApqW7uT_o.png" width="700"></p> 
<h4>3.1.3.集群故障恢复原理</h4> 
<p>一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：</p> 
<ul><li> <p>首先会判断slave节点与master节点断开时间长短，如果超过指定值（down-after-milliseconds * 10）则会排除该slave节点</p> </li><li> <p>然后判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举</p> </li><li> <p>如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高</p> </li><li> <p>最后是判断slave节点的运行id大小，越小优先级越高。</p> </li></ul> 
<p>当选出一个新的master后，该如何实现切换呢？</p> 
<p>流程如下：</p> 
<ul><li> <p>sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master</p> </li><li> <p>sentinel给所有其它slave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据。</p> </li><li> <p>最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点</p> </li></ul> 
<p class="img-center"><img alt="" height="481" src="https://images2.imgbox.com/a0/15/p1VhCyYK_o.png" width="700"></p> 
<h3>3.2.搭建哨兵集群</h3> 
<p>具体搭建流程参考课前资料《Redis集群.md》</p> 
<h3>3.3.RedisTemplate集成哨兵机制</h3> 
<p>在Sentinel集群监管下的Redis主从集群，其节点角色会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。</p> 
<p>下面，我们来实现RedisTemplate集成哨兵机制。</p> 
<p><strong>1.引入依赖</strong></p> 
<p>在项目的pom文件中引入依赖：</p> 
<pre><code class="language-XML">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;
&lt;/dependency&gt;</code></pre> 
<p><strong>2.配置Redis地址</strong></p> 
<p>然后在配置文件application.yml中指定redis的sentinel相关信息：</p> 
<pre><code class="language-XML">spring:
  redis:
    sentinel:
      master: mymaster
      nodes:
        - 192.168.150.101:27001
        - 192.168.150.101:27002
        - 192.168.150.101:27003</code></pre> 
<p><strong>3.配置读写分离</strong></p> 
<p>在项目的启动类中，添加一个新的bean：</p> 
<pre><code class="language-XML">@Bean
public LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer(){
    return clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);
}</code></pre> 
<p>这个bean中配置的就是读写策略，包括四种：</p> 
<ul><li> <p>MASTER：从主节点读取</p> </li><li> <p>MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica</p> </li><li> <p>REPLICA：从slave（replica）节点读取</p> </li><li> <p>REPLICA _PREFERRED：优先从slave（replica）节点读取，所有的slave都不可用才读取master</p> </li></ul> 
<h2>4.Redis分片集群</h2> 
<h3>4.1.搭建分片集群</h3> 
<p>主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：</p> 
<ul><li> <p>海量数据存储问题</p> </li><li> <p>高并发写的问题</p> </li></ul> 
<p>使用分片集群可以解决上述问题，如图:</p> 
<p class="img-center"><img alt="" height="492" src="https://images2.imgbox.com/5b/b3/xAbC8V8F_o.png" width="700"></p> 
<p>分片集群特征：</p> 
<ul><li> <p>集群中有多个master，每个master保存不同数据</p> </li><li> <p>每个master都可以有多个slave节点</p> </li><li> <p>master之间通过ping监测彼此健康状态</p> </li><li> <p>客户端请求可以访问集群任意节点，最终都会被转发到正确节点</p> </li></ul> 
<p>具体搭建流程参考博文：<span style="color:#fe2c24;">Redis集群</span></p> 
<h3>4.2.散列插槽</h3> 
<h4>4.2.1.插槽原理</h4> 
<p>Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到：</p> 
<p></p> 
<p class="img-center"><img alt="" height="140" src="https://images2.imgbox.com/84/05/nVXLYcoK_o.png" width="700"></p> 
<p>数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况：</p> 
<ul><li> <p>key中包含 "{}"，且 "{}" 中至少包含1个字符，"{}" 中的部分是有效部分</p> </li><li> <p>key中不包含 "{}"，整个key都是有效部分</p> </li></ul> 
<p><strong>例如：</strong>key是num，那么就根据num计算，如果是 {itcast}num，则根据 itcast 计算。计算方式是利用 CRC16 算法得到一个 hash 值，然后对 16384 取余，得到的结果就是 slot 值。</p> 
<p class="img-center"><img alt="" height="148" src="https://images2.imgbox.com/68/43/x9RDJo8B_o.png" width="700"></p> 
<p>如图，在7001这个节点执行set a 1时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到103节点。</p> 
<p>到了7003后，执行<code>get num</code>时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点</p> 
<blockquote> 
 <p><strong>总结</strong></p> 
 <p>Redis如何判断某个key应该在哪个实例？</p> 
 <ul><li>查看每个实例被分配到的插槽范围</li><li>根据key的有效部分计算哈希值，对16384取余</li><li>余数作为插槽，寻找插槽所在实例即可</li></ul> 
 <p>如何将同一类数据固定的保存在同一个Redis实例？</p> 
 <ul><li>这一类数据使用相同的有效部分，例如key都以{typeId}为前缀</li></ul> 
</blockquote> 
<h3>4.3.集群伸缩</h3> 
<p>redis-cli --cluster提供了很多操作集群的命令，可以通过下面方式查看：</p> 
<p class="img-center"><img alt="" height="270" src="https://images2.imgbox.com/ea/85/GMJR9jrX_o.png" width="800"></p> 
<p>比如，添加节点的命令：</p> 
<p class="img-center"><img alt="" height="171" src="https://images2.imgbox.com/40/0b/GZNl3d71_o.png" width="800"></p> 
<h4>4.3.1.需求分析</h4> 
<p>需求：向集群中添加一个新的master节点，并向其中存储 num = 10</p> 
<ul><li> <p>启动一个新的redis实例，端口为7004</p> </li><li> <p>添加7004到之前的集群，并作为一个master节点</p> </li><li> <p>给7004节点分配插槽，使得num这个key可以存储到7004实例</p> </li></ul> 
<p>这里需要两个新的功能：</p> 
<ul><li> <p>添加一个节点到集群中</p> </li><li> <p>将部分插槽分配到新插槽</p> </li></ul> 
<h4>4.3.2.创建新的redis实例</h4> 
<p>创建一个文件夹：</p> 
<pre><code class="language-XML">mkdir 7004</code></pre> 
<p>拷贝配置文件：</p> 
<pre><code class="language-XML">cp redis.conf /7004</code></pre> 
<p>修改配置文件：</p> 
<pre><code class="language-XML">sed /s/6379/7004/g 7004/redis.conf</code></pre> 
<p>启动</p> 
<pre><code class="language-XML">redis-server 7004/redis.conf</code></pre> 
<h4>4.3.3.添加新节点到redis</h4> 
<p>添加节点的语法如下：</p> 
<p class="img-center"><img alt="" height="174" src="https://images2.imgbox.com/b4/26/h1fzn9Vf_o.png" width="800"></p> 
<p>执行命令：</p> 
<pre><code class="language-XML">redis-cli --cluster add-node  192.168.150.101:7004 192.168.150.101:7001</code></pre> 
<p>通过命令查看集群状态：</p> 
<pre><code class="language-XML">redis-cli -p 7001 cluster nodes</code></pre> 
<p>如图，7004加入了集群，并且默认是一个master节点：</p> 
<p class="img-center"><img alt="" height="256" src="https://images2.imgbox.com/97/9c/7qyhkVja_o.png" width="800"></p> 
<p>但是，可以看到7004节点的插槽数量为0，因此没有任何数据可以存储到7004上</p> 
<h4>4.3.4.转移插槽</h4> 
<p>我们要将num存储到7004节点，因此需要先看看num的插槽是多少：</p> 
<p class="img-center"><img alt="" height="86" src="https://images2.imgbox.com/13/08/WTJAVDSj_o.png" width="800"></p> 
<p>如上图所示，num的插槽为2765.</p> 
<p>我们可以将0~3000的插槽从7001转移到7004，命令格式如下：</p> 
<p class="img-center"><img alt="" height="528" src="https://images2.imgbox.com/1b/b2/1bUmVUBP_o.png" width="800"></p> 
<p>具体命令如下：</p> 
<p>建立连接：</p> 
<p class="img-center"><img alt="" height="38" src="https://images2.imgbox.com/e1/f1/JhhAGn6W_o.png" width="800"></p> 
<p>得到下面的反馈：</p> 
<p class="img-center"><img alt="" height="147" src="https://images2.imgbox.com/b0/b2/qnxLwxD3_o.png" width="800"></p> 
<p>询问要移动多少个插槽，我们计划是3000个：</p> 
<p>新的问题来了：</p> 
<p class="img-center"><img alt="" height="148" src="https://images2.imgbox.com/cd/f5/QaEGkDzK_o.png" width="800"></p> 
<p>哪个node来接收这些插槽？？</p> 
<p>显然是7004，那么7004节点的id是多少呢？</p> 
<p class="img-center"><img alt="" height="253" src="https://images2.imgbox.com/e4/ce/KZcuOiJM_o.png" width="800"></p> 
<p>复制这个id，然后拷贝到刚才的控制台后：</p> 
<p class="img-center"><img alt="" height="221" src="https://images2.imgbox.com/15/0b/xZWCsFvs_o.png" width="800"></p> 
<p></p> 
<p>这里询问，你的插槽是从哪里移动过来的？</p> 
<ul><li> <p>all：代表全部，也就是三个节点各转移一部分</p> </li><li> <p>具体的id：目标节点的id</p> </li><li> <p>done：没有了</p> </li></ul> 
<p>这里我们要从7001获取，因此填写7001的id：</p> 
<p class="img-center"><img alt="" height="275" src="https://images2.imgbox.com/52/3b/7sarFHbf_o.png" width="800"></p> 
<p>填完后，点击done，这样插槽转移就准备好了：</p> 
<p class="img-center"><img alt="" height="189" src="https://images2.imgbox.com/3f/be/hRsB9yNL_o.png" width="800"></p> 
<p>确认要转移吗？输入yes：</p> 
<p>然后，通过命令查看结果：</p> 
<p class="img-center"><img alt="" height="42" src="https://images2.imgbox.com/e7/ea/uzONFGix_o.png" width="800"></p> 
<p>可以看到：</p> 
<p class="img-center"><img alt="" height="155" src="https://images2.imgbox.com/d5/f9/c3pDVtV2_o.png" width="800"></p> 
<p>目的达成。</p> 
<h3>4.4.故障转移</h3> 
<p>集群初始状态是这样的：</p> 
<p class="img-center"><img alt="" height="92" src="https://images2.imgbox.com/3c/ea/CK14cKsy_o.png" width="800"></p> 
<p>其中7001、7002、7003都是master，我们计划让7002宕机。</p> 
<h4>4.4.1.自动故障转移</h4> 
<p>当集群中有一个master宕机会发生什么呢？</p> 
<p>直接停止一个redis实例，例如7002：</p> 
<pre><code class="language-XML">redis-cli -p 7002 shutdown</code></pre> 
<p>1）首先是该实例与其它实例失去连接</p> 
<p>2）然后是疑似宕机：</p> 
<p class="img-center"><img alt="" height="81" src="https://images2.imgbox.com/24/83/lW6MZOlL_o.png" width="800"></p> 
<p>3）最后是确定下线，自动提升一个slave为新的master：</p> 
<p class="img-center"><img alt="" height="82" src="https://images2.imgbox.com/e5/78/RJ6xk003_o.png" width="800"></p> 
<p>4）当7002再次启动，就会变为一个slave节点了：</p> 
<p class="img-center"><img alt="" height="100" src="https://images2.imgbox.com/8f/0c/HQlWz5di_o.png" width="800"></p> 
<h4>4.4.2.手动故障转移</h4> 
<p>利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。其流程如下：</p> 
<p class="img-center"><img alt="" height="613" src="https://images2.imgbox.com/9b/c3/xFVrx85p_o.png" width="800"></p> 
<p>这种failover命令可以指定三种模式：</p> 
<ul><li> <p>缺省：默认的流程，如图1~6歩</p> </li><li> <p>force：省略了对offset的一致性校验</p> </li><li> <p>takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见</p> </li></ul> 
<p><strong>案例</strong></p> 
<p><strong>需求</strong>：在7002这个slave节点执行手动故障转移，重新夺回master地位</p> 
<p>步骤如下：</p> 
<p>1）利用redis-cli连接7002这个节点</p> 
<p>2）执行cluster failover命令</p> 
<p>如图：</p> 
<p class="img-center"><img alt="" height="89" src="https://images2.imgbox.com/d4/f9/XpbS45qW_o.png" width="800"></p> 
<p>效果：</p> 
<p class="img-center"><img alt="" height="93" src="https://images2.imgbox.com/13/e4/qdunqrle_o.png" width="800"></p> 
<h3>4.5.RedisTemplate访问分片集群</h3> 
<p>RedisTemplate底层同样基于lettuce实现了分片集群的支持，而使用的步骤与哨兵模式基本一致：</p> 
<p>1）引入redis的starter依赖</p> 
<p>2）配置分片集群地址</p> 
<p>3）配置读写分离</p> 
<p>与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下：</p> 
<pre><code class="language-XML">spring:
  redis:
    cluster:
      nodes:
        - 192.168.150.101:7001
        - 192.168.150.101:7002
        - 192.168.150.101:7003
        - 192.168.150.101:8001
        - 192.168.150.101:8002
        - 192.168.150.101:8003</code></pre> 
<p></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/145576bc22392a960408e4f4bc2e6471/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">第三十一周：文献阅读&#43;SVM模型&#43;CNN反向传播</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ff3073298efb76fca9aeb1f813baf2de/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【Web】Ctfshow SSTI刷题记录1</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>