<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>决策树算法 MATLAB 简单实现 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="决策树算法 MATLAB 简单实现" />
<meta property="og:description" content="决策树算法 前言 最近在数据挖掘与机器学习的课程上刚刚学到了决策树算法，于是，想自己用 MATLAB 简单实现一下。虽然拿其中最简单算法的进行实现，但是，从构思–编写–初步完成，也花费了不少时间，毕竟只有动手编写，才能真正体会到算法的内涵。
文章目录 决策树算法前言1 算法流程2 程序设计3 MATLAB 中的调用4 Python 中的调用 1 算法流程 通过阅读机器学习的书籍首先了解决策树算法的基本思想：通过递归的方式构建一棵树，子树是通过选取某一属性，按照其属性值进行划分产生的。其算法伪代码如下：
2 程序设计 程序设计必须对算法的每个细节都要搞清楚，有时可能要实现一个健全完善的算法很困难，我们可以对算法进行简化，忽略复杂的情况，比如，在上面的构建决策树算法的步骤中，子树的划分可能有多个输出，连续属性和无序离散属性的划分的方法也有所不同，如果都要将这些考虑进去程序的设计难度会很大。作为初学者，可以对问题进行简化：
假设无序离散属性都只是二元属性，属性值用0或1表示类别只有两类，用0或1表示每个节点只有两个输出 在明确了细节之后，还需考虑另外一个问题：数据结构。在程序中用什么数据结构来描述所构建的“树”？这一步很关键，因为在对训练集之外的记录进行测试的时候要用到该数据结构。
由于自己实现决策树算法的目的只是加深对算法的理解，并不是实际开发，因此，只是将“树”的结构和参数打印出来。
function build_tree(x, y, L, level, parent_y, sig, p_value) % 自编的用于构建决策树的简单程序，适用于属性为二元属性，二分类情况。（也可对程序进行修改以适用连续属性）。 % 输入： % x：数值矩阵，样本属性记录（每一行为一个样本） % y：数值向量，样本对应的labels % 其它参数调用时可以忽略，在递归时起作用。 % 输出：打印决策树。 if nargin == 2 level = 0; parent_y = -1; L = 1:size(x, 2); sig = -1; p_value = []; % bin_f = zeros(size(x, 2), 1); % for k=1:size(x, 2) % if length(unique(x(:,k))) == 2 % bin_f(k) = 1; % end % end end class = [0, 1]; [r, label] = is_leaf(x, y, parent_y); % 判断是否是叶子节点 if r if sig ==-1 disp([repmat(&#39; &#39;, 1, level), &#39;leaf (&#39;, num2str(label), &#39;)&#39;]); elseif sig ==0 disp([repmat(&#39; &#39;, 1, level), &#39;&lt;&#39;, num2str(p_value),&#39; leaf (&#39;, num2str(label), &#39;)&#39;]); else disp([repmat(&#39; &#39;, 1, level), &#39;&gt;&#39;, num2str(p_value),&#39; leaf (&#39;, num2str(label), &#39;)&#39;]); end else [ind, value, i_] = find_best_test(x, y, L); % 找出最佳的测试值 % % if ind ==1 % keyboard; % end [x1, y1, x2, y2] = split_(x, y, i_, value); % 实施划分 if sig ==-1 disp([repmat(&#39; &#39;, 1, level), &#39;node (&#39;, num2str(ind), &#39;, &#39;, num2str(value), &#39;)&#39;]); elseif sig ==0 disp([repmat(&#39; &#39;, 1, level), &#39;&lt;&#39;, num2str(p_value),&#39; node (&#39;, num2str(ind), &#39;, &#39;, num2str(value), &#39;)&#39;]); else disp([repmat(&#39; &#39;, 1, level), &#39;&gt;&#39;, num2str(p_value),&#39; node (&#39;, num2str(ind), &#39;, &#39;, num2str(value), &#39;)&#39;]); end % if bin_f(i_) == 1 x1(:,i_) = []; x2(:,i_) = []; L(:,i_) = []; % bin_f(i_) = []; % end build_tree(x1, y1, L, level&#43;1, y, 0, value); % 地柜调用 build_tree(x2, y2, L, level&#43;1, y, 1, value); end function [ind, value, i_] = find_best_test(xx, yy, LL) % 子函数：找出最佳测试值（可以对连续属性适用） imp_min = inf; i_ = 1; ind = LL(i_); for i=1:size(xx,2); if length(unique(xx(:,i))) ==1 continue; end % [xx_sorted, ii] = sortrows(xx, i); % yy_sorted = yy(ii, :); vv = unique(xx(:,i)); imp_min_i = inf; best_point = mean([vv(1), vv(2)]); value = best_point; for j = 1:length(vv)-1 point = mean([vv(j), vv(j&#43;1)]); [xx1, yy1, xx2, yy2] = split_(xx, yy, i, point); imp = calc_imp(yy1, yy2); if imp&lt;imp_min_i best_point = point; imp_min_i = imp; end end if imp_min_i &lt; imp_min value = best_point; imp_min = imp_min_i; i_ = i; ind = LL(i_); end end end function imp = calc_imp(y1, y2) % 子函数：计算熵 p11 = sum(y1==class(1))/length(y1); p12 = sum(y1==class(2))/length(y1); p21 = sum(y2==class(1))/length(y2); p22 = sum(y2==class(2))/length(y2); if p11==0 t11 = 0; else t11 = p11*log2(p11); end if p12==0 t12 = 0; else t12 = p12*log2(p12); end if p21==0 t21 = 0; else t21 = p21*log2(p21); end if p22==0 t22 = 0; else t22 = p22*log2(p22); end imp = -t11-t12-t21-t22; end function [x1, y1, x2, y2] = split_(x, y, i, point) % 子函数：实施划分 index = (x(:,i)&lt;point); x1 = x(index,:); y1 = y(index,:); x2 = x(~index,:); y2 = y(~index,:); end function [r, label] = is_leaf(xx, yy, parent_yy) % 子函数：判断是否是叶子节点 if isempty(xx) r = true; label = mode(parent_yy); elseif length(unique(yy)) == 1 r = true; label = unique(yy); else t = xx - repmat(xx(1,:),size(xx, 1), 1); if all(all(t ==0)) r = true; label = mode(yy); else r = false; label = []; end end end end 利用MATLAB提供的数据集进行测试，并与 MATLAB 自身提供的决策树分类的函数进行对比。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/b2c5c47f6e82c2f95a69e0c9bf65aea7/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-10-24T19:22:51+08:00" />
<meta property="article:modified_time" content="2018-10-24T19:22:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">决策树算法 MATLAB 简单实现</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>决策树算法</h2> 
<h3><a id="_2"></a>前言</h3> 
<p>最近在数据挖掘与机器学习的课程上刚刚学到了决策树算法，于是，想自己用 MATLAB 简单实现一下。虽然拿其中最简单算法的进行实现，但是，从构思–编写–初步完成，也花费了不少时间，毕竟只有动手编写，才能真正体会到算法的内涵。</p> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">决策树算法</a></li><li><ul><li><a href="#_2" rel="nofollow">前言</a></li><li><a href="#1__7" rel="nofollow">1 算法流程</a></li><li><a href="#2__13" rel="nofollow">2 程序设计</a></li><li><a href="#3_MATLAB__208" rel="nofollow">3 MATLAB 中的调用</a></li><li><a href="#4_Python__229" rel="nofollow">4 Python 中的调用</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h3><a id="1__7"></a>1 算法流程</h3> 
<p>通过阅读机器学习的书籍首先了解决策树算法的基本思想：通过递归的方式构建一棵树，子树是通过选取某一属性，按照其属性值进行划分产生的。其算法伪代码如下：</p> 
<p><img src="https://images2.imgbox.com/42/f5/DfCW7bK8_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="2__13"></a>2 程序设计</h3> 
<p>程序设计必须对算法的每个细节都要搞清楚，有时可能要实现一个健全完善的算法很困难，我们可以对算法进行简化，忽略复杂的情况，比如，在上面的构建决策树算法的步骤中，子树的划分可能有多个输出，连续属性和无序离散属性的划分的方法也有所不同，如果都要将这些考虑进去程序的设计难度会很大。作为初学者，可以对问题进行简化：</p> 
<ul><li>假设无序离散属性都只是二元属性，属性值用0或1表示</li><li>类别只有两类，用0或1表示</li><li>每个节点只有两个输出</li></ul> 
<p>在明确了细节之后，还需考虑另外一个问题：数据结构。在程序中用什么数据结构来描述所构建的“树”？这一步很关键，因为在对训练集之外的记录进行测试的时候要用到该数据结构。</p> 
<p>由于自己实现决策树算法的目的只是加深对算法的理解，并不是实际开发，因此，只是将“树”的结构和参数打印出来。</p> 
<pre><code class="prism language-matlab">function build_tree(x, y, L, level, parent_y, sig, p_value)
% 自编的用于构建决策树的简单程序，适用于属性为二元属性，二分类情况。（也可对程序进行修改以适用连续属性）。
% 输入：
% x：数值矩阵，样本属性记录（每一行为一个样本）
% y：数值向量，样本对应的labels
% 其它参数调用时可以忽略，在递归时起作用。
% 输出：打印决策树。
    if nargin == 2
       level = 0; 
       parent_y = -1;
       L = 1:size(x, 2);
       sig = -1;
       p_value = [];
%        bin_f = zeros(size(x, 2), 1);
%        for k=1:size(x, 2)
%            if length(unique(x(:,k))) == 2
%               bin_f(k) = 1; 
%            end
%        end
    end
    class = [0, 1];
    [r, label] = is_leaf(x, y, parent_y); % 判断是否是叶子节点
    if r   
        if sig ==-1
            disp([repmat('     ', 1, level), 'leaf (', num2str(label), ')']);
        elseif sig ==0
            disp([repmat('     ', 1, level), '&lt;', num2str(p_value),' leaf (', num2str(label), ')']);
        else
            disp([repmat('     ', 1, level), '&gt;', num2str(p_value),' leaf (', num2str(label), ')']);
        end
    else
        [ind, value, i_] = find_best_test(x, y, L); % 找出最佳的测试值
%         
%         if ind ==1
%            keyboard; 
%         end
        
        [x1, y1, x2, y2] = split_(x, y, i_, value); % 实施划分
        if sig ==-1
            disp([repmat('     ', 1, level), 'node (', num2str(ind), ', ', num2str(value), ')']);
        elseif sig ==0
            disp([repmat('     ', 1, level), '&lt;', num2str(p_value),' node (', num2str(ind), ', ', num2str(value), ')']);
        else
            disp([repmat('     ', 1, level), '&gt;', num2str(p_value),' node (', num2str(ind), ', ', num2str(value), ')']);
        end
%         if bin_f(i_) == 1
            x1(:,i_) = []; 
            x2(:,i_) = [];
            L(:,i_) = [];
%             bin_f(i_) = [];
%         end
        build_tree(x1, y1, L, level+1, y, 0, value); % 地柜调用
        build_tree(x2, y2, L, level+1, y, 1, value);
    end

    function [ind, value, i_] = find_best_test(xx, yy, LL) % 子函数：找出最佳测试值（可以对连续属性适用）
        imp_min = inf;
        i_ = 1;
        ind = LL(i_);
        for i=1:size(xx,2);
            if length(unique(xx(:,i))) ==1
                continue;
            end
%            [xx_sorted, ii] = sortrows(xx, i); 
%            yy_sorted = yy(ii, :);
           vv = unique(xx(:,i));
           imp_min_i = inf;
           best_point = mean([vv(1), vv(2)]);
           value = best_point;
           for j = 1:length(vv)-1
               point = mean([vv(j), vv(j+1)]);               
               [xx1, yy1, xx2, yy2] = split_(xx, yy, i, point);
               imp = calc_imp(yy1, yy2);
               if imp&lt;imp_min_i
                   best_point = point;
                   imp_min_i = imp;
               end
           end
           if imp_min_i &lt; imp_min
              value = best_point;
              imp_min = imp_min_i;
              i_ = i;
              ind = LL(i_);
           end
        end
    end
    
    function imp = calc_imp(y1, y2) % 子函数：计算熵
        p11 = sum(y1==class(1))/length(y1);
        p12 = sum(y1==class(2))/length(y1);
        p21 = sum(y2==class(1))/length(y2);
        p22 = sum(y2==class(2))/length(y2);
        if p11==0
            t11 = 0;
        else
           t11 = p11*log2(p11); 
        end
        if p12==0
            t12 = 0;
        else
           t12 = p12*log2(p12); 
        end
        if p21==0
            t21 = 0;
        else
           t21 = p21*log2(p21); 
        end
        if p22==0
            t22 = 0;
        else
           t22 = p22*log2(p22); 
        end
        
        imp = -t11-t12-t21-t22;
    end

    function [x1, y1, x2, y2] = split_(x, y, i, point) % 子函数：实施划分
       index = (x(:,i)&lt;point);
       x1 = x(index,:);
       y1 = y(index,:);
       x2 = x(~index,:);
       y2 = y(~index,:);
    end
    
    function [r, label] = is_leaf(xx, yy, parent_yy) % 子函数：判断是否是叶子节点
        if isempty(xx)
            r = true;
            label = mode(parent_yy);
        elseif length(unique(yy)) == 1
            r = true;
            label = unique(yy);
        else
            t = xx - repmat(xx(1,:),size(xx, 1), 1);
            if all(all(t ==0))
                r = true;
                label = mode(yy);
            else
                r = false;
                label = [];
            end
        end
    end
end
</code></pre> 
<p>利用MATLAB提供的数据集进行测试，并与 MATLAB 自身提供的决策树分类的函数进行对比。</p> 
<pre><code class="prism language-matlab">clc
clear all
load ionosphere % contains X and Y variables
x = X(:,1:3);
ind = x(:,3)&gt;0;
x(ind,3) = 1;
x(~ind,3) = 0;

y = zeros(size(Y));
y(ismember(Y, 'b')) = 1;

ctree = fitctree(x, y);
view(ctree,'mode','graph') % graphic description
% [label, score] = predict(ctree, X(5,:))

build_tree(x, y);
</code></pre> 
<p>自编程序运行结果</p> 
<p>含义说明：</p> 
<p>node(属性序号， 划分点)</p> 
<p>leaf(类别)</p> 
<p><img src="https://images2.imgbox.com/f2/d7/QdPkexn5_o.png" alt="在这里插入图片描述"></p> 
<p>MATLAB提供的函数的运行结果</p> 
<p><img src="https://images2.imgbox.com/06/44/o0e8vFMi_o.png" alt="在这里插入图片描述"></p> 
<p>结果与MATLAB中自己实现的函数运行结果相同。</p> 
<h3><a id="3_MATLAB__208"></a>3 MATLAB 中的调用</h3> 
<p>自己对算法的实现的目的主要还是用于加深对算法的理解，但是在实际应用时，还得借助成熟的机器学习工具包，比如MATLAB或Python提供的机器学习工具包。下面介绍一下MATLAB中决策树算法的相关函数的调用方法。</p> 
<pre><code class="prism language-matlab">tree = fitctree(x,y) 
tree = fitctree(x,y,Name,Value)
</code></pre> 
<p>根据给定的记录的属性x，对应类别y，构造决策树（二叉树）。要求x为数值矩阵，y为数值向量或cell数组。name-value pair 为可选参数，用于指定算法的参数（划分准则，叶子节点最少记录值等）。x, y 每一行为一个样本。</p> 
<p>返回tree为决策树的数据结构。</p> 
<p>利用tree进行分类：</p> 
<pre><code class="prism language-matlab">label = predict(tree, x)
</code></pre> 
<h3><a id="4_Python__229"></a>4 Python 中的调用</h3> 
<p>scikit-learn 库提供了<a href="http://scikit-learn.org/stable/modules/tree.html#classification" rel="nofollow">决策树分类和回归的方法</a>.</p> 
<p>训练</p> 
<pre><code class="prism language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf <span class="token operator">=</span> tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf <span class="token operator">=</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
</code></pre> 
<p>分类</p> 
<pre><code class="prism language-python"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>DecisionTreeClassifier能够进行二元分类(标签为[- 1,1])和多类分类(标签为[0，…，K-1])。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/acbdc6053c10d5b95f7c9bc751156e0c/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Android中startActivity中的permission检测与UID机制</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/467b252d5287d0b0b79c9f59cd7b9c94/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">使用beyond compare4作为Git的比较工具</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>