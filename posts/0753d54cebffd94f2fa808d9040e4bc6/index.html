<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>黑苹果检测_苹果技术进行情绪检测 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="黑苹果检测_苹果技术进行情绪检测" />
<meta property="og:description" content="黑苹果检测
介绍 (Introduction) Before we get our hands dirty, let’s prepare ourselves for what’s coming next.
在弄脏手之前，让我们为接下来发生的事情做好准备。 第一件事 (First things first) Artificial Intelligence can be defined as an area of computer science that has an emphasis on the creation of intelligent machines that can work and react like humans.
人工智能可以定义为计算机科学领域，其重点是创建可以像人类一样工作和做出React的智能机器 。 Machine Learning can be defined as a subset of AI, in which machines can learn on their own without being explicitly programmed: they can think and perform actions based on their past experiences." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/0753d54cebffd94f2fa808d9040e4bc6/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-09-19T22:20:51+08:00" />
<meta property="article:modified_time" content="2020-09-19T22:20:51+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">黑苹果检测_苹果技术进行情绪检测</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <article style="font-size: 16px;"> 
 <p>黑苹果检测</p> 
 <div> 
  <section> 
   <div> 
    <div> 
     <h2> 介绍 <span style="font-weight: bold;">(</span>Introduction<span style="font-weight: bold;">)</span></h2> 
     <p>Before we get our hands dirty, let’s prepare ourselves for what’s coming next.</p> 
     <p> 在弄脏手之前，让我们为接下来发生的事情做好准备。 </p> 
     <h3> 第一件事 <span style="font-weight: bold;">(</span>First things first<span style="font-weight: bold;">)</span></h3> 
     <p>Artificial Intelligence can be defined as an area of computer science that has an emphasis on the creation of <strong>intelligent machines</strong> that can work and react like humans.</p> 
     <p> 人工智能可以定义为计算机科学领域，其重点是创建可以像人类一样工作和做出React的<strong>智能机器</strong> 。 </p> 
     <p>Machine Learning can be defined as a <strong>subset</strong> of AI, in which machines can <strong>learn on their own</strong> without being explicitly programmed: they can think and perform actions based on their past experiences.In this way, they can <strong>change their algorithm</strong> based on the data sets on which they are operating.</p> 
     <p> 机器学习可以定义为AI的一个<strong>子集</strong> ，其中机器可以<strong>在</strong>不经过明确编程<strong>的</strong>情况下<strong>自行学习</strong> ：他们可以根据过去的经验来思考和执行动作，从而可以根据数据集<strong>更改算法</strong>他们在其上运行。 </p> 
     <p>Machine Learning’s popularity is growing day after day and so are the possible use cases, also thanks to the huge amount of data produced by applications.</p> 
     <p> 机器学习的受欢迎程度每天都在增长，可能的用例也在不断增长，这也要归功于应用程序产生的大量数据。 </p> 
     <p>Machine Learning is used anywhere, from automating daily tasks to offering intelligent insights for basically every industry.</p> 
     <p> 机器学习无处不在，从自动化日常任务到为几乎每个行业提供智能见解。 </p> 
     <p>ML is used for prediction, image recognition, or speech recognition. It is trained to <strong>recognize</strong> cancerous tissues, frauds, or to <strong>optimize</strong> businesses.</p> 
     <p> ML用于预测，图像识别或语音识别。 经过培训可以<strong>识别</strong>癌组织，欺诈或<strong>优化</strong>业务。 </p> 
     <p>Machine learning can be classified into <strong>3 types</strong> of algorithms.</p> 
     <p> 机器学习可分为<strong>3种</strong>算法。 </p> 
     <ul><li><p><strong>Supervised Learning</strong>: we give <strong>labeled</strong> data to the AI system. This means that each data is tagged with the correct label.</p><p> <strong>监督学习</strong> ：我们将<strong>标记的</strong>数据提供给AI系统。 这意味着每个数据都使用正确的标签进行了标记。 </p></li><li><p><strong>Unsupervised Learning</strong>: we give <strong>unlabeled</strong>, uncategorized data to the AI system and it acts on the data without any prior training, so the output is dependent upon the coded algorithms.</p><p> <strong>无监督学习</strong> ：我们将未经<strong>标记</strong> ，未经分类的数据提供给AI系统，并且无需事先培训即可对数据进行操作，因此输出取决于编码算法。 </p></li><li><p><strong>Reinforcement Learning</strong>: the system learns with no human intervention: given an environment, it will receive rewards for performing correct actions and penalties for the incorrect ones.</p><p> <strong>强化学习</strong> ：系统无需人工干预即可<strong>学习</strong> ：在特定环境下，执行正确的动作将获得奖励，对不正确的行为将受到惩罚。 </p></li></ul> 
    </div> 
   </div> 
  </section> 
  <section> 
   <div> 
    <div> 
     <blockquote> 
      <p>A machine learning model can be a mathematical representation of a real-world process.</p> 
      <p> 机器学习模型可以是现实过程的数学表示。 </p> 
     </blockquote> 
     <p>To understand this, we must first know how we come to this point, for the scope of this article, we will talk more specifically about training a classification model.</p> 
     <p> 要理解这一点，我们首先必须知道如何达到这一点，在本文的范围内，我们将更具体地讨论训练分类模型。 </p> 
     <h3> 训练 <span style="font-weight: bold;">(</span>Training<span style="font-weight: bold;">)</span></h3> 
     <blockquote> 
      <p>Training a model simply means learning good values</p> 
      <p> 训练模型仅意味着学习良好的价值观 </p> 
     </blockquote> 
     <p>A neural network, at first, will try to <strong>guess </strong>the output value <strong>randomly</strong>, then, it will gradually learn from its errors and adjust its <strong>values </strong>(weights)<strong> </strong>based on these.</p> 
     <p> 首先，神经网络将尝试<strong>随机</strong> <strong>猜测</strong>输出值，然后逐渐从错误中学习并调整其<strong>值</strong> (权重) <strong> </strong> 基于这些。 </p> 
     <p>There are many types of classification problems:</p> 
     <p> 分类问题有很多类型： </p> 
     <ul><li><p><strong>Binary Classification</strong>: predict a binary possibility (one of two possible classes).</p><p> <strong>二进制分类</strong> ：预测二进制可能性(两个可能的类别之一)。 </p></li><li><p><strong>Multiclass Classification: </strong>allow you to generate predictions for multiple classes (predict one of more than two outcomes).</p><p> <strong>多</strong>类别<strong>分类：</strong>允许您生成多个类别的预测(预测两个以上结果之一)。 </p></li></ul> 
     <p>For iOS developers, Apple provides machine learning tools like Core ML, Vision, and NLP. iOS developers have different choices for accessing trained models to <strong>provide inference</strong>:</p> 
     <p> Apple为iOS开发人员提供了机器学习工具，例如Core ML，Vision和NLP。 iOS开发人员在访问经过训练的模型以<strong>提供推论时</strong>有不同的选择： </p> 
     <ul><li>Use Core ML to access a local on-device pre-trained model.<p class="nodelete"></p> 使用Core ML访问本地的设备上预先训练的模型。 </li><li>Host a Machine Learning Model in the cloud and send data from the device to the hosted endpoint to provide predictions.<p class="nodelete"></p> 在云中托管机器学习模型，并将数据从设备发送到托管端点以提供预测。 </li><li>Call third-party API-Driven Machine Learning cloud managed services where the service hosts and manages a pre-defined trained model. User data is passed through an API call from the device and the service returns the predicted values.<p class="nodelete"></p> 调用第三方API驱动的机器学习云托管服务，其中该服务托管和管理预定义的经过训练的模型。 用户数据通过设备的API调用传递，服务返回预测值。 </li></ul> 
     <figure style="display:block;text-align:center;"> 
      <div> 
       <div> 
        <div> 
         <div> 
          <div style="text-align: center;"> 
           <img alt="Image for post" src="https://images2.imgbox.com/ff/f6/l6Cml98O_o.png" width="3000" height="2000" style="outline: none;"> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
      <figcaption> 
       <a href="https://unsplash.com/@heyerlein?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">h heyerlein</a> on 
       <a href="https://unsplash.com/@heyerlein?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">h heyerlein摄</a>于 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a> 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a> 
      </figcaption> 
     </figure> 
     <h3> 什么是创建ML？ <span style="font-weight: bold;">(</span>What is Create ML?<span style="font-weight: bold;">)</span></h3> 
     <p>Focused at present on vision and natural language data, developers can use Create ML with Swift to create machine learning models, models which are then trained to handle tasks such as understanding text, recognizing photos, or finding relationships between numbers.</p> 
     <p> 目前，开发人员可以专注于视觉和自然语言数据，可以使用带有Swift的Create ML创建机器学习模型，然后对模型进行训练以处理诸如理解文本，识别照片或查找数字之间的关系等任务。 </p> 
     <p>It lets developers build machine learning models on their Macs that they can then deploy across Apple’s platforms using <strong>Swift</strong>.</p> 
     <p> 它使开发人员可以在Mac上构建机器学习模型，然后可以使用<strong>Swift</strong>在苹果的平台上进行部署。 </p> 
     <p>Apple’s decision to commoditize its machine learning tech means developers can build natural language and image classification models much <strong>faster</strong> than the task takes if built from scratch.</p> 
     <p> 苹果公司决定将其机器学习技术商品化，这意味着开发人员可以以比从头开始构建任务<strong>快得多的速度</strong>构建自然语言和图像分类模型。 </p> 
     <p>It also makes it possible to create these models without the use of third-party AI training systems, such as IBM Watson or TensorFlow (though Create ML supports only very specific models).</p> 
     <p> 这也使创建这些模型成为可能，而无需使用第三方AI培训系统，例如IBM Watson或TensorFlow(尽管Create ML仅支持非常特定的模型)。 </p> 
     <h3> 什么是核心ML？ <span style="font-weight: bold;">(</span>What is Core ML?<span style="font-weight: bold;">)</span></h3> 
     <p>Core ML is the machine learning framework used across Apple products (macOS, iOS, watchOS, and tvOS) for performing<strong> fast prediction</strong> or <strong>inference</strong> with easy integration of pre-trained machine learning models on the edge, which allows you to perform <strong>real-time predictions</strong> of live images or video on the device.</p> 
     <p> Core ML是跨Apple产品(macOS，iOS，watchOS和tvOS)使用的机器学习框架，用于通过边缘上预先训练好的机器学习模型的轻松集成来执行<strong>快速预测</strong>或<strong>推断</strong> ，从而使您可以执行<strong>实时预测</strong>设备上的实时图像或视频。 </p> 
     <h3> 机器学习的优势 <span style="font-weight: bold;">(</span>Advantages of ML on the edge<span style="font-weight: bold;">)</span></h3> 
     <p><strong>Low Latency</strong> and Near Real-Time Results: You don’t need to make a network API call by sending the data and then waiting for a response. This can be critical for applications such as video processing of successive frames from the on-device camera.</p> 
     <p> <strong>低延迟</strong>和近乎实时的结果：您不需要通过发送数据然后等待响应来进行网络API调用。 这对于应用程序(例如来自设备上摄像头的连续帧的视频处理)至关重要。 </p> 
     <p>Availability (Offline), <strong>Privacy</strong>, and Compelling Cost as the application runs without network connection, <strong>no API calls</strong>, and the data<strong> never</strong> leaves the device. Imagine using your mobile device to identify historic tiles while in the subway, catalog private vacation photos while in airplane mode, or detect poisonous plants while in the wilderness.</p> 
     <p> 应用程序在没有网络连接的情况下运行， <strong>没有API调用</strong>且数据<strong>永远不会</strong>离开设备，因此可用性(脱机)， <strong>隐私</strong>和诱人的成本。 想象一下，使用移动设备在地铁中识别历史瓷砖，在飞机模式中分类私人度假照片或在旷野中检测有毒植物。 </p> 
     <h3> ML的缺点 <span style="font-weight: bold;">(</span>Disadvantages of ML on the edge<span style="font-weight: bold;">)</span></h3> 
     <ul><li><p><strong>Application Size</strong>: By adding the model to the device, you’re increasing the size of the app and some accurate models can be quite large.</p><p> <strong>应用程序大小</strong> ：通过将模型添加到设备中，您正在增加应用程序的大小，某些准确的模型可能会很大。 </p></li><li><p><strong>System Utilization</strong>: Prediction and inference on the mobile device involves lots of computation, which increases battery drain. Older devices may struggle to provide real-time predictions.</p><p> <strong>系统利用率</strong> ：对移动设备的预测和推断涉及大量计算，这会增加电池消耗。 较旧的设备可能难以提供实时预测。 </p></li><li><p><strong>Model Training</strong>: In most cases, the model on the device must be continually trained outside of the device with new user data. Once the model is retrained, the app will need to be updated with the new model, and depending on the size of the model, this could strain network transfer for the user. Refer back to the application size challenge listed above, and now we have a <strong>potential user experience problem</strong>.</p><p> <strong>模型训练</strong> ：在大多数情况下，必须使用新的用户数据在设备外部持续训练设备上的模型。 重新训练模型后，将需要使用新模型更新应用程序，并且根据模型的大小，这可能会给用户带来网络传输压力。 返回上面列出的应用程序大小挑战，现在我们有一个<strong>潜在的用户体验问题</strong> 。 </p></li></ul> 
     <figure style="display:block;text-align:center;"> 
      <div> 
       <div> 
        <div> 
         <div> 
          <div style="text-align: center;"> 
           <img alt="Image for post" src="https://images2.imgbox.com/73/fe/YlCdgN4R_o.png" width="3882" height="2584" style="outline: none;"> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
      <figcaption>
        Photo by 
       <a href="https://unsplash.com/@cgower?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Christopher Gower</a> on 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a> 
      </figcaption> 
      <figcaption> 
       <a href="https://unsplash.com/@cgower?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Christopher Gower</a>在 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a>上的 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">照片</a> 
      </figcaption> 
     </figure> 
     <h2> 弄脏你的手 <span style="font-weight: bold;">(</span>Getting your hands dirty<span style="font-weight: bold;">)</span></h2> 
     <p>As we dive deeper into the core of this article, we are assuming that you are quite familiar with an iOS Development environment and you have some basic knowledge about python.</p> 
     <p> 当我们深入研究本文的核心时，我们假设您对iOS开发环境非常熟悉，并且您具有有关python的一些基本知识。 </p> 
     <h3> 用python转换模型 <span style="font-weight: bold;">(</span>Converting a model with python<span style="font-weight: bold;">)</span></h3> 
     <p>Now let’s say that we found an interesting model on the web, unfortunately, we notice it’s <strong>not in CoreML format</strong>, but we absolutely want to use it in our iOS app and there’s no other way to obtain it, we can just try to convert it.</p> 
     <p> 现在，我们说我们在网络上找到了一个有趣的模型，不幸的是，我们注意到它<strong>不是CoreML格式的</strong> ，但是我们绝对希望在我们的iOS应用中使用它，并且没有其他方法可以获取它，我们可以尝试将其转换。 </p> 
     <p>Apple has a specific tool to accomplish this task, a python module called <em>coremltools</em> that can be found at <a href="https://github.com/apple/coremltools" target="_blank" rel="noopener nofollow noopener noreferrer">this link</a>.</p> 
     <p> Apple有一个完成此任务的特定工具，一个名为<em>coremltools</em>的python模块，可以在<a href="https://github.com/apple/coremltools" target="_blank" rel="noopener nofollow noopener noreferrer">此链接中</a>找到。 </p> 
     <p>The <a href="https://github.com/priya-dwivedi/face_and_emotion_detection" target="_blank" rel="noopener nofollow noopener noreferrer"><strong>interesting model</strong></a> is built with keras (tensorflow as backend) and it’s about emotion detection, you can download it from <a href="https://github.com/priya-dwivedi/face_and_emotion_detection/blob/master/emotion_detector_models/model_v6_23.hdf5" target="_blank" rel="noopener nofollow noopener noreferrer">here</a>. Let’s now convert it, first of all we’ll install the required packages. For <strong>compatibility reasons</strong>, please use <em>python 2.7 </em>and packages’ specified versions, as <em>coremltools</em> relies on these.</p> 
     <p> 这个<a href="https://github.com/priya-dwivedi/face_and_emotion_detection" target="_blank" rel="noopener nofollow noopener noreferrer"><strong>有趣的模型</strong></a>是使用keras(tensorflow作为后端)构建的，它与情感检测有关，您可以从<a href="https://github.com/priya-dwivedi/face_and_emotion_detection/blob/master/emotion_detector_models/model_v6_23.hdf5" target="_blank" rel="noopener nofollow noopener noreferrer">此处</a>下载。 现在让我们对其进行转换，首先我们将安装所需的软件包。 出于<strong>兼容性原因</strong> ，请使用<em>python 2.7</em>和软件包的指定版本，因为<em>coremltools</em>依赖于这些版本。 </p> 
     <p>One final note, since we are using a deprecated version of python, we create a virtual environment to run our code.</p> 
     <p> 最后一点，由于我们使用的Python版本已弃用，因此我们创建了一个虚拟环境来运行我们的代码。 </p> 
     <p>Final final note, <strong>your path</strong> to Python 2.7 <strong>might be different</strong>, if you’re using Mac OS or Linux, check your /usr/bin/ directory. If you’re using Windows, check the path in which you decided to install python.</p> 
     <p> 最后的最后一点， <strong>您</strong>使用Python 2.7 <strong>的路径</strong> <strong>可能有所不同</strong> ，如果您使用的是Mac OS或Linux，请检查/ usr / bin /目录。 如果您使用Windows，请检查决定安装python的路径。 </p> 
     <pre><code class="has">pip3 install virtualenvvirtualenv -p /usr/bin/python2.7 venv</code></pre> 
     <p>Now we activate the virtual environment we just created.</p> 
     <p> 现在，我们激活刚刚创建的虚拟环境。 </p> 
     <pre><code class="has">source venv/bin/activate</code></pre> 
     <p>And finally, we install our dependencies.</p> 
     <p> 最后，我们安装依赖项。 </p> 
     <pre><code class="has">pip install coremltools keras==2.2.4 tensorflow==1.14.0</code></pre> 
     <p>After this, we can start writing our script. 🚀</p> 
     <p> 之后，我们可以开始编写脚本了。 🚀 </p> 
     <p>Create a file named <strong>converter.py,</strong> the first step will be to import coremltools.</p> 
     <p> 创建一个名为<strong>converter.py</strong>的文件<strong>，</strong>第一步将是导入coremltools。 </p> 
     <pre><code class="has">import coremltools</code></pre> 
     <p>Last but not least, we convert our model into a <strong>.mlmodel</strong> one.</p> 
     <p> 最后但并非最不重要的一点是，我们将模型转换为<strong>.mlmodel</strong> 。 </p> 
     <pre><code class="has">output_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']ml_model = coremltools.converters.keras.convert(<br>    './model_v6.h5', <br>    input_names=['image'], <br>    output_names=['output'], <br>    class_labels=output_labels, <br>    image_input_names='image'<br>)ml_model.save('./model_v6.mlmodel')</code></pre> 
     <p>As you can see, the first line is about <strong>output labels</strong>, this is the most important thing we need to know before converting a model, otherwise, the results will be useless for us since we will not be able to know what the output is about.</p> 
     <p> 如您所见，第一行是关于<strong>输出标签的</strong> ，这是我们在转换模型之前需要了解的最重要的事情，否则，结果对于我们来说将是无用的，因为我们将无法知道输出是关于什么的。 </p> 
     <p>The second line is the main instruction of the script, it calls the Keras<strong> converter</strong> from the coremltools converters and converts our model based on our specifications about input and output (in this case we are specifying that we need an image as input and <strong>output_labels</strong> as output).</p> 
     <p> 第二行是脚本的主要指令，它从coremltools转换器调用Keras <strong>转换器</strong>和我们的模型基于我们对输入和输出规格转换(在这种情况下，我们指定，我们需要一个图像作为输入和<strong>output_labels</strong>作为输出)。 </p> 
     <p>Finally, we <strong>save</strong> the converted model that is ready to use in our app.</p> 
     <p> 最后，我们<strong>保存</strong>已转换的模型，准备在我们的应用程序中使用。 </p> 
     <figure style="display:block;text-align:center;"> 
      <div> 
       <div> 
        <div> 
         <div> 
          <div style="text-align: center;"> 
           <img alt="Image for post" src="https://images2.imgbox.com/f2/b4/pr30UHl3_o.png" width="3648" height="2048" style="outline: none;"> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
      <figcaption>
        Photo by 
       <a href="https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Hitesh Choudhary</a> on 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a> 
      </figcaption> 
      <figcaption> 
       <a href="https://unsplash.com/@hiteshchoudhary?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Hitesh Choudhary</a> 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">摄</a>于 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a> 
      </figcaption> 
     </figure> 
     <h2> 使用Apple技术进行机器学习 <span style="font-weight: bold;">(</span>Machine Learning with Apple technologies<span style="font-weight: bold;">)</span></h2> 
     <p>This is what we expect our final result to be.</p> 
     <p> 这就是我们期望的最终结果。 </p> 
     <figure style="display:block;text-align:center;"> 
      <div> 
       <div> 
        <div> 
         <div style="text-align: center;"> 
          <img alt="A quick tour of the application" src="https://images2.imgbox.com/c4/69/gv3w9AeU_o.gif" width="384" height="848" style="outline: none;"> 
         </div> 
        </div> 
       </div> 
      </div> 
      <figcaption>
        A quick tour of the finished app 
      </figcaption> 
      <figcaption>
        快速浏览完成的应用程序 
      </figcaption> 
     </figure> 
     <p>The first thing to do is to get a good model for our scope.</p> 
     <p> 首先要做的是为我们的范围建立一个良好的模型。 </p> 
     <h3> 通过CreateML应用程序创建模型 <span style="font-weight: bold;">(</span>Creation of a Model via CreateML app<span style="font-weight: bold;">)</span></h3> 
     <p>CreateML app is an application presented in the WWDC 2019 for Xcode 11.0 and Swift 5. This application allows everyone to create an ML Model without having a very big knowledge about training an ML model. It’s only necessary to find the information we want to use to train the model, label them (because the base of CreateML is the <strong>Supervised Training</strong>) and import everything in the application.</p> 
     <p> CreateML应用程序是WWDC 2019中针对Xcode 11.0和Swift 5推出的应用程序。此应用程序使每个人都可以创建ML模型，而无需掌握有关训练ML模型的大量知识。 只需找到我们想要用来训练模型的信息，对其进行标记(因为CreateML的基础是<strong>Supervised Training</strong> )，然后将所有内容导入应用程序。 </p> 
     <p>Now we will use the CreateML app to train our model which will <strong>recognize</strong> our emotions.</p> 
     <p> 现在，我们将使用CreateML应用程序来训练将<strong>识别</strong>我们情绪的模型。 </p> 
     <p>First of all, you have to find the images. I suggest to find a very rich dataset of images because the precision is very important, but the images mustn’t have a very high resolution. After that, you have to <strong>divide your images</strong> into several categories you decide, in the base of emotions you want to recognize and create a folder for each emotion. Then you have to create two super folders: train and test. The first folder is richer of images and it’s the folder where you put the images for training the model, the second folder is used to test the model just trained.</p> 
     <p> 首先，您必须找到图像。 我建议找到一个非常丰富的图像数据集，因为精度非常重要，但是图像不能具有很高的分辨率。 之后，您必须根据要识别的情绪<strong>将图像划分</strong>为几个类别，并为每种情绪创建一个文件夹。 然后，您必须创建两个超级文件夹：训练和测试。 第一个文件夹包含丰富的图像，这是放置图像以训练模型的文件夹，第二个文件夹用于测试刚刚训练的模型。 </p> 
     <p>If this operation could be annoying, don’t worry: lots of datasets have a .csv file where there are the <strong>classification already done</strong>! You have only to write a simple script and solve the problem! Here is an example in Python 3.8:</p> 
     <p> 如果此操作可能很烦人，请不要担心：许多数据集都有一个.csv文件，其中<strong>已经完成</strong>了<strong>分类</strong> ！ 您只需要编写一个简单的脚本即可解决问题！ 这是Python 3.8中的示例： </p> 
     <pre><code class="has">import csv<br>import os<br>import sysdef main():<br>    input_path = “PATH_OF_YOUR_FOLDER”<br>    file_name = “FILE_NAME.csv”<br>    file = open(file_name,”r”)<br>    data = csv.reader(file)<br>    next(data) #this is used to avoid the first line<br>    for info in data:<br>        label_path = os.path.join(input_path, info[-1])<br>        #here you have to consider the structure of .csv filedestination_path = “mv “ + info[1] + “ “ + label_path<br>        os.system(destination_path)<br>        print(“images moved”)<br>    file.close()if <strong>name</strong> == ‘<strong>main</strong>’ : main()</code></pre> 
     <p>After that, press and hold “control” button on the keyboard (if you are using macOS Catalina and Xcode 11) and click on the dock icon of Xcode. You should see a menu called “<strong>Open Developer Tool</strong>” and after, <strong>CreateML</strong>; then you click on “New Document”. You should see an interface where you can choose the right template of our MLModel: we will <strong>classify</strong> images, so we choose “<strong>Image Classifier</strong>”, that is the first template. Next, we will give the name of your project, the name of License, a short description, and where to save the project file.</p> 
     <p> 之后，按住键盘上的“控制”按钮(如果您使用的是macOS Catalina和Xcode 11)，然后单击Xco​​de的停靠图标。 您应该看到一个名为“ <strong>Open Developer Tool</strong> ”的菜单， <strong>其后是CreateML</strong> ； 然后单击“新建文档”。 您应该看到一个界面，您可以在其中选择MLModel的正确模板：我们将对图像<strong>进行分类</strong> ，因此我们选择“ <strong>Image Classifier</strong> ”，这是第一个模板。 接下来，我们将提供您的项目名称，许可证名称，简短说明以及项目文件的保存位置。 </p> 
     <p>Now we have to select the images for training and testing, and the only thing to do is to<strong> drag</strong> the “train” folder in the “Train” section and “test” folder in the “Test” section. Validation must be set in “Auto”. Then we have to choose a maximum of <strong>iterations</strong> (600 should be good) and then press “Start” at the top of the interface. The other commands in the bottom part are only to edit images for being more useful in the training process, but in this situation, we haven’t needed it.</p> 
     <p> 现在，我们必须选择要进行训练和测试的图像，唯一要做的就是<strong>拖动</strong> “训练”部分中的“训练”文件夹和“测试”部分中的“测试”文件夹。 验证必须在“自动”中设置。 然后，我们必须选择最大<strong>迭代次数</strong> (600个应该是好的)，然后在界面顶部按“开始”。 底部的其他命令仅用于编辑图像，以便在训练过程中更有用，但是在这种情况下，我们不需要它。 </p> 
     <p>After a long time, we have our characteristics about our model and, in the top right, <strong>our model</strong>. You have only to drag this model out of CreateML windows and drop it in an external folder or Desktop.</p> 
     <p> 经过很长一段时间，我们对模型有了自己的特征，在右上角， <strong>我们的模型</strong>也有了。 您只需将此模型拖出CreateML窗口，然后将其放在外部文件夹或桌面中即可。 </p> 
     <figure style="display:block;text-align:center;"> 
      <div> 
       <div> 
        <div> 
         <div> 
          <div style="text-align: center;"> 
           <img alt="Image for post" src="https://images2.imgbox.com/de/93/qe9Uws3W_o.png" width="5000" height="3313" style="outline: none;"> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
      <figcaption>
        Photo by 
       <a href="https://unsplash.com/@yancymin?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Yancy Min</a> on 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a> 
      </figcaption> 
      <figcaption> 
       <a href="https://unsplash.com/@yancymin?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Yancy Min</a>在 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">Unsplash</a>上 
       <a href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener nofollow noopener noreferrer" target="_blank">拍摄的</a>照片 
      </figcaption> 
     </figure> 
     <h3> 结合使用CoreML和Vision <span style="font-weight: bold;">(</span>Using CoreML with Vision<span style="font-weight: bold;">)</span></h3> 
     <p>For creating our software we need two frameworks and an MLModel based on image classification (created before or converted from other models): these frameworks are <strong>Vision</strong> and <strong>CoreML</strong>.</p> 
     <p> 为了创建我们的软件，我们需要两个框架和一个基于图像分类的MLModel(在其他模型之前创建或从其他模型转换而来)：这些框架是<strong>Vision</strong>和<strong>CoreML</strong> 。 </p> 
     <p>We already talked about CoreML, but <strong>what’s Vision about</strong>?</p> 
     <p> 我们已经讨论过CoreML，但<strong>愿景是</strong>什么？ </p> 
     <p>Vision permits us to <strong>manipulate</strong> images and videos using <strong>Computer Vision Algorithms</strong> for lots of operations like face and face landmark detection, text detection, barcode recognition, image registration, and general feature tracking. We will use the CoreML interfacing for classifying images.</p> 
     <p> Vision允许我们使用<strong>计算机视觉算法</strong>来<strong>处理</strong>图像和视频，以进行许多操作，例如面部和面部界标检测，文本检测，条形码识别，图像配准以及一般特征跟踪。 我们将使用CoreML接口对图像进行分类。 </p> 
     <p>To start with this tutorial, first of all, clone <a href="https://gitlab.com/Giovygio97/workshop-start.git" rel="noopener nofollow noopener noreferrer" target="_blank">this repository</a>: in it, there is a simple application (written in Swift 5.2 and compatible for iOS 13.2) with a simple ViewController where there is an UIImageView and a Label. The first is used to show the images we choose to verify emotions, the second is used to identify the emotion and indicate the precision of our image classification.There is also a Greyscale converted because lots of datasets give us grayscale images and, for this reason, image classification is more correct.</p> 
     <p> 首先从本教程开始，克隆<a href="https://gitlab.com/Giovygio97/workshop-start.git" rel="noopener nofollow noopener noreferrer" target="_blank">该存储库</a> ：在其中，有一个简单的应用程序(用Swift 5.2编写，并且与iOS 13.2兼容)和一个简单的ViewController，其中有一个UIImageView和一个Label。 第一个用于显示我们选择用来验证情绪的图像，第二个用于识别情绪并指示我们图像分类的精度。还有一个灰度转换，因为许多数据集为我们提供了灰度图像，因此，图像分类比较正确。 </p> 
     <p>Now let’s start:</p> 
     <p> 现在开始： </p> 
     <ol><li>Create a new file called “PredictionManager.swift” where we can implement our classification function.<p class="nodelete"></p> 创建一个名为“ PredictionManager.swift”的新文件，在其中我们可以实现分类功能。 </li><li>Save it in the folder of your app.<p class="nodelete"></p> 将其保存在应用程序的文件夹中。 </li><li>Import UIKit, CoreML and Vision in your project<p class="nodelete"></p> 在您的项目中导入UIKit，CoreML和Vision </li><li>Add your model to the project. To do this just drag and drop the .mlmodel file in the project folder opened in Xcode navigator, then select “Copy as Group”.<p class="nodelete"></p> 将模型添加到项目中。 为此，只需将.mlmodel文件拖放到Xcode导航器中打开的项目文件夹中，然后选择“复制为组”。 </li></ol> 
     <p>Now let’s start to write code! 🥳</p> 
     <p> 现在让我们开始编写代码！ 🥳 </p> 
     <p>First, we create a class, called PredictionManager, with two variables:</p> 
     <p> 首先，我们创建一个名为PredictionManager的类，其中包含两个变量： </p> 
     <pre><code class="has">var emotionModel: <strong>MLModel</strong><br>var visionModel: <strong>VNCoreMLModel</strong></code></pre> 
     <p>The first variable is the MLModel we consider for our project, instead, the second variable is a Vision Container where we put our MLModel (trained for images) and make operations on it (called “VNCoreMLRequest”)</p> 
     <p> 第一个变量是我们为项目考虑的MLModel，第二个变量是Vision容器，我们在其中放置了MLModel(针对图像进行训练)并对其进行操作(称为“ VNCoreMLRequest”) </p> 
     <p>After declaration, let’s create the constructor:</p> 
     <p> 声明后，让我们创建构造函数： </p> 
     <pre><code class="has">init() {<!-- --><br>    self.emotionModel = EmotionClassificator().model<br>    do{<!-- --><br>        self.visionModel = try VNCoreMLModel(for: self.emotionModel)<br>    }catch{<!-- --><br>        fatalError(“Unable to create Vision Model…”)<br>    }<br>}</code></pre> 
     <p>Firstly we assigned to the MLModel variable our model (in this case called “<strong>EmotionClassificator</strong>”, but in general the name of this class is equal to the .mlmodel file name) because every .mlmodel file creates a class called like the model, and this class is usable for every operation with CoreML, but to access to its implementation, you have to open the .mlmodel file and click on the arrow on the right of the Model name.</p> 
     <p> 首先，我们将模型分配给MLModel变量(在本例中为“ <strong>EmotionClassificator</strong> ”，但通常此类的名称等于.mlmodel文件的名称)，因为每个.mlmodel文件都会创建一个称为模型的类，并且该类可用于CoreML的每个操作，但是要访问其实现，您必须打开.mlmodel文件，然后单击Model名称右侧的箭头。 </p> 
     <p>Then we assign to <strong>visionModel</strong> the MLModel if this model is compatible with Vision.</p> 
     <p> 然后，如果此模型与Vision兼容，则将MLModel分配给<strong>visionModel</strong> 。 </p> 
     <p>Now we can start with our function:</p> 
     <p> 现在我们可以从函数开始： </p> 
     <pre><code class="has">func classification(for image: UIImage, complete: <a href="http://twitter.com/escaping" rel="noopener nofollow noopener noreferrer" target="_blank">@escaping</a> (String) -&gt; Void)</code></pre> 
     <p>For classifying our image we have to use an image (UIImage) and we will have to output a String (here we can have a string with <a href="http://twitter.com/escaping" rel="noopener nofollow noopener noreferrer" target="_blank">@escaping</a> closure, that prevents us to delete information, here in type “String” when function variables are de-allocated).</p> 
     <p> 为了对图像进行分类，我们必须使用图像(UIImage)，并且必须输出一个String(这里我们可以使用带<a href="http://twitter.com/escaping" rel="noopener nofollow noopener noreferrer" target="_blank">@escaping</a>闭包的字符串，以防止我们删除信息，此处的函数变量是“ String”类型)。取消分配)。 </p> 
     <p>Now, the first thing we have to do is the VNCoreMLRequest, to create the request to our MLModel:</p> 
     <p> 现在，我们要做的第一件事是VNCoreMLRequest，以创建对MLModel的请求： </p> 
     <pre><code class="has"><strong>func</strong> classification(for image: UIImage, complete: <a href="http://twitter.com/escaping" rel="noopener nofollow noopener noreferrer" target="_blank">@escaping</a> (String) -&gt; Void){<!-- --><strong>let</strong> request = VNCoreMLRequest(model: self.visionModel {(request,error) in<strong>guard</strong> error == nil else {complete(“Error”); <br>        return<br>    }<strong>guard</strong> let results = request.results as [VNClassificationObservation], let firstResult = results.first<strong>else</strong> { <br>            complete(“No Results”); <br>            return<br>        }<br>        complete(String(format: “%@ %.1f%%”, firstResult.identifier, firstResult.confidence * 100)) <br>    }<br>}</code></pre> 
     <p>Our <strong>VNCoreMLRequest</strong> needs the <strong>VNCoreMLModel</strong> to operate the requests and then we consider three situations:</p> 
     <p> 我们的<strong>VNCoreMLRequest</strong>需要<strong>VNCoreMLModel</strong>来操作请求，然后我们考虑三种情况： </p> 
     <ul><li><p>the model<strong> isn’t useful</strong> for our purpose;</p><p> 该模型对我们的目的<strong>没有用</strong> ； </p></li><li><p>the entire request (where the results are represented like VNClassificationObservation) <strong>doesn’t give any result;</strong></p><p> 整个请求(结果表示为VNClassificationObservation) <strong>不给出任何结果；</strong> </p></li><li><p>choosing the first result (the most precise), we will <strong>print our information </strong>(the classification and the confidence).</p><p> 选择第一个结果(最精确的结果)，我们将<strong>打印我们的信息</strong> (分类和置信度)。 </p></li></ul> 
     <p>To have more precision, we will <strong>crop</strong> the images to the center:</p> 
     <p> 为了获得更高的精度，我们将图像<strong>裁剪</strong>到中心： </p> 
     <pre><code class="has">request.imageCropAndScaleOption = .centerCrop</code></pre> 
     <p>Now we need a <strong>handler</strong> to handle every request to the VNCoreMLModel, but first, we have to give it an image filtered and optimized for our process: for this reason, we create a CIImage (Core Image) and we will give it a prefixed orientation with <strong>CGImagePropertyOprientation</strong>:</p> 
     <p> 现在我们需要一个<strong>处理程序</strong>来处理对VNCoreMLModel的每个请求，但是首先，我们必须为它提供经过过滤和优化的图像，以便针对我们的流程进行处理：基于这个原因，我们创建一个CIImage(核心图像)，并为其指定前缀与<strong>CGImagePropertyOprientation</strong> ： </p> 
     <pre><code class="has"><strong>guard</strong> let ciImage = CIImage(image: image) <strong>else</strong> { complete(“error creating image”); return}<strong>let</strong> orientation = CGImagePropertyOrientation(rawValue: UInt32(image.imageOrientation.rawValue))</code></pre> 
     <p>And now it’s time to build the request:</p> 
     <p> 现在是时候建立请求了： </p> 
     <pre><code class="has">DispatchQueue.global(qos: .userInitiated).async {<!-- --><strong>let</strong> handler = VNImageRequestHandler(ciImage: ciImage, orientation: orientation!)<strong>do</strong> {<!-- --><br>        try handler.perform([request])<br>    } <strong>catch</strong> {<!-- --><br>        complete(“Failed to perform classification.”)<br>    }}</code></pre> 
     <p>To help our application, we will permit the handler to go in the global area and be activated <strong>only</strong> on the request of the user (when the user chooses the image). This operation will be <strong>asynchronous</strong>, so it will be executed independently from the rest of the app.</p> 
     <p> 为了帮助我们的应用程序，我们将允许处理程序进入全局区域，并且<strong>仅</strong>在用户请求时(当用户选择图像时)激活处理程序。 该操作将是<strong>异步的</strong> ，因此它将独立于应用程序的其余部分执行。 </p> 
     <p>In the end, we will build our handler (using the CIImage created before and the orientation) and try to perform requests created before.</p> 
     <p> 最后，我们将构建处理程序(使用之前创建的CIImage和方向)并尝试执行之前创建的请求。 </p> 
     <p>Now we complete our function of classification. Let’s go to call it in the <strong>ViewController</strong>.</p> 
     <p> 现在，我们完成了分类功能。 让我们在<strong>ViewController中</strong>调用它。 </p> 
     <p>In the Extension of our ViewController, after the dismiss, let’s write this:</p> 
     <p> 在我们的ViewController的扩展中，解雇之后，让我们这样写： </p> 
     <pre><code class="has">let monoImage = image.mono</code></pre> 
     <p>Here we convert our image in mono-image, after we will</p> 
     <p> 在这里，我们将图像转换为单图像后 </p> 
     <pre><code class="has">predictionManager.classification(for: monoImage) { (result) inDispatchQueue.main.async { [weak self] in<br>        self?.predictionLabel.text = result<br>    }}</code></pre> 
     <p>After the classification, the result will be processed in the main thread (DispatchQueue.main.async), and, with a <strong>weak self</strong> we will give the result of our classification.</p> 
     <p> 分类之后，结果将在主线程(DispatchQueue.main.async)中进行处理，并且使用<strong>弱自身，</strong>我们将给出分类结果。 </p> 
     <p>Now you can classify emotions! 🤩 What are you waiting for? Try in on your iPhone!</p> 
     <p> 现在您可以对情绪进行分类！ you您还在等什么？ 尝试在您的iPhone上！ </p> 
     <p>For the complete project, <strong>check out</strong> our repository:</p> 
     <p> 对于完整的项目， <strong>请查看</strong>我们的存储库： </p> 
     <div> 
      <a href="https://gitlab.com/Giovygio97/emotiondetectioncoreml.git" rel="noopener nofollow noopener noreferrer" target="_blank"></a> 
     </div> 
     <h3> 团队-NoSynapses <span style="font-weight: bold;">(</span>The team — NoSynapses<span style="font-weight: bold;">)</span></h3> 
     <p><a href="https://www.linkedin.com/in/giovanni-prisco-362335183/" rel="noopener nofollow noopener noreferrer" target="_blank">Giovanni Prisco</a></p> 
     <p> <a href="https://www.linkedin.com/in/giovanni-prisco-362335183/" rel="noopener nofollow noopener noreferrer" target="_blank">乔瓦尼·普里斯科(Giovanni Prisco)</a> </p> 
     <p><a href="http://linkedin.com/in/giovanni-di-guida-228287165" rel="noopener nofollow noopener noreferrer" target="_blank">Giovanni Di Guida</a></p> 
     <p> <a href="http://linkedin.com/in/giovanni-di-guida-228287165" rel="noopener nofollow noopener noreferrer" target="_blank">乔凡尼·迪·吉达</a> </p> 
     <p><a href="https://www.linkedin.com/in/iamantonioalfonso/" rel="noopener nofollow noopener noreferrer" target="_blank">Antonio Alfonso</a> (also on <a target="_blank" rel="nofollow noopener noreferrer" href="https://medium.com/@iamantonioalfonso">Medium</a>)</p> 
     <p> <a href="https://www.linkedin.com/in/iamantonioalfonso/" rel="noopener nofollow noopener noreferrer" target="_blank">安东尼奥·阿方索</a> (也在<a target="_blank" rel="nofollow noopener noreferrer" href="https://medium.com/@iamantonioalfonso">Medium上</a> ) </p> 
     <p><a href="https://www.linkedin.com/in/simoneserracassano/" rel="noopener nofollow noopener noreferrer" target="_blank">Simone Serra Cassano</a></p> 
     <p> <a href="https://www.linkedin.com/in/simoneserracassano/" rel="noopener nofollow noopener noreferrer" target="_blank">西蒙妮·塞拉·卡萨诺</a> </p> 
     <p><a href="https://www.linkedin.com/in/vincenzocoppola94/" rel="noopener nofollow noopener noreferrer" target="_blank">Vincenzo Coppola</a></p> 
     <p> <a href="https://www.linkedin.com/in/vincenzocoppola94/" rel="noopener nofollow noopener noreferrer" target="_blank">文森佐·科波拉</a> </p> 
     <p><a href="http://t.me/Eth3real" rel="noopener nofollow noopener noreferrer" target="_blank">Simone Formisano</a></p> 
     <p> <a href="http://t.me/Eth3real" rel="noopener nofollow noopener noreferrer" target="_blank">西蒙娜·福米萨诺</a> </p> 
    </div> 
   </div> 
  </section> 
 </div> 
 <blockquote> 
  <p>翻译自: <a href="https://medium.com/apple-developer-academy-federico-ii/emotion-detection-with-apple-technologies-b782beaa5c44" rel="nofollow">https://medium.com/apple-developer-academy-federico-ii/emotion-detection-with-apple-technologies-b782beaa5c44</a></p> 
 </blockquote> 
 <p>黑苹果检测</p> 
</article>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/ec4b128d5f72f6f044c122743c44786f/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">PHP使用PHPMailer发送邮件</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/43024e6489592f85a8fb523da8b14bca/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">outlook 收件箱分组_如何在Mac版Outlook 2016中禁用统一收件箱（和分组文件夹）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>