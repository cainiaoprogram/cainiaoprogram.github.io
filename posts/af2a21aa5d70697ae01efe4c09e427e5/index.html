<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>【学习笔记】大数据技术之Kafka3.x（监控，外部系统集成） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="【学习笔记】大数据技术之Kafka3.x（监控，外部系统集成）" />
<meta property="og:description" content="大数据技术之Kafka3.x 第 6 章 Kafka-Eagle 监控6.1 MySQL 环境准备6.2 Kafka 环境准备6.3 Kafka-Eagle 安装6.4 Kafka-Eagle 页面操作 第 7 章 Kafka-Kraft 模式7.1 Kafka-Kraft 架构7.2 Kafka-Kraft 集群部署 第 1 章 集成 Flume1.1 Flume 生产者1.2 Flume 消费者 第 2 章 集成 Flink2.1 Flink 生产者2.2 Flink 消费者 第 3 章 集成 SpringBoot第 4 章 集成 Spark4.1 Spark 生产者4.2 Spark 消费者 第 6 章 Kafka-Eagle 监控 Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用。
6.1 MySQL 环境准备 Kafka-Eagle 的安装依赖于 MySQL，MySQL 主要用来存储可视化展示的数据。如果集群中之前安装过 MySQL 可以跨过该步。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/af2a21aa5d70697ae01efe4c09e427e5/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-05T14:55:07+08:00" />
<meta property="article:modified_time" content="2022-04-05T14:55:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">【学习笔记】大数据技术之Kafka3.x（监控，外部系统集成）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>大数据技术之Kafka3.x</h4> 
 <ul><li><a href="#_6__KafkaEagle__4" rel="nofollow">第 6 章 Kafka-Eagle 监控</a></li><li><ul><li><a href="#61_MySQL__6" rel="nofollow">6.1 MySQL 环境准备</a></li><li><a href="#62_Kafka__8" rel="nofollow">6.2 Kafka 环境准备</a></li><li><a href="#63_KafkaEagle__46" rel="nofollow">6.3 Kafka-Eagle 安装</a></li><li><a href="#64_KafkaEagle__236" rel="nofollow">6.4 Kafka-Eagle 页面操作</a></li></ul> 
  </li><li><a href="#_7__KafkaKraft__245" rel="nofollow">第 7 章 Kafka-Kraft 模式</a></li><li><ul><li><a href="#71_KafkaKraft__247" rel="nofollow">7.1 Kafka-Kraft 架构</a></li><li><a href="#72_KafkaKraft__258" rel="nofollow">7.2 Kafka-Kraft 集群部署</a></li></ul> 
  </li><li><a href="#_1___Flume_391" rel="nofollow">第 1 章 集成 Flume</a></li><li><ul><li><a href="#11_Flume__395" rel="nofollow">1.1 Flume 生产者</a></li><li><a href="#12_Flume__469" rel="nofollow">1.2 Flume 消费者</a></li></ul> 
  </li><li><a href="#_2___Flink_522" rel="nofollow">第 2 章 集成 Flink</a></li><li><ul><li><a href="#21_Flink__574" rel="nofollow">2.1 Flink 生产者</a></li><li><a href="#22_Flink__621" rel="nofollow">2.2 Flink 消费者</a></li></ul> 
  </li><li><a href="#_3___SpringBoot_666" rel="nofollow">第 3 章 集成 SpringBoot</a></li><li><a href="#_4___Spark_667" rel="nofollow">第 4 章 集成 Spark</a></li><li><ul><li><a href="#41_Spark__706" rel="nofollow">4.1 Spark 生产者</a></li><li><a href="#42_Spark__744" rel="nofollow">4.2 Spark 消费者</a></li></ul> 
 </li></ul> 
</div> 
<p></p> 
<h2><a id="_6__KafkaEagle__4"></a>第 6 章 Kafka-Eagle 监控</h2> 
<p>Kafka-Eagle 框架可以监控 Kafka 集群的整体运行情况，在生产环境中经常使用。</p> 
<h3><a id="61_MySQL__6"></a>6.1 MySQL 环境准备</h3> 
<p>Kafka-Eagle 的安装依赖于 MySQL，MySQL 主要用来存储可视化展示的数据。如果集群中之前安装过 MySQL 可以跨过该步。</p> 
<h3><a id="62_Kafka__8"></a>6.2 Kafka 环境准备</h3> 
<p>1）关闭 Kafka 集群</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ kf<span class="token punctuation">.</span>sh stop
</code></pre> 
<p>2）修改/opt/module/kafka/bin/kafka-server-start.sh 命令中</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ vim bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh
</code></pre> 
<p>修改如下参数值：</p> 
<pre><code class="prism language-java"><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"x$KAFKA_HEAP_OPTS"</span> <span class="token operator">=</span> <span class="token string">"x"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> then
 export KAFKA_HEAP_OPTS<span class="token operator">=</span><span class="token string">"-Xmx1G -Xms1G"</span>
</code></pre> 
<p>fi<br> 为</p> 
<pre><code class="prism language-bash"><span class="token keyword">if</span> <span class="token punctuation">[</span> <span class="token string">"x<span class="token variable">$KAFKA_HEAP_OPTS</span>"</span> <span class="token operator">=</span> <span class="token string">"x"</span> <span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token keyword">then</span>
 <span class="token builtin class-name">export</span> <span class="token assign-left variable">KAFKA_HEAP_OPTS</span><span class="token operator">=</span><span class="token string">"-server -Xms2G -Xmx2G -XX:PermSize=128m -XX:+UseG1GC -XX:MaxGCPauseMillis=200 -XX:ParallelGCThreads=8 -XX:ConcGCThreads=5 -XX:InitiatingHeapOccupancyPercent=70"</span>
 <span class="token builtin class-name">export</span> <span class="token assign-left variable">JMX_PORT</span><span class="token operator">=</span><span class="token string">"9999"</span>
 <span class="token comment">#export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"</span>
<span class="token keyword">fi</span>
</code></pre> 
<p><mark>注意：修改之后在启动 Kafka 之前要分发之其他节点</mark></p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> bin<span class="token punctuation">]</span>$ xsync kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh
</code></pre> 
<h3><a id="63_KafkaEagle__46"></a>6.3 Kafka-Eagle 安装</h3> 
<p>0）官网：https://www.kafka-eagle.org/<br> 1）上传压缩包 kafka-eagle-bin-2.0.8.tar.gz 到集群/opt/software 目录<br> 2）解压到本地</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> software<span class="token punctuation">]</span>$ tar <span class="token operator">-</span>zxvf kafka<span class="token operator">-</span>eagle<span class="token operator">-</span>bin<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz 
</code></pre> 
<p>3）进入刚才解压的目录</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token operator">-</span>eagle<span class="token operator">-</span>bin<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token punctuation">]</span>$ ll

总用量 <span class="token number">79164</span>
<span class="token operator">-</span>rw<span class="token operator">-</span>rw<span class="token operator">-</span>r<span class="token operator">--</span><span class="token punctuation">.</span> <span class="token number">1</span> atguigu atguigu <span class="token number">81062577</span> <span class="token number">10</span> 月 <span class="token number">13</span> <span class="token number">00</span><span class="token operator">:</span><span class="token number">00</span> efak<span class="token operator">-</span>web<span class="token number">2.0</span><span class="token number">.8</span><span class="token operator">-</span>bin<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz
</code></pre> 
<p>4）将 efak-web-2.0.8-bin.tar.gz 解压至/opt/module</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token operator">-</span>eagle<span class="token operator">-</span>bin<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token punctuation">]</span>$ tar <span class="token operator">-</span>zxvf efak<span class="token operator">-</span>web<span class="token number">2.0</span><span class="token number">.8</span><span class="token operator">-</span>bin<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz <span class="token operator">-</span><span class="token class-name">C</span> <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>
</code></pre> 
<p>5）修改名称</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ mv efak<span class="token operator">-</span>web<span class="token operator">-</span><span class="token number">2.0</span><span class="token number">.8</span><span class="token operator">/</span> efak
</code></pre> 
<p>6）修改配置文件 /opt/module/efak/conf/system-config.properties</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> conf<span class="token punctuation">]</span>$ vim system<span class="token operator">-</span>config<span class="token punctuation">.</span>properties
######################################
# multi zookeeper <span class="token operator">&amp;</span> kafka cluster list
# <span class="token class-name">Settings</span> prefixed <span class="token keyword">with</span> 'kafka<span class="token punctuation">.</span>eagle<span class="token punctuation">.</span>' will be deprecated<span class="token punctuation">,</span> use <span class="token char">'efak.'</span> instead
######################################
efak<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>cluster<span class="token punctuation">.</span>alias<span class="token operator">=</span>cluster1
cluster1<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>list<span class="token operator">=</span>hadoop102<span class="token operator">:</span><span class="token number">2181</span><span class="token punctuation">,</span>hadoop103<span class="token operator">:</span><span class="token number">2181</span><span class="token punctuation">,</span>hadoop104<span class="token operator">:</span><span class="token number">2181</span><span class="token operator">/</span>kafka
######################################
# zookeeper enable acl
######################################
cluster1<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>acl<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster1<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>acl<span class="token punctuation">.</span>schema<span class="token operator">=</span>digest
cluster1<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>acl<span class="token punctuation">.</span>username<span class="token operator">=</span>test
cluster1<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>acl<span class="token punctuation">.</span>password<span class="token operator">=</span>test123
######################################
# broker size online list
######################################
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>broker<span class="token punctuation">.</span>size<span class="token operator">=</span><span class="token number">20</span>
######################################
# zk client thread limit
######################################
kafka<span class="token punctuation">.</span>zk<span class="token punctuation">.</span>limit<span class="token punctuation">.</span>size<span class="token operator">=</span><span class="token number">32</span>
######################################
# EFAK webui port
######################################
efak<span class="token punctuation">.</span>webui<span class="token punctuation">.</span>port<span class="token operator">=</span><span class="token number">8048</span>
######################################
# kafka jmx acl and ssl authenticate
######################################
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>acl<span class="token operator">=</span><span class="token boolean">false</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>user<span class="token operator">=</span>keadmin
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>password<span class="token operator">=</span>keadmin123
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>ssl<span class="token operator">=</span><span class="token boolean">false</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>truststore<span class="token punctuation">.</span>location<span class="token operator">=</span><span class="token operator">/</span>data<span class="token operator">/</span>ssl<span class="token operator">/</span>certificates<span class="token operator">/</span>kafka<span class="token punctuation">.</span>truststore
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>truststore<span class="token punctuation">.</span>password<span class="token operator">=</span>ke123456
######################################
# kafka offset storage
######################################
# offset 保存在 kafka
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>offset<span class="token punctuation">.</span>storage<span class="token operator">=</span>kafka

######################################
# kafka jmx uri
######################################
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>jmx<span class="token punctuation">.</span>uri<span class="token operator">=</span>service<span class="token operator">:</span>jmx<span class="token operator">:</span>rmi<span class="token operator">:</span><span class="token operator">/</span><span class="token comment">//jndi/rmi://%s/jmxrmi</span>
######################################
# kafka metrics<span class="token punctuation">,</span> <span class="token number">15</span> days by <span class="token keyword">default</span>
######################################
efak<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>charts<span class="token operator">=</span><span class="token boolean">true</span>
efak<span class="token punctuation">.</span>metrics<span class="token punctuation">.</span>retain<span class="token operator">=</span><span class="token number">15</span>
######################################
# kafka sql topic records max
######################################
efak<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>topic<span class="token punctuation">.</span>records<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">5000</span>
efak<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>topic<span class="token punctuation">.</span>preview<span class="token punctuation">.</span>records<span class="token punctuation">.</span>max<span class="token operator">=</span><span class="token number">10</span>
######################################
# delete kafka topic token
######################################
efak<span class="token punctuation">.</span>topic<span class="token punctuation">.</span>token<span class="token operator">=</span>keadmin
######################################
# kafka sasl authenticate
######################################
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>protocol<span class="token operator">=</span>SASL_PLAINTEXT
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>mechanism<span class="token operator">=</span>SCRAM<span class="token operator">-</span>SHA<span class="token operator">-</span><span class="token number">256</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>jaas<span class="token punctuation">.</span>config<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>security<span class="token punctuation">.</span>scram<span class="token punctuation">.</span></span>ScramL</span>
oginModule required username<span class="token operator">=</span><span class="token string">"kafka"</span> password<span class="token operator">=</span><span class="token string">"kafka-eagle"</span><span class="token punctuation">;</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>client<span class="token punctuation">.</span>id<span class="token operator">=</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>blacklist<span class="token punctuation">.</span>topics<span class="token operator">=</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>cgroup<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster1<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>cgroup<span class="token punctuation">.</span>topics<span class="token operator">=</span>
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>protocol<span class="token operator">=</span>SASL_PLAINTEXT
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>mechanism<span class="token operator">=</span>PLAIN
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>jaas<span class="token punctuation">.</span>config<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>security<span class="token punctuation">.</span>plain<span class="token punctuation">.</span></span>PlainL</span>
oginModule required username<span class="token operator">=</span><span class="token string">"kafka"</span> password<span class="token operator">=</span><span class="token string">"kafka-eagle"</span><span class="token punctuation">;</span>
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>client<span class="token punctuation">.</span>id<span class="token operator">=</span>
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>blacklist<span class="token punctuation">.</span>topics<span class="token operator">=</span>
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>cgroup<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster2<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>sasl<span class="token punctuation">.</span>cgroup<span class="token punctuation">.</span>topics<span class="token operator">=</span>
######################################
# kafka ssl authenticate
######################################
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>protocol<span class="token operator">=</span>SSL
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>truststore<span class="token punctuation">.</span>location<span class="token operator">=</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>truststore<span class="token punctuation">.</span>password<span class="token operator">=</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>keystore<span class="token punctuation">.</span>location<span class="token operator">=</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>keystore<span class="token punctuation">.</span>password<span class="token operator">=</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>key<span class="token punctuation">.</span>password<span class="token operator">=</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>endpoint<span class="token punctuation">.</span>identification<span class="token punctuation">.</span>algorithm<span class="token operator">=</span>https
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>blacklist<span class="token punctuation">.</span>topics<span class="token operator">=</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>cgroup<span class="token punctuation">.</span>enable<span class="token operator">=</span><span class="token boolean">false</span>
cluster3<span class="token punctuation">.</span>efak<span class="token punctuation">.</span>ssl<span class="token punctuation">.</span>cgroup<span class="token punctuation">.</span>topics<span class="token operator">=</span>
######################################
# kafka sqlite jdbc driver address

######################################


# 配置 mysql 连接
efak<span class="token punctuation">.</span>driver<span class="token operator">=</span><span class="token class-name"><span class="token namespace">com<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>jdbc<span class="token punctuation">.</span></span>Driver</span>
efak<span class="token punctuation">.</span>url<span class="token operator">=</span>jdbc<span class="token operator">:</span>mysql<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop102<span class="token operator">:</span><span class="token number">3306</span><span class="token operator">/</span>ke<span class="token operator">?</span>useUnicode<span class="token operator">=</span><span class="token boolean">true</span><span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span>UTF<span class="token operator">-</span><span class="token number">8</span><span class="token operator">&amp;</span>zeroDateTimeBehavior<span class="token operator">=</span>convertToNull
efak<span class="token punctuation">.</span>username<span class="token operator">=</span>root
efak<span class="token punctuation">.</span>password<span class="token operator">=</span><span class="token number">000000</span>
######################################
# kafka mysql jdbc driver address
######################################
#efak<span class="token punctuation">.</span>driver<span class="token operator">=</span><span class="token class-name"><span class="token namespace">com<span class="token punctuation">.</span>mysql<span class="token punctuation">.</span>cj<span class="token punctuation">.</span>jdbc<span class="token punctuation">.</span></span>Driver</span>
#efak<span class="token punctuation">.</span>url<span class="token operator">=</span>jdbc<span class="token operator">:</span>mysql<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token number">127.0</span><span class="token number">.0</span><span class="token number">.1</span><span class="token operator">:</span><span class="token number">3306</span><span class="token operator">/</span>ke<span class="token operator">?</span>useUnicode<span class="token operator">=</span><span class="token boolean">true</span><span class="token operator">&amp;</span>characterEncoding<span class="token operator">=</span><span class="token class-name">U</span>
TF<span class="token operator">-</span><span class="token number">8</span><span class="token operator">&amp;</span>zeroDateTimeBehavior<span class="token operator">=</span>convertToNull
#efak<span class="token punctuation">.</span>username<span class="token operator">=</span>root
#efak<span class="token punctuation">.</span>password<span class="token operator">=</span><span class="token number">123456</span>
</code></pre> 
<p>7）添加环境变量</p> 
<pre><code class="prism language-bash"><span class="token punctuation">[</span>atguigu@hadoop102 conf<span class="token punctuation">]</span>$ <span class="token function">sudo</span> <span class="token function">vim</span> /etc/profile.d/my_env.sh
<span class="token comment"># kafkaEFAK</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">KE_HOME</span><span class="token operator">=</span>/opt/module/efak
<span class="token builtin class-name">export</span> <span class="token assign-left variable"><span class="token environment constant">PATH</span></span><span class="token operator">=</span><span class="token environment constant">$PATH</span><span class="token builtin class-name">:</span><span class="token variable">$KE_HOME</span>/bin
</code></pre> 
<p>注意：source /etc/profile</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> conf<span class="token punctuation">]</span>$ source <span class="token operator">/</span>etc<span class="token operator">/</span>profile
</code></pre> 
<p>8）启动<br> （1）<mark>注意：启动之前需要先启动 ZK 以及 KAFKA</mark>。</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka<span class="token punctuation">]</span>$ kf<span class="token punctuation">.</span>sh start
</code></pre> 
<p>（2）启动 efak</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> efak<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>ke<span class="token punctuation">.</span>sh start
<span class="token class-name">Version</span> <span class="token number">2.0</span><span class="token number">.8</span> <span class="token operator">--</span> <span class="token class-name">Copyright</span> <span class="token number">2016</span><span class="token operator">-</span><span class="token number">2021</span>
<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
<span class="token operator">*</span> EFAK <span class="token class-name">Service</span> has started success<span class="token punctuation">.</span>
<span class="token operator">*</span> <span class="token class-name">Welcome</span><span class="token punctuation">,</span> <span class="token class-name">Now</span> you can visit 'http<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token number">192.168</span><span class="token number">.10</span><span class="token number">.102</span><span class="token operator">:</span><span class="token number">8048</span>'
<span class="token operator">*</span> <span class="token class-name">Account</span><span class="token operator">:</span>admin <span class="token punctuation">,</span><span class="token class-name">Password</span><span class="token operator">:</span><span class="token number">123456</span>
<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
<span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Usage</span><span class="token punctuation">&gt;</span></span> ke<span class="token punctuation">.</span>sh <span class="token punctuation">[</span>start<span class="token operator">|</span>status<span class="token operator">|</span>stop<span class="token operator">|</span>restart<span class="token operator">|</span>stats<span class="token punctuation">]</span> <span class="token operator">&lt;</span><span class="token operator">/</span><span class="token class-name">Usage</span><span class="token operator">&gt;</span>
<span class="token operator">*</span> <span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">Usage</span><span class="token punctuation">&gt;</span></span> https<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>www<span class="token punctuation">.</span>kafka<span class="token operator">-</span>eagle<span class="token punctuation">.</span>org<span class="token operator">/</span> <span class="token operator">&lt;</span><span class="token operator">/</span><span class="token class-name">Usage</span><span class="token operator">&gt;</span>
<span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span><span class="token operator">*</span>
</code></pre> 
<p>说明：如果停止 efak，执行命令。</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> efak<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>ke<span class="token punctuation">.</span>sh stop
</code></pre> 
<h3><a id="64_KafkaEagle__236"></a>6.4 Kafka-Eagle 页面操作</h3> 
<p>1）登录页面查看监控数据<br> http://192.168.10.102:8048/<br> <img src="https://images2.imgbox.com/a8/c8/V0CSp2GY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/4c/be/xRrT3jtT_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ae/d8/MUpE6QKx_o.png" alt="在这里插入图片描述"></p> 
<p><img src="https://images2.imgbox.com/7d/5f/pAwfbmkv_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_7__KafkaKraft__245"></a>第 7 章 Kafka-Kraft 模式</h2> 
<p>2.8.0新特性</p> 
<h3><a id="71_KafkaKraft__247"></a>7.1 Kafka-Kraft 架构</h3> 
<p><img src="https://images2.imgbox.com/42/f4/4eC1IQ71_o.png" alt="在这里插入图片描述"></p> 
<p>左图为 Kafka 现有架构，元数据在 zookeeper 中，运行时动态选举 controller，由controller 进行 Kafka 集群管理。右图为 kraft 模式架构（实验性），不再依赖 zookeeper 集群，而是用三台 controller 节点代替 zookeeper，元数据保存在 controller 中，由 controller 直接进行 Kafka 集群管理。</p> 
<p>这样做的好处有以下几个：</p> 
<ul><li>Kafka 不再依赖外部框架，而是能够独立运行；</li><li>controller 管理集群时，不再需要从 zookeeper 中先读取数据，集群性能上升；</li><li>由于不依赖 zookeeper，集群扩展时不再受到 zookeeper 读写能力限制；</li><li>controller 不再动态选举，而是由配置文件规定。这样我们可以有针对性的加强controller 节点的配置，而不是像以前一样对随机 controller 节点的高负载束手无策。</li></ul> 
<h3><a id="72_KafkaKraft__258"></a>7.2 Kafka-Kraft 集群部署</h3> 
<p>1）再次解压一份 kafka 安装包</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> software<span class="token punctuation">]</span>$ tar <span class="token operator">-</span>zxvf kafka_2<span class="token punctuation">.</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token number">.0</span><span class="token punctuation">.</span>tgz <span class="token operator">-</span><span class="token class-name">C</span> <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>
</code></pre> 
<p>2）重命名为 kafka2</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ mv kafka_2<span class="token punctuation">.</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">3.0</span><span class="token number">.0</span><span class="token operator">/</span> kafka2
</code></pre> 
<p>3）在 hadoop102 上修改/opt/module/kafka2/config/kraft/server.properties 配置文件</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kraft<span class="token punctuation">]</span>$ vim server<span class="token punctuation">.</span>properties
</code></pre> 
<pre><code class="prism language-java">#kafka 的角色（controller 相当于主机、broker 节点相当于从机，主机类似 zk 功能）
process<span class="token punctuation">.</span>roles<span class="token operator">=</span>broker<span class="token punctuation">,</span> controller
#节点 ID
node<span class="token punctuation">.</span>id<span class="token operator">=</span><span class="token number">2</span>
#controller 服务协议别名
controller<span class="token punctuation">.</span>listener<span class="token punctuation">.</span>names<span class="token operator">=</span>CONTROLLER
#全 <span class="token class-name">Controller</span> 列表
controller<span class="token punctuation">.</span>quorum<span class="token punctuation">.</span>voters<span class="token operator">=</span><span class="token number">2</span><span class="token annotation punctuation">@hadoop102</span><span class="token operator">:</span><span class="token number">9093</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token annotation punctuation">@hadoop103</span><span class="token operator">:</span><span class="token number">9093</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token annotation punctuation">@hado</span>
op104<span class="token operator">:</span><span class="token number">9093</span>
#不同服务器绑定的端口
listeners<span class="token operator">=</span>PLAINTEXT<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token operator">:</span><span class="token number">9092</span><span class="token punctuation">,</span>CONTROLLER<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span><span class="token operator">:</span><span class="token number">9093</span>
#broker 服务协议别名
inter<span class="token punctuation">.</span>broker<span class="token punctuation">.</span>listener<span class="token punctuation">.</span>name<span class="token operator">=</span>PLAINTEXT
#broker 对外暴露的地址
<span class="token class-name"><span class="token namespace">advertised<span class="token punctuation">.</span></span>Listeners</span><span class="token operator">=</span>PLAINTEXT<span class="token operator">:</span><span class="token operator">/</span><span class="token operator">/</span>hadoop102<span class="token operator">:</span><span class="token number">9092</span>
#协议别名到安全协议的映射
listener<span class="token punctuation">.</span>security<span class="token punctuation">.</span>protocol<span class="token punctuation">.</span>map<span class="token operator">=</span>CONTROLLER<span class="token operator">:</span>PLAINTEXT<span class="token punctuation">,</span>PLAINTEXT<span class="token operator">:</span><span class="token class-name">PLA</span>
INTEXT<span class="token punctuation">,</span>SSL<span class="token operator">:</span>SSL<span class="token punctuation">,</span>SASL_PLAINTEXT<span class="token operator">:</span>SASL_PLAINTEXT<span class="token punctuation">,</span>SASL_SSL<span class="token operator">:</span>SASL_SSL
#kafka 数据存储目录
log<span class="token punctuation">.</span>dirs<span class="token operator">=</span><span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>data
</code></pre> 
<p>4）分发 kafka2</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ xsync kafka2<span class="token operator">/</span>
</code></pre> 
<ul><li>在 hadoop103 和 hadoop104 上 需 要 对 node.id 相应改变 ， 值 需 要 和<br> controller.quorum.voters 对应。</li><li>在 hadoop103 和 hadoop104 上需要 根据各自的主机名称，修改相应的<br> advertised.Listeners 地址。</li></ul> 
<p>5）初始化集群数据目录<br> （1）首先生成存储目录唯一 ID。</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh random<span class="token operator">-</span>uuid
<span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span>
</code></pre> 
<p>（2）用该 ID 格式化 kafka 存储目录（三台节点）。</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh format <span class="token operator">-</span>t <span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span> <span class="token operator">-</span>c <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh format <span class="token operator">-</span>t <span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span> <span class="token operator">-</span>c <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>storage<span class="token punctuation">.</span>sh format <span class="token operator">-</span>t <span class="token class-name">J7s9e8PPTKOO47PxzI39VA</span> <span class="token operator">-</span>c <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>kafka2<span class="token operator">/</span>config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
</code></pre> 
<p>6）启动 kafka 集群</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh <span class="token operator">-</span>daemon config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh <span class="token operator">-</span>daemon config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>start<span class="token punctuation">.</span>sh <span class="token operator">-</span>daemon config<span class="token operator">/</span>kraft<span class="token operator">/</span>server<span class="token punctuation">.</span>properties
</code></pre> 
<p>7）停止 kafka 集群</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>stop<span class="token punctuation">.</span>sh
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>stop<span class="token punctuation">.</span>sh
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka2<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>server<span class="token operator">-</span>stop<span class="token punctuation">.</span>sh
</code></pre> 
<p>7.3 Kafka-Kraft 集群启动停止脚本<br> 1）在/home/atguigu/bin 目录下创建文件 kf2.sh 脚本文件</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> bin<span class="token punctuation">]</span>$ vim kf2<span class="token punctuation">.</span>sh
</code></pre> 
<p>脚本如下：</p> 
<pre><code class="prism language-java">#<span class="token operator">!</span> <span class="token operator">/</span>bin<span class="token operator">/</span>bash
<span class="token keyword">case</span> $<span class="token number">1</span> in
<span class="token string">"start"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
 <span class="token keyword">for</span> i in hadoop102 hadoop103 hadoop104
 <span class="token keyword">do</span>
 echo <span class="token string">" --------启动 $i Kafka2-------"</span>
 ssh $i <span class="token string">"/opt/module/kafka2/bin/kafka-server-start.sh -daemon /opt/module/kafka2/config/kraft/server.properties"</span>
 done
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
<span class="token string">"stop"</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
 <span class="token keyword">for</span> i in hadoop102 hadoop103 hadoop104
 <span class="token keyword">do</span>
 echo <span class="token string">" --------停止 $i Kafka2-------"</span>
 ssh $i <span class="token string">"/opt/module/kafka2/bin/kafka-server-stop.sh "</span>
 done
<span class="token punctuation">}</span><span class="token punctuation">;</span><span class="token punctuation">;</span>
esac
</code></pre> 
<p>2）添加执行权限</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> bin<span class="token punctuation">]</span>$ chmod <span class="token operator">+</span>x kf2<span class="token punctuation">.</span>sh
</code></pre> 
<p>3）启动集群命令</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token operator">~</span><span class="token punctuation">]</span>$ kf2<span class="token punctuation">.</span>sh start
</code></pre> 
<p>4）停止集群命令</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token operator">~</span><span class="token punctuation">]</span>$ kf2<span class="token punctuation">.</span>sh sto
</code></pre> 
<h2><a id="_1___Flume_391"></a>第 1 章 集成 Flume</h2> 
<p>Flume 是一个在大数据开发中非常常用的组件。可以用于 Kafka 的生产者，也可以用于Flume 的消费者。<br> <img src="https://images2.imgbox.com/89/38/U4yuxvxL_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="11_Flume__395"></a>1.1 Flume 生产者</h3> 
<p><img src="https://images2.imgbox.com/4a/dc/iKF8mqlr_o.png" alt="在这里插入图片描述"></p> 
<p>（1）启动 kafka 集群</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token operator">~</span><span class="token punctuation">]</span>$ zk<span class="token punctuation">.</span>sh start
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token operator">~</span><span class="token punctuation">]</span>$ kf<span class="token punctuation">.</span>sh start
</code></pre> 
<p>（2）启动 kafka 消费者</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre> 
<p>（3）Flume 安装步骤<br> <a href="https://blog.csdn.net/prague6695/article/details/123819152">在 hadoop102 主机上安装 Flume。</a><br> 详见：尚硅谷大数据技术之 Flume</p> 
<p>（4）配置 Flume<br> 在 hadoop102 节点的 Flume 的 job 目录下创建 file_to_kafka.conf</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> flume<span class="token punctuation">]</span>$ mkdir jobs
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> flume<span class="token punctuation">]</span>$ vim jobs<span class="token operator">/</span>file_to_kafka<span class="token punctuation">.</span>conf 
</code></pre> 
<p>配置文件内容如下</p> 
<pre><code class="prism language-java"># <span class="token number">1</span> 组件定义
a1<span class="token punctuation">.</span>sources <span class="token operator">=</span> r1
a1<span class="token punctuation">.</span>sinks <span class="token operator">=</span> k1
a1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
# <span class="token number">2</span> 配置 source
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>type <span class="token operator">=</span> TAILDIR
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>filegroups <span class="token operator">=</span> f1
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>filegroups<span class="token punctuation">.</span>f1 <span class="token operator">=</span> <span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>applog<span class="token operator">/</span>app<span class="token punctuation">.</span>*
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>positionFile <span class="token operator">=</span> 
<span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>flume<span class="token operator">/</span>taildir_position<span class="token punctuation">.</span>json
# <span class="token number">3</span> 配置 channel
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>type <span class="token operator">=</span> memory
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>capacity <span class="token operator">=</span> <span class="token number">1000</span>
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
# <span class="token number">4</span> 配置 sink
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>type <span class="token operator">=</span> <span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>sink<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>KafkaSink</span>
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>bootstrap<span class="token punctuation">.</span>servers <span class="token operator">=</span> 
hadoop102<span class="token operator">:</span><span class="token number">9092</span><span class="token punctuation">,</span>hadoop103<span class="token operator">:</span><span class="token number">9092</span><span class="token punctuation">,</span>hadoop104<span class="token operator">:</span><span class="token number">9092</span>
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>topic <span class="token operator">=</span> first
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>flumeBatchSize <span class="token operator">=</span> <span class="token number">20</span>
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>acks <span class="token operator">=</span> <span class="token number">1</span>
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>producer<span class="token punctuation">.</span>linger<span class="token punctuation">.</span>ms <span class="token operator">=</span> <span class="token number">1</span>
# <span class="token number">5</span> 拼接组件
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>channel <span class="token operator">=</span> c1
</code></pre> 
<p>（5）启动 Flume</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> flume<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>flume<span class="token operator">-</span>ng agent <span class="token operator">-</span>c conf<span class="token operator">/</span> <span class="token operator">-</span>n a1 <span class="token operator">-</span>f jobs<span class="token operator">/</span>file_to_kafka<span class="token punctuation">.</span>conf <span class="token operator">&amp;</span>
</code></pre> 
<p>&amp;： 表示后台启动<br> （6）向/opt/module/applog/app.log 里追加数据，查看 kafka 消费者消费情况</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> <span class="token keyword">module</span><span class="token punctuation">]</span>$ mkdir applog
<span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> applog<span class="token punctuation">]</span>$ echo hello <span class="token operator">&gt;&gt;</span> 
<span class="token operator">/</span>opt<span class="token operator">/</span><span class="token keyword">module</span><span class="token operator">/</span>applog<span class="token operator">/</span>app<span class="token punctuation">.</span>log
</code></pre> 
<p>（7）观察 kafka 消费者，能够看到消费的 hello 数据</p> 
<h3><a id="12_Flume__469"></a>1.2 Flume 消费者</h3> 
<p><img src="https://images2.imgbox.com/e6/34/mIgqkdG6_o.png" alt="在这里插入图片描述"></p> 
<p>（1）配置 Flume<br> 在 hadoop102 节点的 Flume 的/opt/module/flume/jobs 目录下创建 kafka_to_file.conf</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> jobs<span class="token punctuation">]</span>$ vim kafka_to_file<span class="token punctuation">.</span>conf
</code></pre> 
<p>配置文件内容如下</p> 
<pre><code class="prism language-java"># <span class="token number">1</span> 组件定义
a1<span class="token punctuation">.</span>sources <span class="token operator">=</span> r1
a1<span class="token punctuation">.</span>sinks <span class="token operator">=</span> k1
a1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
# <span class="token number">2</span> 配置 source
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>type <span class="token operator">=</span> <span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flume<span class="token punctuation">.</span>source<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span>KafkaSource</span>
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>batchSize <span class="token operator">=</span> <span class="token number">50</span>
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>batchDurationMillis <span class="token operator">=</span> <span class="token number">200</span>
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>bootstrap<span class="token punctuation">.</span>servers <span class="token operator">=</span> hadoop102<span class="token operator">:</span><span class="token number">9092</span>
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>topics <span class="token operator">=</span> first
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span>group<span class="token punctuation">.</span>id <span class="token operator">=</span> custom<span class="token punctuation">.</span>g<span class="token punctuation">.</span>id
# <span class="token number">3</span> 配置 channel
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>type <span class="token operator">=</span> memory
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>capacity <span class="token operator">=</span> <span class="token number">1000</span>
a1<span class="token punctuation">.</span>channels<span class="token punctuation">.</span>c1<span class="token punctuation">.</span>transactionCapacity <span class="token operator">=</span> <span class="token number">100</span>
# <span class="token number">4</span> 配置 sink
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>type <span class="token operator">=</span> logger

# <span class="token number">5</span> 拼接组件
a1<span class="token punctuation">.</span>sources<span class="token punctuation">.</span>r1<span class="token punctuation">.</span>channels <span class="token operator">=</span> c1
a1<span class="token punctuation">.</span>sinks<span class="token punctuation">.</span>k1<span class="token punctuation">.</span>channel <span class="token operator">=</span> c1
</code></pre> 
<p>（2）启动 Flume</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop102</span> flume<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>flume<span class="token operator">-</span>ng agent <span class="token operator">-</span>c conf<span class="token operator">/</span> <span class="token operator">-</span>n a1 <span class="token operator">-</span>f jobs<span class="token operator">/</span>kafka_to_file<span class="token punctuation">.</span>conf <span class="token operator">-</span><span class="token class-name">Dflume</span><span class="token punctuation">.</span>root<span class="token punctuation">.</span>logger<span class="token operator">=</span>INFO<span class="token punctuation">,</span>console
</code></pre> 
<p>（3）启动 kafka 生产者</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre> 
<p>并输入数据，例如：hello world<br> （4）观察控制台输出的日志</p> 
<h2><a id="_2___Flink_522"></a>第 2 章 集成 Flink</h2> 
<p>Flink 是一个在大数据开发中非常常用的组件。可以用于 Kafka 的生产者，也可以用于Flink 的消费者。<br> <img src="https://images2.imgbox.com/b0/1f/JdWIS74O_o.png" alt="在这里插入图片描述"></p> 
<p>1）Flink 环境准备<br> （1）创建一个 maven 项目 flink-kafka<br> （2）添加配置文件</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-java<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-streaming-java_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-clients_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.flink<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>flink-connector-kafka_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>1.13.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>（3）将 log4j.properties 文件添加到 resources 里面，就能更改打印日志的级别为 error</p> 
<pre><code class="prism language-java">log4j<span class="token punctuation">.</span>rootLogger<span class="token operator">=</span>error<span class="token punctuation">,</span> stdout<span class="token punctuation">,</span><span class="token class-name">R</span>
log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span>stdout<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>ConsoleAppender</span>
log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>layout<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>PatternLayout</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>layout<span class="token punctuation">.</span></span>ConversionPattern</span><span class="token operator">=</span><span class="token operator">%</span>d<span class="token punctuation">{<!-- --></span>yyyy<span class="token operator">-</span>MM<span class="token operator">-</span>dd 
HH<span class="token operator">:</span>mm<span class="token operator">:</span>ss<span class="token punctuation">,</span>SSS<span class="token punctuation">}</span> <span class="token operator">%</span><span class="token number">5</span>p <span class="token operator">--</span><span class="token operator">-</span> <span class="token punctuation">[</span><span class="token operator">%</span><span class="token number">50</span>t<span class="token punctuation">]</span> <span class="token operator">%</span><span class="token operator">-</span><span class="token function">80c</span><span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token operator">%</span><span class="token number">5L</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token operator">%</span>m<span class="token operator">%</span>n
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R</span><span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>RollingFileAppender</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R<span class="token punctuation">.</span>File</span><span class="token operator">=</span><span class="token punctuation">.</span><span class="token punctuation">.</span>/log<span class="token operator">/</span>agent<span class="token punctuation">.</span>log
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R<span class="token punctuation">.</span>MaxFileSize</span><span class="token operator">=</span><span class="token number">1024</span>KB
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R<span class="token punctuation">.</span>MaxBackupIndex</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R</span><span class="token punctuation">.</span>layout<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>PatternLayout</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R</span><span class="token punctuation">.</span>layout<span class="token punctuation">.</span>ConversionPattern<span class="token operator">=</span><span class="token operator">%</span>d<span class="token punctuation">{<!-- --></span>yyyy<span class="token operator">-</span>MM<span class="token operator">-</span>dd 
HH<span class="token operator">:</span>mm<span class="token operator">:</span>ss<span class="token punctuation">,</span>SSS<span class="token punctuation">}</span> <span class="token operator">%</span><span class="token number">5</span>p <span class="token operator">--</span><span class="token operator">-</span> <span class="token punctuation">[</span><span class="token operator">%</span><span class="token number">50</span>t<span class="token punctuation">]</span> <span class="token operator">%</span><span class="token operator">-</span><span class="token function">80c</span><span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token operator">%</span><span class="token number">6L</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token operator">%</span>m<span class="token operator">%</span>n
</code></pre> 
<p>（4）在 java 文件夹下创建包名为 com.atguigu.flink</p> 
<h3><a id="21_Flink__574"></a>2.1 Flink 生产者</h3> 
<p>（1）在 com.atguigu.flink 包下创建 java 类：FlinkKafkaProducer1</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>flink</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>datastream<span class="token punctuation">.</span></span><span class="token class-name">DataStream</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaProducer</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token class-name">ProducerConfig</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkKafkaProducer1</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 0 初始化 flink 环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span> <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 1 读取集合中数据</span>
        <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> wordsList <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        wordsList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"hello"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        wordsList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"world"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        <span class="token class-name">DataStream</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> stream <span class="token operator">=</span> env<span class="token punctuation">.</span><span class="token function">fromCollection</span><span class="token punctuation">(</span>wordsList<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2 kafka 生产者配置信息</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span> <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3 创建 kafka 生产者</span>
        <span class="token class-name">FlinkKafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaProducer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaProducer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>
                <span class="token string">"first"</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                properties
        <span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4 生产者和 flink 流关联</span>
        stream<span class="token punctuation">.</span><span class="token function">addSink</span><span class="token punctuation">(</span>kafkaProducer<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 5 执行</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>（2）启动 Kafka 消费者</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre> 
<p>（3）执行 FlinkKafkaProducer1 程序，观察 kafka 消费者控制台情况</p> 
<h3><a id="22_Flink__621"></a>2.2 Flink 消费者</h3> 
<p>（1）在 com.atguigu.flink 包下创建 java 类：FlinkKafkaConsumer1</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>flink</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>api<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">SimpleStringSchema</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>api<span class="token punctuation">.</span>environment<span class="token punctuation">.</span></span><span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>flink<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>connectors<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span></span><span class="token class-name">FlinkKafkaConsumer</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span><span class="token punctuation">;</span>
        <span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span><span class="token punctuation">;</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">FlinkKafkaConsumer1</span> <span class="token punctuation">{<!-- --></span>
    <span class="token keyword">public</span> <span class="token keyword">static</span> <span class="token keyword">void</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span> <span class="token punctuation">{<!-- --></span>

        <span class="token comment">// 0 初始化 flink 环境</span>
        <span class="token class-name">StreamExecutionEnvironment</span> env <span class="token operator">=</span>
                <span class="token class-name">StreamExecutionEnvironment</span><span class="token punctuation">.</span><span class="token function">getExecutionEnvironment</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        env<span class="token punctuation">.</span><span class="token function">setParallelism</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 1 kafka 消费者配置信息</span>
        <span class="token class-name">Properties</span> properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        properties<span class="token punctuation">.</span><span class="token function">setProperty</span><span class="token punctuation">(</span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span>
                <span class="token string">"hadoop102:9092"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 2 创建 kafka 消费者</span>
        <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">&gt;</span></span> kafkaConsumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">FlinkKafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">&gt;</span></span><span class="token punctuation">(</span>
                <span class="token string">"first"</span><span class="token punctuation">,</span>
                <span class="token keyword">new</span> <span class="token class-name">SimpleStringSchema</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                properties
        <span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 3 消费者和 flink 流关联</span>
        env<span class="token punctuation">.</span><span class="token function">addSource</span><span class="token punctuation">(</span>kafkaConsumer<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 4 执行</span>
        env<span class="token punctuation">.</span><span class="token function">execute</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>（2）启动 FlinkKafkaConsumer1 消费者<br> （3）启动 kafka 生产者</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre> 
<p>（4）观察 IDEA 控制台数据打印</p> 
<h2><a id="_3___SpringBoot_666"></a>第 3 章 集成 SpringBoot</h2> 
<h2><a id="_4___Spark_667"></a>第 4 章 集成 Spark</h2> 
<p>Spark 是一个在大数据开发中非常常用的组件。可以用于 Kafka 的生产者，也可以用于Spark 的消费者。<br> <img src="https://images2.imgbox.com/83/79/X8r47Fdh_o.png" alt="在这里插入图片描述"></p> 
<p>1）Scala 环境准备<br> 尚硅谷大数据技术之Scala（3.8）.docx<br> 2）Spark 环境准备<br> （1）创建一个 maven 项目 spark-kafka<br> （2）在项目 spark-kafka 上点击右键，Add Framework Support=》勾选 scala<br> （3）在 main 下创建 scala 文件夹，并右键 Mark Directory as Sources Root=&gt;在 scala 下创建包名为 com.atguigu.spark<br> （4）添加配置文件</p> 
<pre><code class="prism language-java"><span class="token generics"><span class="token punctuation">&lt;</span>dependencies<span class="token punctuation">&gt;</span></span>
<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">&gt;</span></span>
<span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">&gt;</span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">&gt;</span>
<span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">&gt;</span></span>spark<span class="token operator">-</span>streaming<span class="token operator">-</span>kafka<span class="token operator">-</span><span class="token number">0</span><span class="token operator">-</span><span class="token number">10_2.12</span><span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">&gt;</span>
<span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">&gt;</span></span><span class="token number">3.0</span><span class="token number">.0</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">&gt;</span>
<span class="token operator">&lt;</span><span class="token operator">/</span>dependencies<span class="token operator">&gt;</span>
</code></pre> 
<p>（5）将 log4j.properties 文件添加到 resources 里面，就能更改打印日志的级别为 error</p> 
<pre><code class="prism language-java">log4j<span class="token punctuation">.</span>rootLogger<span class="token operator">=</span>error<span class="token punctuation">,</span> stdout<span class="token punctuation">,</span><span class="token class-name">R</span>
log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span>stdout<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>ConsoleAppender</span>
log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>layout<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>PatternLayout</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span>stdout<span class="token punctuation">.</span>layout<span class="token punctuation">.</span></span>ConversionPattern</span><span class="token operator">=</span><span class="token operator">%</span>d<span class="token punctuation">{<!-- --></span>yyyy<span class="token operator">-</span>MM<span class="token operator">-</span>dd 
HH<span class="token operator">:</span>mm<span class="token operator">:</span>ss<span class="token punctuation">,</span>SSS<span class="token punctuation">}</span> <span class="token operator">%</span><span class="token number">5</span>p <span class="token operator">--</span><span class="token operator">-</span> <span class="token punctuation">[</span><span class="token operator">%</span><span class="token number">50</span>t<span class="token punctuation">]</span> <span class="token operator">%</span><span class="token operator">-</span><span class="token function">80c</span><span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token operator">%</span><span class="token number">5L</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token operator">%</span>m<span class="token operator">%</span>n
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R</span><span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>RollingFileAppender</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R<span class="token punctuation">.</span>File</span><span class="token operator">=</span><span class="token punctuation">.</span><span class="token punctuation">.</span>/log<span class="token operator">/</span>agent<span class="token punctuation">.</span>log
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R<span class="token punctuation">.</span>MaxFileSize</span><span class="token operator">=</span><span class="token number">1024</span>KB
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R<span class="token punctuation">.</span>MaxBackupIndex</span><span class="token operator">=</span><span class="token number">1</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R</span><span class="token punctuation">.</span>layout<span class="token operator">=</span><span class="token class-name"><span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>log4j<span class="token punctuation">.</span></span>PatternLayout</span>
<span class="token class-name"><span class="token namespace">log4j<span class="token punctuation">.</span>appender<span class="token punctuation">.</span></span>R</span><span class="token punctuation">.</span>layout<span class="token punctuation">.</span>ConversionPattern<span class="token operator">=</span><span class="token operator">%</span>d<span class="token punctuation">{<!-- --></span>yyyy<span class="token operator">-</span>MM<span class="token operator">-</span>dd 
HH<span class="token operator">:</span>mm<span class="token operator">:</span>ss<span class="token punctuation">,</span>SSS<span class="token punctuation">}</span> <span class="token operator">%</span><span class="token number">5</span>p <span class="token operator">--</span><span class="token operator">-</span> <span class="token punctuation">[</span><span class="token operator">%</span><span class="token number">50</span>t<span class="token punctuation">]</span> <span class="token operator">%</span><span class="token operator">-</span><span class="token function">80c</span><span class="token punctuation">(</span>line<span class="token operator">:</span><span class="token operator">%</span><span class="token number">6L</span><span class="token punctuation">)</span> <span class="token operator">:</span> <span class="token operator">%</span>m<span class="token operator">%</span>n
</code></pre> 
<h3><a id="41_Spark__706"></a>4.1 Spark 生产者</h3> 
<p>（1）在 com.atguigu.spark 包下创建 scala Object：SparkKafkaProducer</p> 
<pre><code class="prism language-java"><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>atguigu<span class="token punctuation">.</span>spark</span>
        <span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">Properties</span>
        <span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>producer<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span><span class="token class-name">KafkaProducer</span><span class="token punctuation">,</span><span class="token class-name">ProducerRecord</span><span class="token punctuation">}</span>
        object <span class="token class-name">SparkKafkaProducer</span> <span class="token punctuation">{<!-- --></span>def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
        <span class="token comment">// 0 kafka 配置信息</span>
        val properties <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Properties</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG<span class="token punctuation">,</span>
        <span class="token string">"hadoop102:9092,hadoop103:9092,hadoop104:9092"</span><span class="token punctuation">)</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>KEY_SERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span>
        classOf<span class="token punctuation">[</span><span class="token class-name">StringSerializer</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        properties<span class="token punctuation">.</span><span class="token function">put</span><span class="token punctuation">(</span><span class="token class-name">ProducerConfig</span><span class="token punctuation">.</span>VALUE_SERIALIZER_CLASS_CONFIG<span class="token punctuation">,</span>
        classOf<span class="token punctuation">[</span><span class="token class-name">StringSerializer</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment">// 1 创建 kafka 生产者</span>
        <span class="token keyword">var</span> producer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaProducer</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>properties<span class="token punctuation">)</span>
        <span class="token comment">// 2 发送数据</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>i <span class="token operator">&lt;</span><span class="token operator">-</span> <span class="token number">1</span> <span class="token keyword">to</span> <span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">{<!-- --></span>
        producer<span class="token punctuation">.</span><span class="token function">send</span><span class="token punctuation">(</span><span class="token keyword">new</span>
        <span class="token class-name">ProducerRecord</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">,</span><span class="token string">"atguigu"</span> <span class="token operator">+</span> i<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
        <span class="token comment">// 3 关闭资源</span>
        producer<span class="token punctuation">.</span><span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>

</code></pre> 
<p>（2）启动 Kafka 消费者</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop104</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>consumer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre> 
<p>（3）执行 SparkKafkaProducer 程序，观察 kafka 消费者控制台情况</p> 
<h3><a id="42_Spark__744"></a>4.2 Spark 消费者</h3> 
<p>（1）添加配置文件</p> 
<pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependencies</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming-kafka-0-10_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-core_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>spark-streaming_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.0.0<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependencies</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
<p>（2）在 com.atguigu.spark 包下创建 scala Object：SparkKafkaConsumer<br> package com.atguigu.spark</p> 
<pre><code class="prism language-java"><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>clients<span class="token punctuation">.</span>consumer<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span><span class="token class-name">ConsumerConfig</span><span class="token punctuation">,</span> <span class="token class-name">ConsumerRecord</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>kafka<span class="token punctuation">.</span>common<span class="token punctuation">.</span>serialization<span class="token punctuation">.</span></span><span class="token class-name">StringDeserializer</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span></span><span class="token class-name">SparkConf</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>dstream<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span><span class="token class-name">DStream</span><span class="token punctuation">,</span> <span class="token class-name">InputDStream</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span><span class="token class-name">Seconds</span><span class="token punctuation">,</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">}</span>
<span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>streaming<span class="token punctuation">.</span>kafka010<span class="token punctuation">.</span></span><span class="token punctuation">{<!-- --></span><span class="token class-name">ConsumerStrategies</span><span class="token punctuation">,</span> <span class="token class-name">KafkaUtils</span><span class="token punctuation">,</span> <span class="token class-name">LocationStrategies</span><span class="token punctuation">}</span>
object <span class="token class-name">SparkKafkaConsumer</span> <span class="token punctuation">{<!-- --></span>
 def <span class="token function">main</span><span class="token punctuation">(</span>args<span class="token operator">:</span> <span class="token class-name">Array</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token class-name">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
 <span class="token comment">//1.创建 SparkConf</span>
 val sparkConf<span class="token operator">:</span> <span class="token class-name">SparkConf</span> <span class="token operator">=</span> <span class="token keyword">new</span> 
<span class="token class-name">SparkConf</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAppName</span><span class="token punctuation">(</span><span class="token string">"sparkstreaming"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setMaster</span><span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span>
 <span class="token comment">//2.创建 StreamingContext</span>
 val ssc <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">StreamingContext</span><span class="token punctuation">(</span>sparkConf<span class="token punctuation">,</span> <span class="token class-name">Seconds</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token comment">//3.定义 Kafka 参数：kafka 集群地址、消费者组名称、key 序列化、value 序列化</span>
 val kafkaPara<span class="token operator">:</span> <span class="token class-name">Map</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token class-name">Map</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Object</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
 <span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span>BOOTSTRAP_SERVERS_CONFIG <span class="token operator">-&gt;</span> 
<span class="token string">"hadoop102:9092,hadoop103:9092,hadoop104:9092"</span><span class="token punctuation">,</span>
 <span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span>GROUP_ID_CONFIG <span class="token operator">-&gt;</span> <span class="token string">"atguiguGroup"</span><span class="token punctuation">,</span>
 <span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span>KEY_DESERIALIZER_CLASS_CONFIG <span class="token operator">-&gt;</span> 
classOf<span class="token punctuation">[</span><span class="token class-name">StringDeserializer</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
 <span class="token class-name">ConsumerConfig</span><span class="token punctuation">.</span>VALUE_DESERIALIZER_CLASS_CONFIG <span class="token operator">-&gt;</span> 
classOf<span class="token punctuation">[</span><span class="token class-name">StringDeserializer</span><span class="token punctuation">]</span>
 <span class="token punctuation">)</span>
 <span class="token comment">//4.读取 Kafka 数据创建 DStream</span>
 val kafkaDStream<span class="token operator">:</span> <span class="token class-name">InputDStream</span><span class="token punctuation">[</span><span class="token class-name">ConsumerRecord</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> 
<span class="token class-name">KafkaUtils</span><span class="token punctuation">.</span>createDirectStream<span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span>
 ssc<span class="token punctuation">,</span>
 <span class="token class-name">LocationStrategies<span class="token punctuation">.</span>PreferConsistent</span><span class="token punctuation">,</span> <span class="token comment">//优先位置</span>
 <span class="token class-name">ConsumerStrategies<span class="token punctuation">.</span>Subscribe</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><span class="token class-name">Set</span><span class="token punctuation">(</span><span class="token string">"first"</span><span class="token punctuation">)</span><span class="token punctuation">,</span> kafkaPara<span class="token punctuation">)</span><span class="token comment">// 消费策略：（订阅</span>
多个主题，配置参数）
 <span class="token punctuation">)</span>
 <span class="token comment">//5.将每条消息的 KV 取出</span>
 val valueDStream<span class="token operator">:</span> <span class="token class-name">DStream</span><span class="token punctuation">[</span><span class="token class-name">String</span><span class="token punctuation">]</span> <span class="token operator">=</span> kafkaDStream<span class="token punctuation">.</span><span class="token function">map</span><span class="token punctuation">(</span><span class="token keyword">record</span> <span class="token operator">=</span><span class="token operator">&gt;</span> <span class="token keyword">record</span><span class="token punctuation">.</span><span class="token function">value</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
 <span class="token comment">//6.计算 WordCount</span>
 valueDStream<span class="token punctuation">.</span><span class="token function">print</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token comment">//7.开启任务</span>
 ssc<span class="token punctuation">.</span><span class="token function">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 ssc<span class="token punctuation">.</span><span class="token function">awaitTermination</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
 <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>（3）启动 SparkKafkaConsumer 消费者<br> （4）启动 kafka 生产者</p> 
<pre><code class="prism language-java"><span class="token punctuation">[</span>atguigu<span class="token annotation punctuation">@hadoop103</span> kafka<span class="token punctuation">]</span>$ bin<span class="token operator">/</span>kafka<span class="token operator">-</span>console<span class="token operator">-</span>producer<span class="token punctuation">.</span>sh <span class="token operator">--</span>bootstrap<span class="token operator">-</span>server hadoop102<span class="token operator">:</span><span class="token number">9092</span> <span class="token operator">--</span>topic first
</code></pre> 
<p>（5）观察 IDEA 控制台数据打</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/4b27ce7af10d07ee22a70bea7790a3ce/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">蓝桥杯2019年Java C组真题，“人物相关性分析”</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/88834810295c1775d8d994efaf974340/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">socket原理以及socket的简单实现</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>