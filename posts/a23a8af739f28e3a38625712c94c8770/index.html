<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>有关Pytorch训练时Volatile Gpu-Util(GPU利用率)很低，而Memory-ueage(内存占比)很高的情况解释与说明 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="有关Pytorch训练时Volatile Gpu-Util(GPU利用率)很低，而Memory-ueage(内存占比)很高的情况解释与说明" />
<meta property="og:description" content="有关Pytorch训练时GPU利用率很低，而内存占比很高的情况 前言有关GPU的Memory-usage的占用（GPU内存占有率）有关Volatile GPU-Utile的利用率（GPU的利用率） 直接参考
前言 模型开始训练时候，常用watch -n 0.1 nvidia-smi来观察GPU的显存占比情况，如下图所示，通常GPU显存占比和GPU利用率都很高，但有的模型训练的时候GPU利用率（Volatile GPU-util）占比在不断的动态变化，从0-100%之间不断浮动循环。
如果发生上述这种GPU利用率不断变化情况，可以进一步通过命令行中输入Top指令来查询一下CPU的利用率，可以从中发现问题所在。
有关GPU的Memory-usage的占用（GPU内存占有率） GPU中Memory-usage最直接的影响因素是模型的大小和Batch size的大小。其中模型对GPU中Memory-usage因素包括网络的参数量（网络的深度，宽度等），而一般在训练时候模型结构都已经固定，很少再轻易的改动。因此，我们对Memory-usage的占用的影响主要调控在Batch size的大小，如batch size设置为12，Memory-usage为40%；与设置为24相比，Memory-usage内存占用率是80%，接近于2倍关系，偏差不大。所以在模型结构固定的情况下，尽量将batch size设置大，充分利用GPU的内存。（GPU会很快的算完你给进去的数据，而有关训练时间主要瓶颈在CPU的数据吞吐量上面。）
有关Volatile GPU-Utile的利用率（GPU的利用率） 这个是Volatile GPU-Util表示，当没有设置好CPU的线程数时，这个参数是在反复的跳动的，0%，20%，70%，95%，0%。这样停息1-2 秒然后又重复起来。其实是GPU在等待数据从CPU传输过来，当从总线传输到GPU之后，GPU逐渐起计算来，利用率会突然升高，但是GPU的算力很强大，0.5秒就基本能处理完数据，所以利用率接下来又会降下去，等待下一个batch的传入。因此，这个GPU利用率瓶颈在内存带宽和内存介质上以及CPU的性能上面。最好当然就是换更好的四代或者更强大的内存条，配合更好的CPU。
另外的一个方法是，在PyTorch这个框架里面，数据加载Dataloader上做更改和优化，包括num_workers（线程数），pin_memory=True，会提升速度。解决好数据传输的带宽瓶颈和GPU的运算效率低的问题。在TensorFlow下面，也有这个加载数据的设置
为了提高利用率，首先要将num_workers（线程数）设置得体，4,8,16是几个常选的几个参数。本人测试过，将num_workers设置的非常大，例如，24，32,等，其效率反而降低，因为模型需要将数据平均分配到几个子线程去进行预处理，分发等数据操作，设高了反而影响效率。当然，线程数设置为1，是单个CPU来进行数据的预处理和传输给GPU，效率也会低。其次，当你的服务器或者电脑的内存较大，性能较好的时候，建议打开pin_memory打开，就省掉了将数据从CPU传入到缓存RAM里面，再给传输到GPU上；为True时是直接映射到GPU的相关内存块上，省掉了一点数据传输时间。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/a23a8af739f28e3a38625712c94c8770/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-01-30T13:27:34+08:00" />
<meta property="article:modified_time" content="2022-01-30T13:27:34+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">有关Pytorch训练时Volatile Gpu-Util(GPU利用率)很低，而Memory-ueage(内存占比)很高的情况解释与说明</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-github-gist">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p></p> 
<div class="toc"> 
 <h4>有关Pytorch训练时GPU利用率很低，而内存占比很高的情况</h4> 
 <ul><li><a href="#_9" rel="nofollow">前言</a></li><li><a href="#GPUMemoryusageGPU_16" rel="nofollow">有关GPU的Memory-usage的占用（GPU内存占有率）</a></li><li><a href="#Volatile_GPUUtileGPU_20" rel="nofollow">有关Volatile GPU-Utile的利用率（GPU的利用率）</a></li></ul> 
</div> 
<p></p> 
<p><a href="https://blog.csdn.net/qq_32998593/article/details/92849585">直接参考</a></p> 
<h2><a id="_9"></a>前言</h2> 
<p>模型开始训练时候，常用<strong>watch -n 0.1 nvidia-smi</strong>来观察GPU的显存占比情况，如下图所示，通常GPU显存占比和GPU利用率都很高，但有的模型训练的时候GPU利用率（Volatile GPU-util）占比在不断的动态变化，从0-100%之间不断浮动循环。</p> 
<p>如果发生上述这种GPU利用率不断变化情况，可以进一步通过命令行中输入<strong>Top</strong>指令来查询一下CPU的利用率，可以从中发现问题所在。<br> <img src="https://images2.imgbox.com/69/e8/Z1wofRc8_o.png" alt="0"></p> 
<h2><a id="GPUMemoryusageGPU_16"></a>有关GPU的Memory-usage的占用（GPU内存占有率）</h2> 
<p>GPU中Memory-usage最直接的影响因素是<strong>模型的大小</strong>和<strong>Batch size</strong>的大小。其中模型对GPU中Memory-usage因素包括网络的参数量（网络的深度，宽度等），而一般在训练时候模型结构都已经固定，很少再轻易的改动。因此，我们对Memory-usage的占用的影响主要调控在<strong>Batch size</strong>的大小，如batch size设置为12，Memory-usage为40%；与设置为24相比，Memory-usage内存占用率是80%，接近于2倍关系，偏差不大。所以在模型结构固定的情况下，尽量将batch size设置大，充分利用GPU的内存。（GPU会很快的算完你给进去的数据，而有关训练时间主要瓶颈在CPU的数据吞吐量上面。）</p> 
<h2><a id="Volatile_GPUUtileGPU_20"></a>有关Volatile GPU-Utile的利用率（GPU的利用率）</h2> 
<p>这个是Volatile GPU-Util表示，当没有设置好CPU的线程数时，这个参数是在反复的跳动的，0%，20%，70%，95%，0%。这样停息1-2 秒然后又重复起来。其实是GPU在等待数据从CPU传输过来，当从总线传输到GPU之后，GPU逐渐起计算来，利用率会突然升高，但是GPU的算力很强大，0.5秒就基本能处理完数据，所以利用率接下来又会降下去，等待下一个batch的传入。因此，这个GPU利用率瓶颈在内存带宽和内存介质上以及CPU的性能上面。最好当然就是换更好的四代或者更强大的内存条，配合更好的CPU。</p> 
<p>另外的一个方法是，在PyTorch这个框架里面，数据加载Dataloader上做更改和优化，包括<strong>num_workers（线程数），pin_memory=True</strong>，会提升速度。解决好数据传输的带宽瓶颈和GPU的运算效率低的问题。在TensorFlow下面，也有这个加载数据的设置</p> 
<p>为了提高利用率，首先要将num_workers（线程数）设置得体，4,8,16是几个常选的几个参数。本人测试过，将num_workers设置的非常大，例如，24，32,等，其效率反而降低，因为模型需要将数据平均分配到几个子线程去进行预处理，分发等数据操作，设高了反而影响效率。当然，线程数设置为1，是单个CPU来进行数据的预处理和传输给GPU，效率也会低。其次，当你的服务器或者电脑的内存较大，性能较好的时候，建议打开pin_memory打开，就省掉了将数据从CPU传入到缓存RAM里面，再给传输到GPU上；为True时是直接映射到GPU的相关内存块上，省掉了一点数据传输时间。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/74218039a76029cb6d0dd952b6754111/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python如何安装numpy</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/f5e42a91d18b7f7a5c10f2aa592a00df/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">【python】可视化-柱状图</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>