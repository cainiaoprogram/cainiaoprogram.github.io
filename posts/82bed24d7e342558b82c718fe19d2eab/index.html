<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Small Object Detection using Context and Attention - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="Small Object Detection using Context and Attention" />
<meta property="og:description" content="Small Object Detection using Context and Attention阅读记录 论文链接：https://arxiv.org/abs/1912.06319v2
Abstract 作者使用上下文信息和注意力机制检测小目标。
作者使用传统的SSD为基线，当网络输入为300x300时，其在Pascal VOC2007上的mAP为78.1%。
Introduction 作者认为解决小目标检测的关键是如何有效的利用上下文信息。
作者使用深层的抽象信息作为上下文信息，在浅层使用注意力机制，使网络更加关注小目标。
Related Works 省略
Method 首先介绍传统的SSD模型，模型结构如下图，其在VOC2007数据集上的小目标跑分为0.207。
然后是使用上下文信息的SSD模型(F-SSD)，模型结构如下图，他在传统的SSD模型上添加特征融合的过程。
传统SSD与注意力机制结合成A-SSD模型，其结构如下：
其中的注意力模块的结构如下：
Residual block结构：
上下采样1、2阶段分别为：
作者最终的模型(FA-SSD)如下，主要是新增了特征融合和注意力模块：
Experiments 上表为作者的实验结果，特征融合会提升检测网络对各个尺寸的检测性能。增加注意力机制可以提升模型对小目标的检测。除此之外，作者还更换特征提取网络进行测试，结果如下。
Conclusion 省略" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/82bed24d7e342558b82c718fe19d2eab/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-09-11T17:03:24+08:00" />
<meta property="article:modified_time" content="2021-09-11T17:03:24+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Small Object Detection using Context and Attention</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Small_Object_Detection_using_Context_and_Attention_0"></a>Small Object Detection using Context and Attention阅读记录</h2> 
<p>论文链接：<a href="https://arxiv.org/abs/1912.06319v2" rel="nofollow">https://arxiv.org/abs/1912.06319v2</a></p> 
<h3><a id="Abstract_4"></a>Abstract</h3> 
<p>作者使用上下文信息和注意力机制检测小目标。</p> 
<p>作者使用传统的SSD为基线，当网络输入为300x300时，其在Pascal VOC2007上的mAP为78.1%。</p> 
<h3><a id="Introduction_10"></a>Introduction</h3> 
<p>作者认为解决小目标检测的关键是如何有效的利用上下文信息。</p> 
<p>作者使用深层的抽象信息作为上下文信息，在浅层使用注意力机制，使网络更加关注小目标。</p> 
<h3><a id="Related_Works_16"></a>Related Works</h3> 
<p>省略</p> 
<h3><a id="Method_19"></a>Method</h3> 
<p>首先介绍传统的SSD模型，模型结构如下图，其在VOC2007数据集上的小目标跑分为0.207。</p> 
<p><img src="https://images2.imgbox.com/66/84/w2XwtDuN_o.png" alt="在这里插入图片描述"><br> 然后是使用上下文信息的SSD模型(F-SSD)，模型结构如下图，他在传统的SSD模型上添加特征融合的过程。<br> <img src="https://images2.imgbox.com/a8/fa/dg4YVcUN_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/ce/8f/3EbyHEDf_o.png" alt="在这里插入图片描述"><br> 传统SSD与注意力机制结合成A-SSD模型，其结构如下：<br> <img src="https://images2.imgbox.com/28/73/aIx2Tl8F_o.png" alt="在这里插入图片描述"><br> 其中的注意力模块的结构如下：<br> <img src="https://images2.imgbox.com/b6/d8/VlMLFimq_o.png" alt="在这里插入图片描述"><br> Residual block结构：<br> <img src="https://images2.imgbox.com/05/f6/mVPJugBA_o.png" alt="在这里插入图片描述"><br> 上下采样1、2阶段分别为：</p> 
<p><img src="https://images2.imgbox.com/3e/17/ZPfXroDY_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/e2/33/ycwccPwr_o.png" alt="在这里插入图片描述"></p> 
<p>作者最终的模型(FA-SSD)如下，主要是新增了特征融合和注意力模块：<br> <img src="https://images2.imgbox.com/c9/b7/ra5lfl10_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Experiments_40"></a>Experiments</h3> 
<p><img src="https://images2.imgbox.com/8e/0f/ikcCmVQm_o.png" alt="在这里插入图片描述"><br> <img src="https://images2.imgbox.com/4f/ed/tGYF4F7l_o.png" alt="在这里插入图片描述"><br> 上表为作者的实验结果，特征融合会提升检测网络对各个尺寸的检测性能。增加注意力机制可以提升模型对小目标的检测。除此之外，作者还更换特征提取网络进行测试，结果如下。<br> <img src="https://images2.imgbox.com/84/b9/Q79Jz5Fe_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="Conclusion_47"></a>Conclusion</h3> 
<p>省略</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/30cb0a5891b5475a031bf0ff85095bd5/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">如何选购自己满意的主板（建议观看）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/21eabbac0b7dae85b97c40e6afa0814e/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">机器学习（11）线性回归（1）理论：损失函数(含最小二乘法)、正规方程、梯度下降、回归性能评估（均方差）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>