<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>pytorch torch.nn到底是什么？ - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="pytorch torch.nn到底是什么？" />
<meta property="og:description" content="PyTorch提供了模块和类torch.nn， torch.optim， Dataset和DataLoader 来创建和训练神经网络。例子使用MNIST数据集训练基本神经网络。
MNIST数据设置 使用经典的MNIST数据集，该数据集由手绘数字的黑白图像组成（0到9之间）。
下载数据集
from pathlib import Path import requests DATA_PATH = Path(&#34;data&#34;) PATH = DATA_PATH / &#34;mnist&#34; PATH.mkdir(parents=True, exist_ok=True) URL = &#34;https://github.com/pytorch/tutorials/raw/master/_static/&#34; FILENAME = &#34;mnist.pkl.gz&#34; if not (PATH / FILENAME).exists(): content = requests.get(URL &#43; FILENAME).content (PATH / FILENAME).open(&#34;wb&#34;).write(content) 读取数据
该数据集为numpy数组格式，并已使用pickle（一种用于序列化数据的python特定格式）存储。
import pickle import gzip with gzip.open((PATH / FILENAME).as_posix(), &#34;rb&#34;) as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=&#34;latin-1&#34;) x_train.shape # (50000, 784) 每个图像为28 x 28，存储为长度为784（= 28x28）的扁平行。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4a5e3958674b30cb8eab37a18c691bff/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2020-12-11T15:02:32+08:00" />
<meta property="article:modified_time" content="2020-12-11T15:02:32+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">pytorch torch.nn到底是什么？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>PyTorch提供了模块和类torch.nn， torch.optim， Dataset和DataLoader 来创建和训练神经网络。例子使用MNIST数据集训练基本神经网络。</p> 
<h4><a id="MNIST_1"></a>MNIST数据设置</h4> 
<p>使用经典的MNIST数据集，该数据集由手绘数字的黑白图像组成（0到9之间）。</p> 
<p><strong>下载数据集</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
<span class="token keyword">import</span> requests

DATA_PATH <span class="token operator">=</span> Path<span class="token punctuation">(</span><span class="token string">"data"</span><span class="token punctuation">)</span>
PATH <span class="token operator">=</span> DATA_PATH <span class="token operator">/</span> <span class="token string">"mnist"</span>

PATH<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span>parents<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

URL <span class="token operator">=</span> <span class="token string">"https://github.com/pytorch/tutorials/raw/master/_static/"</span>
FILENAME <span class="token operator">=</span> <span class="token string">"mnist.pkl.gz"</span>

<span class="token keyword">if</span> <span class="token operator">not</span> <span class="token punctuation">(</span>PATH <span class="token operator">/</span> FILENAME<span class="token punctuation">)</span><span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        content <span class="token operator">=</span> requests<span class="token punctuation">.</span>get<span class="token punctuation">(</span>URL <span class="token operator">+</span> FILENAME<span class="token punctuation">)</span><span class="token punctuation">.</span>content
        <span class="token punctuation">(</span>PATH <span class="token operator">/</span> FILENAME<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"wb"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
</code></pre> 
<p><strong>读取数据</strong></p> 
<p>该数据集为numpy数组格式，并已使用pickle（一种用于序列化数据的python特定格式）存储。</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> pickle
<span class="token keyword">import</span> gzip

<span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token punctuation">(</span>PATH <span class="token operator">/</span> FILENAME<span class="token punctuation">)</span><span class="token punctuation">.</span>as_posix<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"rb"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        <span class="token punctuation">(</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x_valid<span class="token punctuation">,</span> y_valid<span class="token punctuation">)</span><span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token operator">=</span> pickle<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"latin-1"</span><span class="token punctuation">)</span>
x_train<span class="token punctuation">.</span>shape
<span class="token comment"># (50000, 784)</span>
</code></pre> 
<p>每个图像为28 x 28，存储为长度为784（= 28x28）的扁平行。</p> 
<p><strong>显示图片</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

pyplot<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>x_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">"gray"</span><span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/38/0c/0wD8ALCu_o.png" alt="在这里插入图片描述"><br> <strong>转换数据格式</strong></p> 
<p>PyTorch使用torch.tensor</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> torch

x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_valid<span class="token punctuation">,</span> y_valid <span class="token operator">=</span> <span class="token builtin">map</span><span class="token punctuation">(</span>
    torch<span class="token punctuation">.</span>tensor<span class="token punctuation">,</span> <span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> x_valid<span class="token punctuation">,</span> y_valid<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
n<span class="token punctuation">,</span> c <span class="token operator">=</span> x_train<span class="token punctuation">.</span>shape
x_train<span class="token punctuation">,</span> x_train<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> y_train<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>x_train<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>y_train<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y_train<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_63"></a>从零开始的神经网络</h4> 
<p><strong>初始化权重</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> math

weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">)</span>
weights<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token punctuation">)</span>
bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre> 
<p><strong>定义模型</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">log_softmax</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x <span class="token operator">-</span> x<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>unsqueeze<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">model</span><span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> log_softmax<span class="token punctuation">(</span>xb @ weights <span class="token operator">+</span> bias<span class="token punctuation">)</span>
    
</code></pre> 
<p>@代表点积运算</p> 
<p><strong>预测数据</strong></p> 
<pre><code class="prism language-python"> bs <span class="token operator">=</span> <span class="token number">64</span>  <span class="token comment"># batch size</span>

xb <span class="token operator">=</span> x_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>bs<span class="token punctuation">]</span>  <span class="token comment"># a mini-batch from x</span>
preds <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>  <span class="token comment"># predictions</span>
preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> preds<span class="token punctuation">.</span>shape
<span class="token keyword">print</span><span class="token punctuation">(</span>preds<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> preds<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>
</code></pre> 
<p><strong>计算损失</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">nll</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">,</span> target<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token operator">-</span><span class="token builtin">input</span><span class="token punctuation">[</span><span class="token builtin">range</span><span class="token punctuation">(</span>target<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">]</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>

loss_func <span class="token operator">=</span> nll
</code></pre> 
<p>让我们用随机模型来检查损失，以便我们稍后看向后传播后是否可以改善</p> 
<pre><code class="prism language-python">yb <span class="token operator">=</span> y_train<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span>bs<span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(2.3088, grad_fn=&lt;NegBackward&gt;)</span>
</code></pre> 
<p><strong>计算准确率</strong></p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">accuracy</span><span class="token punctuation">(</span>out<span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">:</span>
    preds <span class="token operator">=</span> torch<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>out<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>preds <span class="token operator">==</span> yb<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>accuracy<span class="token punctuation">(</span>preds<span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># tensor(0.0781)</span>
</code></pre> 
<p>由于我们从随机权重开始，因此在这一阶段，我们的预测不会比随机预测更好。</p> 
<p><strong>训练循环</strong></p> 
<p>对于每次迭代，我们将：</p> 
<ul><li>选择一个小批量的数据（大小为bs）</li><li>使用模型进行预测</li><li>计算损失</li><li>loss.backward() 在这种情况下，将更新模型的渐变，weights 并bias。</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">from</span> IPython<span class="token punctuation">.</span>core<span class="token punctuation">.</span>debugger <span class="token keyword">import</span> set_trace

lr <span class="token operator">=</span> <span class="token number">0.5</span>  <span class="token comment"># learning rate</span>
epochs <span class="token operator">=</span> <span class="token number">2</span>  <span class="token comment"># how many epochs to train for</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> bs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#         set_trace()</span>
        start_i <span class="token operator">=</span> i <span class="token operator">*</span> bs
        end_i <span class="token operator">=</span> start_i <span class="token operator">+</span> bs
        xb <span class="token operator">=</span> x_train<span class="token punctuation">[</span>start_i<span class="token punctuation">:</span>end_i<span class="token punctuation">]</span>
        yb <span class="token operator">=</span> y_train<span class="token punctuation">[</span>start_i<span class="token punctuation">:</span>end_i<span class="token punctuation">]</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> yb<span class="token punctuation">)</span>

        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            weights <span class="token operator">-=</span> weights<span class="token punctuation">.</span>grad <span class="token operator">*</span> lr
            bias <span class="token operator">-=</span> bias<span class="token punctuation">.</span>grad <span class="token operator">*</span> lr
            weights<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
            bias<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>让我们检查损失和准确性，并将其与我们之前获得的进行比较。我们希望损失会减少，准确性会增加，而且确实如此。</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">,</span> accuracy<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>tensor(0.0817, grad_fn=) tensor(1.)</p> 
</blockquote> 
<h4><a id="nnModule_161"></a>使用nn.Module进行重构</h4> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">class</span> <span class="token class-name">Mnist_Logistic</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>weights <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span> <span class="token operator">/</span> math<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>bias <span class="token operator">=</span> nn<span class="token punctuation">.</span>Parameter<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> xb<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> xb @ self<span class="token punctuation">.</span>weights <span class="token operator">+</span> self<span class="token punctuation">.</span>bias
model <span class="token operator">=</span> Mnist_Logistic<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_func <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy
<span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<p>以前，在我们的训练循环中，必须按名称更新每个参数的值，并手动将每个参数的梯度分别归零。<br> 现在，我们可以利用model.parameters（）和model.zero_grad（）来使这些步骤更简洁。</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> bs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            start_i <span class="token operator">=</span> i <span class="token operator">*</span> bs
            end_i <span class="token operator">=</span> start_i <span class="token operator">+</span> bs
            xb <span class="token operator">=</span> x_train<span class="token punctuation">[</span>start_i<span class="token punctuation">:</span>end_i<span class="token punctuation">]</span>
            yb <span class="token operator">=</span> y_train<span class="token punctuation">[</span>start_i<span class="token punctuation">:</span>end_i<span class="token punctuation">]</span>
            pred <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> yb<span class="token punctuation">)</span>

            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                    p <span class="token operator">-=</span> p<span class="token punctuation">.</span>grad <span class="token operator">*</span> lr
                model<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

fit<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>让我们仔细检查一下我们的损失是否减少了：</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<blockquote> 
 <p>tensor(0.0827, grad_fn=&lt; NllLossBackward&gt;)</p> 
</blockquote> 
<h4><a id="nnLinear_205"></a>使用nn.Linear重构</h4> 
<p>使用Pytorch类nn.Linear作为线性层，而不是手动定义和初始化self.weights以及进行self.bias计算。<br> Pytorch还提供了一个包含各种优化算法的包torch.optim。我们可以使用step优化器中的方法优化，而不是手动更新每个参数。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Mnist_Logistic</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>lin <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> xb<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>lin<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">get_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    model <span class="token operator">=</span> Mnist_Logistic<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> model<span class="token punctuation">,</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>

model<span class="token punctuation">,</span> opt <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">//</span> bs <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        start_i <span class="token operator">=</span> i <span class="token operator">*</span> bs
        end_i <span class="token operator">=</span> start_i <span class="token operator">+</span> bs
        xb <span class="token operator">=</span> x_train<span class="token punctuation">[</span>start_i<span class="token punctuation">:</span>end_i<span class="token punctuation">]</span>
        yb <span class="token operator">=</span> y_train<span class="token punctuation">[</span>start_i<span class="token punctuation">:</span>end_i<span class="token punctuation">]</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> yb<span class="token punctuation">)</span>

        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h4><a id="DataLoader_239"></a>使用DataLoader进行重构</h4> 
<p>DataLoader会自动为我们提供每个小批量。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> TensorDataset
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader

train_ds <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
train_dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>bs<span class="token punctuation">)</span>
model<span class="token punctuation">,</span> opt <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> xb<span class="token punctuation">,</span> yb <span class="token keyword">in</span> train_dl<span class="token punctuation">:</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> yb<span class="token punctuation">)</span>

        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<h4><a id="_260"></a>添加验证</h4> 
<p>我们只是试图建立一个合理的训练循环以用于我们的训练数据。实际上，您始终还应该具有一个验证集，以识别是否过度拟合。</p> 
<pre><code class="prism language-python">train_ds <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
train_dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>bs<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

valid_ds <span class="token operator">=</span> TensorDataset<span class="token punctuation">(</span>x_valid<span class="token punctuation">,</span> y_valid<span class="token punctuation">)</span>
valid_dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>valid_ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>bs <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span>

model<span class="token punctuation">,</span> opt <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> xb<span class="token punctuation">,</span> yb <span class="token keyword">in</span> train_dl<span class="token punctuation">:</span>
        pred <span class="token operator">=</span> model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>pred<span class="token punctuation">,</span> yb<span class="token punctuation">)</span>

        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

    model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        valid_loss <span class="token operator">=</span> <span class="token builtin">sum</span><span class="token punctuation">(</span>loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span> <span class="token keyword">for</span> xb<span class="token punctuation">,</span> yb <span class="token keyword">in</span> valid_dl<span class="token punctuation">)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> valid_loss <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>valid_dl<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h4><a id="fitget_data_288"></a>创建fit（）和get_data（）</h4> 
<p>我们经历了两次相似的过程来计算训练集和验证集的损失。因此要设计自己的函数loss_batch来计算损失。<br> 我们将优化器传入训练集中，然后使用它执行反向传播。对于验证集，我们没有通过优化程序，因此该方法不会执行反向传播。<br> fit 来训练我们的模型，并计算每个时期的训练和验证损失<br> get_data 返回训练和验证集的数据加载器</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">loss_batch</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> xb<span class="token punctuation">,</span> yb<span class="token punctuation">,</span> opt<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    loss <span class="token operator">=</span> loss_func<span class="token punctuation">(</span>model<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">,</span> yb<span class="token punctuation">)</span>

    <span class="token keyword">if</span> opt <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
    
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token keyword">def</span> <span class="token function">fit</span><span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> xb<span class="token punctuation">,</span> yb <span class="token keyword">in</span> train_dl<span class="token punctuation">:</span>
            loss_batch<span class="token punctuation">(</span>model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> xb<span class="token punctuation">,</span> yb<span class="token punctuation">,</span> opt<span class="token punctuation">)</span>

        model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            losses<span class="token punctuation">,</span> nums <span class="token operator">=</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>
                <span class="token operator">*</span><span class="token punctuation">[</span>loss_batch<span class="token punctuation">(</span>model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> xb<span class="token punctuation">,</span> yb<span class="token punctuation">)</span> <span class="token keyword">for</span> xb<span class="token punctuation">,</span> yb <span class="token keyword">in</span> valid_dl<span class="token punctuation">]</span>
            <span class="token punctuation">)</span>
        val_loss <span class="token operator">=</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>multiply<span class="token punctuation">(</span>losses<span class="token punctuation">,</span> nums<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> np<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>nums<span class="token punctuation">)</span>

        <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> val_loss<span class="token punctuation">)</span>    
<span class="token keyword">def</span> <span class="token function">get_data</span><span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> valid_ds<span class="token punctuation">,</span> bs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>
        DataLoader<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>bs<span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        DataLoader<span class="token punctuation">(</span>valid_ds<span class="token punctuation">,</span> batch_size<span class="token operator">=</span>bs <span class="token operator">*</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    
<span class="token comment"># 现在，我们获取数据加载器和拟合模型的整个过程可以在3行代码中运行</span>

train_dl<span class="token punctuation">,</span> valid_dl <span class="token operator">=</span> get_data<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> valid_ds<span class="token punctuation">,</span> bs<span class="token punctuation">)</span>
model<span class="token punctuation">,</span> opt <span class="token operator">=</span> get_model<span class="token punctuation">(</span><span class="token punctuation">)</span>
fit<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="CNN_334"></a>CNN</h4> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Mnist_CNN</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conv3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> xb<span class="token punctuation">)</span><span class="token punctuation">:</span>
        xb <span class="token operator">=</span> xb<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
        xb <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">)</span>
        xb <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv2<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">)</span>
        xb <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>conv3<span class="token punctuation">(</span>xb<span class="token punctuation">)</span><span class="token punctuation">)</span>
        xb <span class="token operator">=</span> F<span class="token punctuation">.</span>avg_pool2d<span class="token punctuation">(</span>xb<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> xb<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> xb<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

lr <span class="token operator">=</span> <span class="token number">0.1</span>
model <span class="token operator">=</span> Mnist_CNN<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># Momentum  是随机梯度下降的一种变体，它也考虑了以前的更新，通常可以加快训练速度</span>
opt <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

fit<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="Sequential_358"></a>Sequential</h4> 
<p>torch.nn还有另一个方便的类，可以用来简化我们的代码： Sequential<br> Sequential对象以顺序的方式运行每个包含在其内的模块。</p> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">Lambda</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> func<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>func <span class="token operator">=</span> func

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>func<span class="token punctuation">(</span>x<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    Lambda<span class="token punctuation">(</span>preprocess<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>AvgPool2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

opt <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>

fit<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span>
</code></pre> 
<h4><a id="DataLoader_390"></a>包装DataLoader</h4> 
<p>我们的CNN非常简洁，但仅适用于MNIST，因为：<br> 假设输入为28 * 28长向量<br> 假设CNN的最终网格大小为4 * 4<br> 首先，我们可以删除初始的Lambda层，但将数据预处理移至生成器中：</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y


<span class="token keyword">class</span> <span class="token class-name">WrappedDataLoader</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dl<span class="token punctuation">,</span> func<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>dl <span class="token operator">=</span> dl
        self<span class="token punctuation">.</span>func <span class="token operator">=</span> func

    <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dl<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">__iter__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batches <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>dl<span class="token punctuation">)</span>
        <span class="token keyword">for</span> b <span class="token keyword">in</span> batches<span class="token punctuation">:</span>
            <span class="token keyword">yield</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>func<span class="token punctuation">(</span><span class="token operator">*</span>b<span class="token punctuation">)</span><span class="token punctuation">)</span>

train_dl<span class="token punctuation">,</span> valid_dl <span class="token operator">=</span> get_data<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> valid_ds<span class="token punctuation">,</span> bs<span class="token punctuation">)</span>
train_dl <span class="token operator">=</span> WrappedDataLoader<span class="token punctuation">(</span>train_dl<span class="token punctuation">,</span> preprocess<span class="token punctuation">)</span>
valid_dl <span class="token operator">=</span> WrappedDataLoader<span class="token punctuation">(</span>valid_dl<span class="token punctuation">,</span> preprocess<span class="token punctuation">)</span>
</code></pre> 
<p>替换nn.AvgPool2d为nn.AdaptiveAvgPool2d，这允许我们定义所需的输出张量的大小</p> 
<pre><code class="prism language-python">model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>AdaptiveAvgPool2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    Lambda<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

opt <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
fit<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span>

</code></pre> 
<h4><a id="GPU_434"></a>使用GPU</h4> 
<p>首先检查GPU是否在Pytorch中正常工作</p> 
<pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
<p>创建一个设备对象</p> 
<pre><code class="prism language-python">dev <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span>
    <span class="token string">"cuda"</span><span class="token punctuation">)</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cpu"</span><span class="token punctuation">)</span>
</code></pre> 
<p>将更新 preprocess 移至GPU</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">preprocess</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>dev<span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dev<span class="token punctuation">)</span>
train_dl<span class="token punctuation">,</span> valid_dl <span class="token operator">=</span> get_data<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> valid_ds<span class="token punctuation">,</span> bs<span class="token punctuation">)</span>
train_dl <span class="token operator">=</span> WrappedDataLoader<span class="token punctuation">(</span>train_dl<span class="token punctuation">,</span> preprocess<span class="token punctuation">)</span>
valid_dl <span class="token operator">=</span> WrappedDataLoader<span class="token punctuation">(</span>valid_dl<span class="token punctuation">,</span> preprocess<span class="token punctuation">)</span>
</code></pre> 
<p>最后，我们可以将模型移至GPU。</p> 
<pre><code class="prism language-python">model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>dev<span class="token punctuation">)</span>
opt <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>lr<span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
</code></pre> 
<p>是否运行的更快？</p> 
<pre><code class="prism language-python">fit<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_func<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> valid_dl<span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/8afe0d0aaae161d3d09f28cfdfc368cd/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">python爬虫获取数据失败请稍后访问_Python爬取拉勾网数据返回&#34;success&#34;:false,&#34;msg&#34;:您操作太频繁,请稍后再访问？...</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/525edebeb288566787cfbc7ca593296c/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">java中stringBuilder常用方法</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>