<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>深度学习 Day11——T11优化器对比实验 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="深度学习 Day11——T11优化器对比实验" />
<meta property="og:description" content="🍨 本文为🔗365天深度学习训练营 中的学习记录博客🍖 原作者：K同学啊 | 接辅导、项目定制 文章目录 前言一、我的环境二、代码实现与执行结果1.引入库2.设置GPU（如果使用的是CPU可以忽略这步）3.导入数据4.查看数据5.加载数据6.再次检查数据7.配置数据集8.可视化数据9.构建CNN网络模型10.编译模型11.训练模型12.模型评估 三、知识点详解1.加载预训练的 VGG16 模型2 优化器2.1 梯度下降法 (Gradient Descent)2.1.1 批量梯度下降法 (Batch Gradient Descent, BGD)2.1.2随机梯度下降（Stochastic Gradient Descent, SGD） 2.2 动量优化法（Momentum）2.3 自适应学习率优化算法2.2.1 AdaGrad（Adaptive Gradient）2.2.2 Adadelta2.2.3 RMSprop2.2.4 Adam（Adaptive Moment Estimation） 总结 前言 本文将采用CNN实现好莱坞明星识别，并用两种不同的优化器用于训练，并进行对比。简单讲述实现代码与执行结果，并浅谈涉及知识点。
关键字：加载预训练的 VGG16 模型，优化器。
一、我的环境 电脑系统：Windows 11语言环境：python 3.8.6编译器：pycharm2020.2.3深度学习环境：TensorFlow 2.10.1显卡：NVIDIA GeForce RTX 4070 二、代码实现与执行结果 1.引入库 from PIL import Image import numpy as np from pathlib import Path import tensorflow as tf from tensorflow.keras.layers import Dropout, Dense, BatchNormalization from tensorflow." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/ac28dfbfa3d8da2c48faed473993eaa2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-12-14T11:39:45+08:00" />
<meta property="article:modified_time" content="2023-12-14T11:39:45+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">深度学习 Day11——T11优化器对比实验</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <blockquote> 
 <ul><li><strong>🍨 本文为<a href="https://mp.weixin.qq.com/s/Nb93582M_5usednAKp_Jtw" rel="nofollow">🔗365天深度学习训练营</a> 中的学习记录博客</strong></li><li><strong>🍖 原作者：<a href="https://mtyjkh.blog.csdn.net/" rel="nofollow">K同学啊 | 接辅导、项目定制</a></strong></li></ul> 
</blockquote> 
<p></p> 
<div class="toc"> 
 <h4>文章目录</h4> 
 <ul><li><a href="#_8" rel="nofollow">前言</a></li><li><a href="#_13" rel="nofollow">一、我的环境</a></li><li><a href="#_20" rel="nofollow">二、代码实现与执行结果</a></li><li><ul><li><a href="#1_21" rel="nofollow">1.引入库</a></li><li><a href="#2GPUCPU_36" rel="nofollow">2.设置GPU（如果使用的是CPU可以忽略这步）</a></li><li><a href="#3_54" rel="nofollow">3.导入数据</a></li><li><a href="#4_61" rel="nofollow">4.查看数据</a></li><li><a href="#5_82" rel="nofollow">5.加载数据</a></li><li><a href="#6_118" rel="nofollow">6.再次检查数据</a></li><li><a href="#7_135" rel="nofollow">7.配置数据集</a></li><li><a href="#8_157" rel="nofollow">8.可视化数据</a></li><li><a href="#9CNN_176" rel="nofollow">9.构建CNN网络模型</a></li><li><a href="#10_269" rel="nofollow">10.编译模型</a></li><li><a href="#11_288" rel="nofollow">11.训练模型</a></li><li><a href="#12_322" rel="nofollow">12.模型评估</a></li></ul> 
  </li><li><a href="#_388" rel="nofollow">三、知识点详解</a></li><li><ul><li><a href="#1_VGG16__389" rel="nofollow">1.加载预训练的 VGG16 模型</a></li><li><a href="#2__439" rel="nofollow">2 优化器</a></li><li><ul><li><a href="#21__Gradient_Descent_442" rel="nofollow">2.1 梯度下降法 (Gradient Descent)</a></li><li><ul><li><a href="#211___Batch_Gradient_Descent_BGD_460" rel="nofollow">2.1.1 批量梯度下降法 (Batch Gradient Descent, BGD)</a></li><li><a href="#212Stochastic_Gradient_Descent_SGD_465" rel="nofollow">2.1.2随机梯度下降（Stochastic Gradient Descent, SGD）</a></li></ul> 
    </li><li><a href="#22_Momentum_482" rel="nofollow">2.2 动量优化法（Momentum）</a></li><li><a href="#23__498" rel="nofollow">2.3 自适应学习率优化算法</a></li><li><ul><li><a href="#221__AdaGradAdaptive_Gradient_508" rel="nofollow">2.2.1 AdaGrad（Adaptive Gradient）</a></li><li><a href="#222__Adadelta_519" rel="nofollow">2.2.2 Adadelta</a></li><li><a href="#223_RMSprop_528" rel="nofollow">2.2.3 RMSprop</a></li><li><a href="#224_AdamAdaptive_Moment_Estimation_541" rel="nofollow">2.2.4 Adam（Adaptive Moment Estimation）</a></li></ul> 
   </li></ul> 
  </li></ul> 
  </li><li><a href="#_588" rel="nofollow">总结</a></li></ul> 
</div> 
<p></p> 
<hr> 
<h2><a id="_8"></a>前言</h2> 
<p>本文将采用CNN实现好莱坞明星识别，并用两种不同的优化器用于训练，并进行对比。简单讲述实现代码与执行结果，并浅谈涉及知识点。<br> 关键字：加载预训练的 VGG16 模型，优化器。</p> 
<h2><a id="_13"></a>一、我的环境</h2> 
<ul><li>电脑系统：Windows 11</li><li>语言环境：python 3.8.6</li><li>编译器：pycharm2020.2.3</li><li>深度学习环境：TensorFlow 2.10.1</li><li>显卡：NVIDIA GeForce RTX 4070</li></ul> 
<h2><a id="_20"></a>二、代码实现与执行结果</h2> 
<h3><a id="1_21"></a>1.引入库</h3> 
<pre><code class="prism language-python"><span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> pathlib <span class="token keyword">import</span> Path
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dropout<span class="token punctuation">,</span> Dense<span class="token punctuation">,</span> BatchNormalization
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Model
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token comment"># 支持中文</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'font.sans-serif'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'SimHei'</span><span class="token punctuation">]</span>  <span class="token comment"># 用来正常显示中文标签</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'axes.unicode_minus'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># 用来正常显示负号</span>
<span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>  <span class="token comment"># 忽略一些warning内容，无需打印</span>
</code></pre> 
<h3><a id="2GPUCPU_36"></a>2.设置GPU（如果使用的是CPU可以忽略这步）</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-设置GPU（如果使用的是CPU可以忽略这步）'''</span>
<span class="token comment"># 检查GPU是否可用</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>test<span class="token punctuation">.</span>is_built_with_cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
gpus <span class="token operator">=</span> tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>list_physical_devices<span class="token punctuation">(</span><span class="token string">"GPU"</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>gpus<span class="token punctuation">)</span>
<span class="token keyword">if</span> gpus<span class="token punctuation">:</span>
    gpu0 <span class="token operator">=</span> gpus<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment"># 如果有多个GPU，仅使用第0个GPU</span>
    tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>experimental<span class="token punctuation">.</span>set_memory_growth<span class="token punctuation">(</span>gpu0<span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 设置GPU显存用量按需使用</span>
    tf<span class="token punctuation">.</span>config<span class="token punctuation">.</span>set_visible_devices<span class="token punctuation">(</span><span class="token punctuation">[</span>gpu0<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"GPU"</span><span class="token punctuation">)</span>
</code></pre> 
<p>执行结果</p> 
<pre><code>True
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
</code></pre> 
<h3><a id="3_54"></a>3.导入数据</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-导入数据'''</span>
data_dir <span class="token operator">=</span> <span class="token string">r"D:\DeepLearning\data\HollywoodStars"</span>
data_dir <span class="token operator">=</span> Path<span class="token punctuation">(</span>data_dir<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="4_61"></a>4.查看数据</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''前期工作-查看数据'''</span>
image_count <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">list</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'*/*.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"图片总数为："</span><span class="token punctuation">,</span> image_count<span class="token punctuation">)</span>
roses <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span>data_dir<span class="token punctuation">.</span>glob<span class="token punctuation">(</span><span class="token string">'Jennifer Lawrence/*.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>roses<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 查看图像实例的属性</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">,</span> image<span class="token punctuation">.</span>size<span class="token punctuation">,</span> image<span class="token punctuation">.</span>mode<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>执行结果：</p> 
<pre><code>图片总数为： 1800
JPEG (474, 569) RGB
</code></pre> 
<p><img src="https://images2.imgbox.com/b5/ce/PYmaCpsD_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="5_82"></a>5.加载数据</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''数据预处理-加载数据'''</span>
batch_size <span class="token operator">=</span> <span class="token number">16</span>
img_height <span class="token operator">=</span> <span class="token number">336</span>
img_width <span class="token operator">=</span> <span class="token number">336</span>
<span class="token triple-quoted-string string">"""
关于image_dataset_from_directory()的详细介绍可以参考文章：https://mtyjkh.blog.csdn.net/article/details/117018789
"""</span>
train_ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image_dataset_from_directory<span class="token punctuation">(</span>
    data_dir<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>
    subset<span class="token operator">=</span><span class="token string">"training"</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>img_height<span class="token punctuation">,</span> img_width<span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
val_ds <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>preprocessing<span class="token punctuation">.</span>image_dataset_from_directory<span class="token punctuation">(</span>
    data_dir<span class="token punctuation">,</span>
    validation_split<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>
    subset<span class="token operator">=</span><span class="token string">"validation"</span><span class="token punctuation">,</span>
    seed<span class="token operator">=</span><span class="token number">12</span><span class="token punctuation">,</span>
    image_size<span class="token operator">=</span><span class="token punctuation">(</span>img_height<span class="token punctuation">,</span> img_width<span class="token punctuation">)</span><span class="token punctuation">,</span>
    batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">)</span>
class_names <span class="token operator">=</span> train_ds<span class="token punctuation">.</span>class_names
<span class="token keyword">print</span><span class="token punctuation">(</span>class_names<span class="token punctuation">)</span>
</code></pre> 
<p>运行结果：</p> 
<pre><code class="prism language-html">Found 1800 files belonging to 17 classes.
Using 1440 files for training.
Found 1800 files belonging to 17 classes.
Using 360 files for validation.
['Angelina Jolie', 'Brad Pitt', 'Denzel Washington', 'Hugh Jackman', 'Jennifer Lawrence', 'Johnny Depp', 'Kate Winslet', 'Leonardo DiCaprio', 'Megan Fox', 'Natalie Portman', 'Nicole Kidman', 'Robert Downey Jr', 'Sandra Bullock', 'Scarlett Johansson', 'Tom Cruise', 'Tom Hanks', 'Will Smith']

</code></pre> 
<h3><a id="6_118"></a>6.再次检查数据</h3> 
<pre><code class="prism language-python{.line-numbers}">'''数据预处理-再次检查数据'''
# Image_batch是形状的张量(16, 336, 336, 3)。这是一批形状336x336x3的16张图片（最后一维指的是彩色通道RGB）。
# Label_batch是形状（16，）的张量，这些标签对应16张图片
for image_batch, labels_batch in train_ds:
    print(image_batch.shape)
    print(labels_batch.shape)
    break
</code></pre> 
<p>运行结果</p> 
<pre><code>(16, 336, 336, 3)
(16,)
</code></pre> 
<h3><a id="7_135"></a>7.配置数据集</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''数据预处理-配置数据集'''</span>
AUTOTUNE <span class="token operator">=</span> tf<span class="token punctuation">.</span>data<span class="token punctuation">.</span>AUTOTUNE
<span class="token keyword">def</span> <span class="token function">train_preprocessing</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span> label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>image <span class="token operator">/</span> <span class="token number">255.0</span><span class="token punctuation">,</span> label<span class="token punctuation">)</span>
train_ds <span class="token operator">=</span> <span class="token punctuation">(</span>
    train_ds<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>train_preprocessing<span class="token punctuation">)</span>  <span class="token comment"># 这里可以设置预处理函数</span>
        <span class="token comment"># .batch(batch_size)           # 在image_dataset_from_directory处已经设置了batch_size</span>
        <span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>AUTOTUNE<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
val_ds <span class="token operator">=</span> <span class="token punctuation">(</span>
    val_ds<span class="token punctuation">.</span>cache<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span>
        <span class="token punctuation">.</span><span class="token builtin">map</span><span class="token punctuation">(</span>train_preprocessing<span class="token punctuation">)</span>  <span class="token comment"># 这里可以设置预处理函数</span>
        <span class="token comment"># .batch(batch_size)         # 在image_dataset_from_directory处已经设置了batch_size</span>
        <span class="token punctuation">.</span>prefetch<span class="token punctuation">(</span>buffer_size<span class="token operator">=</span>AUTOTUNE<span class="token punctuation">)</span>
<span class="token punctuation">)</span>
</code></pre> 
<h3><a id="8_157"></a>8.可视化数据</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''数据预处理-可视化数据'''</span>
plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 图形的宽为10高为5</span>
plt<span class="token punctuation">.</span>suptitle<span class="token punctuation">(</span><span class="token string">"数据展示"</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> images<span class="token punctuation">,</span> labels <span class="token keyword">in</span> train_ds<span class="token punctuation">.</span>take<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>xticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>yticks<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        plt<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>

        <span class="token comment"># 显示图片</span>
        plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>images<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># 显示标签</span>
        plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span>class_names<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>labels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>fontdict<span class="token operator">=</span><span class="token punctuation">{<!-- --></span><span class="token string">'family'</span> <span class="token punctuation">:</span> <span class="token string">'Times New Roman'</span><span class="token punctuation">,</span> <span class="token string">'size'</span><span class="token punctuation">:</span><span class="token number">20</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p><img src="https://images2.imgbox.com/ef/e4/B2LFNfWF_o.png" alt="在这里插入图片描述"></p> 
<h3><a id="9CNN_176"></a>9.构建CNN网络模型</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''构建CNN网络'''</span>
<span class="token keyword">def</span> <span class="token function">create_model</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 加载预训练模型</span>
    vgg16_base_model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>applications<span class="token punctuation">.</span>vgg16<span class="token punctuation">.</span>VGG16<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">'imagenet'</span><span class="token punctuation">,</span>
                                                         include_top<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                                         input_shape<span class="token operator">=</span><span class="token punctuation">(</span>img_width<span class="token punctuation">,</span> img_height<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                         pooling<span class="token operator">=</span><span class="token string">'avg'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> layer <span class="token keyword">in</span> vgg16_base_model<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
        layer<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>

    X <span class="token operator">=</span> vgg16_base_model<span class="token punctuation">.</span>output

    X <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">170</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    output <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>class_names<span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    vgg16_model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>vgg16_base_model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>output<span class="token punctuation">)</span>

    vgg16_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
                        loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>
                        metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> vgg16_model
model1 <span class="token operator">=</span> create_model<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2 <span class="token operator">=</span> create_model<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>网络结构结果如下：</p> 
<pre><code>Model: "model_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_2 (InputLayer)        [(None, 336, 336, 3)]     0         
                                                                 
 block1_conv1 (Conv2D)       (None, 336, 336, 64)      1792      
                                                                 
 block1_conv2 (Conv2D)       (None, 336, 336, 64)      36928     
                                                                 
 block1_pool (MaxPooling2D)  (None, 168, 168, 64)      0         
                                                                 
 block2_conv1 (Conv2D)       (None, 168, 168, 128)     73856     
                                                                 
 block2_conv2 (Conv2D)       (None, 168, 168, 128)     147584    
                                                                 
 block2_pool (MaxPooling2D)  (None, 84, 84, 128)       0         
                                                                 
 block3_conv1 (Conv2D)       (None, 84, 84, 256)       295168    
                                                                 
 block3_conv2 (Conv2D)       (None, 84, 84, 256)       590080    
                                                                 
 block3_conv3 (Conv2D)       (None, 84, 84, 256)       590080    
                                                                 
 block3_pool (MaxPooling2D)  (None, 42, 42, 256)       0         
                                                                 
 block4_conv1 (Conv2D)       (None, 42, 42, 512)       1180160   
                                                                 
 block4_conv2 (Conv2D)       (None, 42, 42, 512)       2359808   
                                                                 
 block4_conv3 (Conv2D)       (None, 42, 42, 512)       2359808   
                                                                 
 block4_pool (MaxPooling2D)  (None, 21, 21, 512)       0         
                                                                 
 block5_conv1 (Conv2D)       (None, 21, 21, 512)       2359808   
                                                                 
 block5_conv2 (Conv2D)       (None, 21, 21, 512)       2359808   
                                                                 
 block5_conv3 (Conv2D)       (None, 21, 21, 512)       2359808   
                                                                 
 block5_pool (MaxPooling2D)  (None, 10, 10, 512)       0         
                                                                 
 global_average_pooling2d_1   (None, 512)              0         
 (GlobalAveragePooling2D)                                        
                                                                 
 dense_2 (Dense)             (None, 170)               87210     
                                                                 
 batch_normalization_1 (Batc  (None, 170)              680       
 hNormalization)                                                 
                                                                 
 dropout_1 (Dropout)         (None, 170)               0         
                                                                 
 dense_3 (Dense)             (None, 17)                2907      
                                                                 
=================================================================
Total params: 14,805,485
Trainable params: 90,457
Non-trainable params: 14,715,028
_________________________________________________________________
</code></pre> 
<h3><a id="10_269"></a>10.编译模型</h3> 
<pre><code class="prism language-python"><span class="token comment"># 设置初始学习率</span>
initial_learning_rate <span class="token operator">=</span> <span class="token number">1e-4</span>

lr_schedule <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>schedules<span class="token punctuation">.</span>ExponentialDecay<span class="token punctuation">(</span>
        initial_learning_rate<span class="token punctuation">,</span>
        decay_steps<span class="token operator">=</span><span class="token number">60</span><span class="token punctuation">,</span>      <span class="token comment"># 敲黑板！！！这里是指 steps，不是指epochs</span>
        decay_rate<span class="token operator">=</span><span class="token number">0.96</span><span class="token punctuation">,</span>     <span class="token comment"># lr经过一次衰减就会变成 decay_rate*lr</span>
        staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 将指数衰减学习率送入优化器</span>
optimizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span>lr_schedule<span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
              loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>CategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

</code></pre> 
<h3><a id="11_288"></a>11.训练模型</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''训练模型'''</span>
NO_EPOCHS <span class="token operator">=</span> <span class="token number">50</span>

history_model1 <span class="token operator">=</span> model1<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> epochs<span class="token operator">=</span>NO_EPOCHS<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span>val_ds<span class="token punctuation">)</span>
history_model2 <span class="token operator">=</span> model2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>train_ds<span class="token punctuation">,</span> epochs<span class="token operator">=</span>NO_EPOCHS<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> validation_data<span class="token operator">=</span>val_ds<span class="token punctuation">)</span>

</code></pre> 
<p>训练记录如下：</p> 
<pre><code>Epoch 1/50
90/90 [==============================] - 13s 99ms/step - loss: 2.7601 - accuracy: 0.1764 - val_loss: 2.7506 - val_accuracy: 0.1250
Epoch 2/50
90/90 [==============================] - 8s 86ms/step - loss: 2.0679 - accuracy: 0.3285 - val_loss: 2.4926 - val_accuracy: 0.2111
Epoch 3/50
90/90 [==============================] - 8s 86ms/step - loss: 1.7437 - accuracy: 0.4410 - val_loss: 2.2004 - val_accuracy: 0.3639
......
Epoch 49/50
90/90 [==============================] - 8s 86ms/step - loss: 0.1929 - accuracy: 0.9354 - val_loss: 2.8650 - val_accuracy: 0.4972
Epoch 50/50
90/90 [==============================] - 8s 86ms/step - loss: 0.1694 - accuracy: 0.9458 - val_loss: 2.7593 - val_accuracy: 0.4694
Epoch 1/50
90/90 [==============================] - 8s 87ms/step - loss: 3.0367 - accuracy: 0.1090 - val_loss: 2.7868 - val_accuracy: 0.1250
Epoch 2/50
90/90 [==============================] - 8s 86ms/step - loss: 2.5409 - accuracy: 0.1979 - val_loss: 2.6385 - val_accuracy: 0.1056
Epoch 3/50
90/90 [==============================] - 8s 86ms/step - loss: 2.2875 - accuracy: 0.2847 - val_loss: 2.4560 - val_accuracy: 0.2167
......


</code></pre> 
<h3><a id="12_322"></a>12.模型评估</h3> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">'''模型评估'''</span>
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>ticker <span class="token keyword">import</span> MultipleLocator

plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'savefig.dpi'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">300</span>  <span class="token comment"># 图片像素</span>
plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.dpi'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">300</span>  <span class="token comment"># 分辨率</span>

acc1 <span class="token operator">=</span> history_model1<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
acc2 <span class="token operator">=</span> history_model2<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span>
val_acc1 <span class="token operator">=</span> history_model1<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_accuracy'</span><span class="token punctuation">]</span>
val_acc2 <span class="token operator">=</span> history_model2<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_accuracy'</span><span class="token punctuation">]</span>

loss1 <span class="token operator">=</span> history_model1<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>
loss2 <span class="token operator">=</span> history_model2<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span>
val_loss1 <span class="token operator">=</span> history_model1<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span>
val_loss2 <span class="token operator">=</span> history_model2<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span>

epochs_range <span class="token operator">=</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>acc1<span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> acc1<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy-Adam'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> acc2<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Accuracy-SGD'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> val_acc1<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Accuracy-Adam'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> val_acc2<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Accuracy-SGD'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'lower right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Accuracy'</span><span class="token punctuation">)</span>
<span class="token comment"># 设置刻度间隔，x轴每1一个刻度</span>
ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>MultipleLocator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>subplot<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> loss1<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss-Adam'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> loss2<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Training Loss-SGD'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> val_loss1<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Loss-Adam'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>epochs_range<span class="token punctuation">,</span> val_loss2<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'Validation Loss-SGD'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">'upper right'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Training and Validation Loss'</span><span class="token punctuation">)</span>

<span class="token comment"># 设置刻度间隔，x轴每1一个刻度</span>
ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>
ax<span class="token punctuation">.</span>xaxis<span class="token punctuation">.</span>set_major_locator<span class="token punctuation">(</span>MultipleLocator<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">test_accuracy_report</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span><span class="token punctuation">:</span>
    score <span class="token operator">=</span> model<span class="token punctuation">.</span>evaluate<span class="token punctuation">(</span>val_ds<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Loss function: %s, accuracy:'</span> <span class="token operator">%</span> score<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> score<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


test_accuracy_report<span class="token punctuation">(</span>model1<span class="token punctuation">)</span>
test_accuracy_report<span class="token punctuation">(</span>model2<span class="token punctuation">)</span>

</code></pre> 
<p><img src="https://images2.imgbox.com/d3/10/7JhUjmPv_o.png" alt="在这里插入图片描述"></p> 
<p>Loss function: 2.759303092956543, accuracy: 0.4694444537162781<br> Loss function: 1.3968818187713623, accuracy: 0.5805555582046509</p> 
<h2><a id="_388"></a>三、知识点详解</h2> 
<h3><a id="1_VGG16__389"></a>1.加载预训练的 VGG16 模型</h3> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">create_model</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span><span class="token string">'adam'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 加载预训练模型</span>
    vgg16_base_model <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>applications<span class="token punctuation">.</span>vgg16<span class="token punctuation">.</span>VGG16<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">'imagenet'</span><span class="token punctuation">,</span>
                                                         include_top<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                                                         input_shape<span class="token operator">=</span><span class="token punctuation">(</span>img_width<span class="token punctuation">,</span> img_height<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                                         pooling<span class="token operator">=</span><span class="token string">'avg'</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> layer <span class="token keyword">in</span> vgg16_base_model<span class="token punctuation">.</span>layers<span class="token punctuation">:</span>
        layer<span class="token punctuation">.</span>trainable <span class="token operator">=</span> <span class="token boolean">False</span>

    X <span class="token operator">=</span> vgg16_base_model<span class="token punctuation">.</span>output

    X <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token number">170</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'relu'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> BatchNormalization<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    X <span class="token operator">=</span> Dropout<span class="token punctuation">(</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>

    output <span class="token operator">=</span> Dense<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>class_names<span class="token punctuation">)</span><span class="token punctuation">,</span> activation<span class="token operator">=</span><span class="token string">'softmax'</span><span class="token punctuation">)</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    vgg16_model <span class="token operator">=</span> Model<span class="token punctuation">(</span>inputs<span class="token operator">=</span>vgg16_base_model<span class="token punctuation">.</span><span class="token builtin">input</span><span class="token punctuation">,</span> outputs<span class="token operator">=</span>output<span class="token punctuation">)</span>

    vgg16_model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>optimizer<span class="token punctuation">,</span>
                        loss<span class="token operator">=</span><span class="token string">'sparse_categorical_crossentropy'</span><span class="token punctuation">,</span>
                        metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> vgg16_model


model1 <span class="token operator">=</span> create_model<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2 <span class="token operator">=</span> create_model<span class="token punctuation">(</span>optimizer<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model2<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<p>定义了一个名为 create_model 的函数，该函数接受一个参数 optimizer（默认为 ‘adam’）。函数内部首先使用 tf.keras.applications.vgg16.VGG16 加载了预训练的 VGG16 模型，其中 weights = ‘imagenet’ 表示使用 ImageNet 数据集的预训练权重，include_top = False 表示不包含顶层的全连接层，input_shape 设置输入图像的形状，pooling = ‘avg’ 表示使用平均池化。</p> 
<p>然后，对 VGG16 模型的所有层进行循环遍历，将每一层的 trainable 属性设置为 False，即冻结预训练参数，使它们在训练过程中保持不变。</p> 
<p>接下来，将 VGG16 模型的输出作为输入，并经过一系列的神经网络层进行特征提取和分类。首先是全连接层 Dense(170, activation = ‘relu’)，然后是批归一化层 BatchNormalization()，最后是丢弃层 Dropout(0.5)，用于防止过拟合。</p> 
<p>最后一层是输出层 Dense(len(class_names), activation = ‘softmax’)，其中 len(class_names) 是类别的数量，根据具体情况进行设置，激活函数使用 softmax。</p> 
<p>接下来，使用 Model 函数创建了一个新的模型 vgg16_model，指定了输入和输出。这里的 vgg16_base_model.input 表示 VGG16 模型的输入，output 表示上述神经网络层的输出。</p> 
<p>然后，使用 compile 方法编译了模型，指定了优化器、损失函数和评估指标。优化器根据传入的参数进行选择，如果没有指定，默认为 Adam 优化器。损失函数使用稀疏分类交叉熵，评估指标为准确率。</p> 
<p>最后，函数返回创建的模型。</p> 
<p>接下来，通过调用 create_model 函数分别创建了两个模型 model1 和 model2，分别使用了 Adam 优化器和 SGD 优化器。最后调用 model2.summary() 打印了 model2 的模型摘要信息。</p> 
<p>参考链接：<a href="https://blog.csdn.net/qq_45735298/article/details/131353054">深度学习-第T11周——优化器对比实验</a></p> 
<h3><a id="2__439"></a>2 优化器</h3> 
<p>优化器是一种算法，它在模型优化过程中，动态地调整梯度的大小和方向，使模型能够收敛到更好的位置，或者用更快的速度进行收敛。</p> 
<h4><a id="21__Gradient_Descent_442"></a>2.1 梯度下降法 (Gradient Descent)</h4> 
<p>我们可以把模型的参数空间想象成是一个曲面，曲面的高度是整体上模型预测值与真实值的误差。我们的目的就是找到整个曲面的最低点，这样我们其实就找到了模型参数的最优点。梯度下降法是最基本的优化算法之一，它让参数朝着梯度下降最大的方向去变化。</p> 
<p>假设模型参数为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         θ 
        
       
      
        \theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>，损失函数为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        J(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span> ，损失函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        J(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span> 关于参数 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         θ 
        
       
      
        \theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span> 的偏导数，也就是梯度为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ∇ 
         
        
          t 
         
        
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        \nabla_tJ(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span> ，学习率为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
      
        \alpha 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span></span></span></span></span> ，则使用梯度下降法更新参数的公式为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           θ 
          
          
          
            t 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
         
         
           θ 
          
         
           t 
          
         
        
          − 
         
        
          α 
         
        
          ⋅ 
         
         
         
           ∇ 
          
         
           t 
          
         
        
          J 
         
        
          ( 
         
        
          θ 
         
        
          ) 
         
        
       
         \theta_{t+1}=\theta_t-\alpha\cdot\nabla_tJ(\theta) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.4445em;"></span><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span></span></p> 
<p>梯度下降算法中，沿着梯度的方向不断减小模型参数，从而最小化损失函数。基本策略可以理解为”在你目光所及的范围内，不断寻找最陡最快的路径下山“</p> 
<img src="https://images2.imgbox.com/29/a9/rEYd1THK_o.png" width="70%"> 
<blockquote> 
 <p><strong>算法缺点：</strong></p> 
 <ul><li>训练速度慢：每走一步都要计算调整下一步的方向，下山的速度变慢。在应用于大型数据集中，每输入一个样本都要更新一次参数，且每次迭代都要遍历所有的样本。会使得训练过程及其缓慢，需要花费很长时间才能得到收敛解。</li><li>容易陷入局部最优解：由于是在有限视距内寻找下山的方向。当陷入平坦的洼地，会误以为到达了山地的最低点，从而不会继续往下走。</li></ul> 
</blockquote> 
<p>真正在使用时，主要是经过改进的以下三类方法，区别在于<strong>每次参数更新时计算的样本数据量不同</strong>：</p> 
<ul><li>批量梯度下降法(BGD, Batch Gradient Descent)</li><li>随机梯度下降法(SGD, Stochastic Gradient Descent)</li><li>小批量梯度下降法(Mini-batch Gradient Descent)</li></ul> 
<h5><a id="211___Batch_Gradient_Descent_BGD_460"></a>2.1.1 批量梯度下降法 (Batch Gradient Descent, BGD)</h5> 
<p>  第一种很天然的想法是批量梯度下降法BGD(Batch Gradient Descent)，其实就是每次用全量的数据对参数进行梯度下降。<br> 假设训练样本总数为n，样本为 {(x1,y1), … (xn, yn)} ，模型参数为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         θ 
        
       
      
        \theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span>，损失函数为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        J(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span> ，损失函数<span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        J(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span> 关于参数 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         θ 
        
       
      
        \theta 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.6944em;"></span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span></span></span></span></span> 的偏导数，也就是梯度为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
        
        
          ∇ 
         
        
          t 
         
        
       
         J 
        
       
         ( 
        
       
         θ 
        
       
         ) 
        
       
      
        \nabla_tJ(\theta) 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mclose">)</span></span></span></span></span> ，学习率为 <span class="katex--inline"><span class="katex"><span class="katex-mathml"> 
     
      
       
       
         α 
        
       
      
        \alpha 
       
      
    </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.4306em;"></span><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span></span></span></span></span> ，则使用BGD更新参数为：<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           θ 
          
          
          
            t 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
         
         
           θ 
          
         
           t 
          
         
        
          − 
         
         
         
           α 
          
         
           t 
          
         
        
          ⋅ 
         
         
         
           ∑ 
          
          
          
            i 
           
          
            = 
           
          
            1 
           
          
         
           n 
          
         
         
         
           ∇ 
          
         
           t 
          
         
         
         
           J 
          
         
           i 
          
         
        
          ( 
         
        
          θ 
         
        
          , 
         
         
         
           x 
          
         
           i 
          
         
        
          , 
         
         
         
           y 
          
         
           i 
          
         
        
          ) 
         
        
       
         \theta_{t+1}=\theta_t-\alpha_t\cdot\sum_{i=1}^n\nabla_tJ_i(\theta,x^i,y^i) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.5945em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0037em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 2.9291em; vertical-align: -1.2777em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 1.6514em;"><span class="" style="top: -1.8723em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span class="" style="top: -3.05em;"><span class="pstrut" style="height: 3.05em;"></span><span class=""><span class="mop op-symbol large-op">∑</span></span></span><span class="" style="top: -4.3em; margin-left: 0em;"><span class="pstrut" style="height: 3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 1.2777em;"><span class=""></span></span></span></span></span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0962em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8747em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8747em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> 由上式可以看出，每进行一次参数更新，需要计算整个数据样本集，因此导致批量梯度下降法的速度会比较慢，尤其是数据集非常大的情况下，收敛速度就会非常慢，但是由于每次的下降方向为总体平均梯度，它可能得到的会是一个全局最优解。</p> 
<h5><a id="212Stochastic_Gradient_Descent_SGD_465"></a>2.1.2随机梯度下降（Stochastic Gradient Descent, SGD）</h5> 
<p>随机梯度下降法，不像BGD每一次参数更新，需要计算整个数据样本集的梯度，而是每次参数更新时，仅仅选取一个样本(xi, yi)计算其梯度，参数更新公式为<br> <span class="katex--display"><span class="katex-display"><span class="katex"><span class="katex-mathml"> 
      
       
        
         
         
           θ 
          
          
          
            t 
           
          
            + 
           
          
            1 
           
          
         
        
          = 
         
         
         
           θ 
          
         
           t 
          
         
        
          − 
         
        
          α 
         
        
          ⋅ 
         
         
         
           ∇ 
          
         
           t 
          
         
         
         
           J 
          
         
           i 
          
         
        
          ( 
         
        
          θ 
         
        
          , 
         
         
         
           x 
          
         
           i 
          
         
        
          , 
         
         
         
           y 
          
         
           i 
          
         
        
          ) 
         
        
       
         \theta_{t+1}=\theta_t-\alpha\cdot\nabla_tJ_i(\theta,x^i,y^i) 
        
       
     </span><span class="katex-html"><span class="base"><span class="strut" style="height: 0.9028em; vertical-align: -0.2083em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3011em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.2083em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2778em;"></span></span><span class="base"><span class="strut" style="height: 0.8444em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: -0.0278em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 0.4445em;"></span><span class="mord mathnormal" style="margin-right: 0.0037em;">α</span><span class="mspace" style="margin-right: 0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right: 0.2222em;"></span></span><span class="base"><span class="strut" style="height: 1.1247em; vertical-align: -0.25em;"></span><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.2806em;"><span class="" style="top: -2.55em; margin-left: 0em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0962em;">J</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.3117em;"><span class="" style="top: -2.55em; margin-left: -0.0962em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right: 0.0278em;">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8747em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.0359em;">y</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8747em;"><span class="" style="top: -3.113em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></span><br> SGD训练速度很快，即使在样本量很大的情况下，可能只需要其中一部分样本就能迭代到最优解，由于每次迭代并不是都向着整体最优化方向，导致梯度下降的波动非常大（如下图），更容易从一个局部最优跳到另一个局部最优，准确度下降。</p> 
<img src="https://images2.imgbox.com/1f/9a/zBXTTgfK_o.png" width="50%"> 
<blockquote> 
 <p><strong>优点</strong>：</p> 
 <ul><li>由于每次迭代只使用了一个样本计算梯度，训练速度快，包含一定随机性，但是从期望来看，每次计算的梯度基本是正确的导数的。虽然看起来SGD波动非常大，会走很多弯路，但是对梯度的要求很低（计算梯度快），而且对于引入噪声，大量的理论和实践工作证明，只要噪声不是特别大，SGD都能很好地收敛。</li><li>应用大型数据集时，训练速度很快。比如每次从百万数据样本中，取几百个数据点，算一个SGD梯度，更新一下模型参数。相比于标准梯度下降法的遍历全部样本，每输入一个样本更新一次参数，要快得多<br> <strong>缺点：</strong></li><li>更新频繁，带有随机性，会造成损失函数在收敛过程中严重震荡。SGD没能单独克服局部最优解的问题（主要）</li><li>SGD在随机选择梯度的同时会引入噪声，使得权值更新的方向不一定正确（次要）</li></ul> 
</blockquote> 
<h4><a id="22_Momentum_482"></a>2.2 动量优化法（Momentum）</h4> 
<p><strong>关于动量</strong><br> 动量优化法引入了物理之中的概念。动量 p=mvp=mvp=mv，当一个小球从山顶滚下，速度越来越快，动量越来越大，开始加速梯度下降，当跨越了山谷，滚到对面的坡上时，速度减小，动量减小。</p> 
<p>带动量的小球不仅可以加速梯度；还可以借着积累的动量，冲过小的山坡，以避免落入局部最优点。</p> 
<p><strong>动量优化法（Momentum）提出的原因</strong><br> 梯度下降法容易被困在局部最小的沟壑处来回震荡，可能存在曲面的另一个方向有更小的值；有时候梯度下降法收敛速度还是很慢。动量法就是为了解决这两个问题提出的</p> 
<p><strong>动量优化法思想</strong><br> 参数更新时在一定程度上保留之前更新的方向，同时又利用当前batch的梯度微调最终的更新方向，简言之就是通过积累之前的动量来 (previous_sum_of_gradient) 加速当前的梯度。</p> 
<blockquote> 
 <p><strong>优缺点分析</strong></p> 
 <ul><li>优点：前后梯度一致的时候能够加速学习；前后梯度不一致的时候能够抑制震荡，越过局部极小值（加速收敛，减小震荡）</li><li>缺点：多了一个超参数，增加了计算量</li></ul> 
</blockquote> 
<h4><a id="23__498"></a>2.3 自适应学习率优化算法</h4> 
<p>传统的优化算法要么将学习率设置为常数要么根据训练次数调节学习率。往往忽视了学习率其他变化的可能性。学习率对模型的性能有着显著的影响，需要采取一些策略来更新学习率，进而提高训练速度与准确率。</p> 
<blockquote> 
 <p><strong>使用统一的全局学习率的缺点可能出现的问题</strong></p> 
 <ul><li>对于某些参数，通过算法已经优化到了极小值附近，但是有的参数仍然有着很大的梯度。</li><li>如果学习率太小，则梯度很大的参数会有一个很慢的收敛速度； 如果学习率太大，则已经优化得差不多的参数可能会出现不稳定的情况。</li></ul> 
 <p>解决方案：对每个参与训练的参数设置不同的学习率，在整个学习过程中通过一些算法自动适应这些参数的学习率。<br> 如果损失与某一指定参数的偏导的符号相同，那么学习率应该增加； 如果损失与该参数的偏导的符号不同，那么学习率应该减小。</p> 
</blockquote> 
<h5><a id="221__AdaGradAdaptive_Gradient_508"></a>2.2.1 AdaGrad（Adaptive Gradient）</h5> 
<p>Adagrad其实是对学习率进行了一个约束，对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本（稀疏特征的样本）身上多学一些，即学习速率大一些。该方法中开始使用的二阶动量，意味着“自适应学习率”优化算法时代的到来。</p> 
<blockquote> 
 <p>AdaGrad 算法，独立地适应所有模型参数的学习率，缩放每个参数反比于其所有梯度历史平均值总和的平方根。（知道这么回事就好，基本不用它~）<br> ● 具有损失函数最大梯度的参数相应地有个快速下降的学习率 ● 而具有小梯度的参数在学习率上有相对较小的下降。</p> 
 <p><strong>优点</strong>：自适应的学习率，无需人工调节<br> <strong>缺点</strong>：</p> 
 <ul><li>仍需要手工设置一个全局学习率 η, 如果 η 设置过大的话，会使 regularizer 过于敏感，对梯度的调节太大</li><li>中后期，<strong>分母上梯度累加的平方和会越来越大，使得参数更新量趋近于0</strong>，使得训练提前结束，无法学习</li></ul> 
</blockquote> 
<h5><a id="222__Adadelta_519"></a>2.2.2 Adadelta</h5> 
<p>由于AdaGrad调整学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度，即Adadelta只累加固定大小的项，并且也不直接存储这些项，仅仅是近似计算对应的平均值（指数移动平均值），这就避免了二阶动量持续累积、导致训练过程提前结束的问题了。</p> 
<blockquote> 
 <p><strong>优点</strong>：</p> 
 <ul><li>不依赖全局learning rate</li><li>训练初中期，加速效果不错，很快</li></ul> 
 <p><strong>缺点</strong>： 训练后期，反复在局部最小值附近抖动</p> 
</blockquote> 
<h5><a id="223_RMSprop_528"></a>2.2.3 RMSprop</h5> 
<p>RMSprop 和 Adadelta 都是为了解决 AdaGrad 学习率急剧下降问题的，但是RMSProp算法修改了AdaGrad的梯度平方和累加为<strong>指数加权的移动平均</strong>。</p> 
<blockquote> 
 <p>指数加权平均，旨在消除梯度下降中的摆动，与Momentum的效果一样，某一维度的导数比较大，则指数加权平均就大，某一维度的导数比较小，则其指数加权平均就小，这样就保证了各维度导数都在一个量级，进而减少了摆动。</p> 
</blockquote> 
<p>另外，指数衰减平均的方式可以淡化遥远过去的历史对当前步骤参数更新量的影响，衰减率表明的是只是最近的梯度平方有意义，而很久以前的梯度基本上会被遗忘</p> 
<blockquote> 
 <p><strong>优点</strong>：</p> 
 <ul><li>RMSprop算是Adagrad的一种发展，和Adadelta的变体，效果趋于二者之间</li><li>适合处理非平稳目标(包括季节性和周期性)——对于RNN效果很好</li></ul> 
 <p><strong>缺点</strong>：其实RMSprop依然依赖于全局学习率 η</p> 
</blockquote> 
<h5><a id="224_AdamAdaptive_Moment_Estimation_541"></a>2.2.4 Adam（Adaptive Moment Estimation）</h5> 
<p>Adam 结合了前面方法的一阶动量和二阶动量，是前述方法的集大成者。</p> 
<blockquote> 
 <p><strong>优点</strong>：</p> 
 <ul><li>Adam梯度经过偏置校正后，每一次迭代学习率都有一个固定范围，使得参数比较平稳。</li><li>结合了Adagrad善于处理稀疏梯度和RMSprop善于处理非平稳目标的优点</li><li>为不同的参数计算不同的自适应学习率</li><li>节省了训练集时间、训练成本</li></ul> 
 <p><strong>缺点</strong>： Adam 使用动量的滑动平均，可能会随着训练数据变化而抖动比较剧烈，在online场景可能波动较大，在广告场景往往效果不如 AdaGrad</p> 
</blockquote> 
<p><strong>Adam那么棒，为什么还对SGD念念不忘</strong><br> 举个栗子。很多年以前，摄影离普罗大众非常遥远。十年前，傻瓜相机开始风靡，游客几乎人手一个。智能手机出现以后，摄影更是走进千家万户，手机随手一拍，前后两千万，照亮你的美（咦，这是什么乱七八糟的）。但是专业摄影师还是喜欢用单反，孜孜不倦地调光圈、快门、ISO、白平衡……一堆自拍党从不care的名词。技术的进步，使得傻瓜式操作就可以得到不错的效果，但是在特定的场景下，要拍出最好的效果，依然需要深入地理解光线、理解结构、理解器材。<br> 更深入的内容，可以通过文末的参考文献进入了解。<br> <strong>1）TensorFlow2调用<br> 函数原型：</strong></p> 
<pre><code class="prism language-python">keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>lr<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> beta_1<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">,</span> beta_2<span class="token operator">=</span><span class="token number">0.999</span><span class="token punctuation">,</span> epsilon<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> decay<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> amsgrad<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
<p>📍官网地址：https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam</p> 
<p>参数详解：</p> 
<ul><li>lr: float &gt;= 0. 学习率。</li><li>beta_1: float, 0 &lt; beta &lt; 1. 通常接近于 1。</li><li>beta_2: float, 0 &lt; beta &lt; 1. 通常接近于 1。</li><li>epsilon: float &gt;= 0. 模糊因子. 若为 None, 默认为 K.epsilon()。</li><li>decay: float &gt;= 0. 每次参数更新后学习率衰减值。</li><li>amsgrad: boolean. 是否应用此算法的 AMSGrad 变种，来自论文 “On the Convergence of Adam and Beyond”。</li></ul> 
<p>调用示例：</p> 
<pre><code class="prism language-python"><span class="token comment"># 设置优化器</span>
opt <span class="token operator">=</span> tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>optimizers<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> decay<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>optimizer<span class="token operator">=</span>opt<span class="token punctuation">,</span>
              loss<span class="token operator">=</span>tf<span class="token punctuation">.</span>keras<span class="token punctuation">.</span>losses<span class="token punctuation">.</span>SparseCategoricalCrossentropy<span class="token punctuation">(</span>from_logits<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
              metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
<p>参考文献<br> <a href="https://arxiv.org/pdf/1609.04747.pdf" rel="nofollow">An overview of gradient descent optimization algorithms</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/32262540" rel="nofollow">Adam那么棒，为什么还对SGD念念不忘 (2)—— Adam的两宗罪</a></p> 
<h2><a id="_588"></a>总结</h2> 
<p>通过本次的学习，了解了预加载模型的用法，了解了多种优化器。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/9567413ecebe78c1d590153cffe8c2ef/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Django和ECharts异步请求示例</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/888b5c8a072037923de5bf2fbd2c3604/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">深度学习 Day14——P3天气识别</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>