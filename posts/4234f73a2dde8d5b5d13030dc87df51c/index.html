<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>GNN（图神经网络）基本概念 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="GNN（图神经网络）基本概念" />
<meta property="og:description" content="功能：节点分类和图分类
空域 ：空间上考虑图结构的模型，即考虑目标节点和其他节点的几何关系(有无连接)。
模型代表：GAT（Graph Attention Networks）图注意力模型
用注意力机制对邻近节点特征加权求和。邻近节点特征的权重完全取决于节点特征，独立于图结构。
（将卷积神经网络中的池化看成一种特殊的平均加权的注意力机制，或者说注意力机制是一种具有对输入分配偏好的通用池化方法(含参数的池化方法）
图 1：图注意力网络示意图和更新公式
对于上述公式的一些解释：
公式（1）对 l 层节点嵌入
做了线性变换，W^((l)) 是该变换可训练的参数
公式（2）计算了成对节点间的原始注意力分数。它首先拼接了两个节点的 z 嵌入，注意 || 在这里表示拼接；随后对拼接好的嵌入以及一个可学习的权重向量 做点积；最后应用了一个 LeakyReLU 激活函数。这一形式的注意力机制通常被称为加性注意力，区别于 Transformer 里的点积注意力。
公式（3）对于一个节点所有入边得到的原始注意力分数应用了一个 softmax 操作，得到了注意力权重。
公式（4）形似 GCN 的节点特征更新规则，对所有邻节点的特征做了基于注意力的加权求和。
频域：
模型代表：GCN（Graph Convolutional Network ）图卷积网络
优点：省参数
缺点：不易作用于动态图
(对于同阶的邻域上分配给不同的邻居的权重是完全相同的（无法允许为邻居中的不同节点指定不同的权重)
一次图卷积操作包含对邻节点特征的标准化求和：
其中 N(i) 是对节点 i 距离为 1 邻节点的集合。我们通常会加一条连接节点 i 和它自身的边使得 i 本身也被包括在 N(i) 里。
是一个基于图结构的标准化常数；
σ是一个激活函数（GCN 使用了 ReLU）；
W^((l)) 是节点特征转换的权重矩阵，被所有节点共享。
由于 c_ij 和图的机构相关，使得在一张图上学习到的 GCN 模型比较难直接应用到另一张图上。
共同步骤：
加工图邻接矩阵对图邻接矩阵特征分解，得到特征值，核心区别（如何收集并累和距离为 1 的邻居节点的特征表示 ） 将特征向量看作常数，而卷积核作用在特征值上 GAT 用注意力机制替代了图卷积中固定的标准化操作，将原本的标准化常数替换为使用注意力权重的邻居节点特征聚合函数。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/4234f73a2dde8d5b5d13030dc87df51c/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-06-06T14:06:14+08:00" />
<meta property="article:modified_time" content="2022-06-06T14:06:14+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">GNN（图神经网络）基本概念</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>功能：<strong>节点分类</strong>和图分类</p> 
<p></p> 
<p>空域 ：<strong>空间</strong>上考虑图结构的模型，即考虑目标节点和其他节点的几何关系(<strong>有无连接</strong>)。</p> 
<p>模型代表：GAT（Graph Attention Networks）图注意力模型</p> 
<p>用<a href="https://link.zhihu.com/?target=https%3A//mp.weixin.qq.com/s%3F__biz%3DMzA3MzI4MjgzMw%3D%3D%26mid%3D2650757332%26idx%3D3%26sn%3D4a66ac808542af2617be5621a4a56e5d%26chksm%3D871a9caab06d15bc29f72e3d2c78355cd226d65907486a4c4acbc3f6c60713192908b70eadb4%26token%3D288766650%26lang%3Dzh_CN" rel="nofollow" title="注意力机制">注意力机制</a>对邻近节点特征加权求和。邻近节点特征的权重完全取决于节点特征，独立于图结构。</p> 
<p>（<strong>将<code>卷积神经网络</code>中的池化看成一种特殊的平均加权的<code>注意力机制</code>，或者说注意力机制是一种具有对输入分配偏好的通用池化方法(含参数的池化方法</strong>）</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/2d/10/Z8rUOO2A_o.png"></p> 
<p>图 1：图注意力网络示意图和更新公式</p> 
<p>对于上述公式的一些解释：</p> 
<ul><li> <p>公式（1）对 l 层节点嵌入</p> </li></ul> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/79/91/WOuTxHo6_o.png"></p> 
<p>做了线性变换，W^((l)) 是该变换可训练的参数</p> 
<ul><li> <p>公式（2）计算了成对节点间的原始注意力分数。它首先拼接了两个节点的 z 嵌入，注意 || 在这里表示拼接；随后对拼接好的嵌入以及一个可学习的权重向量 做点积；最后应用了一个 LeakyReLU 激活函数。这一形式的注意力机制通常被称为加性注意力，区别于 Transformer 里的点积注意力。</p> </li><li> <p>公式（3）对于一个节点所有入边得到的原始注意力分数应用了一个 softmax 操作，得到了注意力权重。</p> </li><li> <p>公式（4）形似 GCN 的节点特征更新规则，对所有邻节点的特征做了基于注意力的加权求和。</p> </li></ul> 
<p>频域：</p> 
<p>模型代表：GCN（Graph Convolutional Network ）图卷积网络</p> 
<p>优点：省参数</p> 
<p>缺点：不易作用于动态图</p> 
<p>(对于同阶的邻域上分配给不同的邻居的权重是完全相同的（无法允许为邻居中的不同节点指定不同的权重)</p> 
<p><strong>一次图卷积操作</strong>包含对<strong>邻节点特征的标准化求和</strong>：</p> 
<p><img alt="" height="154" src="https://images2.imgbox.com/15/4d/E6XeJRSx_o.png" width="493"></p> 
<p>其中 <strong>N(i) 是对节点 i 距离为 1 邻节点的集合</strong>。我们通常会加一条连接节点 i 和它自身的边使得 i 本身也被包括在 N(i) 里。</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/45/58/eDkGYCAQ_o.png"></p> 
<p>是一个基于图结构的标准化常数；</p> 
<p>σ是一个激活函数（<strong>GCN 使用了 ReLU</strong>）；</p> 
<p>W^((l)) 是节点特征转换的权重矩阵，被所有节点共享。</p> 
<p>由于 c_ij 和图的机构相关，使得在一张图上学习到的 GCN 模型比较难直接应用到另一张图上。</p> 
<p></p> 
<p>共同步骤：</p> 
<ol><li>加工<strong>图邻接矩阵</strong></li><li>对<strong>图邻接矩阵</strong>特征分解，得到特征值，</li><li>核心区别（如何<u><strong>收集并累和距离为 1 的邻居节点的特征表示</strong></u> ）</li><li> 将特征向量看作常数，而卷积核作用在特征值上</li></ol> 
<p>GAT 用注意力机制替代了图卷积中固定的标准化操作，将原本的<strong>标准化常数</strong>替换为<strong>使用注意力权重的邻居节点特征聚合函数</strong>。</p> 
<p></p> 
<h3><strong>多头注意力 (Multi-head attention)</strong></h3> 
<p>神似卷积神经网络里的多通道，GAT 引入了多头注意力来丰富模型的能力和稳定训练的过程。每一个注意力的头都有它自己的参数。如何整合多个注意力机制的输出结果一般有两种方式：</p> 
<p style="text-align:center;"><img alt="" src="https://images2.imgbox.com/02/26/Vi3Wk0Ze_o.png"></p> 
<p>以上式子中 K 是注意力头的数量。作者们建议对中间层使用拼接对最后一层使用求平均。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/b74d444482f1e6dbd0a44e59400d5432/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">学会正确地二次封装组件，让同事抱着你的大腿喊大神！</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/1ff8819351b6e805aa2e84b37d3f2533/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">golang中的string类型转化为时间戳或者time.Time类型</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>