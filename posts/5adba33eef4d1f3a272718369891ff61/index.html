<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>CPN（Cascaded Pyramid Network for Multi-Person Pose Estimation) 姿态估计 - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="CPN（Cascaded Pyramid Network for Multi-Person Pose Estimation) 姿态估计" />
<meta property="og:description" content="本篇博客是对论文《Cascaded Pyramid Network for Multi-Person Pose Estimation》的个人解读，以及对代码（tensorflow版本)的细节分析。 其他资料： 旷视研究院详解COCO2017人体姿态估计冠军论文实录 | 旷视研究院详解COCO2017人体姿态估计冠军论文（PPT&#43;视频) 前言 目前对多人的姿态点检测的算法总体分为两类：
bottom-up 方法：此方法直接预测关键点，再判断关键点分别属于哪个人，代表有openposetop-down方法：此方法为两阶段方法，先检测人，再根据检测的人的框使用单人姿态点检测算法SPPE（a single-person pose estimator）对每一个人进行关键点的检测，最后整合回原图。 两种方法的区别：
由于top-down方法依赖于人体检测框的结果，非常容易受其影响。比如如果人体重叠部分过大，则可能只检测出一个检测框，导致准确度下降，如下图1所示：top-down算法的时间成本会随着图像中的人数增加而增加，每增加一个人就要进行一次SPPE算法。bottom-up相比没有以上两点问题。 图1 人物重叠容易导致检测框只检测到一个人，从而影响关键点检测。 摘要 论文提出的关键点检测算法是SPPE,提出了一种网络结构，能够对不可见的关键点，重叠的关键点，模糊难以辨识的关键点的检测，克服复杂背景的影响。网络分为两部分：
GlobalNet：为一个FPN网络，用来检测比较简单的关键点，如眼睛，手;但对不可见的等较难的点判断并不是很好。RefineNet：主要是用来检测非常难分辨的关键点，他的输入的GlobalNet的几个不同层次的特征来在线的（后文会讲到如何在线）对判断困难的关键点进行检测。 论文的方法获得了COCO 人体姿态点检测的2017年冠军，在COCO test-dev上的平均检测精度为73.0，在COCO test-challenge 数据集上平均检测精度 72.1，比2016年冠军的60.5高出了19%！
网络结构解读 图2 SPPE网络结构图
GlobalNet 图3 Globalnet 首先，GlobalNet的输入并不是一幅图像，而是Resnet的4个blocks提取出的特征图，论文中分别以C2,C3,C4,C5来代表。其中C2，C3由于层数较浅，所以有很高的空间精度即能够很好的定位原图信息，但是语义信息不足;相反，C4，C5，拥有较高的语义信息，但是空间分辨率较低，不足以定位图像信息。所以，GlobalNet采用FPN的结构充分的利用各个层次的不同信息来对关键点的heatmap进行预测。 注：GlobalNet与FPN稍有不同，在升采样（upsampling process）之后，两层相加之前，要再进行一次1×1的卷积操作。 输入到Globalnet中的每一层要进行的操作：
net1 (from resnet) —&gt; 1*1 conv —&gt; upsampling —&gt; 1 * 1 conv —-&gt; elem-sum(与下一层) ——&gt; predict —&gt; L2 loss
代码解读： def create_global_net(blocks, is_training, trainable=True): &#39;&#39;&#39; blocks: 即C2，C3，C4，C5 &#39;&#39;&#39; global_fms = [] #GlobalNet的输出求loss global_outs = [] #RefineNet的输入！！！ last_fm = None #初始化 initializer = tf." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/5adba33eef4d1f3a272718369891ff61/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-07-11T16:34:47+08:00" />
<meta property="article:modified_time" content="2018-07-11T16:34:47+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">CPN（Cascaded Pyramid Network for Multi-Person Pose Estimation) 姿态估计</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p>本篇博客是对论文<a href="https://arxiv.org/abs/1711.07319" rel="nofollow">《Cascaded Pyramid Network for Multi-Person Pose Estimation》</a>的个人解读，以及对<a href="https://github.com/chestnut111/tf-cpn">代码（tensorflow版本)</a>的细节分析。 <br> <img title="" alt="这里写图片描述" src="https://images2.imgbox.com/16/ca/QV9ibRwa_o.png"></p> 
<h3 id="其他资料">其他资料：</h3> 
<ol><li><a href="https://www.bilibili.com/video/av24143047" rel="nofollow">旷视研究院详解COCO2017人体姿态估计冠军论文</a></li><li><a href="http://www.sohu.com/a/211402864_610300" rel="nofollow">实录 | 旷视研究院详解COCO2017人体姿态估计冠军论文（PPT+视频)</a></li></ol> 
<h3 id="前言">前言</h3> 
<p>目前对<strong>多人的姿态点检测</strong>的算法总体分为两类：</p> 
<ol><li><strong>bottom-up 方法</strong>：此方法直接预测关键点，再判断关键点分别属于哪个人，代表有<a href="https://github.com/CMU-Perceptual-Computing-Lab/openpose">openpose</a></li><li><strong>top-down方法</strong>：此方法为两阶段方法，先检测人，再根据检测的人的框使用单人姿态点检测算法SPPE（a single-person pose estimator）对每一个人进行关键点的检测，最后整合回原图。</li></ol> 
<p>两种方法的区别：</p> 
<ol><li>由于top-down方法依赖于人体检测框的结果，非常容易受其影响。比如如果人体重叠部分过大，则可能只检测出一个检测框，导致准确度下降，如下图1所示：</li><li>top-down算法的时间成本会随着图像中的人数增加而增加，每增加一个人就要进行一次SPPE算法。</li><li>bottom-up相比没有以上两点问题。 <br> <img title="" alt="这里写图片描述" src="https://images2.imgbox.com/d1/44/9AkeravK_o.png"> <br> 图1 人物重叠容易导致检测框只检测到一个人，从而影响关键点检测。</li></ol> 
<h3 id="摘要">摘要</h3> 
<p>论文提出的关键点检测算法是SPPE,提出了一种网络结构，能够对不可见的关键点，重叠的关键点，模糊难以辨识的关键点的检测，克服复杂背景的影响。网络分为两部分：</p> 
<ol><li>GlobalNet：为一个FPN网络，用来检测比较简单的关键点，如眼睛，手;但对不可见的等较难的点判断并不是很好。</li><li>RefineNet：主要是用来检测非常难分辨的关键点，他的输入的GlobalNet的几个不同层次的特征来在线的（后文会讲到如何在线）对判断困难的关键点进行检测。</li></ol> 
<p>论文的方法获得了COCO 人体姿态点检测的2017年冠军，在COCO test-dev上的平均检测精度为73.0，在COCO test-challenge 数据集上平均检测精度 72.1，比2016年冠军的60.5高出了19%！</p> 
<h4 id="网络结构解读">网络结构解读</h4> 
<p><img title="" alt="这里写图片描述" src="https://images2.imgbox.com/16/73/vFIpCY2t_o.png"> <br> 图2 SPPE网络结构图</p> 
<h4 id="globalnet">GlobalNet</h4> 
<p><img title="" alt="这里写图片描述" src="https://images2.imgbox.com/1d/e6/9KhnPwm2_o.png"> <br> 图3 Globalnet <br> 首先，GlobalNet的输入并不是一幅图像，而是Resnet的4个blocks提取出的特征图，论文中分别以C2,C3,C4,C5来代表。其中C2，C3由于层数较浅，所以有很高的空间精度即能够很好的定位原图信息，但是语义信息不足;相反，C4，C5，拥有较高的语义信息，但是空间分辨率较低，不足以定位图像信息。所以，GlobalNet采用FPN的结构充分的利用各个层次的不同信息来对关键点的heatmap进行预测。 <br> 注：GlobalNet与FPN稍有不同，在升采样（upsampling process）之后，两层相加之前，要再进行一次1×1的卷积操作。 <br> 输入到Globalnet中的每一层要进行的操作：</p> 
<blockquote> 
 <p><strong>net1 (from resnet) —&gt; 1*1 conv —&gt; upsampling —&gt; 1 * 1 conv —-&gt; elem-sum(与下一层) ——&gt; predict —&gt; L2 loss</strong></p> 
</blockquote> 
<h5 id="代码解读">代码解读：</h5> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_global_net</span><span class="hljs-params">(blocks, is_training, trainable=True)</span>:</span>
<span class="hljs-string">'''
blocks: 即C2，C3，C4，C5
'''</span>
    global_fms = [] <span class="hljs-comment">#GlobalNet的输出求loss</span>
    global_outs = [] <span class="hljs-comment">#RefineNet的输入！！！</span>
    last_fm = <span class="hljs-keyword">None</span> <span class="hljs-comment">#初始化</span>
    initializer = tf.contrib.layers.xavier_initializer()
    <span class="hljs-keyword">for</span> i, block <span class="hljs-keyword">in</span> enumerate(reversed(blocks)):
        <span class="hljs-keyword">with</span> slim.arg_scope(resnet_arg_scope(bn_is_training=is_training)):
            lateral = slim.conv2d(block, <span class="hljs-number">256</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                trainable=trainable, weights_initializer=initializer,
                padding=<span class="hljs-string">'SAME'</span>, activation_fn=tf.nn.relu,
                scope=<span class="hljs-string">'lateral/res{}'</span>.format(<span class="hljs-number">5</span>-i))
        <span class="hljs-comment">#如果last_fm不是None,则对当前层进行线性差值（上采样）之后与当前层进行相加</span>
        <span class="hljs-keyword">if</span> last_fm <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            sz = tf.shape(lateral)
            upsample = tf.image.resize_bilinear(last_fm, (sz[<span class="hljs-number">1</span>], sz[<span class="hljs-number">2</span>]),
                name=<span class="hljs-string">'upsample/res{}'</span>.format(<span class="hljs-number">5</span>-i))
            upsample = slim.conv2d(upsample, <span class="hljs-number">256</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                trainable=trainable, weights_initializer=initializer,
                padding=<span class="hljs-string">'SAME'</span>, activation_fn=<span class="hljs-keyword">None</span>,
                scope=<span class="hljs-string">'merge/res{}'</span>.format(<span class="hljs-number">5</span>-i))
            last_fm = upsample + lateral <span class="hljs-comment">#两层相加</span>
        <span class="hljs-keyword">else</span>:
            last_fm = lateral <span class="hljs-comment">#此时的层为最高层即最后一层，有最高的语义表征，不进行上采样，直接输出</span>

        <span class="hljs-comment">#对每一层叠加之后的last_fm进行1*1的卷积之后再进行3*3的卷积生成17个feature map(17个关键点的热力图)，作为predict参与训练</span>
        <span class="hljs-keyword">with</span> slim.arg_scope(resnet_arg_scope(bn_is_training=is_training)):
            tmp = slim.conv2d(last_fm, <span class="hljs-number">256</span>, [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                trainable=trainable, weights_initializer=initializer,
                padding=<span class="hljs-string">'SAME'</span>, activation_fn=tf.nn.relu,
                scope=<span class="hljs-string">'tmp/res{}'</span>.format(<span class="hljs-number">5</span>-i))
            out = slim.conv2d(tmp, cfg.nr_skeleton, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
                trainable=trainable, weights_initializer=initializer,
                padding=<span class="hljs-string">'SAME'</span>, activation_fn=<span class="hljs-keyword">None</span>,
                scope=<span class="hljs-string">'pyramid/res{}'</span>.format(<span class="hljs-number">5</span>-i))
        global_fms.append(last_fm)
        global_outs.append(tf.image.resize_bilinear(out, (cfg.output_shape[<span class="hljs-number">0</span>], cfg.output_shape[<span class="hljs-number">1</span>])))
    global_fms.reverse()
    global_outs.reverse()
    <span class="hljs-keyword">return</span> global_fms, global_outs</code></pre> 
<h4 id="refinenet">RefineNet</h4> 
<p><strong>对困难关键点进行定位，此处的困难关键点由训练决定，根据globalnet的loss大小决定哪几个关键点成为困难关键点，并不是人为的决定！！</strong></p> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_refine_net</span><span class="hljs-params">(blocks, is_training, trainable=True)</span>:</span>
    <span class="hljs-comment">#global_fms 即 blocks</span>
    initializer = tf.contrib.layers.xavier_initializer()
    bottleneck = resnet_v1.bottleneck
    refine_fms = []
    <span class="hljs-keyword">for</span> i, block <span class="hljs-keyword">in</span> enumerate(blocks):
        mid_fm = block
        <span class="hljs-keyword">with</span> slim.arg_scope(resnet_arg_scope(bn_is_training=is_training)):
            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(i):
                mid_fm = bottleneck(mid_fm, <span class="hljs-number">256</span>, <span class="hljs-number">128</span>, stride=<span class="hljs-number">1</span>, scope=<span class="hljs-string">'res{}/refine_conv{}'</span>.format(<span class="hljs-number">2</span>+i, j)) <span class="hljs-comment"># no projection</span>
        mid_fm = tf.image.resize_bilinear(mid_fm, (cfg.output_shape[<span class="hljs-number">0</span>], cfg.output_shape[<span class="hljs-number">1</span>]),
            name=<span class="hljs-string">'upsample_conv/res{}'</span>.format(<span class="hljs-number">2</span>+i))
        refine_fms.append(mid_fm)
    refine_fm = tf.concat(refine_fms, axis=<span class="hljs-number">3</span>)  <span class="hljs-comment">##此处的操作的是concat!!!!</span>
    <span class="hljs-keyword">with</span> slim.arg_scope(resnet_arg_scope(bn_is_training=is_training)):
        refine_fm = bottleneck(refine_fm, <span class="hljs-number">256</span>, <span class="hljs-number">128</span>, stride=<span class="hljs-number">1</span>, scope=<span class="hljs-string">'final_bottleneck'</span>)
        res = slim.conv2d(refine_fm, cfg.nr_skeleton, [<span class="hljs-number">3</span>, <span class="hljs-number">3</span>],
            trainable=trainable, weights_initializer=initializer,
            padding=<span class="hljs-string">'SAME'</span>, activation_fn=<span class="hljs-keyword">None</span>,
            scope=<span class="hljs-string">'refine_out'</span>)
    <span class="hljs-keyword">return</span> res</code></pre> 
<p><strong>疑问！ 神经网络有时会利用不同层的语义特征，但是利用的方式有两种，就像本处的Globalnet,对不同层次的特征进行 elem_sum, 即对应元素相加，类似于Resnet;而Refinenet则是对不同层次的特征进行concat，类似于inception; 这两者之间的区别是什么，什么时候用concat什么时候用elem_sum呢？？？</strong></p> 
<p>总体网络架构： <br> <strong>resnet101 + create_global_net + create_refine_net</strong></p> 
<pre class="prettyprint"><code class=" hljs vala">resnet_fms = resnet101(image, is_train, bn_trainable=True)
global_fms, global_outs = create_global_net(resnet_fms, is_train)
<span class="hljs-preprocessor">#flobal_outs: 17*64*48</span>
refine_out = create_refine_net(global_fms, is_train)
<span class="hljs-preprocessor">#refine_outs: 17*</span></code></pre> 
<p>根据每个特征点的loss选择那些点进入到Refinenet中进行挖掘：</p> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">ohkm</span><span class="hljs-params">(loss, top_k)</span>:</span>
    ohkm_loss = <span class="hljs-number">0.</span>
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(cfg.batch_size):
        sub_loss = loss[i]
        topk_val, topk_idx = tf.nn.top_k(sub_loss, k=top_k, sorted=<span class="hljs-keyword">False</span>, name=<span class="hljs-string">'ohkm{}'</span>.format(i))
        tmp_loss = tf.gather(sub_loss, topk_idx, name=<span class="hljs-string">'ohkm_loss{}'</span>.format(i)) <span class="hljs-comment"># can be ignore ???</span>
        ohkm_loss += tf.reduce_sum(tmp_loss) / top_k
    ohkm_loss /= cfg.batch_size
    <span class="hljs-keyword">return</span> ohkm_loss



refine_loss = tf.reduce_mean(tf.square(refine_out - label7), (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)) * tf.to_float((tf.greater(valids, <span class="hljs-number">0.1</span>)))
refine_loss = ohkm(refine_loss, <span class="hljs-number">8</span>) <span class="hljs-comment">#选择8个点作为困哪关键点进行挖掘！可设置调整。</span></code></pre> 
<h3 id="训练数据读入networkpy">训练数据读入(network.py)</h3> 
<pre class="prettyprint"><code class=" hljs python">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_data</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">from</span> COCOAllJoints <span class="hljs-keyword">import</span> COCOJoints
        <span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> Preprocessing
        d = COCOJoints() 
        <span class="hljs-comment">#得到的数据d对象：</span>
        <span class="hljs-comment">#humanData = dict(aid = aid,joints=joints, imgpath=imgname, headRect=rect, bbox=bbox, imgid = ann['image_id'], segmentation = ann['segmentation'])</span>
        <span class="hljs-comment">#输入数据为字典格式，每个字典包含7部分的内容，包括图像id以及关键点坐标，如果想修改训练自己的数据集的化，可以类似修改成这部分的对象</span>
        train_data, _ = d.load_data(cfg.min_kps)

        <span class="hljs-keyword">from</span> tfflat.data_provider <span class="hljs-keyword">import</span> DataFromList, MultiProcessMapDataZMQ, BatchData, MapData
        dp = DataFromList(train_data) <span class="hljs-comment">#转换为list</span>
        <span class="hljs-keyword">if</span> cfg.dpflow_enable:  <span class="hljs-comment">#True</span>
            dp = MultiProcessMapDataZMQ(dp, cfg.nr_dpflows, Preprocessing)
            <span class="hljs-comment">##传入函数Preprocessing，对图像进行裁剪标准框以及关键点坐标变换，并且生成图像关键点热力图标签！</span>
        <span class="hljs-keyword">else</span>:
            dp = MapData(dp, Preprocessing)
        dp = BatchData(dp, cfg.batch_size // cfg.nr_aug) <span class="hljs-comment">##nr_aug = 4</span>
        dp.reset_state()
        dataiter = dp.get_data()
        <span class="hljs-keyword">return</span> dataiter</code></pre> 
<h3 id="图像预处理以及标签生成datasetpy">图像预处理以及标签生成（dataset.py）</h3> 
<p><strong>对图像进行标准框裁剪的时候，先进行了padding操作，使用图像均值进行填充，再对图像进行裁剪，裁剪之后的图像为之前的标准框，并对关键点坐标进行相应的操作！</strong> <br> pad–&gt;crop</p> 
<pre class="prettyprint"><code class=" hljs livecodeserver">def Preprocessing(d, stage=<span class="hljs-string">'train'</span>):
    height, width = cfg.data_shape <span class="hljs-comment">#256 192</span>
    imgs = []
    labels = []
    valids = []
    <span class="hljs-keyword">if</span> cfg.use_seg:
        segms = []

    vis = False
    img = cv2.imread(os.path.join(cfg.img_path, d[<span class="hljs-string">'imgpath'</span>])) <span class="hljs-comment">#读取图像</span>
    <span class="hljs-comment">#hack(multiprocessing data provider)</span>
    <span class="hljs-keyword">while</span> img is None:
        print(<span class="hljs-string">'read none image'</span>)
        <span class="hljs-built_in">time</span>.sleep(np.<span class="hljs-built_in">random</span>.rand() * <span class="hljs-number">5</span>)
        img = cv2.imread(os.path.join(cfg.img_path, d[<span class="hljs-string">'imgpath'</span>]))
    <span class="hljs-built_in">add</span> = <span class="hljs-built_in">max</span>(img.shape[<span class="hljs-number">0</span>], img.shape[<span class="hljs-number">1</span>])
    bimg = cv2.copyMakeBorder(img, <span class="hljs-built_in">add</span>, <span class="hljs-built_in">add</span>, <span class="hljs-built_in">add</span>, <span class="hljs-built_in">add</span>, borderType=cv2.BORDER_CONSTANT,
                              <span class="hljs-built_in">value</span>=cfg.pixel_means.reshape(-<span class="hljs-number">1</span>)) <span class="hljs-comment">#均值填充！！</span>

    bbox = np.array(d[<span class="hljs-string">'bbox'</span>]).reshape(<span class="hljs-number">4</span>, ).astype(np.float32)
    bbox[:<span class="hljs-number">2</span>] += <span class="hljs-built_in">add</span>
    <span class="hljs-keyword">if</span> <span class="hljs-string">'joints'</span> <span class="hljs-operator">in</span> d:
        joints = np.array(d[<span class="hljs-string">'joints'</span>]).reshape(cfg.nr_skeleton, <span class="hljs-number">3</span>).astype(np.float32)
        joints[:, :<span class="hljs-number">2</span>] += <span class="hljs-built_in">add</span>
        inds = np.where(joints[:, -<span class="hljs-number">1</span>] == <span class="hljs-number">0</span>)
        joints[inds, :<span class="hljs-number">2</span>] = -<span class="hljs-number">1000000</span>

    crop_width = bbox[<span class="hljs-number">2</span>] * (<span class="hljs-number">1</span> + cfg.imgExtXBorder * <span class="hljs-number">2</span>)
    crop_height = bbox[<span class="hljs-number">3</span>] * (<span class="hljs-number">1</span> + cfg.imgExtYBorder * <span class="hljs-number">2</span>)
    objcenter = np.array([bbox[<span class="hljs-number">0</span>] + bbox[<span class="hljs-number">2</span>] / <span class="hljs-number">2.</span>, bbox[<span class="hljs-number">1</span>] + bbox[<span class="hljs-number">3</span>] / <span class="hljs-number">2.</span>])

    <span class="hljs-keyword">if</span> stage == <span class="hljs-string">'train'</span>:
        crop_width = crop_width * (<span class="hljs-number">1</span> + <span class="hljs-number">0.25</span>)
        crop_height = crop_height * (<span class="hljs-number">1</span> + <span class="hljs-number">0.25</span>)

    <span class="hljs-keyword">if</span> crop_height / height &gt; crop_width / width:
        crop_size = crop_height
        min_shape = height
    <span class="hljs-keyword">else</span>:
        crop_size = crop_width
        min_shape = width

    crop_size = <span class="hljs-built_in">min</span>(crop_size, objcenter[<span class="hljs-number">0</span>] / width * min_shape * <span class="hljs-number">2.</span> - <span class="hljs-number">1.</span>)                     <span class="hljs-comment">##??</span>
    crop_size = <span class="hljs-built_in">min</span>(crop_size, (bimg.shape[<span class="hljs-number">1</span>] - objcenter[<span class="hljs-number">0</span>]) / width * min_shape * <span class="hljs-number">2.</span> - <span class="hljs-number">1</span>)    <span class="hljs-comment">##??</span>
    crop_size = <span class="hljs-built_in">min</span>(crop_size, objcenter[<span class="hljs-number">1</span>] / height * min_shape * <span class="hljs-number">2.</span> - <span class="hljs-number">1.</span>)                    <span class="hljs-comment">##??</span>
    crop_size = <span class="hljs-built_in">min</span>(crop_size, (bimg.shape[<span class="hljs-number">0</span>] - objcenter[<span class="hljs-number">1</span>]) / height * min_shape * <span class="hljs-number">2.</span> - <span class="hljs-number">1</span>)   <span class="hljs-comment">##??</span>

    min_x = int(objcenter[<span class="hljs-number">0</span>] - crop_size / <span class="hljs-number">2.</span> / min_shape * width)   <span class="hljs-comment">##</span>
    max_x = int(objcenter[<span class="hljs-number">0</span>] + crop_size / <span class="hljs-number">2.</span> / min_shape * width)   <span class="hljs-comment">##</span>
    min_y = int(objcenter[<span class="hljs-number">1</span>] - crop_size / <span class="hljs-number">2.</span> / min_shape * height)  <span class="hljs-comment">##</span>
    max_y = int(objcenter[<span class="hljs-number">1</span>] + crop_size / <span class="hljs-number">2.</span> / min_shape * height)  <span class="hljs-comment">##</span>

    x_ratio = float(width) / (max_x - min_x)
    y_ratio = float(height) / (max_y - min_y)

    <span class="hljs-keyword">if</span> <span class="hljs-string">'joints'</span> <span class="hljs-operator">in</span> d:
        joints[:, <span class="hljs-number">0</span>] = joints[:, <span class="hljs-number">0</span>] - min_x
        joints[:, <span class="hljs-number">1</span>] = joints[:, <span class="hljs-number">1</span>] - min_y  <span class="hljs-comment">##转化为在截取的标准框上的坐标！</span>

        joints[:, <span class="hljs-number">0</span>] *= x_ratio
        joints[:, <span class="hljs-number">1</span>] *= y_ratio    <span class="hljs-comment">##放大到256*192</span>
        label = joints[:, :<span class="hljs-number">2</span>].copy()
        valid = joints[:, <span class="hljs-number">2</span>].copy()

    img = cv2.resize(bimg[min_y:max_y, min_x:max_x, :], (width, height))
    <span class="hljs-comment">#此时的img为截取的标准框图像，关键点都做了相应的变换</span>

    <span class="hljs-comment"># if stage != 'train':</span>
    <span class="hljs-comment">#     details = np.asarray([min_x - add, min_y - add, max_x - add, max_y - add])</span>
    <span class="hljs-comment"># if cfg.use_seg is True and 'segmentation' in d:</span>
    <span class="hljs-comment">#     seg = get_seg(ori_img.shape[0], ori_img.shape[1], d['segmentation'])</span>
    <span class="hljs-comment">#     add = max(seg.shape[0], seg.shape[1])</span>
    <span class="hljs-comment">#     bimg = cv2.copyMakeBorder(seg, add, add, add, add, borderType=cv2.BORDER_CONSTANT, value=(0, 0, 0))</span>
    <span class="hljs-comment">#     seg = cv2.resize(bimg[min_y:max_y, min_x:max_x], (width, height))</span>
    <span class="hljs-comment">#     segms.append(seg)</span>

    <span class="hljs-comment"># if vis:</span>
    <span class="hljs-comment">#     tmpimg = img.copy()</span>
    <span class="hljs-comment">#     from utils.visualize import draw_skeleton</span>
    <span class="hljs-comment">#     draw_skeleton(tmpimg, label.astype(int))</span>
    <span class="hljs-comment">#     cv2.imwrite('vis.jpg', tmpimg)</span>
    <span class="hljs-comment">#     from IPython import embed; embed()</span>

    img = img - cfg.pixel_means  <span class="hljs-comment">##俭掉图像均值</span>
    <span class="hljs-keyword">if</span> cfg.pixel_norm:  <span class="hljs-comment">#True</span>
        img = img / <span class="hljs-number">255.</span>
    img = img.<span class="hljs-built_in">transpose</span>(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <span class="hljs-comment">##变换通道</span>
    imgs.append(img)
    <span class="hljs-keyword">if</span> <span class="hljs-string">'joints'</span> <span class="hljs-operator">in</span> d:
        labels.append(label.reshape(-<span class="hljs-number">1</span>))
        valids.append(valid.reshape(-<span class="hljs-number">1</span>))

    <span class="hljs-keyword">if</span> stage == <span class="hljs-string">'train'</span>:  <span class="hljs-comment">##进行图像增强，以及转换标签为热力图</span>
        imgs, labels, valids = data_augmentation(imgs, labels, valids)
        heatmaps15 = joints_heatmap_gen(imgs, labels, cfg.output_shape, cfg.data_shape, return_valid=False,
                                        gaussian_kernel=cfg.gk15)
        heatmaps11 = joints_heatmap_gen(imgs, labels, cfg.output_shape, cfg.data_shape, return_valid=False,
                                        gaussian_kernel=cfg.gk11)
        heatmaps9 = joints_heatmap_gen(imgs, labels, cfg.output_shape, cfg.data_shape, return_valid=False,
                                       gaussian_kernel=cfg.gk9)
        heatmaps7 = joints_heatmap_gen(imgs, labels, cfg.output_shape, cfg.data_shape, return_valid=False,
                                       gaussian_kernel=cfg.gk7)

        <span class="hljs-constant">return</span> [imgs.astype(np.float32).<span class="hljs-built_in">transpose</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>),
                heatmaps15.astype(np.float32).<span class="hljs-built_in">transpose</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>),
                heatmaps11.astype(np.float32).<span class="hljs-built_in">transpose</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>),
                heatmaps9.astype(np.float32).<span class="hljs-built_in">transpose</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>),
                heatmaps7.astype(np.float32).<span class="hljs-built_in">transpose</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>),
                valids.astype(np.float32)]
    <span class="hljs-keyword">else</span>:
        <span class="hljs-constant">return</span> [np.asarray(imgs).astype(np.float32), details]</code></pre> 
<h3 id="图像标签热力图的生成">图像标签热力图的生成</h3> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">joints_heatmap_gen</span><span class="hljs-params">(data, label, tar_size=cfg.output_shape, ori_size=cfg.data_shape, points=cfg.nr_skeleton,
                       return_valid=False, gaussian_kernel=cfg.gaussain_kernel)</span>:</span>  <span class="hljs-comment">##cfg.output_shape = （64，48）（256，192）---&gt; (64,48)</span>
    <span class="hljs-comment">#注意此时的label是在（256，192）上的关键点坐标，需要转换成（64，48）上的关键点坐标</span>
    <span class="hljs-comment">#对关键点位置进行高斯滤波，使用不同的kernel训练</span>
    <span class="hljs-keyword">if</span> return_valid: <span class="hljs-comment">##False</span>
        valid = np.ones((len(data), points), dtype=np.float32)

    ret = np.zeros((len(data), points, tar_size[<span class="hljs-number">0</span>], tar_size[<span class="hljs-number">1</span>]), dtype=<span class="hljs-string">'float32'</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(ret)):
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(points):  <span class="hljs-comment">##points = 17</span>
            <span class="hljs-keyword">if</span> label[i][j &lt;&lt; <span class="hljs-number">1</span>] &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> label[i][j &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] &lt; <span class="hljs-number">0</span>:  <span class="hljs-comment">##左移一位？？？？？</span>
                <span class="hljs-keyword">continue</span>
            label[i][j &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] = min(label[i][j &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>], ori_size[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>)
            label[i][j &lt;&lt; <span class="hljs-number">1</span>] = min(label[i][j &lt;&lt; <span class="hljs-number">1</span>], ori_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>)
            ret[i][j][int(label[i][j &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] * tar_size[<span class="hljs-number">0</span>] / ori_size[<span class="hljs-number">0</span>])][
                int(label[i][j &lt;&lt; <span class="hljs-number">1</span>] * tar_size[<span class="hljs-number">1</span>] / ori_size[<span class="hljs-number">1</span>])] = <span class="hljs-number">1</span>

    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(ret)):
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(points):
            ret[i, j] = cv2.GaussianBlur(ret[i, j], gaussian_kernel, <span class="hljs-number">0</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(ret)):
        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(cfg.nr_skeleton):
            am = np.amax(ret[i][j])
            <span class="hljs-keyword">if</span> am &lt;= <span class="hljs-number">1e-8</span>:
                <span class="hljs-keyword">if</span> return_valid: <span class="hljs-comment">#False</span>
                    valid[i][j] = <span class="hljs-number">0.</span>
                <span class="hljs-keyword">continue</span>
            ret[i][j] /= am / <span class="hljs-number">255</span>  <span class="hljs-comment">#标准化</span>
    <span class="hljs-keyword">if</span> return_valid:
        <span class="hljs-keyword">return</span> ret, valid
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> ret</code></pre> 
<h3 id="数据增强">数据增强</h3> 
<ol><li>crop augmentation</li><li>random scales</li><li>rotation</li><li>flip</li></ol> 
<pre class="prettyprint"><code class=" hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">data_augmentation</span><span class="hljs-params">(trainData, trainLabel, trainValids, segms=None)</span>:</span>
    trainSegms = segms
    tremNum = cfg.nr_aug - <span class="hljs-number">1</span>
    gotData = trainData.copy()
    trainData = np.append(trainData, [trainData[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(tremNum * len(trainData))], axis=<span class="hljs-number">0</span>)
    <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        gotSegm = trainSegms.copy()
        trainSegms = np.append(trainSegms, [trainSegms[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(tremNum * len(trainSegms))], axis=<span class="hljs-number">0</span>)
    trainLabel = np.append(trainLabel, [trainLabel[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(tremNum * len(trainLabel))], axis=<span class="hljs-number">0</span>)
    trainValids = np.append(trainValids, [trainValids[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(tremNum * len(trainValids))], axis=<span class="hljs-number">0</span>)
    counter = len(gotData)
    <span class="hljs-keyword">for</span> lab <span class="hljs-keyword">in</span> range(len(gotData)):
        ori_img = gotData[lab].transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)
        <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            ori_segm = gotSegm[lab].copy()
        annot = trainLabel[lab].copy()
        annot_valid = trainValids[lab].copy()
        height, width = ori_img.shape[<span class="hljs-number">0</span>], ori_img.shape[<span class="hljs-number">1</span>]
        center = (width / <span class="hljs-number">2.</span>, height / <span class="hljs-number">2.</span>)
        n = cfg.nr_skeleton

        <span class="hljs-comment"># affrat = random.uniform(0.75, 1.25)</span>
        affrat = random.uniform(<span class="hljs-number">0.7</span>, <span class="hljs-number">1.35</span>)
        halfl_w = min(width - center[<span class="hljs-number">0</span>], (width - center[<span class="hljs-number">0</span>]) / <span class="hljs-number">1.25</span> * affrat)
        halfl_h = min(height - center[<span class="hljs-number">1</span>], (height - center[<span class="hljs-number">1</span>]) / <span class="hljs-number">1.25</span> * affrat)
        <span class="hljs-comment"># img = cv2.resize(ori_img[int(center[0] - halfl_w) : int(center[0] + halfl_w + 1), int(center[1] - halfl_h) : int(center[1] + halfl_h + 1)], (width, height))</span>
        img = cv2.resize(ori_img[int(center[<span class="hljs-number">1</span>] - halfl_h): int(center[<span class="hljs-number">1</span>] + halfl_h + <span class="hljs-number">1</span>),
                         int(center[<span class="hljs-number">0</span>] - halfl_w): int(center[<span class="hljs-number">0</span>] + halfl_w + <span class="hljs-number">1</span>)], (width, height))
        <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            segm = cv2.resize(ori_segm[int(center[<span class="hljs-number">1</span>] - halfl_h): int(center[<span class="hljs-number">1</span>] + halfl_h + <span class="hljs-number">1</span>),
                              int(center[<span class="hljs-number">0</span>] - halfl_w): int(center[<span class="hljs-number">0</span>] + halfl_w + <span class="hljs-number">1</span>)], (width, height))
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):
            annot[i &lt;&lt; <span class="hljs-number">1</span>] = (annot[i &lt;&lt; <span class="hljs-number">1</span>] - center[<span class="hljs-number">0</span>]) / halfl_w * (width - center[<span class="hljs-number">0</span>]) + center[<span class="hljs-number">0</span>]
            annot[i &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] = (annot[i &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] - center[<span class="hljs-number">1</span>]) / halfl_h * (height - center[<span class="hljs-number">1</span>]) + center[<span class="hljs-number">1</span>]
            annot_valid[i] *= (
            (annot[i &lt;&lt; <span class="hljs-number">1</span>] &gt;= <span class="hljs-number">0</span>) &amp; (annot[i &lt;&lt; <span class="hljs-number">1</span>] &lt; width) &amp; (annot[i &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] &gt;= <span class="hljs-number">0</span>) &amp; (annot[i &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>] &lt; height))

        trainData[lab] = img.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)
        <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            trainSegms[lab] = segm
        trainLabel[lab] = annot
        trainValids[lab] = annot_valid

        <span class="hljs-comment"># flip augmentation</span>
        newimg = cv2.flip(img, <span class="hljs-number">1</span>)
        <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            newsegm = cv2.flip(segm, <span class="hljs-number">1</span>)
        cod = []
        allc = []
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):
            x, y = annot[i &lt;&lt; <span class="hljs-number">1</span>], annot[i &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>]
            <span class="hljs-keyword">if</span> x &gt;= <span class="hljs-number">0</span>:
                x = width - <span class="hljs-number">1</span> - x
            cod.append((x, y))
        <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            trainSegms[counter] = newsegm
        trainData[counter] = newimg.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)

        <span class="hljs-comment"># **** the joint index depends on the dataset ****</span>
        <span class="hljs-keyword">for</span> (q, w) <span class="hljs-keyword">in</span> cfg.symmetry:
            cod[q], cod[w] = cod[w], cod[q]
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):
            allc.append(cod[i][<span class="hljs-number">0</span>])
            allc.append(cod[i][<span class="hljs-number">1</span>])
        trainLabel[counter] = np.array(allc)
        allc_valid = annot_valid.copy()
        <span class="hljs-keyword">for</span> (q, w) <span class="hljs-keyword">in</span> cfg.symmetry:
            allc_valid[q], allc_valid[w] = allc_valid[w], allc_valid[q]
        trainValids[counter] = np.array(allc_valid)
        counter += <span class="hljs-number">1</span>

        <span class="hljs-comment"># rotated augmentation</span>
        <span class="hljs-keyword">for</span> times <span class="hljs-keyword">in</span> range(tremNum - <span class="hljs-number">1</span>):
            angle = random.uniform(<span class="hljs-number">0</span>, <span class="hljs-number">45</span>)
            <span class="hljs-keyword">if</span> random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>):
                angle *= -<span class="hljs-number">1</span>
            rotMat = cv2.getRotationMatrix2D(center, angle, <span class="hljs-number">1.0</span>)
            newimg = cv2.warpAffine(img, rotMat, (width, height))
            <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
                newsegm = cv2.warpAffine(segm, rotMat, (width, height))

            allc = []
            allc_valid = []
            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(n):
                x, y = annot[i &lt;&lt; <span class="hljs-number">1</span>], annot[i &lt;&lt; <span class="hljs-number">1</span> | <span class="hljs-number">1</span>]
                coor = np.array([x, y])
                <span class="hljs-keyword">if</span> x &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> y &gt;= <span class="hljs-number">0</span>:
                    R = rotMat[:, : <span class="hljs-number">2</span>]
                    W = np.array([rotMat[<span class="hljs-number">0</span>][<span class="hljs-number">2</span>], rotMat[<span class="hljs-number">1</span>][<span class="hljs-number">2</span>]])
                    coor = np.dot(R, coor) + W
                allc.append(coor[<span class="hljs-number">0</span>])
                allc.append(coor[<span class="hljs-number">1</span>])
                allc_valid.append(
                    annot_valid[i] * ((coor[<span class="hljs-number">0</span>] &gt;= <span class="hljs-number">0</span>) &amp; (coor[<span class="hljs-number">0</span>] &lt; width) &amp; (coor[<span class="hljs-number">1</span>] &gt;= <span class="hljs-number">0</span>) &amp; (coor[<span class="hljs-number">1</span>] &lt; height)))

            newimg = newimg.transpose(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)
            trainData[counter] = newimg
            <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
                trainSegms[counter] = newsegm
            trainLabel[counter] = np.array(allc)
            trainValids[counter] = np.array(allc_valid)
            counter += <span class="hljs-number">1</span>
    <span class="hljs-keyword">if</span> trainSegms <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
        <span class="hljs-keyword">return</span> trainData, trainLabel, trainSegms
    <span class="hljs-keyword">else</span>:
        <span class="hljs-keyword">return</span> trainData, trainLabel, trainValids</code></pre> 
<h3 id="模型训练">模型训练</h3> 
<h3 id="cpn项目框架">cpn项目框架</h3> 
<p>tenssorflow项目的架构也可以学习一下，下面是cpn文件夹下的组织架构。 <br> <img title="" alt="这里写图片描述" src="https://images2.imgbox.com/56/a4/8brM2D70_o.png"></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/f7c4ba47fe998c8125ecb0547158ad00/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">接口测试 [测试报告优化] Jenkins&#43;JMeter 接口自动化【转载】</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/d67798fd91985c68fca73793c6149661/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">限流保护电路</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>