<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>SSD训练数据集流程（学习记录） - 菜鸟程序员博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:title" content="SSD训练数据集流程（学习记录）" />
<meta property="og:description" content="关于理论部分我看的是b站“霹雳吧啦Wz”的SSD理论讲解，作为入门小白表示能听懂，需要的同学可以自行观看
目录
1.训练环境
2.训练步骤
1.训练环境 我的环境是win11&#43;anaconda&#43;python3.6.13&#43;pytorch1.10.2&#43;cuda11.6
2.训练步骤 （1）下载SSD源码
可到github进行下载
GitHub - amdegroot/ssd.pytorch: A PyTorch Implementation of Single Shot MultiBox Detector
（2）下载模型文件
VGG16_reducedfc.pth预训练模型下载地址：https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth
将下载的模型文件放置于ssd源码目录中 wights/vgg16_reducedfc.pth
（3）数据集准备
与大多数训练模型一样，ssd支持的训练格式为VOC和coco，这里采用voc2007作为演示，制作自己的数据集以及labimg的使用可自行观看yolo数据集标注软件安装&#43;使用流程_道人兄的博客-CSDN博客_yolo数据集标注工具
voc2007的具体下载方式我也不多赘述，网络上百度也有，或者直接看我之前写的也有提到使用Faster—RCNN训练数据集流程（学习记录）_道人兄的博客-CSDN博客
将下载后的voc2007数据集放置于./data/VOCdevkit/中
然后到ssd.pytorch-master/data/中的voc0712.py进行修改其中的VOC_ROOT = osp.join(HOME, &#34;data/VOCdevkit/&#34;)，他这里的HOME老是读取我的C盘位置，所以一直报错，我直接把数据集的绝对路径写上去了就没报错
将 voc0712.py文件中VOCDetection类的__init__函数，将image_sets修改为[(&#39;2007&#39;, &#39;train&#39;), (&#39;2007&#39;, &#39;val&#39;),(&#39;2007&#39;,&#39;test&#39;)]，修改后的结果如下。
def __init__(self, root, image_sets=[(&#39;2007&#39;, &#39;train&#39;), (&#39;2007&#39;, &#39;val&#39;),(&#39;2007&#39;,&#39;test&#39;)], transform=None, target_transform=VOCAnnotationTransform(), dataset_name=&#39;VOC0712&#39;): 其中如果是训练自己的数据集，记得修改voc0712.py文件中的VOC_CLASSES 变量。例如，将VOC_CLASSES修改为person类，注意如果只有一类则需要加方括号，修改后的结果如下。
VOC_CLASSES = [(&#39;person&#39;) 如果训练自己的数据集，还需要修改config.py文件中的voc字典变量。将其中的num_classes修改为2（以person为例）（背景类&#43;你训练集的种类个数），第一次调试时可以将max_iter调小至1000，修改后的结果如下。
voc = { &#39;num_classes&#39;: 2, &#39;lr_steps&#39;: (80000, 100000, 120000), &#39;max_iter&#39;: 1000, &#39;feature_maps&#39;: [38, 19, 10, 5, 3, 1], &#39;min_dim&#39;: 300, &#39;steps&#39;: [8, 16, 32, 64, 100, 300], &#39;min_sizes&#39;: [30, 60, 111, 162, 213, 264], &#39;max_sizes&#39;: [60, 111, 162, 213, 264, 315], &#39;aspect_ratios&#39;: [[2], [2, 3], [2, 3], [2, 3], [2], [2]], &#39;variance&#39;: [0." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://cainiaoprogram.github.io/posts/f9bc755daea232d0dac8234e83d45570/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-09-14T21:50:07+08:00" />
<meta property="article:modified_time" content="2022-09-14T21:50:07+08:00" />


	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="菜鸟程序员博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">菜鸟程序员博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">SSD训练数据集流程（学习记录）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>关于理论部分我看的是b站“霹雳吧啦Wz”的SSD理论讲解，作为入门小白表示能听懂，需要的同学可以自行观看</p> 
<p id="main-toc"><strong>目录</strong></p> 
<p id="1.%E8%AE%AD%E7%BB%83%E7%8E%AF%E5%A2%83-toc" style="margin-left:0px;"><a href="#1.%E8%AE%AD%E7%BB%83%E7%8E%AF%E5%A2%83" rel="nofollow">1.训练环境</a></p> 
<p id="2.%E8%AE%AD%E7%BB%83%E6%AD%A5%E9%AA%A4-toc" style="margin-left:0px;"><a href="#2.%E8%AE%AD%E7%BB%83%E6%AD%A5%E9%AA%A4" rel="nofollow">2.训练步骤</a></p> 
<hr id="hr-toc"> 
<p></p> 
<h2 id="1.%E8%AE%AD%E7%BB%83%E7%8E%AF%E5%A2%83">1.训练环境</h2> 
<p>我的环境是win11+anaconda+python3.6.13+pytorch1.10.2+cuda11.6</p> 
<h2 id="2.%E8%AE%AD%E7%BB%83%E6%AD%A5%E9%AA%A4">2.训练步骤</h2> 
<p><strong>（1）下载SSD源码</strong></p> 
<p>可到github进行下载</p> 
<p><a href="https://github.com/amdegroot/ssd.pytorch" title="GitHub - amdegroot/ssd.pytorch: A PyTorch Implementation of Single Shot MultiBox Detector">GitHub - amdegroot/ssd.pytorch: A PyTorch Implementation of Single Shot MultiBox Detector</a></p> 
<p><strong>（2）下载模型文件</strong></p> 
<p>VGG16_reducedfc.pth预训练模型下载地址：https://s3.amazonaws.com/amdegroot-models/vgg16_reducedfc.pth</p> 
<p>将下载的模型文件放置于ssd源码目录中  wights/vgg16_reducedfc.pth</p> 
<p><img alt="" height="668" src="https://images2.imgbox.com/f8/04/zXiwKFdd_o.png" width="1008"></p> 
<p><strong>（3）数据集准备</strong></p> 
<p>与大多数训练模型一样，ssd支持的训练格式为VOC和coco，这里采用voc2007作为演示，制作自己的数据集以及labimg的使用可自行观看<a href="https://blog.csdn.net/hhb3329/article/details/126362532?spm=1001.2014.3001.5502" title="yolo数据集标注软件安装+使用流程_道人兄的博客-CSDN博客_yolo数据集标注工具">yolo数据集标注软件安装+使用流程_道人兄的博客-CSDN博客_yolo数据集标注工具</a></p> 
<p>voc2007的具体下载方式我也不多赘述，网络上百度也有，或者直接看我之前写的也有提到<a href="https://blog.csdn.net/hhb3329/article/details/126841297?spm=1001.2014.3001.5502" title="使用Faster—RCNN训练数据集流程（学习记录）_道人兄的博客-CSDN博客">使用Faster—RCNN训练数据集流程（学习记录）_道人兄的博客-CSDN博客</a></p> 
<p>将下载后的voc2007数据集放置于./data/VOCdevkit/中</p> 
<p><img alt="" height="595" src="https://images2.imgbox.com/80/db/clgHN0Rw_o.png" width="947"></p> 
<p> 然后到ssd.pytorch-master/data/中的voc0712.py进行修改其中的VOC_ROOT = osp.join(HOME, "data/VOCdevkit/")，他这里的HOME老是读取我的C盘位置，所以一直报错，我直接把数据集的绝对路径写上去了就没报错</p> 
<p><img alt="" height="106" src="https://images2.imgbox.com/fa/39/J0LFmYSz_o.png" width="766"></p> 
<p>将 <code>voc0712.py</code>文件中<code>VOCDetection</code>类的<code>__init__</code>函数，将<code>image_sets</code>修改为<code>[('2007', 'train'), ('2007', 'val'),('2007','test')]</code>，修改后的结果如下。</p> 
<pre><code class="hljs">def __init__(self, root,
             image_sets=[('2007', 'train'), ('2007', 'val'),('2007','test')],
             transform=None, target_transform=VOCAnnotationTransform(),
             dataset_name='VOC0712'):</code></pre> 
<p>其中如果是训练自己的数据集，记得修改<code>voc0712.py</code>文件中的<code>VOC_CLASSES </code>变量。例如，将VOC_CLASSES修改为person类，<strong>注意如果只有一类则需要加方括号</strong>，修改后的结果如下。</p> 
<pre><code class="hljs">VOC_CLASSES = [('person')
</code></pre> 
<p>如果训练自己的数据集，还需要修改<code>config.py</code>文件中的<code>voc</code>字典变量。将其中的<code>num_classes</code>修改为2（以person为例）（背景类+你训练集的种类个数），第一次调试时可以将<code>max_iter</code>调小至1000，修改后的结果如下。</p> 
<pre><code class="hljs">voc = {
    'num_classes': 2,
    'lr_steps': (80000, 100000, 120000),
    'max_iter': 1000,
    'feature_maps': [38, 19, 10, 5, 3, 1],
    'min_dim': 300,
    'steps': [8, 16, 32, 64, 100, 300],
    'min_sizes': [30, 60, 111, 162, 213, 264],
    'max_sizes': [60, 111, 162, 213, 264, 315],
    'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],
    'variance': [0.1, 0.2],
    'clip': True,
    'name': 'VOC',
}
</code></pre> 
<p>最后一步，把<code>coco_labels.txt</code>放在<code>ssd.pytorch-master/data/coco/</code>目录下，也可以通过修改<code>coco.py</code>文件中的<code>COCO_ROOT = osp.join(HOME, 'data/coco/')</code>来指定存放路径。</p> 
<p><strong>（4）修改源码</strong></p> 
<p>①修改<code>ssd.py</code>文件中<code>SSD</code>类的<code>__init__</code>函数和<code>forward</code>函数，修改后的结果如下。</p> 
<pre><code class="hljs">if phase == 'test':
	self.softmax = nn.Softmax(dim=-1)
    self.detect = Detect(num_classes, 0, 200, 0.01, 0.45)
修改为:
if phase == 'test':
	self.softmax = nn.Softmax()
	self.detect = Detect()
	</code></pre> 
<pre><code class="hljs">if self.phase == "test":
	output = self.detect(
    	loc.view(loc.size(0), -1, 4),                   # loc preds
        self.softmax(conf.view(conf.size(0), -1,
        			 self.num_classes)),                # conf preds
        self.priors.type(type(x.data))                  # default boxes
    )
修改为：
if self.phase == "test":
	output = self.detect.apply(21, 0, 200, 0.01, 0.45,
   		loc.view(loc.size(0), -1, 4),                   # loc preds
        self.softmax(conf.view(-1,21)),                 # conf preds
		self.priors.type(type(x.data))                  # default boxes
	)
</code></pre> 
<p>②修改<code>train.py</code>中187至189行代码，原因是<code>.data[0]</code>写法适用于低版本<a href="https://so.csdn.net/so/search?q=Pytorch&amp;spm=1001.2101.3001.7020" title="Pytorch">Pytorch</a>，否则会出现<code>IndexError:invalid index of a 0-dim tensor...</code>错误，修改后的结果如下。</p> 
<pre><code class="hljs">loc_loss += loss_l.item()
conf_loss += loss_c.item()

if iteration % 10 == 0:
    print('timer: %.4f sec.' % (t1 - t0))
	print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.item()), end=' ')
</code></pre> 
<p>③交换<code>layers/modules/multibox_loss.py</code>中97行和98代码位置，否则会出现<code>IndexError: The shape of the mask [14, 8732] at index 0does...</code>错误，修改后的结果如下。</p> 
<pre><code class="hljs">loss_c = loss_c.view(num, -1)
loss_c[pos] = 0  # filter out pos boxes for now
</code></pre> 
<p>④根据自己的需要对<code>train.py</code>中预训练模型、batch_size、学习率、模型名字和模型保存的次数等参数进行修改。建议学习率修改为<code>1e-4</code>（原因是原版使用1e-3可能会出现loss为nan情况），第一次调试时可以修改为每迭代100次保存，方便调试。</p> 
<pre><code class="hljs"># 加载模型初始参数
parser = argparse.ArgumentParser(
    description='Single Shot MultiBox Detector Training With Pytorch')
train_set = parser.add_mutually_exclusive_group()
# 默认加载VOC数据集
parser.add_argument('--dataset', default='VOC', choices=['VOC', 'COCO'],
                    type=str, help='VOC or COCO')
# 设置VOC数据集根路径
parser.add_argument('--dataset_root', default=VOC_ROOT,
                    help='Dataset root directory path')
# 设置预训练模型vgg16_reducedfc.pth
parser.add_argument('--basenet', default='vgg16_reducedfc.pth',
                    help='Pretrained base model')
# 设置批大小，根据自己显卡能力设置，默认为32，此处我改为16
parser.add_argument('--batch_size', default=16, type=int,
                    help='Batch size for training')
# 是否恢复中断的训练，默认不恢复
parser.add_argument('--resume', default=None, type=str,
                    help='Checkpoint state_dict file to resume training from')
# 恢复训练iter数，默认从第0次迭代开始
parser.add_argument('--start_iter', default=0, type=int,
                    help='Resume training at this iter')
# 数据加载线程数，根据自己CPU个数设置，默认为4
parser.add_argument('--num_workers', default=4, type=int,
                    help='Number of workers used in dataloading')
# 是否使用CUDA加速训练，默认开启，如果没有GPU，可改成False直接用CPU训练
parser.add_argument('--cuda', default=True, type=str2bool,
                    help='Use CUDA to train model')
# 学习率，默认0.001
parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,
                    help='initial learning rate')
# 最佳动量值，默认0.9（动量是梯度下降法中一种常用的加速技术，用于加速梯度下降，减少收敛耗时）
parser.add_argument('--momentum', default=0.9, type=float,
                    help='Momentum value for optim')
# 权重衰减，即正则化项前面的系数，用于防止过拟合；SGD，即mini-batch梯度下降
parser.add_argument('--weight_decay', default=1e-4, type=float,
                    help='Weight decay for SGD')
# gamma更新，默认值0.1
parser.add_argument('--gamma', default=0.1, type=float,
                    help='Gamma update for SGD')
# 使用visdom将训练过程loss图像可视化
parser.add_argument('--visdom', default=False, type=str2bool,
                    help='Use visdom for loss visualization')
# 权重保存位置，默认存在weights/下
parser.add_argument('--save_folder', default='weights/',
                    help='Directory for saving checkpoint models')
args = parser.parse_args()
</code></pre> 
<pre><code class="hljs">if iteration != 0 and iteration % 100 == 0:
	print('Saving state, iter:', iteration)
	torch.save(ssd_net.state_dict(), 'weights/ssd300_VOC_' + repr(iteration) + '.pth')
</code></pre> 
<p>⑤因为pytorch1.9以上版本在这份源代码中并不适用，一旦运行cuda方面会报错如下：</p> 
<pre><code class="hljs">RuntimeError: Expected a ‘cuda‘ device type for generator but found ‘cpu‘</code></pre> 
<p>参考github上的解决方法，有两种方法可成功运行：</p> 
<p>第一种是重装pytorch1.8版本，就可以正常运行，但我觉得太麻烦了</p> 
<p>第二种是修改源码：</p> 
<p>在位于 anaconda 或任何地方的文件“site-packages/torch/utils/data/sampler.py”中。</p> 
<pre><code class="hljs">[修改第 116 行]：generator = torch.Generator()
改成generator = torch.Generator(device='cuda')
[修改第 126 行]：yield from torch.randperm(n, generator=generator).tolist()
改成yield from torch.randperm(n, generator=generator, device='cuda').tolist()</code></pre> 
<p>在train.py文件中，data.DataLoader处进行添加generator</p> 
<pre><code class="hljs">data_loader = data.DataLoader(dataset, args.batch_size,
                                  num_workers=args.num_workers,
                                  shuffle=True, collate_fn=detection_collate,
                                  pin_memory=True, generator=torch.Generator(device='cuda'))</code></pre> 
<p><strong>（5）运行train.py，如下图</strong></p> 
<p><img alt="" height="858" src="https://images2.imgbox.com/58/28/jNqLSiXe_o.png" width="1200"></p> 
<p></p> 
<p>参考资料：</p> 
<p><a href="https://blog.csdn.net/qq_39506912/article/details/116926504" title="SSD训练自己的数据集（pytorch版）_Kellenn的博客-CSDN博客_ssd训练自己的数据集pytorch">SSD训练自己的数据集（pytorch版）_Kellenn的博客-CSDN博客_ssd训练自己的数据集pytorch</a></p> 
<p><a href="https://zhuanlan.zhihu.com/p/92154612" rel="nofollow" title="【目标检测实战】Pytorch—SSD模型训练（VOC数据集） - 知乎 (zhihu.com)">【目标检测实战】Pytorch—SSD模型训练（VOC数据集） - 知乎 (zhihu.com)</a></p> 
<p><a href="https://www.bilibili.com/video/BV1fT4y1L7Gi?spm_id_from=333.337.search-card.all.click" rel="nofollow" title="2.1SSD算法理论_哔哩哔哩_bilibili">2.1SSD算法理论_哔哩哔哩_bilibili</a></p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/19082d61e020e712bcb1f6edb3bb0021/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Druid03-守护线程</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/8f9198bd8367292384a5bae984471386/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Java.lang.Class类 isAnnotationPresent()方法有什么功能呢？</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 菜鸟程序员博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>